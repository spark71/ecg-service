{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8ec33fd3b09926",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-07T18:21:13.855229Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from app.ecg.ecg import Datasets, EcgSignal\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "ptbxl_data = pd.read_csv(r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\labels.csv', index_col=0)\n",
    "# ptbxl_statements = pd.read_csv(Datasets.ptbxl_scp_statements.path, index_col=0)\n",
    "# ptbxl_data['patient_id'] = ptbxl_data['patient_id'].astype(int)\n",
    "# ptbxl_data['nurse'] = ptbxl_data['nurse'].astype('Int64')\n",
    "# ptbxl_data['site'] = ptbxl_data['site'].astype('Int64')\n",
    "# ptbxl_data['validated_by'] = ptbxl_data['validated_by'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79b12c273058880e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:24.796121Z",
     "start_time": "2024-05-05T10:02:24.415908Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21388 entries, 15709.0 to 11744.0\n",
      "Data columns (total 29 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   age                           21388 non-null  float64\n",
      " 1   sex                           21388 non-null  int64  \n",
      " 2   height                        6918 non-null   float64\n",
      " 3   weight                        9366 non-null   float64\n",
      " 4   nurse                         19949 non-null  float64\n",
      " 5   site                          21372 non-null  float64\n",
      " 6   device                        21388 non-null  object \n",
      " 7   recording_date                21388 non-null  object \n",
      " 8   report                        21388 non-null  object \n",
      " 9   scp_codes                     21388 non-null  object \n",
      " 10  heart_axis                    13228 non-null  object \n",
      " 11  infarction_stadium1           5600 non-null   object \n",
      " 12  infarction_stadium2           103 non-null    object \n",
      " 13  validated_by                  12296 non-null  float64\n",
      " 14  second_opinion                21388 non-null  bool   \n",
      " 15  initial_autogenerated_report  21388 non-null  bool   \n",
      " 16  validated_by_human            21388 non-null  bool   \n",
      " 17  baseline_drift                1579 non-null   object \n",
      " 18  static_noise                  3206 non-null   object \n",
      " 19  burst_noise                   581 non-null    object \n",
      " 20  electrodes_problems           28 non-null     object \n",
      " 21  extra_beats                   1882 non-null   object \n",
      " 22  pacemaker                     14 non-null     object \n",
      " 23  strat_fold                    21388 non-null  int64  \n",
      " 24  filename_lr                   21388 non-null  object \n",
      " 25  filename_hr                   21388 non-null  object \n",
      " 26  scp_codes_len                 21388 non-null  int64  \n",
      " 27  superdiagnostic               21388 non-null  object \n",
      " 28  superdiagnostic_len           21388 non-null  int64  \n",
      "dtypes: bool(3), float64(6), int64(4), object(16)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "ptbxl_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4461ee8d19ddae25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:33.162618Z",
     "start_time": "2024-05-05T10:02:32.992583Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_file_paths(filename):\n",
    "    filename_lr = filename.split('/')[-1].split('_')[0]\n",
    "    return fr\"C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\{filename_lr}.npy\"\n",
    "\n",
    "clean_tags = lambda x: [e.replace(\"'\", \"\")  for e in x[1:-1].split(', ')]\n",
    "ptbxl_data[\"file_paths\"] = ptbxl_data[\"filename_lr\"].apply(get_file_paths)\n",
    "ptbxl_data[\"superdiagnostic\"] = ptbxl_data[\"superdiagnostic\"].apply(clean_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e073cf86be1dd6c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T10:14:38.419951Z",
     "start_time": "2024-05-03T10:14:38.376211Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>nurse</th>\n",
       "      <th>site</th>\n",
       "      <th>device</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>report</th>\n",
       "      <th>scp_codes</th>\n",
       "      <th>...</th>\n",
       "      <th>electrodes_problems</th>\n",
       "      <th>extra_beats</th>\n",
       "      <th>pacemaker</th>\n",
       "      <th>strat_fold</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "      <th>scp_codes_len</th>\n",
       "      <th>superdiagnostic</th>\n",
       "      <th>superdiagnostic_len</th>\n",
       "      <th>file_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15709.0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-09 09:17:34</td>\n",
       "      <td>sinusrhythmus periphere niederspannung</td>\n",
       "      <td>{'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00001_lr</td>\n",
       "      <td>records500/00000/00001_hr</td>\n",
       "      <td>3</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13243.0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-14 12:55:37</td>\n",
       "      <td>sinusbradykardie sonst normales ekg</td>\n",
       "      <td>{'NORM': 80.0, 'SBRAD': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/00000/00002_lr</td>\n",
       "      <td>records500/00000/00002_hr</td>\n",
       "      <td>2</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00002.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20372.0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 12:49:10</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>records100/00000/00003_lr</td>\n",
       "      <td>records500/00000/00003_hr</td>\n",
       "      <td>2</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00003.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17014.0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 13:44:57</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00004_lr</td>\n",
       "      <td>records500/00000/00004_hr</td>\n",
       "      <td>2</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00004.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17448.0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-17 10:43:15</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00005_lr</td>\n",
       "      <td>records500/00000/00005_hr</td>\n",
       "      <td>2</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00005.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17180.0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AT-60    3</td>\n",
       "      <td>2001-05-31 09:14:35</td>\n",
       "      <td>ventrikulÄre extrasystole(n) sinustachykardie linkstyp mÄssige amplitudenkriterien fÜr linkshypertrophie st &amp; t abnorm, wahrscheinlich    anterolaterale ischÄmie oder linksbelastung 4.46                          unbestÄtigter bericht</td>\n",
       "      <td>{'NDT': 100.0, 'PVC': 100.0, 'VCLVH': 0.0, 'STACH': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>records100/21000/21833_lr</td>\n",
       "      <td>records500/21000/21833_hr</td>\n",
       "      <td>4</td>\n",
       "      <td>[STTC]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21833.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20703.0</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AT-60    3</td>\n",
       "      <td>2001-06-05 11:33:39</td>\n",
       "      <td>sinusrhythmus lagetyp normal qrs(t) abnorm    inferiorer infarkt     wahrscheinlich alt 4.46                          unbestÄtigter bericht</td>\n",
       "      <td>{'NORM': 100.0, 'ABQRS': 0.0, 'SR': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/21000/21834_lr</td>\n",
       "      <td>records500/21000/21834_hr</td>\n",
       "      <td>3</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21834.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19311.0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AT-60    3</td>\n",
       "      <td>2001-06-08 10:30:27</td>\n",
       "      <td>sinusrhythmus lagetyp normal t abnorm in anterioren ableitungen 4.46                          unbestÄtigter bericht Edit: INJAS 50, (ISCAS)</td>\n",
       "      <td>{'ISCAS': 50.0, 'SR': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/21000/21835_lr</td>\n",
       "      <td>records500/21000/21835_hr</td>\n",
       "      <td>2</td>\n",
       "      <td>[STTC]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21835.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8873.0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AT-60    3</td>\n",
       "      <td>2001-06-09 18:21:49</td>\n",
       "      <td>supraventrikulÄre extrasystole(n) sinusrhythmus linkstyp t abnorm in hochlateralen ableitungen 4.46                          unbestÄtigter bericht</td>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>records100/21000/21836_lr</td>\n",
       "      <td>records500/21000/21836_hr</td>\n",
       "      <td>2</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21836.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744.0</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AT-60    3</td>\n",
       "      <td>2001-06-11 16:43:01</td>\n",
       "      <td>sinusrhythmus p-sinistrocardiale lagetyp normal 4.46                          unbestÄtigter bericht</td>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>records100/21000/21837_lr</td>\n",
       "      <td>records500/21000/21837_hr</td>\n",
       "      <td>2</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21837.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21388 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  sex  height  weight  nurse  site      device  \\\n",
       "patient_id                                                        \n",
       "15709.0      56.0    1     NaN    63.0    2.0   0.0   CS-12   E   \n",
       "13243.0      19.0    0     NaN    70.0    2.0   0.0   CS-12   E   \n",
       "20372.0      37.0    1     NaN    69.0    2.0   0.0   CS-12   E   \n",
       "17014.0      24.0    0     NaN    82.0    2.0   0.0   CS-12   E   \n",
       "17448.0      19.0    1     NaN    70.0    2.0   0.0   CS-12   E   \n",
       "...           ...  ...     ...     ...    ...   ...         ...   \n",
       "17180.0      67.0    1     NaN     NaN    1.0   2.0  AT-60    3   \n",
       "20703.0     300.0    0     NaN     NaN    1.0   2.0  AT-60    3   \n",
       "19311.0      59.0    1     NaN     NaN    1.0   2.0  AT-60    3   \n",
       "8873.0       64.0    1     NaN     NaN    1.0   2.0  AT-60    3   \n",
       "11744.0      68.0    0     NaN     NaN    1.0   2.0  AT-60    3   \n",
       "\n",
       "                 recording_date  \\\n",
       "patient_id                        \n",
       "15709.0     1984-11-09 09:17:34   \n",
       "13243.0     1984-11-14 12:55:37   \n",
       "20372.0     1984-11-15 12:49:10   \n",
       "17014.0     1984-11-15 13:44:57   \n",
       "17448.0     1984-11-17 10:43:15   \n",
       "...                         ...   \n",
       "17180.0     2001-05-31 09:14:35   \n",
       "20703.0     2001-06-05 11:33:39   \n",
       "19311.0     2001-06-08 10:30:27   \n",
       "8873.0      2001-06-09 18:21:49   \n",
       "11744.0     2001-06-11 16:43:01   \n",
       "\n",
       "                                                                                                                                                                                                                                               report  \\\n",
       "patient_id                                                                                                                                                                                                                                              \n",
       "15709.0                                                                                                                                                                                                        sinusrhythmus periphere niederspannung   \n",
       "13243.0                                                                                                                                                                                                           sinusbradykardie sonst normales ekg   \n",
       "20372.0                                                                                                                                                                                                                    sinusrhythmus normales ekg   \n",
       "17014.0                                                                                                                                                                                                                    sinusrhythmus normales ekg   \n",
       "17448.0                                                                                                                                                                                                                    sinusrhythmus normales ekg   \n",
       "...                                                                                                                                                                                                                                               ...   \n",
       "17180.0     ventrikulÄre extrasystole(n) sinustachykardie linkstyp mÄssige amplitudenkriterien fÜr linkshypertrophie st & t abnorm, wahrscheinlich    anterolaterale ischÄmie oder linksbelastung 4.46                          unbestÄtigter bericht   \n",
       "20703.0                                                                                                   sinusrhythmus lagetyp normal qrs(t) abnorm    inferiorer infarkt     wahrscheinlich alt 4.46                          unbestÄtigter bericht   \n",
       "19311.0                                                                                                   sinusrhythmus lagetyp normal t abnorm in anterioren ableitungen 4.46                          unbestÄtigter bericht Edit: INJAS 50, (ISCAS)   \n",
       "8873.0                                                                                             supraventrikulÄre extrasystole(n) sinusrhythmus linkstyp t abnorm in hochlateralen ableitungen 4.46                          unbestÄtigter bericht   \n",
       "11744.0                                                                                                                                           sinusrhythmus p-sinistrocardiale lagetyp normal 4.46                          unbestÄtigter bericht   \n",
       "\n",
       "                                                           scp_codes  ...  \\\n",
       "patient_id                                                            ...   \n",
       "15709.0                     {'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}  ...   \n",
       "13243.0                                 {'NORM': 80.0, 'SBRAD': 0.0}  ...   \n",
       "20372.0                                   {'NORM': 100.0, 'SR': 0.0}  ...   \n",
       "17014.0                                   {'NORM': 100.0, 'SR': 0.0}  ...   \n",
       "17448.0                                   {'NORM': 100.0, 'SR': 0.0}  ...   \n",
       "...                                                              ...  ...   \n",
       "17180.0     {'NDT': 100.0, 'PVC': 100.0, 'VCLVH': 0.0, 'STACH': 0.0}  ...   \n",
       "20703.0                     {'NORM': 100.0, 'ABQRS': 0.0, 'SR': 0.0}  ...   \n",
       "19311.0                                   {'ISCAS': 50.0, 'SR': 0.0}  ...   \n",
       "8873.0                                    {'NORM': 100.0, 'SR': 0.0}  ...   \n",
       "11744.0                                   {'NORM': 100.0, 'SR': 0.0}  ...   \n",
       "\n",
       "           electrodes_problems extra_beats pacemaker  strat_fold  \\\n",
       "patient_id                                                         \n",
       "15709.0                    NaN         NaN       NaN           3   \n",
       "13243.0                    NaN         NaN       NaN           2   \n",
       "20372.0                    NaN         NaN       NaN           5   \n",
       "17014.0                    NaN         NaN       NaN           3   \n",
       "17448.0                    NaN         NaN       NaN           4   \n",
       "...                        ...         ...       ...         ...   \n",
       "17180.0                    NaN         1ES       NaN           7   \n",
       "20703.0                    NaN         NaN       NaN           4   \n",
       "19311.0                    NaN         NaN       NaN           2   \n",
       "8873.0                     NaN        SVES       NaN           8   \n",
       "11744.0                    NaN         NaN       NaN           9   \n",
       "\n",
       "                          filename_lr                filename_hr  \\\n",
       "patient_id                                                         \n",
       "15709.0     records100/00000/00001_lr  records500/00000/00001_hr   \n",
       "13243.0     records100/00000/00002_lr  records500/00000/00002_hr   \n",
       "20372.0     records100/00000/00003_lr  records500/00000/00003_hr   \n",
       "17014.0     records100/00000/00004_lr  records500/00000/00004_hr   \n",
       "17448.0     records100/00000/00005_lr  records500/00000/00005_hr   \n",
       "...                               ...                        ...   \n",
       "17180.0     records100/21000/21833_lr  records500/21000/21833_hr   \n",
       "20703.0     records100/21000/21834_lr  records500/21000/21834_hr   \n",
       "19311.0     records100/21000/21835_lr  records500/21000/21835_hr   \n",
       "8873.0      records100/21000/21836_lr  records500/21000/21836_hr   \n",
       "11744.0     records100/21000/21837_lr  records500/21000/21837_hr   \n",
       "\n",
       "            scp_codes_len superdiagnostic superdiagnostic_len  \\\n",
       "patient_id                                                      \n",
       "15709.0                 3          [NORM]                   1   \n",
       "13243.0                 2          [NORM]                   1   \n",
       "20372.0                 2          [NORM]                   1   \n",
       "17014.0                 2          [NORM]                   1   \n",
       "17448.0                 2          [NORM]                   1   \n",
       "...                   ...             ...                 ...   \n",
       "17180.0                 4          [STTC]                   1   \n",
       "20703.0                 3          [NORM]                   1   \n",
       "19311.0                 2          [STTC]                   1   \n",
       "8873.0                  2          [NORM]                   1   \n",
       "11744.0                 2          [NORM]                   1   \n",
       "\n",
       "                                                                                 file_paths  \n",
       "patient_id                                                                                   \n",
       "15709.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00001.npy  \n",
       "13243.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00002.npy  \n",
       "20372.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00003.npy  \n",
       "17014.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00004.npy  \n",
       "17448.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00005.npy  \n",
       "...                                                                                     ...  \n",
       "17180.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21833.npy  \n",
       "20703.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21834.npy  \n",
       "19311.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21835.npy  \n",
       "8873.0      C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21836.npy  \n",
       "11744.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21837.npy  \n",
       "\n",
       "[21388 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptbxl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b50150dc67d5e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b1f96a43fa64a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:33.218017Z",
     "start_time": "2024-05-05T10:02:33.210194Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CD', 'HYP', 'MI', 'NORM', 'STTC']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(ptbxl_data[\"superdiagnostic\"].values)\n",
    "mlb.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "643096eccfee0d20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:34.684948Z",
     "start_time": "2024-05-05T10:02:34.666422Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_labels = mlb.transform(ptbxl_data[\"superdiagnostic\"].tolist())\n",
    "ptbxl_data[mlb.classes_.tolist()] = train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1fb054fea5c0d7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# ECGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f987bf45fa2937",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ecg_idx = pd.read_csv(r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\ptbxl_database.csv')\n",
    "ptbxl_data['ecg_id']=ecg_idx['ecg_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd773df0ca24acfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:39.842853Z",
     "start_time": "2024-05-05T10:02:39.753475Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQT kernels created, time used = 0.0460 seconds\n",
      "CQT kernels created, time used = 0.0053 seconds\n",
      "CQT kernels created, time used = 0.0056 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\redmi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\nnAudio\\utils.py:429: SyntaxWarning: If fmax is given, n_bins will be ignored\n",
      "  warnings.warn(\"If fmax is given, n_bins will be ignored\", SyntaxWarning)\n",
      "C:\\Users\\redmi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\nnAudio\\utils.py:429: SyntaxWarning: If fmax is given, n_bins will be ignored\n",
      "  warnings.warn(\"If fmax is given, n_bins will be ignored\", SyntaxWarning)\n",
      "C:\\Users\\redmi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\nnAudio\\utils.py:429: SyntaxWarning: If fmax is given, n_bins will be ignored\n",
      "  warnings.warn(\"If fmax is given, n_bins will be ignored\", SyntaxWarning)\n"
     ]
    }
   ],
   "source": [
    "from app.ecg.ecg import EcgDataset\n",
    "\n",
    "valid_df = ptbxl_data[ptbxl_data['strat_fold'] == 9]\n",
    "test_df = ptbxl_data[ptbxl_data['strat_fold'] == 10]\n",
    "\n",
    "dataset = EcgDataset(ptbxl_data)\n",
    "valid_dataset = EcgDataset(valid_df)\n",
    "test_dataset = EcgDataset(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0df29906ae7f07",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from models.ecgnet import ECGNet\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "model = ECGNet()\n",
    "model = model.double()\n",
    "model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\ecgnet_weights_authors.pt'\n",
    "model.load_state_dict(torch.load(model_weights_path, map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e122cee8a95095",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ecg, label = valid_dataset[151]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cee354f34b6668",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prediction = model(ecg)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188244ab06be9ada",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "softmaxed_pred = torch.softmax(prediction, dim=1).to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc03e5d6448a741",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(softmaxed_pred.detach().numpy(), label.numpy().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35f022bb3993bc7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "roc_auc_score(label.numpy().astype(int), prediction.detach().numpy().reshape(-1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decde7d78034b7b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ea4c22e7352cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gt_all = []\n",
    "pred_all = []\n",
    "\n",
    "for id in tqdm(range(len(test_dataset))):\n",
    "    ecg , label = test_dataset[id]\n",
    "    # print(ecg, label)\n",
    "    prediction = model(ecg)\n",
    "    pred_all.append(prediction.detach().numpy())\n",
    "    gt_all.append(label.detach().numpy().astype(int))\n",
    "gt_all_array = np.vstack(gt_all)\n",
    "pred_all_array = np.vstack(pred_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc156ab483e1dfb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gt_all_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388958f92c5ac114",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69fb1ec6d2fc8767",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:49.906375Z",
     "start_time": "2024-05-05T10:02:49.887567Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from models.metrics import Metrics, metric_summary, AUC, roc_auc_score\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    gt_all = []\n",
    "    pred_all = []\n",
    "    for id in tqdm(range(len(loader))):\n",
    "        ecg , label = loader[id]\n",
    "        # print(ecg, label)\n",
    "        prediction = model(ecg)\n",
    "        # pred_all.append(prediction.detach().numpy())\n",
    "        pred_all.append(prediction.detach().numpy())\n",
    "        # pred_all.append(sigmoid(prediction.detach().numpy()))\n",
    "        gt_all.append(label.detach().numpy().astype(int))\n",
    "    gt_all_array = np.vstack(gt_all)\n",
    "    pred_all_array = np.vstack(pred_all)\n",
    "    roc_score = roc_auc_score(gt_all_array, pred_all_array, average=\"macro\")\n",
    "    acc, mean_acc = Metrics(gt_all_array, pred_all_array)\n",
    "    class_auc = AUC(gt_all_array, pred_all_array)\n",
    "    summary = metric_summary(gt_all_array, pred_all_array)\n",
    "    print(f\"class wise accuracy: {acc}\")\n",
    "    print(f\"accuracy: {mean_acc}\")\n",
    "    print(f\"roc_score : {roc_score}\")\n",
    "    print(f\"class wise AUC : {class_auc}\")\n",
    "    print(f\"F1 score (Max): {summary[0]}\")\n",
    "    print(f\"class wise precision, recall, f1 score : {summary}\")\n",
    "    return gt_all_array, pred_all_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e43fe271d7d9e5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ebcdb2582caf93",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152ee2fbb3df21d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f5172eb2500c9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6932d76c1837e46",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6bcc6d4da46c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c59b4c57d529a01",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## EcgNet scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d97fda4adcffa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Metrics(gt_all_array, pred_all_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea31f2557d4ef3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"ecgNet(ptbxlv1.0.2) - test - aurroc- macro: \", roc_auc_score(gt_all_array, pred_all_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4559048a28a77",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "roc_score = roc_auc_score(gt_all_array, pred_all_array, average=\"macro\")\n",
    "acc, mean_acc = Metrics(gt_all_array, pred_all_array)\n",
    "class_auc = AUC(gt_all_array, pred_all_array)\n",
    "summary = metric_summary(gt_all_array, pred_all_array)\n",
    "\n",
    "print(f\"class wise accuracy: {acc}\")\n",
    "print(f\"accuracy: {mean_acc}\")\n",
    "print(f\"roc_score : {roc_score}\")\n",
    "print(f\"class wise AUC : {class_auc}\")\n",
    "print(f\"F1 score (Max): {summary[0]}\")\n",
    "print(f\"class wise precision, recall, f1 score : {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e3a5f3d881f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pred_all_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9010427bbacdd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pred_all_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c92ca294fc5c39",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dab90f685d0d81",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76120faf77a5dae6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"ecgNet - valid - aurroc- macro: \", roc_auc_score(np.vstack(gt_all), np.vstack(pred_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ceeb02518f7b3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68585738728bba96",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097057d1a10e485",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2909445cc75fc42a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# ResNet50 CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8524b9ff0e471477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:40:21.032667Z",
     "start_time": "2024-05-02T17:40:20.717701Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (model): EfficientNet(\n",
       "    (conv_stem): Conv2dSame(1, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvBnAct(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): EdgeResidual(\n",
       "          (conv_exp): Conv2dSame(24, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): EdgeResidual(\n",
       "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): EdgeResidual(\n",
       "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): EdgeResidual(\n",
       "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): EdgeResidual(\n",
       "          (conv_exp): Conv2dSame(48, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): EdgeResidual(\n",
       "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): EdgeResidual(\n",
       "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): EdgeResidual(\n",
       "          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2dSame(960, 960, kernel_size=(3, 3), stride=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (12): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (13): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (14): InvertedResidual(\n",
       "          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNormAct2d(\n",
       "      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Linear(in_features=1280, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.nn.custom_model_cqt import CustomModel\n",
    "from models.config import CqtCFG\n",
    "import torch\n",
    "\n",
    "model_resnet50cqt = CustomModel(CqtCFG)\n",
    "# model = model.double()\n",
    "model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\resnet50\\resnet50d_fold9_best_score.pth'\n",
    "model_resnet50cqt.load_state_dict(torch.load(model_weights_path, map_location=torch.device('cpu')), strict=False)\n",
    "model_resnet50cqt.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e583f00aee24c0a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "valid_dataset = EcgDataset(valid_df, feature='cqt')\n",
    "test_dataset = EcgDataset(test_df, feature='cqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afc5f7af082c58",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cqt_im, label = valid_dataset[0]\n",
    "# cqt_im = cqt_im[None, None, :]\n",
    "cqt_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d7ebee8990579",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_resnet50cqt(cqt_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c82b736339110cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:44:08.154112Z",
     "start_time": "2024-05-02T17:40:48.236478Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2146/2146 [03:19<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.7688723205964585, 0.874650512581547, 0.7483690587138863, 0.554520037278658, 0.7539608574091333]\n",
      "accuracy: 0.7400745573159366\n",
      "roc_score : 0.48158220540497876\n",
      "class wise AUC : [0.4902048957167067, 0.6007075246769349, 0.410993496609935, 0.431645280265165, 0.4743598297561523]\n",
      "F1 score (Max): 0.39902638981000393\n",
      "class wise precision, recall, f1 score : (0.39902638981000393, 0.48158220540497876, [0.39902638981000393, nan, nan, nan, nan, nan, nan, nan, nan, nan], [0.2630475302889096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8260329294812053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\metrics.py:145: RuntimeWarning: invalid value encountered in divide\n",
      "  2\n"
     ]
    }
   ],
   "source": [
    "gt_v, labels_v = evaluate_model(model_resnet50cqt, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74b087034a7a72e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:47:15.006619Z",
     "start_time": "2024-05-02T17:44:08.155180Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [03:06<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.7701575532900834, 0.8785912882298424, 0.7451343836886005, 0.5537534754402225, 0.7585727525486562]\n",
      "accuracy: 0.7412418906394811\n",
      "roc_score : 0.4783042559310203\n",
      "class wise AUC : [0.4759435289779123, 0.5896564080265404, 0.4259294436906377, 0.42449719104784994, 0.4754947079121608]\n",
      "F1 score (Max): 0.3997443915639605\n",
      "class wise precision, recall, f1 score : (0.3997443915639605, 0.4783042559310203, [0.3997443915639605, nan, nan, nan, nan, nan, nan, nan, nan, nan], [0.26309082483781276, nan, nan, nan, nan, nan, nan, nan, nan, nan], [0.8317886932344764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    }
   ],
   "source": [
    "gt_t, labels_t = evaluate_model(model_resnet50cqt, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60d5a23779511978",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:29:52.588365Z",
     "start_time": "2024-05-02T17:29:52.584387Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2146"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee1bc7e81045f7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37e156c06f6094",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3484bd88496cb4a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from models.nn.xresnet1d import xresnet1d101\n",
    "from models.nn.inception1d import inception1d\n",
    "from models.nn.resnet1d import resnet1d_wang\n",
    "from models.nn.rnn1d import RNN1d\n",
    "\n",
    "def model_factory(model_name):\n",
    "    model = None\n",
    "    if model_name.lower()=='xresnet1d101':\n",
    "        model = xresnet1d101(input_channels=12, num_classes=5)\n",
    "\n",
    "    if model_name.lower()=='resnet1d_dwang':\n",
    "        model = resnet1d_wang(input_channels=12, num_classes=5)\n",
    "\n",
    "    if model_name.lower()=='inception1d_model':\n",
    "        model = inception1d(input_channels=12, num_classes=5)\n",
    "\n",
    "    if model_name.lower()=='rnn_1d':\n",
    "        model = RNN1d(input_channels=12, num_classes=5)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020b92e61353f77",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Xresnet1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "259e254f991b3dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:03:27.002826Z",
     "start_time": "2024-05-04T11:03:26.799545Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XResNet1d(\n",
       "  (0): ConvLayer(\n",
       "    (0): Conv1d(12, 32, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): ConvLayer(\n",
       "    (0): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (2): ConvLayer(\n",
       "    (0): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (3): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential(\n",
       "        (0): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential(\n",
       "        (0): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential(\n",
       "        (0): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ConvLayer(\n",
       "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (convpath): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): Sequential(\n",
       "    (0): AdaptiveConcatPool1d(\n",
       "      (ap): AdaptiveAvgPool1d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool1d(output_size=1)\n",
       "    )\n",
       "    (1): fastai.layers.Flatten(full=False)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=5, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.nn.xresnet1d import xresnet1d101\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "xresnet1d_model = xresnet1d101(input_channels=12, num_classes=5)\n",
    "xresnet1d_model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\xresnet1d101\\exp0_xresnet1d101xresnet1d101_fold1_19epoch_best_score.pth'\n",
    "xresnet1d_model.load_state_dict(torch.load(xresnet1d_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "xresnet1d_model.double()\n",
    "xresnet1d_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4739d1841f20cdb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:02:28.714419Z",
     "start_time": "2024-05-04T11:02:27.831688Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.0.weight',\n",
       "              tensor([[[ 1.8142e-01,  7.3431e-02,  5.3870e-02,  3.5905e-01,  1.3066e-01],\n",
       "                       [ 1.8385e-01, -1.3094e-02,  2.9767e-01, -2.4098e-01, -1.8627e-01],\n",
       "                       [ 1.3199e-01,  4.4830e-02,  2.1216e-01,  5.5411e-02, -4.7518e-01],\n",
       "                       ...,\n",
       "                       [-3.0620e-02, -8.0225e-02,  2.6821e-01, -1.3437e-01,  1.1454e-01],\n",
       "                       [ 1.2754e-01, -1.2078e-01, -3.6862e-02,  1.4472e-02,  3.2900e-01],\n",
       "                       [ 5.1923e-02, -1.9296e-01,  1.9608e-01,  1.5318e-01, -2.3305e-01]],\n",
       "              \n",
       "                      [[ 1.5843e-01,  8.3384e-02,  5.8071e-02, -2.7533e-01, -2.3064e-02],\n",
       "                       [-7.6667e-02,  1.5067e-01,  2.9896e-02,  4.8615e-02,  1.1374e-01],\n",
       "                       [ 1.0984e-01, -2.0519e-01, -3.3914e-01, -2.2472e-01, -1.9918e-01],\n",
       "                       ...,\n",
       "                       [-1.0513e-01, -1.6065e-01,  3.6400e-01,  2.0428e-02, -3.3001e-01],\n",
       "                       [ 1.1119e-01,  1.2087e-01,  5.8882e-02,  5.5821e-02, -5.4590e-02],\n",
       "                       [-3.4875e-01, -2.6626e-01, -1.7945e-01,  5.2568e-02,  9.2048e-02]],\n",
       "              \n",
       "                      [[ 6.7100e-02, -8.9009e-02,  1.1362e-02, -6.5221e-02,  1.4460e-02],\n",
       "                       [ 1.9144e-02,  2.3788e-01,  2.7005e-01, -1.4637e-02, -3.3012e-01],\n",
       "                       [-8.5369e-02, -1.1732e-01, -6.2112e-02,  3.1848e-01, -1.6402e-02],\n",
       "                       ...,\n",
       "                       [ 1.5230e-01, -2.4053e-01, -5.9737e-02, -2.0545e-01, -2.1431e-01],\n",
       "                       [-1.3712e-01,  2.2459e-01, -2.3323e-01,  1.0478e-01,  2.4299e-01],\n",
       "                       [ 2.9252e-02, -1.9998e-01, -1.1249e-02, -1.3829e-01, -2.0762e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.1088e-01,  1.1797e-01, -1.9388e-01, -1.0595e-01,  4.5392e-02],\n",
       "                       [ 6.1369e-02, -2.2131e-01,  4.4713e-01, -8.4693e-02, -1.4848e-02],\n",
       "                       [-1.6866e-01, -1.4169e-01, -4.8375e-04, -1.9565e-01,  2.5288e-01],\n",
       "                       ...,\n",
       "                       [-4.7099e-02, -1.3080e-01, -2.2034e-02,  1.3363e-01, -6.2930e-02],\n",
       "                       [-2.3401e-01, -1.5473e-01, -4.2944e-01, -1.0522e-01,  1.1997e-01],\n",
       "                       [-2.7166e-02, -8.8035e-02, -2.4874e-01,  2.6091e-02,  2.3113e-01]],\n",
       "              \n",
       "                      [[ 1.7078e-01, -1.6780e-01, -2.8516e-01,  1.4793e-01, -5.6160e-02],\n",
       "                       [ 2.4429e-01,  1.0378e-01,  2.6631e-01, -1.5251e-01,  3.9580e-02],\n",
       "                       [-1.7805e-02, -6.2298e-01,  1.2660e-01,  1.3032e-01,  1.8159e-01],\n",
       "                       ...,\n",
       "                       [-1.4208e-01, -1.0314e-01, -4.1072e-02, -6.3404e-03,  2.5427e-01],\n",
       "                       [ 9.3824e-03,  9.6014e-02,  1.9215e-01,  2.3597e-01,  1.4155e-01],\n",
       "                       [ 2.4701e-02, -1.6221e-01,  2.3640e-01,  2.7928e-01,  2.5473e-01]],\n",
       "              \n",
       "                      [[-2.2399e-01, -9.9106e-02,  5.2873e-02, -3.5546e-03, -4.3621e-02],\n",
       "                       [-1.6182e-01, -1.0037e-01,  6.1368e-02, -4.3329e-02, -4.7866e-02],\n",
       "                       [-4.1003e-01,  8.9400e-02,  4.5471e-02,  2.4312e-01, -7.7074e-02],\n",
       "                       ...,\n",
       "                       [-1.5430e-01, -1.2417e-01, -2.0403e-01, -1.2153e-01,  1.7421e-01],\n",
       "                       [-4.0174e-02, -3.6258e-02,  7.3798e-03, -9.7204e-02,  2.9192e-01],\n",
       "                       [-1.8855e-01, -1.6982e-02, -8.4379e-02,  1.5244e-01, -9.8980e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('0.1.weight',\n",
       "              tensor([1.0256, 0.9981, 0.9940, 0.9749, 0.9827, 1.0117, 0.9942, 1.0147, 1.0166,\n",
       "                      0.9979, 1.0118, 0.9872, 0.9793, 0.9705, 0.9939, 1.0038, 0.9858, 1.0022,\n",
       "                      1.0183, 0.9843, 0.9880, 0.9862, 1.0089, 1.0003, 0.9893, 1.0363, 1.0024,\n",
       "                      0.9854, 1.0239, 0.9992, 0.9972, 1.0019], dtype=torch.float64)),\n",
       "             ('0.1.bias',\n",
       "              tensor([ 0.0285,  0.0121, -0.0014,  0.0013, -0.0237,  0.0207,  0.0100,  0.0021,\n",
       "                      -0.0203,  0.0159,  0.0013,  0.0173,  0.0140,  0.0184, -0.0005,  0.0202,\n",
       "                       0.0074, -0.0076,  0.0112,  0.0037, -0.0043,  0.0336,  0.0222,  0.0030,\n",
       "                      -0.0003,  0.0266, -0.0235,  0.0164,  0.0245,  0.0219,  0.0060,  0.0115],\n",
       "                     dtype=torch.float64)),\n",
       "             ('0.1.running_mean',\n",
       "              tensor([-0.0020, -0.0012,  0.0003,  0.0028, -0.0014,  0.0034,  0.0019, -0.0017,\n",
       "                      -0.0013, -0.0001, -0.0010,  0.0011, -0.0020, -0.0005,  0.0011,  0.0011,\n",
       "                       0.0015,  0.0004, -0.0025,  0.0009, -0.0022,  0.0016,  0.0014, -0.0010,\n",
       "                      -0.0008,  0.0001, -0.0014, -0.0007,  0.0004, -0.0006, -0.0021,  0.0008],\n",
       "                     dtype=torch.float64)),\n",
       "             ('0.1.running_var',\n",
       "              tensor([0.0549, 0.1067, 0.0656, 0.1858, 0.0870, 0.1217, 0.1490, 0.1063, 0.1662,\n",
       "                      0.0764, 0.1530, 0.0821, 0.1092, 0.0615, 0.2373, 0.0720, 0.0685, 0.0588,\n",
       "                      0.1434, 0.1179, 0.0939, 0.1489, 0.1569, 0.1877, 0.0950, 0.0653, 0.1692,\n",
       "                      0.0899, 0.0625, 0.2387, 0.1246, 0.1326], dtype=torch.float64)),\n",
       "             ('0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('1.0.weight',\n",
       "              tensor([[[ 0.1792,  0.1373,  0.0095,  0.0509, -0.0256],\n",
       "                       [ 0.0421,  0.0153, -0.1042, -0.0502, -0.0098],\n",
       "                       [ 0.1210,  0.0740,  0.2457, -0.2052,  0.0847],\n",
       "                       ...,\n",
       "                       [-0.0379,  0.0130, -0.1263,  0.1348,  0.0393],\n",
       "                       [-0.0458,  0.0491, -0.1407,  0.0286, -0.0296],\n",
       "                       [-0.1918, -0.0042, -0.1062, -0.0770,  0.0754]],\n",
       "              \n",
       "                      [[-0.1043, -0.1417, -0.0277, -0.0091,  0.1257],\n",
       "                       [ 0.0358, -0.0465, -0.0784,  0.1200,  0.0426],\n",
       "                       [ 0.0471,  0.0922, -0.2601, -0.0401, -0.0515],\n",
       "                       ...,\n",
       "                       [-0.0601, -0.0150, -0.1416,  0.0053,  0.1024],\n",
       "                       [-0.1586,  0.2321, -0.0355, -0.0391, -0.1704],\n",
       "                       [-0.1508, -0.0785, -0.0112,  0.1335,  0.0295]],\n",
       "              \n",
       "                      [[-0.0562,  0.0343,  0.1193, -0.0672,  0.0690],\n",
       "                       [ 0.1489, -0.0309, -0.0731,  0.0197,  0.2458],\n",
       "                       [-0.1964,  0.1160, -0.1031, -0.0227,  0.0784],\n",
       "                       ...,\n",
       "                       [ 0.1470,  0.0772,  0.2638, -0.2208, -0.0906],\n",
       "                       [ 0.0061, -0.0813,  0.0386,  0.0161,  0.1246],\n",
       "                       [ 0.0870,  0.0623,  0.0862, -0.1021,  0.0363]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1294,  0.0225,  0.0272, -0.1567, -0.0197],\n",
       "                       [ 0.0371,  0.1694, -0.0371,  0.0981,  0.0748],\n",
       "                       [-0.0567,  0.0498,  0.0160,  0.0151, -0.0614],\n",
       "                       ...,\n",
       "                       [-0.1022,  0.0448, -0.0961, -0.0501, -0.2109],\n",
       "                       [ 0.1804,  0.0800,  0.1375, -0.2404,  0.1176],\n",
       "                       [ 0.1614,  0.0451,  0.0421, -0.0848,  0.0614]],\n",
       "              \n",
       "                      [[-0.1594, -0.0312,  0.0459,  0.0538, -0.0574],\n",
       "                       [-0.2070,  0.0313, -0.0608, -0.0287,  0.0404],\n",
       "                       [-0.1018,  0.0286, -0.0148, -0.1065,  0.1594],\n",
       "                       ...,\n",
       "                       [ 0.0044, -0.0334,  0.0090, -0.0520, -0.1631],\n",
       "                       [-0.0564,  0.0025,  0.0222, -0.0024, -0.0766],\n",
       "                       [ 0.0654, -0.0813, -0.0262,  0.0583, -0.2343]],\n",
       "              \n",
       "                      [[ 0.1262,  0.0851,  0.0017, -0.0492, -0.0588],\n",
       "                       [-0.1227, -0.0504,  0.0506,  0.0807,  0.0867],\n",
       "                       [ 0.0725, -0.0701, -0.0844, -0.0609,  0.1351],\n",
       "                       ...,\n",
       "                       [ 0.2385,  0.0894, -0.2984,  0.1184,  0.0278],\n",
       "                       [-0.1200, -0.0118,  0.0927, -0.0080, -0.0969],\n",
       "                       [ 0.1341, -0.0884, -0.0201,  0.0957, -0.2917]]], dtype=torch.float64)),\n",
       "             ('1.1.weight',\n",
       "              tensor([0.9957, 1.0116, 0.9813, 1.0151, 0.9812, 1.0149, 0.9986, 1.0037, 0.9824,\n",
       "                      1.0101, 1.0039, 0.9914, 1.0077, 0.9961, 1.0063, 0.9838, 1.0047, 1.0239,\n",
       "                      0.9858, 0.9830, 0.9852, 0.9916, 1.0080, 1.0127, 1.0048, 0.9993, 0.9997,\n",
       "                      1.0087, 0.9992, 0.9928, 1.0004, 1.0175], dtype=torch.float64)),\n",
       "             ('1.1.bias',\n",
       "              tensor([-4.9479e-03,  1.7407e-02,  5.1747e-03, -9.1318e-03, -1.9549e-02,\n",
       "                       2.0546e-03, -8.7642e-03,  9.3265e-03, -1.0278e-02,  5.9583e-04,\n",
       "                       2.0592e-02,  1.1175e-02,  3.5771e-03,  8.2693e-03,  3.4966e-02,\n",
       "                      -2.6960e-05,  6.0321e-03,  7.3801e-03, -1.8404e-03, -3.1908e-03,\n",
       "                       8.2527e-03,  8.9980e-03, -5.0678e-03,  2.4535e-02,  2.3169e-02,\n",
       "                       7.0387e-03,  2.8083e-02,  3.4305e-02,  7.7073e-03, -4.0067e-03,\n",
       "                      -1.7835e-02, -4.8574e-03], dtype=torch.float64)),\n",
       "             ('1.1.running_mean',\n",
       "              tensor([ 0.1596, -0.1466,  0.3522,  0.2990,  0.4340, -0.1912,  0.5141,  0.3467,\n",
       "                       0.4756,  0.0909,  0.1192, -0.0038, -0.1492,  0.4331,  0.2963, -0.1779,\n",
       "                      -0.2143, -0.2880,  0.6299,  0.7319,  0.3780, -0.0898,  0.4724, -0.1841,\n",
       "                       0.0842,  0.7220, -0.2232, -0.1767,  0.0151, -0.1095,  0.4916,  0.0749],\n",
       "                     dtype=torch.float64)),\n",
       "             ('1.1.running_var',\n",
       "              tensor([0.5603, 1.2079, 0.4409, 0.9406, 0.8824, 1.0851, 1.7819, 0.8829, 1.2970,\n",
       "                      1.3613, 0.7377, 0.7159, 1.1056, 0.9248, 0.9388, 0.4989, 0.7867, 0.6205,\n",
       "                      0.5819, 1.5427, 0.9711, 1.5751, 1.2026, 0.8510, 0.8826, 1.2662, 0.7732,\n",
       "                      2.3372, 0.7388, 0.7145, 1.5672, 0.8055], dtype=torch.float64)),\n",
       "             ('1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('2.0.weight',\n",
       "              tensor([[[-5.0828e-02, -6.8369e-02, -1.4442e-01, -1.0350e-01,  3.6731e-02],\n",
       "                       [ 3.3094e-02, -1.9343e-03,  1.4545e-01, -1.1399e-01, -1.1857e-01],\n",
       "                       [-9.4462e-02,  4.0412e-02, -1.0198e-01, -1.6336e-01,  1.0333e-01],\n",
       "                       ...,\n",
       "                       [ 1.4770e-01,  2.0168e-01,  1.5744e-03,  4.4223e-02,  2.4812e-02],\n",
       "                       [ 2.1221e-02,  9.1801e-03, -2.2107e-02,  1.9760e-02, -7.6695e-02],\n",
       "                       [-1.0747e-01,  1.0171e-01, -4.4595e-02, -1.8845e-02, -1.1914e-01]],\n",
       "              \n",
       "                      [[ 2.2586e-01,  2.1935e-02,  1.3503e-01, -1.3698e-01, -1.4498e-01],\n",
       "                       [-1.5009e-01, -1.4320e-01, -1.8605e-01, -1.1319e-01,  2.3845e-01],\n",
       "                       [-1.5216e-01,  2.7589e-02,  9.1368e-02, -5.0800e-03,  5.6975e-02],\n",
       "                       ...,\n",
       "                       [ 1.1628e-01, -4.5862e-02, -6.3646e-02,  6.0994e-02,  8.9624e-02],\n",
       "                       [-8.0859e-02, -7.9648e-02, -1.2451e-01,  7.4267e-02, -2.8675e-01],\n",
       "                       [ 8.9720e-02, -1.7418e-01,  7.3221e-02, -6.3739e-02,  1.0362e-01]],\n",
       "              \n",
       "                      [[ 2.0741e-02,  5.7559e-02,  1.3979e-01,  1.8134e-01, -2.3057e-01],\n",
       "                       [ 2.4202e-02,  2.1860e-01,  1.7040e-01,  1.8397e-01,  1.7941e-01],\n",
       "                       [-1.8589e-01, -9.2332e-02,  2.7689e-02, -1.0780e-01,  7.1783e-02],\n",
       "                       ...,\n",
       "                       [-3.1190e-02,  1.5541e-02,  6.9423e-02,  3.1812e-02, -5.8314e-02],\n",
       "                       [ 9.1042e-02,  1.9255e-01, -1.6854e-02, -1.8149e-01, -4.0924e-02],\n",
       "                       [ 7.2905e-03,  1.3938e-01, -7.9636e-02,  1.0899e-02, -8.6410e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.8332e-02, -1.8266e-01,  1.2075e-02,  1.6065e-01,  4.9590e-02],\n",
       "                       [ 9.8270e-02,  4.3527e-02, -1.3785e-01, -1.3253e-01,  4.1328e-02],\n",
       "                       [-1.0669e-01, -8.6518e-02,  3.2768e-02, -8.7622e-02, -4.4476e-03],\n",
       "                       ...,\n",
       "                       [ 2.6281e-01,  7.4776e-02,  4.4956e-02,  2.8837e-02, -2.5415e-02],\n",
       "                       [ 9.3166e-02, -9.2009e-02,  9.7770e-03, -1.0860e-01,  6.3465e-02],\n",
       "                       [-2.0922e-02, -1.8236e-02,  1.6355e-01,  1.1635e-01, -1.8365e-01]],\n",
       "              \n",
       "                      [[ 4.7051e-02, -7.6047e-02,  9.4924e-02, -3.0314e-02, -9.0751e-02],\n",
       "                       [ 5.6992e-02, -7.8012e-02,  5.9171e-02, -1.5740e-01,  8.6556e-02],\n",
       "                       [-6.5004e-02,  7.7237e-02, -2.5840e-01,  3.9884e-02,  2.1299e-02],\n",
       "                       ...,\n",
       "                       [-2.7318e-02, -5.2195e-03, -3.0119e-02, -1.0867e-01, -3.7999e-02],\n",
       "                       [ 2.6635e-02,  5.8282e-02, -4.3859e-02,  2.3174e-02, -9.5806e-02],\n",
       "                       [-4.2134e-02, -7.7897e-02, -2.1096e-01,  9.2208e-02,  5.1147e-02]],\n",
       "              \n",
       "                      [[ 2.7598e-01,  8.4980e-02,  7.3107e-02,  8.8136e-02,  9.6620e-02],\n",
       "                       [ 2.1128e-01, -3.2471e-04, -3.5583e-01, -9.6179e-03,  1.2868e-01],\n",
       "                       [ 3.0512e-02, -8.7394e-05, -2.6139e-02, -3.2137e-02, -8.1327e-02],\n",
       "                       ...,\n",
       "                       [-6.7315e-02,  6.6562e-03, -2.2074e-01, -4.8521e-02,  1.1588e-01],\n",
       "                       [-3.7663e-02, -2.4684e-03,  1.6399e-01, -1.6640e-01,  1.7227e-01],\n",
       "                       [-1.9765e-02, -1.7504e-02,  4.3512e-02, -1.0225e-01, -8.6585e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('2.1.weight',\n",
       "              tensor([1.0114, 0.9971, 0.9957, 1.0026, 1.0004, 1.0105, 0.9932, 0.9981, 0.9985,\n",
       "                      0.9963, 1.0062, 1.0025, 1.0033, 0.9957, 0.9969, 0.9933, 0.9955, 1.0324,\n",
       "                      1.0062, 0.9969, 0.9955, 0.9905, 1.0038, 0.9978, 1.0066, 0.9979, 0.9928,\n",
       "                      0.9903, 1.0011, 1.0014, 1.0054, 0.9993, 0.9737, 1.0166, 0.9919, 1.0067,\n",
       "                      0.9901, 0.9944, 0.9805, 1.0041, 0.9898, 0.9883, 0.9997, 1.0276, 0.9846,\n",
       "                      0.9779, 1.0005, 0.9831, 1.0027, 0.9953, 1.0010, 0.9957, 0.9898, 0.9938,\n",
       "                      0.9988, 1.0064, 0.9940, 1.0068, 1.0055, 1.0007, 0.9901, 1.0025, 0.9999,\n",
       "                      0.9998], dtype=torch.float64)),\n",
       "             ('2.1.bias',\n",
       "              tensor([ 1.7756e-04, -1.4567e-03,  3.0595e-03,  4.0203e-04, -1.7294e-02,\n",
       "                       1.0945e-02,  5.7030e-03,  6.6402e-03, -3.2791e-03, -1.1743e-02,\n",
       "                       1.4788e-02,  3.1075e-03,  8.4751e-03, -6.3035e-03,  1.3796e-03,\n",
       "                      -1.3271e-03, -8.6666e-03,  5.7363e-03,  1.0790e-02, -1.7395e-02,\n",
       "                      -3.5906e-05, -1.7418e-02,  4.4519e-03, -6.3363e-03, -2.2705e-04,\n",
       "                      -4.6684e-03, -1.0280e-02, -4.8785e-04, -3.8618e-03, -7.0208e-03,\n",
       "                       2.7067e-03, -5.4941e-03, -3.3125e-02, -7.4132e-03, -2.1683e-02,\n",
       "                      -7.8934e-03, -1.4289e-03,  8.4682e-04, -2.4302e-02,  1.2000e-02,\n",
       "                       7.9497e-03, -6.2727e-03, -7.7637e-03,  1.0559e-02, -2.8605e-03,\n",
       "                      -2.4261e-02, -4.2198e-03, -3.7400e-03, -1.1643e-02, -8.2744e-03,\n",
       "                      -9.1567e-04, -4.3691e-03,  9.6209e-04,  5.7680e-03,  6.9701e-03,\n",
       "                       2.8468e-03, -1.1994e-02, -2.9369e-02, -1.5636e-02,  1.6451e-02,\n",
       "                      -5.9218e-04,  9.0850e-03,  4.9926e-03,  9.8020e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('2.1.running_mean',\n",
       "              tensor([-4.8069e-01, -2.6039e-01,  2.8728e-01, -1.5051e-01, -6.1899e-02,\n",
       "                       2.4802e-01, -1.8004e-01,  5.0455e-01,  1.2221e-01, -2.4687e-01,\n",
       "                       5.9205e-01,  5.7208e-01,  5.1030e-01,  1.3644e-02, -5.6590e-01,\n",
       "                       6.0137e-01,  8.0631e-01,  3.2527e-01,  4.1364e-01, -4.7557e-02,\n",
       "                      -4.7933e-02, -1.8203e-01,  4.6632e-01, -3.3356e-01, -1.8954e-01,\n",
       "                       5.5763e-01,  3.1278e-01,  3.4997e-01, -7.8608e-02,  8.4839e-04,\n",
       "                      -4.2181e-01, -5.6191e-01, -2.3381e-01,  4.3181e-01, -3.7924e-01,\n",
       "                       1.4073e-01, -7.1553e-01, -3.0095e-01, -8.6362e-01,  4.5776e-01,\n",
       "                       2.5463e-01, -1.1827e+00,  3.5017e-01,  2.1390e-01, -2.6675e-02,\n",
       "                      -2.4968e-01, -2.2583e-01, -5.9503e-01, -6.1239e-01,  2.7020e-01,\n",
       "                      -5.5095e-02, -8.2256e-01,  4.6099e-01,  6.3388e-01,  3.3406e-01,\n",
       "                      -5.9379e-01, -5.7994e-01, -3.3738e-02,  9.8474e-03, -1.3958e-01,\n",
       "                      -4.9425e-01, -7.9121e-02, -9.1969e-02,  7.7951e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('2.1.running_var',\n",
       "              tensor([1.3438, 1.2486, 0.7831, 0.8580, 0.6908, 0.5269, 0.8417, 1.5675, 1.3563,\n",
       "                      0.6689, 1.1856, 1.4626, 2.0695, 0.5821, 1.6126, 0.7827, 1.4582, 0.5874,\n",
       "                      1.5859, 0.4374, 0.5981, 0.6753, 0.8948, 0.9110, 0.9109, 1.2599, 1.4261,\n",
       "                      0.9409, 0.9017, 0.4733, 1.1884, 0.8498, 0.8941, 1.3517, 0.8710, 0.9485,\n",
       "                      1.6003, 0.9523, 1.6227, 2.1731, 1.0342, 1.6151, 0.9533, 1.3677, 0.9936,\n",
       "                      1.1720, 0.8057, 1.6414, 1.9836, 1.3619, 1.2761, 2.3753, 1.0898, 0.5510,\n",
       "                      1.0528, 1.3277, 0.7214, 0.6063, 1.0052, 0.8472, 0.9324, 0.8246, 0.6691,\n",
       "                      0.8483], dtype=torch.float64)),\n",
       "             ('2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.0.convs.0.0.weight',\n",
       "              tensor([[[ 0.1746],\n",
       "                       [-0.0420],\n",
       "                       [-0.1320],\n",
       "                       ...,\n",
       "                       [ 0.0063],\n",
       "                       [ 0.3850],\n",
       "                       [-0.0098]],\n",
       "              \n",
       "                      [[ 0.1294],\n",
       "                       [-0.0562],\n",
       "                       [ 0.1448],\n",
       "                       ...,\n",
       "                       [-0.0543],\n",
       "                       [-0.0546],\n",
       "                       [-0.3303]],\n",
       "              \n",
       "                      [[-0.0932],\n",
       "                       [ 0.2392],\n",
       "                       [-0.1688],\n",
       "                       ...,\n",
       "                       [-0.0135],\n",
       "                       [ 0.0666],\n",
       "                       [ 0.2452]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1935],\n",
       "                       [-0.0845],\n",
       "                       [-0.0212],\n",
       "                       ...,\n",
       "                       [ 0.0498],\n",
       "                       [-0.2612],\n",
       "                       [-0.2907]],\n",
       "              \n",
       "                      [[ 0.0427],\n",
       "                       [-0.0339],\n",
       "                       [-0.1776],\n",
       "                       ...,\n",
       "                       [ 0.0490],\n",
       "                       [ 0.4007],\n",
       "                       [ 0.1686]],\n",
       "              \n",
       "                      [[ 0.0069],\n",
       "                       [ 0.1651],\n",
       "                       [ 0.0134],\n",
       "                       ...,\n",
       "                       [-0.0243],\n",
       "                       [ 0.0017],\n",
       "                       [-0.0978]]], dtype=torch.float64)),\n",
       "             ('4.0.convs.0.1.weight',\n",
       "              tensor([0.9410, 0.9464, 0.9494, 0.9294, 0.9269, 0.9071, 0.9162, 0.9314, 0.9135,\n",
       "                      0.9557, 0.9408, 0.9317, 0.9197, 0.9351, 0.9301, 0.9492, 0.9420, 0.9575,\n",
       "                      0.9157, 0.9447, 0.9294, 0.9259, 0.9631, 0.9424, 0.9456, 0.9249, 0.9311,\n",
       "                      0.9653, 0.9149, 0.9304, 0.9337, 0.9459, 0.9350, 0.9427, 0.9510, 0.9751,\n",
       "                      0.9388, 0.9551, 0.9297, 0.9184, 0.9392, 0.9580, 0.9775, 0.9316, 0.9576,\n",
       "                      0.9402, 0.9603, 0.9468, 0.9521, 0.9429, 0.8836, 0.9302, 0.9494, 0.9338,\n",
       "                      0.9385, 0.9360, 0.9327, 0.9295, 0.9358, 0.9431, 0.9518, 0.9426, 0.9383,\n",
       "                      0.9349], dtype=torch.float64)),\n",
       "             ('4.0.convs.0.1.bias',\n",
       "              tensor([ 0.0028,  0.0144,  0.0082,  0.0130, -0.0006, -0.0198, -0.0031, -0.0119,\n",
       "                       0.0035,  0.0060, -0.0094,  0.0054, -0.0023, -0.0021, -0.0075,  0.0091,\n",
       "                       0.0080,  0.0044, -0.0122, -0.0044, -0.0018,  0.0097,  0.0095, -0.0269,\n",
       "                       0.0108, -0.0034, -0.0017,  0.0225, -0.0076, -0.0115, -0.0174,  0.0045,\n",
       "                       0.0060,  0.0119,  0.0073,  0.0172, -0.0093,  0.0063, -0.0069, -0.0007,\n",
       "                       0.0037,  0.0200,  0.0199, -0.0028,  0.0109,  0.0058,  0.0099,  0.0014,\n",
       "                       0.0109,  0.0195,  0.0047, -0.0081, -0.0088,  0.0024, -0.0090,  0.0062,\n",
       "                       0.0017,  0.0110,  0.0064,  0.0052, -0.0165,  0.0071,  0.0025, -0.0123],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convs.0.1.running_mean',\n",
       "              tensor([ 0.0288, -0.6947, -1.3989, -0.1388, -0.6356,  0.0589,  0.3495,  0.3667,\n",
       "                      -0.2734,  0.0275,  0.1114, -0.0786, -0.9753, -0.1181,  0.4053,  1.0251,\n",
       "                      -0.0885, -0.3129,  0.1751,  0.0510,  0.4098, -0.2097,  0.2498,  0.1215,\n",
       "                      -1.1378, -1.0452, -0.7767,  0.6384, -0.3643,  0.5546,  0.2417, -0.6444,\n",
       "                      -0.6747,  0.7507,  0.0939, -0.4402, -0.0805, -0.1808,  0.9426, -0.2130,\n",
       "                       0.0316, -0.2371, -0.8432,  0.6800,  0.1722, -1.2820, -0.0020,  0.5011,\n",
       "                       0.5566,  0.5801, -0.7212,  0.7273, -1.0379, -1.0848,  0.6063, -0.7894,\n",
       "                      -0.2395,  0.2086,  1.1783, -0.2079,  0.3387,  0.1843,  0.3474, -0.1663],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convs.0.1.running_var',\n",
       "              tensor([0.9093, 0.3288, 1.2500, 1.0267, 1.9935, 0.5738, 1.3001, 0.6802, 1.4648,\n",
       "                      0.9332, 0.5026, 1.0385, 1.8875, 1.4962, 0.4556, 2.6793, 0.7422, 0.7846,\n",
       "                      0.7842, 0.6218, 0.9284, 0.8746, 0.4477, 0.7632, 1.6916, 1.3841, 0.7723,\n",
       "                      0.7409, 1.2389, 1.0836, 1.0241, 1.4053, 0.9130, 0.6950, 0.4817, 0.8633,\n",
       "                      1.1623, 0.7273, 3.6174, 0.8238, 0.4124, 0.3190, 0.7826, 1.0245, 0.8575,\n",
       "                      2.7454, 0.4495, 1.1720, 0.7981, 0.5640, 1.7969, 0.7823, 0.9723, 1.3142,\n",
       "                      1.4376, 1.5796, 0.8547, 1.0106, 2.5988, 0.7706, 0.5973, 0.4879, 1.6286,\n",
       "                      0.6235], dtype=torch.float64)),\n",
       "             ('4.0.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.0.convs.1.0.weight',\n",
       "              tensor([[[ 5.9927e-02,  6.8274e-02, -4.0390e-02,  3.6234e-02, -6.9103e-03],\n",
       "                       [ 8.1514e-03, -9.0629e-03,  9.3375e-02, -7.7648e-02,  3.6492e-02],\n",
       "                       [ 1.8982e-02, -3.2039e-02,  4.4522e-02,  4.4976e-02,  6.2291e-02],\n",
       "                       ...,\n",
       "                       [-2.3505e-02, -1.4944e-02,  4.9613e-02,  5.3850e-02, -6.4702e-02],\n",
       "                       [ 3.3961e-02, -5.3110e-02, -8.0345e-02,  7.2922e-02, -7.2593e-02],\n",
       "                       [-5.4968e-02, -1.0503e-01, -1.5031e-02,  1.7999e-02, -3.1293e-02]],\n",
       "              \n",
       "                      [[ 3.5027e-02, -1.5687e-02,  1.1280e-01,  3.8527e-02,  1.4148e-03],\n",
       "                       [-5.1503e-02, -6.7381e-02, -1.5978e-02,  2.4346e-02,  8.8746e-02],\n",
       "                       [-5.7680e-02, -5.7985e-02, -6.7163e-02,  3.3340e-02, -2.3775e-02],\n",
       "                       ...,\n",
       "                       [ 7.8668e-02, -4.9563e-02, -5.7116e-02, -5.1082e-02, -8.0681e-02],\n",
       "                       [ 1.8827e-02,  2.2210e-02,  6.5901e-02, -1.4361e-02,  5.2684e-02],\n",
       "                       [ 4.9907e-02,  9.4056e-02,  5.0022e-02, -6.5946e-02, -7.0033e-02]],\n",
       "              \n",
       "                      [[ 3.3378e-03, -2.6650e-02,  3.9939e-02,  2.1888e-02, -1.5442e-01],\n",
       "                       [-5.0243e-03, -1.0519e-01,  1.0374e-01,  2.7417e-02,  8.9838e-03],\n",
       "                       [ 4.2547e-04,  7.8680e-02,  1.2529e-01,  1.4506e-02, -1.0893e-01],\n",
       "                       ...,\n",
       "                       [-2.0934e-02, -1.9261e-02,  2.4230e-03, -6.6468e-02, -1.6265e-02],\n",
       "                       [-5.4112e-02,  3.9021e-02,  7.9773e-02,  7.3511e-02,  7.8458e-02],\n",
       "                       [-3.0795e-02, -1.8086e-04,  2.7099e-02, -7.4484e-02,  1.9612e-03]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 2.0474e-02, -1.0542e-02, -1.3959e-01,  6.7694e-02,  2.3214e-03],\n",
       "                       [-1.3659e-01, -7.4529e-02, -1.9424e-02,  2.1284e-02,  4.5282e-03],\n",
       "                       [ 7.2157e-02,  3.5721e-02,  4.4855e-02,  5.0010e-02, -7.9951e-02],\n",
       "                       ...,\n",
       "                       [ 8.7118e-02,  1.7825e-01,  1.0842e-01,  3.2669e-02, -7.2359e-02],\n",
       "                       [ 2.6878e-02, -3.2675e-02, -7.4717e-02,  3.9410e-02,  4.4540e-02],\n",
       "                       [-1.0124e-02,  8.1807e-02, -3.7462e-02,  6.2397e-02,  8.9733e-02]],\n",
       "              \n",
       "                      [[ 3.5384e-02, -6.6726e-02,  5.0894e-02,  2.0477e-02, -4.3781e-02],\n",
       "                       [-3.3403e-02, -5.0487e-02, -1.2854e-01,  1.2611e-01,  6.9323e-02],\n",
       "                       [-4.1450e-02, -7.8809e-03, -3.4681e-02, -2.1100e-02, -2.3751e-02],\n",
       "                       ...,\n",
       "                       [-2.5548e-02,  1.1889e-01, -7.2071e-02, -5.0943e-02,  4.8886e-02],\n",
       "                       [ 2.0861e-02, -1.8498e-01,  3.7345e-02, -3.3005e-02, -4.7221e-02],\n",
       "                       [-1.0617e-01,  3.8453e-02,  5.3551e-02, -6.6472e-02, -9.4374e-03]],\n",
       "              \n",
       "                      [[ 3.2852e-02,  6.3174e-02, -1.6339e-02, -1.1742e-01, -8.1334e-02],\n",
       "                       [ 1.5913e-01, -2.4457e-02,  3.7992e-02, -1.1894e-01, -6.3139e-02],\n",
       "                       [-5.8292e-03,  3.3433e-02, -6.9117e-03, -1.0649e-01,  1.6887e-01],\n",
       "                       ...,\n",
       "                       [-5.6318e-02,  8.1830e-02,  1.9222e-02, -7.3779e-04, -1.5417e-01],\n",
       "                       [ 3.0937e-02, -6.0916e-02,  1.1514e-02,  3.8493e-02, -7.4838e-02],\n",
       "                       [ 7.1926e-02, -3.3470e-03, -2.3598e-02,  6.7616e-02, -7.4616e-03]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convs.1.1.weight',\n",
       "              tensor([0.9601, 0.9441, 0.9471, 0.9276, 0.9153, 0.9214, 0.9173, 0.9614, 0.9470,\n",
       "                      0.9449, 0.9258, 0.9297, 0.8880, 0.9655, 0.9271, 0.9558, 0.9438, 0.9200,\n",
       "                      0.9266, 0.9281, 0.9310, 0.9291, 0.9286, 0.9200, 0.9196, 0.9178, 0.9405,\n",
       "                      0.9218, 0.9500, 0.9330, 0.9294, 0.9206, 0.9439, 0.9578, 0.9346, 0.9386,\n",
       "                      0.9032, 0.9400, 0.9160, 0.9252, 0.9064, 0.9571, 0.9513, 0.9139, 0.9461,\n",
       "                      0.9383, 0.9127, 0.9132, 0.9391, 0.9667, 0.9194, 0.9110, 0.9294, 0.9289,\n",
       "                      0.9290, 0.9193, 0.9004, 0.9467, 0.9437, 0.9131, 0.9387, 0.9240, 0.9283,\n",
       "                      0.9475], dtype=torch.float64)),\n",
       "             ('4.0.convs.1.1.bias',\n",
       "              tensor([ 0.0205,  0.0021, -0.0057,  0.0070,  0.0263, -0.0163, -0.0200,  0.0027,\n",
       "                       0.0193,  0.0153, -0.0027,  0.0061,  0.0057,  0.0004,  0.0050, -0.0127,\n",
       "                      -0.0053, -0.0111, -0.0188, -0.0276, -0.0137, -0.0108, -0.0075, -0.0037,\n",
       "                       0.0016,  0.0158, -0.0042, -0.0146, -0.0033,  0.0041,  0.0070,  0.0045,\n",
       "                      -0.0189,  0.0119, -0.0027,  0.0158, -0.0045, -0.0251, -0.0005, -0.0134,\n",
       "                      -0.0069,  0.0026, -0.0049, -0.0097,  0.0005, -0.0170, -0.0057,  0.0042,\n",
       "                       0.0113,  0.0163,  0.0005, -0.0233, -0.0041, -0.0052, -0.0024,  0.0088,\n",
       "                      -0.0107, -0.0030,  0.0142,  0.0085,  0.0163,  0.0115,  0.0047,  0.0054],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convs.1.1.running_mean',\n",
       "              tensor([ 0.0179, -0.1838, -0.5570, -0.1682, -0.1654, -0.3049,  0.3894, -0.3667,\n",
       "                      -0.3633, -0.5361,  0.2873, -0.1536, -0.2677,  0.4592,  0.3610, -0.3605,\n",
       "                      -0.3594,  0.1621, -0.1345,  0.8120, -0.1837, -0.0708,  0.0167,  0.3869,\n",
       "                      -1.0239,  0.1968,  0.6182,  0.1432,  0.0949,  0.1320, -0.0142, -0.4331,\n",
       "                       0.0396, -0.0999, -0.1719,  0.2801,  0.0586,  0.2857, -0.5476, -0.0668,\n",
       "                      -0.1712, -0.4401,  0.2954, -0.1305,  0.5686,  0.5221,  0.1675, -0.2913,\n",
       "                      -0.0250, -0.0948,  0.0491,  0.2049,  0.4022,  0.1831,  0.6375, -0.2636,\n",
       "                      -0.3939, -0.2922,  0.1335, -0.2775,  0.0127, -0.4342, -0.4751,  0.2475],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convs.1.1.running_var',\n",
       "              tensor([0.2934, 0.2929, 0.3221, 0.4556, 0.9250, 0.6531, 0.7796, 0.5129, 0.6016,\n",
       "                      0.4659, 0.8327, 0.4469, 0.8770, 0.5347, 0.5710, 0.3896, 0.6005, 0.6432,\n",
       "                      0.6615, 0.7063, 0.3380, 0.8666, 0.5421, 0.7303, 0.5533, 0.7084, 0.4544,\n",
       "                      0.5445, 0.3721, 0.6700, 0.2868, 0.4392, 0.2813, 0.2978, 0.4167, 0.3246,\n",
       "                      0.3871, 0.5671, 0.7886, 0.5021, 0.9942, 0.3277, 0.3627, 0.4183, 0.8153,\n",
       "                      0.6375, 1.1438, 0.4741, 0.2797, 0.3257, 0.3939, 0.5186, 0.3771, 0.5812,\n",
       "                      0.5004, 0.4194, 0.8015, 0.4835, 0.4035, 0.4456, 0.3946, 0.3558, 0.5419,\n",
       "                      0.5156], dtype=torch.float64)),\n",
       "             ('4.0.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.0.convs.2.0.weight',\n",
       "              tensor([[[ 0.0510],\n",
       "                       [ 0.0766],\n",
       "                       [-0.0025],\n",
       "                       ...,\n",
       "                       [-0.0554],\n",
       "                       [-0.0525],\n",
       "                       [ 0.0428]],\n",
       "              \n",
       "                      [[ 0.0090],\n",
       "                       [ 0.0900],\n",
       "                       [ 0.1719],\n",
       "                       ...,\n",
       "                       [-0.0947],\n",
       "                       [-0.3793],\n",
       "                       [ 0.2105]],\n",
       "              \n",
       "                      [[-0.0018],\n",
       "                       [-0.0758],\n",
       "                       [-0.0390],\n",
       "                       ...,\n",
       "                       [ 0.0780],\n",
       "                       [ 0.0383],\n",
       "                       [ 0.0042]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.2673],\n",
       "                       [ 0.4015],\n",
       "                       [ 0.2070],\n",
       "                       ...,\n",
       "                       [-0.0480],\n",
       "                       [ 0.1154],\n",
       "                       [-0.0629]],\n",
       "              \n",
       "                      [[ 0.1003],\n",
       "                       [ 0.0125],\n",
       "                       [-0.1353],\n",
       "                       ...,\n",
       "                       [-0.0992],\n",
       "                       [-0.2238],\n",
       "                       [-0.0396]],\n",
       "              \n",
       "                      [[ 0.0412],\n",
       "                       [-0.0411],\n",
       "                       [ 0.2007],\n",
       "                       ...,\n",
       "                       [ 0.0877],\n",
       "                       [ 0.0523],\n",
       "                       [-0.1581]]], dtype=torch.float64)),\n",
       "             ('4.0.convs.2.1.weight',\n",
       "              tensor([-0.0010,  0.0402,  0.0006,  0.0384,  0.0132, -0.0065,  0.0073, -0.0091,\n",
       "                       0.0104, -0.0024,  0.0054, -0.0013, -0.0206,  0.0208, -0.0056,  0.0108,\n",
       "                      -0.0260,  0.0484, -0.0011,  0.0179,  0.0156,  0.0038,  0.0161, -0.0147,\n",
       "                      -0.0097,  0.0317, -0.0101, -0.0127, -0.0042,  0.0111, -0.0005, -0.0376,\n",
       "                      -0.0006,  0.0352,  0.0710, -0.0191, -0.0097,  0.0267,  0.0012,  0.0079,\n",
       "                      -0.0208,  0.0053,  0.0088, -0.0134, -0.0229,  0.0100, -0.0093, -0.0089,\n",
       "                       0.0123, -0.0008,  0.0085, -0.0428, -0.0005,  0.0052,  0.0037,  0.0098,\n",
       "                      -0.0033, -0.0096,  0.0138,  0.0061,  0.0082, -0.0095,  0.0025, -0.0049,\n",
       "                      -0.0004, -0.0087,  0.0265,  0.0356,  0.0037,  0.0305, -0.0063, -0.0090,\n",
       "                       0.0142, -0.0099,  0.0276, -0.0231,  0.0164,  0.0078,  0.0274, -0.0125,\n",
       "                       0.0168,  0.0096,  0.0330,  0.0061,  0.0094, -0.0126,  0.0058,  0.0014,\n",
       "                      -0.0339,  0.0220, -0.0068,  0.0073, -0.0034,  0.0103, -0.0021, -0.0004,\n",
       "                      -0.0031, -0.0106, -0.0197, -0.0001,  0.0278, -0.0101,  0.0189,  0.0072,\n",
       "                      -0.0331,  0.0129, -0.0039,  0.0141, -0.0053,  0.0135, -0.0029, -0.0196,\n",
       "                       0.0276,  0.0122, -0.0034,  0.0069,  0.0124, -0.0056,  0.0090,  0.0121,\n",
       "                       0.0037,  0.0088, -0.0087, -0.0017, -0.0098, -0.0141, -0.0152,  0.0157,\n",
       "                      -0.0277, -0.0070,  0.0159,  0.0088,  0.0084,  0.0013,  0.0153,  0.0008,\n",
       "                      -0.0127,  0.0139, -0.0066, -0.0175,  0.0073,  0.0099, -0.0060,  0.0243,\n",
       "                      -0.0046,  0.0038,  0.0145, -0.0040,  0.0222,  0.0203,  0.0118,  0.0214,\n",
       "                      -0.0180, -0.0010,  0.0020,  0.0110, -0.0202,  0.0072,  0.0236,  0.0345,\n",
       "                      -0.0081, -0.0163, -0.0128,  0.0027,  0.0130,  0.0044,  0.0211, -0.0040,\n",
       "                      -0.0192, -0.0255,  0.0194,  0.0076,  0.0294, -0.0148,  0.0023,  0.0028,\n",
       "                       0.0003, -0.0173,  0.0132,  0.0154,  0.0065, -0.0255,  0.0008,  0.0121,\n",
       "                      -0.0048,  0.0058, -0.0021, -0.0283, -0.0153, -0.0152,  0.0045,  0.0068,\n",
       "                       0.0004, -0.0126, -0.0158,  0.0099, -0.0015,  0.0180,  0.0046,  0.0014,\n",
       "                      -0.0118, -0.0125,  0.0005,  0.0100, -0.0213,  0.0012,  0.0289,  0.0189,\n",
       "                      -0.0113, -0.0205, -0.0003, -0.0037, -0.0097,  0.0017,  0.0156, -0.0150,\n",
       "                      -0.0137, -0.0007, -0.0118, -0.0131, -0.0127, -0.0215, -0.0190,  0.0182,\n",
       "                      -0.0051, -0.0271, -0.0124,  0.0209,  0.0346, -0.0065,  0.0122, -0.0052,\n",
       "                       0.0243,  0.0228,  0.0050,  0.0172, -0.0099,  0.0012, -0.0091,  0.0051,\n",
       "                       0.0001,  0.0034, -0.0192, -0.0020,  0.0169, -0.0136, -0.0008, -0.0167,\n",
       "                      -0.0098, -0.0075, -0.0285, -0.0155, -0.0030, -0.0338, -0.0108,  0.0087],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convs.2.1.bias',\n",
       "              tensor([-7.2795e-04, -3.3469e-03,  2.5615e-02,  1.7376e-03,  9.3212e-03,\n",
       "                      -1.6753e-02, -2.9658e-03, -1.4160e-02, -1.3214e-02, -8.7208e-03,\n",
       "                      -4.9374e-03, -7.9470e-03,  3.0062e-03, -4.8956e-03, -6.4107e-03,\n",
       "                      -1.5175e-02, -1.8393e-02,  2.2720e-02,  4.0796e-03, -4.3133e-03,\n",
       "                       3.1041e-03, -1.9059e-02, -4.1501e-03,  3.6664e-04, -9.4798e-03,\n",
       "                      -2.1313e-02, -1.9297e-03, -4.5335e-03,  2.6222e-03,  3.8868e-03,\n",
       "                      -1.9928e-02, -1.3763e-02, -1.1673e-02, -2.0898e-02,  4.1412e-03,\n",
       "                      -1.5855e-02, -3.0226e-03,  4.0745e-03, -1.0940e-02, -1.7874e-02,\n",
       "                       4.3854e-03, -7.2711e-03, -1.7059e-02, -1.7811e-02,  7.7646e-03,\n",
       "                      -1.0010e-02, -1.3731e-02,  9.3924e-03, -1.1904e-02,  4.3385e-03,\n",
       "                      -4.3618e-03, -2.4723e-03,  2.6984e-03, -1.1851e-02, -7.9505e-03,\n",
       "                      -6.0253e-03, -4.7125e-04, -5.9180e-03, -1.4574e-02,  5.3121e-03,\n",
       "                      -8.4393e-03, -5.2493e-03, -2.3264e-02, -1.6835e-02, -1.1743e-02,\n",
       "                      -3.6267e-03, -3.6482e-03, -2.0177e-03, -2.1536e-02, -1.6293e-02,\n",
       "                       2.2893e-03, -6.6032e-04,  3.3575e-04, -4.7125e-03, -1.6277e-02,\n",
       "                      -1.6786e-02, -2.6764e-02, -1.9008e-02, -5.0277e-03, -1.6644e-02,\n",
       "                      -4.6247e-03, -4.1078e-04, -2.2868e-02, -4.6928e-03,  2.6562e-03,\n",
       "                      -1.7980e-02,  1.2481e-02,  1.6196e-02, -2.4499e-03,  2.4511e-03,\n",
       "                      -1.7947e-02, -4.6330e-03, -1.5217e-02,  4.2939e-03, -5.1057e-03,\n",
       "                      -1.4797e-02,  9.6003e-04, -1.2330e-02,  2.5038e-04, -1.0838e-02,\n",
       "                       2.3859e-03, -3.7735e-03, -1.2845e-02, -1.1175e-02, -6.7415e-04,\n",
       "                       7.2692e-03, -1.1312e-02, -7.4839e-03, -7.9239e-03, -1.2597e-02,\n",
       "                      -8.5915e-03, -5.0790e-03,  1.0275e-03,  1.2115e-03, -4.7034e-03,\n",
       "                      -4.8503e-03, -6.4275e-03, -7.3991e-03,  5.8259e-03, -2.2010e-03,\n",
       "                      -7.3446e-03, -2.2270e-02, -1.3333e-03, -8.2732e-03, -9.4862e-03,\n",
       "                      -8.1979e-03, -1.1344e-02,  1.8440e-03,  1.3599e-03, -2.0410e-02,\n",
       "                      -9.6839e-03, -7.9098e-03, -3.7910e-03,  1.5697e-05, -6.5700e-03,\n",
       "                      -2.1605e-02,  4.2204e-03,  4.0283e-04, -6.4831e-03, -2.0593e-03,\n",
       "                      -2.3457e-03,  1.9256e-03, -1.2860e-02, -2.6430e-03, -1.8717e-02,\n",
       "                      -1.6861e-02, -1.3022e-02, -1.0280e-02, -1.2432e-03,  1.0246e-02,\n",
       "                      -9.3326e-03, -1.5284e-02, -2.7686e-02, -1.0454e-02, -7.1254e-03,\n",
       "                      -3.7724e-03,  1.0640e-02,  2.7505e-03, -1.3317e-02, -2.0494e-02,\n",
       "                      -7.4842e-03,  2.7243e-02, -9.6145e-03, -3.3994e-03, -5.4003e-03,\n",
       "                       4.5228e-03, -8.3312e-03,  2.8939e-02,  1.1500e-04, -2.9051e-02,\n",
       "                      -7.2565e-04, -1.3314e-03, -7.2075e-03, -5.3022e-03, -1.7320e-02,\n",
       "                      -1.6683e-02, -7.8974e-03,  1.4435e-02, -1.1474e-02, -3.6701e-04,\n",
       "                      -1.9463e-03,  2.1519e-02, -1.1158e-02,  2.4624e-03, -4.5132e-03,\n",
       "                      -7.7967e-03, -6.0586e-03,  1.3910e-02, -9.0865e-03, -1.1510e-02,\n",
       "                      -7.4502e-03, -1.8166e-02, -6.3183e-03, -2.0461e-02, -8.9440e-03,\n",
       "                       6.6549e-04, -3.2089e-03, -1.2933e-02, -7.0443e-03, -1.4368e-02,\n",
       "                      -8.0977e-03, -1.3865e-02,  9.2988e-03, -1.1243e-02, -3.2124e-03,\n",
       "                      -9.6305e-03, -4.0261e-03, -1.5690e-02, -7.7035e-03, -2.3680e-02,\n",
       "                       2.4345e-03, -4.0755e-03, -8.5092e-04, -5.7477e-03, -2.0849e-03,\n",
       "                       1.8883e-02, -4.3178e-03,  1.6819e-02,  3.9807e-03, -2.4423e-03,\n",
       "                       2.5718e-03, -2.9551e-03, -1.3181e-02, -1.3747e-03, -2.2727e-02,\n",
       "                       5.7089e-03,  4.4769e-03,  6.1698e-03, -2.0630e-02, -1.0333e-02,\n",
       "                       5.9753e-04,  2.3022e-03,  2.1443e-03,  7.5890e-03, -1.0112e-02,\n",
       "                      -3.6802e-03,  6.6059e-03,  7.0752e-03, -1.1512e-02, -7.2608e-03,\n",
       "                      -7.2489e-03,  3.3995e-03, -1.0654e-02, -1.1668e-02, -8.9250e-03,\n",
       "                      -6.6219e-03, -7.4274e-04,  5.4266e-03, -5.8644e-03, -1.6624e-02,\n",
       "                      -7.5053e-03, -7.3289e-03, -1.2267e-02, -5.6282e-03,  4.0937e-05,\n",
       "                      -5.9866e-04], dtype=torch.float64)),\n",
       "             ('4.0.convs.2.1.running_mean',\n",
       "              tensor([-1.1578e-01,  1.4158e-01,  2.6433e-01,  3.2712e-01, -1.5668e-02,\n",
       "                       1.3126e-01, -2.0683e-02,  1.0507e-01,  2.1800e-03,  1.4118e-01,\n",
       "                      -9.5007e-02,  1.9489e-01,  2.0697e-01, -1.8849e-01,  2.4983e-01,\n",
       "                       4.3032e-02,  3.2477e-01, -5.4898e-01,  3.7983e-02,  3.7709e-01,\n",
       "                      -1.3353e-01, -3.6700e-01, -2.4383e-01,  3.5948e-01, -1.9123e-02,\n",
       "                      -6.4727e-02, -2.1877e-01, -2.0409e-02,  1.4432e-01,  5.2703e-02,\n",
       "                      -6.1961e-01,  3.3659e-01, -9.3631e-02, -1.0217e-01, -2.5888e-01,\n",
       "                       7.7050e-02,  3.5075e-01, -9.0172e-02, -1.0995e-01, -2.3505e-01,\n",
       "                      -8.0178e-01, -2.9860e-02,  1.7033e-01, -7.1453e-01, -4.1577e-01,\n",
       "                      -1.2391e-01, -2.0914e-01,  7.5619e-02, -2.9508e-01,  3.5578e-02,\n",
       "                      -9.6041e-02, -3.0559e-01,  2.7696e-01, -1.6429e-02, -4.4110e-01,\n",
       "                      -2.0352e-01, -1.3997e-02, -2.9686e-01,  1.9188e-01, -1.0232e-01,\n",
       "                       7.4081e-02,  2.4853e-01, -1.7221e-01,  1.6841e-01,  5.1837e-01,\n",
       "                      -1.8933e-02, -5.8636e-01,  2.9902e-02, -1.9554e-01,  1.4545e-01,\n",
       "                      -2.5608e-01,  3.5397e-02, -3.4241e-01, -1.6359e-01,  3.4897e-02,\n",
       "                      -4.1212e-01,  7.8959e-02, -3.3743e-01, -3.3751e-02,  3.1742e-01,\n",
       "                      -3.1577e-01,  2.2491e-01, -7.6560e-01, -7.6081e-01,  2.3304e-02,\n",
       "                      -2.2236e-03, -2.4009e-01, -2.0231e-02, -1.2668e-01, -1.6607e-01,\n",
       "                      -9.2332e-03,  2.1212e-01, -2.3443e-03,  1.5779e-01,  1.7743e-01,\n",
       "                       2.9531e-01,  7.7745e-02,  3.0311e-01, -1.6115e-01, -7.2446e-02,\n",
       "                      -9.6247e-02,  2.2273e-01, -2.4288e-01, -1.9972e-01,  1.8564e-01,\n",
       "                       1.7285e-01,  2.0827e-01, -1.1654e-01,  2.4553e-01,  1.0188e-01,\n",
       "                      -2.0252e-02,  6.3375e-02, -2.1360e-01, -3.4964e-01, -1.0912e-01,\n",
       "                      -4.0965e-02, -2.0619e-01, -3.6362e-01, -1.3493e-02, -1.0500e-01,\n",
       "                      -2.2794e-03,  3.3153e-02,  1.5774e-01,  4.6913e-02, -8.1025e-02,\n",
       "                      -2.7331e-01,  7.1843e-02, -3.2702e-01, -9.6831e-02, -4.8345e-01,\n",
       "                      -1.1988e-01, -1.3751e-01, -1.6979e-01,  2.5665e-01,  5.1327e-01,\n",
       "                      -1.8191e-01,  1.0861e-01,  4.3320e-01, -4.0506e-01, -2.0047e-02,\n",
       "                       1.5334e-01, -3.3304e-01,  1.2437e-01, -7.6602e-03, -2.7165e-02,\n",
       "                      -1.5085e-01, -6.8762e-02, -5.6192e-02, -2.0192e-01, -3.6609e-01,\n",
       "                       3.8151e-01,  1.5476e-02,  6.4966e-01,  7.7298e-02,  2.2244e-01,\n",
       "                      -1.1717e-02, -2.1701e-01,  2.1672e-01, -1.0395e-01, -2.9592e-01,\n",
       "                       9.3124e-02, -4.1344e-01,  4.3611e-02, -1.0612e-02, -4.2286e-02,\n",
       "                      -2.7401e-01,  2.2494e-02, -1.4385e-01,  6.9536e-02,  2.0816e-01,\n",
       "                      -9.1477e-03, -1.5681e-01,  3.4120e-01, -2.2300e-01, -2.9704e-01,\n",
       "                       6.0341e-01,  3.9542e-03,  2.3698e-01, -9.6631e-03, -2.2206e-01,\n",
       "                       2.4525e-01,  4.4015e-01, -1.4203e-02,  4.0267e-02, -4.8545e-01,\n",
       "                      -1.3542e-01, -7.8458e-01,  1.6526e-01,  1.3926e-01,  4.4294e-01,\n",
       "                       3.2859e-01,  4.3802e-01, -1.5863e-01,  1.9650e-01, -1.3072e-01,\n",
       "                      -3.1467e-01, -1.8309e-01, -1.3033e-01, -1.4226e-01,  2.8452e-02,\n",
       "                       1.7161e-01, -1.2408e-01,  5.2814e-02, -3.7975e-02,  6.3113e-01,\n",
       "                       1.3134e-01, -1.9547e-02, -1.0505e-01, -2.3531e-01, -7.9773e-04,\n",
       "                       5.9743e-02, -4.5676e-01,  3.7886e-02,  1.0505e-01, -2.2532e-01,\n",
       "                       2.5387e-01,  1.0116e-01, -2.0516e-01,  4.4582e-01,  3.8690e-02,\n",
       "                      -1.1023e-01,  3.5275e-01,  1.0583e-01,  1.2915e-01, -1.2746e-01,\n",
       "                      -2.0916e-01,  2.9274e-01,  4.6588e-01,  5.3821e-01,  5.1901e-01,\n",
       "                       8.0596e-03, -2.5919e-01, -1.0843e-01,  1.1232e-01, -1.9445e-02,\n",
       "                      -5.7027e-02, -4.8326e-01, -4.4388e-02, -4.1745e-02, -2.8202e-01,\n",
       "                      -6.7727e-02,  4.1758e-01,  9.1063e-03,  1.3424e-01,  3.5230e-02,\n",
       "                      -1.4623e-01, -1.9179e-01,  1.4743e-01, -1.6192e-01, -5.8794e-02,\n",
       "                      -1.2120e-02,  3.0112e-01,  3.7555e-02,  1.6582e-01, -6.7952e-01,\n",
       "                       2.5598e-02], dtype=torch.float64)),\n",
       "             ('4.0.convs.2.1.running_var',\n",
       "              tensor([0.0440, 0.2857, 0.1033, 0.2448, 0.3563, 0.1937, 0.1337, 0.2884, 0.1091,\n",
       "                      0.1761, 0.1045, 0.0666, 0.1426, 0.2953, 0.1207, 0.1117, 0.5159, 0.5097,\n",
       "                      0.1532, 0.2480, 0.3501, 0.2698, 0.2317, 0.2921, 0.3286, 0.1704, 0.2739,\n",
       "                      0.2797, 0.1319, 0.1786, 0.2394, 0.0964, 0.1558, 0.2645, 0.2080, 0.3394,\n",
       "                      0.1451, 0.2790, 0.0968, 0.4124, 0.3920, 0.2663, 0.1148, 0.2325, 0.3037,\n",
       "                      0.1625, 0.1277, 0.2137, 0.1788, 0.1150, 0.1502, 0.3963, 0.1191, 0.1766,\n",
       "                      0.1890, 0.1666, 0.0719, 0.4495, 0.2533, 0.3538, 0.1134, 0.1574, 0.0734,\n",
       "                      0.0910, 0.2351, 0.1066, 0.3052, 0.4823, 0.0396, 0.4310, 0.2640, 0.0735,\n",
       "                      0.0970, 0.2930, 0.3959, 0.1075, 0.1271, 0.2847, 0.2928, 0.1708, 0.3483,\n",
       "                      0.1331, 0.6839, 0.3315, 0.3486, 0.5451, 0.1625, 0.1535, 0.3277, 0.2665,\n",
       "                      0.4893, 0.1868, 0.0580, 0.1631, 0.0956, 0.0799, 0.1306, 0.2312, 0.1964,\n",
       "                      0.0974, 0.3483, 0.3551, 0.1420, 0.1951, 0.1435, 0.0892, 0.3026, 0.3772,\n",
       "                      0.1125, 0.1552, 0.0349, 0.4046, 0.3363, 0.1188, 0.1225, 0.1267, 0.1440,\n",
       "                      0.2832, 0.2235, 0.2327, 0.0582, 0.1301, 0.2916, 0.1054, 0.1908, 0.3913,\n",
       "                      0.1391, 0.1453, 0.3321, 0.1705, 0.0293, 0.1460, 0.3621, 0.1140, 0.1441,\n",
       "                      0.0590, 0.0849, 0.2686, 0.1033, 0.1844, 0.2728, 0.1213, 0.0854, 0.0808,\n",
       "                      0.0745, 0.2571, 0.1096, 0.1771, 0.2132, 0.3038, 0.3986, 0.1302, 0.2823,\n",
       "                      0.0682, 0.0777, 0.2564, 0.2812, 0.1103, 0.1522, 0.1747, 0.0965, 0.2222,\n",
       "                      0.0937, 0.1136, 0.4563, 0.3573, 0.4113, 0.0869, 0.3864, 0.2886, 0.1573,\n",
       "                      0.0773, 0.2260, 0.0569, 0.2749, 0.2269, 0.1054, 0.3876, 0.1265, 0.0741,\n",
       "                      0.1075, 0.1540, 0.1516, 0.2364, 0.2387, 0.1255, 0.2923, 0.1504, 0.0875,\n",
       "                      0.1135, 0.2501, 0.2611, 0.0729, 0.1050, 0.1732, 0.3203, 0.1575, 0.1567,\n",
       "                      0.2064, 0.0633, 0.1708, 0.0617, 0.2209, 0.2549, 0.2912, 0.1254, 0.1321,\n",
       "                      0.1858, 0.1188, 0.2069, 0.0344, 0.0983, 0.1908, 0.1725, 0.1557, 0.2547,\n",
       "                      0.1866, 0.0839, 0.2703, 0.4347, 0.1338, 0.2202, 0.0702, 0.2719, 0.2316,\n",
       "                      0.3331, 0.1303, 0.3630, 0.3517, 0.2471, 0.1121, 0.1939, 0.3163, 0.2394,\n",
       "                      0.0734, 0.2661, 0.3263, 0.0634, 0.2345, 0.1950, 0.0961, 0.2340, 0.3849,\n",
       "                      0.1130, 0.2686, 0.1005, 0.0476, 0.3965, 0.1334, 0.1252, 0.3284, 0.2387,\n",
       "                      0.1090, 0.2877, 0.2772, 0.0949], dtype=torch.float64)),\n",
       "             ('4.0.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.0.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.1746],\n",
       "                       [-0.0420],\n",
       "                       [-0.1320],\n",
       "                       ...,\n",
       "                       [ 0.0063],\n",
       "                       [ 0.3850],\n",
       "                       [-0.0098]],\n",
       "              \n",
       "                      [[ 0.1294],\n",
       "                       [-0.0562],\n",
       "                       [ 0.1448],\n",
       "                       ...,\n",
       "                       [-0.0543],\n",
       "                       [-0.0546],\n",
       "                       [-0.3303]],\n",
       "              \n",
       "                      [[-0.0932],\n",
       "                       [ 0.2392],\n",
       "                       [-0.1688],\n",
       "                       ...,\n",
       "                       [-0.0135],\n",
       "                       [ 0.0666],\n",
       "                       [ 0.2452]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1935],\n",
       "                       [-0.0845],\n",
       "                       [-0.0212],\n",
       "                       ...,\n",
       "                       [ 0.0498],\n",
       "                       [-0.2612],\n",
       "                       [-0.2907]],\n",
       "              \n",
       "                      [[ 0.0427],\n",
       "                       [-0.0339],\n",
       "                       [-0.1776],\n",
       "                       ...,\n",
       "                       [ 0.0490],\n",
       "                       [ 0.4007],\n",
       "                       [ 0.1686]],\n",
       "              \n",
       "                      [[ 0.0069],\n",
       "                       [ 0.1651],\n",
       "                       [ 0.0134],\n",
       "                       ...,\n",
       "                       [-0.0243],\n",
       "                       [ 0.0017],\n",
       "                       [-0.0978]]], dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.0.1.weight',\n",
       "              tensor([0.9410, 0.9464, 0.9494, 0.9294, 0.9269, 0.9071, 0.9162, 0.9314, 0.9135,\n",
       "                      0.9557, 0.9408, 0.9317, 0.9197, 0.9351, 0.9301, 0.9492, 0.9420, 0.9575,\n",
       "                      0.9157, 0.9447, 0.9294, 0.9259, 0.9631, 0.9424, 0.9456, 0.9249, 0.9311,\n",
       "                      0.9653, 0.9149, 0.9304, 0.9337, 0.9459, 0.9350, 0.9427, 0.9510, 0.9751,\n",
       "                      0.9388, 0.9551, 0.9297, 0.9184, 0.9392, 0.9580, 0.9775, 0.9316, 0.9576,\n",
       "                      0.9402, 0.9603, 0.9468, 0.9521, 0.9429, 0.8836, 0.9302, 0.9494, 0.9338,\n",
       "                      0.9385, 0.9360, 0.9327, 0.9295, 0.9358, 0.9431, 0.9518, 0.9426, 0.9383,\n",
       "                      0.9349], dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0028,  0.0144,  0.0082,  0.0130, -0.0006, -0.0198, -0.0031, -0.0119,\n",
       "                       0.0035,  0.0060, -0.0094,  0.0054, -0.0023, -0.0021, -0.0075,  0.0091,\n",
       "                       0.0080,  0.0044, -0.0122, -0.0044, -0.0018,  0.0097,  0.0095, -0.0269,\n",
       "                       0.0108, -0.0034, -0.0017,  0.0225, -0.0076, -0.0115, -0.0174,  0.0045,\n",
       "                       0.0060,  0.0119,  0.0073,  0.0172, -0.0093,  0.0063, -0.0069, -0.0007,\n",
       "                       0.0037,  0.0200,  0.0199, -0.0028,  0.0109,  0.0058,  0.0099,  0.0014,\n",
       "                       0.0109,  0.0195,  0.0047, -0.0081, -0.0088,  0.0024, -0.0090,  0.0062,\n",
       "                       0.0017,  0.0110,  0.0064,  0.0052, -0.0165,  0.0071,  0.0025, -0.0123],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.0288, -0.6947, -1.3989, -0.1388, -0.6356,  0.0589,  0.3495,  0.3667,\n",
       "                      -0.2734,  0.0275,  0.1114, -0.0786, -0.9753, -0.1181,  0.4053,  1.0251,\n",
       "                      -0.0885, -0.3129,  0.1751,  0.0510,  0.4098, -0.2097,  0.2498,  0.1215,\n",
       "                      -1.1378, -1.0452, -0.7767,  0.6384, -0.3643,  0.5546,  0.2417, -0.6444,\n",
       "                      -0.6747,  0.7507,  0.0939, -0.4402, -0.0805, -0.1808,  0.9426, -0.2130,\n",
       "                       0.0316, -0.2371, -0.8432,  0.6800,  0.1722, -1.2820, -0.0020,  0.5011,\n",
       "                       0.5566,  0.5801, -0.7212,  0.7273, -1.0379, -1.0848,  0.6063, -0.7894,\n",
       "                      -0.2395,  0.2086,  1.1783, -0.2079,  0.3387,  0.1843,  0.3474, -0.1663],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.0.1.running_var',\n",
       "              tensor([0.9093, 0.3288, 1.2500, 1.0267, 1.9935, 0.5738, 1.3001, 0.6802, 1.4648,\n",
       "                      0.9332, 0.5026, 1.0385, 1.8875, 1.4962, 0.4556, 2.6793, 0.7422, 0.7846,\n",
       "                      0.7842, 0.6218, 0.9284, 0.8746, 0.4477, 0.7632, 1.6916, 1.3841, 0.7723,\n",
       "                      0.7409, 1.2389, 1.0836, 1.0241, 1.4053, 0.9130, 0.6950, 0.4817, 0.8633,\n",
       "                      1.1623, 0.7273, 3.6174, 0.8238, 0.4124, 0.3190, 0.7826, 1.0245, 0.8575,\n",
       "                      2.7454, 0.4495, 1.1720, 0.7981, 0.5640, 1.7969, 0.7823, 0.9723, 1.3142,\n",
       "                      1.4376, 1.5796, 0.8547, 1.0106, 2.5988, 0.7706, 0.5973, 0.4879, 1.6286,\n",
       "                      0.6235], dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.0.convpath.0.1.0.weight',\n",
       "              tensor([[[ 5.9927e-02,  6.8274e-02, -4.0390e-02,  3.6234e-02, -6.9103e-03],\n",
       "                       [ 8.1514e-03, -9.0629e-03,  9.3375e-02, -7.7648e-02,  3.6492e-02],\n",
       "                       [ 1.8982e-02, -3.2039e-02,  4.4522e-02,  4.4976e-02,  6.2291e-02],\n",
       "                       ...,\n",
       "                       [-2.3505e-02, -1.4944e-02,  4.9613e-02,  5.3850e-02, -6.4702e-02],\n",
       "                       [ 3.3961e-02, -5.3110e-02, -8.0345e-02,  7.2922e-02, -7.2593e-02],\n",
       "                       [-5.4968e-02, -1.0503e-01, -1.5031e-02,  1.7999e-02, -3.1293e-02]],\n",
       "              \n",
       "                      [[ 3.5027e-02, -1.5687e-02,  1.1280e-01,  3.8527e-02,  1.4148e-03],\n",
       "                       [-5.1503e-02, -6.7381e-02, -1.5978e-02,  2.4346e-02,  8.8746e-02],\n",
       "                       [-5.7680e-02, -5.7985e-02, -6.7163e-02,  3.3340e-02, -2.3775e-02],\n",
       "                       ...,\n",
       "                       [ 7.8668e-02, -4.9563e-02, -5.7116e-02, -5.1082e-02, -8.0681e-02],\n",
       "                       [ 1.8827e-02,  2.2210e-02,  6.5901e-02, -1.4361e-02,  5.2684e-02],\n",
       "                       [ 4.9907e-02,  9.4056e-02,  5.0022e-02, -6.5946e-02, -7.0033e-02]],\n",
       "              \n",
       "                      [[ 3.3378e-03, -2.6650e-02,  3.9939e-02,  2.1888e-02, -1.5442e-01],\n",
       "                       [-5.0243e-03, -1.0519e-01,  1.0374e-01,  2.7417e-02,  8.9838e-03],\n",
       "                       [ 4.2547e-04,  7.8680e-02,  1.2529e-01,  1.4506e-02, -1.0893e-01],\n",
       "                       ...,\n",
       "                       [-2.0934e-02, -1.9261e-02,  2.4230e-03, -6.6468e-02, -1.6265e-02],\n",
       "                       [-5.4112e-02,  3.9021e-02,  7.9773e-02,  7.3511e-02,  7.8458e-02],\n",
       "                       [-3.0795e-02, -1.8086e-04,  2.7099e-02, -7.4484e-02,  1.9612e-03]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 2.0474e-02, -1.0542e-02, -1.3959e-01,  6.7694e-02,  2.3214e-03],\n",
       "                       [-1.3659e-01, -7.4529e-02, -1.9424e-02,  2.1284e-02,  4.5282e-03],\n",
       "                       [ 7.2157e-02,  3.5721e-02,  4.4855e-02,  5.0010e-02, -7.9951e-02],\n",
       "                       ...,\n",
       "                       [ 8.7118e-02,  1.7825e-01,  1.0842e-01,  3.2669e-02, -7.2359e-02],\n",
       "                       [ 2.6878e-02, -3.2675e-02, -7.4717e-02,  3.9410e-02,  4.4540e-02],\n",
       "                       [-1.0124e-02,  8.1807e-02, -3.7462e-02,  6.2397e-02,  8.9733e-02]],\n",
       "              \n",
       "                      [[ 3.5384e-02, -6.6726e-02,  5.0894e-02,  2.0477e-02, -4.3781e-02],\n",
       "                       [-3.3403e-02, -5.0487e-02, -1.2854e-01,  1.2611e-01,  6.9323e-02],\n",
       "                       [-4.1450e-02, -7.8809e-03, -3.4681e-02, -2.1100e-02, -2.3751e-02],\n",
       "                       ...,\n",
       "                       [-2.5548e-02,  1.1889e-01, -7.2071e-02, -5.0943e-02,  4.8886e-02],\n",
       "                       [ 2.0861e-02, -1.8498e-01,  3.7345e-02, -3.3005e-02, -4.7221e-02],\n",
       "                       [-1.0617e-01,  3.8453e-02,  5.3551e-02, -6.6472e-02, -9.4374e-03]],\n",
       "              \n",
       "                      [[ 3.2852e-02,  6.3174e-02, -1.6339e-02, -1.1742e-01, -8.1334e-02],\n",
       "                       [ 1.5913e-01, -2.4457e-02,  3.7992e-02, -1.1894e-01, -6.3139e-02],\n",
       "                       [-5.8292e-03,  3.3433e-02, -6.9117e-03, -1.0649e-01,  1.6887e-01],\n",
       "                       ...,\n",
       "                       [-5.6318e-02,  8.1830e-02,  1.9222e-02, -7.3779e-04, -1.5417e-01],\n",
       "                       [ 3.0937e-02, -6.0916e-02,  1.1514e-02,  3.8493e-02, -7.4838e-02],\n",
       "                       [ 7.1926e-02, -3.3470e-03, -2.3598e-02,  6.7616e-02, -7.4616e-03]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.1.1.weight',\n",
       "              tensor([0.9601, 0.9441, 0.9471, 0.9276, 0.9153, 0.9214, 0.9173, 0.9614, 0.9470,\n",
       "                      0.9449, 0.9258, 0.9297, 0.8880, 0.9655, 0.9271, 0.9558, 0.9438, 0.9200,\n",
       "                      0.9266, 0.9281, 0.9310, 0.9291, 0.9286, 0.9200, 0.9196, 0.9178, 0.9405,\n",
       "                      0.9218, 0.9500, 0.9330, 0.9294, 0.9206, 0.9439, 0.9578, 0.9346, 0.9386,\n",
       "                      0.9032, 0.9400, 0.9160, 0.9252, 0.9064, 0.9571, 0.9513, 0.9139, 0.9461,\n",
       "                      0.9383, 0.9127, 0.9132, 0.9391, 0.9667, 0.9194, 0.9110, 0.9294, 0.9289,\n",
       "                      0.9290, 0.9193, 0.9004, 0.9467, 0.9437, 0.9131, 0.9387, 0.9240, 0.9283,\n",
       "                      0.9475], dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.1.1.bias',\n",
       "              tensor([ 0.0205,  0.0021, -0.0057,  0.0070,  0.0263, -0.0163, -0.0200,  0.0027,\n",
       "                       0.0193,  0.0153, -0.0027,  0.0061,  0.0057,  0.0004,  0.0050, -0.0127,\n",
       "                      -0.0053, -0.0111, -0.0188, -0.0276, -0.0137, -0.0108, -0.0075, -0.0037,\n",
       "                       0.0016,  0.0158, -0.0042, -0.0146, -0.0033,  0.0041,  0.0070,  0.0045,\n",
       "                      -0.0189,  0.0119, -0.0027,  0.0158, -0.0045, -0.0251, -0.0005, -0.0134,\n",
       "                      -0.0069,  0.0026, -0.0049, -0.0097,  0.0005, -0.0170, -0.0057,  0.0042,\n",
       "                       0.0113,  0.0163,  0.0005, -0.0233, -0.0041, -0.0052, -0.0024,  0.0088,\n",
       "                      -0.0107, -0.0030,  0.0142,  0.0085,  0.0163,  0.0115,  0.0047,  0.0054],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.0179, -0.1838, -0.5570, -0.1682, -0.1654, -0.3049,  0.3894, -0.3667,\n",
       "                      -0.3633, -0.5361,  0.2873, -0.1536, -0.2677,  0.4592,  0.3610, -0.3605,\n",
       "                      -0.3594,  0.1621, -0.1345,  0.8120, -0.1837, -0.0708,  0.0167,  0.3869,\n",
       "                      -1.0239,  0.1968,  0.6182,  0.1432,  0.0949,  0.1320, -0.0142, -0.4331,\n",
       "                       0.0396, -0.0999, -0.1719,  0.2801,  0.0586,  0.2857, -0.5476, -0.0668,\n",
       "                      -0.1712, -0.4401,  0.2954, -0.1305,  0.5686,  0.5221,  0.1675, -0.2913,\n",
       "                      -0.0250, -0.0948,  0.0491,  0.2049,  0.4022,  0.1831,  0.6375, -0.2636,\n",
       "                      -0.3939, -0.2922,  0.1335, -0.2775,  0.0127, -0.4342, -0.4751,  0.2475],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.1.1.running_var',\n",
       "              tensor([0.2934, 0.2929, 0.3221, 0.4556, 0.9250, 0.6531, 0.7796, 0.5129, 0.6016,\n",
       "                      0.4659, 0.8327, 0.4469, 0.8770, 0.5347, 0.5710, 0.3896, 0.6005, 0.6432,\n",
       "                      0.6615, 0.7063, 0.3380, 0.8666, 0.5421, 0.7303, 0.5533, 0.7084, 0.4544,\n",
       "                      0.5445, 0.3721, 0.6700, 0.2868, 0.4392, 0.2813, 0.2978, 0.4167, 0.3246,\n",
       "                      0.3871, 0.5671, 0.7886, 0.5021, 0.9942, 0.3277, 0.3627, 0.4183, 0.8153,\n",
       "                      0.6375, 1.1438, 0.4741, 0.2797, 0.3257, 0.3939, 0.5186, 0.3771, 0.5812,\n",
       "                      0.5004, 0.4194, 0.8015, 0.4835, 0.4035, 0.4456, 0.3946, 0.3558, 0.5419,\n",
       "                      0.5156], dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.0.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0510],\n",
       "                       [ 0.0766],\n",
       "                       [-0.0025],\n",
       "                       ...,\n",
       "                       [-0.0554],\n",
       "                       [-0.0525],\n",
       "                       [ 0.0428]],\n",
       "              \n",
       "                      [[ 0.0090],\n",
       "                       [ 0.0900],\n",
       "                       [ 0.1719],\n",
       "                       ...,\n",
       "                       [-0.0947],\n",
       "                       [-0.3793],\n",
       "                       [ 0.2105]],\n",
       "              \n",
       "                      [[-0.0018],\n",
       "                       [-0.0758],\n",
       "                       [-0.0390],\n",
       "                       ...,\n",
       "                       [ 0.0780],\n",
       "                       [ 0.0383],\n",
       "                       [ 0.0042]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.2673],\n",
       "                       [ 0.4015],\n",
       "                       [ 0.2070],\n",
       "                       ...,\n",
       "                       [-0.0480],\n",
       "                       [ 0.1154],\n",
       "                       [-0.0629]],\n",
       "              \n",
       "                      [[ 0.1003],\n",
       "                       [ 0.0125],\n",
       "                       [-0.1353],\n",
       "                       ...,\n",
       "                       [-0.0992],\n",
       "                       [-0.2238],\n",
       "                       [-0.0396]],\n",
       "              \n",
       "                      [[ 0.0412],\n",
       "                       [-0.0411],\n",
       "                       [ 0.2007],\n",
       "                       ...,\n",
       "                       [ 0.0877],\n",
       "                       [ 0.0523],\n",
       "                       [-0.1581]]], dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.2.1.weight',\n",
       "              tensor([-0.0010,  0.0402,  0.0006,  0.0384,  0.0132, -0.0065,  0.0073, -0.0091,\n",
       "                       0.0104, -0.0024,  0.0054, -0.0013, -0.0206,  0.0208, -0.0056,  0.0108,\n",
       "                      -0.0260,  0.0484, -0.0011,  0.0179,  0.0156,  0.0038,  0.0161, -0.0147,\n",
       "                      -0.0097,  0.0317, -0.0101, -0.0127, -0.0042,  0.0111, -0.0005, -0.0376,\n",
       "                      -0.0006,  0.0352,  0.0710, -0.0191, -0.0097,  0.0267,  0.0012,  0.0079,\n",
       "                      -0.0208,  0.0053,  0.0088, -0.0134, -0.0229,  0.0100, -0.0093, -0.0089,\n",
       "                       0.0123, -0.0008,  0.0085, -0.0428, -0.0005,  0.0052,  0.0037,  0.0098,\n",
       "                      -0.0033, -0.0096,  0.0138,  0.0061,  0.0082, -0.0095,  0.0025, -0.0049,\n",
       "                      -0.0004, -0.0087,  0.0265,  0.0356,  0.0037,  0.0305, -0.0063, -0.0090,\n",
       "                       0.0142, -0.0099,  0.0276, -0.0231,  0.0164,  0.0078,  0.0274, -0.0125,\n",
       "                       0.0168,  0.0096,  0.0330,  0.0061,  0.0094, -0.0126,  0.0058,  0.0014,\n",
       "                      -0.0339,  0.0220, -0.0068,  0.0073, -0.0034,  0.0103, -0.0021, -0.0004,\n",
       "                      -0.0031, -0.0106, -0.0197, -0.0001,  0.0278, -0.0101,  0.0189,  0.0072,\n",
       "                      -0.0331,  0.0129, -0.0039,  0.0141, -0.0053,  0.0135, -0.0029, -0.0196,\n",
       "                       0.0276,  0.0122, -0.0034,  0.0069,  0.0124, -0.0056,  0.0090,  0.0121,\n",
       "                       0.0037,  0.0088, -0.0087, -0.0017, -0.0098, -0.0141, -0.0152,  0.0157,\n",
       "                      -0.0277, -0.0070,  0.0159,  0.0088,  0.0084,  0.0013,  0.0153,  0.0008,\n",
       "                      -0.0127,  0.0139, -0.0066, -0.0175,  0.0073,  0.0099, -0.0060,  0.0243,\n",
       "                      -0.0046,  0.0038,  0.0145, -0.0040,  0.0222,  0.0203,  0.0118,  0.0214,\n",
       "                      -0.0180, -0.0010,  0.0020,  0.0110, -0.0202,  0.0072,  0.0236,  0.0345,\n",
       "                      -0.0081, -0.0163, -0.0128,  0.0027,  0.0130,  0.0044,  0.0211, -0.0040,\n",
       "                      -0.0192, -0.0255,  0.0194,  0.0076,  0.0294, -0.0148,  0.0023,  0.0028,\n",
       "                       0.0003, -0.0173,  0.0132,  0.0154,  0.0065, -0.0255,  0.0008,  0.0121,\n",
       "                      -0.0048,  0.0058, -0.0021, -0.0283, -0.0153, -0.0152,  0.0045,  0.0068,\n",
       "                       0.0004, -0.0126, -0.0158,  0.0099, -0.0015,  0.0180,  0.0046,  0.0014,\n",
       "                      -0.0118, -0.0125,  0.0005,  0.0100, -0.0213,  0.0012,  0.0289,  0.0189,\n",
       "                      -0.0113, -0.0205, -0.0003, -0.0037, -0.0097,  0.0017,  0.0156, -0.0150,\n",
       "                      -0.0137, -0.0007, -0.0118, -0.0131, -0.0127, -0.0215, -0.0190,  0.0182,\n",
       "                      -0.0051, -0.0271, -0.0124,  0.0209,  0.0346, -0.0065,  0.0122, -0.0052,\n",
       "                       0.0243,  0.0228,  0.0050,  0.0172, -0.0099,  0.0012, -0.0091,  0.0051,\n",
       "                       0.0001,  0.0034, -0.0192, -0.0020,  0.0169, -0.0136, -0.0008, -0.0167,\n",
       "                      -0.0098, -0.0075, -0.0285, -0.0155, -0.0030, -0.0338, -0.0108,  0.0087],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.2.1.bias',\n",
       "              tensor([-7.2795e-04, -3.3469e-03,  2.5615e-02,  1.7376e-03,  9.3212e-03,\n",
       "                      -1.6753e-02, -2.9658e-03, -1.4160e-02, -1.3214e-02, -8.7208e-03,\n",
       "                      -4.9374e-03, -7.9470e-03,  3.0062e-03, -4.8956e-03, -6.4107e-03,\n",
       "                      -1.5175e-02, -1.8393e-02,  2.2720e-02,  4.0796e-03, -4.3133e-03,\n",
       "                       3.1041e-03, -1.9059e-02, -4.1501e-03,  3.6664e-04, -9.4798e-03,\n",
       "                      -2.1313e-02, -1.9297e-03, -4.5335e-03,  2.6222e-03,  3.8868e-03,\n",
       "                      -1.9928e-02, -1.3763e-02, -1.1673e-02, -2.0898e-02,  4.1412e-03,\n",
       "                      -1.5855e-02, -3.0226e-03,  4.0745e-03, -1.0940e-02, -1.7874e-02,\n",
       "                       4.3854e-03, -7.2711e-03, -1.7059e-02, -1.7811e-02,  7.7646e-03,\n",
       "                      -1.0010e-02, -1.3731e-02,  9.3924e-03, -1.1904e-02,  4.3385e-03,\n",
       "                      -4.3618e-03, -2.4723e-03,  2.6984e-03, -1.1851e-02, -7.9505e-03,\n",
       "                      -6.0253e-03, -4.7125e-04, -5.9180e-03, -1.4574e-02,  5.3121e-03,\n",
       "                      -8.4393e-03, -5.2493e-03, -2.3264e-02, -1.6835e-02, -1.1743e-02,\n",
       "                      -3.6267e-03, -3.6482e-03, -2.0177e-03, -2.1536e-02, -1.6293e-02,\n",
       "                       2.2893e-03, -6.6032e-04,  3.3575e-04, -4.7125e-03, -1.6277e-02,\n",
       "                      -1.6786e-02, -2.6764e-02, -1.9008e-02, -5.0277e-03, -1.6644e-02,\n",
       "                      -4.6247e-03, -4.1078e-04, -2.2868e-02, -4.6928e-03,  2.6562e-03,\n",
       "                      -1.7980e-02,  1.2481e-02,  1.6196e-02, -2.4499e-03,  2.4511e-03,\n",
       "                      -1.7947e-02, -4.6330e-03, -1.5217e-02,  4.2939e-03, -5.1057e-03,\n",
       "                      -1.4797e-02,  9.6003e-04, -1.2330e-02,  2.5038e-04, -1.0838e-02,\n",
       "                       2.3859e-03, -3.7735e-03, -1.2845e-02, -1.1175e-02, -6.7415e-04,\n",
       "                       7.2692e-03, -1.1312e-02, -7.4839e-03, -7.9239e-03, -1.2597e-02,\n",
       "                      -8.5915e-03, -5.0790e-03,  1.0275e-03,  1.2115e-03, -4.7034e-03,\n",
       "                      -4.8503e-03, -6.4275e-03, -7.3991e-03,  5.8259e-03, -2.2010e-03,\n",
       "                      -7.3446e-03, -2.2270e-02, -1.3333e-03, -8.2732e-03, -9.4862e-03,\n",
       "                      -8.1979e-03, -1.1344e-02,  1.8440e-03,  1.3599e-03, -2.0410e-02,\n",
       "                      -9.6839e-03, -7.9098e-03, -3.7910e-03,  1.5697e-05, -6.5700e-03,\n",
       "                      -2.1605e-02,  4.2204e-03,  4.0283e-04, -6.4831e-03, -2.0593e-03,\n",
       "                      -2.3457e-03,  1.9256e-03, -1.2860e-02, -2.6430e-03, -1.8717e-02,\n",
       "                      -1.6861e-02, -1.3022e-02, -1.0280e-02, -1.2432e-03,  1.0246e-02,\n",
       "                      -9.3326e-03, -1.5284e-02, -2.7686e-02, -1.0454e-02, -7.1254e-03,\n",
       "                      -3.7724e-03,  1.0640e-02,  2.7505e-03, -1.3317e-02, -2.0494e-02,\n",
       "                      -7.4842e-03,  2.7243e-02, -9.6145e-03, -3.3994e-03, -5.4003e-03,\n",
       "                       4.5228e-03, -8.3312e-03,  2.8939e-02,  1.1500e-04, -2.9051e-02,\n",
       "                      -7.2565e-04, -1.3314e-03, -7.2075e-03, -5.3022e-03, -1.7320e-02,\n",
       "                      -1.6683e-02, -7.8974e-03,  1.4435e-02, -1.1474e-02, -3.6701e-04,\n",
       "                      -1.9463e-03,  2.1519e-02, -1.1158e-02,  2.4624e-03, -4.5132e-03,\n",
       "                      -7.7967e-03, -6.0586e-03,  1.3910e-02, -9.0865e-03, -1.1510e-02,\n",
       "                      -7.4502e-03, -1.8166e-02, -6.3183e-03, -2.0461e-02, -8.9440e-03,\n",
       "                       6.6549e-04, -3.2089e-03, -1.2933e-02, -7.0443e-03, -1.4368e-02,\n",
       "                      -8.0977e-03, -1.3865e-02,  9.2988e-03, -1.1243e-02, -3.2124e-03,\n",
       "                      -9.6305e-03, -4.0261e-03, -1.5690e-02, -7.7035e-03, -2.3680e-02,\n",
       "                       2.4345e-03, -4.0755e-03, -8.5092e-04, -5.7477e-03, -2.0849e-03,\n",
       "                       1.8883e-02, -4.3178e-03,  1.6819e-02,  3.9807e-03, -2.4423e-03,\n",
       "                       2.5718e-03, -2.9551e-03, -1.3181e-02, -1.3747e-03, -2.2727e-02,\n",
       "                       5.7089e-03,  4.4769e-03,  6.1698e-03, -2.0630e-02, -1.0333e-02,\n",
       "                       5.9753e-04,  2.3022e-03,  2.1443e-03,  7.5890e-03, -1.0112e-02,\n",
       "                      -3.6802e-03,  6.6059e-03,  7.0752e-03, -1.1512e-02, -7.2608e-03,\n",
       "                      -7.2489e-03,  3.3995e-03, -1.0654e-02, -1.1668e-02, -8.9250e-03,\n",
       "                      -6.6219e-03, -7.4274e-04,  5.4266e-03, -5.8644e-03, -1.6624e-02,\n",
       "                      -7.5053e-03, -7.3289e-03, -1.2267e-02, -5.6282e-03,  4.0937e-05,\n",
       "                      -5.9866e-04], dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.2.1.running_mean',\n",
       "              tensor([-1.1578e-01,  1.4158e-01,  2.6433e-01,  3.2712e-01, -1.5668e-02,\n",
       "                       1.3126e-01, -2.0683e-02,  1.0507e-01,  2.1800e-03,  1.4118e-01,\n",
       "                      -9.5007e-02,  1.9489e-01,  2.0697e-01, -1.8849e-01,  2.4983e-01,\n",
       "                       4.3032e-02,  3.2477e-01, -5.4898e-01,  3.7983e-02,  3.7709e-01,\n",
       "                      -1.3353e-01, -3.6700e-01, -2.4383e-01,  3.5948e-01, -1.9123e-02,\n",
       "                      -6.4727e-02, -2.1877e-01, -2.0409e-02,  1.4432e-01,  5.2703e-02,\n",
       "                      -6.1961e-01,  3.3659e-01, -9.3631e-02, -1.0217e-01, -2.5888e-01,\n",
       "                       7.7050e-02,  3.5075e-01, -9.0172e-02, -1.0995e-01, -2.3505e-01,\n",
       "                      -8.0178e-01, -2.9860e-02,  1.7033e-01, -7.1453e-01, -4.1577e-01,\n",
       "                      -1.2391e-01, -2.0914e-01,  7.5619e-02, -2.9508e-01,  3.5578e-02,\n",
       "                      -9.6041e-02, -3.0559e-01,  2.7696e-01, -1.6429e-02, -4.4110e-01,\n",
       "                      -2.0352e-01, -1.3997e-02, -2.9686e-01,  1.9188e-01, -1.0232e-01,\n",
       "                       7.4081e-02,  2.4853e-01, -1.7221e-01,  1.6841e-01,  5.1837e-01,\n",
       "                      -1.8933e-02, -5.8636e-01,  2.9902e-02, -1.9554e-01,  1.4545e-01,\n",
       "                      -2.5608e-01,  3.5397e-02, -3.4241e-01, -1.6359e-01,  3.4897e-02,\n",
       "                      -4.1212e-01,  7.8959e-02, -3.3743e-01, -3.3751e-02,  3.1742e-01,\n",
       "                      -3.1577e-01,  2.2491e-01, -7.6560e-01, -7.6081e-01,  2.3304e-02,\n",
       "                      -2.2236e-03, -2.4009e-01, -2.0231e-02, -1.2668e-01, -1.6607e-01,\n",
       "                      -9.2332e-03,  2.1212e-01, -2.3443e-03,  1.5779e-01,  1.7743e-01,\n",
       "                       2.9531e-01,  7.7745e-02,  3.0311e-01, -1.6115e-01, -7.2446e-02,\n",
       "                      -9.6247e-02,  2.2273e-01, -2.4288e-01, -1.9972e-01,  1.8564e-01,\n",
       "                       1.7285e-01,  2.0827e-01, -1.1654e-01,  2.4553e-01,  1.0188e-01,\n",
       "                      -2.0252e-02,  6.3375e-02, -2.1360e-01, -3.4964e-01, -1.0912e-01,\n",
       "                      -4.0965e-02, -2.0619e-01, -3.6362e-01, -1.3493e-02, -1.0500e-01,\n",
       "                      -2.2794e-03,  3.3153e-02,  1.5774e-01,  4.6913e-02, -8.1025e-02,\n",
       "                      -2.7331e-01,  7.1843e-02, -3.2702e-01, -9.6831e-02, -4.8345e-01,\n",
       "                      -1.1988e-01, -1.3751e-01, -1.6979e-01,  2.5665e-01,  5.1327e-01,\n",
       "                      -1.8191e-01,  1.0861e-01,  4.3320e-01, -4.0506e-01, -2.0047e-02,\n",
       "                       1.5334e-01, -3.3304e-01,  1.2437e-01, -7.6602e-03, -2.7165e-02,\n",
       "                      -1.5085e-01, -6.8762e-02, -5.6192e-02, -2.0192e-01, -3.6609e-01,\n",
       "                       3.8151e-01,  1.5476e-02,  6.4966e-01,  7.7298e-02,  2.2244e-01,\n",
       "                      -1.1717e-02, -2.1701e-01,  2.1672e-01, -1.0395e-01, -2.9592e-01,\n",
       "                       9.3124e-02, -4.1344e-01,  4.3611e-02, -1.0612e-02, -4.2286e-02,\n",
       "                      -2.7401e-01,  2.2494e-02, -1.4385e-01,  6.9536e-02,  2.0816e-01,\n",
       "                      -9.1477e-03, -1.5681e-01,  3.4120e-01, -2.2300e-01, -2.9704e-01,\n",
       "                       6.0341e-01,  3.9542e-03,  2.3698e-01, -9.6631e-03, -2.2206e-01,\n",
       "                       2.4525e-01,  4.4015e-01, -1.4203e-02,  4.0267e-02, -4.8545e-01,\n",
       "                      -1.3542e-01, -7.8458e-01,  1.6526e-01,  1.3926e-01,  4.4294e-01,\n",
       "                       3.2859e-01,  4.3802e-01, -1.5863e-01,  1.9650e-01, -1.3072e-01,\n",
       "                      -3.1467e-01, -1.8309e-01, -1.3033e-01, -1.4226e-01,  2.8452e-02,\n",
       "                       1.7161e-01, -1.2408e-01,  5.2814e-02, -3.7975e-02,  6.3113e-01,\n",
       "                       1.3134e-01, -1.9547e-02, -1.0505e-01, -2.3531e-01, -7.9773e-04,\n",
       "                       5.9743e-02, -4.5676e-01,  3.7886e-02,  1.0505e-01, -2.2532e-01,\n",
       "                       2.5387e-01,  1.0116e-01, -2.0516e-01,  4.4582e-01,  3.8690e-02,\n",
       "                      -1.1023e-01,  3.5275e-01,  1.0583e-01,  1.2915e-01, -1.2746e-01,\n",
       "                      -2.0916e-01,  2.9274e-01,  4.6588e-01,  5.3821e-01,  5.1901e-01,\n",
       "                       8.0596e-03, -2.5919e-01, -1.0843e-01,  1.1232e-01, -1.9445e-02,\n",
       "                      -5.7027e-02, -4.8326e-01, -4.4388e-02, -4.1745e-02, -2.8202e-01,\n",
       "                      -6.7727e-02,  4.1758e-01,  9.1063e-03,  1.3424e-01,  3.5230e-02,\n",
       "                      -1.4623e-01, -1.9179e-01,  1.4743e-01, -1.6192e-01, -5.8794e-02,\n",
       "                      -1.2120e-02,  3.0112e-01,  3.7555e-02,  1.6582e-01, -6.7952e-01,\n",
       "                       2.5598e-02], dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.2.1.running_var',\n",
       "              tensor([0.0440, 0.2857, 0.1033, 0.2448, 0.3563, 0.1937, 0.1337, 0.2884, 0.1091,\n",
       "                      0.1761, 0.1045, 0.0666, 0.1426, 0.2953, 0.1207, 0.1117, 0.5159, 0.5097,\n",
       "                      0.1532, 0.2480, 0.3501, 0.2698, 0.2317, 0.2921, 0.3286, 0.1704, 0.2739,\n",
       "                      0.2797, 0.1319, 0.1786, 0.2394, 0.0964, 0.1558, 0.2645, 0.2080, 0.3394,\n",
       "                      0.1451, 0.2790, 0.0968, 0.4124, 0.3920, 0.2663, 0.1148, 0.2325, 0.3037,\n",
       "                      0.1625, 0.1277, 0.2137, 0.1788, 0.1150, 0.1502, 0.3963, 0.1191, 0.1766,\n",
       "                      0.1890, 0.1666, 0.0719, 0.4495, 0.2533, 0.3538, 0.1134, 0.1574, 0.0734,\n",
       "                      0.0910, 0.2351, 0.1066, 0.3052, 0.4823, 0.0396, 0.4310, 0.2640, 0.0735,\n",
       "                      0.0970, 0.2930, 0.3959, 0.1075, 0.1271, 0.2847, 0.2928, 0.1708, 0.3483,\n",
       "                      0.1331, 0.6839, 0.3315, 0.3486, 0.5451, 0.1625, 0.1535, 0.3277, 0.2665,\n",
       "                      0.4893, 0.1868, 0.0580, 0.1631, 0.0956, 0.0799, 0.1306, 0.2312, 0.1964,\n",
       "                      0.0974, 0.3483, 0.3551, 0.1420, 0.1951, 0.1435, 0.0892, 0.3026, 0.3772,\n",
       "                      0.1125, 0.1552, 0.0349, 0.4046, 0.3363, 0.1188, 0.1225, 0.1267, 0.1440,\n",
       "                      0.2832, 0.2235, 0.2327, 0.0582, 0.1301, 0.2916, 0.1054, 0.1908, 0.3913,\n",
       "                      0.1391, 0.1453, 0.3321, 0.1705, 0.0293, 0.1460, 0.3621, 0.1140, 0.1441,\n",
       "                      0.0590, 0.0849, 0.2686, 0.1033, 0.1844, 0.2728, 0.1213, 0.0854, 0.0808,\n",
       "                      0.0745, 0.2571, 0.1096, 0.1771, 0.2132, 0.3038, 0.3986, 0.1302, 0.2823,\n",
       "                      0.0682, 0.0777, 0.2564, 0.2812, 0.1103, 0.1522, 0.1747, 0.0965, 0.2222,\n",
       "                      0.0937, 0.1136, 0.4563, 0.3573, 0.4113, 0.0869, 0.3864, 0.2886, 0.1573,\n",
       "                      0.0773, 0.2260, 0.0569, 0.2749, 0.2269, 0.1054, 0.3876, 0.1265, 0.0741,\n",
       "                      0.1075, 0.1540, 0.1516, 0.2364, 0.2387, 0.1255, 0.2923, 0.1504, 0.0875,\n",
       "                      0.1135, 0.2501, 0.2611, 0.0729, 0.1050, 0.1732, 0.3203, 0.1575, 0.1567,\n",
       "                      0.2064, 0.0633, 0.1708, 0.0617, 0.2209, 0.2549, 0.2912, 0.1254, 0.1321,\n",
       "                      0.1858, 0.1188, 0.2069, 0.0344, 0.0983, 0.1908, 0.1725, 0.1557, 0.2547,\n",
       "                      0.1866, 0.0839, 0.2703, 0.4347, 0.1338, 0.2202, 0.0702, 0.2719, 0.2316,\n",
       "                      0.3331, 0.1303, 0.3630, 0.3517, 0.2471, 0.1121, 0.1939, 0.3163, 0.2394,\n",
       "                      0.0734, 0.2661, 0.3263, 0.0634, 0.2345, 0.1950, 0.0961, 0.2340, 0.3849,\n",
       "                      0.1130, 0.2686, 0.1005, 0.0476, 0.3965, 0.1334, 0.1252, 0.3284, 0.2387,\n",
       "                      0.1090, 0.2877, 0.2772, 0.0949], dtype=torch.float64)),\n",
       "             ('4.0.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.0.idpath.0.0.weight',\n",
       "              tensor([[[ 0.2371],\n",
       "                       [-0.1335],\n",
       "                       [-0.0465],\n",
       "                       ...,\n",
       "                       [-0.1835],\n",
       "                       [-0.0722],\n",
       "                       [-0.0436]],\n",
       "              \n",
       "                      [[ 0.1941],\n",
       "                       [ 0.0505],\n",
       "                       [ 0.2099],\n",
       "                       ...,\n",
       "                       [-0.0588],\n",
       "                       [-0.1481],\n",
       "                       [ 0.3503]],\n",
       "              \n",
       "                      [[ 0.0784],\n",
       "                       [-0.0999],\n",
       "                       [-0.0270],\n",
       "                       ...,\n",
       "                       [ 0.2961],\n",
       "                       [-0.0964],\n",
       "                       [ 0.0357]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.2864],\n",
       "                       [ 0.0104],\n",
       "                       [ 0.4332],\n",
       "                       ...,\n",
       "                       [-0.1639],\n",
       "                       [ 0.1635],\n",
       "                       [ 0.2124]],\n",
       "              \n",
       "                      [[-0.3100],\n",
       "                       [ 0.1112],\n",
       "                       [ 0.1256],\n",
       "                       ...,\n",
       "                       [-0.2260],\n",
       "                       [ 0.0033],\n",
       "                       [-0.1250]],\n",
       "              \n",
       "                      [[-0.3756],\n",
       "                       [-0.1132],\n",
       "                       [ 0.2205],\n",
       "                       ...,\n",
       "                       [ 0.2625],\n",
       "                       [-0.0005],\n",
       "                       [ 0.1064]]], dtype=torch.float64)),\n",
       "             ('4.0.idpath.0.1.weight',\n",
       "              tensor([0.9899, 0.9824, 0.9867, 0.9679, 0.9973, 0.9892, 0.9583, 0.9404, 0.9615,\n",
       "                      0.9586, 0.9701, 0.9832, 0.9786, 0.9867, 0.9710, 0.9294, 0.9548, 0.9788,\n",
       "                      0.9627, 0.9578, 0.9739, 0.9662, 0.9949, 0.9772, 0.9567, 0.9724, 0.9845,\n",
       "                      0.9837, 0.9708, 0.9963, 0.9528, 0.9863, 1.0066, 0.9463, 0.9603, 0.9606,\n",
       "                      0.9729, 1.0011, 0.9757, 0.9697, 0.9732, 0.9775, 0.9606, 0.9744, 0.9868,\n",
       "                      0.9760, 0.9787, 0.9791, 0.9345, 0.9854, 1.0190, 1.0158, 0.9773, 0.9724,\n",
       "                      0.9816, 0.9519, 0.9817, 0.9234, 0.9368, 1.0043, 0.9823, 0.9696, 0.9711,\n",
       "                      0.9843, 0.9397, 0.9648, 0.9767, 0.9516, 0.9720, 0.9588, 0.9889, 0.9830,\n",
       "                      0.9764, 0.9731, 0.9502, 0.9751, 0.9602, 0.9705, 0.9735, 0.9602, 0.9886,\n",
       "                      0.9951, 0.9676, 0.9561, 0.9720, 0.9620, 0.9869, 0.9823, 0.9570, 0.9744,\n",
       "                      0.9620, 0.9792, 0.9648, 0.9761, 0.9881, 0.9818, 0.9535, 0.9648, 0.9865,\n",
       "                      0.9678, 0.9452, 0.9687, 0.9472, 0.9923, 0.9709, 0.9663, 0.9583, 0.9719,\n",
       "                      0.9608, 0.9806, 0.9737, 0.9827, 0.9671, 0.9711, 0.9711, 0.9621, 0.9691,\n",
       "                      0.9510, 0.9827, 0.9779, 0.9810, 0.9487, 0.9751, 0.9684, 0.9717, 0.9313,\n",
       "                      0.9700, 0.9847, 0.9775, 0.9662, 0.9711, 0.9684, 0.9756, 0.9507, 0.9763,\n",
       "                      0.9642, 0.9899, 0.9498, 0.9751, 0.9727, 0.9932, 0.9663, 0.9639, 0.9772,\n",
       "                      0.9708, 0.9459, 0.9901, 0.9599, 0.9720, 0.9931, 0.9517, 0.9690, 0.9540,\n",
       "                      0.9521, 0.9547, 0.9940, 0.9938, 0.9691, 0.9623, 0.9908, 0.9780, 0.9787,\n",
       "                      0.9626, 0.9590, 0.9565, 0.9826, 0.9616, 0.9626, 0.9545, 0.9438, 0.9604,\n",
       "                      0.9647, 0.9671, 0.9750, 0.9663, 0.9644, 0.9725, 0.9607, 0.9718, 0.9748,\n",
       "                      0.9791, 0.9593, 0.9779, 0.9776, 0.9611, 0.9653, 0.9592, 0.9726, 0.9787,\n",
       "                      0.9741, 0.9462, 0.9669, 0.9383, 0.9544, 0.9553, 0.9541, 0.9711, 0.9869,\n",
       "                      0.9726, 0.9643, 0.9848, 0.9401, 0.9652, 0.9685, 0.9784, 0.9838, 0.9782,\n",
       "                      0.9645, 0.9837, 0.9679, 0.9736, 0.9738, 0.9907, 0.9538, 0.9618, 0.9776,\n",
       "                      0.9695, 0.9916, 0.9942, 0.9467, 0.9680, 0.9828, 0.9716, 0.9848, 0.9423,\n",
       "                      0.9755, 0.9756, 0.9802, 0.9567, 0.9511, 0.9770, 0.9797, 0.9755, 0.9649,\n",
       "                      0.9667, 0.9578, 0.9769, 0.9926, 0.9693, 0.9522, 0.9628, 0.9777, 0.9542,\n",
       "                      0.9772, 0.9768, 0.9743, 0.9740, 0.9384, 0.9838, 0.9520, 0.9527, 0.9462,\n",
       "                      0.9894, 0.9455, 0.9685, 0.9804], dtype=torch.float64)),\n",
       "             ('4.0.idpath.0.1.bias',\n",
       "              tensor([-7.2795e-04, -3.3469e-03,  2.5615e-02,  1.7376e-03,  9.3212e-03,\n",
       "                      -1.6753e-02, -2.9658e-03, -1.4160e-02, -1.3214e-02, -8.7208e-03,\n",
       "                      -4.9374e-03, -7.9470e-03,  3.0062e-03, -4.8956e-03, -6.4107e-03,\n",
       "                      -1.5175e-02, -1.8393e-02,  2.2720e-02,  4.0796e-03, -4.3133e-03,\n",
       "                       3.1041e-03, -1.9059e-02, -4.1501e-03,  3.6664e-04, -9.4798e-03,\n",
       "                      -2.1313e-02, -1.9297e-03, -4.5335e-03,  2.6222e-03,  3.8868e-03,\n",
       "                      -1.9928e-02, -1.3763e-02, -1.1673e-02, -2.0898e-02,  4.1412e-03,\n",
       "                      -1.5855e-02, -3.0226e-03,  4.0745e-03, -1.0940e-02, -1.7874e-02,\n",
       "                       4.3854e-03, -7.2711e-03, -1.7059e-02, -1.7811e-02,  7.7646e-03,\n",
       "                      -1.0010e-02, -1.3731e-02,  9.3924e-03, -1.1904e-02,  4.3385e-03,\n",
       "                      -4.3618e-03, -2.4723e-03,  2.6984e-03, -1.1851e-02, -7.9505e-03,\n",
       "                      -6.0253e-03, -4.7125e-04, -5.9180e-03, -1.4574e-02,  5.3121e-03,\n",
       "                      -8.4393e-03, -5.2493e-03, -2.3264e-02, -1.6835e-02, -1.1743e-02,\n",
       "                      -3.6267e-03, -3.6482e-03, -2.0177e-03, -2.1536e-02, -1.6293e-02,\n",
       "                       2.2893e-03, -6.6032e-04,  3.3575e-04, -4.7125e-03, -1.6277e-02,\n",
       "                      -1.6786e-02, -2.6764e-02, -1.9008e-02, -5.0277e-03, -1.6644e-02,\n",
       "                      -4.6247e-03, -4.1078e-04, -2.2868e-02, -4.6928e-03,  2.6562e-03,\n",
       "                      -1.7980e-02,  1.2481e-02,  1.6196e-02, -2.4499e-03,  2.4511e-03,\n",
       "                      -1.7947e-02, -4.6330e-03, -1.5217e-02,  4.2939e-03, -5.1057e-03,\n",
       "                      -1.4797e-02,  9.6003e-04, -1.2330e-02,  2.5038e-04, -1.0838e-02,\n",
       "                       2.3859e-03, -3.7735e-03, -1.2845e-02, -1.1175e-02, -6.7415e-04,\n",
       "                       7.2692e-03, -1.1312e-02, -7.4839e-03, -7.9239e-03, -1.2597e-02,\n",
       "                      -8.5915e-03, -5.0790e-03,  1.0275e-03,  1.2115e-03, -4.7034e-03,\n",
       "                      -4.8503e-03, -6.4275e-03, -7.3991e-03,  5.8259e-03, -2.2010e-03,\n",
       "                      -7.3446e-03, -2.2270e-02, -1.3333e-03, -8.2732e-03, -9.4862e-03,\n",
       "                      -8.1979e-03, -1.1344e-02,  1.8440e-03,  1.3599e-03, -2.0410e-02,\n",
       "                      -9.6839e-03, -7.9098e-03, -3.7910e-03,  1.5697e-05, -6.5700e-03,\n",
       "                      -2.1605e-02,  4.2204e-03,  4.0283e-04, -6.4831e-03, -2.0593e-03,\n",
       "                      -2.3457e-03,  1.9256e-03, -1.2860e-02, -2.6430e-03, -1.8717e-02,\n",
       "                      -1.6861e-02, -1.3022e-02, -1.0280e-02, -1.2432e-03,  1.0246e-02,\n",
       "                      -9.3326e-03, -1.5284e-02, -2.7686e-02, -1.0454e-02, -7.1254e-03,\n",
       "                      -3.7724e-03,  1.0640e-02,  2.7505e-03, -1.3317e-02, -2.0494e-02,\n",
       "                      -7.4842e-03,  2.7243e-02, -9.6145e-03, -3.3994e-03, -5.4003e-03,\n",
       "                       4.5228e-03, -8.3312e-03,  2.8939e-02,  1.1500e-04, -2.9051e-02,\n",
       "                      -7.2565e-04, -1.3314e-03, -7.2075e-03, -5.3022e-03, -1.7320e-02,\n",
       "                      -1.6683e-02, -7.8974e-03,  1.4435e-02, -1.1474e-02, -3.6701e-04,\n",
       "                      -1.9463e-03,  2.1519e-02, -1.1158e-02,  2.4624e-03, -4.5132e-03,\n",
       "                      -7.7967e-03, -6.0586e-03,  1.3910e-02, -9.0865e-03, -1.1510e-02,\n",
       "                      -7.4502e-03, -1.8166e-02, -6.3183e-03, -2.0461e-02, -8.9440e-03,\n",
       "                       6.6549e-04, -3.2089e-03, -1.2933e-02, -7.0443e-03, -1.4368e-02,\n",
       "                      -8.0977e-03, -1.3865e-02,  9.2988e-03, -1.1243e-02, -3.2124e-03,\n",
       "                      -9.6305e-03, -4.0261e-03, -1.5690e-02, -7.7035e-03, -2.3680e-02,\n",
       "                       2.4345e-03, -4.0755e-03, -8.5092e-04, -5.7477e-03, -2.0849e-03,\n",
       "                       1.8883e-02, -4.3178e-03,  1.6819e-02,  3.9807e-03, -2.4423e-03,\n",
       "                       2.5718e-03, -2.9551e-03, -1.3181e-02, -1.3747e-03, -2.2727e-02,\n",
       "                       5.7089e-03,  4.4769e-03,  6.1698e-03, -2.0630e-02, -1.0333e-02,\n",
       "                       5.9753e-04,  2.3022e-03,  2.1443e-03,  7.5890e-03, -1.0112e-02,\n",
       "                      -3.6802e-03,  6.6059e-03,  7.0752e-03, -1.1512e-02, -7.2608e-03,\n",
       "                      -7.2489e-03,  3.3995e-03, -1.0654e-02, -1.1668e-02, -8.9250e-03,\n",
       "                      -6.6219e-03, -7.4274e-04,  5.4266e-03, -5.8644e-03, -1.6624e-02,\n",
       "                      -7.5053e-03, -7.3289e-03, -1.2267e-02, -5.6282e-03,  4.0937e-05,\n",
       "                      -5.9866e-04], dtype=torch.float64)),\n",
       "             ('4.0.idpath.0.1.running_mean',\n",
       "              tensor([-8.6970e-01, -8.2516e-01,  1.6050e-01, -8.8245e-01,  4.2306e-01,\n",
       "                      -4.2279e-01,  6.2539e-01, -9.7500e-01,  9.2605e-01, -4.4388e-01,\n",
       "                       9.0721e-03,  4.7329e-02,  1.7502e+00, -1.0152e+00, -1.5604e-01,\n",
       "                       4.0949e-01,  7.2314e-01,  1.1869e-01,  9.5216e-01, -1.2153e+00,\n",
       "                      -2.6923e-01, -9.1367e-01, -3.8530e-01,  4.5628e-02, -5.0288e-01,\n",
       "                       2.7304e-01,  3.3925e-01,  8.9459e-01,  5.0166e-01, -5.3240e-01,\n",
       "                      -1.1842e+00,  5.1935e-01,  4.5725e-01,  1.3716e-01,  1.9574e-01,\n",
       "                      -1.1665e+00,  1.0351e-01, -1.4172e-01,  7.7860e-01, -4.0838e-01,\n",
       "                      -1.3988e+00,  1.0766e+00,  5.2660e-01, -5.4874e-01, -1.1154e+00,\n",
       "                      -1.4901e+00,  4.0023e-01, -7.1698e-01, -9.1563e-01, -1.1361e+00,\n",
       "                       2.4823e-01,  3.1645e-01, -4.7132e-01, -6.6839e-01, -1.9266e-01,\n",
       "                       2.1838e-01,  2.5450e-01, -1.6479e-02, -1.6050e+00,  7.7678e-01,\n",
       "                       4.9202e-01, -7.8607e-01, -2.7392e-01,  4.5334e-02,  4.1335e-02,\n",
       "                      -8.4635e-01, -9.8035e-01,  1.5407e+00,  3.5765e-01, -9.7200e-01,\n",
       "                       3.8787e-02,  1.0361e+00,  6.0907e-01, -1.7030e+00, -5.0448e-01,\n",
       "                       6.1244e-01, -1.8063e-02,  6.6493e-02, -1.2145e+00,  1.4848e+00,\n",
       "                       2.7367e-01, -3.5150e-01,  1.6714e+00, -4.3504e-01,  2.4836e-01,\n",
       "                      -7.1685e-01,  8.2183e-01,  8.1651e-01, -7.2221e-01,  5.1031e-01,\n",
       "                      -5.1642e-01, -4.6254e-01,  4.9409e-01,  9.9144e-01, -8.1668e-01,\n",
       "                      -9.5168e-02, -1.1251e+00,  1.1677e+00, -4.1693e-01,  2.5504e-01,\n",
       "                      -5.9776e-01, -1.0607e+00,  5.7104e-02,  2.6060e-01, -4.8110e-01,\n",
       "                       7.9906e-01, -2.1088e+00, -4.1257e-01, -8.3475e-02,  6.7099e-01,\n",
       "                       1.1993e+00, -4.4357e-01,  5.2180e-02, -4.7694e-01, -9.5645e-02,\n",
       "                      -2.7651e-01, -8.4560e-01, -9.5772e-01, -1.0573e+00, -1.2443e+00,\n",
       "                       1.0095e+00,  1.8683e-01, -3.0580e-01, -2.0634e-01,  1.1915e+00,\n",
       "                      -1.4900e+00,  8.4578e-01,  3.9342e-01,  1.2837e+00, -6.0713e-01,\n",
       "                       7.5764e-01,  1.1367e-01,  1.6267e-01, -3.5308e-02,  1.4314e+00,\n",
       "                      -4.6808e-01,  9.6316e-01,  6.4256e-01,  2.6801e-01,  7.5102e-01,\n",
       "                       1.3269e-01, -1.0062e-01,  1.2450e-01,  6.6281e-01,  8.1846e-02,\n",
       "                      -1.2012e+00,  6.7323e-01, -5.0267e-01,  2.4565e+00, -7.4361e-01,\n",
       "                      -6.8567e-01,  3.5940e-01,  4.6306e-01,  6.1766e-01,  4.3343e-02,\n",
       "                      -4.4528e-01,  3.3705e-01, -1.0960e-01, -1.1754e+00,  5.5523e-01,\n",
       "                       7.4601e-01, -2.1780e-03, -2.0420e-01,  7.0929e-01, -2.4277e-01,\n",
       "                       2.4057e-01, -2.2474e-01, -4.0028e-01, -5.2164e-01,  9.3689e-01,\n",
       "                       3.5607e-01, -7.5025e-01, -1.3103e-01,  1.0985e+00, -1.1013e+00,\n",
       "                      -9.5393e-01,  1.2212e+00,  1.0217e+00, -3.1593e-01,  8.6217e-01,\n",
       "                      -3.1014e-01,  6.5259e-01, -1.0998e+00, -8.7326e-01,  3.7408e-02,\n",
       "                      -3.2071e-01, -7.6094e-01,  7.7311e-01, -1.1076e-01, -2.3043e-01,\n",
       "                       1.0631e+00,  2.0589e-01,  9.3177e-01, -9.5634e-01,  1.3776e-01,\n",
       "                       1.1256e+00, -1.4307e-01,  9.4384e-01, -5.9184e-01,  7.4670e-01,\n",
       "                       9.7137e-01, -5.6466e-01, -4.4352e-01,  5.1614e-01, -6.7271e-01,\n",
       "                       7.2162e-02,  2.8954e-01,  5.5429e-01, -1.4097e-01, -1.9983e-02,\n",
       "                       7.1585e-01, -7.9685e-01,  6.9718e-01, -1.2441e+00,  1.1940e+00,\n",
       "                      -5.4630e-01, -2.5207e-01,  4.6007e-01,  1.9865e-01, -1.1386e+00,\n",
       "                       8.3696e-02, -2.1574e-01,  3.1598e-01,  4.7775e-01, -3.3512e-01,\n",
       "                      -1.0837e+00,  5.3130e-01,  2.3767e-01, -1.2309e+00, -5.4910e-01,\n",
       "                       4.5156e-01, -5.6311e-01, -8.1764e-01,  6.0986e-01,  3.6265e-01,\n",
       "                      -4.5807e-01,  7.2268e-01,  1.5520e+00, -7.3990e-01, -4.9021e-02,\n",
       "                       1.3154e-03,  1.3057e+00, -1.8731e+00,  5.4473e-01,  4.7733e-01,\n",
       "                       1.6615e+00, -4.8027e-02, -8.9125e-01,  1.4895e-01, -2.8089e-01,\n",
       "                      -1.5938e+00, -1.5455e+00,  7.0318e-01, -6.3224e-01,  3.9002e-02,\n",
       "                       1.3062e+00], dtype=torch.float64)),\n",
       "             ('4.0.idpath.0.1.running_var',\n",
       "              tensor([ 1.9735,  1.0589,  0.9439,  2.3606,  0.3837,  0.6868,  1.8396,  2.1076,\n",
       "                       1.8944,  1.2805,  0.7085,  0.7145,  7.2122,  0.6963,  2.2533,  0.5292,\n",
       "                       0.9283,  0.5410,  3.0329,  2.9820,  0.7840,  1.1018,  0.6320,  0.7323,\n",
       "                       1.7575,  0.8180,  1.2420,  0.6876,  0.9854,  0.7350,  5.0564,  0.6087,\n",
       "                       0.6169,  2.6058,  0.5291,  3.4094,  1.0299,  1.7693,  2.2843,  1.9488,\n",
       "                       1.9768,  2.2614,  2.4679,  2.2254,  1.3204,  1.8735,  0.7190,  0.6510,\n",
       "                       3.8796,  2.6322,  1.2914,  0.5280,  1.1995,  0.5019,  0.8760,  1.8457,\n",
       "                       0.9077,  0.9282,  3.7612,  0.6882,  1.2123,  0.9193,  0.6479,  0.4345,\n",
       "                       0.8827,  0.9133,  1.4090,  2.9678,  0.8500,  1.9771,  1.8851,  3.0204,\n",
       "                       2.4805,  6.2572,  1.6480,  0.9106,  0.5279,  1.1849,  1.7936,  2.7412,\n",
       "                       0.6881,  1.4495,  6.7257,  0.9887,  0.6177,  1.6697,  1.9935,  2.1764,\n",
       "                       1.1930,  1.2355,  1.1046,  0.9980,  1.3488,  3.1240,  1.0524,  0.5291,\n",
       "                       3.6403,  4.3432,  0.6661,  1.1114,  3.0617,  2.0828,  1.3908,  1.7715,\n",
       "                       0.8661,  1.0497,  6.6596,  1.0690,  1.0039,  1.5976,  0.6176,  0.7111,\n",
       "                       1.2118,  0.9582,  0.7753,  1.6378,  0.6582,  1.4629,  1.1347,  1.9292,\n",
       "                       2.7711,  0.5357,  1.5731,  0.4397,  3.0211,  3.8856,  3.0786,  0.9955,\n",
       "                       1.3218,  0.8695,  1.6273,  3.1703,  0.7497,  0.7026,  3.4062,  0.7240,\n",
       "                       1.2437,  2.6632,  0.8349,  1.5747,  0.4706,  0.6963,  0.4345,  2.2579,\n",
       "                       1.3429,  2.5957,  1.0827,  2.3778, 11.6310,  1.0481,  1.4111,  1.1156,\n",
       "                       0.8163,  1.0057,  1.1022,  1.6909,  0.5027,  0.5590,  2.7165,  0.7544,\n",
       "                       0.9671,  0.7275,  0.4158,  0.9332,  1.1163,  0.6228,  1.7176,  0.6107,\n",
       "                       0.6323,  1.7734,  0.7796,  1.4262,  0.5023,  2.5458,  1.9236,  4.3499,\n",
       "                       4.0910,  2.5112,  0.8166,  1.2770,  0.6852,  1.5082,  2.8645,  2.2191,\n",
       "                       0.6928,  1.9947,  0.7945,  1.8441,  0.8695,  0.4899,  0.9763,  0.7612,\n",
       "                       3.0937,  3.0861,  1.2594,  1.1940,  0.5873,  1.8800,  1.3293,  0.6910,\n",
       "                       2.8291,  0.4372,  0.5007,  1.0439,  2.2434,  1.2281,  0.9088,  1.4714,\n",
       "                       0.7049,  0.5277,  3.8043,  2.6656,  1.6304,  2.3733,  2.6948,  0.5541,\n",
       "                       1.3079,  0.6591,  0.8858,  2.0043,  0.6880,  1.0870,  1.7150,  0.5049,\n",
       "                       2.7604,  1.2065,  1.0442,  0.7567,  1.4004,  1.9523,  1.3694,  0.7225,\n",
       "                       0.8776,  0.6733,  1.0029,  1.4279,  0.7410,  1.5281,  1.3873,  0.8646,\n",
       "                       1.1651,  3.7680,  4.5964,  0.6861,  1.5415,  4.8437,  0.9516,  1.4149,\n",
       "                       0.4324,  1.5701,  4.9608,  2.8930,  3.2516,  0.9578,  2.3832,  4.0033],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.0.idpath.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.1.convs.0.0.weight',\n",
       "              tensor([[[ 0.0433],\n",
       "                       [ 0.0729],\n",
       "                       [ 0.0497],\n",
       "                       ...,\n",
       "                       [ 0.0378],\n",
       "                       [-0.0217],\n",
       "                       [ 0.0320]],\n",
       "              \n",
       "                      [[-0.0893],\n",
       "                       [ 0.0643],\n",
       "                       [ 0.1649],\n",
       "                       ...,\n",
       "                       [ 0.1981],\n",
       "                       [ 0.0114],\n",
       "                       [ 0.1326]],\n",
       "              \n",
       "                      [[-0.0556],\n",
       "                       [ 0.0464],\n",
       "                       [ 0.2254],\n",
       "                       ...,\n",
       "                       [ 0.0318],\n",
       "                       [-0.0813],\n",
       "                       [-0.1020]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0480],\n",
       "                       [ 0.0273],\n",
       "                       [-0.1232],\n",
       "                       ...,\n",
       "                       [-0.1617],\n",
       "                       [ 0.0991],\n",
       "                       [-0.0936]],\n",
       "              \n",
       "                      [[-0.1003],\n",
       "                       [-0.0633],\n",
       "                       [ 0.0894],\n",
       "                       ...,\n",
       "                       [-0.0121],\n",
       "                       [ 0.0503],\n",
       "                       [ 0.0952]],\n",
       "              \n",
       "                      [[-0.1189],\n",
       "                       [-0.0043],\n",
       "                       [ 0.0023],\n",
       "                       ...,\n",
       "                       [-0.1041],\n",
       "                       [ 0.0674],\n",
       "                       [ 0.1825]]], dtype=torch.float64)),\n",
       "             ('4.1.convs.0.1.weight',\n",
       "              tensor([1.0034, 0.9469, 0.9723, 0.9739, 0.9762, 0.9611, 0.9750, 0.9575, 0.9692,\n",
       "                      0.9740, 0.9631, 0.9902, 0.9811, 0.9544, 0.9580, 0.9519, 0.9656, 0.9779,\n",
       "                      0.9203, 0.9478, 0.9605, 0.9497, 0.9386, 0.9533, 0.9459, 0.9430, 0.9711,\n",
       "                      0.9746, 0.9570, 0.9580, 0.9550, 0.9575, 0.9650, 0.9662, 0.9379, 0.9584,\n",
       "                      0.9631, 0.9687, 0.9597, 0.9515, 0.9964, 0.9618, 0.9581, 0.9556, 0.9415,\n",
       "                      0.9436, 0.9656, 0.9670, 0.9596, 0.9680, 0.9446, 0.9494, 0.9810, 0.9658,\n",
       "                      0.9638, 0.9320, 0.9919, 0.9957, 0.9370, 0.9610, 0.9799, 0.9369, 0.9505,\n",
       "                      0.9705], dtype=torch.float64)),\n",
       "             ('4.1.convs.0.1.bias',\n",
       "              tensor([ 0.0153,  0.0166,  0.0137,  0.0150,  0.0211,  0.0052, -0.0100,  0.0065,\n",
       "                       0.0003,  0.0118,  0.0110,  0.0178,  0.0011,  0.0065, -0.0053, -0.0034,\n",
       "                       0.0049,  0.0020, -0.0118, -0.0284,  0.0010, -0.0209, -0.0121,  0.0017,\n",
       "                       0.0087,  0.0001,  0.0002, -0.0105,  0.0083, -0.0025, -0.0029, -0.0111,\n",
       "                      -0.0021, -0.0002,  0.0023,  0.0011, -0.0021,  0.0015,  0.0120,  0.0040,\n",
       "                       0.0162,  0.0051, -0.0001, -0.0158, -0.0049, -0.0089,  0.0185,  0.0267,\n",
       "                       0.0002, -0.0048, -0.0005, -0.0045,  0.0029,  0.0089,  0.0153, -0.0133,\n",
       "                       0.0173,  0.0082,  0.0004,  0.0038,  0.0062,  0.0119, -0.0027,  0.0164],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convs.0.1.running_mean',\n",
       "              tensor([-3.6673e-01, -3.1839e-01, -2.2712e-01, -7.3303e-01, -2.6468e-01,\n",
       "                      -3.4504e-01, -5.3686e-01,  4.4931e-01, -1.8099e-01,  4.5594e-01,\n",
       "                      -2.2706e-01, -2.2970e-02,  4.1870e-01,  6.3956e-04, -7.1862e-01,\n",
       "                      -6.0666e-01,  3.2083e-01, -3.1131e-01, -8.1477e-01, -2.6258e-02,\n",
       "                      -3.8624e-02,  9.0266e-03, -1.5698e-01, -3.4816e-03, -3.6534e-01,\n",
       "                      -2.3503e-02, -6.4681e-01,  2.2677e-01, -3.5768e-01, -6.4312e-01,\n",
       "                       6.6613e-02,  8.2632e-01,  4.3019e-01, -9.0011e-03, -6.3850e-01,\n",
       "                      -6.4609e-01,  4.2953e-01, -8.5458e-01, -1.0722e+00, -2.4228e-01,\n",
       "                      -1.4652e-01, -3.8099e-01, -1.7137e-01,  1.8403e-01, -2.6536e-01,\n",
       "                       9.4302e-01, -1.0785e+00, -3.8379e-01,  2.7501e-01, -6.5112e-01,\n",
       "                      -1.0300e+00,  3.8694e-01, -4.9725e-01, -2.3615e-02, -9.3182e-02,\n",
       "                      -3.1703e-01, -8.7847e-01, -2.0344e-01, -1.5094e-01,  6.0241e-01,\n",
       "                      -1.4606e-02, -2.9230e-01, -2.4752e-01,  5.5926e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convs.0.1.running_var',\n",
       "              tensor([0.8764, 1.0767, 0.4243, 0.4149, 0.5302, 0.5180, 0.5863, 2.0796, 0.6191,\n",
       "                      1.3904, 0.3872, 0.3380, 0.3595, 0.4874, 0.3935, 0.6230, 0.3508, 0.4836,\n",
       "                      0.6899, 0.7547, 0.4267, 0.7277, 0.6650, 0.4500, 0.4653, 0.4458, 0.6363,\n",
       "                      0.4481, 0.3858, 0.5953, 0.4685, 1.1678, 1.1814, 0.7938, 1.5083, 0.6731,\n",
       "                      0.5344, 0.4784, 2.1425, 0.4739, 0.5008, 0.5000, 0.9115, 0.7567, 0.4575,\n",
       "                      1.5659, 0.8526, 0.6364, 0.3154, 1.6061, 0.4650, 0.7609, 0.4101, 0.7246,\n",
       "                      0.4935, 0.8381, 0.3731, 0.4475, 0.9651, 0.5591, 0.3131, 0.7044, 0.7307,\n",
       "                      0.4144], dtype=torch.float64)),\n",
       "             ('4.1.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.1.convs.1.0.weight',\n",
       "              tensor([[[ 0.0421, -0.0811,  0.0330,  0.0056,  0.1588],\n",
       "                       [ 0.0385, -0.0733, -0.0175,  0.0611,  0.0599],\n",
       "                       [ 0.0694, -0.0409, -0.0874,  0.0063,  0.0964],\n",
       "                       ...,\n",
       "                       [ 0.1517, -0.0267,  0.0746,  0.1003,  0.0089],\n",
       "                       [ 0.1306, -0.0173,  0.1154, -0.0595,  0.0261],\n",
       "                       [-0.0747,  0.0046,  0.0660, -0.0371, -0.0347]],\n",
       "              \n",
       "                      [[-0.0505, -0.0011, -0.0235, -0.0683,  0.0868],\n",
       "                       [-0.0585,  0.0829,  0.0368,  0.0263, -0.0380],\n",
       "                       [ 0.0188,  0.0786,  0.0824,  0.0868,  0.0356],\n",
       "                       ...,\n",
       "                       [-0.0216,  0.1189,  0.1133, -0.0908, -0.0240],\n",
       "                       [-0.0623, -0.0122, -0.0879,  0.0989,  0.0467],\n",
       "                       [ 0.0985,  0.1105,  0.0686, -0.0625, -0.0092]],\n",
       "              \n",
       "                      [[-0.0649,  0.0434, -0.1118, -0.0303,  0.0119],\n",
       "                       [-0.0747, -0.1580, -0.0966, -0.0388,  0.0641],\n",
       "                       [-0.0063,  0.0922, -0.0461,  0.0850,  0.0342],\n",
       "                       ...,\n",
       "                       [ 0.1181, -0.0842,  0.0485, -0.0386, -0.0531],\n",
       "                       [-0.0632,  0.0632, -0.0538,  0.0249,  0.1037],\n",
       "                       [ 0.0170,  0.0047, -0.0239,  0.0354, -0.0418]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0713,  0.0364,  0.0408, -0.0946, -0.1306],\n",
       "                       [ 0.0318, -0.0729, -0.0014,  0.0644, -0.0119],\n",
       "                       [-0.1309,  0.0735,  0.0060,  0.0275,  0.0364],\n",
       "                       ...,\n",
       "                       [ 0.0505,  0.0300, -0.0917,  0.0684,  0.0617],\n",
       "                       [ 0.0152,  0.0705, -0.1785,  0.0208,  0.0345],\n",
       "                       [-0.1008, -0.0939, -0.0388,  0.1387, -0.0035]],\n",
       "              \n",
       "                      [[-0.0174, -0.0621,  0.1055, -0.0486,  0.0797],\n",
       "                       [-0.0954,  0.0507,  0.0932, -0.0349,  0.0466],\n",
       "                       [ 0.0296, -0.0120,  0.0615,  0.0684, -0.0833],\n",
       "                       ...,\n",
       "                       [-0.0368, -0.0442, -0.1363, -0.0535,  0.0274],\n",
       "                       [ 0.0130, -0.0371,  0.0120, -0.0719, -0.0100],\n",
       "                       [-0.0099, -0.0539, -0.0553,  0.0409, -0.0248]],\n",
       "              \n",
       "                      [[ 0.0012, -0.0103,  0.0057, -0.0038, -0.0738],\n",
       "                       [ 0.0569, -0.0173,  0.1431,  0.0587,  0.1055],\n",
       "                       [ 0.0721, -0.0504, -0.0647, -0.0414,  0.1351],\n",
       "                       ...,\n",
       "                       [ 0.1394,  0.0234, -0.1823, -0.0278,  0.0474],\n",
       "                       [ 0.0502, -0.0492,  0.0562, -0.1517,  0.1205],\n",
       "                       [-0.0972, -0.1027, -0.0387, -0.0323,  0.1212]]], dtype=torch.float64)),\n",
       "             ('4.1.convs.1.1.weight',\n",
       "              tensor([0.9519, 0.9701, 0.9212, 0.9582, 0.9861, 0.9419, 0.9595, 0.9429, 0.9335,\n",
       "                      0.9492, 0.9308, 0.9413, 0.9345, 0.9444, 0.9859, 0.9597, 0.9664, 0.9208,\n",
       "                      0.9404, 0.9575, 0.9676, 0.9332, 0.9134, 0.9310, 0.9467, 0.9325, 0.9623,\n",
       "                      0.9687, 0.9535, 0.9334, 0.9790, 0.9017, 0.9368, 0.9397, 0.9794, 0.9608,\n",
       "                      0.9274, 0.9874, 0.9475, 0.9825, 0.9398, 0.9624, 0.9865, 0.9571, 0.9567,\n",
       "                      0.9571, 0.9432, 0.9650, 0.9797, 0.9342, 1.0027, 0.9488, 0.9369, 0.9480,\n",
       "                      0.9518, 0.9771, 0.9658, 0.9668, 0.9684, 0.9243, 0.9419, 0.9844, 0.8916,\n",
       "                      0.9172], dtype=torch.float64)),\n",
       "             ('4.1.convs.1.1.bias',\n",
       "              tensor([-0.0073, -0.0070, -0.0278,  0.0008, -0.0097,  0.0170, -0.0109,  0.0123,\n",
       "                      -0.0126, -0.0060, -0.0172, -0.0096, -0.0213, -0.0343, -0.0014,  0.0089,\n",
       "                       0.0007, -0.0041, -0.0048,  0.0138,  0.0153,  0.0054, -0.0250, -0.0197,\n",
       "                      -0.0096, -0.0196,  0.0044, -0.0012, -0.0117, -0.0144,  0.0074, -0.0262,\n",
       "                      -0.0111, -0.0248, -0.0015, -0.0020, -0.0128, -0.0037,  0.0050,  0.0049,\n",
       "                       0.0015,  0.0074,  0.0022,  0.0125,  0.0079,  0.0017,  0.0052, -0.0037,\n",
       "                      -0.0035,  0.0158,  0.0056,  0.0064,  0.0012,  0.0051, -0.0112, -0.0139,\n",
       "                      -0.0012,  0.0117, -0.0006,  0.0025, -0.0060, -0.0092, -0.0178,  0.0092],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convs.1.1.running_mean',\n",
       "              tensor([-0.4144, -0.0969, -0.2604,  0.6627, -0.4412, -0.3457, -0.3562, -0.1713,\n",
       "                      -0.3696,  0.2287,  0.2960,  0.1665,  0.0549,  0.7175, -0.5444, -0.2100,\n",
       "                      -0.8041, -0.9723, -0.4251,  0.3375, -0.6228,  0.0723, -0.8489,  0.6034,\n",
       "                       0.1758, -0.2398,  0.3163, -0.1429,  0.0185, -0.2844, -0.3338, -0.2647,\n",
       "                       0.2359,  0.2420,  0.2628, -0.3525,  0.0096,  0.1174, -0.0557, -0.1183,\n",
       "                      -0.2441, -0.0316,  0.1764,  0.1838, -0.4818, -0.0021,  0.8256,  0.5074,\n",
       "                       0.5265, -0.6382, -0.7652,  0.4271, -0.5875, -0.3518,  0.1724, -0.7473,\n",
       "                      -0.6198,  0.3020, -0.0731, -0.5738,  0.4999, -0.1328, -0.5350, -0.6916],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convs.1.1.running_var',\n",
       "              tensor([0.3185, 0.4230, 0.5717, 0.5099, 0.2601, 0.5353, 0.3830, 0.4783, 0.5046,\n",
       "                      0.2716, 1.0798, 0.5491, 0.7090, 0.2874, 0.4343, 0.5546, 0.5345, 0.5770,\n",
       "                      0.6887, 0.3739, 0.3833, 0.4747, 0.5928, 0.7330, 0.4063, 0.3886, 0.2998,\n",
       "                      0.2844, 0.3775, 0.4275, 0.3011, 0.6431, 0.3677, 0.6160, 0.2934, 0.4187,\n",
       "                      0.4495, 0.2772, 0.5281, 0.2542, 0.5348, 0.5972, 0.3615, 0.4208, 0.4818,\n",
       "                      0.4018, 0.3732, 0.2916, 0.3024, 0.7130, 0.2937, 0.3946, 0.8043, 0.5452,\n",
       "                      0.4567, 0.3653, 0.8188, 0.4828, 0.3308, 0.4138, 0.4028, 0.4984, 0.5932,\n",
       "                      1.0395], dtype=torch.float64)),\n",
       "             ('4.1.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.1.convs.2.0.weight',\n",
       "              tensor([[[-4.6101e-02],\n",
       "                       [-5.3052e-03],\n",
       "                       [ 2.2144e-02],\n",
       "                       ...,\n",
       "                       [-1.2974e-01],\n",
       "                       [-1.2044e-01],\n",
       "                       [-2.9767e-02]],\n",
       "              \n",
       "                      [[ 2.1674e-01],\n",
       "                       [-4.0478e-01],\n",
       "                       [ 1.4100e-01],\n",
       "                       ...,\n",
       "                       [ 3.0292e-03],\n",
       "                       [ 2.1738e-01],\n",
       "                       [-6.2854e-02]],\n",
       "              \n",
       "                      [[-1.6119e-01],\n",
       "                       [ 8.5974e-02],\n",
       "                       [-1.6059e-01],\n",
       "                       ...,\n",
       "                       [-2.0828e-01],\n",
       "                       [ 4.9563e-02],\n",
       "                       [-8.8770e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-5.1268e-02],\n",
       "                       [-2.0679e-01],\n",
       "                       [ 3.2676e-02],\n",
       "                       ...,\n",
       "                       [-1.2844e-01],\n",
       "                       [-1.3067e-01],\n",
       "                       [-1.4355e-02]],\n",
       "              \n",
       "                      [[-3.2553e-04],\n",
       "                       [-3.2533e-02],\n",
       "                       [ 1.0006e-01],\n",
       "                       ...,\n",
       "                       [-4.8617e-02],\n",
       "                       [-6.5942e-02],\n",
       "                       [-2.6040e-03]],\n",
       "              \n",
       "                      [[ 5.1859e-02],\n",
       "                       [-3.9522e-02],\n",
       "                       [ 8.0912e-02],\n",
       "                       ...,\n",
       "                       [ 2.6967e-02],\n",
       "                       [ 8.0440e-02],\n",
       "                       [-1.1511e-01]]], dtype=torch.float64)),\n",
       "             ('4.1.convs.2.1.weight',\n",
       "              tensor([ 0.0006,  0.0271, -0.0200, -0.0254, -0.0033, -0.0276,  0.0165,  0.0017,\n",
       "                       0.0101, -0.0015,  0.0021,  0.0058,  0.0119,  0.0204, -0.0248,  0.0129,\n",
       "                      -0.0541, -0.0105, -0.0469,  0.0050,  0.0326, -0.0141,  0.0140, -0.0137,\n",
       "                      -0.0193, -0.0108, -0.0451,  0.0168,  0.0093,  0.0074, -0.0149, -0.0254,\n",
       "                       0.0060,  0.0114, -0.0335,  0.0128,  0.0080, -0.0051, -0.0257,  0.0371,\n",
       "                      -0.0246,  0.0222,  0.0195,  0.0298, -0.0050,  0.0167, -0.0054, -0.0100,\n",
       "                      -0.0150,  0.0072,  0.0343,  0.0346,  0.0090, -0.0035, -0.0135,  0.0360,\n",
       "                      -0.0065, -0.0309, -0.0179, -0.0117,  0.0054, -0.0186,  0.0038,  0.0211,\n",
       "                       0.0168,  0.0161,  0.0170,  0.0025,  0.0218, -0.0335, -0.0044,  0.0165,\n",
       "                      -0.0094,  0.0042, -0.0262, -0.0108,  0.0038,  0.0051, -0.0034,  0.0154,\n",
       "                       0.0071, -0.0122, -0.0183, -0.0050, -0.0238, -0.0072,  0.0079,  0.0212,\n",
       "                       0.0256, -0.0089, -0.0284, -0.0222, -0.0225, -0.0013, -0.0070,  0.0070,\n",
       "                      -0.0094, -0.0109, -0.0093,  0.0107,  0.0099, -0.0176,  0.0003, -0.0029,\n",
       "                      -0.0096, -0.0106,  0.0208, -0.0257,  0.0153, -0.0080, -0.0014, -0.0194,\n",
       "                      -0.0212, -0.0341,  0.0222,  0.0070,  0.0055,  0.0296, -0.0081,  0.0211,\n",
       "                       0.0075,  0.0095,  0.0112, -0.0168, -0.0261,  0.0006,  0.0039,  0.0180,\n",
       "                      -0.0177,  0.0205, -0.0125,  0.0246,  0.0276,  0.0079, -0.0209,  0.0091,\n",
       "                      -0.0278,  0.0272,  0.0085,  0.0115, -0.0051,  0.0166,  0.0098, -0.0059,\n",
       "                      -0.0003, -0.0331, -0.0156, -0.0251, -0.0506,  0.0261, -0.0101,  0.0186,\n",
       "                      -0.0037,  0.0149, -0.0222,  0.0091,  0.0101,  0.0190,  0.0082, -0.0151,\n",
       "                      -0.0077, -0.0064,  0.0231, -0.0130,  0.0003, -0.0157,  0.0394,  0.0025,\n",
       "                       0.0040,  0.0407, -0.0074,  0.0196,  0.0116, -0.0345,  0.0138,  0.0100,\n",
       "                      -0.0194,  0.0156,  0.0133, -0.0207, -0.0074,  0.0118,  0.0020, -0.0131,\n",
       "                      -0.0019, -0.0114,  0.0152, -0.0223,  0.0052,  0.0059, -0.0197, -0.0096,\n",
       "                      -0.0113,  0.0507, -0.0087, -0.0268, -0.0180,  0.0057,  0.0189,  0.0065,\n",
       "                      -0.0043,  0.0205, -0.0168,  0.0124, -0.0123,  0.0100, -0.0320, -0.0099,\n",
       "                      -0.0192,  0.0151, -0.0015,  0.0021,  0.0137,  0.0242,  0.0196, -0.0222,\n",
       "                       0.0351,  0.0164, -0.0001,  0.0211,  0.0146, -0.0162,  0.0165,  0.0317,\n",
       "                       0.0059, -0.0133, -0.0386,  0.0305, -0.0122,  0.0106, -0.0385,  0.0091,\n",
       "                       0.0436,  0.0197,  0.0116, -0.0163,  0.0381, -0.0307, -0.0185,  0.0230,\n",
       "                      -0.0032,  0.0292, -0.0257,  0.0247,  0.0152, -0.0286, -0.0087, -0.0035,\n",
       "                      -0.0226,  0.0317,  0.0044, -0.0018,  0.0225, -0.0161,  0.0136, -0.0145],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convs.2.1.bias',\n",
       "              tensor([ 2.6622e-03,  1.3710e-03,  2.4668e-02,  2.1352e-04,  1.2285e-02,\n",
       "                      -1.6046e-02, -2.8361e-03,  1.3131e-03, -1.3091e-02, -1.0554e-02,\n",
       "                      -4.0515e-03, -5.2755e-03,  1.1840e-02, -1.3139e-02,  6.1576e-03,\n",
       "                       5.8622e-03,  3.4388e-02,  7.8671e-03,  3.4197e-02, -8.2476e-04,\n",
       "                       4.6450e-03,  6.5258e-03, -3.3595e-03, -3.3237e-07, -5.9572e-04,\n",
       "                      -2.2839e-02,  4.4814e-03,  2.7716e-03,  1.3475e-02,  4.0131e-03,\n",
       "                      -1.0429e-02,  1.7458e-02, -1.0648e-02,  2.1937e-02, -1.3994e-03,\n",
       "                      -2.9416e-03, -8.8909e-03,  4.0522e-03, -1.3585e-02, -1.3022e-02,\n",
       "                       3.7569e-03, -6.2779e-03,  1.8634e-03,  1.0811e-02,  4.5246e-03,\n",
       "                      -4.9369e-03, -1.2318e-02,  1.0012e-02, -9.1124e-03,  3.8464e-03,\n",
       "                       2.4045e-03,  2.5560e-02,  5.3867e-03,  4.8155e-03, -7.4186e-03,\n",
       "                       1.6208e-03,  5.6727e-03,  5.4424e-03, -1.7271e-02,  1.0205e-02,\n",
       "                      -5.8928e-03, -4.8369e-03, -2.2371e-02, -5.6922e-03,  1.3169e-03,\n",
       "                       9.9308e-03, -5.0984e-03,  2.3032e-02,  1.4855e-02, -1.6959e-02,\n",
       "                       1.1071e-02,  1.6993e-02, -1.2485e-02, -5.9807e-03,  2.2355e-03,\n",
       "                       2.0908e-02, -1.8641e-02, -1.7686e-02, -6.0985e-03, -7.5990e-03,\n",
       "                      -1.6724e-03, -1.5206e-04,  1.2970e-02,  6.5865e-03,  3.9908e-03,\n",
       "                      -2.1679e-02,  1.6723e-02, -1.2491e-03,  1.2273e-03, -4.7248e-04,\n",
       "                       2.9627e-03,  3.4472e-03,  6.1985e-03,  7.4438e-03,  4.6386e-03,\n",
       "                      -1.4171e-02,  6.9944e-03,  1.1244e-02,  1.6502e-02, -8.8793e-03,\n",
       "                       1.9815e-02,  6.2835e-04, -9.8524e-03, -1.1727e-02, -4.8677e-03,\n",
       "                       3.7418e-03, -1.8245e-02,  1.6108e-03,  1.7072e-02, -8.6741e-03,\n",
       "                      -1.0533e-02, -4.9054e-03,  1.1514e-02, -3.2844e-03, -4.4382e-03,\n",
       "                       1.2024e-02,  8.1511e-03,  1.7058e-02,  8.1910e-03, -7.0219e-03,\n",
       "                      -2.2659e-03, -1.5418e-02,  3.3106e-03, -3.1095e-03, -8.8057e-03,\n",
       "                       1.4026e-02,  5.6511e-03,  2.5897e-03,  1.5465e-02, -2.8600e-03,\n",
       "                      -9.9740e-03,  1.8713e-02, -1.3717e-03,  1.7899e-03, -8.5386e-03,\n",
       "                      -1.8533e-02,  2.3566e-04,  7.0790e-03, -3.3251e-03, -4.8542e-03,\n",
       "                       8.5347e-04,  1.1521e-02, -1.3889e-02, -1.6653e-04, -1.7692e-02,\n",
       "                      -3.8953e-04, -1.4073e-02,  1.5426e-05,  1.5815e-02,  1.7953e-02,\n",
       "                       9.4390e-04, -1.3990e-02, -2.8451e-02, -7.1768e-03,  4.4861e-03,\n",
       "                      -7.4486e-04,  1.2753e-02,  1.7786e-02, -1.6242e-02, -1.9292e-02,\n",
       "                       9.8000e-04,  1.2750e-02, -9.6246e-03,  1.5630e-02,  1.7052e-02,\n",
       "                       9.3223e-03, -7.8075e-03,  1.7067e-02,  3.8369e-03,  3.4596e-02,\n",
       "                       1.8414e-02, -1.9018e-03, -8.3720e-03,  2.3369e-02, -1.7262e-02,\n",
       "                      -4.6177e-03,  8.1083e-03,  2.5694e-02,  1.4343e-02,  1.1967e-03,\n",
       "                      -2.8156e-03,  8.1310e-03, -1.0312e-02,  2.2742e-03,  6.6953e-04,\n",
       "                       4.3218e-03,  4.9382e-03,  3.7847e-02, -1.1845e-03,  7.0539e-03,\n",
       "                      -8.0776e-03, -1.6016e-02, -4.6316e-03, -1.7701e-02, -1.0092e-02,\n",
       "                       1.8452e-02, -5.2258e-03,  1.6192e-02,  1.6435e-02, -1.4427e-02,\n",
       "                       1.7092e-02, -9.1854e-04,  4.4118e-03,  1.9168e-02,  1.2037e-02,\n",
       "                      -8.4665e-03,  8.8794e-03, -1.8915e-02, -5.9494e-03,  4.6580e-03,\n",
       "                       4.4639e-03, -5.5465e-03,  2.1049e-02,  1.9274e-03,  8.1752e-04,\n",
       "                       1.9156e-02,  6.1877e-03,  1.9708e-02,  1.2506e-02,  1.4080e-02,\n",
       "                       4.7879e-04, -6.0023e-03,  7.8806e-05,  5.1932e-03, -4.1084e-03,\n",
       "                       2.2269e-02,  1.4264e-02,  1.0377e-02, -2.2722e-02, -6.4449e-03,\n",
       "                       9.4013e-03,  7.8985e-03,  2.4517e-02,  4.3109e-03, -2.3704e-03,\n",
       "                       9.3053e-03,  1.4397e-02,  7.6741e-03, -7.4824e-03,  4.7430e-03,\n",
       "                      -6.8899e-03,  2.2124e-02,  1.1419e-02,  1.3012e-02,  2.4200e-02,\n",
       "                       2.0350e-02, -4.9785e-03,  1.4649e-02, -9.2872e-03, -1.4771e-02,\n",
       "                       1.9041e-02, -4.2001e-03, -9.0386e-03, -1.4952e-02,  1.5660e-02,\n",
       "                       2.1507e-03], dtype=torch.float64)),\n",
       "             ('4.1.convs.2.1.running_mean',\n",
       "              tensor([-0.3490, -0.3257,  0.1607,  0.0581,  0.0183, -0.3974,  0.0450, -0.0819,\n",
       "                      -0.1347,  0.2878, -0.1497, -0.1594, -0.0296, -0.3385, -0.4748, -0.4994,\n",
       "                      -0.0017,  0.3245,  0.3709,  0.5779,  0.8045, -0.1701,  0.0842, -0.2556,\n",
       "                       1.0248,  0.0246, -0.2827, -0.0964, -0.0681, -0.0657,  0.6462, -0.2160,\n",
       "                      -0.0357, -0.1618, -0.3211, -0.1958,  0.1180, -0.2173,  0.2530, -0.0081,\n",
       "                       0.2209,  0.5518,  0.1535, -0.2112, -0.0401,  0.5834,  0.0017, -0.1488,\n",
       "                       0.3180, -0.2249,  0.1441,  0.3128,  0.0839,  0.2255, -0.1630,  0.0707,\n",
       "                       0.3934,  0.1604,  0.3193,  0.4236,  0.2387, -0.3074, -0.1036,  0.2854,\n",
       "                      -0.1448,  0.2153, -0.4644, -0.0358, -0.4999, -0.2163,  0.1790, -0.1049,\n",
       "                       0.0172,  0.3230, -0.6403, -0.1055, -0.0132,  0.2365, -0.1993,  0.0380,\n",
       "                       0.0862, -0.0120,  0.8576, -0.0290,  0.0673, -0.1129,  0.4312,  0.0790,\n",
       "                       0.1341, -0.1908,  0.3605, -0.2894,  0.2530, -0.3455, -0.0736,  0.1299,\n",
       "                       0.2970, -0.0806, -0.1541, -0.2946, -0.0128,  0.2614, -0.1959, -0.2899,\n",
       "                       0.0984, -0.0954,  0.3801,  0.0031, -0.0116, -0.1876,  0.0905, -0.4068,\n",
       "                      -0.0514, -0.0556,  0.2250, -0.0541, -0.1580,  0.2824,  0.0340, -0.6819,\n",
       "                       0.4667, -0.0944, -0.4318, -0.3325,  0.1531, -0.0955, -0.0187,  0.1850,\n",
       "                       0.0992, -0.2054,  0.1328,  0.0035,  0.4837,  0.2113, -0.2163,  0.1285,\n",
       "                      -0.0864,  0.4211,  0.0791,  0.2858,  0.2118,  0.0513, -0.2165, -0.4369,\n",
       "                      -0.0095,  0.0968,  0.1615, -0.0668, -0.6665, -0.2577, -0.3888, -0.0493,\n",
       "                      -0.1449,  0.2557,  0.3586, -0.1919, -0.2868,  0.0563, -0.2434, -0.3951,\n",
       "                      -0.0237, -0.2338, -0.0835,  0.0911, -0.1855,  0.3321, -0.2775, -0.1253,\n",
       "                      -0.0681,  0.0652, -0.0289, -0.3501,  0.1558,  0.0053, -0.1093,  0.4458,\n",
       "                       0.0015, -0.0630,  0.1160,  0.2421,  0.3361, -0.3478,  0.1220,  0.1046,\n",
       "                      -0.2545, -0.1493, -0.1746,  0.0453,  0.4640,  0.0444,  0.1427, -0.1335,\n",
       "                      -0.0325, -0.0034, -0.3202, -0.1394, -0.0436, -0.1440, -0.2595, -0.1957,\n",
       "                      -0.1482, -0.2321,  0.3111,  0.0433, -0.5786,  0.4695, -0.2927,  0.2200,\n",
       "                      -0.1819,  0.0233, -0.0233,  0.2821,  0.0142,  0.0471,  0.3861,  0.0291,\n",
       "                      -0.3994,  0.3153,  0.0221,  0.0089,  0.2622, -0.1963,  0.2192, -0.0561,\n",
       "                      -0.1063, -0.0018, -0.5074,  0.1205, -0.7941,  0.1876, -0.1873,  0.1491,\n",
       "                       0.6923, -0.0754, -0.3212, -0.8104,  0.1325, -0.0508, -0.5542, -0.2772,\n",
       "                       0.1670,  0.2688, -0.0473,  0.5546,  0.3505,  0.2948,  0.4180,  0.0453,\n",
       "                      -0.2492,  0.2728,  0.1289, -0.1012, -0.1065,  0.5638, -0.3831, -0.2564],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convs.2.1.running_var',\n",
       "              tensor([0.1247, 0.4673, 0.3052, 0.5637, 0.2827, 0.2225, 0.1415, 0.2438, 0.0741,\n",
       "                      0.0966, 0.1076, 0.2908, 0.0768, 0.4434, 0.3968, 0.4592, 0.2444, 0.4463,\n",
       "                      0.2491, 0.2412, 0.2970, 0.2626, 0.3414, 0.2586, 0.3553, 0.1332, 0.3183,\n",
       "                      0.2798, 0.1681, 0.1046, 0.5512, 0.5218, 0.1067, 0.2158, 0.3256, 0.2574,\n",
       "                      0.0836, 0.2849, 0.2553, 0.3248, 0.2735, 0.4395, 0.1424, 0.4309, 0.1653,\n",
       "                      0.2065, 0.0700, 0.2078, 0.4427, 0.1434, 0.3384, 0.2325, 0.4502, 0.1405,\n",
       "                      0.2815, 0.2169, 0.1982, 0.5412, 0.3812, 0.3282, 0.1567, 0.2946, 0.1145,\n",
       "                      0.1886, 0.4259, 0.4017, 0.4724, 0.1040, 0.3960, 0.4610, 0.2352, 0.2451,\n",
       "                      0.1439, 0.6628, 0.7427, 0.1250, 0.1228, 0.1202, 0.2887, 0.0469, 0.3723,\n",
       "                      0.1196, 0.4409, 0.1489, 0.3526, 0.3294, 0.2418, 0.2398, 0.1891, 0.2547,\n",
       "                      0.5151, 0.3699, 0.3376, 0.1772, 0.1726, 0.0871, 0.4601, 0.1384, 0.1047,\n",
       "                      0.1725, 0.3251, 0.3303, 0.2092, 0.1071, 0.2188, 0.2091, 0.4870, 0.3131,\n",
       "                      0.0564, 0.0977, 0.1272, 0.2620, 0.2930, 0.7058, 0.3363, 0.2974, 0.0500,\n",
       "                      0.5259, 0.1642, 0.3415, 0.2050, 0.2879, 0.3843, 0.5279, 0.3956, 0.2741,\n",
       "                      0.1284, 0.1579, 0.1492, 0.5154, 0.0988, 0.2472, 0.4197, 0.2898, 0.2311,\n",
       "                      0.0403, 0.2334, 0.5278, 0.2275, 0.2735, 0.0617, 0.2492, 0.1211, 0.2848,\n",
       "                      0.1390, 0.8003, 0.2216, 0.5505, 0.3214, 0.2679, 0.5748, 0.1755, 0.2163,\n",
       "                      0.1810, 0.3624, 0.3279, 0.1624, 0.3362, 0.3394, 0.3697, 0.0819, 0.0816,\n",
       "                      0.3182, 0.2392, 0.1825, 0.2556, 0.3022, 0.1684, 0.2362, 0.3641, 0.2427,\n",
       "                      0.2435, 0.1387, 0.2504, 0.4459, 0.2891, 0.2800, 0.2901, 0.3036, 0.2811,\n",
       "                      0.1877, 0.3167, 0.1579, 0.2403, 0.1752, 0.2500, 0.4507, 0.2978, 0.2547,\n",
       "                      0.1796, 0.1171, 0.1139, 0.3048, 0.4933, 0.2250, 0.1359, 0.2289, 0.2110,\n",
       "                      0.3020, 0.2026, 0.0692, 0.4942, 0.2327, 0.1886, 0.4562, 0.4333, 0.3647,\n",
       "                      0.3414, 0.5122, 0.4788, 0.0232, 0.1302, 0.2369, 0.3238, 0.1562, 0.2620,\n",
       "                      0.2632, 0.1647, 0.0481, 0.4497, 0.2626, 0.1364, 0.1314, 0.3705, 0.3710,\n",
       "                      0.2258, 0.3244, 0.4746, 0.4787, 0.4340, 0.4045, 0.2990, 0.4532, 0.3032,\n",
       "                      0.2005, 0.3822, 0.4358, 0.2043, 0.3229, 0.2760, 0.2897, 0.1976, 0.4628,\n",
       "                      0.2424, 0.2310, 0.4662, 0.1528, 0.0978, 0.2962, 0.4412, 0.1777, 0.1448,\n",
       "                      0.3359, 0.2935, 0.1682, 0.1672], dtype=torch.float64)),\n",
       "             ('4.1.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.1.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.0433],\n",
       "                       [ 0.0729],\n",
       "                       [ 0.0497],\n",
       "                       ...,\n",
       "                       [ 0.0378],\n",
       "                       [-0.0217],\n",
       "                       [ 0.0320]],\n",
       "              \n",
       "                      [[-0.0893],\n",
       "                       [ 0.0643],\n",
       "                       [ 0.1649],\n",
       "                       ...,\n",
       "                       [ 0.1981],\n",
       "                       [ 0.0114],\n",
       "                       [ 0.1326]],\n",
       "              \n",
       "                      [[-0.0556],\n",
       "                       [ 0.0464],\n",
       "                       [ 0.2254],\n",
       "                       ...,\n",
       "                       [ 0.0318],\n",
       "                       [-0.0813],\n",
       "                       [-0.1020]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0480],\n",
       "                       [ 0.0273],\n",
       "                       [-0.1232],\n",
       "                       ...,\n",
       "                       [-0.1617],\n",
       "                       [ 0.0991],\n",
       "                       [-0.0936]],\n",
       "              \n",
       "                      [[-0.1003],\n",
       "                       [-0.0633],\n",
       "                       [ 0.0894],\n",
       "                       ...,\n",
       "                       [-0.0121],\n",
       "                       [ 0.0503],\n",
       "                       [ 0.0952]],\n",
       "              \n",
       "                      [[-0.1189],\n",
       "                       [-0.0043],\n",
       "                       [ 0.0023],\n",
       "                       ...,\n",
       "                       [-0.1041],\n",
       "                       [ 0.0674],\n",
       "                       [ 0.1825]]], dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.0.1.weight',\n",
       "              tensor([1.0034, 0.9469, 0.9723, 0.9739, 0.9762, 0.9611, 0.9750, 0.9575, 0.9692,\n",
       "                      0.9740, 0.9631, 0.9902, 0.9811, 0.9544, 0.9580, 0.9519, 0.9656, 0.9779,\n",
       "                      0.9203, 0.9478, 0.9605, 0.9497, 0.9386, 0.9533, 0.9459, 0.9430, 0.9711,\n",
       "                      0.9746, 0.9570, 0.9580, 0.9550, 0.9575, 0.9650, 0.9662, 0.9379, 0.9584,\n",
       "                      0.9631, 0.9687, 0.9597, 0.9515, 0.9964, 0.9618, 0.9581, 0.9556, 0.9415,\n",
       "                      0.9436, 0.9656, 0.9670, 0.9596, 0.9680, 0.9446, 0.9494, 0.9810, 0.9658,\n",
       "                      0.9638, 0.9320, 0.9919, 0.9957, 0.9370, 0.9610, 0.9799, 0.9369, 0.9505,\n",
       "                      0.9705], dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0153,  0.0166,  0.0137,  0.0150,  0.0211,  0.0052, -0.0100,  0.0065,\n",
       "                       0.0003,  0.0118,  0.0110,  0.0178,  0.0011,  0.0065, -0.0053, -0.0034,\n",
       "                       0.0049,  0.0020, -0.0118, -0.0284,  0.0010, -0.0209, -0.0121,  0.0017,\n",
       "                       0.0087,  0.0001,  0.0002, -0.0105,  0.0083, -0.0025, -0.0029, -0.0111,\n",
       "                      -0.0021, -0.0002,  0.0023,  0.0011, -0.0021,  0.0015,  0.0120,  0.0040,\n",
       "                       0.0162,  0.0051, -0.0001, -0.0158, -0.0049, -0.0089,  0.0185,  0.0267,\n",
       "                       0.0002, -0.0048, -0.0005, -0.0045,  0.0029,  0.0089,  0.0153, -0.0133,\n",
       "                       0.0173,  0.0082,  0.0004,  0.0038,  0.0062,  0.0119, -0.0027,  0.0164],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.0.1.running_mean',\n",
       "              tensor([-3.6673e-01, -3.1839e-01, -2.2712e-01, -7.3303e-01, -2.6468e-01,\n",
       "                      -3.4504e-01, -5.3686e-01,  4.4931e-01, -1.8099e-01,  4.5594e-01,\n",
       "                      -2.2706e-01, -2.2970e-02,  4.1870e-01,  6.3956e-04, -7.1862e-01,\n",
       "                      -6.0666e-01,  3.2083e-01, -3.1131e-01, -8.1477e-01, -2.6258e-02,\n",
       "                      -3.8624e-02,  9.0266e-03, -1.5698e-01, -3.4816e-03, -3.6534e-01,\n",
       "                      -2.3503e-02, -6.4681e-01,  2.2677e-01, -3.5768e-01, -6.4312e-01,\n",
       "                       6.6613e-02,  8.2632e-01,  4.3019e-01, -9.0011e-03, -6.3850e-01,\n",
       "                      -6.4609e-01,  4.2953e-01, -8.5458e-01, -1.0722e+00, -2.4228e-01,\n",
       "                      -1.4652e-01, -3.8099e-01, -1.7137e-01,  1.8403e-01, -2.6536e-01,\n",
       "                       9.4302e-01, -1.0785e+00, -3.8379e-01,  2.7501e-01, -6.5112e-01,\n",
       "                      -1.0300e+00,  3.8694e-01, -4.9725e-01, -2.3615e-02, -9.3182e-02,\n",
       "                      -3.1703e-01, -8.7847e-01, -2.0344e-01, -1.5094e-01,  6.0241e-01,\n",
       "                      -1.4606e-02, -2.9230e-01, -2.4752e-01,  5.5926e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.0.1.running_var',\n",
       "              tensor([0.8764, 1.0767, 0.4243, 0.4149, 0.5302, 0.5180, 0.5863, 2.0796, 0.6191,\n",
       "                      1.3904, 0.3872, 0.3380, 0.3595, 0.4874, 0.3935, 0.6230, 0.3508, 0.4836,\n",
       "                      0.6899, 0.7547, 0.4267, 0.7277, 0.6650, 0.4500, 0.4653, 0.4458, 0.6363,\n",
       "                      0.4481, 0.3858, 0.5953, 0.4685, 1.1678, 1.1814, 0.7938, 1.5083, 0.6731,\n",
       "                      0.5344, 0.4784, 2.1425, 0.4739, 0.5008, 0.5000, 0.9115, 0.7567, 0.4575,\n",
       "                      1.5659, 0.8526, 0.6364, 0.3154, 1.6061, 0.4650, 0.7609, 0.4101, 0.7246,\n",
       "                      0.4935, 0.8381, 0.3731, 0.4475, 0.9651, 0.5591, 0.3131, 0.7044, 0.7307,\n",
       "                      0.4144], dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.1.convpath.0.1.0.weight',\n",
       "              tensor([[[ 0.0421, -0.0811,  0.0330,  0.0056,  0.1588],\n",
       "                       [ 0.0385, -0.0733, -0.0175,  0.0611,  0.0599],\n",
       "                       [ 0.0694, -0.0409, -0.0874,  0.0063,  0.0964],\n",
       "                       ...,\n",
       "                       [ 0.1517, -0.0267,  0.0746,  0.1003,  0.0089],\n",
       "                       [ 0.1306, -0.0173,  0.1154, -0.0595,  0.0261],\n",
       "                       [-0.0747,  0.0046,  0.0660, -0.0371, -0.0347]],\n",
       "              \n",
       "                      [[-0.0505, -0.0011, -0.0235, -0.0683,  0.0868],\n",
       "                       [-0.0585,  0.0829,  0.0368,  0.0263, -0.0380],\n",
       "                       [ 0.0188,  0.0786,  0.0824,  0.0868,  0.0356],\n",
       "                       ...,\n",
       "                       [-0.0216,  0.1189,  0.1133, -0.0908, -0.0240],\n",
       "                       [-0.0623, -0.0122, -0.0879,  0.0989,  0.0467],\n",
       "                       [ 0.0985,  0.1105,  0.0686, -0.0625, -0.0092]],\n",
       "              \n",
       "                      [[-0.0649,  0.0434, -0.1118, -0.0303,  0.0119],\n",
       "                       [-0.0747, -0.1580, -0.0966, -0.0388,  0.0641],\n",
       "                       [-0.0063,  0.0922, -0.0461,  0.0850,  0.0342],\n",
       "                       ...,\n",
       "                       [ 0.1181, -0.0842,  0.0485, -0.0386, -0.0531],\n",
       "                       [-0.0632,  0.0632, -0.0538,  0.0249,  0.1037],\n",
       "                       [ 0.0170,  0.0047, -0.0239,  0.0354, -0.0418]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0713,  0.0364,  0.0408, -0.0946, -0.1306],\n",
       "                       [ 0.0318, -0.0729, -0.0014,  0.0644, -0.0119],\n",
       "                       [-0.1309,  0.0735,  0.0060,  0.0275,  0.0364],\n",
       "                       ...,\n",
       "                       [ 0.0505,  0.0300, -0.0917,  0.0684,  0.0617],\n",
       "                       [ 0.0152,  0.0705, -0.1785,  0.0208,  0.0345],\n",
       "                       [-0.1008, -0.0939, -0.0388,  0.1387, -0.0035]],\n",
       "              \n",
       "                      [[-0.0174, -0.0621,  0.1055, -0.0486,  0.0797],\n",
       "                       [-0.0954,  0.0507,  0.0932, -0.0349,  0.0466],\n",
       "                       [ 0.0296, -0.0120,  0.0615,  0.0684, -0.0833],\n",
       "                       ...,\n",
       "                       [-0.0368, -0.0442, -0.1363, -0.0535,  0.0274],\n",
       "                       [ 0.0130, -0.0371,  0.0120, -0.0719, -0.0100],\n",
       "                       [-0.0099, -0.0539, -0.0553,  0.0409, -0.0248]],\n",
       "              \n",
       "                      [[ 0.0012, -0.0103,  0.0057, -0.0038, -0.0738],\n",
       "                       [ 0.0569, -0.0173,  0.1431,  0.0587,  0.1055],\n",
       "                       [ 0.0721, -0.0504, -0.0647, -0.0414,  0.1351],\n",
       "                       ...,\n",
       "                       [ 0.1394,  0.0234, -0.1823, -0.0278,  0.0474],\n",
       "                       [ 0.0502, -0.0492,  0.0562, -0.1517,  0.1205],\n",
       "                       [-0.0972, -0.1027, -0.0387, -0.0323,  0.1212]]], dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.1.1.weight',\n",
       "              tensor([0.9519, 0.9701, 0.9212, 0.9582, 0.9861, 0.9419, 0.9595, 0.9429, 0.9335,\n",
       "                      0.9492, 0.9308, 0.9413, 0.9345, 0.9444, 0.9859, 0.9597, 0.9664, 0.9208,\n",
       "                      0.9404, 0.9575, 0.9676, 0.9332, 0.9134, 0.9310, 0.9467, 0.9325, 0.9623,\n",
       "                      0.9687, 0.9535, 0.9334, 0.9790, 0.9017, 0.9368, 0.9397, 0.9794, 0.9608,\n",
       "                      0.9274, 0.9874, 0.9475, 0.9825, 0.9398, 0.9624, 0.9865, 0.9571, 0.9567,\n",
       "                      0.9571, 0.9432, 0.9650, 0.9797, 0.9342, 1.0027, 0.9488, 0.9369, 0.9480,\n",
       "                      0.9518, 0.9771, 0.9658, 0.9668, 0.9684, 0.9243, 0.9419, 0.9844, 0.8916,\n",
       "                      0.9172], dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.1.1.bias',\n",
       "              tensor([-0.0073, -0.0070, -0.0278,  0.0008, -0.0097,  0.0170, -0.0109,  0.0123,\n",
       "                      -0.0126, -0.0060, -0.0172, -0.0096, -0.0213, -0.0343, -0.0014,  0.0089,\n",
       "                       0.0007, -0.0041, -0.0048,  0.0138,  0.0153,  0.0054, -0.0250, -0.0197,\n",
       "                      -0.0096, -0.0196,  0.0044, -0.0012, -0.0117, -0.0144,  0.0074, -0.0262,\n",
       "                      -0.0111, -0.0248, -0.0015, -0.0020, -0.0128, -0.0037,  0.0050,  0.0049,\n",
       "                       0.0015,  0.0074,  0.0022,  0.0125,  0.0079,  0.0017,  0.0052, -0.0037,\n",
       "                      -0.0035,  0.0158,  0.0056,  0.0064,  0.0012,  0.0051, -0.0112, -0.0139,\n",
       "                      -0.0012,  0.0117, -0.0006,  0.0025, -0.0060, -0.0092, -0.0178,  0.0092],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.1.1.running_mean',\n",
       "              tensor([-0.4144, -0.0969, -0.2604,  0.6627, -0.4412, -0.3457, -0.3562, -0.1713,\n",
       "                      -0.3696,  0.2287,  0.2960,  0.1665,  0.0549,  0.7175, -0.5444, -0.2100,\n",
       "                      -0.8041, -0.9723, -0.4251,  0.3375, -0.6228,  0.0723, -0.8489,  0.6034,\n",
       "                       0.1758, -0.2398,  0.3163, -0.1429,  0.0185, -0.2844, -0.3338, -0.2647,\n",
       "                       0.2359,  0.2420,  0.2628, -0.3525,  0.0096,  0.1174, -0.0557, -0.1183,\n",
       "                      -0.2441, -0.0316,  0.1764,  0.1838, -0.4818, -0.0021,  0.8256,  0.5074,\n",
       "                       0.5265, -0.6382, -0.7652,  0.4271, -0.5875, -0.3518,  0.1724, -0.7473,\n",
       "                      -0.6198,  0.3020, -0.0731, -0.5738,  0.4999, -0.1328, -0.5350, -0.6916],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.1.1.running_var',\n",
       "              tensor([0.3185, 0.4230, 0.5717, 0.5099, 0.2601, 0.5353, 0.3830, 0.4783, 0.5046,\n",
       "                      0.2716, 1.0798, 0.5491, 0.7090, 0.2874, 0.4343, 0.5546, 0.5345, 0.5770,\n",
       "                      0.6887, 0.3739, 0.3833, 0.4747, 0.5928, 0.7330, 0.4063, 0.3886, 0.2998,\n",
       "                      0.2844, 0.3775, 0.4275, 0.3011, 0.6431, 0.3677, 0.6160, 0.2934, 0.4187,\n",
       "                      0.4495, 0.2772, 0.5281, 0.2542, 0.5348, 0.5972, 0.3615, 0.4208, 0.4818,\n",
       "                      0.4018, 0.3732, 0.2916, 0.3024, 0.7130, 0.2937, 0.3946, 0.8043, 0.5452,\n",
       "                      0.4567, 0.3653, 0.8188, 0.4828, 0.3308, 0.4138, 0.4028, 0.4984, 0.5932,\n",
       "                      1.0395], dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.1.convpath.0.2.0.weight',\n",
       "              tensor([[[-4.6101e-02],\n",
       "                       [-5.3052e-03],\n",
       "                       [ 2.2144e-02],\n",
       "                       ...,\n",
       "                       [-1.2974e-01],\n",
       "                       [-1.2044e-01],\n",
       "                       [-2.9767e-02]],\n",
       "              \n",
       "                      [[ 2.1674e-01],\n",
       "                       [-4.0478e-01],\n",
       "                       [ 1.4100e-01],\n",
       "                       ...,\n",
       "                       [ 3.0292e-03],\n",
       "                       [ 2.1738e-01],\n",
       "                       [-6.2854e-02]],\n",
       "              \n",
       "                      [[-1.6119e-01],\n",
       "                       [ 8.5974e-02],\n",
       "                       [-1.6059e-01],\n",
       "                       ...,\n",
       "                       [-2.0828e-01],\n",
       "                       [ 4.9563e-02],\n",
       "                       [-8.8770e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-5.1268e-02],\n",
       "                       [-2.0679e-01],\n",
       "                       [ 3.2676e-02],\n",
       "                       ...,\n",
       "                       [-1.2844e-01],\n",
       "                       [-1.3067e-01],\n",
       "                       [-1.4355e-02]],\n",
       "              \n",
       "                      [[-3.2553e-04],\n",
       "                       [-3.2533e-02],\n",
       "                       [ 1.0006e-01],\n",
       "                       ...,\n",
       "                       [-4.8617e-02],\n",
       "                       [-6.5942e-02],\n",
       "                       [-2.6040e-03]],\n",
       "              \n",
       "                      [[ 5.1859e-02],\n",
       "                       [-3.9522e-02],\n",
       "                       [ 8.0912e-02],\n",
       "                       ...,\n",
       "                       [ 2.6967e-02],\n",
       "                       [ 8.0440e-02],\n",
       "                       [-1.1511e-01]]], dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.2.1.weight',\n",
       "              tensor([ 0.0006,  0.0271, -0.0200, -0.0254, -0.0033, -0.0276,  0.0165,  0.0017,\n",
       "                       0.0101, -0.0015,  0.0021,  0.0058,  0.0119,  0.0204, -0.0248,  0.0129,\n",
       "                      -0.0541, -0.0105, -0.0469,  0.0050,  0.0326, -0.0141,  0.0140, -0.0137,\n",
       "                      -0.0193, -0.0108, -0.0451,  0.0168,  0.0093,  0.0074, -0.0149, -0.0254,\n",
       "                       0.0060,  0.0114, -0.0335,  0.0128,  0.0080, -0.0051, -0.0257,  0.0371,\n",
       "                      -0.0246,  0.0222,  0.0195,  0.0298, -0.0050,  0.0167, -0.0054, -0.0100,\n",
       "                      -0.0150,  0.0072,  0.0343,  0.0346,  0.0090, -0.0035, -0.0135,  0.0360,\n",
       "                      -0.0065, -0.0309, -0.0179, -0.0117,  0.0054, -0.0186,  0.0038,  0.0211,\n",
       "                       0.0168,  0.0161,  0.0170,  0.0025,  0.0218, -0.0335, -0.0044,  0.0165,\n",
       "                      -0.0094,  0.0042, -0.0262, -0.0108,  0.0038,  0.0051, -0.0034,  0.0154,\n",
       "                       0.0071, -0.0122, -0.0183, -0.0050, -0.0238, -0.0072,  0.0079,  0.0212,\n",
       "                       0.0256, -0.0089, -0.0284, -0.0222, -0.0225, -0.0013, -0.0070,  0.0070,\n",
       "                      -0.0094, -0.0109, -0.0093,  0.0107,  0.0099, -0.0176,  0.0003, -0.0029,\n",
       "                      -0.0096, -0.0106,  0.0208, -0.0257,  0.0153, -0.0080, -0.0014, -0.0194,\n",
       "                      -0.0212, -0.0341,  0.0222,  0.0070,  0.0055,  0.0296, -0.0081,  0.0211,\n",
       "                       0.0075,  0.0095,  0.0112, -0.0168, -0.0261,  0.0006,  0.0039,  0.0180,\n",
       "                      -0.0177,  0.0205, -0.0125,  0.0246,  0.0276,  0.0079, -0.0209,  0.0091,\n",
       "                      -0.0278,  0.0272,  0.0085,  0.0115, -0.0051,  0.0166,  0.0098, -0.0059,\n",
       "                      -0.0003, -0.0331, -0.0156, -0.0251, -0.0506,  0.0261, -0.0101,  0.0186,\n",
       "                      -0.0037,  0.0149, -0.0222,  0.0091,  0.0101,  0.0190,  0.0082, -0.0151,\n",
       "                      -0.0077, -0.0064,  0.0231, -0.0130,  0.0003, -0.0157,  0.0394,  0.0025,\n",
       "                       0.0040,  0.0407, -0.0074,  0.0196,  0.0116, -0.0345,  0.0138,  0.0100,\n",
       "                      -0.0194,  0.0156,  0.0133, -0.0207, -0.0074,  0.0118,  0.0020, -0.0131,\n",
       "                      -0.0019, -0.0114,  0.0152, -0.0223,  0.0052,  0.0059, -0.0197, -0.0096,\n",
       "                      -0.0113,  0.0507, -0.0087, -0.0268, -0.0180,  0.0057,  0.0189,  0.0065,\n",
       "                      -0.0043,  0.0205, -0.0168,  0.0124, -0.0123,  0.0100, -0.0320, -0.0099,\n",
       "                      -0.0192,  0.0151, -0.0015,  0.0021,  0.0137,  0.0242,  0.0196, -0.0222,\n",
       "                       0.0351,  0.0164, -0.0001,  0.0211,  0.0146, -0.0162,  0.0165,  0.0317,\n",
       "                       0.0059, -0.0133, -0.0386,  0.0305, -0.0122,  0.0106, -0.0385,  0.0091,\n",
       "                       0.0436,  0.0197,  0.0116, -0.0163,  0.0381, -0.0307, -0.0185,  0.0230,\n",
       "                      -0.0032,  0.0292, -0.0257,  0.0247,  0.0152, -0.0286, -0.0087, -0.0035,\n",
       "                      -0.0226,  0.0317,  0.0044, -0.0018,  0.0225, -0.0161,  0.0136, -0.0145],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.2.1.bias',\n",
       "              tensor([ 2.6622e-03,  1.3710e-03,  2.4668e-02,  2.1352e-04,  1.2285e-02,\n",
       "                      -1.6046e-02, -2.8361e-03,  1.3131e-03, -1.3091e-02, -1.0554e-02,\n",
       "                      -4.0515e-03, -5.2755e-03,  1.1840e-02, -1.3139e-02,  6.1576e-03,\n",
       "                       5.8622e-03,  3.4388e-02,  7.8671e-03,  3.4197e-02, -8.2476e-04,\n",
       "                       4.6450e-03,  6.5258e-03, -3.3595e-03, -3.3237e-07, -5.9572e-04,\n",
       "                      -2.2839e-02,  4.4814e-03,  2.7716e-03,  1.3475e-02,  4.0131e-03,\n",
       "                      -1.0429e-02,  1.7458e-02, -1.0648e-02,  2.1937e-02, -1.3994e-03,\n",
       "                      -2.9416e-03, -8.8909e-03,  4.0522e-03, -1.3585e-02, -1.3022e-02,\n",
       "                       3.7569e-03, -6.2779e-03,  1.8634e-03,  1.0811e-02,  4.5246e-03,\n",
       "                      -4.9369e-03, -1.2318e-02,  1.0012e-02, -9.1124e-03,  3.8464e-03,\n",
       "                       2.4045e-03,  2.5560e-02,  5.3867e-03,  4.8155e-03, -7.4186e-03,\n",
       "                       1.6208e-03,  5.6727e-03,  5.4424e-03, -1.7271e-02,  1.0205e-02,\n",
       "                      -5.8928e-03, -4.8369e-03, -2.2371e-02, -5.6922e-03,  1.3169e-03,\n",
       "                       9.9308e-03, -5.0984e-03,  2.3032e-02,  1.4855e-02, -1.6959e-02,\n",
       "                       1.1071e-02,  1.6993e-02, -1.2485e-02, -5.9807e-03,  2.2355e-03,\n",
       "                       2.0908e-02, -1.8641e-02, -1.7686e-02, -6.0985e-03, -7.5990e-03,\n",
       "                      -1.6724e-03, -1.5206e-04,  1.2970e-02,  6.5865e-03,  3.9908e-03,\n",
       "                      -2.1679e-02,  1.6723e-02, -1.2491e-03,  1.2273e-03, -4.7248e-04,\n",
       "                       2.9627e-03,  3.4472e-03,  6.1985e-03,  7.4438e-03,  4.6386e-03,\n",
       "                      -1.4171e-02,  6.9944e-03,  1.1244e-02,  1.6502e-02, -8.8793e-03,\n",
       "                       1.9815e-02,  6.2835e-04, -9.8524e-03, -1.1727e-02, -4.8677e-03,\n",
       "                       3.7418e-03, -1.8245e-02,  1.6108e-03,  1.7072e-02, -8.6741e-03,\n",
       "                      -1.0533e-02, -4.9054e-03,  1.1514e-02, -3.2844e-03, -4.4382e-03,\n",
       "                       1.2024e-02,  8.1511e-03,  1.7058e-02,  8.1910e-03, -7.0219e-03,\n",
       "                      -2.2659e-03, -1.5418e-02,  3.3106e-03, -3.1095e-03, -8.8057e-03,\n",
       "                       1.4026e-02,  5.6511e-03,  2.5897e-03,  1.5465e-02, -2.8600e-03,\n",
       "                      -9.9740e-03,  1.8713e-02, -1.3717e-03,  1.7899e-03, -8.5386e-03,\n",
       "                      -1.8533e-02,  2.3566e-04,  7.0790e-03, -3.3251e-03, -4.8542e-03,\n",
       "                       8.5347e-04,  1.1521e-02, -1.3889e-02, -1.6653e-04, -1.7692e-02,\n",
       "                      -3.8953e-04, -1.4073e-02,  1.5426e-05,  1.5815e-02,  1.7953e-02,\n",
       "                       9.4390e-04, -1.3990e-02, -2.8451e-02, -7.1768e-03,  4.4861e-03,\n",
       "                      -7.4486e-04,  1.2753e-02,  1.7786e-02, -1.6242e-02, -1.9292e-02,\n",
       "                       9.8000e-04,  1.2750e-02, -9.6246e-03,  1.5630e-02,  1.7052e-02,\n",
       "                       9.3223e-03, -7.8075e-03,  1.7067e-02,  3.8369e-03,  3.4596e-02,\n",
       "                       1.8414e-02, -1.9018e-03, -8.3720e-03,  2.3369e-02, -1.7262e-02,\n",
       "                      -4.6177e-03,  8.1083e-03,  2.5694e-02,  1.4343e-02,  1.1967e-03,\n",
       "                      -2.8156e-03,  8.1310e-03, -1.0312e-02,  2.2742e-03,  6.6953e-04,\n",
       "                       4.3218e-03,  4.9382e-03,  3.7847e-02, -1.1845e-03,  7.0539e-03,\n",
       "                      -8.0776e-03, -1.6016e-02, -4.6316e-03, -1.7701e-02, -1.0092e-02,\n",
       "                       1.8452e-02, -5.2258e-03,  1.6192e-02,  1.6435e-02, -1.4427e-02,\n",
       "                       1.7092e-02, -9.1854e-04,  4.4118e-03,  1.9168e-02,  1.2037e-02,\n",
       "                      -8.4665e-03,  8.8794e-03, -1.8915e-02, -5.9494e-03,  4.6580e-03,\n",
       "                       4.4639e-03, -5.5465e-03,  2.1049e-02,  1.9274e-03,  8.1752e-04,\n",
       "                       1.9156e-02,  6.1877e-03,  1.9708e-02,  1.2506e-02,  1.4080e-02,\n",
       "                       4.7879e-04, -6.0023e-03,  7.8806e-05,  5.1932e-03, -4.1084e-03,\n",
       "                       2.2269e-02,  1.4264e-02,  1.0377e-02, -2.2722e-02, -6.4449e-03,\n",
       "                       9.4013e-03,  7.8985e-03,  2.4517e-02,  4.3109e-03, -2.3704e-03,\n",
       "                       9.3053e-03,  1.4397e-02,  7.6741e-03, -7.4824e-03,  4.7430e-03,\n",
       "                      -6.8899e-03,  2.2124e-02,  1.1419e-02,  1.3012e-02,  2.4200e-02,\n",
       "                       2.0350e-02, -4.9785e-03,  1.4649e-02, -9.2872e-03, -1.4771e-02,\n",
       "                       1.9041e-02, -4.2001e-03, -9.0386e-03, -1.4952e-02,  1.5660e-02,\n",
       "                       2.1507e-03], dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.2.1.running_mean',\n",
       "              tensor([-0.3490, -0.3257,  0.1607,  0.0581,  0.0183, -0.3974,  0.0450, -0.0819,\n",
       "                      -0.1347,  0.2878, -0.1497, -0.1594, -0.0296, -0.3385, -0.4748, -0.4994,\n",
       "                      -0.0017,  0.3245,  0.3709,  0.5779,  0.8045, -0.1701,  0.0842, -0.2556,\n",
       "                       1.0248,  0.0246, -0.2827, -0.0964, -0.0681, -0.0657,  0.6462, -0.2160,\n",
       "                      -0.0357, -0.1618, -0.3211, -0.1958,  0.1180, -0.2173,  0.2530, -0.0081,\n",
       "                       0.2209,  0.5518,  0.1535, -0.2112, -0.0401,  0.5834,  0.0017, -0.1488,\n",
       "                       0.3180, -0.2249,  0.1441,  0.3128,  0.0839,  0.2255, -0.1630,  0.0707,\n",
       "                       0.3934,  0.1604,  0.3193,  0.4236,  0.2387, -0.3074, -0.1036,  0.2854,\n",
       "                      -0.1448,  0.2153, -0.4644, -0.0358, -0.4999, -0.2163,  0.1790, -0.1049,\n",
       "                       0.0172,  0.3230, -0.6403, -0.1055, -0.0132,  0.2365, -0.1993,  0.0380,\n",
       "                       0.0862, -0.0120,  0.8576, -0.0290,  0.0673, -0.1129,  0.4312,  0.0790,\n",
       "                       0.1341, -0.1908,  0.3605, -0.2894,  0.2530, -0.3455, -0.0736,  0.1299,\n",
       "                       0.2970, -0.0806, -0.1541, -0.2946, -0.0128,  0.2614, -0.1959, -0.2899,\n",
       "                       0.0984, -0.0954,  0.3801,  0.0031, -0.0116, -0.1876,  0.0905, -0.4068,\n",
       "                      -0.0514, -0.0556,  0.2250, -0.0541, -0.1580,  0.2824,  0.0340, -0.6819,\n",
       "                       0.4667, -0.0944, -0.4318, -0.3325,  0.1531, -0.0955, -0.0187,  0.1850,\n",
       "                       0.0992, -0.2054,  0.1328,  0.0035,  0.4837,  0.2113, -0.2163,  0.1285,\n",
       "                      -0.0864,  0.4211,  0.0791,  0.2858,  0.2118,  0.0513, -0.2165, -0.4369,\n",
       "                      -0.0095,  0.0968,  0.1615, -0.0668, -0.6665, -0.2577, -0.3888, -0.0493,\n",
       "                      -0.1449,  0.2557,  0.3586, -0.1919, -0.2868,  0.0563, -0.2434, -0.3951,\n",
       "                      -0.0237, -0.2338, -0.0835,  0.0911, -0.1855,  0.3321, -0.2775, -0.1253,\n",
       "                      -0.0681,  0.0652, -0.0289, -0.3501,  0.1558,  0.0053, -0.1093,  0.4458,\n",
       "                       0.0015, -0.0630,  0.1160,  0.2421,  0.3361, -0.3478,  0.1220,  0.1046,\n",
       "                      -0.2545, -0.1493, -0.1746,  0.0453,  0.4640,  0.0444,  0.1427, -0.1335,\n",
       "                      -0.0325, -0.0034, -0.3202, -0.1394, -0.0436, -0.1440, -0.2595, -0.1957,\n",
       "                      -0.1482, -0.2321,  0.3111,  0.0433, -0.5786,  0.4695, -0.2927,  0.2200,\n",
       "                      -0.1819,  0.0233, -0.0233,  0.2821,  0.0142,  0.0471,  0.3861,  0.0291,\n",
       "                      -0.3994,  0.3153,  0.0221,  0.0089,  0.2622, -0.1963,  0.2192, -0.0561,\n",
       "                      -0.1063, -0.0018, -0.5074,  0.1205, -0.7941,  0.1876, -0.1873,  0.1491,\n",
       "                       0.6923, -0.0754, -0.3212, -0.8104,  0.1325, -0.0508, -0.5542, -0.2772,\n",
       "                       0.1670,  0.2688, -0.0473,  0.5546,  0.3505,  0.2948,  0.4180,  0.0453,\n",
       "                      -0.2492,  0.2728,  0.1289, -0.1012, -0.1065,  0.5638, -0.3831, -0.2564],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.2.1.running_var',\n",
       "              tensor([0.1247, 0.4673, 0.3052, 0.5637, 0.2827, 0.2225, 0.1415, 0.2438, 0.0741,\n",
       "                      0.0966, 0.1076, 0.2908, 0.0768, 0.4434, 0.3968, 0.4592, 0.2444, 0.4463,\n",
       "                      0.2491, 0.2412, 0.2970, 0.2626, 0.3414, 0.2586, 0.3553, 0.1332, 0.3183,\n",
       "                      0.2798, 0.1681, 0.1046, 0.5512, 0.5218, 0.1067, 0.2158, 0.3256, 0.2574,\n",
       "                      0.0836, 0.2849, 0.2553, 0.3248, 0.2735, 0.4395, 0.1424, 0.4309, 0.1653,\n",
       "                      0.2065, 0.0700, 0.2078, 0.4427, 0.1434, 0.3384, 0.2325, 0.4502, 0.1405,\n",
       "                      0.2815, 0.2169, 0.1982, 0.5412, 0.3812, 0.3282, 0.1567, 0.2946, 0.1145,\n",
       "                      0.1886, 0.4259, 0.4017, 0.4724, 0.1040, 0.3960, 0.4610, 0.2352, 0.2451,\n",
       "                      0.1439, 0.6628, 0.7427, 0.1250, 0.1228, 0.1202, 0.2887, 0.0469, 0.3723,\n",
       "                      0.1196, 0.4409, 0.1489, 0.3526, 0.3294, 0.2418, 0.2398, 0.1891, 0.2547,\n",
       "                      0.5151, 0.3699, 0.3376, 0.1772, 0.1726, 0.0871, 0.4601, 0.1384, 0.1047,\n",
       "                      0.1725, 0.3251, 0.3303, 0.2092, 0.1071, 0.2188, 0.2091, 0.4870, 0.3131,\n",
       "                      0.0564, 0.0977, 0.1272, 0.2620, 0.2930, 0.7058, 0.3363, 0.2974, 0.0500,\n",
       "                      0.5259, 0.1642, 0.3415, 0.2050, 0.2879, 0.3843, 0.5279, 0.3956, 0.2741,\n",
       "                      0.1284, 0.1579, 0.1492, 0.5154, 0.0988, 0.2472, 0.4197, 0.2898, 0.2311,\n",
       "                      0.0403, 0.2334, 0.5278, 0.2275, 0.2735, 0.0617, 0.2492, 0.1211, 0.2848,\n",
       "                      0.1390, 0.8003, 0.2216, 0.5505, 0.3214, 0.2679, 0.5748, 0.1755, 0.2163,\n",
       "                      0.1810, 0.3624, 0.3279, 0.1624, 0.3362, 0.3394, 0.3697, 0.0819, 0.0816,\n",
       "                      0.3182, 0.2392, 0.1825, 0.2556, 0.3022, 0.1684, 0.2362, 0.3641, 0.2427,\n",
       "                      0.2435, 0.1387, 0.2504, 0.4459, 0.2891, 0.2800, 0.2901, 0.3036, 0.2811,\n",
       "                      0.1877, 0.3167, 0.1579, 0.2403, 0.1752, 0.2500, 0.4507, 0.2978, 0.2547,\n",
       "                      0.1796, 0.1171, 0.1139, 0.3048, 0.4933, 0.2250, 0.1359, 0.2289, 0.2110,\n",
       "                      0.3020, 0.2026, 0.0692, 0.4942, 0.2327, 0.1886, 0.4562, 0.4333, 0.3647,\n",
       "                      0.3414, 0.5122, 0.4788, 0.0232, 0.1302, 0.2369, 0.3238, 0.1562, 0.2620,\n",
       "                      0.2632, 0.1647, 0.0481, 0.4497, 0.2626, 0.1364, 0.1314, 0.3705, 0.3710,\n",
       "                      0.2258, 0.3244, 0.4746, 0.4787, 0.4340, 0.4045, 0.2990, 0.4532, 0.3032,\n",
       "                      0.2005, 0.3822, 0.4358, 0.2043, 0.3229, 0.2760, 0.2897, 0.1976, 0.4628,\n",
       "                      0.2424, 0.2310, 0.4662, 0.1528, 0.0978, 0.2962, 0.4412, 0.1777, 0.1448,\n",
       "                      0.3359, 0.2935, 0.1682, 0.1672], dtype=torch.float64)),\n",
       "             ('4.1.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.2.convs.0.0.weight',\n",
       "              tensor([[[ 0.0702],\n",
       "                       [-0.1698],\n",
       "                       [ 0.0550],\n",
       "                       ...,\n",
       "                       [ 0.2336],\n",
       "                       [ 0.0287],\n",
       "                       [ 0.0159]],\n",
       "              \n",
       "                      [[ 0.0541],\n",
       "                       [ 0.0581],\n",
       "                       [-0.0672],\n",
       "                       ...,\n",
       "                       [-0.0276],\n",
       "                       [-0.1097],\n",
       "                       [ 0.0335]],\n",
       "              \n",
       "                      [[ 0.0974],\n",
       "                       [ 0.0572],\n",
       "                       [ 0.1448],\n",
       "                       ...,\n",
       "                       [-0.1670],\n",
       "                       [-0.0445],\n",
       "                       [-0.0218]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0403],\n",
       "                       [ 0.0969],\n",
       "                       [ 0.0285],\n",
       "                       ...,\n",
       "                       [ 0.1109],\n",
       "                       [-0.1581],\n",
       "                       [-0.0688]],\n",
       "              \n",
       "                      [[ 0.0472],\n",
       "                       [ 0.0161],\n",
       "                       [ 0.0451],\n",
       "                       ...,\n",
       "                       [-0.0118],\n",
       "                       [ 0.0003],\n",
       "                       [-0.1417]],\n",
       "              \n",
       "                      [[-0.1838],\n",
       "                       [ 0.0187],\n",
       "                       [ 0.0299],\n",
       "                       ...,\n",
       "                       [ 0.0636],\n",
       "                       [-0.0217],\n",
       "                       [-0.1200]]], dtype=torch.float64)),\n",
       "             ('4.2.convs.0.1.weight',\n",
       "              tensor([0.9464, 0.9544, 0.9544, 0.9406, 0.9657, 0.9796, 0.9911, 0.9462, 0.9470,\n",
       "                      0.9485, 0.9590, 0.9834, 0.9869, 0.9393, 0.9201, 0.9573, 0.9800, 0.9343,\n",
       "                      0.9711, 0.9364, 0.9834, 0.9484, 0.9501, 0.9312, 0.9601, 0.9669, 0.9615,\n",
       "                      0.9540, 0.9825, 0.9531, 0.9683, 0.9648, 0.9747, 0.9481, 0.9748, 0.9592,\n",
       "                      0.9760, 0.9416, 0.9526, 0.9392, 0.9587, 0.9612, 0.9515, 0.9770, 0.9669,\n",
       "                      0.9689, 0.9870, 0.9921, 0.9594, 0.9754, 0.9709, 0.9670, 0.9544, 0.9562,\n",
       "                      0.9368, 0.9454, 0.9812, 0.9478, 0.9984, 0.9660, 0.9485, 0.9321, 0.9549,\n",
       "                      0.9644], dtype=torch.float64)),\n",
       "             ('4.2.convs.0.1.bias',\n",
       "              tensor([-1.9495e-02,  3.5216e-03,  1.2734e-02, -1.2759e-02,  5.8002e-06,\n",
       "                       1.2951e-02,  2.4563e-02,  1.0208e-05,  1.7490e-02, -1.7263e-02,\n",
       "                       8.1130e-03,  2.0233e-02,  1.7482e-02, -1.1692e-03,  3.6552e-04,\n",
       "                      -1.0009e-02,  1.2297e-02, -1.8936e-03,  1.2223e-02, -2.1336e-03,\n",
       "                       1.3507e-02,  1.0784e-02,  1.1740e-02, -1.8731e-02, -9.9534e-03,\n",
       "                       1.4411e-02, -1.3349e-02, -2.7622e-02, -9.7460e-03,  6.6328e-03,\n",
       "                      -9.0697e-03, -1.2296e-02,  2.1980e-03, -2.6876e-02, -1.0755e-02,\n",
       "                       1.3761e-02, -2.9314e-03,  3.0514e-03,  3.8375e-03, -1.4342e-02,\n",
       "                      -8.1784e-03, -2.2646e-03, -5.7542e-03, -3.3786e-03, -6.6312e-03,\n",
       "                       5.9922e-03,  1.9001e-02,  6.6351e-03, -3.8141e-03, -5.8616e-03,\n",
       "                       7.4615e-03,  1.0806e-02,  9.1947e-03,  4.5208e-03, -7.6495e-03,\n",
       "                       5.2995e-03,  8.5199e-03, -6.4357e-03,  1.5609e-03,  1.5071e-02,\n",
       "                      -1.4606e-02, -9.5897e-03, -4.6254e-03,  1.3692e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convs.0.1.running_mean',\n",
       "              tensor([ 0.8013, -0.2368, -0.0489, -0.2212,  0.0110, -0.5408, -0.5364, -0.1092,\n",
       "                      -0.0800,  0.2726, -0.0555, -0.1361, -0.2313, -0.3139,  0.1442,  0.1016,\n",
       "                      -0.2290, -0.9682,  0.0298, -0.4661, -0.5634,  0.2962, -0.3537, -0.4533,\n",
       "                       0.2838,  0.2925, -0.5299, -0.0292,  0.0045, -0.6137,  0.0535, -0.3243,\n",
       "                      -0.2748,  0.1033,  0.4276, -0.0116,  0.7363, -0.7275, -0.3070,  0.5123,\n",
       "                      -0.4906, -0.0562,  0.0475,  0.9380, -0.8622,  0.4700, -0.6253, -0.5178,\n",
       "                      -0.1892,  0.4800, -0.1133,  0.0089, -0.0762, -0.7750, -0.0866,  0.0789,\n",
       "                      -0.8547, -0.6356, -0.6864,  0.0259,  0.1845,  0.1646, -0.2231, -0.2072],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convs.0.1.running_var',\n",
       "              tensor([0.8658, 1.0441, 0.4828, 0.4140, 0.4526, 0.3806, 0.3011, 0.6723, 0.5109,\n",
       "                      1.3491, 0.3508, 0.2678, 0.7463, 0.5745, 0.6340, 0.4593, 0.2861, 1.6291,\n",
       "                      0.6184, 0.8625, 0.6584, 0.3762, 1.0309, 0.8042, 0.5474, 0.9957, 0.3217,\n",
       "                      0.2816, 0.3237, 1.1559, 0.3513, 1.1314, 0.2869, 0.4829, 0.2436, 0.5693,\n",
       "                      0.5492, 0.8320, 0.4094, 0.4211, 0.2751, 0.8711, 0.4345, 0.4309, 0.2922,\n",
       "                      0.4506, 0.7352, 0.3182, 0.7248, 0.2263, 0.4969, 0.3575, 0.8962, 0.4385,\n",
       "                      0.4293, 0.9178, 0.3657, 0.7007, 0.2615, 1.4762, 0.3850, 0.8489, 0.7226,\n",
       "                      0.6106], dtype=torch.float64)),\n",
       "             ('4.2.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.2.convs.1.0.weight',\n",
       "              tensor([[[ 1.5965e-02, -8.7334e-02,  2.3339e-02,  8.5295e-02,  5.2375e-02],\n",
       "                       [ 1.7278e-02,  2.4789e-02,  1.3672e-01, -1.1739e-01,  4.4454e-02],\n",
       "                       [ 6.7152e-02,  8.4430e-02,  7.5823e-02,  1.0004e-02, -1.0539e-02],\n",
       "                       ...,\n",
       "                       [ 6.4077e-03,  4.5944e-02,  1.1689e-02,  1.9172e-02, -6.5984e-02],\n",
       "                       [-1.5304e-02,  8.0513e-02,  1.2624e-01, -9.9547e-02, -6.2065e-02],\n",
       "                       [-6.6264e-02,  1.5129e-02, -5.6860e-02,  7.6153e-02, -2.2226e-03]],\n",
       "              \n",
       "                      [[ 6.2345e-02, -2.5090e-02, -4.0143e-02, -2.1504e-02, -8.5179e-04],\n",
       "                       [ 3.5015e-02,  3.2886e-02,  1.3576e-02,  3.0697e-02, -7.2117e-02],\n",
       "                       [ 2.6434e-03,  2.1661e-02, -1.0804e-01, -1.2891e-01, -7.7489e-02],\n",
       "                       ...,\n",
       "                       [-4.2200e-02,  4.3630e-02,  4.4493e-02,  4.3232e-02, -7.4799e-02],\n",
       "                       [ 9.7887e-02, -6.7348e-02,  5.8831e-02,  1.8867e-02,  1.4218e-01],\n",
       "                       [-4.9538e-02, -8.2036e-02,  3.4987e-02,  2.5011e-02,  8.4173e-03]],\n",
       "              \n",
       "                      [[-2.5509e-02, -3.9872e-03,  4.3003e-02, -1.6950e-02,  8.7339e-02],\n",
       "                       [ 4.8127e-02,  6.1724e-02, -7.5430e-02, -7.5543e-02,  3.0899e-02],\n",
       "                       [-7.6841e-03,  1.8897e-02,  4.7319e-02,  4.9399e-02, -8.9394e-02],\n",
       "                       ...,\n",
       "                       [ 2.5673e-02,  3.3955e-02, -5.6531e-02, -8.9550e-02, -1.2304e-01],\n",
       "                       [ 2.3678e-02, -6.8152e-02,  7.5393e-02, -1.8406e-02, -1.2966e-01],\n",
       "                       [ 7.6372e-02,  2.6798e-02,  2.6066e-02, -2.6055e-03,  5.6527e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 1.3829e-01,  4.6206e-02,  1.1636e-01,  2.2173e-02, -5.3954e-02],\n",
       "                       [ 2.9702e-02,  4.0493e-02, -7.5827e-02, -2.1623e-02, -3.2042e-02],\n",
       "                       [-5.0497e-02,  5.0515e-02,  6.9311e-02,  1.3458e-01,  1.6030e-01],\n",
       "                       ...,\n",
       "                       [ 7.9468e-02,  1.8635e-01, -3.1411e-02,  2.3866e-02, -5.2812e-03],\n",
       "                       [ 5.4575e-03, -9.9997e-02, -4.2273e-02, -5.6591e-02,  1.3082e-01],\n",
       "                       [-1.3916e-01, -3.5978e-02, -6.6961e-03, -8.0260e-02,  2.1887e-02]],\n",
       "              \n",
       "                      [[ 7.5167e-02,  6.8957e-02, -7.1652e-02, -8.5743e-02,  1.3428e-01],\n",
       "                       [ 3.9528e-02, -1.0137e-02, -1.9709e-02,  9.0289e-03,  1.1808e-02],\n",
       "                       [ 7.6913e-02,  9.0583e-02, -1.6944e-01,  1.7404e-01,  2.0995e-02],\n",
       "                       ...,\n",
       "                       [-2.0166e-02, -1.4202e-02, -4.3247e-02, -2.1059e-02,  1.8705e-01],\n",
       "                       [ 2.0755e-02,  5.1492e-02, -4.3478e-02,  4.5100e-02, -7.4607e-02],\n",
       "                       [ 8.3739e-02,  3.6374e-02,  1.1067e-01, -6.5703e-04,  4.2008e-02]],\n",
       "              \n",
       "                      [[-5.6865e-02, -2.6879e-02,  1.1214e-05,  9.6894e-02, -3.4499e-03],\n",
       "                       [-1.3260e-01,  5.2316e-02,  6.5022e-02, -6.2424e-02,  9.2010e-02],\n",
       "                       [ 3.6169e-02, -8.1982e-02, -3.1340e-02,  2.6578e-02, -1.2896e-02],\n",
       "                       ...,\n",
       "                       [ 1.8496e-02,  5.0213e-02, -4.0650e-02,  5.9497e-02, -8.6081e-02],\n",
       "                       [ 1.1426e-01,  3.3271e-02, -9.0838e-02,  7.1756e-03,  1.0398e-01],\n",
       "                       [-2.1491e-02,  7.3455e-02,  2.9381e-02,  1.2381e-02, -1.4010e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convs.1.1.weight',\n",
       "              tensor([0.9423, 0.9662, 0.9396, 0.9476, 0.9674, 0.9272, 0.9681, 0.9722, 0.9339,\n",
       "                      0.9761, 0.9349, 0.9861, 0.9671, 0.9391, 0.9457, 0.9982, 0.9010, 0.9275,\n",
       "                      0.9353, 0.9832, 0.9404, 0.9281, 0.9358, 0.9515, 0.9156, 0.9391, 0.9292,\n",
       "                      0.9614, 0.9226, 0.9436, 0.9280, 0.9120, 0.9815, 0.9537, 0.9291, 0.9343,\n",
       "                      0.9925, 0.9345, 0.9737, 0.9434, 0.9873, 0.9853, 0.9333, 0.9774, 0.9498,\n",
       "                      0.9194, 0.9493, 0.9525, 0.9345, 0.9618, 0.9711, 0.9491, 0.9519, 0.9380,\n",
       "                      0.9567, 0.9804, 0.9453, 0.9842, 0.9697, 0.9792, 0.8994, 0.9496, 0.9489,\n",
       "                      0.9191], dtype=torch.float64)),\n",
       "             ('4.2.convs.1.1.bias',\n",
       "              tensor([-1.3109e-02,  1.8005e-02, -6.5840e-03, -7.9476e-03, -4.4230e-04,\n",
       "                      -4.4252e-03, -9.3745e-03,  2.3976e-02,  1.8121e-03,  5.4741e-03,\n",
       "                       1.0906e-02,  9.0400e-03,  2.3741e-03, -1.6474e-02,  3.7379e-03,\n",
       "                       1.0767e-02, -2.5383e-02, -2.4819e-02,  2.1622e-02,  6.8772e-03,\n",
       "                      -1.7393e-02, -1.1126e-02, -2.4145e-02,  7.6955e-04, -2.1592e-02,\n",
       "                      -1.5686e-02, -1.0719e-02, -2.8384e-05, -3.7678e-03,  1.4840e-02,\n",
       "                      -3.5656e-03, -1.6408e-02, -1.0770e-02, -8.5793e-03, -2.8265e-03,\n",
       "                      -1.8730e-02,  2.9778e-02,  3.6265e-03,  1.7948e-02, -1.0905e-02,\n",
       "                       6.9440e-03, -6.7054e-03, -1.8334e-02,  1.1669e-02, -1.3875e-02,\n",
       "                      -5.9053e-03, -1.1787e-03,  1.8392e-02, -1.8350e-03,  8.8758e-03,\n",
       "                       1.0188e-02, -2.2408e-02, -4.3536e-03, -2.8781e-03, -1.5995e-02,\n",
       "                       2.6976e-02, -1.3820e-02, -2.4503e-03,  9.3554e-03, -1.0622e-03,\n",
       "                      -1.0494e-02, -5.1209e-03, -2.7442e-02, -1.5361e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convs.1.1.running_mean',\n",
       "              tensor([ 0.5599, -0.6813,  0.5047,  0.0202, -0.4026,  0.0520,  0.3703, -0.3439,\n",
       "                      -0.3455, -0.8571, -0.2387, -0.1952,  0.2586, -0.1220,  0.1479, -0.2297,\n",
       "                      -0.4347,  0.3835, -0.5195, -0.0291,  0.1048,  0.4773,  1.2663, -0.2231,\n",
       "                       0.0830,  0.1964, -0.1539,  0.0284, -0.2582, -0.5224,  0.1370, -0.1453,\n",
       "                      -0.3110,  0.3673, -0.7171,  0.3127,  0.3361, -0.0663, -0.6876,  0.4397,\n",
       "                      -0.1260,  0.2848, -0.3000, -0.7592, -0.0198, -0.3640, -0.0108,  0.3412,\n",
       "                       0.1658, -0.3082, -0.3016,  0.6141,  0.1885, -0.1382, -1.1476, -0.1223,\n",
       "                      -0.7389, -0.4085, -0.5790,  0.8025, -0.0469, -0.1233,  0.5507,  0.2853],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convs.1.1.running_var',\n",
       "              tensor([0.9067, 0.3428, 0.4494, 0.3018, 0.2833, 0.4519, 0.4343, 0.5535, 0.7867,\n",
       "                      0.5390, 0.4694, 0.3933, 0.3447, 0.4470, 0.4655, 0.2867, 1.0934, 1.0591,\n",
       "                      0.4050, 0.3376, 0.5769, 0.5339, 1.1698, 0.3003, 0.4116, 0.5572, 0.5072,\n",
       "                      0.5395, 0.5949, 0.3919, 0.6542, 0.3395, 0.3884, 0.9852, 0.5406, 0.7128,\n",
       "                      0.5391, 0.4167, 0.6062, 0.5158, 0.4401, 0.3453, 0.4030, 0.4781, 0.3605,\n",
       "                      0.5585, 0.4536, 0.4190, 0.2972, 0.7026, 0.6629, 0.8444, 0.2798, 0.4130,\n",
       "                      0.3815, 0.4689, 0.4057, 0.6268, 0.4900, 0.3708, 0.7184, 0.4737, 0.5560,\n",
       "                      0.5098], dtype=torch.float64)),\n",
       "             ('4.2.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.2.convs.2.0.weight',\n",
       "              tensor([[[-0.0321],\n",
       "                       [-0.1682],\n",
       "                       [ 0.0317],\n",
       "                       ...,\n",
       "                       [ 0.1145],\n",
       "                       [-0.1091],\n",
       "                       [-0.0575]],\n",
       "              \n",
       "                      [[-0.1367],\n",
       "                       [ 0.0007],\n",
       "                       [ 0.0081],\n",
       "                       ...,\n",
       "                       [-0.0289],\n",
       "                       [-0.2310],\n",
       "                       [-0.0343]],\n",
       "              \n",
       "                      [[-0.1589],\n",
       "                       [-0.1134],\n",
       "                       [ 0.3602],\n",
       "                       ...,\n",
       "                       [ 0.0616],\n",
       "                       [-0.0984],\n",
       "                       [-0.1072]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0441],\n",
       "                       [ 0.2674],\n",
       "                       [-0.1192],\n",
       "                       ...,\n",
       "                       [-0.1718],\n",
       "                       [-0.0294],\n",
       "                       [ 0.2213]],\n",
       "              \n",
       "                      [[ 0.0906],\n",
       "                       [ 0.1696],\n",
       "                       [-0.1439],\n",
       "                       ...,\n",
       "                       [-0.1461],\n",
       "                       [-0.0710],\n",
       "                       [-0.0285]],\n",
       "              \n",
       "                      [[ 0.0423],\n",
       "                       [-0.3263],\n",
       "                       [ 0.0508],\n",
       "                       ...,\n",
       "                       [-0.0360],\n",
       "                       [-0.1137],\n",
       "                       [-0.0988]]], dtype=torch.float64)),\n",
       "             ('4.2.convs.2.1.weight',\n",
       "              tensor([ 0.0042, -0.0382,  0.0169,  0.0011, -0.0347,  0.0163, -0.0213,  0.0145,\n",
       "                      -0.0151,  0.0092,  0.0006,  0.0256,  0.0126, -0.0153, -0.0065,  0.0181,\n",
       "                      -0.0318, -0.0134, -0.0193,  0.0100,  0.0104,  0.0300, -0.0208,  0.0320,\n",
       "                      -0.0220, -0.0164,  0.0122,  0.0164,  0.0200,  0.0077, -0.0025, -0.0379,\n",
       "                      -0.0076, -0.0049,  0.0416,  0.0206,  0.0034,  0.0127,  0.0054, -0.0253,\n",
       "                      -0.0110,  0.0110, -0.0207, -0.0320,  0.0231, -0.0063, -0.0082, -0.0028,\n",
       "                      -0.0250, -0.0130, -0.0179, -0.0020,  0.0167,  0.0182, -0.0031, -0.0101,\n",
       "                      -0.0054,  0.0097, -0.0141,  0.0067,  0.0051,  0.0297,  0.0026, -0.0160,\n",
       "                      -0.0171,  0.0184,  0.0098, -0.0118,  0.0307, -0.0137, -0.0050,  0.0069,\n",
       "                       0.0118, -0.0020, -0.0246, -0.0069, -0.0028,  0.0095, -0.0166,  0.0064,\n",
       "                      -0.0104, -0.0068,  0.0499, -0.0194, -0.0130, -0.0101,  0.0283,  0.0318,\n",
       "                       0.0528,  0.0088, -0.0092,  0.0177, -0.0045,  0.0023,  0.0003,  0.0174,\n",
       "                      -0.0134, -0.0217, -0.0123,  0.0074,  0.0057, -0.0140,  0.0310,  0.0282,\n",
       "                      -0.0057,  0.0180,  0.0215,  0.0147,  0.0366,  0.0044, -0.0040,  0.0090,\n",
       "                      -0.0362, -0.0171, -0.0110, -0.0152, -0.0031, -0.0073,  0.0117,  0.0077,\n",
       "                      -0.0234, -0.0219, -0.0195,  0.0271, -0.0018, -0.0014,  0.0122, -0.0163,\n",
       "                       0.0234, -0.0346,  0.0059, -0.0202,  0.0341,  0.0213,  0.0021,  0.0016,\n",
       "                      -0.0061, -0.0095,  0.0222,  0.0008, -0.0047, -0.0141, -0.0098,  0.0347,\n",
       "                      -0.0047, -0.0378, -0.0214, -0.0105,  0.0021,  0.0161,  0.0256,  0.0007,\n",
       "                      -0.0284, -0.0170, -0.0010,  0.0181,  0.0049,  0.0111, -0.0018,  0.0154,\n",
       "                      -0.0098,  0.0209, -0.0156,  0.0211,  0.0097, -0.0191, -0.0040,  0.0080,\n",
       "                       0.0059, -0.0300,  0.0013,  0.0193, -0.0073,  0.0064,  0.0120,  0.0109,\n",
       "                       0.0080,  0.0215, -0.0303, -0.0084,  0.0086, -0.0129, -0.0029, -0.0115,\n",
       "                       0.0393, -0.0093, -0.0376,  0.0521,  0.0153, -0.0145,  0.0044,  0.0058,\n",
       "                      -0.0270,  0.0194,  0.0249, -0.0024,  0.0042, -0.0095,  0.0025,  0.0011,\n",
       "                       0.0021, -0.0277,  0.0147, -0.0127,  0.0033,  0.0045, -0.0342,  0.0207,\n",
       "                       0.0100,  0.0192,  0.0058,  0.0103,  0.0002,  0.0090, -0.0087,  0.0029,\n",
       "                      -0.0103, -0.0278, -0.0128,  0.0141, -0.0035,  0.0119,  0.0036, -0.0154,\n",
       "                       0.0085,  0.0126, -0.0141, -0.0009, -0.0014, -0.0076, -0.0352,  0.0166,\n",
       "                      -0.0433,  0.0051, -0.0161,  0.0024, -0.0136, -0.0205, -0.0086,  0.0156,\n",
       "                       0.0048, -0.0023, -0.0004,  0.0185, -0.0261, -0.0085, -0.0071,  0.0134,\n",
       "                       0.0174, -0.0486, -0.0148,  0.0266, -0.0191,  0.0320, -0.0035,  0.0223],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convs.2.1.bias',\n",
       "              tensor([ 2.2981e-03,  6.0355e-03,  3.0007e-02, -1.3390e-03,  1.4013e-02,\n",
       "                      -1.6159e-02, -3.2799e-03, -1.3372e-03, -1.2572e-02, -9.1693e-03,\n",
       "                      -5.5602e-03, -5.7822e-03,  1.4705e-02, -1.3795e-02,  8.6815e-03,\n",
       "                       5.6836e-03,  3.3969e-02,  6.5681e-03,  2.4544e-02, -9.3135e-04,\n",
       "                       1.7069e-03,  4.4020e-03,  6.4256e-04, -1.0262e-03,  1.7300e-03,\n",
       "                      -2.3364e-02,  3.7162e-03,  1.3636e-02,  1.1473e-02,  5.0608e-03,\n",
       "                      -8.9330e-03,  2.1448e-02, -1.1811e-02,  1.6927e-02,  1.3091e-02,\n",
       "                      -3.2098e-04, -8.9734e-03,  4.5552e-03, -1.3376e-02, -7.0448e-03,\n",
       "                       1.0680e-02, -8.3521e-03, -1.8405e-03,  1.1746e-02,  6.9080e-03,\n",
       "                      -4.2487e-03, -1.5921e-02,  8.3356e-03, -3.3936e-03, -3.0647e-03,\n",
       "                      -1.9244e-03,  3.4782e-03,  1.6608e-02,  2.8802e-02, -7.5906e-03,\n",
       "                       2.0866e-03,  2.3706e-03,  5.4979e-03, -1.7742e-02,  9.0638e-03,\n",
       "                      -7.1016e-03,  8.6566e-04, -1.9732e-02,  2.8876e-04,  4.0477e-03,\n",
       "                       1.4831e-02, -6.1769e-03,  2.3492e-02,  2.4774e-02, -1.7151e-02,\n",
       "                       1.1681e-02,  7.9894e-03,  7.3410e-03, -6.5583e-03, -4.5579e-03,\n",
       "                       1.7578e-02,  7.3620e-03, -1.8193e-02,  1.6897e-03,  1.0131e-02,\n",
       "                      -6.3668e-03,  6.6972e-04,  1.7577e-02,  4.7862e-03,  4.9707e-03,\n",
       "                      -2.2640e-02,  1.4011e-02,  1.3818e-02,  6.8424e-03, -3.7594e-03,\n",
       "                       5.8248e-03,  1.0848e-02,  1.4915e-02,  6.6864e-03,  5.0534e-03,\n",
       "                      -1.2815e-02,  1.1481e-02,  1.0703e-02,  1.3009e-02, -1.1513e-02,\n",
       "                       2.2523e-02,  1.2651e-03, -5.1943e-03, -1.3343e-02,  4.8336e-03,\n",
       "                       1.1113e-02, -1.1996e-02, -9.7674e-04,  1.7487e-02, -9.8886e-03,\n",
       "                      -1.3223e-02, -6.4504e-03,  1.3571e-02,  1.4810e-02,  1.5687e-02,\n",
       "                       8.7651e-03,  9.3772e-03,  1.1581e-02,  1.1279e-02, -6.1102e-03,\n",
       "                       1.7679e-02, -1.1416e-02,  2.0439e-03,  2.6063e-03, -8.8128e-03,\n",
       "                       1.2904e-02,  4.2038e-03,  7.4398e-03,  1.1056e-02, -6.8831e-04,\n",
       "                      -7.3310e-03,  6.1786e-03,  2.0150e-03,  5.3117e-03, -7.2624e-03,\n",
       "                      -1.6135e-02,  4.1060e-03,  2.9873e-02, -1.4422e-03, -7.6886e-03,\n",
       "                       7.2946e-04,  9.8148e-03, -9.9029e-03, -2.2951e-03, -1.5686e-02,\n",
       "                      -5.4162e-03,  4.6320e-03, -5.8741e-03,  1.2422e-02,  2.3152e-02,\n",
       "                       1.9946e-03, -1.2418e-02, -2.4738e-02,  1.7292e-02, -4.1586e-03,\n",
       "                       1.1232e-02,  9.4844e-03,  2.1819e-02, -4.1767e-03, -2.0144e-02,\n",
       "                      -9.9166e-05,  1.1130e-02, -1.1883e-02,  1.8993e-02,  1.7969e-02,\n",
       "                       1.0380e-02, -7.9747e-03,  2.1661e-02,  1.2728e-02,  2.3638e-02,\n",
       "                       1.2848e-02, -4.1754e-03, -8.3021e-03,  2.0047e-02, -1.6692e-02,\n",
       "                      -6.1638e-03,  6.3373e-03,  2.3157e-02,  1.6104e-02, -2.4939e-03,\n",
       "                      -3.7590e-03,  1.3873e-03, -9.7327e-03, -1.1150e-03,  5.9546e-03,\n",
       "                       7.6138e-03,  1.7157e-02,  3.2642e-02, -1.7507e-03,  8.1882e-03,\n",
       "                      -7.7682e-03, -1.4533e-02,  3.6442e-03, -1.7871e-02,  1.0974e-02,\n",
       "                       1.8575e-02, -4.9975e-03,  1.4283e-02,  1.2792e-02, -1.6664e-02,\n",
       "                       1.5296e-02,  3.0710e-03,  9.8463e-04,  1.6290e-02,  3.6353e-03,\n",
       "                      -5.9694e-03,  8.4527e-03, -1.6902e-02,  6.0383e-03,  1.0562e-02,\n",
       "                       6.0151e-03, -9.1413e-03,  7.7327e-03, -1.0408e-03,  1.8305e-03,\n",
       "                       1.2953e-02,  3.5994e-03,  1.0672e-02,  1.2097e-02,  1.0209e-02,\n",
       "                      -8.4629e-05, -1.0060e-02,  1.1748e-02,  7.4849e-05, -1.4349e-03,\n",
       "                       1.8271e-02,  1.0349e-02,  4.8985e-03, -2.4221e-02, -3.6036e-03,\n",
       "                      -2.4693e-03,  1.0476e-02,  2.7278e-02,  3.1265e-03, -1.8923e-03,\n",
       "                       6.9213e-03,  1.5240e-02,  6.3762e-03, -9.1332e-03,  5.0912e-03,\n",
       "                      -5.5732e-03,  4.1736e-03,  1.1687e-02,  3.5444e-03,  1.3644e-02,\n",
       "                       1.8368e-02, -1.2853e-03,  1.3878e-02, -1.0017e-02, -1.4650e-02,\n",
       "                       1.9003e-02, -1.2700e-03, -1.0338e-02,  2.2673e-02,  2.3178e-02,\n",
       "                       6.8945e-03], dtype=torch.float64)),\n",
       "             ('4.2.convs.2.1.running_mean',\n",
       "              tensor([ 2.2142e-01, -3.5158e-02,  4.7936e-01,  1.3704e-01,  1.5016e-01,\n",
       "                      -2.9301e-01,  2.8332e-01,  1.4424e-01,  2.8096e-01,  6.1163e-01,\n",
       "                       8.5292e-02,  7.7581e-02,  6.1009e-02,  1.1685e-01, -6.7240e-01,\n",
       "                      -6.9520e-04, -3.9635e-01,  8.0276e-01,  6.6967e-01, -8.1997e-01,\n",
       "                       1.6503e-01, -2.0750e-01,  4.3678e-01, -6.5098e-01,  1.7848e-01,\n",
       "                      -2.4521e-01, -3.7271e-01,  1.5257e-01,  3.0628e-01,  3.0542e-01,\n",
       "                      -2.9402e-01,  8.3692e-01,  6.5709e-02,  6.5633e-02, -3.4898e-01,\n",
       "                       4.7584e-01,  1.6067e-02,  1.6485e-01,  2.4903e-01, -4.5836e-01,\n",
       "                      -1.1768e-01, -2.3431e-01,  1.8861e-01, -2.9288e-02,  3.6511e-01,\n",
       "                      -3.2776e-01, -3.3418e-01, -2.8739e-02,  1.3645e-01,  3.3940e-01,\n",
       "                       1.6950e-01, -1.8935e-01,  1.6950e-01,  7.7983e-02,  8.8855e-02,\n",
       "                      -6.1477e-02, -2.3188e-01, -6.3246e-02, -2.6731e-01,  8.7092e-02,\n",
       "                       1.4543e-01, -4.9972e-02,  3.5225e-01, -2.4500e-01,  1.5744e-01,\n",
       "                      -1.2062e-01, -1.9639e-01,  1.0864e-01, -2.0654e-01, -1.0682e-01,\n",
       "                      -4.9675e-02, -8.4615e-02, -1.4485e-01,  6.9949e-01,  5.1589e-01,\n",
       "                      -8.8552e-02,  1.4291e-02, -1.8502e-01,  4.4828e-01, -2.1247e-01,\n",
       "                       1.6623e-01,  2.0076e-01, -3.7122e-01,  7.7382e-01,  2.8990e-01,\n",
       "                      -7.4275e-01,  5.1118e-01,  4.3443e-02, -2.5806e-02, -1.3909e-01,\n",
       "                      -2.1683e-01,  1.1638e-01,  3.9570e-02, -5.1656e-02, -3.9182e-02,\n",
       "                      -2.6096e-02, -5.1525e-01,  2.1138e-01, -1.8937e-01,  6.1392e-01,\n",
       "                       4.6584e-02, -3.5009e-01,  1.7265e-01,  1.0096e-01, -3.9140e-01,\n",
       "                      -6.0333e-01,  1.2356e-01,  1.3604e-01, -3.1294e-01,  1.1004e-01,\n",
       "                       2.2361e-01, -1.0477e-01,  1.4201e-01, -2.6361e-03, -2.4967e-01,\n",
       "                       1.2752e-01, -1.0775e-01,  9.8541e-02, -2.6598e-01, -2.1570e-01,\n",
       "                      -1.9860e-01,  1.2686e-01, -9.8351e-02,  5.9487e-01, -3.1013e-02,\n",
       "                      -8.9968e-02,  6.7673e-01, -2.0401e-01,  1.0732e-01,  2.4746e-01,\n",
       "                      -1.3224e-01,  2.6989e-01, -4.6560e-01,  7.1059e-02, -1.3566e-01,\n",
       "                       2.8899e-01, -8.2771e-02,  1.2047e-01,  1.1373e-01,  3.0030e-01,\n",
       "                      -4.7368e-01,  1.5133e-02, -3.6606e-01, -3.1214e-02,  2.0281e-01,\n",
       "                      -6.2564e-02, -7.9454e-01,  8.2024e-01, -1.1752e-01,  1.1513e-02,\n",
       "                       1.1064e-01,  3.1738e-01,  2.2243e-01, -4.2587e-02,  3.4996e-03,\n",
       "                       3.0102e-01,  1.4794e-01, -2.7961e-01, -1.5764e-01,  2.8097e-01,\n",
       "                      -2.8864e-01, -4.7957e-01, -5.0146e-02,  4.9852e-01,  4.6698e-01,\n",
       "                       3.2214e-01,  3.0504e-01,  2.9440e-01, -4.2277e-01,  1.7022e-01,\n",
       "                       6.4302e-02,  1.0283e-01,  8.1499e-02,  5.0447e-02,  4.7729e-01,\n",
       "                       6.8529e-03,  6.2631e-02,  4.5509e-01, -2.7544e-01, -2.9442e-01,\n",
       "                      -1.5363e-01,  1.5365e-01,  5.7494e-01,  3.2734e-01,  1.6687e-01,\n",
       "                       1.4306e-01,  1.1846e-01,  2.5563e-01, -5.9768e-01, -3.1768e-01,\n",
       "                       5.6654e-05, -2.2829e-01,  5.9329e-01, -3.3185e-01, -3.3549e-01,\n",
       "                      -4.2196e-02,  8.0192e-02,  2.6960e-01, -1.2091e-01,  1.0461e-01,\n",
       "                       4.3255e-01,  1.8091e-01,  4.4113e-01, -4.1657e-02, -5.0203e-01,\n",
       "                       3.5528e-02,  4.7656e-01, -1.5542e-01,  6.5555e-02, -2.3467e-01,\n",
       "                       1.7397e-01,  1.2085e-01,  2.3107e-01,  2.1652e-01,  1.5883e-01,\n",
       "                      -2.4920e-02, -1.2971e-01,  2.5491e-01,  2.0970e-01, -7.3771e-01,\n",
       "                      -4.8901e-02,  5.9636e-02,  6.8819e-02, -1.4104e-01,  9.0482e-01,\n",
       "                       2.0468e-01, -4.2534e-01, -1.5065e-01,  3.2987e-01, -2.1250e-01,\n",
       "                      -3.9264e-01, -9.6778e-02, -3.1806e-01, -1.6343e-01,  3.3466e-01,\n",
       "                      -3.8532e-01, -4.0276e-01,  2.7974e-02, -1.2858e-01, -2.5921e-01,\n",
       "                      -1.2651e-01,  1.6659e-01, -1.6267e-01, -1.4795e-01, -7.3921e-03,\n",
       "                      -1.9303e-01, -5.0223e-01,  4.1150e-01,  3.2483e-01, -4.1626e-02,\n",
       "                      -2.3209e-01, -2.6750e-01, -6.4750e-02, -3.3819e-01, -5.1727e-02,\n",
       "                      -3.8360e-01], dtype=torch.float64)),\n",
       "             ('4.2.convs.2.1.running_var',\n",
       "              tensor([0.3494, 0.3664, 0.5004, 0.2424, 0.4853, 0.2903, 0.2619, 0.3312, 0.1057,\n",
       "                      0.3090, 0.1433, 0.2842, 0.2199, 0.3126, 0.6621, 0.2775, 0.3625, 0.7359,\n",
       "                      0.3012, 0.3333, 0.2643, 0.4854, 0.2571, 0.3565, 0.4389, 0.1531, 0.3283,\n",
       "                      0.3391, 0.2246, 0.2702, 0.3921, 0.6336, 0.2376, 0.1874, 0.3359, 0.3782,\n",
       "                      0.0775, 0.3302, 0.1297, 0.7002, 0.4018, 0.0763, 0.1583, 0.6357, 0.5126,\n",
       "                      0.1717, 0.2589, 0.0645, 0.4337, 0.3108, 0.2681, 0.1602, 0.3169, 0.2280,\n",
       "                      0.1088, 0.1705, 0.1895, 0.3184, 0.2708, 0.2359, 0.0773, 0.2504, 0.2813,\n",
       "                      0.3729, 0.6203, 0.3734, 0.3693, 0.4202, 0.4217, 0.2804, 0.3392, 0.1044,\n",
       "                      0.2604, 0.5761, 0.6272, 0.1467, 0.1798, 0.1571, 0.3038, 0.1496, 0.3359,\n",
       "                      0.1670, 0.4270, 0.5396, 0.1584, 0.2921, 0.4444, 0.3492, 0.3100, 0.0724,\n",
       "                      0.3694, 0.3629, 0.4728, 0.0720, 0.0826, 0.2072, 0.5206, 0.1613, 0.4708,\n",
       "                      0.3128, 0.3138, 0.2628, 0.2690, 0.2873, 0.3417, 0.4148, 0.2431, 0.3579,\n",
       "                      0.4063, 0.0342, 0.1433, 0.4559, 0.3074, 0.4460, 0.4856, 0.1305, 0.1772,\n",
       "                      0.4879, 0.1669, 0.1863, 0.2000, 0.4973, 0.4043, 0.4526, 0.0449, 0.1972,\n",
       "                      0.3342, 0.2001, 0.2827, 0.2879, 0.0789, 0.4231, 0.5012, 0.3574, 0.0993,\n",
       "                      0.1236, 0.2986, 0.2042, 0.1935, 0.2214, 0.1848, 0.2062, 0.3228, 0.2898,\n",
       "                      0.1555, 0.6018, 0.2927, 0.5353, 0.0708, 0.2957, 0.3032, 0.0721, 0.4335,\n",
       "                      0.2709, 0.0514, 0.5275, 0.1669, 0.1499, 0.1675, 0.2188, 0.3065, 0.3264,\n",
       "                      0.1616, 0.3622, 0.2976, 0.3722, 0.4573, 0.1545, 0.1959, 0.6024, 0.0432,\n",
       "                      0.3219, 0.1022, 0.0954, 0.4639, 0.3849, 0.3074, 0.5008, 0.3763, 0.1747,\n",
       "                      0.1534, 0.2606, 0.4120, 0.2213, 0.3451, 0.1596, 0.6406, 0.3423, 0.5384,\n",
       "                      0.4377, 0.0987, 0.1373, 0.2969, 0.4314, 0.3624, 0.3267, 0.2923, 0.2659,\n",
       "                      0.1215, 0.0513, 0.1512, 0.2044, 0.4376, 0.2054, 0.3051, 0.2576, 0.2613,\n",
       "                      0.0522, 0.1541, 0.3856, 0.1245, 0.2651, 0.0817, 0.1799, 0.0465, 0.0550,\n",
       "                      0.2209, 0.2880, 0.4932, 0.4446, 0.0395, 0.2346, 0.1144, 0.3688, 0.3867,\n",
       "                      0.3351, 0.3443, 0.0668, 0.3079, 0.3591, 0.5042, 0.5272, 0.5843, 0.2058,\n",
       "                      0.3878, 0.2597, 0.2097, 0.2800, 0.3690, 0.1457, 0.1344, 0.1432, 0.3141,\n",
       "                      0.1558, 0.3444, 0.1713, 0.2369, 0.2696, 0.1473, 0.3800, 0.2939, 0.3554,\n",
       "                      0.3341, 0.4072, 0.1675, 0.4181], dtype=torch.float64)),\n",
       "             ('4.2.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.2.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.0702],\n",
       "                       [-0.1698],\n",
       "                       [ 0.0550],\n",
       "                       ...,\n",
       "                       [ 0.2336],\n",
       "                       [ 0.0287],\n",
       "                       [ 0.0159]],\n",
       "              \n",
       "                      [[ 0.0541],\n",
       "                       [ 0.0581],\n",
       "                       [-0.0672],\n",
       "                       ...,\n",
       "                       [-0.0276],\n",
       "                       [-0.1097],\n",
       "                       [ 0.0335]],\n",
       "              \n",
       "                      [[ 0.0974],\n",
       "                       [ 0.0572],\n",
       "                       [ 0.1448],\n",
       "                       ...,\n",
       "                       [-0.1670],\n",
       "                       [-0.0445],\n",
       "                       [-0.0218]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0403],\n",
       "                       [ 0.0969],\n",
       "                       [ 0.0285],\n",
       "                       ...,\n",
       "                       [ 0.1109],\n",
       "                       [-0.1581],\n",
       "                       [-0.0688]],\n",
       "              \n",
       "                      [[ 0.0472],\n",
       "                       [ 0.0161],\n",
       "                       [ 0.0451],\n",
       "                       ...,\n",
       "                       [-0.0118],\n",
       "                       [ 0.0003],\n",
       "                       [-0.1417]],\n",
       "              \n",
       "                      [[-0.1838],\n",
       "                       [ 0.0187],\n",
       "                       [ 0.0299],\n",
       "                       ...,\n",
       "                       [ 0.0636],\n",
       "                       [-0.0217],\n",
       "                       [-0.1200]]], dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.0.1.weight',\n",
       "              tensor([0.9464, 0.9544, 0.9544, 0.9406, 0.9657, 0.9796, 0.9911, 0.9462, 0.9470,\n",
       "                      0.9485, 0.9590, 0.9834, 0.9869, 0.9393, 0.9201, 0.9573, 0.9800, 0.9343,\n",
       "                      0.9711, 0.9364, 0.9834, 0.9484, 0.9501, 0.9312, 0.9601, 0.9669, 0.9615,\n",
       "                      0.9540, 0.9825, 0.9531, 0.9683, 0.9648, 0.9747, 0.9481, 0.9748, 0.9592,\n",
       "                      0.9760, 0.9416, 0.9526, 0.9392, 0.9587, 0.9612, 0.9515, 0.9770, 0.9669,\n",
       "                      0.9689, 0.9870, 0.9921, 0.9594, 0.9754, 0.9709, 0.9670, 0.9544, 0.9562,\n",
       "                      0.9368, 0.9454, 0.9812, 0.9478, 0.9984, 0.9660, 0.9485, 0.9321, 0.9549,\n",
       "                      0.9644], dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.0.1.bias',\n",
       "              tensor([-1.9495e-02,  3.5216e-03,  1.2734e-02, -1.2759e-02,  5.8002e-06,\n",
       "                       1.2951e-02,  2.4563e-02,  1.0208e-05,  1.7490e-02, -1.7263e-02,\n",
       "                       8.1130e-03,  2.0233e-02,  1.7482e-02, -1.1692e-03,  3.6552e-04,\n",
       "                      -1.0009e-02,  1.2297e-02, -1.8936e-03,  1.2223e-02, -2.1336e-03,\n",
       "                       1.3507e-02,  1.0784e-02,  1.1740e-02, -1.8731e-02, -9.9534e-03,\n",
       "                       1.4411e-02, -1.3349e-02, -2.7622e-02, -9.7460e-03,  6.6328e-03,\n",
       "                      -9.0697e-03, -1.2296e-02,  2.1980e-03, -2.6876e-02, -1.0755e-02,\n",
       "                       1.3761e-02, -2.9314e-03,  3.0514e-03,  3.8375e-03, -1.4342e-02,\n",
       "                      -8.1784e-03, -2.2646e-03, -5.7542e-03, -3.3786e-03, -6.6312e-03,\n",
       "                       5.9922e-03,  1.9001e-02,  6.6351e-03, -3.8141e-03, -5.8616e-03,\n",
       "                       7.4615e-03,  1.0806e-02,  9.1947e-03,  4.5208e-03, -7.6495e-03,\n",
       "                       5.2995e-03,  8.5199e-03, -6.4357e-03,  1.5609e-03,  1.5071e-02,\n",
       "                      -1.4606e-02, -9.5897e-03, -4.6254e-03,  1.3692e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.8013, -0.2368, -0.0489, -0.2212,  0.0110, -0.5408, -0.5364, -0.1092,\n",
       "                      -0.0800,  0.2726, -0.0555, -0.1361, -0.2313, -0.3139,  0.1442,  0.1016,\n",
       "                      -0.2290, -0.9682,  0.0298, -0.4661, -0.5634,  0.2962, -0.3537, -0.4533,\n",
       "                       0.2838,  0.2925, -0.5299, -0.0292,  0.0045, -0.6137,  0.0535, -0.3243,\n",
       "                      -0.2748,  0.1033,  0.4276, -0.0116,  0.7363, -0.7275, -0.3070,  0.5123,\n",
       "                      -0.4906, -0.0562,  0.0475,  0.9380, -0.8622,  0.4700, -0.6253, -0.5178,\n",
       "                      -0.1892,  0.4800, -0.1133,  0.0089, -0.0762, -0.7750, -0.0866,  0.0789,\n",
       "                      -0.8547, -0.6356, -0.6864,  0.0259,  0.1845,  0.1646, -0.2231, -0.2072],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.0.1.running_var',\n",
       "              tensor([0.8658, 1.0441, 0.4828, 0.4140, 0.4526, 0.3806, 0.3011, 0.6723, 0.5109,\n",
       "                      1.3491, 0.3508, 0.2678, 0.7463, 0.5745, 0.6340, 0.4593, 0.2861, 1.6291,\n",
       "                      0.6184, 0.8625, 0.6584, 0.3762, 1.0309, 0.8042, 0.5474, 0.9957, 0.3217,\n",
       "                      0.2816, 0.3237, 1.1559, 0.3513, 1.1314, 0.2869, 0.4829, 0.2436, 0.5693,\n",
       "                      0.5492, 0.8320, 0.4094, 0.4211, 0.2751, 0.8711, 0.4345, 0.4309, 0.2922,\n",
       "                      0.4506, 0.7352, 0.3182, 0.7248, 0.2263, 0.4969, 0.3575, 0.8962, 0.4385,\n",
       "                      0.4293, 0.9178, 0.3657, 0.7007, 0.2615, 1.4762, 0.3850, 0.8489, 0.7226,\n",
       "                      0.6106], dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.2.convpath.0.1.0.weight',\n",
       "              tensor([[[ 1.5965e-02, -8.7334e-02,  2.3339e-02,  8.5295e-02,  5.2375e-02],\n",
       "                       [ 1.7278e-02,  2.4789e-02,  1.3672e-01, -1.1739e-01,  4.4454e-02],\n",
       "                       [ 6.7152e-02,  8.4430e-02,  7.5823e-02,  1.0004e-02, -1.0539e-02],\n",
       "                       ...,\n",
       "                       [ 6.4077e-03,  4.5944e-02,  1.1689e-02,  1.9172e-02, -6.5984e-02],\n",
       "                       [-1.5304e-02,  8.0513e-02,  1.2624e-01, -9.9547e-02, -6.2065e-02],\n",
       "                       [-6.6264e-02,  1.5129e-02, -5.6860e-02,  7.6153e-02, -2.2226e-03]],\n",
       "              \n",
       "                      [[ 6.2345e-02, -2.5090e-02, -4.0143e-02, -2.1504e-02, -8.5179e-04],\n",
       "                       [ 3.5015e-02,  3.2886e-02,  1.3576e-02,  3.0697e-02, -7.2117e-02],\n",
       "                       [ 2.6434e-03,  2.1661e-02, -1.0804e-01, -1.2891e-01, -7.7489e-02],\n",
       "                       ...,\n",
       "                       [-4.2200e-02,  4.3630e-02,  4.4493e-02,  4.3232e-02, -7.4799e-02],\n",
       "                       [ 9.7887e-02, -6.7348e-02,  5.8831e-02,  1.8867e-02,  1.4218e-01],\n",
       "                       [-4.9538e-02, -8.2036e-02,  3.4987e-02,  2.5011e-02,  8.4173e-03]],\n",
       "              \n",
       "                      [[-2.5509e-02, -3.9872e-03,  4.3003e-02, -1.6950e-02,  8.7339e-02],\n",
       "                       [ 4.8127e-02,  6.1724e-02, -7.5430e-02, -7.5543e-02,  3.0899e-02],\n",
       "                       [-7.6841e-03,  1.8897e-02,  4.7319e-02,  4.9399e-02, -8.9394e-02],\n",
       "                       ...,\n",
       "                       [ 2.5673e-02,  3.3955e-02, -5.6531e-02, -8.9550e-02, -1.2304e-01],\n",
       "                       [ 2.3678e-02, -6.8152e-02,  7.5393e-02, -1.8406e-02, -1.2966e-01],\n",
       "                       [ 7.6372e-02,  2.6798e-02,  2.6066e-02, -2.6055e-03,  5.6527e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 1.3829e-01,  4.6206e-02,  1.1636e-01,  2.2173e-02, -5.3954e-02],\n",
       "                       [ 2.9702e-02,  4.0493e-02, -7.5827e-02, -2.1623e-02, -3.2042e-02],\n",
       "                       [-5.0497e-02,  5.0515e-02,  6.9311e-02,  1.3458e-01,  1.6030e-01],\n",
       "                       ...,\n",
       "                       [ 7.9468e-02,  1.8635e-01, -3.1411e-02,  2.3866e-02, -5.2812e-03],\n",
       "                       [ 5.4575e-03, -9.9997e-02, -4.2273e-02, -5.6591e-02,  1.3082e-01],\n",
       "                       [-1.3916e-01, -3.5978e-02, -6.6961e-03, -8.0260e-02,  2.1887e-02]],\n",
       "              \n",
       "                      [[ 7.5167e-02,  6.8957e-02, -7.1652e-02, -8.5743e-02,  1.3428e-01],\n",
       "                       [ 3.9528e-02, -1.0137e-02, -1.9709e-02,  9.0289e-03,  1.1808e-02],\n",
       "                       [ 7.6913e-02,  9.0583e-02, -1.6944e-01,  1.7404e-01,  2.0995e-02],\n",
       "                       ...,\n",
       "                       [-2.0166e-02, -1.4202e-02, -4.3247e-02, -2.1059e-02,  1.8705e-01],\n",
       "                       [ 2.0755e-02,  5.1492e-02, -4.3478e-02,  4.5100e-02, -7.4607e-02],\n",
       "                       [ 8.3739e-02,  3.6374e-02,  1.1067e-01, -6.5703e-04,  4.2008e-02]],\n",
       "              \n",
       "                      [[-5.6865e-02, -2.6879e-02,  1.1214e-05,  9.6894e-02, -3.4499e-03],\n",
       "                       [-1.3260e-01,  5.2316e-02,  6.5022e-02, -6.2424e-02,  9.2010e-02],\n",
       "                       [ 3.6169e-02, -8.1982e-02, -3.1340e-02,  2.6578e-02, -1.2896e-02],\n",
       "                       ...,\n",
       "                       [ 1.8496e-02,  5.0213e-02, -4.0650e-02,  5.9497e-02, -8.6081e-02],\n",
       "                       [ 1.1426e-01,  3.3271e-02, -9.0838e-02,  7.1756e-03,  1.0398e-01],\n",
       "                       [-2.1491e-02,  7.3455e-02,  2.9381e-02,  1.2381e-02, -1.4010e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.1.1.weight',\n",
       "              tensor([0.9423, 0.9662, 0.9396, 0.9476, 0.9674, 0.9272, 0.9681, 0.9722, 0.9339,\n",
       "                      0.9761, 0.9349, 0.9861, 0.9671, 0.9391, 0.9457, 0.9982, 0.9010, 0.9275,\n",
       "                      0.9353, 0.9832, 0.9404, 0.9281, 0.9358, 0.9515, 0.9156, 0.9391, 0.9292,\n",
       "                      0.9614, 0.9226, 0.9436, 0.9280, 0.9120, 0.9815, 0.9537, 0.9291, 0.9343,\n",
       "                      0.9925, 0.9345, 0.9737, 0.9434, 0.9873, 0.9853, 0.9333, 0.9774, 0.9498,\n",
       "                      0.9194, 0.9493, 0.9525, 0.9345, 0.9618, 0.9711, 0.9491, 0.9519, 0.9380,\n",
       "                      0.9567, 0.9804, 0.9453, 0.9842, 0.9697, 0.9792, 0.8994, 0.9496, 0.9489,\n",
       "                      0.9191], dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.1.1.bias',\n",
       "              tensor([-1.3109e-02,  1.8005e-02, -6.5840e-03, -7.9476e-03, -4.4230e-04,\n",
       "                      -4.4252e-03, -9.3745e-03,  2.3976e-02,  1.8121e-03,  5.4741e-03,\n",
       "                       1.0906e-02,  9.0400e-03,  2.3741e-03, -1.6474e-02,  3.7379e-03,\n",
       "                       1.0767e-02, -2.5383e-02, -2.4819e-02,  2.1622e-02,  6.8772e-03,\n",
       "                      -1.7393e-02, -1.1126e-02, -2.4145e-02,  7.6955e-04, -2.1592e-02,\n",
       "                      -1.5686e-02, -1.0719e-02, -2.8384e-05, -3.7678e-03,  1.4840e-02,\n",
       "                      -3.5656e-03, -1.6408e-02, -1.0770e-02, -8.5793e-03, -2.8265e-03,\n",
       "                      -1.8730e-02,  2.9778e-02,  3.6265e-03,  1.7948e-02, -1.0905e-02,\n",
       "                       6.9440e-03, -6.7054e-03, -1.8334e-02,  1.1669e-02, -1.3875e-02,\n",
       "                      -5.9053e-03, -1.1787e-03,  1.8392e-02, -1.8350e-03,  8.8758e-03,\n",
       "                       1.0188e-02, -2.2408e-02, -4.3536e-03, -2.8781e-03, -1.5995e-02,\n",
       "                       2.6976e-02, -1.3820e-02, -2.4503e-03,  9.3554e-03, -1.0622e-03,\n",
       "                      -1.0494e-02, -5.1209e-03, -2.7442e-02, -1.5361e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.5599, -0.6813,  0.5047,  0.0202, -0.4026,  0.0520,  0.3703, -0.3439,\n",
       "                      -0.3455, -0.8571, -0.2387, -0.1952,  0.2586, -0.1220,  0.1479, -0.2297,\n",
       "                      -0.4347,  0.3835, -0.5195, -0.0291,  0.1048,  0.4773,  1.2663, -0.2231,\n",
       "                       0.0830,  0.1964, -0.1539,  0.0284, -0.2582, -0.5224,  0.1370, -0.1453,\n",
       "                      -0.3110,  0.3673, -0.7171,  0.3127,  0.3361, -0.0663, -0.6876,  0.4397,\n",
       "                      -0.1260,  0.2848, -0.3000, -0.7592, -0.0198, -0.3640, -0.0108,  0.3412,\n",
       "                       0.1658, -0.3082, -0.3016,  0.6141,  0.1885, -0.1382, -1.1476, -0.1223,\n",
       "                      -0.7389, -0.4085, -0.5790,  0.8025, -0.0469, -0.1233,  0.5507,  0.2853],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.1.1.running_var',\n",
       "              tensor([0.9067, 0.3428, 0.4494, 0.3018, 0.2833, 0.4519, 0.4343, 0.5535, 0.7867,\n",
       "                      0.5390, 0.4694, 0.3933, 0.3447, 0.4470, 0.4655, 0.2867, 1.0934, 1.0591,\n",
       "                      0.4050, 0.3376, 0.5769, 0.5339, 1.1698, 0.3003, 0.4116, 0.5572, 0.5072,\n",
       "                      0.5395, 0.5949, 0.3919, 0.6542, 0.3395, 0.3884, 0.9852, 0.5406, 0.7128,\n",
       "                      0.5391, 0.4167, 0.6062, 0.5158, 0.4401, 0.3453, 0.4030, 0.4781, 0.3605,\n",
       "                      0.5585, 0.4536, 0.4190, 0.2972, 0.7026, 0.6629, 0.8444, 0.2798, 0.4130,\n",
       "                      0.3815, 0.4689, 0.4057, 0.6268, 0.4900, 0.3708, 0.7184, 0.4737, 0.5560,\n",
       "                      0.5098], dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('4.2.convpath.0.2.0.weight',\n",
       "              tensor([[[-0.0321],\n",
       "                       [-0.1682],\n",
       "                       [ 0.0317],\n",
       "                       ...,\n",
       "                       [ 0.1145],\n",
       "                       [-0.1091],\n",
       "                       [-0.0575]],\n",
       "              \n",
       "                      [[-0.1367],\n",
       "                       [ 0.0007],\n",
       "                       [ 0.0081],\n",
       "                       ...,\n",
       "                       [-0.0289],\n",
       "                       [-0.2310],\n",
       "                       [-0.0343]],\n",
       "              \n",
       "                      [[-0.1589],\n",
       "                       [-0.1134],\n",
       "                       [ 0.3602],\n",
       "                       ...,\n",
       "                       [ 0.0616],\n",
       "                       [-0.0984],\n",
       "                       [-0.1072]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0441],\n",
       "                       [ 0.2674],\n",
       "                       [-0.1192],\n",
       "                       ...,\n",
       "                       [-0.1718],\n",
       "                       [-0.0294],\n",
       "                       [ 0.2213]],\n",
       "              \n",
       "                      [[ 0.0906],\n",
       "                       [ 0.1696],\n",
       "                       [-0.1439],\n",
       "                       ...,\n",
       "                       [-0.1461],\n",
       "                       [-0.0710],\n",
       "                       [-0.0285]],\n",
       "              \n",
       "                      [[ 0.0423],\n",
       "                       [-0.3263],\n",
       "                       [ 0.0508],\n",
       "                       ...,\n",
       "                       [-0.0360],\n",
       "                       [-0.1137],\n",
       "                       [-0.0988]]], dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.2.1.weight',\n",
       "              tensor([ 0.0042, -0.0382,  0.0169,  0.0011, -0.0347,  0.0163, -0.0213,  0.0145,\n",
       "                      -0.0151,  0.0092,  0.0006,  0.0256,  0.0126, -0.0153, -0.0065,  0.0181,\n",
       "                      -0.0318, -0.0134, -0.0193,  0.0100,  0.0104,  0.0300, -0.0208,  0.0320,\n",
       "                      -0.0220, -0.0164,  0.0122,  0.0164,  0.0200,  0.0077, -0.0025, -0.0379,\n",
       "                      -0.0076, -0.0049,  0.0416,  0.0206,  0.0034,  0.0127,  0.0054, -0.0253,\n",
       "                      -0.0110,  0.0110, -0.0207, -0.0320,  0.0231, -0.0063, -0.0082, -0.0028,\n",
       "                      -0.0250, -0.0130, -0.0179, -0.0020,  0.0167,  0.0182, -0.0031, -0.0101,\n",
       "                      -0.0054,  0.0097, -0.0141,  0.0067,  0.0051,  0.0297,  0.0026, -0.0160,\n",
       "                      -0.0171,  0.0184,  0.0098, -0.0118,  0.0307, -0.0137, -0.0050,  0.0069,\n",
       "                       0.0118, -0.0020, -0.0246, -0.0069, -0.0028,  0.0095, -0.0166,  0.0064,\n",
       "                      -0.0104, -0.0068,  0.0499, -0.0194, -0.0130, -0.0101,  0.0283,  0.0318,\n",
       "                       0.0528,  0.0088, -0.0092,  0.0177, -0.0045,  0.0023,  0.0003,  0.0174,\n",
       "                      -0.0134, -0.0217, -0.0123,  0.0074,  0.0057, -0.0140,  0.0310,  0.0282,\n",
       "                      -0.0057,  0.0180,  0.0215,  0.0147,  0.0366,  0.0044, -0.0040,  0.0090,\n",
       "                      -0.0362, -0.0171, -0.0110, -0.0152, -0.0031, -0.0073,  0.0117,  0.0077,\n",
       "                      -0.0234, -0.0219, -0.0195,  0.0271, -0.0018, -0.0014,  0.0122, -0.0163,\n",
       "                       0.0234, -0.0346,  0.0059, -0.0202,  0.0341,  0.0213,  0.0021,  0.0016,\n",
       "                      -0.0061, -0.0095,  0.0222,  0.0008, -0.0047, -0.0141, -0.0098,  0.0347,\n",
       "                      -0.0047, -0.0378, -0.0214, -0.0105,  0.0021,  0.0161,  0.0256,  0.0007,\n",
       "                      -0.0284, -0.0170, -0.0010,  0.0181,  0.0049,  0.0111, -0.0018,  0.0154,\n",
       "                      -0.0098,  0.0209, -0.0156,  0.0211,  0.0097, -0.0191, -0.0040,  0.0080,\n",
       "                       0.0059, -0.0300,  0.0013,  0.0193, -0.0073,  0.0064,  0.0120,  0.0109,\n",
       "                       0.0080,  0.0215, -0.0303, -0.0084,  0.0086, -0.0129, -0.0029, -0.0115,\n",
       "                       0.0393, -0.0093, -0.0376,  0.0521,  0.0153, -0.0145,  0.0044,  0.0058,\n",
       "                      -0.0270,  0.0194,  0.0249, -0.0024,  0.0042, -0.0095,  0.0025,  0.0011,\n",
       "                       0.0021, -0.0277,  0.0147, -0.0127,  0.0033,  0.0045, -0.0342,  0.0207,\n",
       "                       0.0100,  0.0192,  0.0058,  0.0103,  0.0002,  0.0090, -0.0087,  0.0029,\n",
       "                      -0.0103, -0.0278, -0.0128,  0.0141, -0.0035,  0.0119,  0.0036, -0.0154,\n",
       "                       0.0085,  0.0126, -0.0141, -0.0009, -0.0014, -0.0076, -0.0352,  0.0166,\n",
       "                      -0.0433,  0.0051, -0.0161,  0.0024, -0.0136, -0.0205, -0.0086,  0.0156,\n",
       "                       0.0048, -0.0023, -0.0004,  0.0185, -0.0261, -0.0085, -0.0071,  0.0134,\n",
       "                       0.0174, -0.0486, -0.0148,  0.0266, -0.0191,  0.0320, -0.0035,  0.0223],\n",
       "                     dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.2.1.bias',\n",
       "              tensor([ 2.2981e-03,  6.0355e-03,  3.0007e-02, -1.3390e-03,  1.4013e-02,\n",
       "                      -1.6159e-02, -3.2799e-03, -1.3372e-03, -1.2572e-02, -9.1693e-03,\n",
       "                      -5.5602e-03, -5.7822e-03,  1.4705e-02, -1.3795e-02,  8.6815e-03,\n",
       "                       5.6836e-03,  3.3969e-02,  6.5681e-03,  2.4544e-02, -9.3135e-04,\n",
       "                       1.7069e-03,  4.4020e-03,  6.4256e-04, -1.0262e-03,  1.7300e-03,\n",
       "                      -2.3364e-02,  3.7162e-03,  1.3636e-02,  1.1473e-02,  5.0608e-03,\n",
       "                      -8.9330e-03,  2.1448e-02, -1.1811e-02,  1.6927e-02,  1.3091e-02,\n",
       "                      -3.2098e-04, -8.9734e-03,  4.5552e-03, -1.3376e-02, -7.0448e-03,\n",
       "                       1.0680e-02, -8.3521e-03, -1.8405e-03,  1.1746e-02,  6.9080e-03,\n",
       "                      -4.2487e-03, -1.5921e-02,  8.3356e-03, -3.3936e-03, -3.0647e-03,\n",
       "                      -1.9244e-03,  3.4782e-03,  1.6608e-02,  2.8802e-02, -7.5906e-03,\n",
       "                       2.0866e-03,  2.3706e-03,  5.4979e-03, -1.7742e-02,  9.0638e-03,\n",
       "                      -7.1016e-03,  8.6566e-04, -1.9732e-02,  2.8876e-04,  4.0477e-03,\n",
       "                       1.4831e-02, -6.1769e-03,  2.3492e-02,  2.4774e-02, -1.7151e-02,\n",
       "                       1.1681e-02,  7.9894e-03,  7.3410e-03, -6.5583e-03, -4.5579e-03,\n",
       "                       1.7578e-02,  7.3620e-03, -1.8193e-02,  1.6897e-03,  1.0131e-02,\n",
       "                      -6.3668e-03,  6.6972e-04,  1.7577e-02,  4.7862e-03,  4.9707e-03,\n",
       "                      -2.2640e-02,  1.4011e-02,  1.3818e-02,  6.8424e-03, -3.7594e-03,\n",
       "                       5.8248e-03,  1.0848e-02,  1.4915e-02,  6.6864e-03,  5.0534e-03,\n",
       "                      -1.2815e-02,  1.1481e-02,  1.0703e-02,  1.3009e-02, -1.1513e-02,\n",
       "                       2.2523e-02,  1.2651e-03, -5.1943e-03, -1.3343e-02,  4.8336e-03,\n",
       "                       1.1113e-02, -1.1996e-02, -9.7674e-04,  1.7487e-02, -9.8886e-03,\n",
       "                      -1.3223e-02, -6.4504e-03,  1.3571e-02,  1.4810e-02,  1.5687e-02,\n",
       "                       8.7651e-03,  9.3772e-03,  1.1581e-02,  1.1279e-02, -6.1102e-03,\n",
       "                       1.7679e-02, -1.1416e-02,  2.0439e-03,  2.6063e-03, -8.8128e-03,\n",
       "                       1.2904e-02,  4.2038e-03,  7.4398e-03,  1.1056e-02, -6.8831e-04,\n",
       "                      -7.3310e-03,  6.1786e-03,  2.0150e-03,  5.3117e-03, -7.2624e-03,\n",
       "                      -1.6135e-02,  4.1060e-03,  2.9873e-02, -1.4422e-03, -7.6886e-03,\n",
       "                       7.2946e-04,  9.8148e-03, -9.9029e-03, -2.2951e-03, -1.5686e-02,\n",
       "                      -5.4162e-03,  4.6320e-03, -5.8741e-03,  1.2422e-02,  2.3152e-02,\n",
       "                       1.9946e-03, -1.2418e-02, -2.4738e-02,  1.7292e-02, -4.1586e-03,\n",
       "                       1.1232e-02,  9.4844e-03,  2.1819e-02, -4.1767e-03, -2.0144e-02,\n",
       "                      -9.9166e-05,  1.1130e-02, -1.1883e-02,  1.8993e-02,  1.7969e-02,\n",
       "                       1.0380e-02, -7.9747e-03,  2.1661e-02,  1.2728e-02,  2.3638e-02,\n",
       "                       1.2848e-02, -4.1754e-03, -8.3021e-03,  2.0047e-02, -1.6692e-02,\n",
       "                      -6.1638e-03,  6.3373e-03,  2.3157e-02,  1.6104e-02, -2.4939e-03,\n",
       "                      -3.7590e-03,  1.3873e-03, -9.7327e-03, -1.1150e-03,  5.9546e-03,\n",
       "                       7.6138e-03,  1.7157e-02,  3.2642e-02, -1.7507e-03,  8.1882e-03,\n",
       "                      -7.7682e-03, -1.4533e-02,  3.6442e-03, -1.7871e-02,  1.0974e-02,\n",
       "                       1.8575e-02, -4.9975e-03,  1.4283e-02,  1.2792e-02, -1.6664e-02,\n",
       "                       1.5296e-02,  3.0710e-03,  9.8463e-04,  1.6290e-02,  3.6353e-03,\n",
       "                      -5.9694e-03,  8.4527e-03, -1.6902e-02,  6.0383e-03,  1.0562e-02,\n",
       "                       6.0151e-03, -9.1413e-03,  7.7327e-03, -1.0408e-03,  1.8305e-03,\n",
       "                       1.2953e-02,  3.5994e-03,  1.0672e-02,  1.2097e-02,  1.0209e-02,\n",
       "                      -8.4629e-05, -1.0060e-02,  1.1748e-02,  7.4849e-05, -1.4349e-03,\n",
       "                       1.8271e-02,  1.0349e-02,  4.8985e-03, -2.4221e-02, -3.6036e-03,\n",
       "                      -2.4693e-03,  1.0476e-02,  2.7278e-02,  3.1265e-03, -1.8923e-03,\n",
       "                       6.9213e-03,  1.5240e-02,  6.3762e-03, -9.1332e-03,  5.0912e-03,\n",
       "                      -5.5732e-03,  4.1736e-03,  1.1687e-02,  3.5444e-03,  1.3644e-02,\n",
       "                       1.8368e-02, -1.2853e-03,  1.3878e-02, -1.0017e-02, -1.4650e-02,\n",
       "                       1.9003e-02, -1.2700e-03, -1.0338e-02,  2.2673e-02,  2.3178e-02,\n",
       "                       6.8945e-03], dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.2.1.running_mean',\n",
       "              tensor([ 2.2142e-01, -3.5158e-02,  4.7936e-01,  1.3704e-01,  1.5016e-01,\n",
       "                      -2.9301e-01,  2.8332e-01,  1.4424e-01,  2.8096e-01,  6.1163e-01,\n",
       "                       8.5292e-02,  7.7581e-02,  6.1009e-02,  1.1685e-01, -6.7240e-01,\n",
       "                      -6.9520e-04, -3.9635e-01,  8.0276e-01,  6.6967e-01, -8.1997e-01,\n",
       "                       1.6503e-01, -2.0750e-01,  4.3678e-01, -6.5098e-01,  1.7848e-01,\n",
       "                      -2.4521e-01, -3.7271e-01,  1.5257e-01,  3.0628e-01,  3.0542e-01,\n",
       "                      -2.9402e-01,  8.3692e-01,  6.5709e-02,  6.5633e-02, -3.4898e-01,\n",
       "                       4.7584e-01,  1.6067e-02,  1.6485e-01,  2.4903e-01, -4.5836e-01,\n",
       "                      -1.1768e-01, -2.3431e-01,  1.8861e-01, -2.9288e-02,  3.6511e-01,\n",
       "                      -3.2776e-01, -3.3418e-01, -2.8739e-02,  1.3645e-01,  3.3940e-01,\n",
       "                       1.6950e-01, -1.8935e-01,  1.6950e-01,  7.7983e-02,  8.8855e-02,\n",
       "                      -6.1477e-02, -2.3188e-01, -6.3246e-02, -2.6731e-01,  8.7092e-02,\n",
       "                       1.4543e-01, -4.9972e-02,  3.5225e-01, -2.4500e-01,  1.5744e-01,\n",
       "                      -1.2062e-01, -1.9639e-01,  1.0864e-01, -2.0654e-01, -1.0682e-01,\n",
       "                      -4.9675e-02, -8.4615e-02, -1.4485e-01,  6.9949e-01,  5.1589e-01,\n",
       "                      -8.8552e-02,  1.4291e-02, -1.8502e-01,  4.4828e-01, -2.1247e-01,\n",
       "                       1.6623e-01,  2.0076e-01, -3.7122e-01,  7.7382e-01,  2.8990e-01,\n",
       "                      -7.4275e-01,  5.1118e-01,  4.3443e-02, -2.5806e-02, -1.3909e-01,\n",
       "                      -2.1683e-01,  1.1638e-01,  3.9570e-02, -5.1656e-02, -3.9182e-02,\n",
       "                      -2.6096e-02, -5.1525e-01,  2.1138e-01, -1.8937e-01,  6.1392e-01,\n",
       "                       4.6584e-02, -3.5009e-01,  1.7265e-01,  1.0096e-01, -3.9140e-01,\n",
       "                      -6.0333e-01,  1.2356e-01,  1.3604e-01, -3.1294e-01,  1.1004e-01,\n",
       "                       2.2361e-01, -1.0477e-01,  1.4201e-01, -2.6361e-03, -2.4967e-01,\n",
       "                       1.2752e-01, -1.0775e-01,  9.8541e-02, -2.6598e-01, -2.1570e-01,\n",
       "                      -1.9860e-01,  1.2686e-01, -9.8351e-02,  5.9487e-01, -3.1013e-02,\n",
       "                      -8.9968e-02,  6.7673e-01, -2.0401e-01,  1.0732e-01,  2.4746e-01,\n",
       "                      -1.3224e-01,  2.6989e-01, -4.6560e-01,  7.1059e-02, -1.3566e-01,\n",
       "                       2.8899e-01, -8.2771e-02,  1.2047e-01,  1.1373e-01,  3.0030e-01,\n",
       "                      -4.7368e-01,  1.5133e-02, -3.6606e-01, -3.1214e-02,  2.0281e-01,\n",
       "                      -6.2564e-02, -7.9454e-01,  8.2024e-01, -1.1752e-01,  1.1513e-02,\n",
       "                       1.1064e-01,  3.1738e-01,  2.2243e-01, -4.2587e-02,  3.4996e-03,\n",
       "                       3.0102e-01,  1.4794e-01, -2.7961e-01, -1.5764e-01,  2.8097e-01,\n",
       "                      -2.8864e-01, -4.7957e-01, -5.0146e-02,  4.9852e-01,  4.6698e-01,\n",
       "                       3.2214e-01,  3.0504e-01,  2.9440e-01, -4.2277e-01,  1.7022e-01,\n",
       "                       6.4302e-02,  1.0283e-01,  8.1499e-02,  5.0447e-02,  4.7729e-01,\n",
       "                       6.8529e-03,  6.2631e-02,  4.5509e-01, -2.7544e-01, -2.9442e-01,\n",
       "                      -1.5363e-01,  1.5365e-01,  5.7494e-01,  3.2734e-01,  1.6687e-01,\n",
       "                       1.4306e-01,  1.1846e-01,  2.5563e-01, -5.9768e-01, -3.1768e-01,\n",
       "                       5.6654e-05, -2.2829e-01,  5.9329e-01, -3.3185e-01, -3.3549e-01,\n",
       "                      -4.2196e-02,  8.0192e-02,  2.6960e-01, -1.2091e-01,  1.0461e-01,\n",
       "                       4.3255e-01,  1.8091e-01,  4.4113e-01, -4.1657e-02, -5.0203e-01,\n",
       "                       3.5528e-02,  4.7656e-01, -1.5542e-01,  6.5555e-02, -2.3467e-01,\n",
       "                       1.7397e-01,  1.2085e-01,  2.3107e-01,  2.1652e-01,  1.5883e-01,\n",
       "                      -2.4920e-02, -1.2971e-01,  2.5491e-01,  2.0970e-01, -7.3771e-01,\n",
       "                      -4.8901e-02,  5.9636e-02,  6.8819e-02, -1.4104e-01,  9.0482e-01,\n",
       "                       2.0468e-01, -4.2534e-01, -1.5065e-01,  3.2987e-01, -2.1250e-01,\n",
       "                      -3.9264e-01, -9.6778e-02, -3.1806e-01, -1.6343e-01,  3.3466e-01,\n",
       "                      -3.8532e-01, -4.0276e-01,  2.7974e-02, -1.2858e-01, -2.5921e-01,\n",
       "                      -1.2651e-01,  1.6659e-01, -1.6267e-01, -1.4795e-01, -7.3921e-03,\n",
       "                      -1.9303e-01, -5.0223e-01,  4.1150e-01,  3.2483e-01, -4.1626e-02,\n",
       "                      -2.3209e-01, -2.6750e-01, -6.4750e-02, -3.3819e-01, -5.1727e-02,\n",
       "                      -3.8360e-01], dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.2.1.running_var',\n",
       "              tensor([0.3494, 0.3664, 0.5004, 0.2424, 0.4853, 0.2903, 0.2619, 0.3312, 0.1057,\n",
       "                      0.3090, 0.1433, 0.2842, 0.2199, 0.3126, 0.6621, 0.2775, 0.3625, 0.7359,\n",
       "                      0.3012, 0.3333, 0.2643, 0.4854, 0.2571, 0.3565, 0.4389, 0.1531, 0.3283,\n",
       "                      0.3391, 0.2246, 0.2702, 0.3921, 0.6336, 0.2376, 0.1874, 0.3359, 0.3782,\n",
       "                      0.0775, 0.3302, 0.1297, 0.7002, 0.4018, 0.0763, 0.1583, 0.6357, 0.5126,\n",
       "                      0.1717, 0.2589, 0.0645, 0.4337, 0.3108, 0.2681, 0.1602, 0.3169, 0.2280,\n",
       "                      0.1088, 0.1705, 0.1895, 0.3184, 0.2708, 0.2359, 0.0773, 0.2504, 0.2813,\n",
       "                      0.3729, 0.6203, 0.3734, 0.3693, 0.4202, 0.4217, 0.2804, 0.3392, 0.1044,\n",
       "                      0.2604, 0.5761, 0.6272, 0.1467, 0.1798, 0.1571, 0.3038, 0.1496, 0.3359,\n",
       "                      0.1670, 0.4270, 0.5396, 0.1584, 0.2921, 0.4444, 0.3492, 0.3100, 0.0724,\n",
       "                      0.3694, 0.3629, 0.4728, 0.0720, 0.0826, 0.2072, 0.5206, 0.1613, 0.4708,\n",
       "                      0.3128, 0.3138, 0.2628, 0.2690, 0.2873, 0.3417, 0.4148, 0.2431, 0.3579,\n",
       "                      0.4063, 0.0342, 0.1433, 0.4559, 0.3074, 0.4460, 0.4856, 0.1305, 0.1772,\n",
       "                      0.4879, 0.1669, 0.1863, 0.2000, 0.4973, 0.4043, 0.4526, 0.0449, 0.1972,\n",
       "                      0.3342, 0.2001, 0.2827, 0.2879, 0.0789, 0.4231, 0.5012, 0.3574, 0.0993,\n",
       "                      0.1236, 0.2986, 0.2042, 0.1935, 0.2214, 0.1848, 0.2062, 0.3228, 0.2898,\n",
       "                      0.1555, 0.6018, 0.2927, 0.5353, 0.0708, 0.2957, 0.3032, 0.0721, 0.4335,\n",
       "                      0.2709, 0.0514, 0.5275, 0.1669, 0.1499, 0.1675, 0.2188, 0.3065, 0.3264,\n",
       "                      0.1616, 0.3622, 0.2976, 0.3722, 0.4573, 0.1545, 0.1959, 0.6024, 0.0432,\n",
       "                      0.3219, 0.1022, 0.0954, 0.4639, 0.3849, 0.3074, 0.5008, 0.3763, 0.1747,\n",
       "                      0.1534, 0.2606, 0.4120, 0.2213, 0.3451, 0.1596, 0.6406, 0.3423, 0.5384,\n",
       "                      0.4377, 0.0987, 0.1373, 0.2969, 0.4314, 0.3624, 0.3267, 0.2923, 0.2659,\n",
       "                      0.1215, 0.0513, 0.1512, 0.2044, 0.4376, 0.2054, 0.3051, 0.2576, 0.2613,\n",
       "                      0.0522, 0.1541, 0.3856, 0.1245, 0.2651, 0.0817, 0.1799, 0.0465, 0.0550,\n",
       "                      0.2209, 0.2880, 0.4932, 0.4446, 0.0395, 0.2346, 0.1144, 0.3688, 0.3867,\n",
       "                      0.3351, 0.3443, 0.0668, 0.3079, 0.3591, 0.5042, 0.5272, 0.5843, 0.2058,\n",
       "                      0.3878, 0.2597, 0.2097, 0.2800, 0.3690, 0.1457, 0.1344, 0.1432, 0.3141,\n",
       "                      0.1558, 0.3444, 0.1713, 0.2369, 0.2696, 0.1473, 0.3800, 0.2939, 0.3554,\n",
       "                      0.3341, 0.4072, 0.1675, 0.4181], dtype=torch.float64)),\n",
       "             ('4.2.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.0.convs.0.0.weight',\n",
       "              tensor([[[-1.6193e-02],\n",
       "                       [ 1.4339e-01],\n",
       "                       [-3.9059e-02],\n",
       "                       ...,\n",
       "                       [-9.8477e-02],\n",
       "                       [-4.0168e-03],\n",
       "                       [ 1.2020e-01]],\n",
       "              \n",
       "                      [[-1.2132e-01],\n",
       "                       [-2.2085e-02],\n",
       "                       [ 4.3886e-02],\n",
       "                       ...,\n",
       "                       [-6.4113e-02],\n",
       "                       [ 1.9117e-02],\n",
       "                       [ 7.6345e-02]],\n",
       "              \n",
       "                      [[-6.9510e-02],\n",
       "                       [ 2.0369e-01],\n",
       "                       [-6.5022e-02],\n",
       "                       ...,\n",
       "                       [-4.0309e-02],\n",
       "                       [-1.4086e-01],\n",
       "                       [-1.7633e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 5.3615e-02],\n",
       "                       [-2.1643e-01],\n",
       "                       [ 1.3548e-04],\n",
       "                       ...,\n",
       "                       [ 4.9714e-02],\n",
       "                       [ 1.3369e-01],\n",
       "                       [ 5.6184e-02]],\n",
       "              \n",
       "                      [[ 6.0763e-02],\n",
       "                       [ 1.3545e-01],\n",
       "                       [-1.2473e-01],\n",
       "                       ...,\n",
       "                       [ 8.8573e-02],\n",
       "                       [-6.8880e-02],\n",
       "                       [ 8.5210e-02]],\n",
       "              \n",
       "                      [[-3.9655e-02],\n",
       "                       [ 2.7945e-02],\n",
       "                       [-1.0454e-02],\n",
       "                       ...,\n",
       "                       [-6.4360e-02],\n",
       "                       [ 1.6623e-01],\n",
       "                       [ 3.4773e-02]]], dtype=torch.float64)),\n",
       "             ('5.0.convs.0.1.weight',\n",
       "              tensor([0.9612, 0.9548, 0.9841, 0.8988, 0.9710, 0.9649, 0.9483, 0.9637, 0.9605,\n",
       "                      0.9574, 0.9840, 0.9386, 0.9626, 0.9424, 0.9501, 0.9514, 0.9488, 0.9807,\n",
       "                      0.9543, 0.9809, 0.9639, 0.9642, 0.9732, 0.9402, 0.9635, 0.9702, 0.9569,\n",
       "                      0.9386, 0.9480, 0.9715, 0.9638, 0.9893, 0.9654, 0.9769, 0.9565, 0.9727,\n",
       "                      0.9721, 0.9553, 0.9668, 0.9733, 0.9509, 0.9796, 0.9436, 0.9823, 0.9745,\n",
       "                      0.9718, 0.9768, 0.9696, 0.9571, 0.9752, 0.9738, 0.9686, 0.9642, 0.9599,\n",
       "                      0.9588, 0.9526, 0.9548, 0.9389, 0.9473, 0.9790, 0.9661, 0.9730, 0.9692,\n",
       "                      0.9792], dtype=torch.float64)),\n",
       "             ('5.0.convs.0.1.bias',\n",
       "              tensor([ 5.6125e-03, -1.3392e-02, -2.4821e-03, -2.0347e-02,  2.0468e-03,\n",
       "                       1.7624e-02, -2.3028e-02,  9.1761e-03, -7.5666e-03,  4.8939e-03,\n",
       "                       1.9081e-02, -7.0951e-03, -1.3071e-02,  2.9753e-03,  1.1719e-02,\n",
       "                      -4.5798e-04,  2.9463e-03, -1.8419e-02, -8.9741e-03, -9.1919e-03,\n",
       "                      -1.7555e-02,  1.6522e-03,  5.3877e-03, -1.7726e-02,  7.6360e-03,\n",
       "                      -7.0222e-05, -1.4356e-02, -8.8763e-03, -1.1436e-02,  1.9395e-02,\n",
       "                      -8.7408e-03,  2.0512e-03, -9.0275e-03, -4.8991e-03, -6.0910e-03,\n",
       "                      -1.6335e-02,  2.5532e-02, -6.9656e-04, -8.3465e-04, -2.2590e-02,\n",
       "                      -6.0248e-04,  1.3854e-02, -7.5309e-03, -1.2159e-02, -3.7264e-03,\n",
       "                       9.6112e-03, -6.0236e-03, -5.1005e-04, -9.7465e-04,  2.2000e-02,\n",
       "                      -1.7667e-03,  7.9870e-03,  1.7791e-02,  1.1027e-02, -2.3230e-03,\n",
       "                      -5.3583e-03,  1.2229e-02, -1.5513e-02,  5.9525e-03, -4.3905e-03,\n",
       "                       1.1867e-02, -9.7494e-03,  2.1736e-02, -1.7782e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convs.0.1.running_mean',\n",
       "              tensor([ 0.5184,  0.9086,  0.5741, -0.3299, -0.2047,  0.6258, -0.1037, -0.2019,\n",
       "                       0.1684, -0.5944, -0.1803, -0.2233, -0.1019,  0.2525, -0.4697,  0.5870,\n",
       "                       0.5860, -0.2809,  0.5662, -0.1987,  0.1073,  0.2324, -0.2151,  0.6797,\n",
       "                      -0.1383,  0.7590,  0.5590, -0.1111,  0.4753, -1.0378,  0.1913,  0.0987,\n",
       "                      -0.1458,  0.2429,  0.3652, -0.1003,  0.1869,  0.2412,  0.0066, -0.2072,\n",
       "                      -0.2106,  0.0900, -0.0302,  0.1881,  0.1006, -0.1501, -0.4074,  0.2443,\n",
       "                      -0.3751, -0.5529, -0.0377, -0.3751, -0.2253, -0.1928, -0.1997, -0.1209,\n",
       "                       0.0624, -0.0180, -0.0045,  0.8905, -0.4463, -0.0650, -0.0415, -0.1543],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convs.0.1.running_var',\n",
       "              tensor([0.3204, 2.5917, 0.3345, 2.0139, 0.6740, 1.3483, 0.4906, 0.7597, 0.3381,\n",
       "                      0.3165, 0.7291, 0.6836, 0.6696, 0.3006, 0.7443, 0.3772, 0.6199, 0.3920,\n",
       "                      0.7972, 0.5937, 0.3762, 0.2632, 0.6530, 0.4224, 0.3020, 0.8255, 0.3730,\n",
       "                      0.3612, 0.7546, 0.4975, 0.3082, 0.3788, 0.2388, 0.3157, 0.7938, 0.3169,\n",
       "                      0.3124, 0.4118, 0.4253, 0.3924, 0.4320, 0.3413, 0.4494, 0.4278, 0.3284,\n",
       "                      0.4717, 0.2275, 0.3343, 0.7079, 0.4269, 0.3834, 0.3875, 0.5796, 0.2694,\n",
       "                      0.7276, 0.3019, 0.8488, 0.6803, 0.8303, 0.9048, 0.2939, 0.3141, 0.3811,\n",
       "                      0.4750], dtype=torch.float64)),\n",
       "             ('5.0.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.0.convs.1.0.weight',\n",
       "              tensor([[[-0.0448,  0.0357,  0.0548, -0.0142,  0.1158],\n",
       "                       [ 0.0934, -0.1324,  0.0485,  0.1063, -0.0690],\n",
       "                       [ 0.0348,  0.0770,  0.0354,  0.0389,  0.1044],\n",
       "                       ...,\n",
       "                       [ 0.0129,  0.0111,  0.0293,  0.0092,  0.0146],\n",
       "                       [-0.0357,  0.0855,  0.0461,  0.0151, -0.0019],\n",
       "                       [-0.0180,  0.0213, -0.1474,  0.0530,  0.0009]],\n",
       "              \n",
       "                      [[-0.0665, -0.0622, -0.0062, -0.0767, -0.0284],\n",
       "                       [ 0.0491, -0.0174, -0.0600,  0.1014, -0.0745],\n",
       "                       [-0.0595, -0.0391,  0.0708, -0.0292,  0.0896],\n",
       "                       ...,\n",
       "                       [-0.1708, -0.0805, -0.0025,  0.0614, -0.0696],\n",
       "                       [-0.0256, -0.0556,  0.0378,  0.0639, -0.0411],\n",
       "                       [-0.0295,  0.0299,  0.0753,  0.0765, -0.1001]],\n",
       "              \n",
       "                      [[ 0.0183, -0.0517,  0.0201, -0.0020,  0.0108],\n",
       "                       [-0.0481, -0.0907, -0.0531,  0.1573, -0.1443],\n",
       "                       [ 0.0512, -0.1478, -0.0303,  0.0015, -0.0726],\n",
       "                       ...,\n",
       "                       [-0.1179,  0.0856,  0.0878, -0.0592, -0.0033],\n",
       "                       [-0.0419,  0.0198,  0.1016, -0.0036, -0.0275],\n",
       "                       [-0.0559, -0.0811, -0.0427,  0.0792, -0.0459]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0166,  0.0453, -0.0142,  0.0750,  0.0723],\n",
       "                       [-0.2292,  0.0008, -0.0853, -0.0225,  0.0227],\n",
       "                       [ 0.0515, -0.0216, -0.0811,  0.1569,  0.0159],\n",
       "                       ...,\n",
       "                       [-0.0326,  0.0589,  0.0680, -0.0147, -0.0036],\n",
       "                       [-0.1047, -0.0337,  0.0281, -0.0784, -0.0937],\n",
       "                       [ 0.0115, -0.0332,  0.0809,  0.0160, -0.1283]],\n",
       "              \n",
       "                      [[-0.0337,  0.0346, -0.1508,  0.0597,  0.0074],\n",
       "                       [ 0.0734,  0.0282,  0.1071,  0.1366, -0.1050],\n",
       "                       [-0.0843, -0.1389, -0.0381,  0.0454, -0.0269],\n",
       "                       ...,\n",
       "                       [ 0.1217, -0.0091,  0.0604, -0.0917, -0.0258],\n",
       "                       [-0.0517, -0.0253, -0.0178, -0.0871, -0.0597],\n",
       "                       [-0.0837, -0.0421, -0.1083, -0.0742, -0.0314]],\n",
       "              \n",
       "                      [[ 0.0878, -0.0014,  0.1778,  0.1395,  0.1412],\n",
       "                       [ 0.0589, -0.0589,  0.0340,  0.0512,  0.0596],\n",
       "                       [ 0.0050,  0.0306, -0.0325, -0.0347,  0.0138],\n",
       "                       ...,\n",
       "                       [-0.0679,  0.0070, -0.1278,  0.0789,  0.0429],\n",
       "                       [-0.1009, -0.0607,  0.0052,  0.0444,  0.0069],\n",
       "                       [ 0.0751,  0.1174, -0.0734,  0.0062, -0.0279]]], dtype=torch.float64)),\n",
       "             ('5.0.convs.1.1.weight',\n",
       "              tensor([0.9565, 0.9391, 0.9045, 0.9485, 0.9415, 0.9428, 0.9382, 0.9497, 0.9464,\n",
       "                      0.9364, 0.9579, 0.9576, 0.9852, 0.9574, 0.9402, 0.9473, 0.9477, 0.9478,\n",
       "                      0.9712, 0.9601, 0.9582, 0.9614, 0.9464, 0.9525, 0.9482, 0.9219, 1.0309,\n",
       "                      0.9569, 0.9351, 0.9673, 0.9350, 0.9412, 0.9330, 0.9449, 0.9436, 0.9318,\n",
       "                      0.9627, 0.9794, 0.9616, 0.9936, 0.9476, 0.9665, 0.9529, 0.9749, 0.9508,\n",
       "                      0.9544, 0.9533, 0.9385, 0.9492, 0.9172, 0.9516, 0.9565, 0.9428, 0.9215,\n",
       "                      0.9392, 0.9704, 0.9175, 0.9455, 0.9135, 0.9463, 0.9786, 0.9444, 0.9730,\n",
       "                      0.9493], dtype=torch.float64)),\n",
       "             ('5.0.convs.1.1.bias',\n",
       "              tensor([-0.0023,  0.0058, -0.0468, -0.0162, -0.0238,  0.0217,  0.0097,  0.0063,\n",
       "                      -0.0032,  0.0149,  0.0054,  0.0074,  0.0038, -0.0165,  0.0023, -0.0145,\n",
       "                      -0.0116,  0.0011,  0.0079, -0.0088, -0.0146, -0.0201, -0.0031, -0.0242,\n",
       "                      -0.0147, -0.0113,  0.0183, -0.0150,  0.0066, -0.0048, -0.0028, -0.0090,\n",
       "                       0.0058, -0.0044, -0.0322,  0.0027,  0.0091,  0.0210,  0.0085, -0.0055,\n",
       "                      -0.0094, -0.0055, -0.0022, -0.0003, -0.0067, -0.0125, -0.0013, -0.0047,\n",
       "                       0.0028, -0.0208, -0.0030,  0.0088, -0.0048, -0.0154, -0.0130, -0.0073,\n",
       "                      -0.0218, -0.0217,  0.0074, -0.0140, -0.0033,  0.0028,  0.0058,  0.0053],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convs.1.1.running_mean',\n",
       "              tensor([ 0.0477,  0.3339, -0.6848, -0.7439,  0.0176, -0.1585, -0.1547,  0.2427,\n",
       "                      -0.6721, -0.4381,  0.2546, -0.6044, -0.3044,  0.3928, -0.0617,  0.2110,\n",
       "                      -0.0649,  0.2224,  0.1284,  0.0156, -0.1217,  1.0216,  0.2337, -0.1605,\n",
       "                       0.2719, -0.7570,  0.3986,  0.1255, -0.1715, -0.5823, -0.8623,  0.1904,\n",
       "                      -0.9609, -0.2791, -0.4669, -0.0794, -0.5670, -0.3526,  0.0971, -0.0235,\n",
       "                      -0.3574,  0.3678,  0.6019, -0.0559, -0.6992, -0.1028, -0.3507, -0.2092,\n",
       "                      -0.0458, -0.3558, -0.1932, -0.7560, -0.3781, -0.0841, -0.3318, -0.0981,\n",
       "                      -1.0976,  0.0216, -0.3573,  0.7427,  0.2718, -0.0029, -0.3226,  0.4599],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convs.1.1.running_var',\n",
       "              tensor([0.3984, 0.8305, 0.9275, 0.5564, 0.4883, 0.7233, 0.8415, 0.6282, 1.0628,\n",
       "                      0.9651, 0.5015, 0.5064, 0.4811, 0.7187, 0.5319, 0.4739, 0.3040, 0.8534,\n",
       "                      0.5360, 0.7670, 0.3634, 0.3463, 0.8624, 0.4742, 0.5167, 1.3145, 0.4158,\n",
       "                      0.4635, 0.4657, 0.5020, 0.8875, 1.0591, 0.8111, 0.5291, 0.8666, 0.5639,\n",
       "                      0.9157, 0.5246, 0.6922, 0.5077, 0.5403, 0.5968, 0.7983, 0.4020, 0.4601,\n",
       "                      0.8705, 0.4634, 0.4453, 0.5179, 0.5025, 0.5840, 0.8594, 0.5312, 1.0335,\n",
       "                      0.3983, 0.2820, 1.7544, 0.4584, 0.6945, 1.3581, 0.6393, 0.5620, 0.3810,\n",
       "                      1.0840], dtype=torch.float64)),\n",
       "             ('5.0.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.0.convs.2.0.weight',\n",
       "              tensor([[[-0.3310],\n",
       "                       [ 0.3236],\n",
       "                       [ 0.1253],\n",
       "                       ...,\n",
       "                       [-0.0280],\n",
       "                       [ 0.0421],\n",
       "                       [ 0.1964]],\n",
       "              \n",
       "                      [[ 0.0201],\n",
       "                       [ 0.1515],\n",
       "                       [-0.1185],\n",
       "                       ...,\n",
       "                       [-0.1034],\n",
       "                       [-0.0609],\n",
       "                       [-0.1538]],\n",
       "              \n",
       "                      [[-0.0711],\n",
       "                       [-0.0257],\n",
       "                       [-0.0068],\n",
       "                       ...,\n",
       "                       [ 0.0867],\n",
       "                       [ 0.3698],\n",
       "                       [ 0.0336]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.4292],\n",
       "                       [ 0.1787],\n",
       "                       [ 0.0046],\n",
       "                       ...,\n",
       "                       [-0.1697],\n",
       "                       [ 0.0488],\n",
       "                       [ 0.0309]],\n",
       "              \n",
       "                      [[ 0.0051],\n",
       "                       [ 0.1778],\n",
       "                       [-0.0798],\n",
       "                       ...,\n",
       "                       [-0.0313],\n",
       "                       [ 0.0990],\n",
       "                       [ 0.0843]],\n",
       "              \n",
       "                      [[ 0.0025],\n",
       "                       [ 0.0516],\n",
       "                       [ 0.0786],\n",
       "                       ...,\n",
       "                       [ 0.0079],\n",
       "                       [ 0.0168],\n",
       "                       [-0.0138]]], dtype=torch.float64)),\n",
       "             ('5.0.convs.2.1.weight',\n",
       "              tensor([ 4.5432e-02,  8.2374e-03, -1.5719e-02, -4.9548e-03, -2.0598e-02,\n",
       "                       6.6469e-04, -9.6774e-04,  9.0064e-03,  1.5192e-02,  9.9131e-03,\n",
       "                      -4.8245e-03,  5.7220e-03,  5.8915e-03, -1.1790e-02,  5.4477e-03,\n",
       "                       3.1207e-02,  5.7109e-05, -1.6854e-02, -2.8326e-02,  5.8081e-03,\n",
       "                       1.1387e-02, -9.0507e-03,  2.5466e-02,  1.7752e-02,  1.3490e-02,\n",
       "                       9.0892e-03,  3.4559e-02, -2.9228e-03, -5.3453e-03, -6.2003e-03,\n",
       "                      -5.3539e-03, -2.9028e-03, -1.8126e-03, -1.6295e-02,  4.1412e-03,\n",
       "                      -6.2688e-04, -5.6938e-03, -1.5535e-03, -2.3495e-02, -2.2071e-02,\n",
       "                      -2.0392e-02, -1.3473e-02, -1.7483e-02, -1.8589e-02,  4.6320e-03,\n",
       "                       3.0106e-03,  1.4963e-02, -1.9754e-02, -2.3475e-02, -1.2424e-02,\n",
       "                       9.3329e-03,  1.5508e-02,  6.2950e-03,  1.9211e-03,  6.5618e-03,\n",
       "                       3.4101e-02,  3.8279e-03,  4.6036e-02,  1.4749e-02, -9.1731e-03,\n",
       "                       2.6285e-02,  5.0391e-02, -9.7101e-03,  1.5282e-03,  1.1053e-03,\n",
       "                      -4.9476e-02,  1.0740e-03, -3.1611e-02,  3.9014e-02,  1.8904e-02,\n",
       "                      -2.7035e-02, -1.6833e-02, -6.0979e-03, -2.7552e-02,  1.1287e-02,\n",
       "                       4.8214e-02,  6.1762e-03,  2.2982e-02, -2.2863e-02, -8.1260e-03,\n",
       "                       7.8631e-03, -1.3750e-02, -1.7340e-02,  2.1449e-02, -1.1954e-02,\n",
       "                       6.8070e-03,  3.2363e-02, -1.0328e-02, -3.1706e-02,  1.5025e-02,\n",
       "                      -1.3259e-02,  9.3129e-03, -2.0461e-02, -1.0609e-02,  6.5652e-03,\n",
       "                       1.7502e-02, -8.9404e-04,  1.1590e-02, -1.7037e-02, -2.8837e-02,\n",
       "                       1.7892e-02, -1.8687e-02, -9.4611e-03,  2.1540e-02,  1.9293e-02,\n",
       "                       7.5645e-03,  6.8044e-03,  1.6201e-02,  3.9086e-02, -5.4396e-03,\n",
       "                       1.5254e-02,  1.5711e-02,  1.7957e-03,  2.9064e-02, -5.9782e-03,\n",
       "                      -3.1120e-02, -6.6782e-03, -5.5766e-03, -6.2555e-03,  3.8383e-02,\n",
       "                      -1.6606e-02,  2.0551e-02, -6.7405e-03, -4.4888e-03, -5.6200e-03,\n",
       "                      -1.0353e-02,  7.0228e-03,  5.0408e-03,  1.5941e-02, -2.5716e-02,\n",
       "                       2.3396e-02,  1.9308e-02,  1.2756e-03,  9.9343e-03,  2.9471e-04,\n",
       "                       4.8807e-03,  1.2608e-02,  2.4726e-02, -2.0498e-02,  6.5127e-03,\n",
       "                       1.4461e-02, -1.6298e-02, -1.5903e-02,  1.0929e-02,  7.4992e-03,\n",
       "                      -1.1129e-02,  3.0909e-02, -2.1679e-02,  1.2998e-02,  1.5501e-02,\n",
       "                      -3.1060e-02,  8.4022e-03, -8.4538e-03, -3.6138e-02,  9.2362e-03,\n",
       "                       1.3818e-02,  1.8956e-02,  3.9033e-02,  1.2070e-02,  2.9674e-03,\n",
       "                      -2.7902e-02,  2.3445e-02, -5.6416e-03, -1.3342e-02, -5.7199e-02,\n",
       "                      -3.8147e-02, -4.6818e-03,  2.6068e-02,  3.5507e-02,  3.5087e-02,\n",
       "                      -1.4904e-02,  1.9209e-02, -2.1884e-02,  7.0171e-03,  6.9575e-03,\n",
       "                      -6.8105e-03,  2.1477e-02,  1.7064e-02,  1.8206e-03,  7.9294e-03,\n",
       "                       8.1526e-04,  2.1088e-02,  3.1611e-03,  1.1310e-02,  7.3817e-03,\n",
       "                       1.0088e-02, -9.3567e-03, -1.2680e-02,  1.0357e-03,  9.2277e-03,\n",
       "                       6.2108e-03, -2.3192e-02,  4.1703e-02,  6.3829e-04, -9.2145e-03,\n",
       "                       9.7588e-03, -1.3011e-02,  1.3356e-02,  1.2092e-02, -9.9384e-03,\n",
       "                      -1.0873e-02, -1.2937e-02, -2.0260e-02,  5.1795e-03, -3.6689e-05,\n",
       "                       9.3429e-03, -3.4157e-02, -4.8186e-03, -1.5909e-02,  3.6942e-02,\n",
       "                      -2.3008e-02,  8.2630e-03,  8.8086e-03, -2.8541e-02, -3.7564e-02,\n",
       "                      -2.2907e-02,  1.3554e-02,  6.1275e-03, -1.7052e-02,  9.4038e-03,\n",
       "                      -1.0323e-02,  2.2399e-02, -2.1424e-02,  9.6430e-03, -2.2842e-02,\n",
       "                      -1.3418e-02, -1.6006e-02, -9.8159e-03,  3.5593e-03, -2.0933e-02,\n",
       "                       1.7416e-02,  2.2278e-04,  2.7365e-02,  1.3456e-02, -1.5015e-02,\n",
       "                       5.9859e-03,  7.6125e-03,  4.3295e-02, -9.2453e-03, -2.4580e-02,\n",
       "                      -2.2613e-02, -9.7458e-03, -3.7189e-03,  7.1470e-03,  1.8052e-02,\n",
       "                       4.6106e-03,  2.6930e-02, -3.1685e-02,  2.4028e-02,  4.4258e-02,\n",
       "                       5.5194e-03,  4.2683e-03, -8.4135e-04, -5.8526e-03,  3.9372e-04,\n",
       "                      -6.5046e-03], dtype=torch.float64)),\n",
       "             ('5.0.convs.2.1.bias',\n",
       "              tensor([ 0.0147,  0.0019,  0.0248,  0.0023,  0.0104, -0.0129,  0.0106,  0.0041,\n",
       "                       0.0123, -0.0117, -0.0039, -0.0093,  0.0158, -0.0151,  0.0087,  0.0090,\n",
       "                       0.0216,  0.0056,  0.0216, -0.0027,  0.0026,  0.0003,  0.0007, -0.0023,\n",
       "                       0.0043, -0.0234, -0.0001,  0.0187,  0.0063,  0.0042, -0.0084,  0.0168,\n",
       "                      -0.0126,  0.0168,  0.0145, -0.0035,  0.0110,  0.0234, -0.0116, -0.0024,\n",
       "                       0.0069, -0.0050, -0.0064,  0.0064,  0.0166, -0.0026, -0.0066,  0.0072,\n",
       "                      -0.0052, -0.0051, -0.0071,  0.0042,  0.0180,  0.0199, -0.0114, -0.0067,\n",
       "                       0.0016,  0.0087, -0.0015,  0.0088, -0.0108,  0.0059, -0.0107,  0.0130,\n",
       "                       0.0001,  0.0061, -0.0082,  0.0180,  0.0096, -0.0143,  0.0103,  0.0107,\n",
       "                       0.0110, -0.0081,  0.0038,  0.0179,  0.0101, -0.0209,  0.0060,  0.0116,\n",
       "                       0.0165,  0.0011,  0.0169,  0.0082,  0.0017, -0.0260,  0.0068,  0.0093,\n",
       "                       0.0077, -0.0044,  0.0057,  0.0212,  0.0131,  0.0048,  0.0048, -0.0112,\n",
       "                       0.0086,  0.0083,  0.0181, -0.0104,  0.0230, -0.0007, -0.0088, -0.0175,\n",
       "                       0.0050,  0.0063, -0.0169,  0.0044,  0.0128, -0.0092, -0.0120, -0.0033,\n",
       "                       0.0137,  0.0091,  0.0077,  0.0099,  0.0098,  0.0126,  0.0123, -0.0108,\n",
       "                       0.0124,  0.0150,  0.0042, -0.0024, -0.0090,  0.0110,  0.0080,  0.0065,\n",
       "                       0.0071,  0.0107,  0.0099,  0.0040,  0.0068,  0.0097, -0.0073, -0.0176,\n",
       "                       0.0038,  0.0198, -0.0062, -0.0085, -0.0029,  0.0076, -0.0107,  0.0167,\n",
       "                      -0.0117, -0.0051,  0.0038, -0.0024,  0.0119,  0.0047,  0.0073,  0.0181,\n",
       "                       0.0163,  0.0290, -0.0083,  0.0289,  0.0102,  0.0221,  0.0003, -0.0191,\n",
       "                       0.0022,  0.0023, -0.0035,  0.0192,  0.0207,  0.0069, -0.0086,  0.0206,\n",
       "                       0.0262,  0.0222,  0.0127,  0.0030, -0.0015,  0.0209, -0.0156,  0.0001,\n",
       "                       0.0083,  0.0261,  0.0103, -0.0065, -0.0061,  0.0223, -0.0122, -0.0047,\n",
       "                       0.0114,  0.0086,  0.0171,  0.0178, -0.0020,  0.0015, -0.0109,  0.0040,\n",
       "                       0.0038, -0.0180,  0.0099,  0.0100, -0.0089,  0.0062,  0.0132, -0.0176,\n",
       "                       0.0148,  0.0021,  0.0154,  0.0218,  0.0019, -0.0089,  0.0131, -0.0097,\n",
       "                       0.0047,  0.0082,  0.0084,  0.0183,  0.0072, -0.0002,  0.0043,  0.0127,\n",
       "                       0.0021,  0.0143,  0.0097,  0.0028, -0.0016, -0.0043,  0.0163,  0.0027,\n",
       "                      -0.0002,  0.0133,  0.0044,  0.0037, -0.0259, -0.0095, -0.0066,  0.0090,\n",
       "                       0.0130,  0.0009,  0.0075,  0.0054,  0.0131,  0.0010, -0.0011,  0.0096,\n",
       "                      -0.0033,  0.0074,  0.0115,  0.0002,  0.0110,  0.0138,  0.0092,  0.0165,\n",
       "                      -0.0060, -0.0140,  0.0225,  0.0094, -0.0086,  0.0257,  0.0225,  0.0067],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convs.2.1.running_mean',\n",
       "              tensor([ 0.3068,  0.2695,  0.0776,  0.4544, -0.5410, -0.1558, -0.0646,  0.0819,\n",
       "                       0.1777, -0.0867, -0.3025, -0.1962,  0.1169,  0.2370,  0.7053, -0.5405,\n",
       "                       0.0034, -0.3865,  0.3976, -0.3870, -0.0672,  0.1951,  0.0920,  0.0077,\n",
       "                      -0.9116, -0.1621, -0.1072,  0.0929,  0.1542, -0.0344,  0.1501,  0.4266,\n",
       "                       0.0249, -0.1023,  0.3372, -0.1489,  0.0219,  0.1186,  0.1759,  0.1288,\n",
       "                      -0.3005, -0.1422,  0.1998, -0.1750,  0.3566,  0.0135, -0.2763, -0.3626,\n",
       "                       0.5121,  0.2125,  0.1645,  0.0601, -0.1028, -0.1112, -0.1833,  0.7054,\n",
       "                      -0.0551, -0.4247,  0.5521, -0.0291,  0.0439, -0.0471,  0.4200,  0.0063,\n",
       "                       0.1596, -0.0735, -0.1166, -0.3348, -0.4262,  0.4699, -0.3280, -0.3540,\n",
       "                      -0.2045, -0.1846, -0.2668, -0.0506,  0.0786, -0.0189, -0.3077,  0.0081,\n",
       "                       0.3476, -0.0838,  0.6027,  0.3881, -0.3849, -0.3255, -0.1446, -0.4063,\n",
       "                       0.1342, -0.3307, -0.4945,  0.1297,  0.2587,  0.2305,  0.3377,  0.1558,\n",
       "                      -0.0023,  0.0300, -0.3815, -0.0295,  0.3856, -0.7704,  0.3440, -0.3619,\n",
       "                       0.4816, -0.4101, -0.4015,  0.7764, -0.0247, -0.1041,  0.1263,  0.0931,\n",
       "                      -0.0343,  0.0951, -0.2040,  0.1746, -0.0692,  0.1366,  0.1881,  0.5210,\n",
       "                       0.3116, -0.0848,  0.0143,  0.0965, -0.1428,  0.9029,  0.4707, -0.3619,\n",
       "                       0.2360,  0.7910,  0.3600, -0.2074,  0.2835, -0.1444, -0.0809,  0.2841,\n",
       "                       0.2771, -0.1851, -0.3721, -0.0889,  0.0468,  0.1656, -0.2878, -0.3578,\n",
       "                      -0.1800, -0.0792,  0.2197,  0.1899, -0.1574, -0.1568, -0.5712, -0.2454,\n",
       "                       0.2578,  0.1261,  0.5874, -0.2140, -0.2545, -0.3070,  0.0912,  0.0138,\n",
       "                      -0.1409, -0.4229, -0.2494,  0.2161, -0.0541, -0.1352,  0.8806, -0.3823,\n",
       "                       0.0772, -0.2723, -0.7044, -0.2436,  0.2162,  0.2671,  0.2230, -0.0402,\n",
       "                      -0.5560,  0.3005,  0.4770,  0.3008,  0.0926,  0.2380, -0.2429,  0.5389,\n",
       "                       0.1737, -0.3125, -0.1936, -0.2913, -0.2511,  0.1921,  0.1616,  0.3423,\n",
       "                      -0.3590, -0.3210, -0.0790,  0.0239, -0.0143, -0.0903, -0.1981,  0.1557,\n",
       "                      -0.1358,  0.1610,  0.1323, -0.4181, -0.0943, -0.2987,  0.2982,  0.0648,\n",
       "                      -0.0996,  0.5974,  0.0950, -0.1230, -0.0476,  0.0067, -0.4163,  0.1145,\n",
       "                      -0.1748,  0.2158, -0.2162,  0.1237, -0.5088, -0.1113, -0.0739,  0.3186,\n",
       "                       0.3751,  0.1848, -0.0621, -0.0179,  0.4022, -0.1096,  0.1666, -0.1335,\n",
       "                       0.3498,  0.1680, -0.0143,  0.3994, -0.2059,  0.6061, -0.3071,  0.6025,\n",
       "                      -0.1455,  0.4524, -0.3702,  0.0679,  0.0569, -0.2014,  0.4530, -0.3718,\n",
       "                       0.4393,  0.4545,  0.2058,  0.4067, -0.2951, -0.3567,  0.4521, -0.2681],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convs.2.1.running_var',\n",
       "              tensor([0.3334, 0.3404, 0.2847, 0.3704, 0.2191, 0.1789, 0.1649, 0.2393, 0.1431,\n",
       "                      0.3602, 0.2409, 0.2308, 0.1086, 0.1773, 0.3765, 0.2929, 0.0813, 0.2021,\n",
       "                      0.2694, 0.2881, 0.1589, 0.2418, 0.3362, 0.1613, 0.4866, 0.1868, 0.7097,\n",
       "                      0.1278, 0.1285, 0.1494, 0.4516, 0.2757, 0.0509, 0.4885, 0.2519, 0.1884,\n",
       "                      0.1574, 0.1246, 0.1770, 0.3626, 0.1592, 0.1799, 0.0908, 0.3595, 0.1920,\n",
       "                      0.2939, 0.2280, 0.1191, 0.3692, 0.1552, 0.1142, 0.3339, 0.0900, 0.1522,\n",
       "                      0.1729, 0.2698, 0.0717, 0.5296, 0.4614, 0.2400, 0.3325, 0.4285, 0.2641,\n",
       "                      0.0666, 0.3094, 0.3163, 0.1979, 0.2632, 0.5348, 0.4275, 0.4411, 0.2881,\n",
       "                      0.1755, 0.4168, 0.4319, 0.1434, 0.1121, 0.3188, 0.3364, 0.1073, 0.1203,\n",
       "                      0.2313, 0.5583, 0.3230, 0.2108, 0.4882, 0.2437, 0.3819, 0.3257, 0.1917,\n",
       "                      0.6383, 0.2345, 0.2769, 0.3201, 0.1597, 0.3811, 0.2429, 0.2413, 0.3381,\n",
       "                      0.4766, 0.4067, 0.3343, 0.1261, 0.3040, 0.4294, 0.2879, 0.2403, 0.7014,\n",
       "                      0.3242, 0.1885, 0.0931, 0.2430, 0.2595, 0.2747, 0.3854, 0.3228, 0.2377,\n",
       "                      0.2319, 0.2176, 0.3460, 0.1750, 0.2648, 0.4689, 0.4535, 0.1968, 0.4173,\n",
       "                      0.4954, 0.1388, 0.1205, 0.4649, 0.3517, 0.1911, 0.2667, 0.0929, 0.0899,\n",
       "                      0.2467, 0.1912, 0.1356, 0.2567, 0.0727, 0.2482, 0.3662, 0.2881, 0.3829,\n",
       "                      0.2374, 0.2518, 0.1963, 0.3951, 0.3888, 0.2068, 0.5858, 0.2579, 0.2151,\n",
       "                      0.2863, 0.2732, 0.2658, 0.4147, 0.4745, 0.1460, 0.2259, 0.3147, 0.3983,\n",
       "                      0.1162, 0.2417, 0.2921, 0.1843, 0.3671, 0.3669, 0.3830, 0.4908, 0.3018,\n",
       "                      0.2282, 0.1474, 0.2132, 0.5300, 0.3596, 0.3045, 0.2747, 0.2099, 0.1851,\n",
       "                      0.1375, 0.4052, 0.5132, 0.6296, 0.1777, 0.2655, 0.3792, 0.2351, 0.2398,\n",
       "                      0.2488, 0.0875, 0.4107, 0.3884, 0.2651, 0.1312, 0.2653, 0.2992, 0.2450,\n",
       "                      0.3128, 0.0604, 0.3273, 0.2133, 0.2701, 0.4080, 0.1049, 0.2305, 0.4332,\n",
       "                      0.0846, 0.2594, 0.4454, 0.1783, 0.2998, 0.1100, 0.3025, 0.2767, 0.1550,\n",
       "                      0.3629, 0.1222, 0.2588, 0.3282, 0.2285, 0.1372, 0.1351, 0.2323, 0.3535,\n",
       "                      0.1460, 0.3820, 0.2632, 0.3601, 0.3634, 0.4341, 0.1619, 0.2836, 0.3729,\n",
       "                      0.1953, 0.2570, 0.2572, 0.3025, 0.3721, 0.2270, 0.4455, 0.4097, 0.3909,\n",
       "                      0.2061, 0.1899, 0.1344, 0.3193, 0.4055, 0.2876, 0.4387, 0.2327, 0.2360,\n",
       "                      0.0765, 0.3957, 0.1651, 0.1184], dtype=torch.float64)),\n",
       "             ('5.0.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.0.convpath.0.0.0.weight',\n",
       "              tensor([[[-1.6193e-02],\n",
       "                       [ 1.4339e-01],\n",
       "                       [-3.9059e-02],\n",
       "                       ...,\n",
       "                       [-9.8477e-02],\n",
       "                       [-4.0168e-03],\n",
       "                       [ 1.2020e-01]],\n",
       "              \n",
       "                      [[-1.2132e-01],\n",
       "                       [-2.2085e-02],\n",
       "                       [ 4.3886e-02],\n",
       "                       ...,\n",
       "                       [-6.4113e-02],\n",
       "                       [ 1.9117e-02],\n",
       "                       [ 7.6345e-02]],\n",
       "              \n",
       "                      [[-6.9510e-02],\n",
       "                       [ 2.0369e-01],\n",
       "                       [-6.5022e-02],\n",
       "                       ...,\n",
       "                       [-4.0309e-02],\n",
       "                       [-1.4086e-01],\n",
       "                       [-1.7633e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 5.3615e-02],\n",
       "                       [-2.1643e-01],\n",
       "                       [ 1.3548e-04],\n",
       "                       ...,\n",
       "                       [ 4.9714e-02],\n",
       "                       [ 1.3369e-01],\n",
       "                       [ 5.6184e-02]],\n",
       "              \n",
       "                      [[ 6.0763e-02],\n",
       "                       [ 1.3545e-01],\n",
       "                       [-1.2473e-01],\n",
       "                       ...,\n",
       "                       [ 8.8573e-02],\n",
       "                       [-6.8880e-02],\n",
       "                       [ 8.5210e-02]],\n",
       "              \n",
       "                      [[-3.9655e-02],\n",
       "                       [ 2.7945e-02],\n",
       "                       [-1.0454e-02],\n",
       "                       ...,\n",
       "                       [-6.4360e-02],\n",
       "                       [ 1.6623e-01],\n",
       "                       [ 3.4773e-02]]], dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.0.1.weight',\n",
       "              tensor([0.9612, 0.9548, 0.9841, 0.8988, 0.9710, 0.9649, 0.9483, 0.9637, 0.9605,\n",
       "                      0.9574, 0.9840, 0.9386, 0.9626, 0.9424, 0.9501, 0.9514, 0.9488, 0.9807,\n",
       "                      0.9543, 0.9809, 0.9639, 0.9642, 0.9732, 0.9402, 0.9635, 0.9702, 0.9569,\n",
       "                      0.9386, 0.9480, 0.9715, 0.9638, 0.9893, 0.9654, 0.9769, 0.9565, 0.9727,\n",
       "                      0.9721, 0.9553, 0.9668, 0.9733, 0.9509, 0.9796, 0.9436, 0.9823, 0.9745,\n",
       "                      0.9718, 0.9768, 0.9696, 0.9571, 0.9752, 0.9738, 0.9686, 0.9642, 0.9599,\n",
       "                      0.9588, 0.9526, 0.9548, 0.9389, 0.9473, 0.9790, 0.9661, 0.9730, 0.9692,\n",
       "                      0.9792], dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.0.1.bias',\n",
       "              tensor([ 5.6125e-03, -1.3392e-02, -2.4821e-03, -2.0347e-02,  2.0468e-03,\n",
       "                       1.7624e-02, -2.3028e-02,  9.1761e-03, -7.5666e-03,  4.8939e-03,\n",
       "                       1.9081e-02, -7.0951e-03, -1.3071e-02,  2.9753e-03,  1.1719e-02,\n",
       "                      -4.5798e-04,  2.9463e-03, -1.8419e-02, -8.9741e-03, -9.1919e-03,\n",
       "                      -1.7555e-02,  1.6522e-03,  5.3877e-03, -1.7726e-02,  7.6360e-03,\n",
       "                      -7.0222e-05, -1.4356e-02, -8.8763e-03, -1.1436e-02,  1.9395e-02,\n",
       "                      -8.7408e-03,  2.0512e-03, -9.0275e-03, -4.8991e-03, -6.0910e-03,\n",
       "                      -1.6335e-02,  2.5532e-02, -6.9656e-04, -8.3465e-04, -2.2590e-02,\n",
       "                      -6.0248e-04,  1.3854e-02, -7.5309e-03, -1.2159e-02, -3.7264e-03,\n",
       "                       9.6112e-03, -6.0236e-03, -5.1005e-04, -9.7465e-04,  2.2000e-02,\n",
       "                      -1.7667e-03,  7.9870e-03,  1.7791e-02,  1.1027e-02, -2.3230e-03,\n",
       "                      -5.3583e-03,  1.2229e-02, -1.5513e-02,  5.9525e-03, -4.3905e-03,\n",
       "                       1.1867e-02, -9.7494e-03,  2.1736e-02, -1.7782e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.5184,  0.9086,  0.5741, -0.3299, -0.2047,  0.6258, -0.1037, -0.2019,\n",
       "                       0.1684, -0.5944, -0.1803, -0.2233, -0.1019,  0.2525, -0.4697,  0.5870,\n",
       "                       0.5860, -0.2809,  0.5662, -0.1987,  0.1073,  0.2324, -0.2151,  0.6797,\n",
       "                      -0.1383,  0.7590,  0.5590, -0.1111,  0.4753, -1.0378,  0.1913,  0.0987,\n",
       "                      -0.1458,  0.2429,  0.3652, -0.1003,  0.1869,  0.2412,  0.0066, -0.2072,\n",
       "                      -0.2106,  0.0900, -0.0302,  0.1881,  0.1006, -0.1501, -0.4074,  0.2443,\n",
       "                      -0.3751, -0.5529, -0.0377, -0.3751, -0.2253, -0.1928, -0.1997, -0.1209,\n",
       "                       0.0624, -0.0180, -0.0045,  0.8905, -0.4463, -0.0650, -0.0415, -0.1543],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.0.1.running_var',\n",
       "              tensor([0.3204, 2.5917, 0.3345, 2.0139, 0.6740, 1.3483, 0.4906, 0.7597, 0.3381,\n",
       "                      0.3165, 0.7291, 0.6836, 0.6696, 0.3006, 0.7443, 0.3772, 0.6199, 0.3920,\n",
       "                      0.7972, 0.5937, 0.3762, 0.2632, 0.6530, 0.4224, 0.3020, 0.8255, 0.3730,\n",
       "                      0.3612, 0.7546, 0.4975, 0.3082, 0.3788, 0.2388, 0.3157, 0.7938, 0.3169,\n",
       "                      0.3124, 0.4118, 0.4253, 0.3924, 0.4320, 0.3413, 0.4494, 0.4278, 0.3284,\n",
       "                      0.4717, 0.2275, 0.3343, 0.7079, 0.4269, 0.3834, 0.3875, 0.5796, 0.2694,\n",
       "                      0.7276, 0.3019, 0.8488, 0.6803, 0.8303, 0.9048, 0.2939, 0.3141, 0.3811,\n",
       "                      0.4750], dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.0.convpath.0.1.0.weight',\n",
       "              tensor([[[-0.0448,  0.0357,  0.0548, -0.0142,  0.1158],\n",
       "                       [ 0.0934, -0.1324,  0.0485,  0.1063, -0.0690],\n",
       "                       [ 0.0348,  0.0770,  0.0354,  0.0389,  0.1044],\n",
       "                       ...,\n",
       "                       [ 0.0129,  0.0111,  0.0293,  0.0092,  0.0146],\n",
       "                       [-0.0357,  0.0855,  0.0461,  0.0151, -0.0019],\n",
       "                       [-0.0180,  0.0213, -0.1474,  0.0530,  0.0009]],\n",
       "              \n",
       "                      [[-0.0665, -0.0622, -0.0062, -0.0767, -0.0284],\n",
       "                       [ 0.0491, -0.0174, -0.0600,  0.1014, -0.0745],\n",
       "                       [-0.0595, -0.0391,  0.0708, -0.0292,  0.0896],\n",
       "                       ...,\n",
       "                       [-0.1708, -0.0805, -0.0025,  0.0614, -0.0696],\n",
       "                       [-0.0256, -0.0556,  0.0378,  0.0639, -0.0411],\n",
       "                       [-0.0295,  0.0299,  0.0753,  0.0765, -0.1001]],\n",
       "              \n",
       "                      [[ 0.0183, -0.0517,  0.0201, -0.0020,  0.0108],\n",
       "                       [-0.0481, -0.0907, -0.0531,  0.1573, -0.1443],\n",
       "                       [ 0.0512, -0.1478, -0.0303,  0.0015, -0.0726],\n",
       "                       ...,\n",
       "                       [-0.1179,  0.0856,  0.0878, -0.0592, -0.0033],\n",
       "                       [-0.0419,  0.0198,  0.1016, -0.0036, -0.0275],\n",
       "                       [-0.0559, -0.0811, -0.0427,  0.0792, -0.0459]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0166,  0.0453, -0.0142,  0.0750,  0.0723],\n",
       "                       [-0.2292,  0.0008, -0.0853, -0.0225,  0.0227],\n",
       "                       [ 0.0515, -0.0216, -0.0811,  0.1569,  0.0159],\n",
       "                       ...,\n",
       "                       [-0.0326,  0.0589,  0.0680, -0.0147, -0.0036],\n",
       "                       [-0.1047, -0.0337,  0.0281, -0.0784, -0.0937],\n",
       "                       [ 0.0115, -0.0332,  0.0809,  0.0160, -0.1283]],\n",
       "              \n",
       "                      [[-0.0337,  0.0346, -0.1508,  0.0597,  0.0074],\n",
       "                       [ 0.0734,  0.0282,  0.1071,  0.1366, -0.1050],\n",
       "                       [-0.0843, -0.1389, -0.0381,  0.0454, -0.0269],\n",
       "                       ...,\n",
       "                       [ 0.1217, -0.0091,  0.0604, -0.0917, -0.0258],\n",
       "                       [-0.0517, -0.0253, -0.0178, -0.0871, -0.0597],\n",
       "                       [-0.0837, -0.0421, -0.1083, -0.0742, -0.0314]],\n",
       "              \n",
       "                      [[ 0.0878, -0.0014,  0.1778,  0.1395,  0.1412],\n",
       "                       [ 0.0589, -0.0589,  0.0340,  0.0512,  0.0596],\n",
       "                       [ 0.0050,  0.0306, -0.0325, -0.0347,  0.0138],\n",
       "                       ...,\n",
       "                       [-0.0679,  0.0070, -0.1278,  0.0789,  0.0429],\n",
       "                       [-0.1009, -0.0607,  0.0052,  0.0444,  0.0069],\n",
       "                       [ 0.0751,  0.1174, -0.0734,  0.0062, -0.0279]]], dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.1.1.weight',\n",
       "              tensor([0.9565, 0.9391, 0.9045, 0.9485, 0.9415, 0.9428, 0.9382, 0.9497, 0.9464,\n",
       "                      0.9364, 0.9579, 0.9576, 0.9852, 0.9574, 0.9402, 0.9473, 0.9477, 0.9478,\n",
       "                      0.9712, 0.9601, 0.9582, 0.9614, 0.9464, 0.9525, 0.9482, 0.9219, 1.0309,\n",
       "                      0.9569, 0.9351, 0.9673, 0.9350, 0.9412, 0.9330, 0.9449, 0.9436, 0.9318,\n",
       "                      0.9627, 0.9794, 0.9616, 0.9936, 0.9476, 0.9665, 0.9529, 0.9749, 0.9508,\n",
       "                      0.9544, 0.9533, 0.9385, 0.9492, 0.9172, 0.9516, 0.9565, 0.9428, 0.9215,\n",
       "                      0.9392, 0.9704, 0.9175, 0.9455, 0.9135, 0.9463, 0.9786, 0.9444, 0.9730,\n",
       "                      0.9493], dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.1.1.bias',\n",
       "              tensor([-0.0023,  0.0058, -0.0468, -0.0162, -0.0238,  0.0217,  0.0097,  0.0063,\n",
       "                      -0.0032,  0.0149,  0.0054,  0.0074,  0.0038, -0.0165,  0.0023, -0.0145,\n",
       "                      -0.0116,  0.0011,  0.0079, -0.0088, -0.0146, -0.0201, -0.0031, -0.0242,\n",
       "                      -0.0147, -0.0113,  0.0183, -0.0150,  0.0066, -0.0048, -0.0028, -0.0090,\n",
       "                       0.0058, -0.0044, -0.0322,  0.0027,  0.0091,  0.0210,  0.0085, -0.0055,\n",
       "                      -0.0094, -0.0055, -0.0022, -0.0003, -0.0067, -0.0125, -0.0013, -0.0047,\n",
       "                       0.0028, -0.0208, -0.0030,  0.0088, -0.0048, -0.0154, -0.0130, -0.0073,\n",
       "                      -0.0218, -0.0217,  0.0074, -0.0140, -0.0033,  0.0028,  0.0058,  0.0053],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.0477,  0.3339, -0.6848, -0.7439,  0.0176, -0.1585, -0.1547,  0.2427,\n",
       "                      -0.6721, -0.4381,  0.2546, -0.6044, -0.3044,  0.3928, -0.0617,  0.2110,\n",
       "                      -0.0649,  0.2224,  0.1284,  0.0156, -0.1217,  1.0216,  0.2337, -0.1605,\n",
       "                       0.2719, -0.7570,  0.3986,  0.1255, -0.1715, -0.5823, -0.8623,  0.1904,\n",
       "                      -0.9609, -0.2791, -0.4669, -0.0794, -0.5670, -0.3526,  0.0971, -0.0235,\n",
       "                      -0.3574,  0.3678,  0.6019, -0.0559, -0.6992, -0.1028, -0.3507, -0.2092,\n",
       "                      -0.0458, -0.3558, -0.1932, -0.7560, -0.3781, -0.0841, -0.3318, -0.0981,\n",
       "                      -1.0976,  0.0216, -0.3573,  0.7427,  0.2718, -0.0029, -0.3226,  0.4599],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.1.1.running_var',\n",
       "              tensor([0.3984, 0.8305, 0.9275, 0.5564, 0.4883, 0.7233, 0.8415, 0.6282, 1.0628,\n",
       "                      0.9651, 0.5015, 0.5064, 0.4811, 0.7187, 0.5319, 0.4739, 0.3040, 0.8534,\n",
       "                      0.5360, 0.7670, 0.3634, 0.3463, 0.8624, 0.4742, 0.5167, 1.3145, 0.4158,\n",
       "                      0.4635, 0.4657, 0.5020, 0.8875, 1.0591, 0.8111, 0.5291, 0.8666, 0.5639,\n",
       "                      0.9157, 0.5246, 0.6922, 0.5077, 0.5403, 0.5968, 0.7983, 0.4020, 0.4601,\n",
       "                      0.8705, 0.4634, 0.4453, 0.5179, 0.5025, 0.5840, 0.8594, 0.5312, 1.0335,\n",
       "                      0.3983, 0.2820, 1.7544, 0.4584, 0.6945, 1.3581, 0.6393, 0.5620, 0.3810,\n",
       "                      1.0840], dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.0.convpath.0.2.0.weight',\n",
       "              tensor([[[-0.3310],\n",
       "                       [ 0.3236],\n",
       "                       [ 0.1253],\n",
       "                       ...,\n",
       "                       [-0.0280],\n",
       "                       [ 0.0421],\n",
       "                       [ 0.1964]],\n",
       "              \n",
       "                      [[ 0.0201],\n",
       "                       [ 0.1515],\n",
       "                       [-0.1185],\n",
       "                       ...,\n",
       "                       [-0.1034],\n",
       "                       [-0.0609],\n",
       "                       [-0.1538]],\n",
       "              \n",
       "                      [[-0.0711],\n",
       "                       [-0.0257],\n",
       "                       [-0.0068],\n",
       "                       ...,\n",
       "                       [ 0.0867],\n",
       "                       [ 0.3698],\n",
       "                       [ 0.0336]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.4292],\n",
       "                       [ 0.1787],\n",
       "                       [ 0.0046],\n",
       "                       ...,\n",
       "                       [-0.1697],\n",
       "                       [ 0.0488],\n",
       "                       [ 0.0309]],\n",
       "              \n",
       "                      [[ 0.0051],\n",
       "                       [ 0.1778],\n",
       "                       [-0.0798],\n",
       "                       ...,\n",
       "                       [-0.0313],\n",
       "                       [ 0.0990],\n",
       "                       [ 0.0843]],\n",
       "              \n",
       "                      [[ 0.0025],\n",
       "                       [ 0.0516],\n",
       "                       [ 0.0786],\n",
       "                       ...,\n",
       "                       [ 0.0079],\n",
       "                       [ 0.0168],\n",
       "                       [-0.0138]]], dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.2.1.weight',\n",
       "              tensor([ 4.5432e-02,  8.2374e-03, -1.5719e-02, -4.9548e-03, -2.0598e-02,\n",
       "                       6.6469e-04, -9.6774e-04,  9.0064e-03,  1.5192e-02,  9.9131e-03,\n",
       "                      -4.8245e-03,  5.7220e-03,  5.8915e-03, -1.1790e-02,  5.4477e-03,\n",
       "                       3.1207e-02,  5.7109e-05, -1.6854e-02, -2.8326e-02,  5.8081e-03,\n",
       "                       1.1387e-02, -9.0507e-03,  2.5466e-02,  1.7752e-02,  1.3490e-02,\n",
       "                       9.0892e-03,  3.4559e-02, -2.9228e-03, -5.3453e-03, -6.2003e-03,\n",
       "                      -5.3539e-03, -2.9028e-03, -1.8126e-03, -1.6295e-02,  4.1412e-03,\n",
       "                      -6.2688e-04, -5.6938e-03, -1.5535e-03, -2.3495e-02, -2.2071e-02,\n",
       "                      -2.0392e-02, -1.3473e-02, -1.7483e-02, -1.8589e-02,  4.6320e-03,\n",
       "                       3.0106e-03,  1.4963e-02, -1.9754e-02, -2.3475e-02, -1.2424e-02,\n",
       "                       9.3329e-03,  1.5508e-02,  6.2950e-03,  1.9211e-03,  6.5618e-03,\n",
       "                       3.4101e-02,  3.8279e-03,  4.6036e-02,  1.4749e-02, -9.1731e-03,\n",
       "                       2.6285e-02,  5.0391e-02, -9.7101e-03,  1.5282e-03,  1.1053e-03,\n",
       "                      -4.9476e-02,  1.0740e-03, -3.1611e-02,  3.9014e-02,  1.8904e-02,\n",
       "                      -2.7035e-02, -1.6833e-02, -6.0979e-03, -2.7552e-02,  1.1287e-02,\n",
       "                       4.8214e-02,  6.1762e-03,  2.2982e-02, -2.2863e-02, -8.1260e-03,\n",
       "                       7.8631e-03, -1.3750e-02, -1.7340e-02,  2.1449e-02, -1.1954e-02,\n",
       "                       6.8070e-03,  3.2363e-02, -1.0328e-02, -3.1706e-02,  1.5025e-02,\n",
       "                      -1.3259e-02,  9.3129e-03, -2.0461e-02, -1.0609e-02,  6.5652e-03,\n",
       "                       1.7502e-02, -8.9404e-04,  1.1590e-02, -1.7037e-02, -2.8837e-02,\n",
       "                       1.7892e-02, -1.8687e-02, -9.4611e-03,  2.1540e-02,  1.9293e-02,\n",
       "                       7.5645e-03,  6.8044e-03,  1.6201e-02,  3.9086e-02, -5.4396e-03,\n",
       "                       1.5254e-02,  1.5711e-02,  1.7957e-03,  2.9064e-02, -5.9782e-03,\n",
       "                      -3.1120e-02, -6.6782e-03, -5.5766e-03, -6.2555e-03,  3.8383e-02,\n",
       "                      -1.6606e-02,  2.0551e-02, -6.7405e-03, -4.4888e-03, -5.6200e-03,\n",
       "                      -1.0353e-02,  7.0228e-03,  5.0408e-03,  1.5941e-02, -2.5716e-02,\n",
       "                       2.3396e-02,  1.9308e-02,  1.2756e-03,  9.9343e-03,  2.9471e-04,\n",
       "                       4.8807e-03,  1.2608e-02,  2.4726e-02, -2.0498e-02,  6.5127e-03,\n",
       "                       1.4461e-02, -1.6298e-02, -1.5903e-02,  1.0929e-02,  7.4992e-03,\n",
       "                      -1.1129e-02,  3.0909e-02, -2.1679e-02,  1.2998e-02,  1.5501e-02,\n",
       "                      -3.1060e-02,  8.4022e-03, -8.4538e-03, -3.6138e-02,  9.2362e-03,\n",
       "                       1.3818e-02,  1.8956e-02,  3.9033e-02,  1.2070e-02,  2.9674e-03,\n",
       "                      -2.7902e-02,  2.3445e-02, -5.6416e-03, -1.3342e-02, -5.7199e-02,\n",
       "                      -3.8147e-02, -4.6818e-03,  2.6068e-02,  3.5507e-02,  3.5087e-02,\n",
       "                      -1.4904e-02,  1.9209e-02, -2.1884e-02,  7.0171e-03,  6.9575e-03,\n",
       "                      -6.8105e-03,  2.1477e-02,  1.7064e-02,  1.8206e-03,  7.9294e-03,\n",
       "                       8.1526e-04,  2.1088e-02,  3.1611e-03,  1.1310e-02,  7.3817e-03,\n",
       "                       1.0088e-02, -9.3567e-03, -1.2680e-02,  1.0357e-03,  9.2277e-03,\n",
       "                       6.2108e-03, -2.3192e-02,  4.1703e-02,  6.3829e-04, -9.2145e-03,\n",
       "                       9.7588e-03, -1.3011e-02,  1.3356e-02,  1.2092e-02, -9.9384e-03,\n",
       "                      -1.0873e-02, -1.2937e-02, -2.0260e-02,  5.1795e-03, -3.6689e-05,\n",
       "                       9.3429e-03, -3.4157e-02, -4.8186e-03, -1.5909e-02,  3.6942e-02,\n",
       "                      -2.3008e-02,  8.2630e-03,  8.8086e-03, -2.8541e-02, -3.7564e-02,\n",
       "                      -2.2907e-02,  1.3554e-02,  6.1275e-03, -1.7052e-02,  9.4038e-03,\n",
       "                      -1.0323e-02,  2.2399e-02, -2.1424e-02,  9.6430e-03, -2.2842e-02,\n",
       "                      -1.3418e-02, -1.6006e-02, -9.8159e-03,  3.5593e-03, -2.0933e-02,\n",
       "                       1.7416e-02,  2.2278e-04,  2.7365e-02,  1.3456e-02, -1.5015e-02,\n",
       "                       5.9859e-03,  7.6125e-03,  4.3295e-02, -9.2453e-03, -2.4580e-02,\n",
       "                      -2.2613e-02, -9.7458e-03, -3.7189e-03,  7.1470e-03,  1.8052e-02,\n",
       "                       4.6106e-03,  2.6930e-02, -3.1685e-02,  2.4028e-02,  4.4258e-02,\n",
       "                       5.5194e-03,  4.2683e-03, -8.4135e-04, -5.8526e-03,  3.9372e-04,\n",
       "                      -6.5046e-03], dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.2.1.bias',\n",
       "              tensor([ 0.0147,  0.0019,  0.0248,  0.0023,  0.0104, -0.0129,  0.0106,  0.0041,\n",
       "                       0.0123, -0.0117, -0.0039, -0.0093,  0.0158, -0.0151,  0.0087,  0.0090,\n",
       "                       0.0216,  0.0056,  0.0216, -0.0027,  0.0026,  0.0003,  0.0007, -0.0023,\n",
       "                       0.0043, -0.0234, -0.0001,  0.0187,  0.0063,  0.0042, -0.0084,  0.0168,\n",
       "                      -0.0126,  0.0168,  0.0145, -0.0035,  0.0110,  0.0234, -0.0116, -0.0024,\n",
       "                       0.0069, -0.0050, -0.0064,  0.0064,  0.0166, -0.0026, -0.0066,  0.0072,\n",
       "                      -0.0052, -0.0051, -0.0071,  0.0042,  0.0180,  0.0199, -0.0114, -0.0067,\n",
       "                       0.0016,  0.0087, -0.0015,  0.0088, -0.0108,  0.0059, -0.0107,  0.0130,\n",
       "                       0.0001,  0.0061, -0.0082,  0.0180,  0.0096, -0.0143,  0.0103,  0.0107,\n",
       "                       0.0110, -0.0081,  0.0038,  0.0179,  0.0101, -0.0209,  0.0060,  0.0116,\n",
       "                       0.0165,  0.0011,  0.0169,  0.0082,  0.0017, -0.0260,  0.0068,  0.0093,\n",
       "                       0.0077, -0.0044,  0.0057,  0.0212,  0.0131,  0.0048,  0.0048, -0.0112,\n",
       "                       0.0086,  0.0083,  0.0181, -0.0104,  0.0230, -0.0007, -0.0088, -0.0175,\n",
       "                       0.0050,  0.0063, -0.0169,  0.0044,  0.0128, -0.0092, -0.0120, -0.0033,\n",
       "                       0.0137,  0.0091,  0.0077,  0.0099,  0.0098,  0.0126,  0.0123, -0.0108,\n",
       "                       0.0124,  0.0150,  0.0042, -0.0024, -0.0090,  0.0110,  0.0080,  0.0065,\n",
       "                       0.0071,  0.0107,  0.0099,  0.0040,  0.0068,  0.0097, -0.0073, -0.0176,\n",
       "                       0.0038,  0.0198, -0.0062, -0.0085, -0.0029,  0.0076, -0.0107,  0.0167,\n",
       "                      -0.0117, -0.0051,  0.0038, -0.0024,  0.0119,  0.0047,  0.0073,  0.0181,\n",
       "                       0.0163,  0.0290, -0.0083,  0.0289,  0.0102,  0.0221,  0.0003, -0.0191,\n",
       "                       0.0022,  0.0023, -0.0035,  0.0192,  0.0207,  0.0069, -0.0086,  0.0206,\n",
       "                       0.0262,  0.0222,  0.0127,  0.0030, -0.0015,  0.0209, -0.0156,  0.0001,\n",
       "                       0.0083,  0.0261,  0.0103, -0.0065, -0.0061,  0.0223, -0.0122, -0.0047,\n",
       "                       0.0114,  0.0086,  0.0171,  0.0178, -0.0020,  0.0015, -0.0109,  0.0040,\n",
       "                       0.0038, -0.0180,  0.0099,  0.0100, -0.0089,  0.0062,  0.0132, -0.0176,\n",
       "                       0.0148,  0.0021,  0.0154,  0.0218,  0.0019, -0.0089,  0.0131, -0.0097,\n",
       "                       0.0047,  0.0082,  0.0084,  0.0183,  0.0072, -0.0002,  0.0043,  0.0127,\n",
       "                       0.0021,  0.0143,  0.0097,  0.0028, -0.0016, -0.0043,  0.0163,  0.0027,\n",
       "                      -0.0002,  0.0133,  0.0044,  0.0037, -0.0259, -0.0095, -0.0066,  0.0090,\n",
       "                       0.0130,  0.0009,  0.0075,  0.0054,  0.0131,  0.0010, -0.0011,  0.0096,\n",
       "                      -0.0033,  0.0074,  0.0115,  0.0002,  0.0110,  0.0138,  0.0092,  0.0165,\n",
       "                      -0.0060, -0.0140,  0.0225,  0.0094, -0.0086,  0.0257,  0.0225,  0.0067],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.2.1.running_mean',\n",
       "              tensor([ 0.3068,  0.2695,  0.0776,  0.4544, -0.5410, -0.1558, -0.0646,  0.0819,\n",
       "                       0.1777, -0.0867, -0.3025, -0.1962,  0.1169,  0.2370,  0.7053, -0.5405,\n",
       "                       0.0034, -0.3865,  0.3976, -0.3870, -0.0672,  0.1951,  0.0920,  0.0077,\n",
       "                      -0.9116, -0.1621, -0.1072,  0.0929,  0.1542, -0.0344,  0.1501,  0.4266,\n",
       "                       0.0249, -0.1023,  0.3372, -0.1489,  0.0219,  0.1186,  0.1759,  0.1288,\n",
       "                      -0.3005, -0.1422,  0.1998, -0.1750,  0.3566,  0.0135, -0.2763, -0.3626,\n",
       "                       0.5121,  0.2125,  0.1645,  0.0601, -0.1028, -0.1112, -0.1833,  0.7054,\n",
       "                      -0.0551, -0.4247,  0.5521, -0.0291,  0.0439, -0.0471,  0.4200,  0.0063,\n",
       "                       0.1596, -0.0735, -0.1166, -0.3348, -0.4262,  0.4699, -0.3280, -0.3540,\n",
       "                      -0.2045, -0.1846, -0.2668, -0.0506,  0.0786, -0.0189, -0.3077,  0.0081,\n",
       "                       0.3476, -0.0838,  0.6027,  0.3881, -0.3849, -0.3255, -0.1446, -0.4063,\n",
       "                       0.1342, -0.3307, -0.4945,  0.1297,  0.2587,  0.2305,  0.3377,  0.1558,\n",
       "                      -0.0023,  0.0300, -0.3815, -0.0295,  0.3856, -0.7704,  0.3440, -0.3619,\n",
       "                       0.4816, -0.4101, -0.4015,  0.7764, -0.0247, -0.1041,  0.1263,  0.0931,\n",
       "                      -0.0343,  0.0951, -0.2040,  0.1746, -0.0692,  0.1366,  0.1881,  0.5210,\n",
       "                       0.3116, -0.0848,  0.0143,  0.0965, -0.1428,  0.9029,  0.4707, -0.3619,\n",
       "                       0.2360,  0.7910,  0.3600, -0.2074,  0.2835, -0.1444, -0.0809,  0.2841,\n",
       "                       0.2771, -0.1851, -0.3721, -0.0889,  0.0468,  0.1656, -0.2878, -0.3578,\n",
       "                      -0.1800, -0.0792,  0.2197,  0.1899, -0.1574, -0.1568, -0.5712, -0.2454,\n",
       "                       0.2578,  0.1261,  0.5874, -0.2140, -0.2545, -0.3070,  0.0912,  0.0138,\n",
       "                      -0.1409, -0.4229, -0.2494,  0.2161, -0.0541, -0.1352,  0.8806, -0.3823,\n",
       "                       0.0772, -0.2723, -0.7044, -0.2436,  0.2162,  0.2671,  0.2230, -0.0402,\n",
       "                      -0.5560,  0.3005,  0.4770,  0.3008,  0.0926,  0.2380, -0.2429,  0.5389,\n",
       "                       0.1737, -0.3125, -0.1936, -0.2913, -0.2511,  0.1921,  0.1616,  0.3423,\n",
       "                      -0.3590, -0.3210, -0.0790,  0.0239, -0.0143, -0.0903, -0.1981,  0.1557,\n",
       "                      -0.1358,  0.1610,  0.1323, -0.4181, -0.0943, -0.2987,  0.2982,  0.0648,\n",
       "                      -0.0996,  0.5974,  0.0950, -0.1230, -0.0476,  0.0067, -0.4163,  0.1145,\n",
       "                      -0.1748,  0.2158, -0.2162,  0.1237, -0.5088, -0.1113, -0.0739,  0.3186,\n",
       "                       0.3751,  0.1848, -0.0621, -0.0179,  0.4022, -0.1096,  0.1666, -0.1335,\n",
       "                       0.3498,  0.1680, -0.0143,  0.3994, -0.2059,  0.6061, -0.3071,  0.6025,\n",
       "                      -0.1455,  0.4524, -0.3702,  0.0679,  0.0569, -0.2014,  0.4530, -0.3718,\n",
       "                       0.4393,  0.4545,  0.2058,  0.4067, -0.2951, -0.3567,  0.4521, -0.2681],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.2.1.running_var',\n",
       "              tensor([0.3334, 0.3404, 0.2847, 0.3704, 0.2191, 0.1789, 0.1649, 0.2393, 0.1431,\n",
       "                      0.3602, 0.2409, 0.2308, 0.1086, 0.1773, 0.3765, 0.2929, 0.0813, 0.2021,\n",
       "                      0.2694, 0.2881, 0.1589, 0.2418, 0.3362, 0.1613, 0.4866, 0.1868, 0.7097,\n",
       "                      0.1278, 0.1285, 0.1494, 0.4516, 0.2757, 0.0509, 0.4885, 0.2519, 0.1884,\n",
       "                      0.1574, 0.1246, 0.1770, 0.3626, 0.1592, 0.1799, 0.0908, 0.3595, 0.1920,\n",
       "                      0.2939, 0.2280, 0.1191, 0.3692, 0.1552, 0.1142, 0.3339, 0.0900, 0.1522,\n",
       "                      0.1729, 0.2698, 0.0717, 0.5296, 0.4614, 0.2400, 0.3325, 0.4285, 0.2641,\n",
       "                      0.0666, 0.3094, 0.3163, 0.1979, 0.2632, 0.5348, 0.4275, 0.4411, 0.2881,\n",
       "                      0.1755, 0.4168, 0.4319, 0.1434, 0.1121, 0.3188, 0.3364, 0.1073, 0.1203,\n",
       "                      0.2313, 0.5583, 0.3230, 0.2108, 0.4882, 0.2437, 0.3819, 0.3257, 0.1917,\n",
       "                      0.6383, 0.2345, 0.2769, 0.3201, 0.1597, 0.3811, 0.2429, 0.2413, 0.3381,\n",
       "                      0.4766, 0.4067, 0.3343, 0.1261, 0.3040, 0.4294, 0.2879, 0.2403, 0.7014,\n",
       "                      0.3242, 0.1885, 0.0931, 0.2430, 0.2595, 0.2747, 0.3854, 0.3228, 0.2377,\n",
       "                      0.2319, 0.2176, 0.3460, 0.1750, 0.2648, 0.4689, 0.4535, 0.1968, 0.4173,\n",
       "                      0.4954, 0.1388, 0.1205, 0.4649, 0.3517, 0.1911, 0.2667, 0.0929, 0.0899,\n",
       "                      0.2467, 0.1912, 0.1356, 0.2567, 0.0727, 0.2482, 0.3662, 0.2881, 0.3829,\n",
       "                      0.2374, 0.2518, 0.1963, 0.3951, 0.3888, 0.2068, 0.5858, 0.2579, 0.2151,\n",
       "                      0.2863, 0.2732, 0.2658, 0.4147, 0.4745, 0.1460, 0.2259, 0.3147, 0.3983,\n",
       "                      0.1162, 0.2417, 0.2921, 0.1843, 0.3671, 0.3669, 0.3830, 0.4908, 0.3018,\n",
       "                      0.2282, 0.1474, 0.2132, 0.5300, 0.3596, 0.3045, 0.2747, 0.2099, 0.1851,\n",
       "                      0.1375, 0.4052, 0.5132, 0.6296, 0.1777, 0.2655, 0.3792, 0.2351, 0.2398,\n",
       "                      0.2488, 0.0875, 0.4107, 0.3884, 0.2651, 0.1312, 0.2653, 0.2992, 0.2450,\n",
       "                      0.3128, 0.0604, 0.3273, 0.2133, 0.2701, 0.4080, 0.1049, 0.2305, 0.4332,\n",
       "                      0.0846, 0.2594, 0.4454, 0.1783, 0.2998, 0.1100, 0.3025, 0.2767, 0.1550,\n",
       "                      0.3629, 0.1222, 0.2588, 0.3282, 0.2285, 0.1372, 0.1351, 0.2323, 0.3535,\n",
       "                      0.1460, 0.3820, 0.2632, 0.3601, 0.3634, 0.4341, 0.1619, 0.2836, 0.3729,\n",
       "                      0.1953, 0.2570, 0.2572, 0.3025, 0.3721, 0.2270, 0.4455, 0.4097, 0.3909,\n",
       "                      0.2061, 0.1899, 0.1344, 0.3193, 0.4055, 0.2876, 0.4387, 0.2327, 0.2360,\n",
       "                      0.0765, 0.3957, 0.1651, 0.1184], dtype=torch.float64)),\n",
       "             ('5.0.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.1.convs.0.0.weight',\n",
       "              tensor([[[ 0.0076],\n",
       "                       [-0.0982],\n",
       "                       [-0.0178],\n",
       "                       ...,\n",
       "                       [-0.0798],\n",
       "                       [-0.0446],\n",
       "                       [ 0.0332]],\n",
       "              \n",
       "                      [[ 0.1163],\n",
       "                       [-0.0898],\n",
       "                       [ 0.0355],\n",
       "                       ...,\n",
       "                       [-0.0894],\n",
       "                       [ 0.0627],\n",
       "                       [ 0.1547]],\n",
       "              \n",
       "                      [[-0.0080],\n",
       "                       [ 0.1616],\n",
       "                       [-0.1517],\n",
       "                       ...,\n",
       "                       [-0.0432],\n",
       "                       [-0.0443],\n",
       "                       [ 0.0113]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0169],\n",
       "                       [ 0.0508],\n",
       "                       [ 0.0046],\n",
       "                       ...,\n",
       "                       [ 0.1651],\n",
       "                       [ 0.1270],\n",
       "                       [-0.0545]],\n",
       "              \n",
       "                      [[-0.0298],\n",
       "                       [ 0.1147],\n",
       "                       [-0.0598],\n",
       "                       ...,\n",
       "                       [ 0.0002],\n",
       "                       [ 0.1135],\n",
       "                       [ 0.0419]],\n",
       "              \n",
       "                      [[-0.0184],\n",
       "                       [-0.0036],\n",
       "                       [-0.1082],\n",
       "                       ...,\n",
       "                       [-0.0426],\n",
       "                       [-0.1598],\n",
       "                       [-0.0270]]], dtype=torch.float64)),\n",
       "             ('5.1.convs.0.1.weight',\n",
       "              tensor([0.9542, 0.9726, 0.9547, 0.9844, 0.9470, 0.9612, 0.9635, 0.9581, 0.9643,\n",
       "                      0.9584, 0.9628, 0.9636, 0.9591, 0.9880, 0.9528, 0.9826, 0.9588, 0.9508,\n",
       "                      0.9822, 0.9764, 0.9798, 0.9575, 0.9815, 0.9557, 0.9573, 0.9787, 0.9932,\n",
       "                      0.9611, 0.9849, 0.9847, 0.9721, 0.9414, 0.9655, 0.9875, 0.9560, 0.9877,\n",
       "                      0.9514, 0.9880, 0.9545, 0.9745, 1.0012, 0.9487, 0.9591, 0.9452, 0.9579,\n",
       "                      0.9613, 0.9584, 0.9899, 0.9645, 0.9808, 0.9528, 0.9768, 0.9631, 0.9795,\n",
       "                      0.9749, 0.9608, 0.9955, 0.9540, 0.9649, 0.9630, 0.9609, 0.9487, 0.9520,\n",
       "                      0.9967], dtype=torch.float64)),\n",
       "             ('5.1.convs.0.1.bias',\n",
       "              tensor([ 0.0145,  0.0082,  0.0121,  0.0194,  0.0162,  0.0151, -0.0090,  0.0111,\n",
       "                      -0.0068, -0.0026, -0.0111,  0.0037,  0.0070,  0.0081, -0.0133,  0.0097,\n",
       "                       0.0055,  0.0033,  0.0151,  0.0097, -0.0045, -0.0224,  0.0100, -0.0079,\n",
       "                       0.0030, -0.0071,  0.0152,  0.0025,  0.0202,  0.0090, -0.0188,  0.0089,\n",
       "                       0.0130,  0.0257, -0.0005,  0.0115,  0.0046,  0.0253, -0.0070,  0.0055,\n",
       "                       0.0017, -0.0224, -0.0131,  0.0144, -0.0069, -0.0004,  0.0199, -0.0056,\n",
       "                       0.0127, -0.0062, -0.0092,  0.0128,  0.0008,  0.0133, -0.0085,  0.0076,\n",
       "                       0.0454,  0.0092,  0.0159,  0.0154, -0.0173, -0.0076, -0.0145,  0.0306],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convs.0.1.running_mean',\n",
       "              tensor([-0.4015,  0.3196, -0.3832, -0.4130, -0.6135, -0.0987,  0.5634, -0.4502,\n",
       "                      -0.1414,  0.0754,  0.0739, -0.5565,  0.1044, -0.7221,  0.3753, -0.0966,\n",
       "                       0.0424, -0.7741,  0.0641,  0.5895,  0.2306, -0.0159,  0.0631, -0.5771,\n",
       "                       0.0146,  0.3478,  0.4249, -0.3396, -1.0293,  0.5138,  0.2020, -0.9589,\n",
       "                      -0.4396, -0.0913,  0.6810, -0.3692,  0.3011, -1.0276,  0.4403,  0.2252,\n",
       "                       0.3268,  0.7222,  0.7186, -0.5876,  0.1908, -0.1902, -0.4671, -0.7667,\n",
       "                       0.4031, -0.0417,  0.1755, -0.1440, -0.5106, -0.7178, -0.2990, -0.3281,\n",
       "                       0.2159,  0.0703, -0.1432,  0.0612,  0.4324,  0.6224,  0.4043, -0.4857],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convs.0.1.running_var',\n",
       "              tensor([0.3512, 0.2639, 0.3500, 0.2246, 1.0532, 0.2996, 0.4827, 1.2664, 0.4607,\n",
       "                      0.6660, 0.3107, 0.4125, 0.3903, 0.4698, 0.9222, 0.1887, 0.5127, 0.5488,\n",
       "                      0.1266, 2.4062, 0.2648, 0.5591, 0.4424, 1.0512, 0.2584, 0.1376, 0.2405,\n",
       "                      0.2588, 0.2594, 0.3091, 0.3472, 2.2546, 0.5255, 0.2641, 0.2329, 0.2488,\n",
       "                      0.3938, 0.2428, 0.5283, 0.2762, 0.2008, 1.4145, 1.2052, 1.3863, 0.1852,\n",
       "                      0.2493, 0.3640, 0.2333, 1.4517, 0.1355, 0.3578, 0.2755, 0.2707, 0.2753,\n",
       "                      0.2557, 0.7284, 0.4098, 0.2760, 0.2808, 0.6784, 0.6208, 1.2235, 0.6766,\n",
       "                      0.2110], dtype=torch.float64)),\n",
       "             ('5.1.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.1.convs.1.0.weight',\n",
       "              tensor([[[-2.8822e-02,  1.2485e-03,  1.8985e-02, -9.2963e-02, -1.4103e-01],\n",
       "                       [-3.8532e-02,  1.1846e-01, -6.4143e-03, -1.3094e-01,  6.5535e-02],\n",
       "                       [-9.4960e-02,  1.6787e-02,  4.3510e-02, -6.3501e-02, -5.2746e-02],\n",
       "                       ...,\n",
       "                       [-3.3159e-02,  9.1410e-03, -9.6063e-02,  4.1033e-02,  1.5353e-02],\n",
       "                       [ 1.1296e-02, -4.6843e-03, -3.5706e-02, -5.4735e-02, -2.3998e-02],\n",
       "                       [-3.7127e-02,  1.4047e-01, -4.9726e-02,  5.0396e-02, -7.7704e-02]],\n",
       "              \n",
       "                      [[-7.9695e-02, -6.1371e-02,  8.2181e-02,  2.4825e-03, -4.5607e-02],\n",
       "                       [-8.9958e-02, -4.2680e-02, -6.1142e-02, -8.6555e-02, -8.1925e-02],\n",
       "                       [-2.7633e-02, -1.2870e-01,  2.1726e-02,  4.6425e-02, -7.2292e-02],\n",
       "                       ...,\n",
       "                       [-4.1130e-02, -7.8817e-02,  6.3787e-02, -3.8858e-02,  4.6789e-02],\n",
       "                       [-1.1209e-01, -4.2281e-02,  1.1450e-01,  5.2905e-02,  8.0796e-02],\n",
       "                       [ 1.3445e-01,  1.1298e-01,  3.4486e-02,  1.0648e-01, -6.6742e-03]],\n",
       "              \n",
       "                      [[-3.8999e-03, -2.0157e-02,  5.9176e-02, -7.8486e-02, -1.4282e-01],\n",
       "                       [-2.1463e-02,  1.7024e-02, -1.3019e-02,  1.7350e-02,  2.0830e-02],\n",
       "                       [ 1.2035e-02,  1.1232e-01, -1.9243e-01, -1.0697e-01, -2.0361e-02],\n",
       "                       ...,\n",
       "                       [-1.0004e-02, -9.1690e-02,  4.0629e-02, -1.9581e-01, -3.6702e-02],\n",
       "                       [-2.5979e-02, -1.2273e-02, -9.9933e-02, -2.6069e-02, -7.3736e-03],\n",
       "                       [ 2.3884e-02,  1.1642e-01, -1.8114e-01, -7.3712e-02,  2.0206e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 4.2080e-02, -7.6083e-02,  4.0925e-02,  3.3351e-02, -2.6871e-02],\n",
       "                       [-1.9038e-02,  7.3626e-02, -1.3557e-01, -4.8968e-02,  1.0000e-01],\n",
       "                       [ 9.3484e-02, -1.2961e-01,  1.0342e-01,  4.6477e-02,  1.1057e-02],\n",
       "                       ...,\n",
       "                       [ 7.5360e-02,  1.0262e-01,  2.9145e-03, -1.6490e-02, -7.8245e-02],\n",
       "                       [ 2.0870e-01,  9.3220e-04,  3.5401e-02, -4.8976e-02,  5.4136e-02],\n",
       "                       [ 6.8829e-02,  1.4155e-02,  1.5808e-04, -5.5147e-02, -8.8265e-02]],\n",
       "              \n",
       "                      [[-2.6412e-03, -1.0583e-01,  7.4697e-02,  2.0400e-02,  9.5265e-02],\n",
       "                       [ 1.2656e-01, -7.3105e-02, -7.2432e-02, -2.0990e-02, -1.3040e-02],\n",
       "                       [-1.0603e-01,  5.4632e-02, -9.9588e-03, -2.3245e-03, -1.0607e-01],\n",
       "                       ...,\n",
       "                       [ 5.3532e-03,  7.2195e-02, -3.9823e-02,  6.5705e-02,  4.6370e-02],\n",
       "                       [-4.2855e-03,  3.4427e-02,  1.0558e-01,  9.6915e-03, -7.6557e-02],\n",
       "                       [ 8.4089e-02, -6.7822e-02,  1.3072e-02, -1.1363e-01,  6.1712e-02]],\n",
       "              \n",
       "                      [[-1.3348e-02,  3.9903e-02, -2.2272e-02,  4.2507e-02, -6.7797e-02],\n",
       "                       [-8.5360e-03, -1.1590e-01, -1.4245e-01, -1.2304e-01,  5.1314e-02],\n",
       "                       [ 1.0559e-01, -7.4059e-02,  5.8632e-02, -8.1564e-02,  1.7192e-02],\n",
       "                       ...,\n",
       "                       [ 5.2315e-02,  1.6432e-01, -4.1654e-02,  1.5325e-02,  2.8996e-02],\n",
       "                       [ 6.9300e-03,  3.9455e-02,  8.3214e-03, -1.3036e-01, -7.3669e-02],\n",
       "                       [-6.5765e-02, -1.1853e-01,  4.8825e-02,  9.3607e-02, -1.5216e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convs.1.1.weight',\n",
       "              tensor([0.9722, 0.9357, 0.9484, 0.9477, 0.9739, 0.9537, 0.9841, 0.9407, 0.9567,\n",
       "                      0.9408, 0.9677, 0.9597, 1.0016, 0.9671, 0.9639, 0.9408, 0.9698, 0.9637,\n",
       "                      0.9410, 0.9552, 0.9355, 0.9578, 0.9649, 0.9530, 0.9647, 0.9949, 0.9994,\n",
       "                      0.9352, 0.9620, 0.9830, 0.9396, 0.9447, 0.9794, 0.9663, 0.9718, 0.9526,\n",
       "                      0.9634, 0.9594, 0.9903, 0.9402, 0.9425, 0.9839, 0.9811, 0.9757, 0.9702,\n",
       "                      0.9685, 0.9703, 0.9493, 0.9458, 0.9343, 0.9509, 0.9749, 0.9513, 0.9507,\n",
       "                      0.9554, 0.9404, 0.9541, 0.9664, 0.9620, 0.9471, 0.9134, 0.9650, 0.9607,\n",
       "                      0.9568], dtype=torch.float64)),\n",
       "             ('5.1.convs.1.1.bias',\n",
       "              tensor([ 0.0115, -0.0010,  0.0144,  0.0087, -0.0084, -0.0146, -0.0037, -0.0025,\n",
       "                       0.0072, -0.0294, -0.0195, -0.0080,  0.0052, -0.0137, -0.0018, -0.0110,\n",
       "                      -0.0178,  0.0073, -0.0092,  0.0066,  0.0005, -0.0205,  0.0090, -0.0065,\n",
       "                      -0.0090,  0.0028,  0.0182,  0.0011, -0.0046,  0.0104, -0.0083, -0.0009,\n",
       "                       0.0114, -0.0061, -0.0067, -0.0157, -0.0099, -0.0049, -0.0079, -0.0008,\n",
       "                      -0.0133, -0.0042, -0.0026, -0.0038,  0.0067, -0.0016,  0.0125,  0.0097,\n",
       "                      -0.0110, -0.0143, -0.0157,  0.0014, -0.0142,  0.0033,  0.0104,  0.0029,\n",
       "                       0.0168, -0.0145, -0.0007, -0.0061, -0.0240, -0.0042, -0.0238,  0.0014],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convs.1.1.running_mean',\n",
       "              tensor([ 0.2460, -0.7263, -0.8839, -0.4444, -0.2036,  0.5146,  0.0956, -0.1903,\n",
       "                      -0.8145, -0.1859,  0.0559, -0.2376, -0.6705,  0.4210, -0.0619, -0.4655,\n",
       "                      -0.1691, -0.9954, -0.2535, -0.0864,  0.0398, -0.5552,  0.4488, -1.6294,\n",
       "                       0.4878, -0.5536, -0.5203, -0.2061,  0.7451, -0.2923, -0.5234,  0.4983,\n",
       "                      -0.1976, -0.6074, -0.2561,  0.1104,  0.3511,  0.2087, -0.7091, -0.1421,\n",
       "                       0.2730, -0.2149,  0.7309,  0.1189, -0.1028,  0.1600, -0.3771, -0.3887,\n",
       "                       0.8279, -0.0818, -0.1739,  0.3368,  0.2999, -0.8493, -0.1990, -0.5888,\n",
       "                      -0.0979, -1.0269,  0.5693,  0.3546, -0.2058,  0.5056, -0.4248, -0.2196],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convs.1.1.running_var',\n",
       "              tensor([0.3385, 0.7571, 0.9774, 0.4811, 0.4292, 0.3068, 0.5528, 1.1460, 0.5158,\n",
       "                      0.5674, 0.6217, 0.5287, 0.4167, 0.6227, 0.7274, 0.4905, 0.3726, 0.5732,\n",
       "                      0.6586, 0.5560, 0.9818, 0.7259, 0.4499, 0.5902, 0.4680, 0.4380, 0.3904,\n",
       "                      0.7961, 0.9763, 0.7018, 0.6855, 0.4412, 0.4781, 0.4218, 0.6745, 0.4236,\n",
       "                      0.6542, 0.5003, 0.5218, 0.5681, 0.3624, 0.3073, 0.5675, 0.4707, 0.4017,\n",
       "                      0.8201, 0.4755, 0.7380, 0.6446, 0.6470, 0.4889, 0.3855, 0.8941, 0.7151,\n",
       "                      0.4213, 0.6554, 0.5438, 0.4121, 0.5246, 0.4166, 1.0352, 0.4654, 0.6506,\n",
       "                      0.3318], dtype=torch.float64)),\n",
       "             ('5.1.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.1.convs.2.0.weight',\n",
       "              tensor([[[ 0.0887],\n",
       "                       [-0.1184],\n",
       "                       [ 0.0219],\n",
       "                       ...,\n",
       "                       [-0.0692],\n",
       "                       [-0.0604],\n",
       "                       [ 0.0245]],\n",
       "              \n",
       "                      [[-0.1176],\n",
       "                       [ 0.0129],\n",
       "                       [-0.0251],\n",
       "                       ...,\n",
       "                       [-0.1393],\n",
       "                       [-0.1761],\n",
       "                       [-0.1405]],\n",
       "              \n",
       "                      [[-0.0464],\n",
       "                       [-0.0757],\n",
       "                       [ 0.2077],\n",
       "                       ...,\n",
       "                       [-0.0788],\n",
       "                       [-0.1461],\n",
       "                       [ 0.0595]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0047],\n",
       "                       [-0.0862],\n",
       "                       [ 0.0382],\n",
       "                       ...,\n",
       "                       [ 0.1366],\n",
       "                       [-0.1257],\n",
       "                       [-0.0427]],\n",
       "              \n",
       "                      [[ 0.0675],\n",
       "                       [-0.1607],\n",
       "                       [-0.1476],\n",
       "                       ...,\n",
       "                       [ 0.1047],\n",
       "                       [-0.3514],\n",
       "                       [ 0.0181]],\n",
       "              \n",
       "                      [[ 0.2848],\n",
       "                       [ 0.0039],\n",
       "                       [-0.0269],\n",
       "                       ...,\n",
       "                       [-0.0451],\n",
       "                       [ 0.1248],\n",
       "                       [-0.1390]]], dtype=torch.float64)),\n",
       "             ('5.1.convs.2.1.weight',\n",
       "              tensor([-1.4484e-02,  2.4060e-02, -1.5821e-02,  1.7680e-02,  1.0004e-02,\n",
       "                       6.7027e-03,  7.1994e-03, -5.7556e-03,  2.7408e-02, -1.5671e-02,\n",
       "                       2.8246e-02, -1.3701e-02,  9.5285e-03, -8.2807e-03,  2.7995e-02,\n",
       "                       5.1928e-03,  2.7838e-02, -1.2236e-02, -1.1792e-02, -1.2598e-03,\n",
       "                       1.3194e-02,  3.9099e-02,  1.8926e-02, -9.4776e-03, -3.3609e-02,\n",
       "                      -1.6652e-02,  1.4418e-02, -1.3012e-02,  1.7943e-03,  1.7996e-05,\n",
       "                      -1.0830e-02,  3.4367e-02,  6.0117e-03, -7.8726e-03, -1.8774e-02,\n",
       "                       1.6318e-02,  8.7413e-03, -2.2869e-02,  3.0065e-02, -5.1092e-02,\n",
       "                      -4.1643e-03, -1.0612e-02, -1.0678e-02,  2.8561e-02, -1.4670e-02,\n",
       "                      -1.2908e-02, -1.1333e-02,  1.7391e-02, -1.0823e-02,  1.4037e-02,\n",
       "                      -2.5065e-02,  7.2836e-03, -5.9721e-03,  4.3940e-03,  1.2836e-03,\n",
       "                       1.4670e-02, -6.0508e-03, -4.2665e-04,  5.8563e-03, -2.4786e-02,\n",
       "                       1.6972e-03, -1.1594e-02, -2.2277e-02,  2.7276e-02, -2.4767e-02,\n",
       "                       2.1095e-05,  1.6215e-02,  1.6422e-02, -1.0606e-02, -1.4994e-02,\n",
       "                      -1.5378e-02, -1.0347e-02,  1.5926e-02,  1.2498e-02, -2.7314e-02,\n",
       "                      -2.0244e-03, -4.3138e-04,  1.9042e-02,  6.3526e-03,  1.5578e-02,\n",
       "                       3.7470e-03,  1.5024e-02, -3.4547e-02, -7.3746e-03,  3.1425e-03,\n",
       "                      -7.4004e-03,  8.9991e-03,  8.6577e-03, -2.4076e-02,  1.2354e-02,\n",
       "                       4.3793e-02,  1.3150e-02,  3.6373e-03,  2.2131e-03, -1.4569e-02,\n",
       "                       4.9260e-03, -1.1855e-02, -1.8495e-02,  2.3242e-02,  7.7317e-03,\n",
       "                      -1.7826e-02, -4.1511e-03, -4.6887e-05, -2.9618e-02, -9.9099e-03,\n",
       "                       9.9212e-03, -8.5481e-03,  1.7056e-02, -8.1480e-03,  2.2757e-02,\n",
       "                       4.1966e-03,  1.2208e-02,  2.9778e-02, -2.2393e-02, -4.9657e-03,\n",
       "                       1.0071e-02, -2.8339e-02, -1.7792e-02, -2.3064e-02, -1.0165e-03,\n",
       "                      -7.5977e-03, -1.2112e-02, -3.8129e-03, -2.4011e-02, -1.8196e-02,\n",
       "                       2.0467e-03, -1.0265e-02,  1.3830e-03, -1.5956e-03,  1.3412e-02,\n",
       "                      -3.3821e-02,  2.2743e-02, -2.5334e-03,  4.7229e-03, -1.6918e-04,\n",
       "                      -7.7931e-03, -6.5810e-03, -2.3996e-02,  1.7700e-02, -1.1242e-02,\n",
       "                      -2.2661e-02,  2.3588e-02,  3.0319e-02, -3.3790e-02, -5.3754e-03,\n",
       "                      -3.5318e-02, -2.9229e-02,  1.5058e-02, -2.2024e-03, -3.5551e-03,\n",
       "                      -1.4546e-02,  1.1025e-02, -1.7624e-02, -3.8083e-03,  7.2399e-04,\n",
       "                       1.1371e-02, -2.7100e-02, -1.9468e-02,  7.0739e-03, -1.2828e-02,\n",
       "                       1.0319e-02, -2.7104e-02,  7.1754e-03,  1.8182e-02,  7.7546e-03,\n",
       "                      -3.9762e-03, -2.5968e-02,  2.3149e-02,  1.3973e-03,  2.4551e-02,\n",
       "                      -2.6404e-02, -1.7582e-02,  1.2709e-02, -2.5211e-02, -1.5519e-02,\n",
       "                       1.4110e-02,  3.2698e-02,  3.0017e-02,  1.5884e-02, -2.7614e-02,\n",
       "                      -4.8938e-03,  1.5177e-03,  1.8752e-02, -1.9644e-03, -1.4398e-02,\n",
       "                      -1.0213e-02, -5.2851e-03, -3.8904e-02,  1.8935e-02, -7.9892e-03,\n",
       "                       3.9587e-02,  2.9115e-02, -7.2967e-03,  1.6550e-03, -1.6670e-02,\n",
       "                       2.1029e-02, -2.1488e-02,  1.6215e-02,  7.9129e-03, -2.0565e-02,\n",
       "                       1.6048e-02, -1.2154e-02,  1.5583e-02, -8.4278e-03,  8.6094e-03,\n",
       "                       1.0712e-02, -1.9833e-03, -4.4301e-03,  1.4733e-02, -6.4257e-03,\n",
       "                       6.4938e-03,  2.2979e-02, -5.5136e-02, -3.6341e-02,  2.2795e-03,\n",
       "                       2.3132e-02, -5.5454e-03,  1.1062e-03,  1.3274e-02,  1.1317e-03,\n",
       "                      -3.5712e-03,  2.2272e-02,  1.2925e-02, -5.5573e-03,  2.4395e-02,\n",
       "                      -8.0691e-03,  1.2851e-02,  1.9469e-03, -1.2008e-02,  3.6867e-02,\n",
       "                       2.0844e-02,  1.2165e-02,  4.1987e-03,  1.8967e-02, -2.3222e-02,\n",
       "                      -1.7012e-03, -1.0029e-02,  6.7193e-04, -2.4867e-02,  2.9023e-02,\n",
       "                      -7.1035e-03,  2.0554e-02,  1.5082e-02, -4.6764e-03, -4.3468e-02,\n",
       "                      -1.4599e-02, -1.4143e-02,  2.4892e-02,  8.1495e-03, -9.3870e-03,\n",
       "                      -1.0902e-02,  1.5992e-02, -2.2400e-02, -5.8628e-03,  1.5269e-02,\n",
       "                      -3.4191e-02], dtype=torch.float64)),\n",
       "             ('5.1.convs.2.1.bias',\n",
       "              tensor([ 2.6467e-03,  3.5621e-03,  2.4586e-02,  9.1864e-04,  5.4386e-03,\n",
       "                      -1.3073e-02,  1.4003e-02,  4.7672e-03,  1.0467e-02, -7.4992e-03,\n",
       "                       7.8223e-03, -8.1994e-03,  1.5500e-02, -1.5284e-02,  1.0318e-02,\n",
       "                       1.1017e-02,  2.3494e-02,  5.9243e-03,  2.2890e-02, -3.1521e-03,\n",
       "                       2.6486e-03, -3.2956e-03, -9.4196e-04,  6.5877e-03,  2.5979e-03,\n",
       "                      -2.4859e-02,  1.9443e-04,  1.9493e-02,  5.1488e-03,  3.9546e-03,\n",
       "                      -1.1861e-02,  1.6343e-02, -1.2308e-02,  1.6588e-02,  1.4449e-02,\n",
       "                      -2.9676e-03,  8.4376e-03,  2.6566e-02,  7.5975e-04,  1.4410e-03,\n",
       "                       4.0850e-03, -1.9492e-03, -4.1031e-03,  1.1416e-02,  1.7308e-02,\n",
       "                      -4.6010e-03, -1.0145e-02,  7.5677e-03, -5.0903e-03,  7.8801e-03,\n",
       "                      -6.8099e-03,  3.6849e-03,  1.6951e-02,  1.9921e-02, -1.3318e-02,\n",
       "                       3.8281e-03,  2.5204e-03,  1.2347e-02,  5.8227e-03,  8.4169e-03,\n",
       "                      -1.4195e-02,  5.1661e-03,  2.8175e-03,  1.5309e-02,  7.6095e-04,\n",
       "                       5.7642e-04, -9.4214e-03,  1.4950e-02,  6.5317e-03, -1.4393e-02,\n",
       "                       8.7542e-03,  1.7641e-02,  1.0705e-02, -8.3376e-03,  3.7260e-03,\n",
       "                       1.6089e-02,  9.4727e-03, -1.5217e-02,  8.7095e-03,  1.1258e-02,\n",
       "                       1.5661e-02, -2.2282e-04,  1.5608e-02,  8.8063e-03,  1.5374e-03,\n",
       "                       5.7068e-03,  5.8167e-03,  6.3144e-03,  1.2047e-02, -5.6070e-03,\n",
       "                       7.8076e-03,  2.0185e-02,  2.1289e-02,  3.5340e-03,  5.4981e-03,\n",
       "                      -1.3772e-02,  9.1510e-03,  7.6078e-03,  1.9582e-02, -1.1931e-02,\n",
       "                       2.8270e-02, -3.5271e-03, -9.0778e-03, -2.3380e-02,  1.3050e-02,\n",
       "                       6.4681e-03, -1.9051e-02,  6.6048e-03,  7.6475e-03,  2.2611e-03,\n",
       "                      -9.8005e-03, -4.5752e-03,  1.2396e-02,  1.1839e-02,  8.9775e-03,\n",
       "                       8.5787e-03,  1.3353e-02,  1.1867e-02,  1.1656e-02, -1.1063e-02,\n",
       "                       1.0566e-02,  1.2834e-02,  6.3888e-03,  1.3243e-03, -6.5305e-03,\n",
       "                       1.1252e-02,  7.8873e-03,  4.9865e-03,  5.5484e-03,  4.0718e-03,\n",
       "                       2.8809e-03,  1.3060e-04,  7.1151e-03,  6.6269e-03, -4.1984e-03,\n",
       "                      -1.4836e-02, -5.4421e-04,  1.8262e-02,  9.4871e-03, -8.7651e-03,\n",
       "                      -4.2096e-03,  9.2563e-03, -1.3128e-03,  1.6432e-02, -1.0688e-02,\n",
       "                      -4.6770e-03,  3.3567e-03, -3.0195e-03,  1.1251e-02,  1.2881e-02,\n",
       "                      -1.8275e-03,  2.1332e-02,  1.3575e-02,  1.6090e-02,  7.5408e-03,\n",
       "                       1.6935e-02,  1.1664e-02,  1.5063e-02, -5.0726e-04, -1.9454e-02,\n",
       "                       4.6041e-03,  1.2843e-03, -5.5430e-03,  2.0276e-02,  9.3970e-03,\n",
       "                       6.6393e-03, -7.2259e-03,  2.0915e-02,  1.4294e-02,  1.6495e-02,\n",
       "                       1.2451e-02,  4.9003e-03, -5.1965e-03,  2.0434e-02, -1.6000e-02,\n",
       "                      -3.0319e-03,  5.5181e-03,  2.7155e-02,  9.9750e-03,  2.1698e-03,\n",
       "                      -5.7021e-03,  1.9082e-02, -1.2070e-02, -4.4871e-03,  1.1556e-02,\n",
       "                       7.4446e-03,  1.2396e-02,  1.6811e-02,  6.2275e-04,  9.8089e-04,\n",
       "                      -1.1326e-02,  8.8346e-03,  1.3930e-02, -1.5289e-02,  9.0687e-03,\n",
       "                       9.0314e-03, -1.0433e-02,  5.0957e-03,  1.3083e-02, -1.7574e-02,\n",
       "                       1.1813e-02,  2.4866e-03,  1.5218e-02,  2.1210e-02,  1.6170e-03,\n",
       "                      -6.4291e-03,  1.9493e-02, -9.3202e-03,  8.3216e-05,  1.1686e-02,\n",
       "                       3.9976e-03,  1.5542e-02,  7.6439e-03,  1.4180e-02,  4.6126e-03,\n",
       "                       9.1490e-03,  3.1062e-03,  1.4317e-02,  9.1694e-03,  6.7761e-04,\n",
       "                      -2.7925e-03, -5.3314e-03,  1.3476e-02,  1.5350e-03,  2.6178e-03,\n",
       "                       8.7681e-03,  3.2841e-03,  4.3396e-03, -2.6013e-02, -4.8178e-03,\n",
       "                      -1.0945e-02,  9.1176e-03,  1.0112e-02,  4.4025e-03,  2.7864e-03,\n",
       "                       5.5671e-03,  9.2334e-03,  2.0519e-04,  6.6878e-03,  1.5838e-02,\n",
       "                      -6.5399e-03,  7.2038e-03,  1.2324e-02,  9.2483e-04,  1.0488e-02,\n",
       "                       1.3904e-02,  1.0555e-02,  2.2139e-02, -6.6749e-03, -1.2933e-02,\n",
       "                       2.2974e-02,  9.9409e-03,  1.0546e-02,  2.4950e-02,  2.2768e-02,\n",
       "                       7.5406e-03], dtype=torch.float64)),\n",
       "             ('5.1.convs.2.1.running_mean',\n",
       "              tensor([ 0.1799,  0.2545, -1.0684, -0.0301,  0.0502, -0.3574, -0.0693, -0.3150,\n",
       "                      -0.1281,  0.0464, -0.5032, -0.3386, -0.4414,  0.0697, -0.0848,  0.2036,\n",
       "                      -0.0998,  0.2620, -0.4533,  0.1850,  0.3123, -0.1771, -0.2537,  0.3064,\n",
       "                       0.7670,  0.5196,  0.1614,  0.5801,  0.4516,  0.0686,  0.4415, -0.3302,\n",
       "                      -0.1308, -0.3081,  0.4754,  0.1104,  0.0675,  0.3615, -0.1302,  0.3732,\n",
       "                      -0.1112,  0.3024,  0.3030,  0.0607,  0.1409,  0.1522, -0.1603,  0.3408,\n",
       "                      -0.2801,  0.3629, -0.1850,  0.1913, -0.1634, -0.1457,  0.2779, -0.4692,\n",
       "                      -0.1993,  0.0512, -0.1551,  0.5274, -0.0227,  0.6553, -0.2389, -0.4373,\n",
       "                       0.1403,  0.1935, -0.4901, -0.0802,  0.3918, -0.2360, -0.0385,  0.0058,\n",
       "                       0.1625,  0.2746, -0.1614,  0.0605,  0.2209, -0.0312,  0.5692, -0.2589,\n",
       "                      -0.2791,  0.1027,  0.2905, -0.0795, -0.1235, -0.4761, -0.4858,  0.1625,\n",
       "                       0.4696,  0.9872,  0.2046,  0.3632, -0.2589,  0.4811,  0.4034,  0.2007,\n",
       "                       0.5738, -0.4710,  0.3987, -0.1481, -0.2564, -0.4176,  0.0557,  0.4308,\n",
       "                       0.0284, -0.5646, -0.5781,  0.6282,  0.1819,  0.2029, -0.0011, -0.4480,\n",
       "                       0.6909,  0.4385, -0.2755, -0.0793,  0.4621, -0.5441,  0.6407, -0.0380,\n",
       "                       0.3739, -0.0545,  0.5805, -0.4208, -0.2036, -0.5364,  0.1907, -0.4222,\n",
       "                       0.0274,  0.1612, -0.5792, -0.5994,  0.6857, -0.6049, -0.4200, -0.2065,\n",
       "                       0.1632,  0.1546,  0.1242,  0.1398, -0.3307,  0.2271,  0.4490,  0.4329,\n",
       "                      -0.0159, -0.1483, -0.4382, -0.2899, -0.1896, -0.5038, -0.1710, -0.0723,\n",
       "                       0.3827,  0.0726, -0.2493,  0.2988,  0.1441,  0.2591, -0.7494, -0.0289,\n",
       "                      -0.7942,  0.2059, -0.2673, -0.6443, -0.4627, -0.3680, -0.4649, -0.0570,\n",
       "                       0.3165, -0.2184, -0.0011,  0.2783,  0.2601, -0.1636,  0.1370,  0.1517,\n",
       "                      -0.2626, -0.2333, -0.3996,  0.1684, -0.3741, -0.0440, -0.3362, -0.3169,\n",
       "                      -0.3687, -0.2183,  0.2959, -0.3455, -0.0560, -0.1653,  0.2082, -0.3645,\n",
       "                      -0.5862,  0.4253, -0.5083,  0.1078, -0.0019,  0.0697, -0.1366, -0.4649,\n",
       "                      -0.2601, -0.2101,  0.6666,  0.2146,  0.3121, -0.3148, -0.0060,  0.3212,\n",
       "                      -0.0285,  0.1868, -0.3835, -0.0466,  0.1268,  0.0465, -0.2208,  0.4443,\n",
       "                      -0.1136, -0.2645,  0.5335,  0.5235, -0.3720, -0.9376,  0.0054, -0.5012,\n",
       "                      -0.7063, -0.0275,  0.2142, -0.1865,  0.1894,  0.2918, -0.1469, -0.3304,\n",
       "                      -0.2009,  0.4353, -0.2344, -0.2793, -0.3011,  0.0890, -0.2630,  0.0165,\n",
       "                       0.6288,  0.4842,  0.4707, -0.0747, -0.0866,  0.0673,  0.3266,  0.4181,\n",
       "                      -0.0662, -0.0472,  0.5022,  0.2459, -0.3195, -0.2582, -0.2492, -0.1294],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convs.2.1.running_var',\n",
       "              tensor([0.5083, 0.4525, 0.4264, 0.4030, 0.2131, 0.2214, 0.0872, 0.2819, 0.2365,\n",
       "                      0.3857, 0.3239, 0.2090, 0.2513, 0.2205, 0.4706, 0.2331, 0.4063, 0.5280,\n",
       "                      0.1390, 0.4195, 0.3273, 0.4307, 0.3184, 0.3764, 0.6338, 0.3207, 0.3061,\n",
       "                      0.4294, 0.2039, 0.1357, 0.3558, 0.3176, 0.3359, 0.4530, 0.3442, 0.5268,\n",
       "                      0.2307, 0.3414, 0.4628, 0.4066, 0.0804, 0.1596, 0.2515, 0.4422, 0.2434,\n",
       "                      0.2322, 0.6315, 0.3841, 0.7122, 0.4020, 0.2835, 0.2713, 0.2560, 0.1708,\n",
       "                      0.3551, 0.3925, 0.2648, 0.1672, 0.3340, 0.3882, 0.0428, 0.5039, 0.4115,\n",
       "                      0.3638, 0.4886, 0.2170, 0.3542, 0.2313, 0.3556, 0.4583, 0.3788, 0.2604,\n",
       "                      0.1423, 0.5101, 0.4413, 0.0444, 0.1431, 0.3172, 0.4177, 0.4100, 0.2575,\n",
       "                      0.2465, 0.2106, 0.2513, 0.2056, 0.4136, 0.3246, 0.2026, 0.4262, 0.5689,\n",
       "                      0.4934, 0.3784, 0.2777, 0.2366, 0.1733, 0.3448, 0.5307, 0.2373, 0.4583,\n",
       "                      0.3108, 0.3837, 0.2506, 0.0355, 0.2489, 0.1779, 0.2896, 0.3316, 0.3510,\n",
       "                      0.2836, 0.1879, 0.0991, 0.3623, 0.4366, 0.5086, 0.2951, 0.3674, 0.2996,\n",
       "                      0.4407, 0.2471, 0.1693, 0.1206, 0.3549, 0.5662, 0.4759, 0.2303, 0.2170,\n",
       "                      0.1431, 0.2873, 0.0623, 0.3189, 0.2714, 0.2241, 0.2750, 0.2059, 0.2472,\n",
       "                      0.1296, 0.0951, 0.6274, 0.2723, 0.1928, 0.2035, 0.2051, 0.2913, 0.2437,\n",
       "                      0.1742, 0.3946, 0.1887, 0.4072, 0.0466, 0.5468, 0.4535, 0.2292, 0.3212,\n",
       "                      0.2862, 0.4399, 0.3765, 0.5877, 0.2998, 0.4328, 0.0761, 0.2586, 0.2693,\n",
       "                      0.1558, 0.1633, 0.2083, 0.2559, 0.5269, 0.3179, 0.3107, 0.3687, 0.2612,\n",
       "                      0.3297, 0.3701, 0.2630, 0.4493, 0.5962, 0.3719, 0.4477, 0.4263, 0.4919,\n",
       "                      0.2203, 0.2870, 0.3967, 0.4773, 0.3568, 0.5817, 0.3578, 0.6070, 0.2943,\n",
       "                      0.0964, 0.2554, 0.6090, 0.3904, 0.3197, 0.2639, 0.2806, 0.2134, 0.1997,\n",
       "                      0.2890, 0.4716, 0.1724, 0.3214, 0.3035, 0.1765, 0.1868, 0.3011, 0.1621,\n",
       "                      0.0784, 0.2137, 0.2643, 0.1179, 0.3438, 0.4663, 0.2542, 0.0423, 0.4008,\n",
       "                      0.3419, 0.1204, 0.3841, 0.4801, 0.2602, 0.3955, 0.0697, 0.4197, 0.6130,\n",
       "                      0.2240, 0.2783, 0.1415, 0.4425, 0.3721, 0.2576, 0.1467, 0.1896, 0.4804,\n",
       "                      0.3742, 0.2743, 0.2529, 0.0914, 0.4352, 0.4298, 0.1658, 0.1864, 0.4956,\n",
       "                      0.2357, 0.2129, 0.1157, 0.2210, 0.4624, 0.0971, 0.3878, 0.3802, 0.5571,\n",
       "                      0.2806, 0.4068, 0.4196, 0.3667], dtype=torch.float64)),\n",
       "             ('5.1.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.1.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.0076],\n",
       "                       [-0.0982],\n",
       "                       [-0.0178],\n",
       "                       ...,\n",
       "                       [-0.0798],\n",
       "                       [-0.0446],\n",
       "                       [ 0.0332]],\n",
       "              \n",
       "                      [[ 0.1163],\n",
       "                       [-0.0898],\n",
       "                       [ 0.0355],\n",
       "                       ...,\n",
       "                       [-0.0894],\n",
       "                       [ 0.0627],\n",
       "                       [ 0.1547]],\n",
       "              \n",
       "                      [[-0.0080],\n",
       "                       [ 0.1616],\n",
       "                       [-0.1517],\n",
       "                       ...,\n",
       "                       [-0.0432],\n",
       "                       [-0.0443],\n",
       "                       [ 0.0113]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0169],\n",
       "                       [ 0.0508],\n",
       "                       [ 0.0046],\n",
       "                       ...,\n",
       "                       [ 0.1651],\n",
       "                       [ 0.1270],\n",
       "                       [-0.0545]],\n",
       "              \n",
       "                      [[-0.0298],\n",
       "                       [ 0.1147],\n",
       "                       [-0.0598],\n",
       "                       ...,\n",
       "                       [ 0.0002],\n",
       "                       [ 0.1135],\n",
       "                       [ 0.0419]],\n",
       "              \n",
       "                      [[-0.0184],\n",
       "                       [-0.0036],\n",
       "                       [-0.1082],\n",
       "                       ...,\n",
       "                       [-0.0426],\n",
       "                       [-0.1598],\n",
       "                       [-0.0270]]], dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.0.1.weight',\n",
       "              tensor([0.9542, 0.9726, 0.9547, 0.9844, 0.9470, 0.9612, 0.9635, 0.9581, 0.9643,\n",
       "                      0.9584, 0.9628, 0.9636, 0.9591, 0.9880, 0.9528, 0.9826, 0.9588, 0.9508,\n",
       "                      0.9822, 0.9764, 0.9798, 0.9575, 0.9815, 0.9557, 0.9573, 0.9787, 0.9932,\n",
       "                      0.9611, 0.9849, 0.9847, 0.9721, 0.9414, 0.9655, 0.9875, 0.9560, 0.9877,\n",
       "                      0.9514, 0.9880, 0.9545, 0.9745, 1.0012, 0.9487, 0.9591, 0.9452, 0.9579,\n",
       "                      0.9613, 0.9584, 0.9899, 0.9645, 0.9808, 0.9528, 0.9768, 0.9631, 0.9795,\n",
       "                      0.9749, 0.9608, 0.9955, 0.9540, 0.9649, 0.9630, 0.9609, 0.9487, 0.9520,\n",
       "                      0.9967], dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0145,  0.0082,  0.0121,  0.0194,  0.0162,  0.0151, -0.0090,  0.0111,\n",
       "                      -0.0068, -0.0026, -0.0111,  0.0037,  0.0070,  0.0081, -0.0133,  0.0097,\n",
       "                       0.0055,  0.0033,  0.0151,  0.0097, -0.0045, -0.0224,  0.0100, -0.0079,\n",
       "                       0.0030, -0.0071,  0.0152,  0.0025,  0.0202,  0.0090, -0.0188,  0.0089,\n",
       "                       0.0130,  0.0257, -0.0005,  0.0115,  0.0046,  0.0253, -0.0070,  0.0055,\n",
       "                       0.0017, -0.0224, -0.0131,  0.0144, -0.0069, -0.0004,  0.0199, -0.0056,\n",
       "                       0.0127, -0.0062, -0.0092,  0.0128,  0.0008,  0.0133, -0.0085,  0.0076,\n",
       "                       0.0454,  0.0092,  0.0159,  0.0154, -0.0173, -0.0076, -0.0145,  0.0306],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.4015,  0.3196, -0.3832, -0.4130, -0.6135, -0.0987,  0.5634, -0.4502,\n",
       "                      -0.1414,  0.0754,  0.0739, -0.5565,  0.1044, -0.7221,  0.3753, -0.0966,\n",
       "                       0.0424, -0.7741,  0.0641,  0.5895,  0.2306, -0.0159,  0.0631, -0.5771,\n",
       "                       0.0146,  0.3478,  0.4249, -0.3396, -1.0293,  0.5138,  0.2020, -0.9589,\n",
       "                      -0.4396, -0.0913,  0.6810, -0.3692,  0.3011, -1.0276,  0.4403,  0.2252,\n",
       "                       0.3268,  0.7222,  0.7186, -0.5876,  0.1908, -0.1902, -0.4671, -0.7667,\n",
       "                       0.4031, -0.0417,  0.1755, -0.1440, -0.5106, -0.7178, -0.2990, -0.3281,\n",
       "                       0.2159,  0.0703, -0.1432,  0.0612,  0.4324,  0.6224,  0.4043, -0.4857],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.0.1.running_var',\n",
       "              tensor([0.3512, 0.2639, 0.3500, 0.2246, 1.0532, 0.2996, 0.4827, 1.2664, 0.4607,\n",
       "                      0.6660, 0.3107, 0.4125, 0.3903, 0.4698, 0.9222, 0.1887, 0.5127, 0.5488,\n",
       "                      0.1266, 2.4062, 0.2648, 0.5591, 0.4424, 1.0512, 0.2584, 0.1376, 0.2405,\n",
       "                      0.2588, 0.2594, 0.3091, 0.3472, 2.2546, 0.5255, 0.2641, 0.2329, 0.2488,\n",
       "                      0.3938, 0.2428, 0.5283, 0.2762, 0.2008, 1.4145, 1.2052, 1.3863, 0.1852,\n",
       "                      0.2493, 0.3640, 0.2333, 1.4517, 0.1355, 0.3578, 0.2755, 0.2707, 0.2753,\n",
       "                      0.2557, 0.7284, 0.4098, 0.2760, 0.2808, 0.6784, 0.6208, 1.2235, 0.6766,\n",
       "                      0.2110], dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.1.convpath.0.1.0.weight',\n",
       "              tensor([[[-2.8822e-02,  1.2485e-03,  1.8985e-02, -9.2963e-02, -1.4103e-01],\n",
       "                       [-3.8532e-02,  1.1846e-01, -6.4143e-03, -1.3094e-01,  6.5535e-02],\n",
       "                       [-9.4960e-02,  1.6787e-02,  4.3510e-02, -6.3501e-02, -5.2746e-02],\n",
       "                       ...,\n",
       "                       [-3.3159e-02,  9.1410e-03, -9.6063e-02,  4.1033e-02,  1.5353e-02],\n",
       "                       [ 1.1296e-02, -4.6843e-03, -3.5706e-02, -5.4735e-02, -2.3998e-02],\n",
       "                       [-3.7127e-02,  1.4047e-01, -4.9726e-02,  5.0396e-02, -7.7704e-02]],\n",
       "              \n",
       "                      [[-7.9695e-02, -6.1371e-02,  8.2181e-02,  2.4825e-03, -4.5607e-02],\n",
       "                       [-8.9958e-02, -4.2680e-02, -6.1142e-02, -8.6555e-02, -8.1925e-02],\n",
       "                       [-2.7633e-02, -1.2870e-01,  2.1726e-02,  4.6425e-02, -7.2292e-02],\n",
       "                       ...,\n",
       "                       [-4.1130e-02, -7.8817e-02,  6.3787e-02, -3.8858e-02,  4.6789e-02],\n",
       "                       [-1.1209e-01, -4.2281e-02,  1.1450e-01,  5.2905e-02,  8.0796e-02],\n",
       "                       [ 1.3445e-01,  1.1298e-01,  3.4486e-02,  1.0648e-01, -6.6742e-03]],\n",
       "              \n",
       "                      [[-3.8999e-03, -2.0157e-02,  5.9176e-02, -7.8486e-02, -1.4282e-01],\n",
       "                       [-2.1463e-02,  1.7024e-02, -1.3019e-02,  1.7350e-02,  2.0830e-02],\n",
       "                       [ 1.2035e-02,  1.1232e-01, -1.9243e-01, -1.0697e-01, -2.0361e-02],\n",
       "                       ...,\n",
       "                       [-1.0004e-02, -9.1690e-02,  4.0629e-02, -1.9581e-01, -3.6702e-02],\n",
       "                       [-2.5979e-02, -1.2273e-02, -9.9933e-02, -2.6069e-02, -7.3736e-03],\n",
       "                       [ 2.3884e-02,  1.1642e-01, -1.8114e-01, -7.3712e-02,  2.0206e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 4.2080e-02, -7.6083e-02,  4.0925e-02,  3.3351e-02, -2.6871e-02],\n",
       "                       [-1.9038e-02,  7.3626e-02, -1.3557e-01, -4.8968e-02,  1.0000e-01],\n",
       "                       [ 9.3484e-02, -1.2961e-01,  1.0342e-01,  4.6477e-02,  1.1057e-02],\n",
       "                       ...,\n",
       "                       [ 7.5360e-02,  1.0262e-01,  2.9145e-03, -1.6490e-02, -7.8245e-02],\n",
       "                       [ 2.0870e-01,  9.3220e-04,  3.5401e-02, -4.8976e-02,  5.4136e-02],\n",
       "                       [ 6.8829e-02,  1.4155e-02,  1.5808e-04, -5.5147e-02, -8.8265e-02]],\n",
       "              \n",
       "                      [[-2.6412e-03, -1.0583e-01,  7.4697e-02,  2.0400e-02,  9.5265e-02],\n",
       "                       [ 1.2656e-01, -7.3105e-02, -7.2432e-02, -2.0990e-02, -1.3040e-02],\n",
       "                       [-1.0603e-01,  5.4632e-02, -9.9588e-03, -2.3245e-03, -1.0607e-01],\n",
       "                       ...,\n",
       "                       [ 5.3532e-03,  7.2195e-02, -3.9823e-02,  6.5705e-02,  4.6370e-02],\n",
       "                       [-4.2855e-03,  3.4427e-02,  1.0558e-01,  9.6915e-03, -7.6557e-02],\n",
       "                       [ 8.4089e-02, -6.7822e-02,  1.3072e-02, -1.1363e-01,  6.1712e-02]],\n",
       "              \n",
       "                      [[-1.3348e-02,  3.9903e-02, -2.2272e-02,  4.2507e-02, -6.7797e-02],\n",
       "                       [-8.5360e-03, -1.1590e-01, -1.4245e-01, -1.2304e-01,  5.1314e-02],\n",
       "                       [ 1.0559e-01, -7.4059e-02,  5.8632e-02, -8.1564e-02,  1.7192e-02],\n",
       "                       ...,\n",
       "                       [ 5.2315e-02,  1.6432e-01, -4.1654e-02,  1.5325e-02,  2.8996e-02],\n",
       "                       [ 6.9300e-03,  3.9455e-02,  8.3214e-03, -1.3036e-01, -7.3669e-02],\n",
       "                       [-6.5765e-02, -1.1853e-01,  4.8825e-02,  9.3607e-02, -1.5216e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.1.1.weight',\n",
       "              tensor([0.9722, 0.9357, 0.9484, 0.9477, 0.9739, 0.9537, 0.9841, 0.9407, 0.9567,\n",
       "                      0.9408, 0.9677, 0.9597, 1.0016, 0.9671, 0.9639, 0.9408, 0.9698, 0.9637,\n",
       "                      0.9410, 0.9552, 0.9355, 0.9578, 0.9649, 0.9530, 0.9647, 0.9949, 0.9994,\n",
       "                      0.9352, 0.9620, 0.9830, 0.9396, 0.9447, 0.9794, 0.9663, 0.9718, 0.9526,\n",
       "                      0.9634, 0.9594, 0.9903, 0.9402, 0.9425, 0.9839, 0.9811, 0.9757, 0.9702,\n",
       "                      0.9685, 0.9703, 0.9493, 0.9458, 0.9343, 0.9509, 0.9749, 0.9513, 0.9507,\n",
       "                      0.9554, 0.9404, 0.9541, 0.9664, 0.9620, 0.9471, 0.9134, 0.9650, 0.9607,\n",
       "                      0.9568], dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.1.1.bias',\n",
       "              tensor([ 0.0115, -0.0010,  0.0144,  0.0087, -0.0084, -0.0146, -0.0037, -0.0025,\n",
       "                       0.0072, -0.0294, -0.0195, -0.0080,  0.0052, -0.0137, -0.0018, -0.0110,\n",
       "                      -0.0178,  0.0073, -0.0092,  0.0066,  0.0005, -0.0205,  0.0090, -0.0065,\n",
       "                      -0.0090,  0.0028,  0.0182,  0.0011, -0.0046,  0.0104, -0.0083, -0.0009,\n",
       "                       0.0114, -0.0061, -0.0067, -0.0157, -0.0099, -0.0049, -0.0079, -0.0008,\n",
       "                      -0.0133, -0.0042, -0.0026, -0.0038,  0.0067, -0.0016,  0.0125,  0.0097,\n",
       "                      -0.0110, -0.0143, -0.0157,  0.0014, -0.0142,  0.0033,  0.0104,  0.0029,\n",
       "                       0.0168, -0.0145, -0.0007, -0.0061, -0.0240, -0.0042, -0.0238,  0.0014],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.2460, -0.7263, -0.8839, -0.4444, -0.2036,  0.5146,  0.0956, -0.1903,\n",
       "                      -0.8145, -0.1859,  0.0559, -0.2376, -0.6705,  0.4210, -0.0619, -0.4655,\n",
       "                      -0.1691, -0.9954, -0.2535, -0.0864,  0.0398, -0.5552,  0.4488, -1.6294,\n",
       "                       0.4878, -0.5536, -0.5203, -0.2061,  0.7451, -0.2923, -0.5234,  0.4983,\n",
       "                      -0.1976, -0.6074, -0.2561,  0.1104,  0.3511,  0.2087, -0.7091, -0.1421,\n",
       "                       0.2730, -0.2149,  0.7309,  0.1189, -0.1028,  0.1600, -0.3771, -0.3887,\n",
       "                       0.8279, -0.0818, -0.1739,  0.3368,  0.2999, -0.8493, -0.1990, -0.5888,\n",
       "                      -0.0979, -1.0269,  0.5693,  0.3546, -0.2058,  0.5056, -0.4248, -0.2196],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.1.1.running_var',\n",
       "              tensor([0.3385, 0.7571, 0.9774, 0.4811, 0.4292, 0.3068, 0.5528, 1.1460, 0.5158,\n",
       "                      0.5674, 0.6217, 0.5287, 0.4167, 0.6227, 0.7274, 0.4905, 0.3726, 0.5732,\n",
       "                      0.6586, 0.5560, 0.9818, 0.7259, 0.4499, 0.5902, 0.4680, 0.4380, 0.3904,\n",
       "                      0.7961, 0.9763, 0.7018, 0.6855, 0.4412, 0.4781, 0.4218, 0.6745, 0.4236,\n",
       "                      0.6542, 0.5003, 0.5218, 0.5681, 0.3624, 0.3073, 0.5675, 0.4707, 0.4017,\n",
       "                      0.8201, 0.4755, 0.7380, 0.6446, 0.6470, 0.4889, 0.3855, 0.8941, 0.7151,\n",
       "                      0.4213, 0.6554, 0.5438, 0.4121, 0.5246, 0.4166, 1.0352, 0.4654, 0.6506,\n",
       "                      0.3318], dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.1.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0887],\n",
       "                       [-0.1184],\n",
       "                       [ 0.0219],\n",
       "                       ...,\n",
       "                       [-0.0692],\n",
       "                       [-0.0604],\n",
       "                       [ 0.0245]],\n",
       "              \n",
       "                      [[-0.1176],\n",
       "                       [ 0.0129],\n",
       "                       [-0.0251],\n",
       "                       ...,\n",
       "                       [-0.1393],\n",
       "                       [-0.1761],\n",
       "                       [-0.1405]],\n",
       "              \n",
       "                      [[-0.0464],\n",
       "                       [-0.0757],\n",
       "                       [ 0.2077],\n",
       "                       ...,\n",
       "                       [-0.0788],\n",
       "                       [-0.1461],\n",
       "                       [ 0.0595]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0047],\n",
       "                       [-0.0862],\n",
       "                       [ 0.0382],\n",
       "                       ...,\n",
       "                       [ 0.1366],\n",
       "                       [-0.1257],\n",
       "                       [-0.0427]],\n",
       "              \n",
       "                      [[ 0.0675],\n",
       "                       [-0.1607],\n",
       "                       [-0.1476],\n",
       "                       ...,\n",
       "                       [ 0.1047],\n",
       "                       [-0.3514],\n",
       "                       [ 0.0181]],\n",
       "              \n",
       "                      [[ 0.2848],\n",
       "                       [ 0.0039],\n",
       "                       [-0.0269],\n",
       "                       ...,\n",
       "                       [-0.0451],\n",
       "                       [ 0.1248],\n",
       "                       [-0.1390]]], dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.2.1.weight',\n",
       "              tensor([-1.4484e-02,  2.4060e-02, -1.5821e-02,  1.7680e-02,  1.0004e-02,\n",
       "                       6.7027e-03,  7.1994e-03, -5.7556e-03,  2.7408e-02, -1.5671e-02,\n",
       "                       2.8246e-02, -1.3701e-02,  9.5285e-03, -8.2807e-03,  2.7995e-02,\n",
       "                       5.1928e-03,  2.7838e-02, -1.2236e-02, -1.1792e-02, -1.2598e-03,\n",
       "                       1.3194e-02,  3.9099e-02,  1.8926e-02, -9.4776e-03, -3.3609e-02,\n",
       "                      -1.6652e-02,  1.4418e-02, -1.3012e-02,  1.7943e-03,  1.7996e-05,\n",
       "                      -1.0830e-02,  3.4367e-02,  6.0117e-03, -7.8726e-03, -1.8774e-02,\n",
       "                       1.6318e-02,  8.7413e-03, -2.2869e-02,  3.0065e-02, -5.1092e-02,\n",
       "                      -4.1643e-03, -1.0612e-02, -1.0678e-02,  2.8561e-02, -1.4670e-02,\n",
       "                      -1.2908e-02, -1.1333e-02,  1.7391e-02, -1.0823e-02,  1.4037e-02,\n",
       "                      -2.5065e-02,  7.2836e-03, -5.9721e-03,  4.3940e-03,  1.2836e-03,\n",
       "                       1.4670e-02, -6.0508e-03, -4.2665e-04,  5.8563e-03, -2.4786e-02,\n",
       "                       1.6972e-03, -1.1594e-02, -2.2277e-02,  2.7276e-02, -2.4767e-02,\n",
       "                       2.1095e-05,  1.6215e-02,  1.6422e-02, -1.0606e-02, -1.4994e-02,\n",
       "                      -1.5378e-02, -1.0347e-02,  1.5926e-02,  1.2498e-02, -2.7314e-02,\n",
       "                      -2.0244e-03, -4.3138e-04,  1.9042e-02,  6.3526e-03,  1.5578e-02,\n",
       "                       3.7470e-03,  1.5024e-02, -3.4547e-02, -7.3746e-03,  3.1425e-03,\n",
       "                      -7.4004e-03,  8.9991e-03,  8.6577e-03, -2.4076e-02,  1.2354e-02,\n",
       "                       4.3793e-02,  1.3150e-02,  3.6373e-03,  2.2131e-03, -1.4569e-02,\n",
       "                       4.9260e-03, -1.1855e-02, -1.8495e-02,  2.3242e-02,  7.7317e-03,\n",
       "                      -1.7826e-02, -4.1511e-03, -4.6887e-05, -2.9618e-02, -9.9099e-03,\n",
       "                       9.9212e-03, -8.5481e-03,  1.7056e-02, -8.1480e-03,  2.2757e-02,\n",
       "                       4.1966e-03,  1.2208e-02,  2.9778e-02, -2.2393e-02, -4.9657e-03,\n",
       "                       1.0071e-02, -2.8339e-02, -1.7792e-02, -2.3064e-02, -1.0165e-03,\n",
       "                      -7.5977e-03, -1.2112e-02, -3.8129e-03, -2.4011e-02, -1.8196e-02,\n",
       "                       2.0467e-03, -1.0265e-02,  1.3830e-03, -1.5956e-03,  1.3412e-02,\n",
       "                      -3.3821e-02,  2.2743e-02, -2.5334e-03,  4.7229e-03, -1.6918e-04,\n",
       "                      -7.7931e-03, -6.5810e-03, -2.3996e-02,  1.7700e-02, -1.1242e-02,\n",
       "                      -2.2661e-02,  2.3588e-02,  3.0319e-02, -3.3790e-02, -5.3754e-03,\n",
       "                      -3.5318e-02, -2.9229e-02,  1.5058e-02, -2.2024e-03, -3.5551e-03,\n",
       "                      -1.4546e-02,  1.1025e-02, -1.7624e-02, -3.8083e-03,  7.2399e-04,\n",
       "                       1.1371e-02, -2.7100e-02, -1.9468e-02,  7.0739e-03, -1.2828e-02,\n",
       "                       1.0319e-02, -2.7104e-02,  7.1754e-03,  1.8182e-02,  7.7546e-03,\n",
       "                      -3.9762e-03, -2.5968e-02,  2.3149e-02,  1.3973e-03,  2.4551e-02,\n",
       "                      -2.6404e-02, -1.7582e-02,  1.2709e-02, -2.5211e-02, -1.5519e-02,\n",
       "                       1.4110e-02,  3.2698e-02,  3.0017e-02,  1.5884e-02, -2.7614e-02,\n",
       "                      -4.8938e-03,  1.5177e-03,  1.8752e-02, -1.9644e-03, -1.4398e-02,\n",
       "                      -1.0213e-02, -5.2851e-03, -3.8904e-02,  1.8935e-02, -7.9892e-03,\n",
       "                       3.9587e-02,  2.9115e-02, -7.2967e-03,  1.6550e-03, -1.6670e-02,\n",
       "                       2.1029e-02, -2.1488e-02,  1.6215e-02,  7.9129e-03, -2.0565e-02,\n",
       "                       1.6048e-02, -1.2154e-02,  1.5583e-02, -8.4278e-03,  8.6094e-03,\n",
       "                       1.0712e-02, -1.9833e-03, -4.4301e-03,  1.4733e-02, -6.4257e-03,\n",
       "                       6.4938e-03,  2.2979e-02, -5.5136e-02, -3.6341e-02,  2.2795e-03,\n",
       "                       2.3132e-02, -5.5454e-03,  1.1062e-03,  1.3274e-02,  1.1317e-03,\n",
       "                      -3.5712e-03,  2.2272e-02,  1.2925e-02, -5.5573e-03,  2.4395e-02,\n",
       "                      -8.0691e-03,  1.2851e-02,  1.9469e-03, -1.2008e-02,  3.6867e-02,\n",
       "                       2.0844e-02,  1.2165e-02,  4.1987e-03,  1.8967e-02, -2.3222e-02,\n",
       "                      -1.7012e-03, -1.0029e-02,  6.7193e-04, -2.4867e-02,  2.9023e-02,\n",
       "                      -7.1035e-03,  2.0554e-02,  1.5082e-02, -4.6764e-03, -4.3468e-02,\n",
       "                      -1.4599e-02, -1.4143e-02,  2.4892e-02,  8.1495e-03, -9.3870e-03,\n",
       "                      -1.0902e-02,  1.5992e-02, -2.2400e-02, -5.8628e-03,  1.5269e-02,\n",
       "                      -3.4191e-02], dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.2.1.bias',\n",
       "              tensor([ 2.6467e-03,  3.5621e-03,  2.4586e-02,  9.1864e-04,  5.4386e-03,\n",
       "                      -1.3073e-02,  1.4003e-02,  4.7672e-03,  1.0467e-02, -7.4992e-03,\n",
       "                       7.8223e-03, -8.1994e-03,  1.5500e-02, -1.5284e-02,  1.0318e-02,\n",
       "                       1.1017e-02,  2.3494e-02,  5.9243e-03,  2.2890e-02, -3.1521e-03,\n",
       "                       2.6486e-03, -3.2956e-03, -9.4196e-04,  6.5877e-03,  2.5979e-03,\n",
       "                      -2.4859e-02,  1.9443e-04,  1.9493e-02,  5.1488e-03,  3.9546e-03,\n",
       "                      -1.1861e-02,  1.6343e-02, -1.2308e-02,  1.6588e-02,  1.4449e-02,\n",
       "                      -2.9676e-03,  8.4376e-03,  2.6566e-02,  7.5975e-04,  1.4410e-03,\n",
       "                       4.0850e-03, -1.9492e-03, -4.1031e-03,  1.1416e-02,  1.7308e-02,\n",
       "                      -4.6010e-03, -1.0145e-02,  7.5677e-03, -5.0903e-03,  7.8801e-03,\n",
       "                      -6.8099e-03,  3.6849e-03,  1.6951e-02,  1.9921e-02, -1.3318e-02,\n",
       "                       3.8281e-03,  2.5204e-03,  1.2347e-02,  5.8227e-03,  8.4169e-03,\n",
       "                      -1.4195e-02,  5.1661e-03,  2.8175e-03,  1.5309e-02,  7.6095e-04,\n",
       "                       5.7642e-04, -9.4214e-03,  1.4950e-02,  6.5317e-03, -1.4393e-02,\n",
       "                       8.7542e-03,  1.7641e-02,  1.0705e-02, -8.3376e-03,  3.7260e-03,\n",
       "                       1.6089e-02,  9.4727e-03, -1.5217e-02,  8.7095e-03,  1.1258e-02,\n",
       "                       1.5661e-02, -2.2282e-04,  1.5608e-02,  8.8063e-03,  1.5374e-03,\n",
       "                       5.7068e-03,  5.8167e-03,  6.3144e-03,  1.2047e-02, -5.6070e-03,\n",
       "                       7.8076e-03,  2.0185e-02,  2.1289e-02,  3.5340e-03,  5.4981e-03,\n",
       "                      -1.3772e-02,  9.1510e-03,  7.6078e-03,  1.9582e-02, -1.1931e-02,\n",
       "                       2.8270e-02, -3.5271e-03, -9.0778e-03, -2.3380e-02,  1.3050e-02,\n",
       "                       6.4681e-03, -1.9051e-02,  6.6048e-03,  7.6475e-03,  2.2611e-03,\n",
       "                      -9.8005e-03, -4.5752e-03,  1.2396e-02,  1.1839e-02,  8.9775e-03,\n",
       "                       8.5787e-03,  1.3353e-02,  1.1867e-02,  1.1656e-02, -1.1063e-02,\n",
       "                       1.0566e-02,  1.2834e-02,  6.3888e-03,  1.3243e-03, -6.5305e-03,\n",
       "                       1.1252e-02,  7.8873e-03,  4.9865e-03,  5.5484e-03,  4.0718e-03,\n",
       "                       2.8809e-03,  1.3060e-04,  7.1151e-03,  6.6269e-03, -4.1984e-03,\n",
       "                      -1.4836e-02, -5.4421e-04,  1.8262e-02,  9.4871e-03, -8.7651e-03,\n",
       "                      -4.2096e-03,  9.2563e-03, -1.3128e-03,  1.6432e-02, -1.0688e-02,\n",
       "                      -4.6770e-03,  3.3567e-03, -3.0195e-03,  1.1251e-02,  1.2881e-02,\n",
       "                      -1.8275e-03,  2.1332e-02,  1.3575e-02,  1.6090e-02,  7.5408e-03,\n",
       "                       1.6935e-02,  1.1664e-02,  1.5063e-02, -5.0726e-04, -1.9454e-02,\n",
       "                       4.6041e-03,  1.2843e-03, -5.5430e-03,  2.0276e-02,  9.3970e-03,\n",
       "                       6.6393e-03, -7.2259e-03,  2.0915e-02,  1.4294e-02,  1.6495e-02,\n",
       "                       1.2451e-02,  4.9003e-03, -5.1965e-03,  2.0434e-02, -1.6000e-02,\n",
       "                      -3.0319e-03,  5.5181e-03,  2.7155e-02,  9.9750e-03,  2.1698e-03,\n",
       "                      -5.7021e-03,  1.9082e-02, -1.2070e-02, -4.4871e-03,  1.1556e-02,\n",
       "                       7.4446e-03,  1.2396e-02,  1.6811e-02,  6.2275e-04,  9.8089e-04,\n",
       "                      -1.1326e-02,  8.8346e-03,  1.3930e-02, -1.5289e-02,  9.0687e-03,\n",
       "                       9.0314e-03, -1.0433e-02,  5.0957e-03,  1.3083e-02, -1.7574e-02,\n",
       "                       1.1813e-02,  2.4866e-03,  1.5218e-02,  2.1210e-02,  1.6170e-03,\n",
       "                      -6.4291e-03,  1.9493e-02, -9.3202e-03,  8.3216e-05,  1.1686e-02,\n",
       "                       3.9976e-03,  1.5542e-02,  7.6439e-03,  1.4180e-02,  4.6126e-03,\n",
       "                       9.1490e-03,  3.1062e-03,  1.4317e-02,  9.1694e-03,  6.7761e-04,\n",
       "                      -2.7925e-03, -5.3314e-03,  1.3476e-02,  1.5350e-03,  2.6178e-03,\n",
       "                       8.7681e-03,  3.2841e-03,  4.3396e-03, -2.6013e-02, -4.8178e-03,\n",
       "                      -1.0945e-02,  9.1176e-03,  1.0112e-02,  4.4025e-03,  2.7864e-03,\n",
       "                       5.5671e-03,  9.2334e-03,  2.0519e-04,  6.6878e-03,  1.5838e-02,\n",
       "                      -6.5399e-03,  7.2038e-03,  1.2324e-02,  9.2483e-04,  1.0488e-02,\n",
       "                       1.3904e-02,  1.0555e-02,  2.2139e-02, -6.6749e-03, -1.2933e-02,\n",
       "                       2.2974e-02,  9.9409e-03,  1.0546e-02,  2.4950e-02,  2.2768e-02,\n",
       "                       7.5406e-03], dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.2.1.running_mean',\n",
       "              tensor([ 0.1799,  0.2545, -1.0684, -0.0301,  0.0502, -0.3574, -0.0693, -0.3150,\n",
       "                      -0.1281,  0.0464, -0.5032, -0.3386, -0.4414,  0.0697, -0.0848,  0.2036,\n",
       "                      -0.0998,  0.2620, -0.4533,  0.1850,  0.3123, -0.1771, -0.2537,  0.3064,\n",
       "                       0.7670,  0.5196,  0.1614,  0.5801,  0.4516,  0.0686,  0.4415, -0.3302,\n",
       "                      -0.1308, -0.3081,  0.4754,  0.1104,  0.0675,  0.3615, -0.1302,  0.3732,\n",
       "                      -0.1112,  0.3024,  0.3030,  0.0607,  0.1409,  0.1522, -0.1603,  0.3408,\n",
       "                      -0.2801,  0.3629, -0.1850,  0.1913, -0.1634, -0.1457,  0.2779, -0.4692,\n",
       "                      -0.1993,  0.0512, -0.1551,  0.5274, -0.0227,  0.6553, -0.2389, -0.4373,\n",
       "                       0.1403,  0.1935, -0.4901, -0.0802,  0.3918, -0.2360, -0.0385,  0.0058,\n",
       "                       0.1625,  0.2746, -0.1614,  0.0605,  0.2209, -0.0312,  0.5692, -0.2589,\n",
       "                      -0.2791,  0.1027,  0.2905, -0.0795, -0.1235, -0.4761, -0.4858,  0.1625,\n",
       "                       0.4696,  0.9872,  0.2046,  0.3632, -0.2589,  0.4811,  0.4034,  0.2007,\n",
       "                       0.5738, -0.4710,  0.3987, -0.1481, -0.2564, -0.4176,  0.0557,  0.4308,\n",
       "                       0.0284, -0.5646, -0.5781,  0.6282,  0.1819,  0.2029, -0.0011, -0.4480,\n",
       "                       0.6909,  0.4385, -0.2755, -0.0793,  0.4621, -0.5441,  0.6407, -0.0380,\n",
       "                       0.3739, -0.0545,  0.5805, -0.4208, -0.2036, -0.5364,  0.1907, -0.4222,\n",
       "                       0.0274,  0.1612, -0.5792, -0.5994,  0.6857, -0.6049, -0.4200, -0.2065,\n",
       "                       0.1632,  0.1546,  0.1242,  0.1398, -0.3307,  0.2271,  0.4490,  0.4329,\n",
       "                      -0.0159, -0.1483, -0.4382, -0.2899, -0.1896, -0.5038, -0.1710, -0.0723,\n",
       "                       0.3827,  0.0726, -0.2493,  0.2988,  0.1441,  0.2591, -0.7494, -0.0289,\n",
       "                      -0.7942,  0.2059, -0.2673, -0.6443, -0.4627, -0.3680, -0.4649, -0.0570,\n",
       "                       0.3165, -0.2184, -0.0011,  0.2783,  0.2601, -0.1636,  0.1370,  0.1517,\n",
       "                      -0.2626, -0.2333, -0.3996,  0.1684, -0.3741, -0.0440, -0.3362, -0.3169,\n",
       "                      -0.3687, -0.2183,  0.2959, -0.3455, -0.0560, -0.1653,  0.2082, -0.3645,\n",
       "                      -0.5862,  0.4253, -0.5083,  0.1078, -0.0019,  0.0697, -0.1366, -0.4649,\n",
       "                      -0.2601, -0.2101,  0.6666,  0.2146,  0.3121, -0.3148, -0.0060,  0.3212,\n",
       "                      -0.0285,  0.1868, -0.3835, -0.0466,  0.1268,  0.0465, -0.2208,  0.4443,\n",
       "                      -0.1136, -0.2645,  0.5335,  0.5235, -0.3720, -0.9376,  0.0054, -0.5012,\n",
       "                      -0.7063, -0.0275,  0.2142, -0.1865,  0.1894,  0.2918, -0.1469, -0.3304,\n",
       "                      -0.2009,  0.4353, -0.2344, -0.2793, -0.3011,  0.0890, -0.2630,  0.0165,\n",
       "                       0.6288,  0.4842,  0.4707, -0.0747, -0.0866,  0.0673,  0.3266,  0.4181,\n",
       "                      -0.0662, -0.0472,  0.5022,  0.2459, -0.3195, -0.2582, -0.2492, -0.1294],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.2.1.running_var',\n",
       "              tensor([0.5083, 0.4525, 0.4264, 0.4030, 0.2131, 0.2214, 0.0872, 0.2819, 0.2365,\n",
       "                      0.3857, 0.3239, 0.2090, 0.2513, 0.2205, 0.4706, 0.2331, 0.4063, 0.5280,\n",
       "                      0.1390, 0.4195, 0.3273, 0.4307, 0.3184, 0.3764, 0.6338, 0.3207, 0.3061,\n",
       "                      0.4294, 0.2039, 0.1357, 0.3558, 0.3176, 0.3359, 0.4530, 0.3442, 0.5268,\n",
       "                      0.2307, 0.3414, 0.4628, 0.4066, 0.0804, 0.1596, 0.2515, 0.4422, 0.2434,\n",
       "                      0.2322, 0.6315, 0.3841, 0.7122, 0.4020, 0.2835, 0.2713, 0.2560, 0.1708,\n",
       "                      0.3551, 0.3925, 0.2648, 0.1672, 0.3340, 0.3882, 0.0428, 0.5039, 0.4115,\n",
       "                      0.3638, 0.4886, 0.2170, 0.3542, 0.2313, 0.3556, 0.4583, 0.3788, 0.2604,\n",
       "                      0.1423, 0.5101, 0.4413, 0.0444, 0.1431, 0.3172, 0.4177, 0.4100, 0.2575,\n",
       "                      0.2465, 0.2106, 0.2513, 0.2056, 0.4136, 0.3246, 0.2026, 0.4262, 0.5689,\n",
       "                      0.4934, 0.3784, 0.2777, 0.2366, 0.1733, 0.3448, 0.5307, 0.2373, 0.4583,\n",
       "                      0.3108, 0.3837, 0.2506, 0.0355, 0.2489, 0.1779, 0.2896, 0.3316, 0.3510,\n",
       "                      0.2836, 0.1879, 0.0991, 0.3623, 0.4366, 0.5086, 0.2951, 0.3674, 0.2996,\n",
       "                      0.4407, 0.2471, 0.1693, 0.1206, 0.3549, 0.5662, 0.4759, 0.2303, 0.2170,\n",
       "                      0.1431, 0.2873, 0.0623, 0.3189, 0.2714, 0.2241, 0.2750, 0.2059, 0.2472,\n",
       "                      0.1296, 0.0951, 0.6274, 0.2723, 0.1928, 0.2035, 0.2051, 0.2913, 0.2437,\n",
       "                      0.1742, 0.3946, 0.1887, 0.4072, 0.0466, 0.5468, 0.4535, 0.2292, 0.3212,\n",
       "                      0.2862, 0.4399, 0.3765, 0.5877, 0.2998, 0.4328, 0.0761, 0.2586, 0.2693,\n",
       "                      0.1558, 0.1633, 0.2083, 0.2559, 0.5269, 0.3179, 0.3107, 0.3687, 0.2612,\n",
       "                      0.3297, 0.3701, 0.2630, 0.4493, 0.5962, 0.3719, 0.4477, 0.4263, 0.4919,\n",
       "                      0.2203, 0.2870, 0.3967, 0.4773, 0.3568, 0.5817, 0.3578, 0.6070, 0.2943,\n",
       "                      0.0964, 0.2554, 0.6090, 0.3904, 0.3197, 0.2639, 0.2806, 0.2134, 0.1997,\n",
       "                      0.2890, 0.4716, 0.1724, 0.3214, 0.3035, 0.1765, 0.1868, 0.3011, 0.1621,\n",
       "                      0.0784, 0.2137, 0.2643, 0.1179, 0.3438, 0.4663, 0.2542, 0.0423, 0.4008,\n",
       "                      0.3419, 0.1204, 0.3841, 0.4801, 0.2602, 0.3955, 0.0697, 0.4197, 0.6130,\n",
       "                      0.2240, 0.2783, 0.1415, 0.4425, 0.3721, 0.2576, 0.1467, 0.1896, 0.4804,\n",
       "                      0.3742, 0.2743, 0.2529, 0.0914, 0.4352, 0.4298, 0.1658, 0.1864, 0.4956,\n",
       "                      0.2357, 0.2129, 0.1157, 0.2210, 0.4624, 0.0971, 0.3878, 0.3802, 0.5571,\n",
       "                      0.2806, 0.4068, 0.4196, 0.3667], dtype=torch.float64)),\n",
       "             ('5.1.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.2.convs.0.0.weight',\n",
       "              tensor([[[ 0.2465],\n",
       "                       [ 0.0327],\n",
       "                       [ 0.1565],\n",
       "                       ...,\n",
       "                       [ 0.0351],\n",
       "                       [ 0.2499],\n",
       "                       [ 0.0393]],\n",
       "              \n",
       "                      [[-0.1605],\n",
       "                       [-0.0112],\n",
       "                       [-0.1289],\n",
       "                       ...,\n",
       "                       [ 0.0487],\n",
       "                       [-0.1187],\n",
       "                       [-0.1153]],\n",
       "              \n",
       "                      [[ 0.0234],\n",
       "                       [ 0.0714],\n",
       "                       [ 0.0335],\n",
       "                       ...,\n",
       "                       [-0.0326],\n",
       "                       [ 0.1077],\n",
       "                       [ 0.0157]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0647],\n",
       "                       [ 0.1698],\n",
       "                       [-0.2075],\n",
       "                       ...,\n",
       "                       [ 0.0198],\n",
       "                       [ 0.0900],\n",
       "                       [ 0.0786]],\n",
       "              \n",
       "                      [[ 0.0538],\n",
       "                       [ 0.0904],\n",
       "                       [-0.0362],\n",
       "                       ...,\n",
       "                       [ 0.0161],\n",
       "                       [ 0.1532],\n",
       "                       [ 0.0023]],\n",
       "              \n",
       "                      [[ 0.1125],\n",
       "                       [-0.0409],\n",
       "                       [ 0.0799],\n",
       "                       ...,\n",
       "                       [-0.0316],\n",
       "                       [-0.0877],\n",
       "                       [ 0.0267]]], dtype=torch.float64)),\n",
       "             ('5.2.convs.0.1.weight',\n",
       "              tensor([0.9718, 0.9777, 0.9873, 0.9560, 0.9861, 0.9529, 0.9876, 0.9585, 0.9495,\n",
       "                      0.9689, 0.9613, 0.9486, 0.9840, 0.9657, 0.9529, 0.9297, 0.9400, 0.9771,\n",
       "                      0.9702, 0.9706, 0.9701, 0.9638, 0.9673, 0.9656, 0.9542, 0.9832, 0.9519,\n",
       "                      0.9800, 0.9740, 0.9579, 0.9796, 0.9857, 0.9505, 0.9300, 0.9698, 0.9621,\n",
       "                      0.9450, 0.9521, 0.9544, 0.9788, 0.9951, 0.9470, 0.9968, 0.9734, 1.0029,\n",
       "                      0.9602, 0.9962, 0.9744, 0.9632, 0.9564, 0.9475, 0.9758, 0.9684, 0.9493,\n",
       "                      0.9586, 0.9765, 1.0156, 0.9701, 1.0021, 0.9873, 0.9622, 0.9918, 0.9635,\n",
       "                      0.9517], dtype=torch.float64)),\n",
       "             ('5.2.convs.0.1.bias',\n",
       "              tensor([ 0.0128,  0.0049,  0.0139,  0.0025,  0.0016, -0.0142,  0.0261, -0.0112,\n",
       "                      -0.0076,  0.0091,  0.0041, -0.0126,  0.0117,  0.0036, -0.0037, -0.0279,\n",
       "                      -0.0085, -0.0267, -0.0282,  0.0037, -0.0136, -0.0065,  0.0166,  0.0084,\n",
       "                      -0.0028,  0.0073,  0.0134, -0.0006,  0.0160,  0.0039, -0.0076,  0.0151,\n",
       "                      -0.0118, -0.0019,  0.0151, -0.0161, -0.0051, -0.0081, -0.0138,  0.0108,\n",
       "                       0.0153, -0.0089,  0.0191,  0.0055,  0.0013, -0.0054,  0.0010, -0.0022,\n",
       "                      -0.0028, -0.0218, -0.0210, -0.0124, -0.0024, -0.0183,  0.0074, -0.0113,\n",
       "                       0.0223,  0.0022,  0.0126,  0.0226,  0.0154,  0.0154,  0.0166, -0.0041],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convs.0.1.running_mean',\n",
       "              tensor([ 0.1861, -0.4981,  0.1280,  0.3149,  0.5631,  0.1058, -0.5804,  0.5050,\n",
       "                       0.4690, -0.0734,  0.2646,  0.2869, -0.1322, -0.5256, -0.1596,  0.6383,\n",
       "                      -0.4537, -0.0892,  0.0048,  0.2870, -0.1865, -0.1021,  0.3619,  0.1271,\n",
       "                      -0.5318,  0.8270,  0.0630,  0.3405, -0.3889, -0.2037,  0.3884, -0.5711,\n",
       "                      -0.3243, -0.1310,  0.2976,  0.3313, -0.2495,  0.1354, -0.3669,  0.2238,\n",
       "                      -0.1816,  0.2281,  0.7505, -0.4221, -0.1864, -0.1407, -0.3311,  0.0103,\n",
       "                       0.3222,  0.2643,  0.2738,  0.3247, -0.1160, -0.2153, -0.0671, -0.8978,\n",
       "                      -0.0743,  0.3005, -0.5724,  0.2061, -0.2143,  0.5772,  0.6037, -0.4130],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convs.0.1.running_var',\n",
       "              tensor([0.2737, 0.2852, 0.1659, 0.1925, 0.4861, 0.3042, 0.6225, 0.1398, 0.8645,\n",
       "                      0.2841, 0.1744, 0.4147, 0.1803, 0.4634, 0.6174, 0.4701, 0.5342, 0.1912,\n",
       "                      0.2771, 0.2143, 0.3767, 0.5351, 0.4776, 0.3440, 0.4651, 1.0038, 0.6621,\n",
       "                      0.3207, 0.4459, 0.2635, 0.1684, 0.5185, 0.1838, 1.0525, 0.7845, 0.4282,\n",
       "                      0.7125, 1.3959, 0.7664, 0.3390, 0.3703, 0.4147, 0.6935, 0.5135, 0.4189,\n",
       "                      0.2424, 0.1737, 0.1830, 0.2703, 0.4573, 0.7137, 0.4623, 0.8958, 1.0623,\n",
       "                      0.3095, 0.1404, 0.3933, 0.2169, 0.2733, 0.3009, 0.3690, 0.7798, 2.1939,\n",
       "                      1.0433], dtype=torch.float64)),\n",
       "             ('5.2.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.2.convs.1.0.weight',\n",
       "              tensor([[[ 0.0267, -0.0278, -0.0824, -0.0077,  0.0798],\n",
       "                       [-0.1499, -0.0092, -0.0124,  0.0436, -0.0924],\n",
       "                       [-0.0308,  0.0029,  0.1709,  0.0220,  0.0762],\n",
       "                       ...,\n",
       "                       [-0.0044, -0.1050,  0.0058, -0.0167, -0.0694],\n",
       "                       [-0.0729,  0.1170, -0.0244, -0.0123, -0.0150],\n",
       "                       [ 0.0932,  0.0632, -0.0174,  0.1201,  0.0390]],\n",
       "              \n",
       "                      [[ 0.0006,  0.0196,  0.0151, -0.0849, -0.1938],\n",
       "                       [-0.0505, -0.0889, -0.0670, -0.0169, -0.0062],\n",
       "                       [ 0.1040, -0.0827,  0.0639,  0.0728,  0.0010],\n",
       "                       ...,\n",
       "                       [ 0.0433, -0.0441,  0.0453,  0.0311, -0.1213],\n",
       "                       [ 0.0293,  0.0865,  0.1829,  0.1123, -0.1026],\n",
       "                       [ 0.1678,  0.0870,  0.0900,  0.0161, -0.0459]],\n",
       "              \n",
       "                      [[ 0.1008,  0.0028,  0.0360, -0.0558, -0.0558],\n",
       "                       [-0.1065, -0.0553,  0.0231, -0.0518, -0.1905],\n",
       "                       [ 0.1324, -0.1144,  0.0928, -0.0772, -0.0241],\n",
       "                       ...,\n",
       "                       [-0.0225, -0.0419, -0.1298, -0.1394,  0.0419],\n",
       "                       [ 0.1130,  0.0456,  0.0146, -0.0136, -0.0062],\n",
       "                       [-0.0142, -0.0184, -0.1355, -0.0254, -0.1185]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0244,  0.0019, -0.0136, -0.0343,  0.0246],\n",
       "                       [-0.1187,  0.0454,  0.0309,  0.0833,  0.1114],\n",
       "                       [ 0.0173,  0.0710, -0.0162, -0.1391,  0.0260],\n",
       "                       ...,\n",
       "                       [-0.0933,  0.1038, -0.0115, -0.1776, -0.0114],\n",
       "                       [ 0.0270, -0.1323, -0.0570, -0.0025,  0.0352],\n",
       "                       [-0.0348, -0.0544,  0.0174,  0.1369, -0.0911]],\n",
       "              \n",
       "                      [[ 0.2121,  0.0498, -0.0729,  0.0567,  0.0127],\n",
       "                       [-0.0625,  0.0561,  0.0045,  0.0480,  0.0451],\n",
       "                       [ 0.0325, -0.0058, -0.0166, -0.0508, -0.0300],\n",
       "                       ...,\n",
       "                       [-0.0131, -0.0609, -0.0637,  0.0036,  0.0440],\n",
       "                       [-0.0642, -0.0043, -0.0678, -0.0191,  0.0035],\n",
       "                       [-0.0985,  0.1032,  0.0250,  0.0416,  0.0501]],\n",
       "              \n",
       "                      [[-0.0639, -0.0551, -0.0403, -0.0509, -0.1249],\n",
       "                       [ 0.0133, -0.1062, -0.0041,  0.0765, -0.0700],\n",
       "                       [ 0.0836, -0.0446, -0.1639, -0.0522, -0.0371],\n",
       "                       ...,\n",
       "                       [ 0.0325,  0.0946, -0.0663,  0.1416,  0.0080],\n",
       "                       [ 0.1071, -0.0153, -0.0143, -0.0866,  0.0613],\n",
       "                       [-0.0047, -0.0542,  0.1036, -0.0031, -0.0496]]], dtype=torch.float64)),\n",
       "             ('5.2.convs.1.1.weight',\n",
       "              tensor([0.9452, 0.9588, 0.9792, 0.9549, 0.9559, 0.9314, 0.9493, 0.9904, 0.9600,\n",
       "                      0.9590, 0.9584, 0.9725, 0.9978, 0.9839, 0.9722, 1.0143, 0.9760, 0.9175,\n",
       "                      0.9549, 0.9702, 0.9459, 0.9395, 0.9378, 0.9889, 0.9777, 0.9716, 0.9648,\n",
       "                      0.9882, 0.9241, 1.0013, 0.9391, 1.0092, 0.9578, 0.9618, 0.9352, 0.9792,\n",
       "                      0.9429, 0.9581, 0.9732, 0.9706, 0.9443, 0.9790, 0.9635, 0.9627, 0.9195,\n",
       "                      0.9801, 0.9356, 0.9571, 0.9640, 1.0175, 0.9562, 0.9535, 0.9720, 0.9299,\n",
       "                      0.9137, 0.9616, 0.9601, 0.9708, 0.9492, 0.9554, 0.9506, 0.9405, 0.9406,\n",
       "                      0.9609], dtype=torch.float64)),\n",
       "             ('5.2.convs.1.1.bias',\n",
       "              tensor([ 0.0045,  0.0047,  0.0127, -0.0244, -0.0140, -0.0245, -0.0105, -0.0141,\n",
       "                       0.0062,  0.0182, -0.0048, -0.0060,  0.0137, -0.0113, -0.0158,  0.0264,\n",
       "                      -0.0057, -0.0167,  0.0010, -0.0059, -0.0086,  0.0008, -0.0085,  0.0071,\n",
       "                      -0.0100,  0.0156,  0.0007,  0.0075,  0.0046,  0.0374, -0.0289,  0.0265,\n",
       "                      -0.0030, -0.0223, -0.0086, -0.0152, -0.0172,  0.0038, -0.0017, -0.0097,\n",
       "                       0.0075,  0.0175,  0.0128, -0.0216,  0.0014, -0.0006, -0.0029, -0.0074,\n",
       "                      -0.0117,  0.0214,  0.0064, -0.0095, -0.0108, -0.0064, -0.0001,  0.0099,\n",
       "                       0.0096,  0.0060,  0.0199, -0.0330, -0.0325, -0.0204, -0.0217,  0.0018],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convs.1.1.running_mean',\n",
       "              tensor([-0.5590,  0.2872, -0.4774,  0.1880,  0.0862, -0.4153,  0.4243, -0.1905,\n",
       "                      -0.3249, -0.8446, -0.1133, -0.7955, -0.0531,  0.3375,  0.7426,  0.0348,\n",
       "                      -0.2056, -0.7436, -0.7210,  0.1127, -0.5343, -1.1006,  0.0898, -0.4722,\n",
       "                      -0.0682, -0.0822, -0.3062,  0.3147, -0.0716, -0.6074, -0.2978,  0.0640,\n",
       "                       0.5326,  0.4372,  0.4151,  0.1852, -0.8952, -0.8330, -0.3593, -1.0658,\n",
       "                      -0.2528, -0.5342, -0.4132,  0.6631, -0.6332, -0.3022, -0.5100,  0.5441,\n",
       "                      -0.1287, -0.4375, -0.2796, -0.2046, -0.2930, -0.8862, -0.5406,  0.0384,\n",
       "                       0.0638,  0.8414, -0.0291, -0.2924,  0.2907, -0.0937, -0.3307, -0.0902],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convs.1.1.running_var',\n",
       "              tensor([0.7594, 1.2881, 0.9124, 0.5638, 0.8131, 0.6536, 0.4475, 0.3312, 0.4160,\n",
       "                      1.1729, 0.4780, 0.5346, 0.4475, 0.3942, 0.6429, 0.4068, 0.9322, 1.0151,\n",
       "                      0.6030, 0.3815, 0.8400, 1.0118, 0.5295, 0.8745, 0.5717, 0.5017, 0.5024,\n",
       "                      0.3238, 0.6847, 0.7990, 0.6565, 0.4191, 0.6770, 0.9683, 0.5887, 0.4251,\n",
       "                      0.4819, 0.6405, 1.3750, 0.8232, 0.7416, 0.6119, 0.4224, 0.9823, 0.9154,\n",
       "                      0.7862, 0.4644, 1.0391, 0.6467, 0.4700, 0.5878, 0.4639, 0.4625, 1.9194,\n",
       "                      1.3265, 0.8025, 0.4810, 1.4349, 0.3681, 0.8418, 0.7349, 1.0717, 0.3841,\n",
       "                      0.9685], dtype=torch.float64)),\n",
       "             ('5.2.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.2.convs.2.0.weight',\n",
       "              tensor([[[ 0.0677],\n",
       "                       [-0.0901],\n",
       "                       [ 0.1860],\n",
       "                       ...,\n",
       "                       [ 0.1461],\n",
       "                       [-0.0717],\n",
       "                       [-0.2872]],\n",
       "              \n",
       "                      [[ 0.0078],\n",
       "                       [-0.0172],\n",
       "                       [-0.0999],\n",
       "                       ...,\n",
       "                       [-0.2508],\n",
       "                       [-0.1696],\n",
       "                       [ 0.1343]],\n",
       "              \n",
       "                      [[ 0.0590],\n",
       "                       [ 0.0999],\n",
       "                       [-0.1416],\n",
       "                       ...,\n",
       "                       [ 0.2324],\n",
       "                       [-0.2262],\n",
       "                       [-0.2073]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0620],\n",
       "                       [-0.0539],\n",
       "                       [ 0.2210],\n",
       "                       ...,\n",
       "                       [ 0.0141],\n",
       "                       [ 0.0642],\n",
       "                       [-0.0649]],\n",
       "              \n",
       "                      [[-0.0454],\n",
       "                       [-0.1227],\n",
       "                       [-0.0536],\n",
       "                       ...,\n",
       "                       [-0.0058],\n",
       "                       [-0.0805],\n",
       "                       [-0.0226]],\n",
       "              \n",
       "                      [[-0.0588],\n",
       "                       [ 0.1041],\n",
       "                       [ 0.0179],\n",
       "                       ...,\n",
       "                       [ 0.0193],\n",
       "                       [ 0.0241],\n",
       "                       [-0.2101]]], dtype=torch.float64)),\n",
       "             ('5.2.convs.2.1.weight',\n",
       "              tensor([-4.6090e-03,  4.4520e-02, -3.5884e-02, -5.1809e-03, -1.1737e-02,\n",
       "                       1.9843e-03,  2.5209e-03,  2.0795e-02, -1.6808e-02,  2.8201e-02,\n",
       "                       1.2781e-02,  4.1221e-03,  1.1184e-02,  1.8085e-02,  4.1422e-02,\n",
       "                       2.3324e-02, -3.2433e-02,  7.9463e-03, -3.4576e-02, -7.4583e-03,\n",
       "                      -1.3111e-02,  2.7582e-02, -1.1040e-02, -1.5856e-02,  8.8957e-03,\n",
       "                      -2.1841e-02,  3.2805e-02,  1.2532e-02,  1.5146e-02,  1.3258e-02,\n",
       "                      -6.7615e-03,  1.9925e-02,  9.7864e-03, -3.6253e-02, -1.2236e-02,\n",
       "                      -1.3461e-02,  4.4562e-03,  2.5041e-02, -2.6462e-02, -1.6940e-02,\n",
       "                       8.7100e-03,  1.9238e-02,  4.4784e-03,  3.4245e-02,  2.0531e-02,\n",
       "                       5.2516e-03, -3.5861e-03, -1.2469e-02, -5.2432e-02,  9.6388e-03,\n",
       "                      -5.6816e-04,  6.9154e-03,  8.5357e-03, -2.2981e-02,  1.1508e-02,\n",
       "                       1.9899e-02, -1.6698e-02, -8.0961e-03, -2.2956e-02,  3.0904e-03,\n",
       "                      -3.7870e-03,  1.5946e-02, -1.2915e-02, -1.0833e-02,  1.2147e-02,\n",
       "                       1.4231e-02,  1.2813e-02, -1.9293e-03,  1.0169e-02,  2.4295e-02,\n",
       "                      -3.0872e-02,  1.1113e-02,  1.9294e-03, -3.9288e-03, -2.3505e-02,\n",
       "                       1.8764e-02,  2.5213e-02,  2.4943e-02, -5.8700e-03,  1.3171e-02,\n",
       "                      -1.0873e-02, -6.3622e-03, -1.1389e-02, -1.3333e-02, -1.0907e-02,\n",
       "                       3.4652e-03, -1.0699e-02, -7.0520e-03,  1.7228e-02, -1.6052e-02,\n",
       "                       1.1300e-02,  1.9971e-05, -2.6295e-02, -1.6014e-02, -3.7381e-03,\n",
       "                       3.9927e-03, -1.7577e-02,  1.1085e-02,  5.2897e-02, -4.0533e-03,\n",
       "                      -3.3725e-02,  1.3661e-03, -1.1513e-02, -2.3842e-02, -1.5184e-02,\n",
       "                       2.5902e-02,  1.0272e-02,  2.5413e-02,  3.3512e-02, -2.3581e-02,\n",
       "                      -2.3382e-03, -2.1988e-02, -2.3419e-03, -1.0452e-03, -3.2009e-03,\n",
       "                       1.2412e-02,  4.1544e-03,  2.6490e-02,  7.6751e-04,  6.3902e-03,\n",
       "                       2.7935e-02, -1.9132e-02, -1.8581e-02,  5.6709e-03, -4.8726e-03,\n",
       "                       1.8139e-02,  1.0187e-02, -9.2331e-03,  9.6519e-03, -2.9871e-02,\n",
       "                      -2.0533e-02,  1.0392e-02,  4.1550e-03,  2.4514e-03,  1.3863e-02,\n",
       "                       4.0471e-03,  4.7898e-02,  2.3197e-02,  1.8580e-02, -2.1985e-02,\n",
       "                      -9.0022e-03, -2.2905e-02,  1.1052e-03,  1.7456e-03, -9.1983e-03,\n",
       "                       2.3448e-03,  2.3743e-02, -2.3288e-02,  6.8589e-03,  9.5408e-03,\n",
       "                      -1.6068e-02, -3.0709e-02, -9.7736e-03,  1.1624e-02,  6.2602e-03,\n",
       "                       9.2581e-03,  2.3574e-02, -1.0938e-03,  7.8775e-03, -8.4378e-03,\n",
       "                      -2.2444e-02,  1.4696e-02, -1.3945e-02, -1.0824e-02, -2.6026e-02,\n",
       "                       8.2813e-03, -1.2789e-02, -1.7927e-02, -1.9098e-03, -2.9530e-02,\n",
       "                       2.1569e-02, -3.3837e-02,  1.4654e-02,  1.6397e-03, -2.6433e-02,\n",
       "                       1.4694e-02,  7.2873e-03, -4.4663e-02,  5.3338e-03,  7.8448e-03,\n",
       "                       1.8089e-02, -8.3196e-03,  9.1017e-03,  8.9745e-03,  1.7489e-02,\n",
       "                       1.5938e-02,  7.5342e-04,  3.6302e-02, -2.1499e-02,  3.5404e-03,\n",
       "                      -2.8467e-02,  1.4964e-02, -1.2929e-02, -2.4299e-02,  8.2310e-03,\n",
       "                       1.0306e-02, -2.4439e-02,  8.6288e-03, -3.1911e-02,  1.4273e-02,\n",
       "                       1.1631e-02,  3.3644e-02, -3.9123e-03,  1.5698e-02,  8.3408e-03,\n",
       "                      -1.6262e-02, -2.1112e-02,  2.0150e-02,  2.1594e-02,  2.2470e-02,\n",
       "                      -8.5558e-03,  8.2238e-03,  8.4670e-03, -4.4100e-03,  1.6837e-03,\n",
       "                      -3.2625e-03,  2.3982e-04,  1.1434e-02,  1.4614e-02, -2.4817e-02,\n",
       "                       4.8282e-03,  3.4655e-04,  1.5107e-03, -1.4052e-02, -1.4265e-02,\n",
       "                       9.9219e-03, -3.9925e-03, -1.8142e-02,  2.0845e-03,  4.8382e-02,\n",
       "                      -1.4085e-02,  5.3192e-03,  4.5871e-04, -3.4340e-03,  3.9627e-03,\n",
       "                       1.0486e-02,  2.6164e-02,  4.5831e-03,  1.7923e-02,  3.6957e-02,\n",
       "                      -4.8271e-03,  2.9398e-03, -1.6607e-02,  1.2179e-02, -3.3932e-03,\n",
       "                       1.8982e-03,  8.4003e-03, -2.1865e-02, -8.2961e-03, -1.9538e-02,\n",
       "                      -2.2067e-02,  3.1041e-03,  1.8884e-02, -2.1856e-02, -4.0352e-03,\n",
       "                       6.4049e-03], dtype=torch.float64)),\n",
       "             ('5.2.convs.2.1.bias',\n",
       "              tensor([-0.0014,  0.0054,  0.0250, -0.0009,  0.0015, -0.0124,  0.0169,  0.0051,\n",
       "                       0.0055, -0.0075,  0.0010, -0.0076,  0.0146, -0.0116,  0.0109,  0.0111,\n",
       "                       0.0222,  0.0064,  0.0217, -0.0040, -0.0003, -0.0030, -0.0013,  0.0080,\n",
       "                       0.0002, -0.0266,  0.0013,  0.0189,  0.0021,  0.0018, -0.0117,  0.0163,\n",
       "                      -0.0144,  0.0174,  0.0141, -0.0006,  0.0066,  0.0260,  0.0155, -0.0001,\n",
       "                       0.0041, -0.0093, -0.0032,  0.0134,  0.0152, -0.0066, -0.0137,  0.0090,\n",
       "                      -0.0059,  0.0098, -0.0062,  0.0037,  0.0164,  0.0200, -0.0149,  0.0051,\n",
       "                       0.0064,  0.0125,  0.0100,  0.0063, -0.0138,  0.0035,  0.0029,  0.0150,\n",
       "                      -0.0011, -0.0011, -0.0090,  0.0121,  0.0010, -0.0134,  0.0025,  0.0209,\n",
       "                       0.0107, -0.0084,  0.0207,  0.0160,  0.0096, -0.0145,  0.0091,  0.0079,\n",
       "                       0.0155, -0.0007,  0.0184,  0.0087,  0.0002,  0.0043,  0.0058,  0.0057,\n",
       "                       0.0122, -0.0021,  0.0014,  0.0183,  0.0212,  0.0029,  0.0022, -0.0123,\n",
       "                       0.0072,  0.0057,  0.0162, -0.0103,  0.0331, -0.0036, -0.0137, -0.0280,\n",
       "                       0.0139,  0.0064,  0.0012,  0.0099,  0.0080,  0.0026, -0.0088, -0.0054,\n",
       "                       0.0099,  0.0158,  0.0074,  0.0099,  0.0120,  0.0074,  0.0084, -0.0134,\n",
       "                       0.0113,  0.0182,  0.0042,  0.0004, -0.0081,  0.0114,  0.0075,  0.0057,\n",
       "                       0.0054,  0.0078,  0.0051,  0.0093,  0.0075,  0.0060, -0.0023, -0.0136,\n",
       "                      -0.0054,  0.0135,  0.0146,  0.0177, -0.0078,  0.0060, -0.0006,  0.0140,\n",
       "                      -0.0098, -0.0042,  0.0111, -0.0087,  0.0105,  0.0125,  0.0021,  0.0224,\n",
       "                       0.0142,  0.0162,  0.0134,  0.0183,  0.0075,  0.0156, -0.0046, -0.0165,\n",
       "                       0.0086, -0.0009, -0.0053,  0.0190,  0.0089,  0.0060, -0.0090,  0.0153,\n",
       "                       0.0144,  0.0165,  0.0093, -0.0017, -0.0003,  0.0122, -0.0158, -0.0041,\n",
       "                       0.0016,  0.0292,  0.0068,  0.0018, -0.0031,  0.0216, -0.0134, -0.0055,\n",
       "                       0.0106,  0.0068,  0.0106,  0.0126, -0.0026,  0.0025,  0.0090,  0.0063,\n",
       "                       0.0144, -0.0188,  0.0092,  0.0091, -0.0080,  0.0155,  0.0133, -0.0183,\n",
       "                       0.0082, -0.0021,  0.0140,  0.0210,  0.0007, -0.0077,  0.0173, -0.0096,\n",
       "                       0.0115,  0.0112,  0.0029,  0.0126,  0.0121,  0.0067,  0.0056,  0.0088,\n",
       "                       0.0052,  0.0141,  0.0080,  0.0006, -0.0057, -0.0053,  0.0110,  0.0018,\n",
       "                      -0.0039,  0.0056,  0.0005,  0.0040, -0.0265,  0.0008, -0.0116,  0.0067,\n",
       "                       0.0107,  0.0033,  0.0119,  0.0058,  0.0088,  0.0010,  0.0032,  0.0201,\n",
       "                      -0.0081,  0.0029,  0.0125,  0.0022,  0.0072,  0.0144,  0.0079,  0.0151,\n",
       "                      -0.0059, -0.0092,  0.0237,  0.0089,  0.0178,  0.0251,  0.0202,  0.0040],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convs.2.1.running_mean',\n",
       "              tensor([-0.0862, -0.0165, -0.2398,  0.3852, -0.6019, -0.5676,  0.0825, -0.7221,\n",
       "                       0.2181, -0.3597,  0.1015,  0.0824, -0.4817, -0.3997,  0.1277, -0.3706,\n",
       "                       0.2177,  0.2849,  0.2576,  0.4792, -0.4415, -0.1918,  0.0606,  0.6394,\n",
       "                      -0.2762,  0.1784, -0.1828, -0.7421,  0.2326,  0.4814, -0.0799, -0.4709,\n",
       "                      -0.5291, -0.1194, -0.0158, -0.1229,  0.4049,  0.4543,  0.7844, -0.0387,\n",
       "                      -0.1087,  0.1492, -0.3487, -0.3085, -0.4336, -0.1643, -0.5457, -0.5845,\n",
       "                       0.3287, -0.2307,  0.2002,  0.0758,  0.0641,  0.2803, -0.1433,  0.7532,\n",
       "                      -0.3457,  0.1953, -0.0031, -0.0913,  0.0674,  0.0324, -0.5562,  0.2221,\n",
       "                      -0.9758, -0.5766, -0.2547, -0.0495, -0.0079, -0.3639,  0.2663, -0.0612,\n",
       "                       0.5695, -0.0193,  0.3017, -0.3923,  0.2664, -0.1438, -0.8519, -0.4391,\n",
       "                       0.5560,  0.0707,  0.2655,  0.6996, -0.4839, -0.3393, -0.2678,  0.2010,\n",
       "                       0.3435, -0.2256,  0.9106,  0.0826,  0.0613, -0.3814, -0.6878,  0.3369,\n",
       "                       0.2004, -0.0137,  0.6613, -0.1420,  0.3559, -0.1298,  0.1191,  0.7050,\n",
       "                      -0.3615,  0.9383, -0.2041,  0.6062, -0.5241, -0.0445, -0.1914, -0.0072,\n",
       "                       0.1048,  0.2355, -0.0203, -1.1482, -0.2945, -0.3258,  0.2933,  0.9523,\n",
       "                      -0.4485, -1.0821, -0.1384,  0.2491, -0.2982, -0.7233, -0.3215, -0.4616,\n",
       "                      -0.1417, -0.0625, -0.4790, -0.0806, -0.6347,  0.0702,  0.1821,  0.1276,\n",
       "                       0.1181,  0.1011, -0.2943, -0.9211, -0.1767,  0.0638, -0.0307,  0.4276,\n",
       "                       0.0262,  0.0987,  0.2867,  0.0029,  0.2342,  0.3344, -0.5391,  0.1652,\n",
       "                      -0.0490, -0.0376, -0.0779,  0.6314, -0.6156,  0.1035,  0.3060,  0.3423,\n",
       "                      -0.0016, -0.0583, -0.2557,  0.3799,  0.2874, -0.1679,  0.0842, -0.0640,\n",
       "                       0.0222,  0.4106,  0.4494, -0.2461, -0.2516,  0.6102, -0.0346,  0.5627,\n",
       "                      -0.1453,  0.0615, -0.3682, -0.4874, -0.0298,  0.1001, -0.5881, -0.4559,\n",
       "                       0.2214,  0.5460,  0.0181,  0.6201,  0.2594,  0.4201, -0.0685,  0.2428,\n",
       "                      -0.0697,  0.3292,  0.0267,  0.4397,  0.3055,  0.4633,  0.9841, -0.0257,\n",
       "                       0.2111,  0.4707,  0.3625, -0.0267,  0.1512, -0.5698, -0.5079,  0.0393,\n",
       "                      -0.0893, -0.9192, -0.4831,  0.0691, -0.3910,  0.1755,  0.4904,  0.2875,\n",
       "                      -0.6479,  0.3098, -0.5619,  0.6141, -0.1605, -0.1535,  0.3593, -0.4387,\n",
       "                       1.1955,  0.0958,  0.2576, -0.0976,  0.7708,  0.3244, -0.6470,  0.1516,\n",
       "                       0.2895,  0.0466,  0.1541, -0.1817,  0.2676,  0.2526,  0.6274,  0.4594,\n",
       "                       0.0349,  0.0355, -0.3388,  0.4101, -0.1183, -0.3021, -0.1553,  0.4324,\n",
       "                      -0.1234, -1.0030,  0.2239,  0.2310,  0.3218,  0.6022, -0.2103, -0.2831],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convs.2.1.running_var',\n",
       "              tensor([0.3352, 0.2564, 0.2799, 0.4492, 0.5220, 0.1955, 0.2102, 0.3939, 0.1522,\n",
       "                      0.7558, 0.2717, 0.1844, 0.2933, 0.2646, 0.3506, 0.3375, 0.2702, 0.4839,\n",
       "                      0.3884, 0.2690, 0.2379, 0.4195, 0.3081, 0.5743, 0.3273, 0.2536, 0.2848,\n",
       "                      0.3815, 0.3955, 0.3020, 0.2356, 0.5191, 0.2456, 0.3065, 0.3673, 0.5255,\n",
       "                      0.1654, 0.2727, 0.3475, 0.3676, 0.3756, 0.3541, 0.0711, 0.3162, 0.2773,\n",
       "                      0.2051, 0.2966, 0.3374, 0.3404, 0.2807, 0.1750, 0.4299, 0.3584, 0.2858,\n",
       "                      0.2203, 0.3723, 0.2287, 0.3688, 0.2893, 0.2901, 0.0461, 0.3720, 0.4216,\n",
       "                      0.2195, 0.4312, 0.4617, 0.2013, 0.1958, 0.3080, 0.3465, 0.4459, 0.2609,\n",
       "                      0.2725, 0.4328, 0.3982, 0.2279, 0.3118, 0.2388, 0.3807, 0.2634, 0.4011,\n",
       "                      0.1563, 0.3628, 0.3705, 0.3523, 0.4394, 0.2084, 0.2160, 0.2658, 0.2571,\n",
       "                      0.3032, 0.1051, 0.3977, 0.3648, 0.2478, 0.3682, 0.5797, 0.1093, 0.2609,\n",
       "                      0.4779, 0.3884, 0.1941, 0.2569, 0.5157, 0.2487, 0.3688, 0.2816, 0.4108,\n",
       "                      0.3200, 0.1934, 0.1869, 0.3566, 0.3062, 0.4110, 0.3639, 0.4461, 0.3120,\n",
       "                      0.3501, 0.3184, 0.2931, 0.2159, 0.3193, 0.3587, 0.3932, 0.1747, 0.4736,\n",
       "                      0.3708, 0.2467, 0.1635, 0.3656, 0.5559, 0.2694, 0.3327, 0.3234, 0.1302,\n",
       "                      0.1681, 0.2277, 0.2226, 0.3051, 0.3185, 0.3111, 0.2419, 0.1848, 0.1595,\n",
       "                      0.1146, 0.1997, 0.2221, 0.3696, 0.2985, 0.5123, 0.2843, 0.3340, 0.1416,\n",
       "                      0.3584, 0.1410, 0.3108, 0.3438, 0.1658, 0.2806, 0.2869, 0.3761, 0.2490,\n",
       "                      0.2865, 0.2018, 0.3572, 0.4376, 0.3120, 0.1775, 0.1743, 0.3624, 0.2908,\n",
       "                      0.2586, 0.2520, 0.0805, 0.3674, 0.6431, 0.3711, 0.3285, 0.1387, 0.2215,\n",
       "                      0.4609, 0.3508, 0.2920, 0.2505, 0.2106, 0.2523, 0.2179, 0.2649, 0.3916,\n",
       "                      0.3477, 0.3985, 0.2558, 0.2979, 0.5287, 0.3345, 0.2578, 0.2555, 0.2065,\n",
       "                      0.4242, 0.2237, 0.1887, 0.1833, 0.2252, 0.3354, 0.1562, 0.3601, 0.1743,\n",
       "                      0.2100, 0.4339, 0.4113, 0.1012, 0.1653, 0.1181, 0.3122, 0.3007, 0.2600,\n",
       "                      0.3007, 0.2605, 0.2849, 0.3293, 0.1048, 0.2080, 0.1463, 0.4738, 0.5100,\n",
       "                      0.2495, 0.1632, 0.4620, 0.3586, 0.3808, 0.2265, 0.2938, 0.0881, 0.0774,\n",
       "                      0.3049, 0.1874, 0.3676, 0.3531, 0.6355, 0.3933, 0.3094, 0.0435, 0.4446,\n",
       "                      0.4810, 0.1139, 0.1779, 0.1173, 0.2729, 0.1644, 0.5448, 0.2112, 0.3089,\n",
       "                      0.2682, 0.3588, 0.1909, 0.3476], dtype=torch.float64)),\n",
       "             ('5.2.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.2.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.2465],\n",
       "                       [ 0.0327],\n",
       "                       [ 0.1565],\n",
       "                       ...,\n",
       "                       [ 0.0351],\n",
       "                       [ 0.2499],\n",
       "                       [ 0.0393]],\n",
       "              \n",
       "                      [[-0.1605],\n",
       "                       [-0.0112],\n",
       "                       [-0.1289],\n",
       "                       ...,\n",
       "                       [ 0.0487],\n",
       "                       [-0.1187],\n",
       "                       [-0.1153]],\n",
       "              \n",
       "                      [[ 0.0234],\n",
       "                       [ 0.0714],\n",
       "                       [ 0.0335],\n",
       "                       ...,\n",
       "                       [-0.0326],\n",
       "                       [ 0.1077],\n",
       "                       [ 0.0157]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0647],\n",
       "                       [ 0.1698],\n",
       "                       [-0.2075],\n",
       "                       ...,\n",
       "                       [ 0.0198],\n",
       "                       [ 0.0900],\n",
       "                       [ 0.0786]],\n",
       "              \n",
       "                      [[ 0.0538],\n",
       "                       [ 0.0904],\n",
       "                       [-0.0362],\n",
       "                       ...,\n",
       "                       [ 0.0161],\n",
       "                       [ 0.1532],\n",
       "                       [ 0.0023]],\n",
       "              \n",
       "                      [[ 0.1125],\n",
       "                       [-0.0409],\n",
       "                       [ 0.0799],\n",
       "                       ...,\n",
       "                       [-0.0316],\n",
       "                       [-0.0877],\n",
       "                       [ 0.0267]]], dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.0.1.weight',\n",
       "              tensor([0.9718, 0.9777, 0.9873, 0.9560, 0.9861, 0.9529, 0.9876, 0.9585, 0.9495,\n",
       "                      0.9689, 0.9613, 0.9486, 0.9840, 0.9657, 0.9529, 0.9297, 0.9400, 0.9771,\n",
       "                      0.9702, 0.9706, 0.9701, 0.9638, 0.9673, 0.9656, 0.9542, 0.9832, 0.9519,\n",
       "                      0.9800, 0.9740, 0.9579, 0.9796, 0.9857, 0.9505, 0.9300, 0.9698, 0.9621,\n",
       "                      0.9450, 0.9521, 0.9544, 0.9788, 0.9951, 0.9470, 0.9968, 0.9734, 1.0029,\n",
       "                      0.9602, 0.9962, 0.9744, 0.9632, 0.9564, 0.9475, 0.9758, 0.9684, 0.9493,\n",
       "                      0.9586, 0.9765, 1.0156, 0.9701, 1.0021, 0.9873, 0.9622, 0.9918, 0.9635,\n",
       "                      0.9517], dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0128,  0.0049,  0.0139,  0.0025,  0.0016, -0.0142,  0.0261, -0.0112,\n",
       "                      -0.0076,  0.0091,  0.0041, -0.0126,  0.0117,  0.0036, -0.0037, -0.0279,\n",
       "                      -0.0085, -0.0267, -0.0282,  0.0037, -0.0136, -0.0065,  0.0166,  0.0084,\n",
       "                      -0.0028,  0.0073,  0.0134, -0.0006,  0.0160,  0.0039, -0.0076,  0.0151,\n",
       "                      -0.0118, -0.0019,  0.0151, -0.0161, -0.0051, -0.0081, -0.0138,  0.0108,\n",
       "                       0.0153, -0.0089,  0.0191,  0.0055,  0.0013, -0.0054,  0.0010, -0.0022,\n",
       "                      -0.0028, -0.0218, -0.0210, -0.0124, -0.0024, -0.0183,  0.0074, -0.0113,\n",
       "                       0.0223,  0.0022,  0.0126,  0.0226,  0.0154,  0.0154,  0.0166, -0.0041],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.1861, -0.4981,  0.1280,  0.3149,  0.5631,  0.1058, -0.5804,  0.5050,\n",
       "                       0.4690, -0.0734,  0.2646,  0.2869, -0.1322, -0.5256, -0.1596,  0.6383,\n",
       "                      -0.4537, -0.0892,  0.0048,  0.2870, -0.1865, -0.1021,  0.3619,  0.1271,\n",
       "                      -0.5318,  0.8270,  0.0630,  0.3405, -0.3889, -0.2037,  0.3884, -0.5711,\n",
       "                      -0.3243, -0.1310,  0.2976,  0.3313, -0.2495,  0.1354, -0.3669,  0.2238,\n",
       "                      -0.1816,  0.2281,  0.7505, -0.4221, -0.1864, -0.1407, -0.3311,  0.0103,\n",
       "                       0.3222,  0.2643,  0.2738,  0.3247, -0.1160, -0.2153, -0.0671, -0.8978,\n",
       "                      -0.0743,  0.3005, -0.5724,  0.2061, -0.2143,  0.5772,  0.6037, -0.4130],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.0.1.running_var',\n",
       "              tensor([0.2737, 0.2852, 0.1659, 0.1925, 0.4861, 0.3042, 0.6225, 0.1398, 0.8645,\n",
       "                      0.2841, 0.1744, 0.4147, 0.1803, 0.4634, 0.6174, 0.4701, 0.5342, 0.1912,\n",
       "                      0.2771, 0.2143, 0.3767, 0.5351, 0.4776, 0.3440, 0.4651, 1.0038, 0.6621,\n",
       "                      0.3207, 0.4459, 0.2635, 0.1684, 0.5185, 0.1838, 1.0525, 0.7845, 0.4282,\n",
       "                      0.7125, 1.3959, 0.7664, 0.3390, 0.3703, 0.4147, 0.6935, 0.5135, 0.4189,\n",
       "                      0.2424, 0.1737, 0.1830, 0.2703, 0.4573, 0.7137, 0.4623, 0.8958, 1.0623,\n",
       "                      0.3095, 0.1404, 0.3933, 0.2169, 0.2733, 0.3009, 0.3690, 0.7798, 2.1939,\n",
       "                      1.0433], dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.2.convpath.0.1.0.weight',\n",
       "              tensor([[[ 0.0267, -0.0278, -0.0824, -0.0077,  0.0798],\n",
       "                       [-0.1499, -0.0092, -0.0124,  0.0436, -0.0924],\n",
       "                       [-0.0308,  0.0029,  0.1709,  0.0220,  0.0762],\n",
       "                       ...,\n",
       "                       [-0.0044, -0.1050,  0.0058, -0.0167, -0.0694],\n",
       "                       [-0.0729,  0.1170, -0.0244, -0.0123, -0.0150],\n",
       "                       [ 0.0932,  0.0632, -0.0174,  0.1201,  0.0390]],\n",
       "              \n",
       "                      [[ 0.0006,  0.0196,  0.0151, -0.0849, -0.1938],\n",
       "                       [-0.0505, -0.0889, -0.0670, -0.0169, -0.0062],\n",
       "                       [ 0.1040, -0.0827,  0.0639,  0.0728,  0.0010],\n",
       "                       ...,\n",
       "                       [ 0.0433, -0.0441,  0.0453,  0.0311, -0.1213],\n",
       "                       [ 0.0293,  0.0865,  0.1829,  0.1123, -0.1026],\n",
       "                       [ 0.1678,  0.0870,  0.0900,  0.0161, -0.0459]],\n",
       "              \n",
       "                      [[ 0.1008,  0.0028,  0.0360, -0.0558, -0.0558],\n",
       "                       [-0.1065, -0.0553,  0.0231, -0.0518, -0.1905],\n",
       "                       [ 0.1324, -0.1144,  0.0928, -0.0772, -0.0241],\n",
       "                       ...,\n",
       "                       [-0.0225, -0.0419, -0.1298, -0.1394,  0.0419],\n",
       "                       [ 0.1130,  0.0456,  0.0146, -0.0136, -0.0062],\n",
       "                       [-0.0142, -0.0184, -0.1355, -0.0254, -0.1185]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0244,  0.0019, -0.0136, -0.0343,  0.0246],\n",
       "                       [-0.1187,  0.0454,  0.0309,  0.0833,  0.1114],\n",
       "                       [ 0.0173,  0.0710, -0.0162, -0.1391,  0.0260],\n",
       "                       ...,\n",
       "                       [-0.0933,  0.1038, -0.0115, -0.1776, -0.0114],\n",
       "                       [ 0.0270, -0.1323, -0.0570, -0.0025,  0.0352],\n",
       "                       [-0.0348, -0.0544,  0.0174,  0.1369, -0.0911]],\n",
       "              \n",
       "                      [[ 0.2121,  0.0498, -0.0729,  0.0567,  0.0127],\n",
       "                       [-0.0625,  0.0561,  0.0045,  0.0480,  0.0451],\n",
       "                       [ 0.0325, -0.0058, -0.0166, -0.0508, -0.0300],\n",
       "                       ...,\n",
       "                       [-0.0131, -0.0609, -0.0637,  0.0036,  0.0440],\n",
       "                       [-0.0642, -0.0043, -0.0678, -0.0191,  0.0035],\n",
       "                       [-0.0985,  0.1032,  0.0250,  0.0416,  0.0501]],\n",
       "              \n",
       "                      [[-0.0639, -0.0551, -0.0403, -0.0509, -0.1249],\n",
       "                       [ 0.0133, -0.1062, -0.0041,  0.0765, -0.0700],\n",
       "                       [ 0.0836, -0.0446, -0.1639, -0.0522, -0.0371],\n",
       "                       ...,\n",
       "                       [ 0.0325,  0.0946, -0.0663,  0.1416,  0.0080],\n",
       "                       [ 0.1071, -0.0153, -0.0143, -0.0866,  0.0613],\n",
       "                       [-0.0047, -0.0542,  0.1036, -0.0031, -0.0496]]], dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.1.1.weight',\n",
       "              tensor([0.9452, 0.9588, 0.9792, 0.9549, 0.9559, 0.9314, 0.9493, 0.9904, 0.9600,\n",
       "                      0.9590, 0.9584, 0.9725, 0.9978, 0.9839, 0.9722, 1.0143, 0.9760, 0.9175,\n",
       "                      0.9549, 0.9702, 0.9459, 0.9395, 0.9378, 0.9889, 0.9777, 0.9716, 0.9648,\n",
       "                      0.9882, 0.9241, 1.0013, 0.9391, 1.0092, 0.9578, 0.9618, 0.9352, 0.9792,\n",
       "                      0.9429, 0.9581, 0.9732, 0.9706, 0.9443, 0.9790, 0.9635, 0.9627, 0.9195,\n",
       "                      0.9801, 0.9356, 0.9571, 0.9640, 1.0175, 0.9562, 0.9535, 0.9720, 0.9299,\n",
       "                      0.9137, 0.9616, 0.9601, 0.9708, 0.9492, 0.9554, 0.9506, 0.9405, 0.9406,\n",
       "                      0.9609], dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.1.1.bias',\n",
       "              tensor([ 0.0045,  0.0047,  0.0127, -0.0244, -0.0140, -0.0245, -0.0105, -0.0141,\n",
       "                       0.0062,  0.0182, -0.0048, -0.0060,  0.0137, -0.0113, -0.0158,  0.0264,\n",
       "                      -0.0057, -0.0167,  0.0010, -0.0059, -0.0086,  0.0008, -0.0085,  0.0071,\n",
       "                      -0.0100,  0.0156,  0.0007,  0.0075,  0.0046,  0.0374, -0.0289,  0.0265,\n",
       "                      -0.0030, -0.0223, -0.0086, -0.0152, -0.0172,  0.0038, -0.0017, -0.0097,\n",
       "                       0.0075,  0.0175,  0.0128, -0.0216,  0.0014, -0.0006, -0.0029, -0.0074,\n",
       "                      -0.0117,  0.0214,  0.0064, -0.0095, -0.0108, -0.0064, -0.0001,  0.0099,\n",
       "                       0.0096,  0.0060,  0.0199, -0.0330, -0.0325, -0.0204, -0.0217,  0.0018],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.1.1.running_mean',\n",
       "              tensor([-0.5590,  0.2872, -0.4774,  0.1880,  0.0862, -0.4153,  0.4243, -0.1905,\n",
       "                      -0.3249, -0.8446, -0.1133, -0.7955, -0.0531,  0.3375,  0.7426,  0.0348,\n",
       "                      -0.2056, -0.7436, -0.7210,  0.1127, -0.5343, -1.1006,  0.0898, -0.4722,\n",
       "                      -0.0682, -0.0822, -0.3062,  0.3147, -0.0716, -0.6074, -0.2978,  0.0640,\n",
       "                       0.5326,  0.4372,  0.4151,  0.1852, -0.8952, -0.8330, -0.3593, -1.0658,\n",
       "                      -0.2528, -0.5342, -0.4132,  0.6631, -0.6332, -0.3022, -0.5100,  0.5441,\n",
       "                      -0.1287, -0.4375, -0.2796, -0.2046, -0.2930, -0.8862, -0.5406,  0.0384,\n",
       "                       0.0638,  0.8414, -0.0291, -0.2924,  0.2907, -0.0937, -0.3307, -0.0902],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.1.1.running_var',\n",
       "              tensor([0.7594, 1.2881, 0.9124, 0.5638, 0.8131, 0.6536, 0.4475, 0.3312, 0.4160,\n",
       "                      1.1729, 0.4780, 0.5346, 0.4475, 0.3942, 0.6429, 0.4068, 0.9322, 1.0151,\n",
       "                      0.6030, 0.3815, 0.8400, 1.0118, 0.5295, 0.8745, 0.5717, 0.5017, 0.5024,\n",
       "                      0.3238, 0.6847, 0.7990, 0.6565, 0.4191, 0.6770, 0.9683, 0.5887, 0.4251,\n",
       "                      0.4819, 0.6405, 1.3750, 0.8232, 0.7416, 0.6119, 0.4224, 0.9823, 0.9154,\n",
       "                      0.7862, 0.4644, 1.0391, 0.6467, 0.4700, 0.5878, 0.4639, 0.4625, 1.9194,\n",
       "                      1.3265, 0.8025, 0.4810, 1.4349, 0.3681, 0.8418, 0.7349, 1.0717, 0.3841,\n",
       "                      0.9685], dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.2.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0677],\n",
       "                       [-0.0901],\n",
       "                       [ 0.1860],\n",
       "                       ...,\n",
       "                       [ 0.1461],\n",
       "                       [-0.0717],\n",
       "                       [-0.2872]],\n",
       "              \n",
       "                      [[ 0.0078],\n",
       "                       [-0.0172],\n",
       "                       [-0.0999],\n",
       "                       ...,\n",
       "                       [-0.2508],\n",
       "                       [-0.1696],\n",
       "                       [ 0.1343]],\n",
       "              \n",
       "                      [[ 0.0590],\n",
       "                       [ 0.0999],\n",
       "                       [-0.1416],\n",
       "                       ...,\n",
       "                       [ 0.2324],\n",
       "                       [-0.2262],\n",
       "                       [-0.2073]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0620],\n",
       "                       [-0.0539],\n",
       "                       [ 0.2210],\n",
       "                       ...,\n",
       "                       [ 0.0141],\n",
       "                       [ 0.0642],\n",
       "                       [-0.0649]],\n",
       "              \n",
       "                      [[-0.0454],\n",
       "                       [-0.1227],\n",
       "                       [-0.0536],\n",
       "                       ...,\n",
       "                       [-0.0058],\n",
       "                       [-0.0805],\n",
       "                       [-0.0226]],\n",
       "              \n",
       "                      [[-0.0588],\n",
       "                       [ 0.1041],\n",
       "                       [ 0.0179],\n",
       "                       ...,\n",
       "                       [ 0.0193],\n",
       "                       [ 0.0241],\n",
       "                       [-0.2101]]], dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.2.1.weight',\n",
       "              tensor([-4.6090e-03,  4.4520e-02, -3.5884e-02, -5.1809e-03, -1.1737e-02,\n",
       "                       1.9843e-03,  2.5209e-03,  2.0795e-02, -1.6808e-02,  2.8201e-02,\n",
       "                       1.2781e-02,  4.1221e-03,  1.1184e-02,  1.8085e-02,  4.1422e-02,\n",
       "                       2.3324e-02, -3.2433e-02,  7.9463e-03, -3.4576e-02, -7.4583e-03,\n",
       "                      -1.3111e-02,  2.7582e-02, -1.1040e-02, -1.5856e-02,  8.8957e-03,\n",
       "                      -2.1841e-02,  3.2805e-02,  1.2532e-02,  1.5146e-02,  1.3258e-02,\n",
       "                      -6.7615e-03,  1.9925e-02,  9.7864e-03, -3.6253e-02, -1.2236e-02,\n",
       "                      -1.3461e-02,  4.4562e-03,  2.5041e-02, -2.6462e-02, -1.6940e-02,\n",
       "                       8.7100e-03,  1.9238e-02,  4.4784e-03,  3.4245e-02,  2.0531e-02,\n",
       "                       5.2516e-03, -3.5861e-03, -1.2469e-02, -5.2432e-02,  9.6388e-03,\n",
       "                      -5.6816e-04,  6.9154e-03,  8.5357e-03, -2.2981e-02,  1.1508e-02,\n",
       "                       1.9899e-02, -1.6698e-02, -8.0961e-03, -2.2956e-02,  3.0904e-03,\n",
       "                      -3.7870e-03,  1.5946e-02, -1.2915e-02, -1.0833e-02,  1.2147e-02,\n",
       "                       1.4231e-02,  1.2813e-02, -1.9293e-03,  1.0169e-02,  2.4295e-02,\n",
       "                      -3.0872e-02,  1.1113e-02,  1.9294e-03, -3.9288e-03, -2.3505e-02,\n",
       "                       1.8764e-02,  2.5213e-02,  2.4943e-02, -5.8700e-03,  1.3171e-02,\n",
       "                      -1.0873e-02, -6.3622e-03, -1.1389e-02, -1.3333e-02, -1.0907e-02,\n",
       "                       3.4652e-03, -1.0699e-02, -7.0520e-03,  1.7228e-02, -1.6052e-02,\n",
       "                       1.1300e-02,  1.9971e-05, -2.6295e-02, -1.6014e-02, -3.7381e-03,\n",
       "                       3.9927e-03, -1.7577e-02,  1.1085e-02,  5.2897e-02, -4.0533e-03,\n",
       "                      -3.3725e-02,  1.3661e-03, -1.1513e-02, -2.3842e-02, -1.5184e-02,\n",
       "                       2.5902e-02,  1.0272e-02,  2.5413e-02,  3.3512e-02, -2.3581e-02,\n",
       "                      -2.3382e-03, -2.1988e-02, -2.3419e-03, -1.0452e-03, -3.2009e-03,\n",
       "                       1.2412e-02,  4.1544e-03,  2.6490e-02,  7.6751e-04,  6.3902e-03,\n",
       "                       2.7935e-02, -1.9132e-02, -1.8581e-02,  5.6709e-03, -4.8726e-03,\n",
       "                       1.8139e-02,  1.0187e-02, -9.2331e-03,  9.6519e-03, -2.9871e-02,\n",
       "                      -2.0533e-02,  1.0392e-02,  4.1550e-03,  2.4514e-03,  1.3863e-02,\n",
       "                       4.0471e-03,  4.7898e-02,  2.3197e-02,  1.8580e-02, -2.1985e-02,\n",
       "                      -9.0022e-03, -2.2905e-02,  1.1052e-03,  1.7456e-03, -9.1983e-03,\n",
       "                       2.3448e-03,  2.3743e-02, -2.3288e-02,  6.8589e-03,  9.5408e-03,\n",
       "                      -1.6068e-02, -3.0709e-02, -9.7736e-03,  1.1624e-02,  6.2602e-03,\n",
       "                       9.2581e-03,  2.3574e-02, -1.0938e-03,  7.8775e-03, -8.4378e-03,\n",
       "                      -2.2444e-02,  1.4696e-02, -1.3945e-02, -1.0824e-02, -2.6026e-02,\n",
       "                       8.2813e-03, -1.2789e-02, -1.7927e-02, -1.9098e-03, -2.9530e-02,\n",
       "                       2.1569e-02, -3.3837e-02,  1.4654e-02,  1.6397e-03, -2.6433e-02,\n",
       "                       1.4694e-02,  7.2873e-03, -4.4663e-02,  5.3338e-03,  7.8448e-03,\n",
       "                       1.8089e-02, -8.3196e-03,  9.1017e-03,  8.9745e-03,  1.7489e-02,\n",
       "                       1.5938e-02,  7.5342e-04,  3.6302e-02, -2.1499e-02,  3.5404e-03,\n",
       "                      -2.8467e-02,  1.4964e-02, -1.2929e-02, -2.4299e-02,  8.2310e-03,\n",
       "                       1.0306e-02, -2.4439e-02,  8.6288e-03, -3.1911e-02,  1.4273e-02,\n",
       "                       1.1631e-02,  3.3644e-02, -3.9123e-03,  1.5698e-02,  8.3408e-03,\n",
       "                      -1.6262e-02, -2.1112e-02,  2.0150e-02,  2.1594e-02,  2.2470e-02,\n",
       "                      -8.5558e-03,  8.2238e-03,  8.4670e-03, -4.4100e-03,  1.6837e-03,\n",
       "                      -3.2625e-03,  2.3982e-04,  1.1434e-02,  1.4614e-02, -2.4817e-02,\n",
       "                       4.8282e-03,  3.4655e-04,  1.5107e-03, -1.4052e-02, -1.4265e-02,\n",
       "                       9.9219e-03, -3.9925e-03, -1.8142e-02,  2.0845e-03,  4.8382e-02,\n",
       "                      -1.4085e-02,  5.3192e-03,  4.5871e-04, -3.4340e-03,  3.9627e-03,\n",
       "                       1.0486e-02,  2.6164e-02,  4.5831e-03,  1.7923e-02,  3.6957e-02,\n",
       "                      -4.8271e-03,  2.9398e-03, -1.6607e-02,  1.2179e-02, -3.3932e-03,\n",
       "                       1.8982e-03,  8.4003e-03, -2.1865e-02, -8.2961e-03, -1.9538e-02,\n",
       "                      -2.2067e-02,  3.1041e-03,  1.8884e-02, -2.1856e-02, -4.0352e-03,\n",
       "                       6.4049e-03], dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.2.1.bias',\n",
       "              tensor([-0.0014,  0.0054,  0.0250, -0.0009,  0.0015, -0.0124,  0.0169,  0.0051,\n",
       "                       0.0055, -0.0075,  0.0010, -0.0076,  0.0146, -0.0116,  0.0109,  0.0111,\n",
       "                       0.0222,  0.0064,  0.0217, -0.0040, -0.0003, -0.0030, -0.0013,  0.0080,\n",
       "                       0.0002, -0.0266,  0.0013,  0.0189,  0.0021,  0.0018, -0.0117,  0.0163,\n",
       "                      -0.0144,  0.0174,  0.0141, -0.0006,  0.0066,  0.0260,  0.0155, -0.0001,\n",
       "                       0.0041, -0.0093, -0.0032,  0.0134,  0.0152, -0.0066, -0.0137,  0.0090,\n",
       "                      -0.0059,  0.0098, -0.0062,  0.0037,  0.0164,  0.0200, -0.0149,  0.0051,\n",
       "                       0.0064,  0.0125,  0.0100,  0.0063, -0.0138,  0.0035,  0.0029,  0.0150,\n",
       "                      -0.0011, -0.0011, -0.0090,  0.0121,  0.0010, -0.0134,  0.0025,  0.0209,\n",
       "                       0.0107, -0.0084,  0.0207,  0.0160,  0.0096, -0.0145,  0.0091,  0.0079,\n",
       "                       0.0155, -0.0007,  0.0184,  0.0087,  0.0002,  0.0043,  0.0058,  0.0057,\n",
       "                       0.0122, -0.0021,  0.0014,  0.0183,  0.0212,  0.0029,  0.0022, -0.0123,\n",
       "                       0.0072,  0.0057,  0.0162, -0.0103,  0.0331, -0.0036, -0.0137, -0.0280,\n",
       "                       0.0139,  0.0064,  0.0012,  0.0099,  0.0080,  0.0026, -0.0088, -0.0054,\n",
       "                       0.0099,  0.0158,  0.0074,  0.0099,  0.0120,  0.0074,  0.0084, -0.0134,\n",
       "                       0.0113,  0.0182,  0.0042,  0.0004, -0.0081,  0.0114,  0.0075,  0.0057,\n",
       "                       0.0054,  0.0078,  0.0051,  0.0093,  0.0075,  0.0060, -0.0023, -0.0136,\n",
       "                      -0.0054,  0.0135,  0.0146,  0.0177, -0.0078,  0.0060, -0.0006,  0.0140,\n",
       "                      -0.0098, -0.0042,  0.0111, -0.0087,  0.0105,  0.0125,  0.0021,  0.0224,\n",
       "                       0.0142,  0.0162,  0.0134,  0.0183,  0.0075,  0.0156, -0.0046, -0.0165,\n",
       "                       0.0086, -0.0009, -0.0053,  0.0190,  0.0089,  0.0060, -0.0090,  0.0153,\n",
       "                       0.0144,  0.0165,  0.0093, -0.0017, -0.0003,  0.0122, -0.0158, -0.0041,\n",
       "                       0.0016,  0.0292,  0.0068,  0.0018, -0.0031,  0.0216, -0.0134, -0.0055,\n",
       "                       0.0106,  0.0068,  0.0106,  0.0126, -0.0026,  0.0025,  0.0090,  0.0063,\n",
       "                       0.0144, -0.0188,  0.0092,  0.0091, -0.0080,  0.0155,  0.0133, -0.0183,\n",
       "                       0.0082, -0.0021,  0.0140,  0.0210,  0.0007, -0.0077,  0.0173, -0.0096,\n",
       "                       0.0115,  0.0112,  0.0029,  0.0126,  0.0121,  0.0067,  0.0056,  0.0088,\n",
       "                       0.0052,  0.0141,  0.0080,  0.0006, -0.0057, -0.0053,  0.0110,  0.0018,\n",
       "                      -0.0039,  0.0056,  0.0005,  0.0040, -0.0265,  0.0008, -0.0116,  0.0067,\n",
       "                       0.0107,  0.0033,  0.0119,  0.0058,  0.0088,  0.0010,  0.0032,  0.0201,\n",
       "                      -0.0081,  0.0029,  0.0125,  0.0022,  0.0072,  0.0144,  0.0079,  0.0151,\n",
       "                      -0.0059, -0.0092,  0.0237,  0.0089,  0.0178,  0.0251,  0.0202,  0.0040],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.2.1.running_mean',\n",
       "              tensor([-0.0862, -0.0165, -0.2398,  0.3852, -0.6019, -0.5676,  0.0825, -0.7221,\n",
       "                       0.2181, -0.3597,  0.1015,  0.0824, -0.4817, -0.3997,  0.1277, -0.3706,\n",
       "                       0.2177,  0.2849,  0.2576,  0.4792, -0.4415, -0.1918,  0.0606,  0.6394,\n",
       "                      -0.2762,  0.1784, -0.1828, -0.7421,  0.2326,  0.4814, -0.0799, -0.4709,\n",
       "                      -0.5291, -0.1194, -0.0158, -0.1229,  0.4049,  0.4543,  0.7844, -0.0387,\n",
       "                      -0.1087,  0.1492, -0.3487, -0.3085, -0.4336, -0.1643, -0.5457, -0.5845,\n",
       "                       0.3287, -0.2307,  0.2002,  0.0758,  0.0641,  0.2803, -0.1433,  0.7532,\n",
       "                      -0.3457,  0.1953, -0.0031, -0.0913,  0.0674,  0.0324, -0.5562,  0.2221,\n",
       "                      -0.9758, -0.5766, -0.2547, -0.0495, -0.0079, -0.3639,  0.2663, -0.0612,\n",
       "                       0.5695, -0.0193,  0.3017, -0.3923,  0.2664, -0.1438, -0.8519, -0.4391,\n",
       "                       0.5560,  0.0707,  0.2655,  0.6996, -0.4839, -0.3393, -0.2678,  0.2010,\n",
       "                       0.3435, -0.2256,  0.9106,  0.0826,  0.0613, -0.3814, -0.6878,  0.3369,\n",
       "                       0.2004, -0.0137,  0.6613, -0.1420,  0.3559, -0.1298,  0.1191,  0.7050,\n",
       "                      -0.3615,  0.9383, -0.2041,  0.6062, -0.5241, -0.0445, -0.1914, -0.0072,\n",
       "                       0.1048,  0.2355, -0.0203, -1.1482, -0.2945, -0.3258,  0.2933,  0.9523,\n",
       "                      -0.4485, -1.0821, -0.1384,  0.2491, -0.2982, -0.7233, -0.3215, -0.4616,\n",
       "                      -0.1417, -0.0625, -0.4790, -0.0806, -0.6347,  0.0702,  0.1821,  0.1276,\n",
       "                       0.1181,  0.1011, -0.2943, -0.9211, -0.1767,  0.0638, -0.0307,  0.4276,\n",
       "                       0.0262,  0.0987,  0.2867,  0.0029,  0.2342,  0.3344, -0.5391,  0.1652,\n",
       "                      -0.0490, -0.0376, -0.0779,  0.6314, -0.6156,  0.1035,  0.3060,  0.3423,\n",
       "                      -0.0016, -0.0583, -0.2557,  0.3799,  0.2874, -0.1679,  0.0842, -0.0640,\n",
       "                       0.0222,  0.4106,  0.4494, -0.2461, -0.2516,  0.6102, -0.0346,  0.5627,\n",
       "                      -0.1453,  0.0615, -0.3682, -0.4874, -0.0298,  0.1001, -0.5881, -0.4559,\n",
       "                       0.2214,  0.5460,  0.0181,  0.6201,  0.2594,  0.4201, -0.0685,  0.2428,\n",
       "                      -0.0697,  0.3292,  0.0267,  0.4397,  0.3055,  0.4633,  0.9841, -0.0257,\n",
       "                       0.2111,  0.4707,  0.3625, -0.0267,  0.1512, -0.5698, -0.5079,  0.0393,\n",
       "                      -0.0893, -0.9192, -0.4831,  0.0691, -0.3910,  0.1755,  0.4904,  0.2875,\n",
       "                      -0.6479,  0.3098, -0.5619,  0.6141, -0.1605, -0.1535,  0.3593, -0.4387,\n",
       "                       1.1955,  0.0958,  0.2576, -0.0976,  0.7708,  0.3244, -0.6470,  0.1516,\n",
       "                       0.2895,  0.0466,  0.1541, -0.1817,  0.2676,  0.2526,  0.6274,  0.4594,\n",
       "                       0.0349,  0.0355, -0.3388,  0.4101, -0.1183, -0.3021, -0.1553,  0.4324,\n",
       "                      -0.1234, -1.0030,  0.2239,  0.2310,  0.3218,  0.6022, -0.2103, -0.2831],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.2.1.running_var',\n",
       "              tensor([0.3352, 0.2564, 0.2799, 0.4492, 0.5220, 0.1955, 0.2102, 0.3939, 0.1522,\n",
       "                      0.7558, 0.2717, 0.1844, 0.2933, 0.2646, 0.3506, 0.3375, 0.2702, 0.4839,\n",
       "                      0.3884, 0.2690, 0.2379, 0.4195, 0.3081, 0.5743, 0.3273, 0.2536, 0.2848,\n",
       "                      0.3815, 0.3955, 0.3020, 0.2356, 0.5191, 0.2456, 0.3065, 0.3673, 0.5255,\n",
       "                      0.1654, 0.2727, 0.3475, 0.3676, 0.3756, 0.3541, 0.0711, 0.3162, 0.2773,\n",
       "                      0.2051, 0.2966, 0.3374, 0.3404, 0.2807, 0.1750, 0.4299, 0.3584, 0.2858,\n",
       "                      0.2203, 0.3723, 0.2287, 0.3688, 0.2893, 0.2901, 0.0461, 0.3720, 0.4216,\n",
       "                      0.2195, 0.4312, 0.4617, 0.2013, 0.1958, 0.3080, 0.3465, 0.4459, 0.2609,\n",
       "                      0.2725, 0.4328, 0.3982, 0.2279, 0.3118, 0.2388, 0.3807, 0.2634, 0.4011,\n",
       "                      0.1563, 0.3628, 0.3705, 0.3523, 0.4394, 0.2084, 0.2160, 0.2658, 0.2571,\n",
       "                      0.3032, 0.1051, 0.3977, 0.3648, 0.2478, 0.3682, 0.5797, 0.1093, 0.2609,\n",
       "                      0.4779, 0.3884, 0.1941, 0.2569, 0.5157, 0.2487, 0.3688, 0.2816, 0.4108,\n",
       "                      0.3200, 0.1934, 0.1869, 0.3566, 0.3062, 0.4110, 0.3639, 0.4461, 0.3120,\n",
       "                      0.3501, 0.3184, 0.2931, 0.2159, 0.3193, 0.3587, 0.3932, 0.1747, 0.4736,\n",
       "                      0.3708, 0.2467, 0.1635, 0.3656, 0.5559, 0.2694, 0.3327, 0.3234, 0.1302,\n",
       "                      0.1681, 0.2277, 0.2226, 0.3051, 0.3185, 0.3111, 0.2419, 0.1848, 0.1595,\n",
       "                      0.1146, 0.1997, 0.2221, 0.3696, 0.2985, 0.5123, 0.2843, 0.3340, 0.1416,\n",
       "                      0.3584, 0.1410, 0.3108, 0.3438, 0.1658, 0.2806, 0.2869, 0.3761, 0.2490,\n",
       "                      0.2865, 0.2018, 0.3572, 0.4376, 0.3120, 0.1775, 0.1743, 0.3624, 0.2908,\n",
       "                      0.2586, 0.2520, 0.0805, 0.3674, 0.6431, 0.3711, 0.3285, 0.1387, 0.2215,\n",
       "                      0.4609, 0.3508, 0.2920, 0.2505, 0.2106, 0.2523, 0.2179, 0.2649, 0.3916,\n",
       "                      0.3477, 0.3985, 0.2558, 0.2979, 0.5287, 0.3345, 0.2578, 0.2555, 0.2065,\n",
       "                      0.4242, 0.2237, 0.1887, 0.1833, 0.2252, 0.3354, 0.1562, 0.3601, 0.1743,\n",
       "                      0.2100, 0.4339, 0.4113, 0.1012, 0.1653, 0.1181, 0.3122, 0.3007, 0.2600,\n",
       "                      0.3007, 0.2605, 0.2849, 0.3293, 0.1048, 0.2080, 0.1463, 0.4738, 0.5100,\n",
       "                      0.2495, 0.1632, 0.4620, 0.3586, 0.3808, 0.2265, 0.2938, 0.0881, 0.0774,\n",
       "                      0.3049, 0.1874, 0.3676, 0.3531, 0.6355, 0.3933, 0.3094, 0.0435, 0.4446,\n",
       "                      0.4810, 0.1139, 0.1779, 0.1173, 0.2729, 0.1644, 0.5448, 0.2112, 0.3089,\n",
       "                      0.2682, 0.3588, 0.1909, 0.3476], dtype=torch.float64)),\n",
       "             ('5.2.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.3.convs.0.0.weight',\n",
       "              tensor([[[-0.0730],\n",
       "                       [-0.1134],\n",
       "                       [ 0.1650],\n",
       "                       ...,\n",
       "                       [ 0.0808],\n",
       "                       [-0.0915],\n",
       "                       [ 0.0239]],\n",
       "              \n",
       "                      [[-0.0908],\n",
       "                       [-0.0915],\n",
       "                       [-0.0872],\n",
       "                       ...,\n",
       "                       [ 0.0140],\n",
       "                       [ 0.0101],\n",
       "                       [ 0.0539]],\n",
       "              \n",
       "                      [[-0.0190],\n",
       "                       [-0.0615],\n",
       "                       [ 0.1286],\n",
       "                       ...,\n",
       "                       [-0.0102],\n",
       "                       [-0.0692],\n",
       "                       [ 0.0099]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0350],\n",
       "                       [ 0.0626],\n",
       "                       [-0.1071],\n",
       "                       ...,\n",
       "                       [-0.1013],\n",
       "                       [ 0.0263],\n",
       "                       [-0.0304]],\n",
       "              \n",
       "                      [[-0.0144],\n",
       "                       [-0.1935],\n",
       "                       [-0.0385],\n",
       "                       ...,\n",
       "                       [-0.0348],\n",
       "                       [-0.1080],\n",
       "                       [ 0.0330]],\n",
       "              \n",
       "                      [[ 0.1550],\n",
       "                       [-0.1085],\n",
       "                       [-0.0084],\n",
       "                       ...,\n",
       "                       [-0.1381],\n",
       "                       [-0.0245],\n",
       "                       [ 0.0683]]], dtype=torch.float64)),\n",
       "             ('5.3.convs.0.1.weight',\n",
       "              tensor([0.9786, 0.9778, 0.9706, 0.9658, 0.9860, 0.9728, 0.9696, 0.9776, 0.9609,\n",
       "                      0.9570, 0.9839, 0.9777, 0.9565, 0.9701, 0.9825, 0.9955, 0.9867, 0.9784,\n",
       "                      0.9769, 0.9655, 0.9730, 0.9802, 0.9823, 0.9790, 0.9625, 0.9574, 0.9744,\n",
       "                      0.9727, 0.9826, 0.9659, 0.9453, 0.9460, 0.9874, 0.9575, 0.9561, 0.9725,\n",
       "                      0.9797, 0.9578, 0.9603, 0.9791, 0.9730, 0.9765, 0.9596, 0.9431, 1.0121,\n",
       "                      0.9944, 0.9750, 0.9373, 0.9765, 0.9911, 1.0031, 0.9725, 0.9585, 0.9917,\n",
       "                      0.9760, 0.9570, 0.9672, 0.9758, 0.9863, 0.9559, 0.9800, 0.9864, 0.9680,\n",
       "                      0.9963], dtype=torch.float64)),\n",
       "             ('5.3.convs.0.1.bias',\n",
       "              tensor([ 0.0014,  0.0052,  0.0156,  0.0109,  0.0148, -0.0193, -0.0044, -0.0066,\n",
       "                      -0.0218, -0.0074,  0.0120,  0.0113, -0.0019, -0.0064,  0.0021, -0.0021,\n",
       "                       0.0247,  0.0051,  0.0031, -0.0101,  0.0076,  0.0116,  0.0002, -0.0006,\n",
       "                       0.0092, -0.0005, -0.0013,  0.0139,  0.0284,  0.0044, -0.0171, -0.0156,\n",
       "                       0.0138, -0.0175, -0.0258, -0.0140, -0.0058, -0.0222, -0.0063,  0.0138,\n",
       "                      -0.0037, -0.0070,  0.0065, -0.0210,  0.0118,  0.0173, -0.0218, -0.0101,\n",
       "                      -0.0074,  0.0121,  0.0318, -0.0030, -0.0146,  0.0008,  0.0159,  0.0116,\n",
       "                      -0.0081,  0.0007,  0.0248, -0.0116,  0.0210,  0.0048,  0.0073,  0.0247],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convs.0.1.running_mean',\n",
       "              tensor([-0.6049, -0.4152,  0.0880,  0.6016, -0.2947,  0.0682,  0.3947,  0.3074,\n",
       "                       0.3306,  0.2386,  0.4756,  0.1629, -0.2642,  0.9581, -0.0676, -0.4790,\n",
       "                      -0.5742, -0.0540,  0.0568,  0.9929, -0.5000,  0.6728,  0.1925, -0.0654,\n",
       "                      -0.0216, -0.4671, -0.0174,  0.2646, -0.2849,  0.6013, -0.0210, -0.5748,\n",
       "                      -0.4132,  0.3725,  0.2332, -0.0161, -0.0770,  0.5225,  0.9889,  0.0181,\n",
       "                       0.1388,  0.3304,  0.1180,  0.8317,  0.4472, -0.1146,  0.2205, -0.7231,\n",
       "                      -0.2235, -0.8052, -0.4622,  0.3173, -0.2066, -0.7538,  0.2552,  0.3281,\n",
       "                       0.6575,  0.6886, -0.4073, -0.0605, -0.1072, -0.4732, -0.2691, -0.2825],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convs.0.1.running_var',\n",
       "              tensor([0.1663, 0.2801, 0.3877, 0.7420, 0.2253, 0.2560, 0.4599, 0.3733, 0.2903,\n",
       "                      0.7494, 0.4084, 0.2755, 0.3988, 1.4678, 0.6109, 0.2988, 0.6372, 0.8398,\n",
       "                      0.2040, 1.4996, 0.9881, 0.2902, 0.4727, 0.6883, 0.4019, 0.4009, 0.2320,\n",
       "                      0.1327, 0.4879, 0.6595, 0.3513, 1.2131, 0.1970, 0.3595, 0.3974, 0.2318,\n",
       "                      0.2626, 1.2334, 0.9566, 0.2209, 0.6718, 0.7316, 0.3475, 1.1943, 0.1442,\n",
       "                      0.2418, 0.1528, 1.7944, 0.2095, 0.2959, 0.3535, 0.4009, 0.5704, 0.2363,\n",
       "                      0.2296, 0.3013, 1.4100, 0.9587, 0.3548, 0.2982, 0.6653, 0.1702, 0.2322,\n",
       "                      0.7279], dtype=torch.float64)),\n",
       "             ('5.3.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.3.convs.1.0.weight',\n",
       "              tensor([[[-0.0529,  0.0870, -0.0250,  0.0546,  0.0074],\n",
       "                       [ 0.0331, -0.0124, -0.0554, -0.0390,  0.0782],\n",
       "                       [ 0.0540, -0.0181, -0.0016,  0.0137,  0.0350],\n",
       "                       ...,\n",
       "                       [ 0.0212,  0.0664,  0.0009, -0.1306,  0.1132],\n",
       "                       [-0.0960,  0.0457, -0.0212,  0.0492, -0.0319],\n",
       "                       [ 0.0530,  0.0014, -0.0676,  0.0735,  0.0363]],\n",
       "              \n",
       "                      [[ 0.0250, -0.0386,  0.0232, -0.0669,  0.0871],\n",
       "                       [-0.0066,  0.0420,  0.0360, -0.0262,  0.1177],\n",
       "                       [ 0.1677,  0.0365, -0.0677,  0.0751, -0.0389],\n",
       "                       ...,\n",
       "                       [ 0.0650,  0.1577, -0.1000, -0.1001, -0.0397],\n",
       "                       [ 0.0212, -0.0353,  0.0015,  0.0260,  0.0970],\n",
       "                       [-0.0315, -0.0904, -0.0573,  0.0627, -0.0076]],\n",
       "              \n",
       "                      [[ 0.0528,  0.0315,  0.0011,  0.0820, -0.0103],\n",
       "                       [-0.0764, -0.0166, -0.0047, -0.0048, -0.0334],\n",
       "                       [-0.0849,  0.0603, -0.0143,  0.0054,  0.1008],\n",
       "                       ...,\n",
       "                       [-0.0322, -0.0064,  0.0578,  0.0246, -0.0345],\n",
       "                       [-0.0444, -0.0146, -0.1001, -0.0759, -0.0043],\n",
       "                       [-0.0089,  0.0202, -0.0429, -0.0517,  0.0236]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0516, -0.1299, -0.1958, -0.0887,  0.0070],\n",
       "                       [-0.0754,  0.0215, -0.0892, -0.0163,  0.0714],\n",
       "                       [-0.0536, -0.0501, -0.0211, -0.0419, -0.1046],\n",
       "                       ...,\n",
       "                       [-0.0214,  0.0345,  0.0897, -0.0015, -0.0816],\n",
       "                       [ 0.0269,  0.0373, -0.0724,  0.1050, -0.0127],\n",
       "                       [ 0.0527, -0.0594,  0.0263,  0.0104,  0.0602]],\n",
       "              \n",
       "                      [[-0.0745,  0.1269,  0.0214, -0.0510,  0.0071],\n",
       "                       [-0.0358,  0.0628, -0.1278, -0.0351, -0.0964],\n",
       "                       [ 0.0746,  0.0211, -0.0669, -0.0011, -0.1323],\n",
       "                       ...,\n",
       "                       [-0.1402,  0.0739, -0.0155, -0.0041,  0.1165],\n",
       "                       [ 0.0289, -0.0490,  0.0319, -0.0757, -0.1412],\n",
       "                       [-0.0327,  0.0836,  0.0412,  0.0508,  0.1160]],\n",
       "              \n",
       "                      [[-0.0714,  0.0189,  0.0191, -0.0513, -0.0394],\n",
       "                       [ 0.0993,  0.0954, -0.0149,  0.0413, -0.0994],\n",
       "                       [-0.0009,  0.0225,  0.0552, -0.0738,  0.0180],\n",
       "                       ...,\n",
       "                       [ 0.0775, -0.0696, -0.0689,  0.0148,  0.0564],\n",
       "                       [ 0.1100, -0.1010,  0.0209, -0.0200,  0.0553],\n",
       "                       [ 0.0388,  0.0306, -0.0277, -0.0953, -0.1510]]], dtype=torch.float64)),\n",
       "             ('5.3.convs.1.1.weight',\n",
       "              tensor([0.9712, 0.9686, 0.9774, 0.9857, 0.9447, 0.9638, 0.9759, 0.9681, 0.9739,\n",
       "                      0.9489, 0.9634, 0.9911, 0.9767, 0.9604, 0.9125, 0.9784, 0.9857, 1.0201,\n",
       "                      0.9657, 0.9684, 0.9673, 0.9682, 0.9592, 0.9708, 0.9859, 0.9612, 0.9841,\n",
       "                      0.9182, 0.9323, 0.9360, 0.9872, 0.9521, 0.9134, 0.9420, 0.9441, 0.9799,\n",
       "                      0.9475, 0.9789, 0.9809, 0.9924, 0.9897, 0.9663, 0.9367, 0.9943, 0.9568,\n",
       "                      0.9608, 0.9547, 0.9970, 0.9461, 0.9758, 0.9220, 0.9497, 0.9568, 0.9759,\n",
       "                      0.9547, 0.9492, 0.9339, 0.9457, 0.9599, 0.9555, 0.9553, 0.9648, 0.9713,\n",
       "                      0.9562], dtype=torch.float64)),\n",
       "             ('5.3.convs.1.1.bias',\n",
       "              tensor([-2.1816e-02, -1.7777e-02,  2.5409e-02,  1.4187e-02, -1.8367e-02,\n",
       "                      -5.3592e-03, -1.0645e-02, -1.9208e-02,  5.8650e-03, -2.2752e-02,\n",
       "                      -1.4683e-02, -1.4344e-02,  9.0271e-03,  5.9783e-04, -6.5306e-03,\n",
       "                      -3.2494e-03, -9.8720e-03,  2.1030e-02, -1.5311e-02, -5.8999e-03,\n",
       "                      -1.0087e-02,  8.8320e-03, -6.2903e-03, -1.7931e-02, -1.4199e-02,\n",
       "                      -2.7993e-02, -5.7738e-03, -4.4619e-03, -1.9864e-02, -4.2919e-03,\n",
       "                       1.1007e-02, -2.7539e-02, -2.6813e-02, -3.3304e-03,  1.5825e-02,\n",
       "                       1.1213e-02, -9.6899e-03, -5.4661e-03,  4.2204e-03,  3.5011e-05,\n",
       "                      -1.5457e-02, -1.1615e-02, -1.3990e-02,  9.1949e-03, -2.7876e-03,\n",
       "                      -1.7079e-02,  1.5275e-02,  4.8054e-03, -5.0017e-04, -6.6978e-05,\n",
       "                      -2.9418e-02, -8.3716e-03, -5.7128e-04, -1.4547e-02,  9.0625e-04,\n",
       "                      -1.5546e-02, -2.1604e-02, -1.0430e-02, -1.1210e-02, -1.6800e-02,\n",
       "                      -1.1154e-02,  7.4977e-03,  1.6724e-02, -1.2630e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convs.1.1.running_mean',\n",
       "              tensor([ 0.2794,  0.1898, -0.0707, -0.0750, -0.1517,  0.0831, -0.5452, -0.6698,\n",
       "                      -0.4186,  0.4852, -0.1245, -0.2697,  0.0081, -0.1627, -0.0335,  0.5354,\n",
       "                      -0.1779, -0.0325,  0.5645, -0.4776,  0.6304, -0.0719,  0.0135,  0.1194,\n",
       "                       0.4775,  0.2816, -0.3085, -0.2595,  0.0542, -0.3208, -0.1225, -0.4261,\n",
       "                      -0.8632, -0.3544, -0.6738,  0.4403, -0.6101, -0.1985, -0.3912, -0.1022,\n",
       "                      -0.2301, -0.4370, -0.1214, -0.4250, -0.0650,  0.4371, -0.2645, -0.3008,\n",
       "                       0.5081, -0.2417, -0.3805, -0.6219, -0.2269, -0.5891, -0.5998, -0.6586,\n",
       "                      -0.0526,  0.4790, -0.4874,  0.1390,  0.8981, -0.1165, -0.1777, -0.2286],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convs.1.1.running_var',\n",
       "              tensor([1.0093, 1.0319, 0.3667, 0.3792, 0.8875, 0.3362, 0.5115, 0.6183, 1.1835,\n",
       "                      0.4314, 0.3526, 0.5524, 0.6288, 0.6846, 1.2261, 0.4111, 0.5362, 0.4094,\n",
       "                      0.7930, 0.6103, 0.5558, 0.5414, 0.3986, 0.6676, 0.5148, 0.9956, 0.3751,\n",
       "                      1.1489, 1.6513, 1.0437, 0.4789, 0.4533, 1.5465, 0.7035, 0.9554, 0.5463,\n",
       "                      0.9240, 0.5755, 0.3416, 0.5066, 0.4178, 1.0751, 0.7850, 0.6239, 0.3439,\n",
       "                      0.6473, 0.5669, 0.6776, 0.5674, 0.3418, 0.7720, 0.5270, 0.7832, 0.5416,\n",
       "                      0.5178, 0.5546, 0.8007, 0.7954, 0.3757, 0.6893, 1.0762, 0.5076, 0.7073,\n",
       "                      0.8935], dtype=torch.float64)),\n",
       "             ('5.3.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.3.convs.2.0.weight',\n",
       "              tensor([[[ 0.0703],\n",
       "                       [-0.0006],\n",
       "                       [-0.0581],\n",
       "                       ...,\n",
       "                       [ 0.0878],\n",
       "                       [-0.0307],\n",
       "                       [ 0.0071]],\n",
       "              \n",
       "                      [[ 0.0391],\n",
       "                       [-0.0487],\n",
       "                       [-0.0311],\n",
       "                       ...,\n",
       "                       [ 0.0177],\n",
       "                       [-0.0800],\n",
       "                       [ 0.1407]],\n",
       "              \n",
       "                      [[ 0.0334],\n",
       "                       [ 0.0831],\n",
       "                       [-0.2349],\n",
       "                       ...,\n",
       "                       [-0.0827],\n",
       "                       [ 0.0171],\n",
       "                       [-0.2185]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.4092],\n",
       "                       [-0.0551],\n",
       "                       [ 0.0535],\n",
       "                       ...,\n",
       "                       [ 0.0626],\n",
       "                       [ 0.1836],\n",
       "                       [-0.1450]],\n",
       "              \n",
       "                      [[-0.0229],\n",
       "                       [ 0.0534],\n",
       "                       [-0.0155],\n",
       "                       ...,\n",
       "                       [-0.0672],\n",
       "                       [-0.3458],\n",
       "                       [-0.1254]],\n",
       "              \n",
       "                      [[ 0.1801],\n",
       "                       [-0.1595],\n",
       "                       [ 0.0825],\n",
       "                       ...,\n",
       "                       [-0.1389],\n",
       "                       [ 0.0803],\n",
       "                       [-0.1397]]], dtype=torch.float64)),\n",
       "             ('5.3.convs.2.1.weight',\n",
       "              tensor([-0.0043, -0.0048, -0.0076, -0.0096, -0.0024,  0.0078, -0.0054, -0.0018,\n",
       "                      -0.0161,  0.0094, -0.0039, -0.0009, -0.0094, -0.0468, -0.0409, -0.0169,\n",
       "                       0.0248,  0.0311,  0.0090, -0.0047,  0.0232,  0.0339,  0.0068, -0.0022,\n",
       "                      -0.0076, -0.0106,  0.0022,  0.0011,  0.0164,  0.0198, -0.0260, -0.0493,\n",
       "                      -0.0110, -0.0189, -0.0140, -0.0234, -0.0121,  0.0148, -0.0159,  0.0157,\n",
       "                       0.0085,  0.0028,  0.0086, -0.0130,  0.0172, -0.0077,  0.0243, -0.0116,\n",
       "                       0.0141, -0.0050, -0.0176, -0.0185, -0.0228, -0.0301, -0.0116,  0.0011,\n",
       "                      -0.0190, -0.0318, -0.0134, -0.0107,  0.0160, -0.0211,  0.0111, -0.0080,\n",
       "                      -0.0082,  0.0165,  0.0062,  0.0200, -0.0136,  0.0167, -0.0028,  0.0012,\n",
       "                      -0.0122, -0.0262,  0.0224, -0.0121,  0.0625, -0.0070,  0.0160,  0.0051,\n",
       "                       0.0035,  0.0116,  0.0584,  0.0307,  0.0216,  0.0399, -0.0048, -0.0011,\n",
       "                       0.0023, -0.0057,  0.0082,  0.0166, -0.0158,  0.0271,  0.0049, -0.0028,\n",
       "                       0.0054,  0.0155,  0.0293, -0.0123, -0.0189,  0.0285, -0.0130, -0.0085,\n",
       "                       0.0202,  0.0120,  0.0232,  0.0010,  0.0128, -0.0179,  0.0163, -0.0098,\n",
       "                       0.0083, -0.0190,  0.0030,  0.0072, -0.0032,  0.0036, -0.0264,  0.0033,\n",
       "                       0.0156, -0.0010, -0.0256,  0.0277,  0.0064, -0.0174,  0.0294,  0.0183,\n",
       "                       0.0079,  0.0063,  0.0067, -0.0095,  0.0142,  0.0092,  0.0049, -0.0047,\n",
       "                       0.0043, -0.0208,  0.0184,  0.0304,  0.0012,  0.0143, -0.0128, -0.0049,\n",
       "                       0.0153, -0.0128,  0.0019,  0.0105, -0.0148, -0.0009, -0.0067,  0.0359,\n",
       "                       0.0320, -0.0177,  0.0027, -0.0064,  0.0077,  0.0086,  0.0111, -0.0128,\n",
       "                      -0.0007, -0.0120, -0.0096,  0.0130,  0.0258,  0.0005, -0.0399, -0.0125,\n",
       "                      -0.0372,  0.0053, -0.0138, -0.0078,  0.0428,  0.0188, -0.0082, -0.0133,\n",
       "                       0.0075, -0.0141,  0.0098,  0.0240,  0.0141,  0.0172,  0.0400,  0.0072,\n",
       "                       0.0112, -0.0246,  0.0142, -0.0422,  0.0095,  0.0167,  0.0447,  0.0014,\n",
       "                      -0.0207, -0.0347,  0.0381,  0.0079, -0.0040,  0.0110,  0.0006,  0.0029,\n",
       "                       0.0027,  0.0346, -0.0177,  0.0200, -0.0144, -0.0151,  0.0141,  0.0018,\n",
       "                      -0.0129,  0.0090, -0.0116, -0.0026,  0.0140,  0.0079,  0.0281,  0.0322,\n",
       "                      -0.0195,  0.0380,  0.0477, -0.0143, -0.0024, -0.0009, -0.0166, -0.0057,\n",
       "                       0.0170, -0.0004, -0.0047, -0.0142, -0.0093,  0.0173, -0.0024,  0.0042,\n",
       "                       0.0067, -0.0186, -0.0036, -0.0500, -0.0015, -0.0265, -0.0206,  0.0310,\n",
       "                       0.0043,  0.0139,  0.0267,  0.0133, -0.0083,  0.0040, -0.0115, -0.0189,\n",
       "                      -0.0079, -0.0386,  0.0040,  0.0057,  0.0155, -0.0113,  0.0162, -0.0072],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convs.2.1.bias',\n",
       "              tensor([-6.3887e-04, -4.0647e-03,  2.1364e-02,  6.2034e-03, -1.9000e-03,\n",
       "                      -1.3072e-02,  1.7759e-02,  2.2344e-03,  1.2202e-02,  1.9587e-02,\n",
       "                      -4.4969e-03, -5.7991e-03,  1.3204e-02, -7.2764e-03,  1.3324e-02,\n",
       "                       1.0164e-02,  2.2745e-02,  1.0041e-02,  1.8895e-02, -6.6854e-03,\n",
       "                      -5.6202e-04,  5.8272e-03, -2.5647e-03,  6.0610e-03, -3.6746e-03,\n",
       "                      -2.5566e-02,  9.2644e-03,  1.0533e-02,  5.8387e-03,  1.8568e-03,\n",
       "                      -8.0075e-03,  1.1864e-02, -1.7029e-02,  2.3001e-02,  1.3861e-02,\n",
       "                       1.1602e-03,  3.3371e-03,  2.6461e-02,  1.9183e-02,  1.1472e-02,\n",
       "                       2.6044e-03, -9.3484e-03, -4.3218e-03,  5.1953e-03,  1.5233e-02,\n",
       "                      -7.6972e-03, -2.0580e-03,  1.1362e-02, -8.4105e-03,  6.6046e-03,\n",
       "                      -1.9166e-03,  2.4499e-03,  1.6570e-02,  1.9461e-02, -1.3702e-02,\n",
       "                      -1.9292e-03,  6.6099e-03,  1.3216e-02,  5.2063e-03,  5.7547e-03,\n",
       "                      -1.1355e-02,  6.1355e-03, -5.1213e-04,  1.0585e-02, -2.0086e-03,\n",
       "                       1.4981e-02, -9.1195e-03,  1.2142e-02,  1.3030e-03, -1.3168e-02,\n",
       "                       3.8022e-03,  1.2216e-02,  1.0980e-02, -6.4504e-03,  2.2738e-02,\n",
       "                       8.5880e-03,  8.1136e-03, -1.4326e-02,  8.0742e-03,  7.0039e-03,\n",
       "                       1.3571e-02, -3.1573e-03,  1.4684e-02,  7.2891e-03,  6.1078e-04,\n",
       "                       7.3977e-03,  8.7112e-03,  4.4942e-03,  1.0875e-02,  7.2141e-03,\n",
       "                       1.1323e-03,  1.6197e-02,  1.9573e-02,  5.4885e-04,  4.9150e-03,\n",
       "                      -1.1353e-02,  7.1363e-03,  6.0952e-03,  1.0353e-02, -1.0691e-02,\n",
       "                       2.8608e-02, -5.6944e-03, -9.4944e-03, -2.2617e-02,  1.2011e-02,\n",
       "                       3.8650e-03,  4.4853e-03,  8.4501e-04,  4.5319e-03,  6.5910e-03,\n",
       "                      -6.7278e-03, -4.7204e-03,  8.3341e-03,  1.8122e-02,  7.4130e-03,\n",
       "                       7.8655e-03,  1.1304e-02,  1.6754e-03,  9.1084e-03, -1.3400e-02,\n",
       "                       4.7133e-03,  1.2976e-02,  4.6433e-03,  2.7075e-03, -6.6156e-03,\n",
       "                       1.2141e-02,  7.0365e-03,  4.8307e-03,  4.7059e-03,  9.0757e-03,\n",
       "                       2.2005e-03,  4.9007e-03,  7.7811e-03,  1.2611e-02,  1.7299e-03,\n",
       "                      -1.6393e-02,  4.5643e-04,  1.5586e-02,  1.0813e-02,  1.1029e-02,\n",
       "                      -7.0930e-03,  4.3861e-03, -5.3571e-04,  1.2885e-02, -1.2485e-02,\n",
       "                      -4.4892e-03,  4.1339e-03, -1.3255e-03,  1.0024e-02,  1.1044e-02,\n",
       "                       8.6549e-03,  3.2498e-02,  1.4242e-02,  1.7529e-02,  1.8887e-02,\n",
       "                       1.6451e-02,  2.2513e-03,  1.4089e-02, -2.3116e-03, -1.6123e-02,\n",
       "                       2.1674e-03,  1.3491e-03,  1.0743e-03,  1.9439e-02,  4.9917e-03,\n",
       "                       3.9682e-03, -7.2644e-03,  6.5169e-03,  1.3627e-02,  1.6172e-02,\n",
       "                       4.6044e-03, -1.4444e-03,  8.1002e-03,  1.2096e-02, -1.5642e-02,\n",
       "                      -3.8141e-03, -8.9964e-04,  2.3817e-02,  5.8831e-03,  9.4751e-03,\n",
       "                      -2.8132e-03,  2.2086e-02, -1.4456e-02, -4.4533e-03,  1.4024e-02,\n",
       "                       8.6503e-03,  1.1536e-02,  1.8742e-02, -3.3009e-03,  1.1747e-03,\n",
       "                       7.6575e-03, -1.2056e-03,  1.8428e-02, -2.1536e-02,  7.4855e-03,\n",
       "                       1.1300e-02, -8.5633e-03,  1.6895e-02,  9.6312e-03, -1.5870e-02,\n",
       "                       5.8270e-03, -8.8419e-04,  1.2938e-02,  2.1696e-02,  2.4334e-03,\n",
       "                      -8.3693e-03,  1.4810e-02, -1.0183e-02,  8.6087e-03,  8.6641e-03,\n",
       "                       1.5371e-04,  1.3084e-02,  1.2512e-02,  6.5208e-03,  6.1465e-03,\n",
       "                       1.0607e-02,  4.6932e-03,  1.4600e-02,  8.0792e-03,  9.7572e-05,\n",
       "                      -6.9314e-03, -6.9845e-03,  1.0003e-02,  2.7858e-02, -3.5712e-03,\n",
       "                      -1.2112e-04, -4.3388e-04,  1.6662e-03, -2.5998e-02,  1.8026e-03,\n",
       "                       2.0000e-02,  6.1719e-03,  1.1003e-02,  2.3760e-03,  1.0371e-02,\n",
       "                       6.4296e-03,  8.1386e-03,  2.8036e-03,  5.3197e-03,  1.4614e-02,\n",
       "                      -6.6263e-03,  3.4073e-03,  1.1054e-02, -2.2398e-04,  7.5147e-03,\n",
       "                       1.4856e-02,  6.6866e-03,  1.1898e-02, -4.8538e-03, -7.8340e-03,\n",
       "                       1.5311e-02,  7.5289e-03,  2.1566e-02,  2.3692e-02,  1.9520e-02,\n",
       "                       2.9027e-03], dtype=torch.float64)),\n",
       "             ('5.3.convs.2.1.running_mean',\n",
       "              tensor([ 0.4124, -0.0096, -0.8011, -0.0950,  0.0559,  0.1874, -0.1256, -0.2686,\n",
       "                      -0.5384, -0.0447, -0.2683, -0.4431,  0.3032, -0.1489,  0.9169,  0.4619,\n",
       "                      -0.6089,  0.1535, -0.3866,  0.4746,  0.1170,  0.3971,  0.1030,  0.1144,\n",
       "                      -0.0110,  0.4086, -0.4751, -0.1057, -0.2841, -0.2941, -0.1534,  1.1162,\n",
       "                      -0.3167, -0.1320,  0.0735, -0.1066,  0.3522,  0.1312, -0.1458,  0.6455,\n",
       "                       0.0132,  0.2461,  0.1389, -0.2385,  0.2537,  0.4057, -0.0319, -0.5077,\n",
       "                      -0.5940, -0.4255, -0.0347,  0.0232,  0.3935,  0.0776, -0.0184,  0.2142,\n",
       "                      -0.0068,  1.1388, -0.6292,  0.4449,  0.5935,  0.5635, -0.1454,  0.0300,\n",
       "                      -0.0489, -0.1861,  0.3126, -0.6144,  0.1453, -0.6030, -0.0348, -0.0387,\n",
       "                       0.2074, -0.0550,  0.3099, -0.2859,  0.3149, -0.1383,  0.1301, -0.1700,\n",
       "                      -0.2106, -0.0473, -0.1117,  0.1110, -0.2326, -0.0556, -0.2226, -0.3421,\n",
       "                       0.4421, -0.0274, -0.3438, -0.3106, -0.0571, -0.1958, -0.0109, -0.1868,\n",
       "                       0.1236,  0.1177, -0.1610, -0.0297,  0.0225,  0.4046, -0.0589, -0.2376,\n",
       "                       0.3300,  0.5707,  0.3657,  0.0683, -0.3905,  0.2888,  0.0525, -0.2951,\n",
       "                      -0.0175,  0.2864,  0.2144,  0.1488,  0.1579,  0.6209,  0.5971,  0.0825,\n",
       "                       0.3387, -0.1079, -0.1861, -0.1857, -0.2171,  0.2297, -0.0247, -0.0258,\n",
       "                       0.3134, -0.0514,  0.1340,  0.2164, -0.0396,  0.1412, -0.1937, -0.0121,\n",
       "                      -0.1267, -0.3960, -0.3048,  0.1869,  0.4263, -0.1307, -0.2689, -0.2222,\n",
       "                       0.2758,  0.4750, -0.1319,  0.7055, -0.1012, -0.2024, -0.3398, -0.3946,\n",
       "                      -0.5469,  0.4258,  0.0810,  0.5945, -0.0871, -0.2251, -0.1228, -0.2235,\n",
       "                      -0.0515, -0.4006, -0.1299,  0.2699, -0.7675,  0.1228, -0.2362, -0.0265,\n",
       "                      -0.1189, -0.0893,  0.3059, -0.6212,  0.3346,  0.2798, -0.2379, -0.1525,\n",
       "                      -0.2051,  0.3744, -0.1459,  0.0777, -0.0247,  0.4538,  0.2245,  0.6873,\n",
       "                       0.1688,  0.9142, -0.2394,  0.4566, -0.1004,  0.5061,  0.4664,  0.0989,\n",
       "                      -0.0176, -0.2184,  0.2568,  0.1067,  0.0287, -0.2602,  0.1708,  0.0301,\n",
       "                      -0.3081, -0.3562,  0.0682, -0.2590, -0.3701, -0.2986,  0.0663,  0.1957,\n",
       "                      -0.2194, -0.2390,  0.1144,  0.4235, -0.0405,  0.5257,  0.3823,  0.5491,\n",
       "                      -1.2602,  0.3709, -0.4742, -0.0184, -0.0997,  0.0065,  0.1146, -0.4412,\n",
       "                      -0.2190,  0.0753, -0.2445,  0.1343,  0.2108, -0.3314, -0.3753,  0.2655,\n",
       "                      -0.2935, -0.3211,  0.3481, -0.6652,  0.0547,  0.1851, -0.5539,  0.0808,\n",
       "                       0.1165,  0.2840, -0.2779, -0.2260, -0.1139, -0.1904, -0.4673,  0.0626,\n",
       "                       0.1821, -0.0576,  0.0299, -0.4333,  0.4227,  0.1861,  0.0734,  0.4437],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convs.2.1.running_var',\n",
       "              tensor([0.1202, 0.3140, 0.2868, 0.2815, 0.2094, 0.2291, 0.2431, 0.1354, 0.1637,\n",
       "                      0.3213, 0.2707, 0.1180, 0.2963, 0.3076, 0.3347, 0.4244, 0.6896, 0.4558,\n",
       "                      0.3247, 0.3800, 0.2943, 0.5471, 0.6224, 0.1502, 0.3818, 0.3542, 0.2970,\n",
       "                      0.1122, 0.2493, 0.2665, 0.2108, 0.3792, 0.1930, 0.3937, 0.2914, 0.1973,\n",
       "                      0.1349, 0.2095, 0.3910, 0.5305, 0.2320, 0.0985, 0.1311, 0.3056, 0.2369,\n",
       "                      0.4958, 0.3403, 0.1601, 0.4912, 0.2895, 0.2500, 0.3183, 0.4855, 0.3410,\n",
       "                      0.2884, 0.1955, 0.3910, 0.3526, 0.3729, 0.2710, 0.3047, 0.3347, 0.4184,\n",
       "                      0.3675, 0.4222, 0.0800, 0.2254, 0.2555, 0.3885, 0.3753, 0.2459, 0.0457,\n",
       "                      0.2832, 0.3977, 0.3510, 0.1703, 0.4101, 0.1482, 0.4604, 0.2474, 0.3357,\n",
       "                      0.2736, 0.3734, 0.4499, 0.3608, 0.3739, 0.3995, 0.4463, 0.1756, 0.1257,\n",
       "                      0.5095, 0.2758, 0.1853, 0.6160, 0.3035, 0.1671, 0.3586, 0.1276, 0.1641,\n",
       "                      0.5433, 0.3265, 0.3703, 0.2231, 0.2306, 0.4007, 0.4745, 0.6165, 0.4554,\n",
       "                      0.2590, 0.2785, 0.1544, 0.3020, 0.3302, 0.2777, 0.2649, 0.2982, 0.2208,\n",
       "                      0.4789, 0.3255, 0.1889, 0.1135, 0.0937, 0.2864, 0.5263, 0.1125, 0.2621,\n",
       "                      0.3085, 0.1247, 0.2534, 0.3554, 0.1637, 0.2268, 0.3761, 0.0894, 0.1295,\n",
       "                      0.0488, 0.2557, 0.2693, 0.2745, 0.2609, 0.1977, 0.2497, 0.3916, 0.2525,\n",
       "                      0.1748, 0.7151, 0.0744, 0.3781, 0.1735, 0.1502, 0.3473, 0.2838, 0.4976,\n",
       "                      0.5947, 0.1319, 0.3458, 0.2664, 0.2735, 0.3811, 0.2855, 0.2443, 0.2867,\n",
       "                      0.1556, 0.1427, 0.4710, 0.1243, 0.4768, 0.2655, 0.4209, 0.3465, 0.2084,\n",
       "                      0.3655, 0.2703, 0.2959, 0.5168, 0.3955, 0.3101, 0.1269, 0.1561, 0.1917,\n",
       "                      0.1673, 0.2166, 0.3166, 0.3873, 0.2917, 0.4600, 0.3200, 0.2894, 0.1221,\n",
       "                      0.4412, 0.4437, 0.2416, 0.4867, 0.4599, 0.2619, 0.2733, 0.0985, 0.3060,\n",
       "                      0.1462, 0.3375, 0.2611, 0.4587, 0.3199, 0.3059, 0.6223, 0.5544, 0.2658,\n",
       "                      0.0523, 0.3685, 0.4548, 0.1121, 0.0933, 0.4420, 0.1536, 0.2723, 0.2951,\n",
       "                      0.4439, 0.2361, 0.2351, 0.2406, 0.1483, 0.1470, 0.1451, 0.4183, 0.5358,\n",
       "                      0.1342, 0.3321, 0.3501, 0.3895, 0.4608, 0.1451, 0.3868, 0.3904, 0.3519,\n",
       "                      0.2535, 0.4708, 0.2332, 0.3359, 0.3401, 0.3544, 0.0744, 0.3489, 0.3796,\n",
       "                      0.1614, 0.1784, 0.2616, 0.0992, 0.2778, 0.1440, 0.3581, 0.1561, 0.3185,\n",
       "                      0.2231, 0.5070, 0.2164, 0.3047], dtype=torch.float64)),\n",
       "             ('5.3.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.3.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0730],\n",
       "                       [-0.1134],\n",
       "                       [ 0.1650],\n",
       "                       ...,\n",
       "                       [ 0.0808],\n",
       "                       [-0.0915],\n",
       "                       [ 0.0239]],\n",
       "              \n",
       "                      [[-0.0908],\n",
       "                       [-0.0915],\n",
       "                       [-0.0872],\n",
       "                       ...,\n",
       "                       [ 0.0140],\n",
       "                       [ 0.0101],\n",
       "                       [ 0.0539]],\n",
       "              \n",
       "                      [[-0.0190],\n",
       "                       [-0.0615],\n",
       "                       [ 0.1286],\n",
       "                       ...,\n",
       "                       [-0.0102],\n",
       "                       [-0.0692],\n",
       "                       [ 0.0099]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0350],\n",
       "                       [ 0.0626],\n",
       "                       [-0.1071],\n",
       "                       ...,\n",
       "                       [-0.1013],\n",
       "                       [ 0.0263],\n",
       "                       [-0.0304]],\n",
       "              \n",
       "                      [[-0.0144],\n",
       "                       [-0.1935],\n",
       "                       [-0.0385],\n",
       "                       ...,\n",
       "                       [-0.0348],\n",
       "                       [-0.1080],\n",
       "                       [ 0.0330]],\n",
       "              \n",
       "                      [[ 0.1550],\n",
       "                       [-0.1085],\n",
       "                       [-0.0084],\n",
       "                       ...,\n",
       "                       [-0.1381],\n",
       "                       [-0.0245],\n",
       "                       [ 0.0683]]], dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.0.1.weight',\n",
       "              tensor([0.9786, 0.9778, 0.9706, 0.9658, 0.9860, 0.9728, 0.9696, 0.9776, 0.9609,\n",
       "                      0.9570, 0.9839, 0.9777, 0.9565, 0.9701, 0.9825, 0.9955, 0.9867, 0.9784,\n",
       "                      0.9769, 0.9655, 0.9730, 0.9802, 0.9823, 0.9790, 0.9625, 0.9574, 0.9744,\n",
       "                      0.9727, 0.9826, 0.9659, 0.9453, 0.9460, 0.9874, 0.9575, 0.9561, 0.9725,\n",
       "                      0.9797, 0.9578, 0.9603, 0.9791, 0.9730, 0.9765, 0.9596, 0.9431, 1.0121,\n",
       "                      0.9944, 0.9750, 0.9373, 0.9765, 0.9911, 1.0031, 0.9725, 0.9585, 0.9917,\n",
       "                      0.9760, 0.9570, 0.9672, 0.9758, 0.9863, 0.9559, 0.9800, 0.9864, 0.9680,\n",
       "                      0.9963], dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0014,  0.0052,  0.0156,  0.0109,  0.0148, -0.0193, -0.0044, -0.0066,\n",
       "                      -0.0218, -0.0074,  0.0120,  0.0113, -0.0019, -0.0064,  0.0021, -0.0021,\n",
       "                       0.0247,  0.0051,  0.0031, -0.0101,  0.0076,  0.0116,  0.0002, -0.0006,\n",
       "                       0.0092, -0.0005, -0.0013,  0.0139,  0.0284,  0.0044, -0.0171, -0.0156,\n",
       "                       0.0138, -0.0175, -0.0258, -0.0140, -0.0058, -0.0222, -0.0063,  0.0138,\n",
       "                      -0.0037, -0.0070,  0.0065, -0.0210,  0.0118,  0.0173, -0.0218, -0.0101,\n",
       "                      -0.0074,  0.0121,  0.0318, -0.0030, -0.0146,  0.0008,  0.0159,  0.0116,\n",
       "                      -0.0081,  0.0007,  0.0248, -0.0116,  0.0210,  0.0048,  0.0073,  0.0247],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.6049, -0.4152,  0.0880,  0.6016, -0.2947,  0.0682,  0.3947,  0.3074,\n",
       "                       0.3306,  0.2386,  0.4756,  0.1629, -0.2642,  0.9581, -0.0676, -0.4790,\n",
       "                      -0.5742, -0.0540,  0.0568,  0.9929, -0.5000,  0.6728,  0.1925, -0.0654,\n",
       "                      -0.0216, -0.4671, -0.0174,  0.2646, -0.2849,  0.6013, -0.0210, -0.5748,\n",
       "                      -0.4132,  0.3725,  0.2332, -0.0161, -0.0770,  0.5225,  0.9889,  0.0181,\n",
       "                       0.1388,  0.3304,  0.1180,  0.8317,  0.4472, -0.1146,  0.2205, -0.7231,\n",
       "                      -0.2235, -0.8052, -0.4622,  0.3173, -0.2066, -0.7538,  0.2552,  0.3281,\n",
       "                       0.6575,  0.6886, -0.4073, -0.0605, -0.1072, -0.4732, -0.2691, -0.2825],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.0.1.running_var',\n",
       "              tensor([0.1663, 0.2801, 0.3877, 0.7420, 0.2253, 0.2560, 0.4599, 0.3733, 0.2903,\n",
       "                      0.7494, 0.4084, 0.2755, 0.3988, 1.4678, 0.6109, 0.2988, 0.6372, 0.8398,\n",
       "                      0.2040, 1.4996, 0.9881, 0.2902, 0.4727, 0.6883, 0.4019, 0.4009, 0.2320,\n",
       "                      0.1327, 0.4879, 0.6595, 0.3513, 1.2131, 0.1970, 0.3595, 0.3974, 0.2318,\n",
       "                      0.2626, 1.2334, 0.9566, 0.2209, 0.6718, 0.7316, 0.3475, 1.1943, 0.1442,\n",
       "                      0.2418, 0.1528, 1.7944, 0.2095, 0.2959, 0.3535, 0.4009, 0.5704, 0.2363,\n",
       "                      0.2296, 0.3013, 1.4100, 0.9587, 0.3548, 0.2982, 0.6653, 0.1702, 0.2322,\n",
       "                      0.7279], dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.3.convpath.0.1.0.weight',\n",
       "              tensor([[[-0.0529,  0.0870, -0.0250,  0.0546,  0.0074],\n",
       "                       [ 0.0331, -0.0124, -0.0554, -0.0390,  0.0782],\n",
       "                       [ 0.0540, -0.0181, -0.0016,  0.0137,  0.0350],\n",
       "                       ...,\n",
       "                       [ 0.0212,  0.0664,  0.0009, -0.1306,  0.1132],\n",
       "                       [-0.0960,  0.0457, -0.0212,  0.0492, -0.0319],\n",
       "                       [ 0.0530,  0.0014, -0.0676,  0.0735,  0.0363]],\n",
       "              \n",
       "                      [[ 0.0250, -0.0386,  0.0232, -0.0669,  0.0871],\n",
       "                       [-0.0066,  0.0420,  0.0360, -0.0262,  0.1177],\n",
       "                       [ 0.1677,  0.0365, -0.0677,  0.0751, -0.0389],\n",
       "                       ...,\n",
       "                       [ 0.0650,  0.1577, -0.1000, -0.1001, -0.0397],\n",
       "                       [ 0.0212, -0.0353,  0.0015,  0.0260,  0.0970],\n",
       "                       [-0.0315, -0.0904, -0.0573,  0.0627, -0.0076]],\n",
       "              \n",
       "                      [[ 0.0528,  0.0315,  0.0011,  0.0820, -0.0103],\n",
       "                       [-0.0764, -0.0166, -0.0047, -0.0048, -0.0334],\n",
       "                       [-0.0849,  0.0603, -0.0143,  0.0054,  0.1008],\n",
       "                       ...,\n",
       "                       [-0.0322, -0.0064,  0.0578,  0.0246, -0.0345],\n",
       "                       [-0.0444, -0.0146, -0.1001, -0.0759, -0.0043],\n",
       "                       [-0.0089,  0.0202, -0.0429, -0.0517,  0.0236]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0516, -0.1299, -0.1958, -0.0887,  0.0070],\n",
       "                       [-0.0754,  0.0215, -0.0892, -0.0163,  0.0714],\n",
       "                       [-0.0536, -0.0501, -0.0211, -0.0419, -0.1046],\n",
       "                       ...,\n",
       "                       [-0.0214,  0.0345,  0.0897, -0.0015, -0.0816],\n",
       "                       [ 0.0269,  0.0373, -0.0724,  0.1050, -0.0127],\n",
       "                       [ 0.0527, -0.0594,  0.0263,  0.0104,  0.0602]],\n",
       "              \n",
       "                      [[-0.0745,  0.1269,  0.0214, -0.0510,  0.0071],\n",
       "                       [-0.0358,  0.0628, -0.1278, -0.0351, -0.0964],\n",
       "                       [ 0.0746,  0.0211, -0.0669, -0.0011, -0.1323],\n",
       "                       ...,\n",
       "                       [-0.1402,  0.0739, -0.0155, -0.0041,  0.1165],\n",
       "                       [ 0.0289, -0.0490,  0.0319, -0.0757, -0.1412],\n",
       "                       [-0.0327,  0.0836,  0.0412,  0.0508,  0.1160]],\n",
       "              \n",
       "                      [[-0.0714,  0.0189,  0.0191, -0.0513, -0.0394],\n",
       "                       [ 0.0993,  0.0954, -0.0149,  0.0413, -0.0994],\n",
       "                       [-0.0009,  0.0225,  0.0552, -0.0738,  0.0180],\n",
       "                       ...,\n",
       "                       [ 0.0775, -0.0696, -0.0689,  0.0148,  0.0564],\n",
       "                       [ 0.1100, -0.1010,  0.0209, -0.0200,  0.0553],\n",
       "                       [ 0.0388,  0.0306, -0.0277, -0.0953, -0.1510]]], dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.1.1.weight',\n",
       "              tensor([0.9712, 0.9686, 0.9774, 0.9857, 0.9447, 0.9638, 0.9759, 0.9681, 0.9739,\n",
       "                      0.9489, 0.9634, 0.9911, 0.9767, 0.9604, 0.9125, 0.9784, 0.9857, 1.0201,\n",
       "                      0.9657, 0.9684, 0.9673, 0.9682, 0.9592, 0.9708, 0.9859, 0.9612, 0.9841,\n",
       "                      0.9182, 0.9323, 0.9360, 0.9872, 0.9521, 0.9134, 0.9420, 0.9441, 0.9799,\n",
       "                      0.9475, 0.9789, 0.9809, 0.9924, 0.9897, 0.9663, 0.9367, 0.9943, 0.9568,\n",
       "                      0.9608, 0.9547, 0.9970, 0.9461, 0.9758, 0.9220, 0.9497, 0.9568, 0.9759,\n",
       "                      0.9547, 0.9492, 0.9339, 0.9457, 0.9599, 0.9555, 0.9553, 0.9648, 0.9713,\n",
       "                      0.9562], dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.1.1.bias',\n",
       "              tensor([-2.1816e-02, -1.7777e-02,  2.5409e-02,  1.4187e-02, -1.8367e-02,\n",
       "                      -5.3592e-03, -1.0645e-02, -1.9208e-02,  5.8650e-03, -2.2752e-02,\n",
       "                      -1.4683e-02, -1.4344e-02,  9.0271e-03,  5.9783e-04, -6.5306e-03,\n",
       "                      -3.2494e-03, -9.8720e-03,  2.1030e-02, -1.5311e-02, -5.8999e-03,\n",
       "                      -1.0087e-02,  8.8320e-03, -6.2903e-03, -1.7931e-02, -1.4199e-02,\n",
       "                      -2.7993e-02, -5.7738e-03, -4.4619e-03, -1.9864e-02, -4.2919e-03,\n",
       "                       1.1007e-02, -2.7539e-02, -2.6813e-02, -3.3304e-03,  1.5825e-02,\n",
       "                       1.1213e-02, -9.6899e-03, -5.4661e-03,  4.2204e-03,  3.5011e-05,\n",
       "                      -1.5457e-02, -1.1615e-02, -1.3990e-02,  9.1949e-03, -2.7876e-03,\n",
       "                      -1.7079e-02,  1.5275e-02,  4.8054e-03, -5.0017e-04, -6.6978e-05,\n",
       "                      -2.9418e-02, -8.3716e-03, -5.7128e-04, -1.4547e-02,  9.0625e-04,\n",
       "                      -1.5546e-02, -2.1604e-02, -1.0430e-02, -1.1210e-02, -1.6800e-02,\n",
       "                      -1.1154e-02,  7.4977e-03,  1.6724e-02, -1.2630e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.2794,  0.1898, -0.0707, -0.0750, -0.1517,  0.0831, -0.5452, -0.6698,\n",
       "                      -0.4186,  0.4852, -0.1245, -0.2697,  0.0081, -0.1627, -0.0335,  0.5354,\n",
       "                      -0.1779, -0.0325,  0.5645, -0.4776,  0.6304, -0.0719,  0.0135,  0.1194,\n",
       "                       0.4775,  0.2816, -0.3085, -0.2595,  0.0542, -0.3208, -0.1225, -0.4261,\n",
       "                      -0.8632, -0.3544, -0.6738,  0.4403, -0.6101, -0.1985, -0.3912, -0.1022,\n",
       "                      -0.2301, -0.4370, -0.1214, -0.4250, -0.0650,  0.4371, -0.2645, -0.3008,\n",
       "                       0.5081, -0.2417, -0.3805, -0.6219, -0.2269, -0.5891, -0.5998, -0.6586,\n",
       "                      -0.0526,  0.4790, -0.4874,  0.1390,  0.8981, -0.1165, -0.1777, -0.2286],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.1.1.running_var',\n",
       "              tensor([1.0093, 1.0319, 0.3667, 0.3792, 0.8875, 0.3362, 0.5115, 0.6183, 1.1835,\n",
       "                      0.4314, 0.3526, 0.5524, 0.6288, 0.6846, 1.2261, 0.4111, 0.5362, 0.4094,\n",
       "                      0.7930, 0.6103, 0.5558, 0.5414, 0.3986, 0.6676, 0.5148, 0.9956, 0.3751,\n",
       "                      1.1489, 1.6513, 1.0437, 0.4789, 0.4533, 1.5465, 0.7035, 0.9554, 0.5463,\n",
       "                      0.9240, 0.5755, 0.3416, 0.5066, 0.4178, 1.0751, 0.7850, 0.6239, 0.3439,\n",
       "                      0.6473, 0.5669, 0.6776, 0.5674, 0.3418, 0.7720, 0.5270, 0.7832, 0.5416,\n",
       "                      0.5178, 0.5546, 0.8007, 0.7954, 0.3757, 0.6893, 1.0762, 0.5076, 0.7073,\n",
       "                      0.8935], dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('5.3.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0703],\n",
       "                       [-0.0006],\n",
       "                       [-0.0581],\n",
       "                       ...,\n",
       "                       [ 0.0878],\n",
       "                       [-0.0307],\n",
       "                       [ 0.0071]],\n",
       "              \n",
       "                      [[ 0.0391],\n",
       "                       [-0.0487],\n",
       "                       [-0.0311],\n",
       "                       ...,\n",
       "                       [ 0.0177],\n",
       "                       [-0.0800],\n",
       "                       [ 0.1407]],\n",
       "              \n",
       "                      [[ 0.0334],\n",
       "                       [ 0.0831],\n",
       "                       [-0.2349],\n",
       "                       ...,\n",
       "                       [-0.0827],\n",
       "                       [ 0.0171],\n",
       "                       [-0.2185]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.4092],\n",
       "                       [-0.0551],\n",
       "                       [ 0.0535],\n",
       "                       ...,\n",
       "                       [ 0.0626],\n",
       "                       [ 0.1836],\n",
       "                       [-0.1450]],\n",
       "              \n",
       "                      [[-0.0229],\n",
       "                       [ 0.0534],\n",
       "                       [-0.0155],\n",
       "                       ...,\n",
       "                       [-0.0672],\n",
       "                       [-0.3458],\n",
       "                       [-0.1254]],\n",
       "              \n",
       "                      [[ 0.1801],\n",
       "                       [-0.1595],\n",
       "                       [ 0.0825],\n",
       "                       ...,\n",
       "                       [-0.1389],\n",
       "                       [ 0.0803],\n",
       "                       [-0.1397]]], dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.2.1.weight',\n",
       "              tensor([-0.0043, -0.0048, -0.0076, -0.0096, -0.0024,  0.0078, -0.0054, -0.0018,\n",
       "                      -0.0161,  0.0094, -0.0039, -0.0009, -0.0094, -0.0468, -0.0409, -0.0169,\n",
       "                       0.0248,  0.0311,  0.0090, -0.0047,  0.0232,  0.0339,  0.0068, -0.0022,\n",
       "                      -0.0076, -0.0106,  0.0022,  0.0011,  0.0164,  0.0198, -0.0260, -0.0493,\n",
       "                      -0.0110, -0.0189, -0.0140, -0.0234, -0.0121,  0.0148, -0.0159,  0.0157,\n",
       "                       0.0085,  0.0028,  0.0086, -0.0130,  0.0172, -0.0077,  0.0243, -0.0116,\n",
       "                       0.0141, -0.0050, -0.0176, -0.0185, -0.0228, -0.0301, -0.0116,  0.0011,\n",
       "                      -0.0190, -0.0318, -0.0134, -0.0107,  0.0160, -0.0211,  0.0111, -0.0080,\n",
       "                      -0.0082,  0.0165,  0.0062,  0.0200, -0.0136,  0.0167, -0.0028,  0.0012,\n",
       "                      -0.0122, -0.0262,  0.0224, -0.0121,  0.0625, -0.0070,  0.0160,  0.0051,\n",
       "                       0.0035,  0.0116,  0.0584,  0.0307,  0.0216,  0.0399, -0.0048, -0.0011,\n",
       "                       0.0023, -0.0057,  0.0082,  0.0166, -0.0158,  0.0271,  0.0049, -0.0028,\n",
       "                       0.0054,  0.0155,  0.0293, -0.0123, -0.0189,  0.0285, -0.0130, -0.0085,\n",
       "                       0.0202,  0.0120,  0.0232,  0.0010,  0.0128, -0.0179,  0.0163, -0.0098,\n",
       "                       0.0083, -0.0190,  0.0030,  0.0072, -0.0032,  0.0036, -0.0264,  0.0033,\n",
       "                       0.0156, -0.0010, -0.0256,  0.0277,  0.0064, -0.0174,  0.0294,  0.0183,\n",
       "                       0.0079,  0.0063,  0.0067, -0.0095,  0.0142,  0.0092,  0.0049, -0.0047,\n",
       "                       0.0043, -0.0208,  0.0184,  0.0304,  0.0012,  0.0143, -0.0128, -0.0049,\n",
       "                       0.0153, -0.0128,  0.0019,  0.0105, -0.0148, -0.0009, -0.0067,  0.0359,\n",
       "                       0.0320, -0.0177,  0.0027, -0.0064,  0.0077,  0.0086,  0.0111, -0.0128,\n",
       "                      -0.0007, -0.0120, -0.0096,  0.0130,  0.0258,  0.0005, -0.0399, -0.0125,\n",
       "                      -0.0372,  0.0053, -0.0138, -0.0078,  0.0428,  0.0188, -0.0082, -0.0133,\n",
       "                       0.0075, -0.0141,  0.0098,  0.0240,  0.0141,  0.0172,  0.0400,  0.0072,\n",
       "                       0.0112, -0.0246,  0.0142, -0.0422,  0.0095,  0.0167,  0.0447,  0.0014,\n",
       "                      -0.0207, -0.0347,  0.0381,  0.0079, -0.0040,  0.0110,  0.0006,  0.0029,\n",
       "                       0.0027,  0.0346, -0.0177,  0.0200, -0.0144, -0.0151,  0.0141,  0.0018,\n",
       "                      -0.0129,  0.0090, -0.0116, -0.0026,  0.0140,  0.0079,  0.0281,  0.0322,\n",
       "                      -0.0195,  0.0380,  0.0477, -0.0143, -0.0024, -0.0009, -0.0166, -0.0057,\n",
       "                       0.0170, -0.0004, -0.0047, -0.0142, -0.0093,  0.0173, -0.0024,  0.0042,\n",
       "                       0.0067, -0.0186, -0.0036, -0.0500, -0.0015, -0.0265, -0.0206,  0.0310,\n",
       "                       0.0043,  0.0139,  0.0267,  0.0133, -0.0083,  0.0040, -0.0115, -0.0189,\n",
       "                      -0.0079, -0.0386,  0.0040,  0.0057,  0.0155, -0.0113,  0.0162, -0.0072],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.2.1.bias',\n",
       "              tensor([-6.3887e-04, -4.0647e-03,  2.1364e-02,  6.2034e-03, -1.9000e-03,\n",
       "                      -1.3072e-02,  1.7759e-02,  2.2344e-03,  1.2202e-02,  1.9587e-02,\n",
       "                      -4.4969e-03, -5.7991e-03,  1.3204e-02, -7.2764e-03,  1.3324e-02,\n",
       "                       1.0164e-02,  2.2745e-02,  1.0041e-02,  1.8895e-02, -6.6854e-03,\n",
       "                      -5.6202e-04,  5.8272e-03, -2.5647e-03,  6.0610e-03, -3.6746e-03,\n",
       "                      -2.5566e-02,  9.2644e-03,  1.0533e-02,  5.8387e-03,  1.8568e-03,\n",
       "                      -8.0075e-03,  1.1864e-02, -1.7029e-02,  2.3001e-02,  1.3861e-02,\n",
       "                       1.1602e-03,  3.3371e-03,  2.6461e-02,  1.9183e-02,  1.1472e-02,\n",
       "                       2.6044e-03, -9.3484e-03, -4.3218e-03,  5.1953e-03,  1.5233e-02,\n",
       "                      -7.6972e-03, -2.0580e-03,  1.1362e-02, -8.4105e-03,  6.6046e-03,\n",
       "                      -1.9166e-03,  2.4499e-03,  1.6570e-02,  1.9461e-02, -1.3702e-02,\n",
       "                      -1.9292e-03,  6.6099e-03,  1.3216e-02,  5.2063e-03,  5.7547e-03,\n",
       "                      -1.1355e-02,  6.1355e-03, -5.1213e-04,  1.0585e-02, -2.0086e-03,\n",
       "                       1.4981e-02, -9.1195e-03,  1.2142e-02,  1.3030e-03, -1.3168e-02,\n",
       "                       3.8022e-03,  1.2216e-02,  1.0980e-02, -6.4504e-03,  2.2738e-02,\n",
       "                       8.5880e-03,  8.1136e-03, -1.4326e-02,  8.0742e-03,  7.0039e-03,\n",
       "                       1.3571e-02, -3.1573e-03,  1.4684e-02,  7.2891e-03,  6.1078e-04,\n",
       "                       7.3977e-03,  8.7112e-03,  4.4942e-03,  1.0875e-02,  7.2141e-03,\n",
       "                       1.1323e-03,  1.6197e-02,  1.9573e-02,  5.4885e-04,  4.9150e-03,\n",
       "                      -1.1353e-02,  7.1363e-03,  6.0952e-03,  1.0353e-02, -1.0691e-02,\n",
       "                       2.8608e-02, -5.6944e-03, -9.4944e-03, -2.2617e-02,  1.2011e-02,\n",
       "                       3.8650e-03,  4.4853e-03,  8.4501e-04,  4.5319e-03,  6.5910e-03,\n",
       "                      -6.7278e-03, -4.7204e-03,  8.3341e-03,  1.8122e-02,  7.4130e-03,\n",
       "                       7.8655e-03,  1.1304e-02,  1.6754e-03,  9.1084e-03, -1.3400e-02,\n",
       "                       4.7133e-03,  1.2976e-02,  4.6433e-03,  2.7075e-03, -6.6156e-03,\n",
       "                       1.2141e-02,  7.0365e-03,  4.8307e-03,  4.7059e-03,  9.0757e-03,\n",
       "                       2.2005e-03,  4.9007e-03,  7.7811e-03,  1.2611e-02,  1.7299e-03,\n",
       "                      -1.6393e-02,  4.5643e-04,  1.5586e-02,  1.0813e-02,  1.1029e-02,\n",
       "                      -7.0930e-03,  4.3861e-03, -5.3571e-04,  1.2885e-02, -1.2485e-02,\n",
       "                      -4.4892e-03,  4.1339e-03, -1.3255e-03,  1.0024e-02,  1.1044e-02,\n",
       "                       8.6549e-03,  3.2498e-02,  1.4242e-02,  1.7529e-02,  1.8887e-02,\n",
       "                       1.6451e-02,  2.2513e-03,  1.4089e-02, -2.3116e-03, -1.6123e-02,\n",
       "                       2.1674e-03,  1.3491e-03,  1.0743e-03,  1.9439e-02,  4.9917e-03,\n",
       "                       3.9682e-03, -7.2644e-03,  6.5169e-03,  1.3627e-02,  1.6172e-02,\n",
       "                       4.6044e-03, -1.4444e-03,  8.1002e-03,  1.2096e-02, -1.5642e-02,\n",
       "                      -3.8141e-03, -8.9964e-04,  2.3817e-02,  5.8831e-03,  9.4751e-03,\n",
       "                      -2.8132e-03,  2.2086e-02, -1.4456e-02, -4.4533e-03,  1.4024e-02,\n",
       "                       8.6503e-03,  1.1536e-02,  1.8742e-02, -3.3009e-03,  1.1747e-03,\n",
       "                       7.6575e-03, -1.2056e-03,  1.8428e-02, -2.1536e-02,  7.4855e-03,\n",
       "                       1.1300e-02, -8.5633e-03,  1.6895e-02,  9.6312e-03, -1.5870e-02,\n",
       "                       5.8270e-03, -8.8419e-04,  1.2938e-02,  2.1696e-02,  2.4334e-03,\n",
       "                      -8.3693e-03,  1.4810e-02, -1.0183e-02,  8.6087e-03,  8.6641e-03,\n",
       "                       1.5371e-04,  1.3084e-02,  1.2512e-02,  6.5208e-03,  6.1465e-03,\n",
       "                       1.0607e-02,  4.6932e-03,  1.4600e-02,  8.0792e-03,  9.7572e-05,\n",
       "                      -6.9314e-03, -6.9845e-03,  1.0003e-02,  2.7858e-02, -3.5712e-03,\n",
       "                      -1.2112e-04, -4.3388e-04,  1.6662e-03, -2.5998e-02,  1.8026e-03,\n",
       "                       2.0000e-02,  6.1719e-03,  1.1003e-02,  2.3760e-03,  1.0371e-02,\n",
       "                       6.4296e-03,  8.1386e-03,  2.8036e-03,  5.3197e-03,  1.4614e-02,\n",
       "                      -6.6263e-03,  3.4073e-03,  1.1054e-02, -2.2398e-04,  7.5147e-03,\n",
       "                       1.4856e-02,  6.6866e-03,  1.1898e-02, -4.8538e-03, -7.8340e-03,\n",
       "                       1.5311e-02,  7.5289e-03,  2.1566e-02,  2.3692e-02,  1.9520e-02,\n",
       "                       2.9027e-03], dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.2.1.running_mean',\n",
       "              tensor([ 0.4124, -0.0096, -0.8011, -0.0950,  0.0559,  0.1874, -0.1256, -0.2686,\n",
       "                      -0.5384, -0.0447, -0.2683, -0.4431,  0.3032, -0.1489,  0.9169,  0.4619,\n",
       "                      -0.6089,  0.1535, -0.3866,  0.4746,  0.1170,  0.3971,  0.1030,  0.1144,\n",
       "                      -0.0110,  0.4086, -0.4751, -0.1057, -0.2841, -0.2941, -0.1534,  1.1162,\n",
       "                      -0.3167, -0.1320,  0.0735, -0.1066,  0.3522,  0.1312, -0.1458,  0.6455,\n",
       "                       0.0132,  0.2461,  0.1389, -0.2385,  0.2537,  0.4057, -0.0319, -0.5077,\n",
       "                      -0.5940, -0.4255, -0.0347,  0.0232,  0.3935,  0.0776, -0.0184,  0.2142,\n",
       "                      -0.0068,  1.1388, -0.6292,  0.4449,  0.5935,  0.5635, -0.1454,  0.0300,\n",
       "                      -0.0489, -0.1861,  0.3126, -0.6144,  0.1453, -0.6030, -0.0348, -0.0387,\n",
       "                       0.2074, -0.0550,  0.3099, -0.2859,  0.3149, -0.1383,  0.1301, -0.1700,\n",
       "                      -0.2106, -0.0473, -0.1117,  0.1110, -0.2326, -0.0556, -0.2226, -0.3421,\n",
       "                       0.4421, -0.0274, -0.3438, -0.3106, -0.0571, -0.1958, -0.0109, -0.1868,\n",
       "                       0.1236,  0.1177, -0.1610, -0.0297,  0.0225,  0.4046, -0.0589, -0.2376,\n",
       "                       0.3300,  0.5707,  0.3657,  0.0683, -0.3905,  0.2888,  0.0525, -0.2951,\n",
       "                      -0.0175,  0.2864,  0.2144,  0.1488,  0.1579,  0.6209,  0.5971,  0.0825,\n",
       "                       0.3387, -0.1079, -0.1861, -0.1857, -0.2171,  0.2297, -0.0247, -0.0258,\n",
       "                       0.3134, -0.0514,  0.1340,  0.2164, -0.0396,  0.1412, -0.1937, -0.0121,\n",
       "                      -0.1267, -0.3960, -0.3048,  0.1869,  0.4263, -0.1307, -0.2689, -0.2222,\n",
       "                       0.2758,  0.4750, -0.1319,  0.7055, -0.1012, -0.2024, -0.3398, -0.3946,\n",
       "                      -0.5469,  0.4258,  0.0810,  0.5945, -0.0871, -0.2251, -0.1228, -0.2235,\n",
       "                      -0.0515, -0.4006, -0.1299,  0.2699, -0.7675,  0.1228, -0.2362, -0.0265,\n",
       "                      -0.1189, -0.0893,  0.3059, -0.6212,  0.3346,  0.2798, -0.2379, -0.1525,\n",
       "                      -0.2051,  0.3744, -0.1459,  0.0777, -0.0247,  0.4538,  0.2245,  0.6873,\n",
       "                       0.1688,  0.9142, -0.2394,  0.4566, -0.1004,  0.5061,  0.4664,  0.0989,\n",
       "                      -0.0176, -0.2184,  0.2568,  0.1067,  0.0287, -0.2602,  0.1708,  0.0301,\n",
       "                      -0.3081, -0.3562,  0.0682, -0.2590, -0.3701, -0.2986,  0.0663,  0.1957,\n",
       "                      -0.2194, -0.2390,  0.1144,  0.4235, -0.0405,  0.5257,  0.3823,  0.5491,\n",
       "                      -1.2602,  0.3709, -0.4742, -0.0184, -0.0997,  0.0065,  0.1146, -0.4412,\n",
       "                      -0.2190,  0.0753, -0.2445,  0.1343,  0.2108, -0.3314, -0.3753,  0.2655,\n",
       "                      -0.2935, -0.3211,  0.3481, -0.6652,  0.0547,  0.1851, -0.5539,  0.0808,\n",
       "                       0.1165,  0.2840, -0.2779, -0.2260, -0.1139, -0.1904, -0.4673,  0.0626,\n",
       "                       0.1821, -0.0576,  0.0299, -0.4333,  0.4227,  0.1861,  0.0734,  0.4437],\n",
       "                     dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.2.1.running_var',\n",
       "              tensor([0.1202, 0.3140, 0.2868, 0.2815, 0.2094, 0.2291, 0.2431, 0.1354, 0.1637,\n",
       "                      0.3213, 0.2707, 0.1180, 0.2963, 0.3076, 0.3347, 0.4244, 0.6896, 0.4558,\n",
       "                      0.3247, 0.3800, 0.2943, 0.5471, 0.6224, 0.1502, 0.3818, 0.3542, 0.2970,\n",
       "                      0.1122, 0.2493, 0.2665, 0.2108, 0.3792, 0.1930, 0.3937, 0.2914, 0.1973,\n",
       "                      0.1349, 0.2095, 0.3910, 0.5305, 0.2320, 0.0985, 0.1311, 0.3056, 0.2369,\n",
       "                      0.4958, 0.3403, 0.1601, 0.4912, 0.2895, 0.2500, 0.3183, 0.4855, 0.3410,\n",
       "                      0.2884, 0.1955, 0.3910, 0.3526, 0.3729, 0.2710, 0.3047, 0.3347, 0.4184,\n",
       "                      0.3675, 0.4222, 0.0800, 0.2254, 0.2555, 0.3885, 0.3753, 0.2459, 0.0457,\n",
       "                      0.2832, 0.3977, 0.3510, 0.1703, 0.4101, 0.1482, 0.4604, 0.2474, 0.3357,\n",
       "                      0.2736, 0.3734, 0.4499, 0.3608, 0.3739, 0.3995, 0.4463, 0.1756, 0.1257,\n",
       "                      0.5095, 0.2758, 0.1853, 0.6160, 0.3035, 0.1671, 0.3586, 0.1276, 0.1641,\n",
       "                      0.5433, 0.3265, 0.3703, 0.2231, 0.2306, 0.4007, 0.4745, 0.6165, 0.4554,\n",
       "                      0.2590, 0.2785, 0.1544, 0.3020, 0.3302, 0.2777, 0.2649, 0.2982, 0.2208,\n",
       "                      0.4789, 0.3255, 0.1889, 0.1135, 0.0937, 0.2864, 0.5263, 0.1125, 0.2621,\n",
       "                      0.3085, 0.1247, 0.2534, 0.3554, 0.1637, 0.2268, 0.3761, 0.0894, 0.1295,\n",
       "                      0.0488, 0.2557, 0.2693, 0.2745, 0.2609, 0.1977, 0.2497, 0.3916, 0.2525,\n",
       "                      0.1748, 0.7151, 0.0744, 0.3781, 0.1735, 0.1502, 0.3473, 0.2838, 0.4976,\n",
       "                      0.5947, 0.1319, 0.3458, 0.2664, 0.2735, 0.3811, 0.2855, 0.2443, 0.2867,\n",
       "                      0.1556, 0.1427, 0.4710, 0.1243, 0.4768, 0.2655, 0.4209, 0.3465, 0.2084,\n",
       "                      0.3655, 0.2703, 0.2959, 0.5168, 0.3955, 0.3101, 0.1269, 0.1561, 0.1917,\n",
       "                      0.1673, 0.2166, 0.3166, 0.3873, 0.2917, 0.4600, 0.3200, 0.2894, 0.1221,\n",
       "                      0.4412, 0.4437, 0.2416, 0.4867, 0.4599, 0.2619, 0.2733, 0.0985, 0.3060,\n",
       "                      0.1462, 0.3375, 0.2611, 0.4587, 0.3199, 0.3059, 0.6223, 0.5544, 0.2658,\n",
       "                      0.0523, 0.3685, 0.4548, 0.1121, 0.0933, 0.4420, 0.1536, 0.2723, 0.2951,\n",
       "                      0.4439, 0.2361, 0.2351, 0.2406, 0.1483, 0.1470, 0.1451, 0.4183, 0.5358,\n",
       "                      0.1342, 0.3321, 0.3501, 0.3895, 0.4608, 0.1451, 0.3868, 0.3904, 0.3519,\n",
       "                      0.2535, 0.4708, 0.2332, 0.3359, 0.3401, 0.3544, 0.0744, 0.3489, 0.3796,\n",
       "                      0.1614, 0.1784, 0.2616, 0.0992, 0.2778, 0.1440, 0.3581, 0.1561, 0.3185,\n",
       "                      0.2231, 0.5070, 0.2164, 0.3047], dtype=torch.float64)),\n",
       "             ('5.3.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.0.convs.0.0.weight',\n",
       "              tensor([[[-2.6970e-02],\n",
       "                       [-3.6803e-03],\n",
       "                       [-9.6383e-02],\n",
       "                       ...,\n",
       "                       [-2.8363e-02],\n",
       "                       [-1.4273e-01],\n",
       "                       [ 1.4194e-01]],\n",
       "              \n",
       "                      [[ 1.0622e-01],\n",
       "                       [-3.8758e-02],\n",
       "                       [ 3.5894e-05],\n",
       "                       ...,\n",
       "                       [-4.5822e-02],\n",
       "                       [-5.4668e-03],\n",
       "                       [ 7.9421e-03]],\n",
       "              \n",
       "                      [[-1.6322e-01],\n",
       "                       [-6.7668e-02],\n",
       "                       [-5.5133e-02],\n",
       "                       ...,\n",
       "                       [ 1.6949e-01],\n",
       "                       [-5.0897e-02],\n",
       "                       [-1.2894e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 5.1697e-02],\n",
       "                       [-4.2094e-02],\n",
       "                       [-5.0710e-02],\n",
       "                       ...,\n",
       "                       [-2.0678e-01],\n",
       "                       [-7.9579e-03],\n",
       "                       [ 2.0308e-02]],\n",
       "              \n",
       "                      [[-7.3728e-02],\n",
       "                       [ 8.0049e-02],\n",
       "                       [-8.1751e-02],\n",
       "                       ...,\n",
       "                       [-5.0059e-02],\n",
       "                       [ 5.4614e-02],\n",
       "                       [-1.5907e-01]],\n",
       "              \n",
       "                      [[-7.7045e-02],\n",
       "                       [-1.1295e-01],\n",
       "                       [-8.1520e-02],\n",
       "                       ...,\n",
       "                       [-1.8396e-01],\n",
       "                       [ 3.8302e-02],\n",
       "                       [-6.1302e-02]]], dtype=torch.float64)),\n",
       "             ('6.0.convs.0.1.weight',\n",
       "              tensor([0.9733, 0.9626, 0.9769, 0.9667, 0.9645, 0.9621, 0.9552, 0.9773, 0.9869,\n",
       "                      0.9764, 0.9850, 0.9834, 0.9512, 0.9561, 0.9595, 0.9639, 0.9866, 0.9504,\n",
       "                      0.9536, 0.9499, 0.9648, 0.9685, 0.9470, 0.9857, 0.9731, 0.9530, 0.9857,\n",
       "                      0.9613, 0.9664, 0.9704, 0.9583, 0.9523, 0.9583, 0.9381, 0.9631, 0.9477,\n",
       "                      0.9694, 0.9740, 0.9530, 0.9843, 0.9656, 0.9630, 0.9602, 0.9750, 0.9555,\n",
       "                      0.9664, 0.9937, 0.9696, 0.9714, 0.9809, 0.9755, 0.9606, 0.9642, 0.9594,\n",
       "                      0.9875, 0.9568, 0.9527, 0.9711, 0.9613, 0.9579, 0.9654, 0.9781, 0.9494,\n",
       "                      0.9917], dtype=torch.float64)),\n",
       "             ('6.0.convs.0.1.bias',\n",
       "              tensor([ 0.0182,  0.0044,  0.0155,  0.0101, -0.0147,  0.0076,  0.0094,  0.0137,\n",
       "                       0.0094, -0.0042,  0.0171,  0.0154, -0.0050, -0.0074, -0.0044,  0.0118,\n",
       "                       0.0128,  0.0066, -0.0114, -0.0086, -0.0003,  0.0185,  0.0020, -0.0117,\n",
       "                       0.0092,  0.0183,  0.0128,  0.0075,  0.0061, -0.0046, -0.0017, -0.0059,\n",
       "                      -0.0078, -0.0038,  0.0109,  0.0027, -0.0155,  0.0233, -0.0079,  0.0159,\n",
       "                       0.0030, -0.0032, -0.0107,  0.0217, -0.0026, -0.0086,  0.0032,  0.0018,\n",
       "                       0.0169, -0.0049,  0.0017,  0.0022,  0.0052, -0.0124,  0.0073, -0.0054,\n",
       "                      -0.0144, -0.0094,  0.0048, -0.0039, -0.0202,  0.0241, -0.0054,  0.0164],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convs.0.1.running_mean',\n",
       "              tensor([-0.1898,  0.5286,  0.0335, -0.3213, -0.0168, -0.5279,  0.1501, -0.5237,\n",
       "                      -0.3966, -0.1989, -0.2629, -0.5886, -0.1360, -0.0880, -0.0809, -0.5115,\n",
       "                       0.3257, -0.5946,  0.4340,  0.1103, -0.3697, -1.0466, -0.5314,  0.9367,\n",
       "                      -0.1604, -0.5161, -0.5635, -0.1232,  0.2103,  0.4975, -0.0730, -0.8035,\n",
       "                       0.0293, -0.4794, -0.3607, -0.3912, -0.3421, -0.1106,  0.0427,  0.5211,\n",
       "                       0.3341, -0.2243, -0.1664,  0.5373, -0.6242,  0.2612, -0.0353, -0.0982,\n",
       "                      -0.6819,  0.1599, -0.7689,  0.3543,  0.6521, -0.1273, -0.2356,  0.3384,\n",
       "                       0.5187, -1.2648,  0.2145,  0.6314,  0.3822, -0.0959, -0.0830, -0.2557],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convs.0.1.running_var',\n",
       "              tensor([0.2949, 1.3506, 0.2095, 0.3228, 0.5939, 0.3086, 0.4491, 0.2959, 0.2250,\n",
       "                      0.2610, 0.2137, 0.3347, 0.4316, 0.3474, 0.2600, 0.4867, 0.1647, 0.4199,\n",
       "                      0.3177, 0.3693, 0.3048, 0.3139, 1.1285, 0.2792, 0.3162, 1.4534, 0.2276,\n",
       "                      0.3284, 0.5564, 0.6521, 0.2618, 0.6349, 1.4750, 1.1205, 0.4926, 0.3085,\n",
       "                      0.2899, 0.2563, 0.6309, 0.6086, 0.2059, 0.5342, 0.2046, 0.1553, 1.0869,\n",
       "                      0.2841, 0.2513, 0.2682, 0.4857, 0.2348, 0.2554, 0.4058, 0.8443, 0.3353,\n",
       "                      0.2551, 0.6225, 0.5646, 0.4638, 0.4132, 0.6166, 0.3495, 0.5060, 0.3995,\n",
       "                      0.2474], dtype=torch.float64)),\n",
       "             ('6.0.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.0.convs.1.0.weight',\n",
       "              tensor([[[ 1.4300e-02, -1.6613e-01,  5.0351e-02, -1.1099e-02,  8.5365e-02],\n",
       "                       [ 9.8312e-02, -5.9451e-02, -6.2093e-02,  7.6365e-02, -2.1359e-02],\n",
       "                       [ 5.0143e-02,  5.1288e-02, -2.1402e-02,  4.7861e-02,  1.2735e-01],\n",
       "                       ...,\n",
       "                       [ 6.7171e-03,  2.4499e-02, -1.1445e-01, -4.8095e-02,  2.6229e-03],\n",
       "                       [-8.1411e-02,  8.6263e-02, -5.1260e-03,  2.5771e-02,  7.8661e-02],\n",
       "                       [ 7.6977e-02, -7.4010e-02,  9.6184e-02, -1.4804e-01, -3.4727e-02]],\n",
       "              \n",
       "                      [[ 4.5393e-02, -6.0341e-02, -8.4389e-02,  8.6802e-02, -1.6013e-01],\n",
       "                       [-7.9932e-02, -7.5873e-02,  9.5843e-02, -7.6574e-02, -1.0187e-01],\n",
       "                       [-3.2304e-02,  5.7686e-02,  1.2541e-01, -1.9176e-02,  1.6634e-02],\n",
       "                       ...,\n",
       "                       [-3.3401e-02, -7.0081e-02, -3.1010e-02, -9.2812e-02,  1.9510e-02],\n",
       "                       [ 8.3299e-02, -4.3040e-05, -3.2365e-02, -3.8651e-02, -4.2099e-02],\n",
       "                       [-1.7246e-02, -2.4016e-02, -3.8546e-02, -9.4165e-03,  7.8797e-02]],\n",
       "              \n",
       "                      [[ 5.0659e-02,  2.5301e-02,  4.9000e-02,  5.0935e-02, -1.6699e-02],\n",
       "                       [ 4.4271e-02,  5.2339e-02, -2.9406e-02, -6.1004e-02, -1.2174e-02],\n",
       "                       [-1.2739e-01, -1.8848e-01, -1.0607e-01,  5.7483e-02,  8.0239e-02],\n",
       "                       ...,\n",
       "                       [ 1.0591e-01, -4.4503e-02, -6.2935e-03,  1.1126e-01, -3.5547e-02],\n",
       "                       [-3.0620e-02,  1.0402e-01,  3.6872e-02,  2.0736e-02,  1.7067e-01],\n",
       "                       [-4.7079e-02,  5.9846e-02, -6.3831e-02, -3.8970e-02,  2.5046e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 7.7700e-03,  1.1718e-01,  1.7228e-02, -1.5217e-02,  5.0478e-02],\n",
       "                       [-8.2533e-03, -6.7451e-02, -5.0580e-02, -3.5622e-02,  7.3493e-02],\n",
       "                       [ 6.5439e-02, -1.9100e-02, -1.4990e-02,  2.9701e-02, -1.0450e-01],\n",
       "                       ...,\n",
       "                       [-3.1419e-02, -6.2197e-02,  8.9559e-02,  1.3460e-01, -5.9444e-02],\n",
       "                       [ 8.3296e-02, -1.0445e-01, -1.3977e-02, -1.0446e-01, -1.7055e-02],\n",
       "                       [ 6.5726e-02,  9.9994e-02,  4.3117e-02, -4.6600e-02, -2.3974e-02]],\n",
       "              \n",
       "                      [[-1.0273e-01, -3.1845e-03, -5.8346e-02, -4.4879e-02,  1.1000e-01],\n",
       "                       [ 7.2528e-02, -9.8926e-02, -1.2251e-01, -7.4172e-02, -2.3046e-02],\n",
       "                       [-1.9921e-02, -2.2300e-02,  2.7006e-02, -8.2926e-02, -1.2887e-01],\n",
       "                       ...,\n",
       "                       [ 2.0463e-02, -5.8621e-02, -1.0312e-02,  6.3664e-02, -1.7162e-03],\n",
       "                       [-1.1698e-02, -2.3072e-02, -1.0209e-01, -1.2406e-01, -1.1682e-01],\n",
       "                       [-2.1273e-03,  3.7681e-02, -5.7927e-02, -5.5688e-02,  3.9049e-02]],\n",
       "              \n",
       "                      [[ 4.1006e-02, -6.9948e-02, -2.2717e-02, -6.7585e-02, -3.9872e-03],\n",
       "                       [-3.9864e-02,  2.0570e-02,  1.7803e-02,  6.2099e-03,  4.8159e-02],\n",
       "                       [-3.3721e-03,  9.4295e-02, -4.7379e-02, -6.8278e-02,  8.1723e-02],\n",
       "                       ...,\n",
       "                       [-9.0028e-02, -6.6673e-02,  9.1409e-02, -1.8492e-02,  1.9293e-02],\n",
       "                       [ 7.0934e-02,  4.6042e-02, -8.1902e-02, -1.1503e-01,  2.0710e-02],\n",
       "                       [-1.5933e-02,  3.1570e-02,  7.1365e-02, -2.3068e-01,  2.7605e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convs.1.1.weight',\n",
       "              tensor([0.9772, 0.9657, 0.9904, 0.9677, 0.9467, 0.9760, 0.9845, 0.9339, 0.9552,\n",
       "                      0.9730, 0.9871, 0.9569, 0.9616, 0.9632, 0.9808, 0.9587, 0.9529, 0.9390,\n",
       "                      0.9686, 0.9313, 0.9522, 0.9481, 0.9594, 0.9552, 0.9837, 0.9258, 0.9615,\n",
       "                      0.9435, 0.9587, 0.9819, 0.9615, 0.9618, 0.9489, 0.9698, 0.9545, 0.9801,\n",
       "                      0.9747, 0.9557, 0.9573, 0.9640, 0.9726, 0.9735, 0.9665, 0.9526, 0.9606,\n",
       "                      0.9738, 0.9691, 0.9582, 0.9767, 0.9587, 0.9691, 0.9865, 0.9445, 0.9475,\n",
       "                      0.9505, 0.9650, 0.9384, 0.9429, 0.9540, 0.9639, 0.9670, 0.9594, 0.9721,\n",
       "                      0.9555], dtype=torch.float64)),\n",
       "             ('6.0.convs.1.1.bias',\n",
       "              tensor([-0.0031, -0.0078, -0.0057, -0.0053, -0.0112, -0.0063,  0.0148, -0.0183,\n",
       "                      -0.0160,  0.0005,  0.0039, -0.0100,  0.0104,  0.0115,  0.0040, -0.0104,\n",
       "                      -0.0144,  0.0034,  0.0005, -0.0205, -0.0027,  0.0125,  0.0045, -0.0064,\n",
       "                       0.0177, -0.0131,  0.0071, -0.0039, -0.0167,  0.0071, -0.0171, -0.0294,\n",
       "                      -0.0149,  0.0221, -0.0059, -0.0067,  0.0125, -0.0113,  0.0044,  0.0022,\n",
       "                      -0.0059, -0.0090,  0.0185, -0.0149, -0.0038,  0.0002, -0.0040, -0.0058,\n",
       "                      -0.0019, -0.0136,  0.0111, -0.0298, -0.0237, -0.0047,  0.0010,  0.0101,\n",
       "                      -0.0135, -0.0108, -0.0042,  0.0065, -0.0105, -0.0132, -0.0063,  0.0028],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convs.1.1.running_mean',\n",
       "              tensor([ 0.4012, -0.4091,  0.0604, -0.4854, -0.2893, -0.1028, -0.0115,  0.3455,\n",
       "                      -0.0449,  0.4850,  0.4138, -0.5967,  0.3608, -0.8848, -0.5577,  0.3049,\n",
       "                       0.1373, -0.1257, -0.4323, -0.3823,  0.4486, -0.7119,  0.0787,  0.1405,\n",
       "                       0.5263, -0.9175, -0.6052,  0.6887, -1.0031,  0.0758,  0.3468,  0.2492,\n",
       "                       0.0186,  0.0636, -0.5071,  0.6360,  0.8923, -0.8908,  0.4495,  0.2354,\n",
       "                       0.0971,  0.2575,  0.8363, -0.0414, -0.3072, -0.0315, -0.4707,  0.4006,\n",
       "                       0.7368,  0.1495,  0.1364,  0.8887, -0.5170, -0.3615, -0.3102, -0.4515,\n",
       "                      -0.9232, -0.9359,  0.2585, -0.4430, -0.0661, -0.2814, -0.2297, -0.1975],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convs.1.1.running_var',\n",
       "              tensor([0.4697, 0.3462, 0.6115, 0.6543, 0.3535, 0.8766, 0.4727, 0.5686, 0.3484,\n",
       "                      0.3092, 0.3595, 0.7819, 0.5885, 0.4289, 0.3098, 0.7597, 0.7137, 0.4922,\n",
       "                      0.5136, 0.5295, 0.6163, 0.5648, 0.4553, 0.3683, 0.4510, 0.5584, 0.2478,\n",
       "                      0.6515, 0.8206, 0.4619, 0.5173, 0.3721, 0.5299, 0.4317, 0.5280, 0.5363,\n",
       "                      0.5326, 0.4945, 0.4166, 0.4753, 0.4615, 0.4844, 0.4739, 0.5528, 0.5394,\n",
       "                      0.3477, 0.4482, 0.7215, 0.3526, 0.5556, 0.4774, 0.4855, 0.4149, 0.5104,\n",
       "                      0.4351, 0.5948, 0.3415, 0.4312, 0.6211, 0.6765, 0.4514, 0.6177, 0.6639,\n",
       "                      0.5058], dtype=torch.float64)),\n",
       "             ('6.0.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.0.convs.2.0.weight',\n",
       "              tensor([[[ 0.2423],\n",
       "                       [ 0.0678],\n",
       "                       [-0.1224],\n",
       "                       ...,\n",
       "                       [-0.0126],\n",
       "                       [ 0.0016],\n",
       "                       [ 0.0017]],\n",
       "              \n",
       "                      [[-0.2289],\n",
       "                       [-0.2979],\n",
       "                       [ 0.2175],\n",
       "                       ...,\n",
       "                       [ 0.1080],\n",
       "                       [ 0.1306],\n",
       "                       [-0.1502]],\n",
       "              \n",
       "                      [[ 0.0911],\n",
       "                       [ 0.0726],\n",
       "                       [-0.1599],\n",
       "                       ...,\n",
       "                       [-0.0212],\n",
       "                       [-0.0425],\n",
       "                       [-0.0222]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0237],\n",
       "                       [-0.0678],\n",
       "                       [-0.0063],\n",
       "                       ...,\n",
       "                       [-0.0885],\n",
       "                       [-0.0355],\n",
       "                       [ 0.0205]],\n",
       "              \n",
       "                      [[-0.0423],\n",
       "                       [-0.0107],\n",
       "                       [ 0.1330],\n",
       "                       ...,\n",
       "                       [ 0.0471],\n",
       "                       [ 0.0839],\n",
       "                       [ 0.0514]],\n",
       "              \n",
       "                      [[ 0.0804],\n",
       "                       [-0.0290],\n",
       "                       [ 0.0372],\n",
       "                       ...,\n",
       "                       [ 0.1110],\n",
       "                       [-0.1031],\n",
       "                       [-0.1347]]], dtype=torch.float64)),\n",
       "             ('6.0.convs.2.1.weight',\n",
       "              tensor([ 1.2589e-02,  2.2134e-02,  1.4982e-03, -1.0002e-02,  6.8350e-03,\n",
       "                       2.7259e-02, -5.5047e-03,  2.3923e-02,  3.1186e-03,  8.5064e-03,\n",
       "                       4.6943e-03,  4.6265e-03,  1.0152e-02, -3.9186e-03,  9.8827e-03,\n",
       "                      -1.4132e-02,  9.0858e-03,  2.4119e-02,  1.4784e-02, -1.1469e-02,\n",
       "                      -3.4464e-04, -3.3942e-02, -1.4982e-02, -1.0714e-02,  3.3634e-02,\n",
       "                       2.5132e-02,  5.9036e-03, -1.7812e-03,  1.6919e-03, -1.0305e-02,\n",
       "                      -2.4515e-02, -2.3907e-02, -3.6213e-04,  8.4237e-03,  1.2070e-02,\n",
       "                      -1.4688e-02, -7.5030e-03,  1.1786e-04,  1.5954e-02,  5.4133e-03,\n",
       "                       6.0047e-03, -1.1529e-02,  1.0736e-02,  1.5569e-02, -8.1443e-03,\n",
       "                      -7.4892e-04, -1.5531e-02, -5.7282e-03,  3.9492e-03,  2.4710e-03,\n",
       "                      -2.0063e-02, -6.8316e-03, -2.2209e-04, -2.2354e-02, -1.4528e-02,\n",
       "                      -8.2951e-03,  1.7758e-02, -4.2690e-02, -6.2631e-03,  1.1134e-02,\n",
       "                       8.9511e-03,  1.2944e-02,  8.3517e-03, -2.1371e-03,  1.9489e-02,\n",
       "                       2.2800e-02, -1.3371e-02, -1.2709e-02,  2.6410e-02, -6.7265e-03,\n",
       "                      -1.2115e-02, -8.9795e-03, -1.9000e-02,  1.3643e-02, -9.7831e-03,\n",
       "                       1.9139e-02,  2.4012e-02,  1.2607e-02, -1.0823e-02, -2.0259e-02,\n",
       "                      -5.5155e-03,  1.7089e-02, -4.3870e-02,  3.0878e-02, -3.4828e-02,\n",
       "                      -1.5229e-02,  3.0851e-02, -4.7761e-04, -1.1347e-02, -1.7289e-02,\n",
       "                      -4.4876e-02, -6.5281e-04,  1.4520e-02, -5.4784e-03, -3.5537e-03,\n",
       "                       3.5752e-03, -3.5605e-02,  1.0840e-03, -1.0007e-03,  2.8729e-02,\n",
       "                       4.6823e-03,  8.1020e-03, -2.9972e-03,  1.0286e-02,  2.3756e-02,\n",
       "                      -1.4443e-02, -1.1917e-02,  1.3830e-02, -2.6427e-02, -7.4733e-03,\n",
       "                      -6.5341e-03,  1.2077e-03,  3.8398e-03,  1.7993e-03,  2.8002e-02,\n",
       "                      -1.2012e-02,  6.8674e-03,  4.1180e-03, -4.9496e-04, -1.0257e-02,\n",
       "                       1.6305e-02,  2.9369e-02, -9.3340e-03, -5.2921e-03,  1.5934e-02,\n",
       "                       1.8353e-02,  3.3962e-03, -1.7315e-02, -2.1504e-03,  3.9781e-04,\n",
       "                      -3.2770e-03, -1.8545e-02, -5.0681e-03, -2.8501e-03,  1.6818e-02,\n",
       "                      -1.2274e-02,  4.5861e-02, -7.9423e-03,  2.3305e-02,  5.1455e-04,\n",
       "                       1.6888e-02,  1.4197e-03,  1.3604e-02,  9.6374e-06,  3.4015e-03,\n",
       "                      -2.8965e-02,  7.6350e-03,  3.1075e-03,  5.1877e-03, -6.5824e-05,\n",
       "                      -1.2750e-02,  6.0342e-03,  2.4308e-02, -8.0952e-03, -8.7356e-03,\n",
       "                      -1.3684e-02, -8.3638e-03,  2.8634e-03, -1.5896e-02, -8.8031e-04,\n",
       "                       7.4047e-03,  1.2607e-02,  8.0281e-03,  1.4698e-03,  4.7841e-02,\n",
       "                       9.1095e-03,  9.1333e-03,  2.7199e-02, -2.4835e-02, -2.3206e-02,\n",
       "                       1.2201e-03, -8.6248e-04, -6.3817e-03,  8.6714e-03,  2.6644e-03,\n",
       "                      -8.8644e-03,  8.3611e-03, -1.3300e-02, -1.9668e-02, -2.8264e-02,\n",
       "                       3.8536e-02,  1.5099e-02, -7.0421e-03, -3.5954e-03, -8.5808e-03,\n",
       "                       1.4133e-02,  9.7383e-03,  2.9362e-02,  1.6455e-02, -2.0519e-03,\n",
       "                       1.9844e-02,  1.4509e-02, -4.7951e-03, -3.7688e-02,  1.7180e-02,\n",
       "                      -1.8202e-02, -2.2994e-03, -9.3939e-04, -1.7049e-02,  9.0388e-03,\n",
       "                      -1.1602e-02,  2.0356e-02,  7.4361e-04, -1.5174e-02,  4.6653e-03,\n",
       "                       1.4713e-02,  4.4670e-03,  7.0714e-03,  1.1514e-03,  1.8712e-02,\n",
       "                       1.5238e-02, -6.4437e-03, -8.1187e-03, -1.1528e-03,  5.1901e-04,\n",
       "                      -3.4911e-03, -8.2275e-03,  1.0125e-02,  3.6172e-02,  1.1648e-02,\n",
       "                      -1.4007e-03, -1.9274e-02,  2.6684e-03,  9.2241e-03,  1.9817e-02,\n",
       "                       1.3887e-02,  3.9888e-03,  1.5255e-03, -6.2476e-03,  6.0278e-03,\n",
       "                       2.5531e-02, -1.1539e-02, -1.4804e-02,  1.4940e-02, -1.3097e-02,\n",
       "                       1.2203e-02, -1.5113e-03, -1.0267e-02,  2.2433e-02, -5.5860e-03,\n",
       "                       5.8517e-03,  4.7929e-03,  3.0242e-02,  1.7900e-02,  1.5140e-02,\n",
       "                      -5.5452e-03, -2.2973e-02, -1.9603e-02,  1.2895e-02, -3.6269e-02,\n",
       "                      -5.9550e-03,  9.1785e-03,  1.6192e-02, -4.8521e-03,  3.8073e-02,\n",
       "                       1.1540e-02], dtype=torch.float64)),\n",
       "             ('6.0.convs.2.1.bias',\n",
       "              tensor([-2.6710e-03, -4.4757e-03,  1.9047e-02,  7.9802e-03,  4.5639e-03,\n",
       "                       6.3193e-03,  2.1594e-02,  3.1125e-04,  1.1535e-02,  2.0684e-02,\n",
       "                       1.0022e-02, -7.4316e-03,  1.3917e-02, -8.1055e-03,  6.9060e-03,\n",
       "                       9.1917e-03,  1.7281e-02,  1.3197e-03,  1.6949e-02, -7.9680e-03,\n",
       "                      -2.1120e-03,  4.7207e-03,  2.7994e-03,  6.7468e-03, -2.9368e-03,\n",
       "                      -1.3028e-02,  6.3551e-03,  1.0486e-02,  3.2672e-03,  6.2418e-04,\n",
       "                      -9.8721e-03,  8.7850e-03, -8.5806e-03,  1.5453e-02,  1.8509e-02,\n",
       "                      -4.5585e-03,  5.0924e-03,  2.6859e-02,  1.3148e-02,  1.4147e-02,\n",
       "                       9.4985e-04, -1.4161e-02, -6.3559e-03,  2.4406e-03,  1.2313e-02,\n",
       "                      -1.1858e-02,  1.4381e-02,  6.8018e-03, -1.1003e-02, -1.6633e-03,\n",
       "                       3.7283e-03,  2.5442e-03,  8.2851e-03,  2.1109e-02, -1.8510e-03,\n",
       "                      -2.5443e-03,  8.0939e-03,  7.5784e-03,  7.7029e-03,  8.8865e-03,\n",
       "                      -6.5805e-03,  2.9684e-03,  4.4420e-03,  1.0176e-02, -3.2072e-03,\n",
       "                       1.5495e-02, -1.1231e-02,  1.4449e-02, -2.0563e-03, -9.1886e-03,\n",
       "                       3.8787e-03,  1.0248e-02,  1.3782e-02, -7.9940e-03,  1.4503e-02,\n",
       "                       1.4225e-02,  2.1259e-03, -7.5022e-03,  3.2457e-03,  7.0246e-03,\n",
       "                       1.1919e-02, -5.5552e-03,  7.4540e-03,  5.7170e-03, -1.4955e-03,\n",
       "                       4.2297e-03,  6.4495e-03,  3.8244e-03,  9.0017e-03,  6.0969e-03,\n",
       "                      -1.6878e-03,  2.0648e-02,  1.8853e-02, -7.4074e-04,  5.3471e-03,\n",
       "                      -1.6457e-02,  5.8088e-03,  6.4733e-03,  1.1973e-02, -2.4289e-03,\n",
       "                       2.6342e-02,  7.8291e-03, -1.6686e-03, -2.0576e-02,  1.4190e-02,\n",
       "                       1.0357e-03,  6.9472e-03, -2.2884e-03,  3.9864e-03,  6.8144e-03,\n",
       "                      -7.6664e-03, -6.1410e-03,  6.2409e-03,  1.5377e-02,  6.4755e-03,\n",
       "                       8.0066e-03,  1.0746e-02,  2.5508e-03,  1.1056e-03, -1.4409e-02,\n",
       "                       5.7554e-03,  1.4332e-02, -2.3352e-05,  1.4963e-03, -1.2396e-02,\n",
       "                       1.3699e-02,  1.3938e-02,  1.8219e-03,  1.0190e-03,  9.8542e-03,\n",
       "                      -9.5031e-04,  7.4841e-03,  1.3461e-02,  1.1462e-02,  9.5348e-03,\n",
       "                      -3.4521e-04,  1.0565e-03,  7.6090e-03,  1.2472e-02,  6.2729e-03,\n",
       "                      -2.0479e-03, -3.3668e-03, -1.0103e-03,  9.5984e-03, -7.3289e-03,\n",
       "                      -5.4630e-03,  4.4780e-03,  1.0373e-03,  1.2046e-02,  1.0613e-02,\n",
       "                       1.7689e-03,  1.2276e-02,  5.7251e-03,  1.5362e-02,  1.8950e-02,\n",
       "                       1.6699e-02,  2.9974e-04,  1.0392e-02,  4.4700e-04, -1.4558e-02,\n",
       "                      -5.9215e-04,  1.6275e-03, -1.7849e-03,  1.7888e-02,  6.5666e-03,\n",
       "                       3.5940e-03, -7.0571e-03,  1.2028e-02,  8.0600e-03,  1.5393e-02,\n",
       "                       5.2645e-03,  9.0200e-03,  1.3390e-02,  8.2356e-03, -1.3984e-02,\n",
       "                      -5.1562e-03, -3.5023e-03,  2.1900e-02,  5.7860e-03,  4.3705e-03,\n",
       "                      -1.6601e-03,  1.1240e-02, -8.0598e-03, -9.8081e-03,  1.9230e-02,\n",
       "                       3.0851e-03,  1.0214e-02,  1.9930e-02, -3.7627e-03,  2.7477e-03,\n",
       "                       5.6262e-03, -3.0982e-03,  1.4564e-02, -1.3703e-02,  1.1121e-02,\n",
       "                       8.4436e-03, -4.9463e-03,  1.4878e-02,  8.7587e-03, -8.2572e-03,\n",
       "                       3.3886e-03,  8.7394e-03,  2.0713e-02,  1.7387e-02,  5.7210e-03,\n",
       "                      -7.1348e-03,  1.4240e-02, -1.4810e-03,  2.3217e-03,  6.9327e-03,\n",
       "                       1.6514e-03,  1.3766e-02,  1.5536e-02,  6.6130e-03,  6.5846e-03,\n",
       "                       9.7555e-03,  1.0358e-03, -3.1396e-04,  8.0360e-03, -8.6887e-04,\n",
       "                      -8.7640e-03, -4.5100e-03,  7.0237e-03,  2.5777e-02, -7.0481e-03,\n",
       "                       6.4169e-03, -6.4992e-04,  2.9110e-03, -1.9480e-02,  1.8421e-03,\n",
       "                       1.8544e-02,  2.1945e-03,  1.0925e-02,  1.0034e-02,  1.1152e-02,\n",
       "                       3.1598e-03,  6.4625e-03, -1.0455e-03,  3.6897e-03,  6.7947e-03,\n",
       "                       8.3055e-03,  3.0324e-03,  2.5599e-03,  8.1136e-03,  5.6226e-03,\n",
       "                       1.3669e-02,  6.1828e-03,  9.1897e-03,  2.3778e-03, -6.4222e-03,\n",
       "                       1.5377e-02,  7.6411e-03,  1.5317e-02,  2.3442e-02,  1.7283e-02,\n",
       "                       1.1949e-03], dtype=torch.float64)),\n",
       "             ('6.0.convs.2.1.running_mean',\n",
       "              tensor([ 3.6377e-01,  1.7554e-02, -2.6962e-01, -4.1481e-01, -1.6189e-01,\n",
       "                       5.0392e-01,  1.7596e-01, -7.0541e-01,  7.0634e-01,  4.5587e-01,\n",
       "                       5.4911e-01,  1.8238e-01,  3.1880e-01,  5.5257e-01,  7.2893e-01,\n",
       "                       6.6627e-01, -4.4744e-02, -2.5096e-01, -4.2137e-01,  1.9596e-01,\n",
       "                      -1.1878e-03,  3.9145e-01,  7.4479e-01, -2.1830e-01, -3.9026e-01,\n",
       "                      -1.2492e-01,  4.7468e-01,  9.5392e-02,  1.8119e-01, -3.9681e-01,\n",
       "                      -2.7664e-01,  1.2552e+00, -2.8184e-01, -5.0011e-01, -3.7969e-01,\n",
       "                       5.1232e-01,  2.9533e-01, -3.7860e-01, -5.1598e-01, -1.8300e-01,\n",
       "                       4.3152e-03,  1.4463e-01, -4.2384e-01, -3.6366e-02,  1.5020e-01,\n",
       "                      -4.9829e-01, -4.0840e-01, -2.5977e-01, -5.3684e-01,  6.8666e-01,\n",
       "                       1.9049e-01, -8.3944e-01, -4.2900e-01,  1.4235e-01, -4.6562e-01,\n",
       "                       3.2655e-01, -5.0138e-01,  5.2629e-01, -3.9421e-01,  3.3558e-02,\n",
       "                       7.4408e-02,  3.9566e-01, -4.2918e-02, -2.3454e-01,  1.0313e-01,\n",
       "                       4.8544e-02, -3.6417e-01,  3.7146e-01, -6.2069e-01, -2.9958e-01,\n",
       "                      -3.2694e-01,  2.6089e-01,  4.2522e-02, -5.6105e-02, -2.9843e-01,\n",
       "                       5.4353e-01,  1.1431e-01, -3.2288e-01, -5.9292e-02,  1.4410e-01,\n",
       "                       1.4594e-01,  3.7571e-01,  6.5166e-01, -1.1116e-01,  1.0201e-01,\n",
       "                      -1.6946e-01, -3.1272e-01,  9.3765e-01,  2.0867e-01, -2.5698e-01,\n",
       "                       6.0670e-03,  1.0732e-01,  3.0473e-01, -8.4131e-02,  1.2448e-02,\n",
       "                       4.8148e-03,  5.3295e-01,  1.3120e-01,  2.2328e-01,  2.4700e-01,\n",
       "                      -4.6290e-01,  1.7772e-01,  8.1894e-02, -1.4177e-01, -1.0934e-01,\n",
       "                      -4.4043e-02, -3.7988e-01,  6.7852e-01,  6.6260e-01,  4.4203e-01,\n",
       "                       3.3434e-01, -2.4067e-01,  2.0392e-01, -2.2849e-01,  1.5232e-01,\n",
       "                       2.9728e-01, -8.0962e-02, -2.6122e-01, -2.2531e-02, -4.3568e-01,\n",
       "                       4.5757e-02,  3.6668e-01,  7.1696e-01,  3.3430e-01,  1.0712e-01,\n",
       "                      -3.4559e-01,  2.0120e-01,  1.9433e-02, -2.9892e-01, -1.7277e-01,\n",
       "                       1.1715e-01,  7.1933e-01, -1.6211e-01,  2.4701e-01,  7.9156e-02,\n",
       "                      -2.2194e-01,  2.5696e-02, -2.0928e-01, -2.3847e-01,  9.2383e-01,\n",
       "                      -1.7176e-01,  1.0379e-01,  6.6398e-01,  2.1299e-01,  1.8118e-01,\n",
       "                       2.3779e-01,  2.5162e-01,  2.6358e-01, -2.9817e-01,  7.9486e-02,\n",
       "                       3.7910e-01, -3.0363e-01, -8.4003e-02,  1.4260e-01, -1.8461e-01,\n",
       "                      -5.7784e-02, -3.6613e-01,  5.5125e-02, -2.4391e-02, -8.7965e-03,\n",
       "                       2.8361e-01, -2.9177e-01, -5.0725e-01,  1.2631e-01, -9.1693e-01,\n",
       "                      -2.3704e-01,  8.8452e-02,  6.6346e-02, -2.1333e-01, -1.7179e-01,\n",
       "                      -3.4002e-01,  2.6617e-01,  2.9861e-01, -1.9910e-01,  7.3577e-01,\n",
       "                      -6.6514e-01, -6.6696e-01, -1.2186e-01, -2.1923e-02,  2.9851e-01,\n",
       "                       5.2749e-01, -5.0299e-01,  2.8115e-01,  1.4221e-01, -9.6480e-02,\n",
       "                       1.3441e-02,  7.7165e-01, -3.9838e-01,  3.2533e-01,  6.7849e-01,\n",
       "                       3.1344e-01, -3.0429e-01,  3.4668e-01,  4.9948e-01, -4.2529e-03,\n",
       "                       1.2933e-01, -3.9582e-01, -4.5942e-02,  1.0172e-01,  2.3336e-01,\n",
       "                       3.4618e-01, -1.2381e-01, -1.1693e-01,  4.2156e-01, -3.8208e-01,\n",
       "                      -1.0009e-01, -1.5718e-01,  3.1867e-01, -1.1720e-01, -5.1834e-01,\n",
       "                      -7.3052e-01, -6.5495e-01,  1.2811e-02, -4.4319e-01,  3.0355e-02,\n",
       "                      -6.1308e-02, -1.8974e-01,  2.6507e-01,  1.2711e-01, -9.4675e-01,\n",
       "                       2.1744e-01,  4.1437e-01, -5.0084e-02, -2.2246e-02, -2.5358e-01,\n",
       "                       2.5616e-01, -1.9389e-02, -8.3695e-02,  3.4118e-01,  2.7205e-01,\n",
       "                       2.1946e-01, -1.6800e-01,  1.9707e-01,  4.7704e-01, -3.9518e-01,\n",
       "                       7.3016e-02, -8.7250e-02, -1.8092e-01, -1.2146e-01, -2.7383e-01,\n",
       "                       6.4702e-01,  2.3325e-01,  3.9800e-01, -1.2917e-01,  3.7474e-01,\n",
       "                       1.1956e-02, -6.1496e-02, -3.5286e-01,  8.4307e-01,  4.7302e-02,\n",
       "                       5.9140e-01, -4.7060e-01, -3.4064e-01,  3.2771e-01, -2.3994e-01,\n",
       "                       4.8034e-03], dtype=torch.float64)),\n",
       "             ('6.0.convs.2.1.running_var',\n",
       "              tensor([0.4599, 0.5193, 0.1771, 0.3985, 0.3347, 0.4226, 0.0982, 0.5156, 0.2875,\n",
       "                      0.3232, 0.3282, 0.1703, 0.2470, 0.2960, 0.5448, 0.2597, 0.2660, 0.3900,\n",
       "                      0.2569, 0.5238, 0.0803, 0.4508, 0.3527, 0.3910, 0.4835, 0.2329, 0.2399,\n",
       "                      0.3063, 0.2538, 0.3270, 0.3776, 0.7894, 0.0958, 0.3482, 0.3627, 0.3982,\n",
       "                      0.3632, 0.1164, 0.2070, 0.7324, 0.2148, 0.4183, 0.2143, 0.4552, 0.3814,\n",
       "                      0.2413, 0.3669, 0.1750, 0.2792, 0.2939, 0.3400, 0.2722, 0.3291, 0.2542,\n",
       "                      0.4558, 0.2856, 0.3468, 0.3955, 0.3432, 0.4203, 0.2492, 0.2213, 0.1166,\n",
       "                      0.0701, 0.4794, 0.3995, 0.2191, 0.2253, 0.4958, 0.2858, 0.3817, 0.3120,\n",
       "                      0.2565, 0.6139, 0.4735, 0.2196, 0.4406, 0.2112, 0.5700, 0.1907, 0.2953,\n",
       "                      0.2449, 0.3661, 0.4390, 0.3839, 0.5576, 0.3281, 0.4393, 0.5962, 0.3219,\n",
       "                      0.4640, 0.0764, 0.4195, 0.4952, 0.2798, 0.2425, 0.3840, 0.0467, 0.1646,\n",
       "                      0.1640, 0.2956, 0.1325, 0.1562, 0.1925, 0.3624, 0.3517, 0.3260, 0.4081,\n",
       "                      0.5305, 0.1350, 0.3864, 0.4156, 0.3144, 0.2105, 0.2436, 0.5096, 0.1165,\n",
       "                      0.1932, 0.1159, 0.4411, 0.2314, 0.5419, 0.6227, 0.2421, 0.3191, 0.4046,\n",
       "                      0.5738, 0.2892, 0.2561, 0.2780, 0.1976, 0.4282, 0.4484, 0.1573, 0.3482,\n",
       "                      0.3932, 0.3251, 0.1870, 0.5274, 0.4046, 0.4978, 0.0945, 0.5531, 0.1566,\n",
       "                      0.1519, 0.6283, 0.4106, 0.3108, 0.1662, 0.2684, 0.5077, 0.2172, 0.3048,\n",
       "                      0.2087, 0.3461, 0.3752, 0.2839, 0.1826, 0.3653, 0.0844, 0.4103, 0.3834,\n",
       "                      0.3789, 0.1545, 0.4832, 0.1594, 0.6762, 0.3914, 0.3739, 0.4262, 0.1582,\n",
       "                      0.0759, 0.1330, 0.2201, 0.6565, 0.4295, 0.4065, 0.3363, 0.4797, 0.2097,\n",
       "                      0.4579, 0.2470, 0.3006, 0.2201, 0.4440, 0.3853, 0.3628, 0.4775, 0.2904,\n",
       "                      0.1953, 0.5650, 0.7159, 0.2510, 0.4040, 0.3468, 0.4739, 0.2371, 0.1211,\n",
       "                      0.4130, 0.1939, 0.1427, 0.2667, 0.1371, 0.2859, 0.2738, 0.3903, 0.1401,\n",
       "                      0.1394, 0.1515, 0.5333, 0.3042, 0.2755, 0.2541, 0.3534, 0.0609, 0.3358,\n",
       "                      0.4918, 0.2806, 0.3696, 0.3182, 0.0893, 0.3698, 0.1025, 0.2177, 0.4522,\n",
       "                      0.2811, 0.1441, 0.2088, 0.3258, 0.3670, 0.1267, 0.2864, 0.4355, 0.2716,\n",
       "                      0.2503, 0.3426, 0.0957, 0.1857, 0.5993, 0.2882, 0.2578, 0.1556, 0.2994,\n",
       "                      0.2280, 0.3436, 0.1469, 0.3648, 0.3834, 0.6300, 0.4562, 0.3652, 0.5238,\n",
       "                      0.3307, 0.3367, 0.3825, 0.2320], dtype=torch.float64)),\n",
       "             ('6.0.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.0.convpath.0.0.0.weight',\n",
       "              tensor([[[-2.6970e-02],\n",
       "                       [-3.6803e-03],\n",
       "                       [-9.6383e-02],\n",
       "                       ...,\n",
       "                       [-2.8363e-02],\n",
       "                       [-1.4273e-01],\n",
       "                       [ 1.4194e-01]],\n",
       "              \n",
       "                      [[ 1.0622e-01],\n",
       "                       [-3.8758e-02],\n",
       "                       [ 3.5894e-05],\n",
       "                       ...,\n",
       "                       [-4.5822e-02],\n",
       "                       [-5.4668e-03],\n",
       "                       [ 7.9421e-03]],\n",
       "              \n",
       "                      [[-1.6322e-01],\n",
       "                       [-6.7668e-02],\n",
       "                       [-5.5133e-02],\n",
       "                       ...,\n",
       "                       [ 1.6949e-01],\n",
       "                       [-5.0897e-02],\n",
       "                       [-1.2894e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 5.1697e-02],\n",
       "                       [-4.2094e-02],\n",
       "                       [-5.0710e-02],\n",
       "                       ...,\n",
       "                       [-2.0678e-01],\n",
       "                       [-7.9579e-03],\n",
       "                       [ 2.0308e-02]],\n",
       "              \n",
       "                      [[-7.3728e-02],\n",
       "                       [ 8.0049e-02],\n",
       "                       [-8.1751e-02],\n",
       "                       ...,\n",
       "                       [-5.0059e-02],\n",
       "                       [ 5.4614e-02],\n",
       "                       [-1.5907e-01]],\n",
       "              \n",
       "                      [[-7.7045e-02],\n",
       "                       [-1.1295e-01],\n",
       "                       [-8.1520e-02],\n",
       "                       ...,\n",
       "                       [-1.8396e-01],\n",
       "                       [ 3.8302e-02],\n",
       "                       [-6.1302e-02]]], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.0.1.weight',\n",
       "              tensor([0.9733, 0.9626, 0.9769, 0.9667, 0.9645, 0.9621, 0.9552, 0.9773, 0.9869,\n",
       "                      0.9764, 0.9850, 0.9834, 0.9512, 0.9561, 0.9595, 0.9639, 0.9866, 0.9504,\n",
       "                      0.9536, 0.9499, 0.9648, 0.9685, 0.9470, 0.9857, 0.9731, 0.9530, 0.9857,\n",
       "                      0.9613, 0.9664, 0.9704, 0.9583, 0.9523, 0.9583, 0.9381, 0.9631, 0.9477,\n",
       "                      0.9694, 0.9740, 0.9530, 0.9843, 0.9656, 0.9630, 0.9602, 0.9750, 0.9555,\n",
       "                      0.9664, 0.9937, 0.9696, 0.9714, 0.9809, 0.9755, 0.9606, 0.9642, 0.9594,\n",
       "                      0.9875, 0.9568, 0.9527, 0.9711, 0.9613, 0.9579, 0.9654, 0.9781, 0.9494,\n",
       "                      0.9917], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0182,  0.0044,  0.0155,  0.0101, -0.0147,  0.0076,  0.0094,  0.0137,\n",
       "                       0.0094, -0.0042,  0.0171,  0.0154, -0.0050, -0.0074, -0.0044,  0.0118,\n",
       "                       0.0128,  0.0066, -0.0114, -0.0086, -0.0003,  0.0185,  0.0020, -0.0117,\n",
       "                       0.0092,  0.0183,  0.0128,  0.0075,  0.0061, -0.0046, -0.0017, -0.0059,\n",
       "                      -0.0078, -0.0038,  0.0109,  0.0027, -0.0155,  0.0233, -0.0079,  0.0159,\n",
       "                       0.0030, -0.0032, -0.0107,  0.0217, -0.0026, -0.0086,  0.0032,  0.0018,\n",
       "                       0.0169, -0.0049,  0.0017,  0.0022,  0.0052, -0.0124,  0.0073, -0.0054,\n",
       "                      -0.0144, -0.0094,  0.0048, -0.0039, -0.0202,  0.0241, -0.0054,  0.0164],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.1898,  0.5286,  0.0335, -0.3213, -0.0168, -0.5279,  0.1501, -0.5237,\n",
       "                      -0.3966, -0.1989, -0.2629, -0.5886, -0.1360, -0.0880, -0.0809, -0.5115,\n",
       "                       0.3257, -0.5946,  0.4340,  0.1103, -0.3697, -1.0466, -0.5314,  0.9367,\n",
       "                      -0.1604, -0.5161, -0.5635, -0.1232,  0.2103,  0.4975, -0.0730, -0.8035,\n",
       "                       0.0293, -0.4794, -0.3607, -0.3912, -0.3421, -0.1106,  0.0427,  0.5211,\n",
       "                       0.3341, -0.2243, -0.1664,  0.5373, -0.6242,  0.2612, -0.0353, -0.0982,\n",
       "                      -0.6819,  0.1599, -0.7689,  0.3543,  0.6521, -0.1273, -0.2356,  0.3384,\n",
       "                       0.5187, -1.2648,  0.2145,  0.6314,  0.3822, -0.0959, -0.0830, -0.2557],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.0.1.running_var',\n",
       "              tensor([0.2949, 1.3506, 0.2095, 0.3228, 0.5939, 0.3086, 0.4491, 0.2959, 0.2250,\n",
       "                      0.2610, 0.2137, 0.3347, 0.4316, 0.3474, 0.2600, 0.4867, 0.1647, 0.4199,\n",
       "                      0.3177, 0.3693, 0.3048, 0.3139, 1.1285, 0.2792, 0.3162, 1.4534, 0.2276,\n",
       "                      0.3284, 0.5564, 0.6521, 0.2618, 0.6349, 1.4750, 1.1205, 0.4926, 0.3085,\n",
       "                      0.2899, 0.2563, 0.6309, 0.6086, 0.2059, 0.5342, 0.2046, 0.1553, 1.0869,\n",
       "                      0.2841, 0.2513, 0.2682, 0.4857, 0.2348, 0.2554, 0.4058, 0.8443, 0.3353,\n",
       "                      0.2551, 0.6225, 0.5646, 0.4638, 0.4132, 0.6166, 0.3495, 0.5060, 0.3995,\n",
       "                      0.2474], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.0.convpath.0.1.0.weight',\n",
       "              tensor([[[ 1.4300e-02, -1.6613e-01,  5.0351e-02, -1.1099e-02,  8.5365e-02],\n",
       "                       [ 9.8312e-02, -5.9451e-02, -6.2093e-02,  7.6365e-02, -2.1359e-02],\n",
       "                       [ 5.0143e-02,  5.1288e-02, -2.1402e-02,  4.7861e-02,  1.2735e-01],\n",
       "                       ...,\n",
       "                       [ 6.7171e-03,  2.4499e-02, -1.1445e-01, -4.8095e-02,  2.6229e-03],\n",
       "                       [-8.1411e-02,  8.6263e-02, -5.1260e-03,  2.5771e-02,  7.8661e-02],\n",
       "                       [ 7.6977e-02, -7.4010e-02,  9.6184e-02, -1.4804e-01, -3.4727e-02]],\n",
       "              \n",
       "                      [[ 4.5393e-02, -6.0341e-02, -8.4389e-02,  8.6802e-02, -1.6013e-01],\n",
       "                       [-7.9932e-02, -7.5873e-02,  9.5843e-02, -7.6574e-02, -1.0187e-01],\n",
       "                       [-3.2304e-02,  5.7686e-02,  1.2541e-01, -1.9176e-02,  1.6634e-02],\n",
       "                       ...,\n",
       "                       [-3.3401e-02, -7.0081e-02, -3.1010e-02, -9.2812e-02,  1.9510e-02],\n",
       "                       [ 8.3299e-02, -4.3040e-05, -3.2365e-02, -3.8651e-02, -4.2099e-02],\n",
       "                       [-1.7246e-02, -2.4016e-02, -3.8546e-02, -9.4165e-03,  7.8797e-02]],\n",
       "              \n",
       "                      [[ 5.0659e-02,  2.5301e-02,  4.9000e-02,  5.0935e-02, -1.6699e-02],\n",
       "                       [ 4.4271e-02,  5.2339e-02, -2.9406e-02, -6.1004e-02, -1.2174e-02],\n",
       "                       [-1.2739e-01, -1.8848e-01, -1.0607e-01,  5.7483e-02,  8.0239e-02],\n",
       "                       ...,\n",
       "                       [ 1.0591e-01, -4.4503e-02, -6.2935e-03,  1.1126e-01, -3.5547e-02],\n",
       "                       [-3.0620e-02,  1.0402e-01,  3.6872e-02,  2.0736e-02,  1.7067e-01],\n",
       "                       [-4.7079e-02,  5.9846e-02, -6.3831e-02, -3.8970e-02,  2.5046e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 7.7700e-03,  1.1718e-01,  1.7228e-02, -1.5217e-02,  5.0478e-02],\n",
       "                       [-8.2533e-03, -6.7451e-02, -5.0580e-02, -3.5622e-02,  7.3493e-02],\n",
       "                       [ 6.5439e-02, -1.9100e-02, -1.4990e-02,  2.9701e-02, -1.0450e-01],\n",
       "                       ...,\n",
       "                       [-3.1419e-02, -6.2197e-02,  8.9559e-02,  1.3460e-01, -5.9444e-02],\n",
       "                       [ 8.3296e-02, -1.0445e-01, -1.3977e-02, -1.0446e-01, -1.7055e-02],\n",
       "                       [ 6.5726e-02,  9.9994e-02,  4.3117e-02, -4.6600e-02, -2.3974e-02]],\n",
       "              \n",
       "                      [[-1.0273e-01, -3.1845e-03, -5.8346e-02, -4.4879e-02,  1.1000e-01],\n",
       "                       [ 7.2528e-02, -9.8926e-02, -1.2251e-01, -7.4172e-02, -2.3046e-02],\n",
       "                       [-1.9921e-02, -2.2300e-02,  2.7006e-02, -8.2926e-02, -1.2887e-01],\n",
       "                       ...,\n",
       "                       [ 2.0463e-02, -5.8621e-02, -1.0312e-02,  6.3664e-02, -1.7162e-03],\n",
       "                       [-1.1698e-02, -2.3072e-02, -1.0209e-01, -1.2406e-01, -1.1682e-01],\n",
       "                       [-2.1273e-03,  3.7681e-02, -5.7927e-02, -5.5688e-02,  3.9049e-02]],\n",
       "              \n",
       "                      [[ 4.1006e-02, -6.9948e-02, -2.2717e-02, -6.7585e-02, -3.9872e-03],\n",
       "                       [-3.9864e-02,  2.0570e-02,  1.7803e-02,  6.2099e-03,  4.8159e-02],\n",
       "                       [-3.3721e-03,  9.4295e-02, -4.7379e-02, -6.8278e-02,  8.1723e-02],\n",
       "                       ...,\n",
       "                       [-9.0028e-02, -6.6673e-02,  9.1409e-02, -1.8492e-02,  1.9293e-02],\n",
       "                       [ 7.0934e-02,  4.6042e-02, -8.1902e-02, -1.1503e-01,  2.0710e-02],\n",
       "                       [-1.5933e-02,  3.1570e-02,  7.1365e-02, -2.3068e-01,  2.7605e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.1.1.weight',\n",
       "              tensor([0.9772, 0.9657, 0.9904, 0.9677, 0.9467, 0.9760, 0.9845, 0.9339, 0.9552,\n",
       "                      0.9730, 0.9871, 0.9569, 0.9616, 0.9632, 0.9808, 0.9587, 0.9529, 0.9390,\n",
       "                      0.9686, 0.9313, 0.9522, 0.9481, 0.9594, 0.9552, 0.9837, 0.9258, 0.9615,\n",
       "                      0.9435, 0.9587, 0.9819, 0.9615, 0.9618, 0.9489, 0.9698, 0.9545, 0.9801,\n",
       "                      0.9747, 0.9557, 0.9573, 0.9640, 0.9726, 0.9735, 0.9665, 0.9526, 0.9606,\n",
       "                      0.9738, 0.9691, 0.9582, 0.9767, 0.9587, 0.9691, 0.9865, 0.9445, 0.9475,\n",
       "                      0.9505, 0.9650, 0.9384, 0.9429, 0.9540, 0.9639, 0.9670, 0.9594, 0.9721,\n",
       "                      0.9555], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.1.1.bias',\n",
       "              tensor([-0.0031, -0.0078, -0.0057, -0.0053, -0.0112, -0.0063,  0.0148, -0.0183,\n",
       "                      -0.0160,  0.0005,  0.0039, -0.0100,  0.0104,  0.0115,  0.0040, -0.0104,\n",
       "                      -0.0144,  0.0034,  0.0005, -0.0205, -0.0027,  0.0125,  0.0045, -0.0064,\n",
       "                       0.0177, -0.0131,  0.0071, -0.0039, -0.0167,  0.0071, -0.0171, -0.0294,\n",
       "                      -0.0149,  0.0221, -0.0059, -0.0067,  0.0125, -0.0113,  0.0044,  0.0022,\n",
       "                      -0.0059, -0.0090,  0.0185, -0.0149, -0.0038,  0.0002, -0.0040, -0.0058,\n",
       "                      -0.0019, -0.0136,  0.0111, -0.0298, -0.0237, -0.0047,  0.0010,  0.0101,\n",
       "                      -0.0135, -0.0108, -0.0042,  0.0065, -0.0105, -0.0132, -0.0063,  0.0028],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.4012, -0.4091,  0.0604, -0.4854, -0.2893, -0.1028, -0.0115,  0.3455,\n",
       "                      -0.0449,  0.4850,  0.4138, -0.5967,  0.3608, -0.8848, -0.5577,  0.3049,\n",
       "                       0.1373, -0.1257, -0.4323, -0.3823,  0.4486, -0.7119,  0.0787,  0.1405,\n",
       "                       0.5263, -0.9175, -0.6052,  0.6887, -1.0031,  0.0758,  0.3468,  0.2492,\n",
       "                       0.0186,  0.0636, -0.5071,  0.6360,  0.8923, -0.8908,  0.4495,  0.2354,\n",
       "                       0.0971,  0.2575,  0.8363, -0.0414, -0.3072, -0.0315, -0.4707,  0.4006,\n",
       "                       0.7368,  0.1495,  0.1364,  0.8887, -0.5170, -0.3615, -0.3102, -0.4515,\n",
       "                      -0.9232, -0.9359,  0.2585, -0.4430, -0.0661, -0.2814, -0.2297, -0.1975],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.1.1.running_var',\n",
       "              tensor([0.4697, 0.3462, 0.6115, 0.6543, 0.3535, 0.8766, 0.4727, 0.5686, 0.3484,\n",
       "                      0.3092, 0.3595, 0.7819, 0.5885, 0.4289, 0.3098, 0.7597, 0.7137, 0.4922,\n",
       "                      0.5136, 0.5295, 0.6163, 0.5648, 0.4553, 0.3683, 0.4510, 0.5584, 0.2478,\n",
       "                      0.6515, 0.8206, 0.4619, 0.5173, 0.3721, 0.5299, 0.4317, 0.5280, 0.5363,\n",
       "                      0.5326, 0.4945, 0.4166, 0.4753, 0.4615, 0.4844, 0.4739, 0.5528, 0.5394,\n",
       "                      0.3477, 0.4482, 0.7215, 0.3526, 0.5556, 0.4774, 0.4855, 0.4149, 0.5104,\n",
       "                      0.4351, 0.5948, 0.3415, 0.4312, 0.6211, 0.6765, 0.4514, 0.6177, 0.6639,\n",
       "                      0.5058], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.0.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.2423],\n",
       "                       [ 0.0678],\n",
       "                       [-0.1224],\n",
       "                       ...,\n",
       "                       [-0.0126],\n",
       "                       [ 0.0016],\n",
       "                       [ 0.0017]],\n",
       "              \n",
       "                      [[-0.2289],\n",
       "                       [-0.2979],\n",
       "                       [ 0.2175],\n",
       "                       ...,\n",
       "                       [ 0.1080],\n",
       "                       [ 0.1306],\n",
       "                       [-0.1502]],\n",
       "              \n",
       "                      [[ 0.0911],\n",
       "                       [ 0.0726],\n",
       "                       [-0.1599],\n",
       "                       ...,\n",
       "                       [-0.0212],\n",
       "                       [-0.0425],\n",
       "                       [-0.0222]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0237],\n",
       "                       [-0.0678],\n",
       "                       [-0.0063],\n",
       "                       ...,\n",
       "                       [-0.0885],\n",
       "                       [-0.0355],\n",
       "                       [ 0.0205]],\n",
       "              \n",
       "                      [[-0.0423],\n",
       "                       [-0.0107],\n",
       "                       [ 0.1330],\n",
       "                       ...,\n",
       "                       [ 0.0471],\n",
       "                       [ 0.0839],\n",
       "                       [ 0.0514]],\n",
       "              \n",
       "                      [[ 0.0804],\n",
       "                       [-0.0290],\n",
       "                       [ 0.0372],\n",
       "                       ...,\n",
       "                       [ 0.1110],\n",
       "                       [-0.1031],\n",
       "                       [-0.1347]]], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.2.1.weight',\n",
       "              tensor([ 1.2589e-02,  2.2134e-02,  1.4982e-03, -1.0002e-02,  6.8350e-03,\n",
       "                       2.7259e-02, -5.5047e-03,  2.3923e-02,  3.1186e-03,  8.5064e-03,\n",
       "                       4.6943e-03,  4.6265e-03,  1.0152e-02, -3.9186e-03,  9.8827e-03,\n",
       "                      -1.4132e-02,  9.0858e-03,  2.4119e-02,  1.4784e-02, -1.1469e-02,\n",
       "                      -3.4464e-04, -3.3942e-02, -1.4982e-02, -1.0714e-02,  3.3634e-02,\n",
       "                       2.5132e-02,  5.9036e-03, -1.7812e-03,  1.6919e-03, -1.0305e-02,\n",
       "                      -2.4515e-02, -2.3907e-02, -3.6213e-04,  8.4237e-03,  1.2070e-02,\n",
       "                      -1.4688e-02, -7.5030e-03,  1.1786e-04,  1.5954e-02,  5.4133e-03,\n",
       "                       6.0047e-03, -1.1529e-02,  1.0736e-02,  1.5569e-02, -8.1443e-03,\n",
       "                      -7.4892e-04, -1.5531e-02, -5.7282e-03,  3.9492e-03,  2.4710e-03,\n",
       "                      -2.0063e-02, -6.8316e-03, -2.2209e-04, -2.2354e-02, -1.4528e-02,\n",
       "                      -8.2951e-03,  1.7758e-02, -4.2690e-02, -6.2631e-03,  1.1134e-02,\n",
       "                       8.9511e-03,  1.2944e-02,  8.3517e-03, -2.1371e-03,  1.9489e-02,\n",
       "                       2.2800e-02, -1.3371e-02, -1.2709e-02,  2.6410e-02, -6.7265e-03,\n",
       "                      -1.2115e-02, -8.9795e-03, -1.9000e-02,  1.3643e-02, -9.7831e-03,\n",
       "                       1.9139e-02,  2.4012e-02,  1.2607e-02, -1.0823e-02, -2.0259e-02,\n",
       "                      -5.5155e-03,  1.7089e-02, -4.3870e-02,  3.0878e-02, -3.4828e-02,\n",
       "                      -1.5229e-02,  3.0851e-02, -4.7761e-04, -1.1347e-02, -1.7289e-02,\n",
       "                      -4.4876e-02, -6.5281e-04,  1.4520e-02, -5.4784e-03, -3.5537e-03,\n",
       "                       3.5752e-03, -3.5605e-02,  1.0840e-03, -1.0007e-03,  2.8729e-02,\n",
       "                       4.6823e-03,  8.1020e-03, -2.9972e-03,  1.0286e-02,  2.3756e-02,\n",
       "                      -1.4443e-02, -1.1917e-02,  1.3830e-02, -2.6427e-02, -7.4733e-03,\n",
       "                      -6.5341e-03,  1.2077e-03,  3.8398e-03,  1.7993e-03,  2.8002e-02,\n",
       "                      -1.2012e-02,  6.8674e-03,  4.1180e-03, -4.9496e-04, -1.0257e-02,\n",
       "                       1.6305e-02,  2.9369e-02, -9.3340e-03, -5.2921e-03,  1.5934e-02,\n",
       "                       1.8353e-02,  3.3962e-03, -1.7315e-02, -2.1504e-03,  3.9781e-04,\n",
       "                      -3.2770e-03, -1.8545e-02, -5.0681e-03, -2.8501e-03,  1.6818e-02,\n",
       "                      -1.2274e-02,  4.5861e-02, -7.9423e-03,  2.3305e-02,  5.1455e-04,\n",
       "                       1.6888e-02,  1.4197e-03,  1.3604e-02,  9.6374e-06,  3.4015e-03,\n",
       "                      -2.8965e-02,  7.6350e-03,  3.1075e-03,  5.1877e-03, -6.5824e-05,\n",
       "                      -1.2750e-02,  6.0342e-03,  2.4308e-02, -8.0952e-03, -8.7356e-03,\n",
       "                      -1.3684e-02, -8.3638e-03,  2.8634e-03, -1.5896e-02, -8.8031e-04,\n",
       "                       7.4047e-03,  1.2607e-02,  8.0281e-03,  1.4698e-03,  4.7841e-02,\n",
       "                       9.1095e-03,  9.1333e-03,  2.7199e-02, -2.4835e-02, -2.3206e-02,\n",
       "                       1.2201e-03, -8.6248e-04, -6.3817e-03,  8.6714e-03,  2.6644e-03,\n",
       "                      -8.8644e-03,  8.3611e-03, -1.3300e-02, -1.9668e-02, -2.8264e-02,\n",
       "                       3.8536e-02,  1.5099e-02, -7.0421e-03, -3.5954e-03, -8.5808e-03,\n",
       "                       1.4133e-02,  9.7383e-03,  2.9362e-02,  1.6455e-02, -2.0519e-03,\n",
       "                       1.9844e-02,  1.4509e-02, -4.7951e-03, -3.7688e-02,  1.7180e-02,\n",
       "                      -1.8202e-02, -2.2994e-03, -9.3939e-04, -1.7049e-02,  9.0388e-03,\n",
       "                      -1.1602e-02,  2.0356e-02,  7.4361e-04, -1.5174e-02,  4.6653e-03,\n",
       "                       1.4713e-02,  4.4670e-03,  7.0714e-03,  1.1514e-03,  1.8712e-02,\n",
       "                       1.5238e-02, -6.4437e-03, -8.1187e-03, -1.1528e-03,  5.1901e-04,\n",
       "                      -3.4911e-03, -8.2275e-03,  1.0125e-02,  3.6172e-02,  1.1648e-02,\n",
       "                      -1.4007e-03, -1.9274e-02,  2.6684e-03,  9.2241e-03,  1.9817e-02,\n",
       "                       1.3887e-02,  3.9888e-03,  1.5255e-03, -6.2476e-03,  6.0278e-03,\n",
       "                       2.5531e-02, -1.1539e-02, -1.4804e-02,  1.4940e-02, -1.3097e-02,\n",
       "                       1.2203e-02, -1.5113e-03, -1.0267e-02,  2.2433e-02, -5.5860e-03,\n",
       "                       5.8517e-03,  4.7929e-03,  3.0242e-02,  1.7900e-02,  1.5140e-02,\n",
       "                      -5.5452e-03, -2.2973e-02, -1.9603e-02,  1.2895e-02, -3.6269e-02,\n",
       "                      -5.9550e-03,  9.1785e-03,  1.6192e-02, -4.8521e-03,  3.8073e-02,\n",
       "                       1.1540e-02], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.2.1.bias',\n",
       "              tensor([-2.6710e-03, -4.4757e-03,  1.9047e-02,  7.9802e-03,  4.5639e-03,\n",
       "                       6.3193e-03,  2.1594e-02,  3.1125e-04,  1.1535e-02,  2.0684e-02,\n",
       "                       1.0022e-02, -7.4316e-03,  1.3917e-02, -8.1055e-03,  6.9060e-03,\n",
       "                       9.1917e-03,  1.7281e-02,  1.3197e-03,  1.6949e-02, -7.9680e-03,\n",
       "                      -2.1120e-03,  4.7207e-03,  2.7994e-03,  6.7468e-03, -2.9368e-03,\n",
       "                      -1.3028e-02,  6.3551e-03,  1.0486e-02,  3.2672e-03,  6.2418e-04,\n",
       "                      -9.8721e-03,  8.7850e-03, -8.5806e-03,  1.5453e-02,  1.8509e-02,\n",
       "                      -4.5585e-03,  5.0924e-03,  2.6859e-02,  1.3148e-02,  1.4147e-02,\n",
       "                       9.4985e-04, -1.4161e-02, -6.3559e-03,  2.4406e-03,  1.2313e-02,\n",
       "                      -1.1858e-02,  1.4381e-02,  6.8018e-03, -1.1003e-02, -1.6633e-03,\n",
       "                       3.7283e-03,  2.5442e-03,  8.2851e-03,  2.1109e-02, -1.8510e-03,\n",
       "                      -2.5443e-03,  8.0939e-03,  7.5784e-03,  7.7029e-03,  8.8865e-03,\n",
       "                      -6.5805e-03,  2.9684e-03,  4.4420e-03,  1.0176e-02, -3.2072e-03,\n",
       "                       1.5495e-02, -1.1231e-02,  1.4449e-02, -2.0563e-03, -9.1886e-03,\n",
       "                       3.8787e-03,  1.0248e-02,  1.3782e-02, -7.9940e-03,  1.4503e-02,\n",
       "                       1.4225e-02,  2.1259e-03, -7.5022e-03,  3.2457e-03,  7.0246e-03,\n",
       "                       1.1919e-02, -5.5552e-03,  7.4540e-03,  5.7170e-03, -1.4955e-03,\n",
       "                       4.2297e-03,  6.4495e-03,  3.8244e-03,  9.0017e-03,  6.0969e-03,\n",
       "                      -1.6878e-03,  2.0648e-02,  1.8853e-02, -7.4074e-04,  5.3471e-03,\n",
       "                      -1.6457e-02,  5.8088e-03,  6.4733e-03,  1.1973e-02, -2.4289e-03,\n",
       "                       2.6342e-02,  7.8291e-03, -1.6686e-03, -2.0576e-02,  1.4190e-02,\n",
       "                       1.0357e-03,  6.9472e-03, -2.2884e-03,  3.9864e-03,  6.8144e-03,\n",
       "                      -7.6664e-03, -6.1410e-03,  6.2409e-03,  1.5377e-02,  6.4755e-03,\n",
       "                       8.0066e-03,  1.0746e-02,  2.5508e-03,  1.1056e-03, -1.4409e-02,\n",
       "                       5.7554e-03,  1.4332e-02, -2.3352e-05,  1.4963e-03, -1.2396e-02,\n",
       "                       1.3699e-02,  1.3938e-02,  1.8219e-03,  1.0190e-03,  9.8542e-03,\n",
       "                      -9.5031e-04,  7.4841e-03,  1.3461e-02,  1.1462e-02,  9.5348e-03,\n",
       "                      -3.4521e-04,  1.0565e-03,  7.6090e-03,  1.2472e-02,  6.2729e-03,\n",
       "                      -2.0479e-03, -3.3668e-03, -1.0103e-03,  9.5984e-03, -7.3289e-03,\n",
       "                      -5.4630e-03,  4.4780e-03,  1.0373e-03,  1.2046e-02,  1.0613e-02,\n",
       "                       1.7689e-03,  1.2276e-02,  5.7251e-03,  1.5362e-02,  1.8950e-02,\n",
       "                       1.6699e-02,  2.9974e-04,  1.0392e-02,  4.4700e-04, -1.4558e-02,\n",
       "                      -5.9215e-04,  1.6275e-03, -1.7849e-03,  1.7888e-02,  6.5666e-03,\n",
       "                       3.5940e-03, -7.0571e-03,  1.2028e-02,  8.0600e-03,  1.5393e-02,\n",
       "                       5.2645e-03,  9.0200e-03,  1.3390e-02,  8.2356e-03, -1.3984e-02,\n",
       "                      -5.1562e-03, -3.5023e-03,  2.1900e-02,  5.7860e-03,  4.3705e-03,\n",
       "                      -1.6601e-03,  1.1240e-02, -8.0598e-03, -9.8081e-03,  1.9230e-02,\n",
       "                       3.0851e-03,  1.0214e-02,  1.9930e-02, -3.7627e-03,  2.7477e-03,\n",
       "                       5.6262e-03, -3.0982e-03,  1.4564e-02, -1.3703e-02,  1.1121e-02,\n",
       "                       8.4436e-03, -4.9463e-03,  1.4878e-02,  8.7587e-03, -8.2572e-03,\n",
       "                       3.3886e-03,  8.7394e-03,  2.0713e-02,  1.7387e-02,  5.7210e-03,\n",
       "                      -7.1348e-03,  1.4240e-02, -1.4810e-03,  2.3217e-03,  6.9327e-03,\n",
       "                       1.6514e-03,  1.3766e-02,  1.5536e-02,  6.6130e-03,  6.5846e-03,\n",
       "                       9.7555e-03,  1.0358e-03, -3.1396e-04,  8.0360e-03, -8.6887e-04,\n",
       "                      -8.7640e-03, -4.5100e-03,  7.0237e-03,  2.5777e-02, -7.0481e-03,\n",
       "                       6.4169e-03, -6.4992e-04,  2.9110e-03, -1.9480e-02,  1.8421e-03,\n",
       "                       1.8544e-02,  2.1945e-03,  1.0925e-02,  1.0034e-02,  1.1152e-02,\n",
       "                       3.1598e-03,  6.4625e-03, -1.0455e-03,  3.6897e-03,  6.7947e-03,\n",
       "                       8.3055e-03,  3.0324e-03,  2.5599e-03,  8.1136e-03,  5.6226e-03,\n",
       "                       1.3669e-02,  6.1828e-03,  9.1897e-03,  2.3778e-03, -6.4222e-03,\n",
       "                       1.5377e-02,  7.6411e-03,  1.5317e-02,  2.3442e-02,  1.7283e-02,\n",
       "                       1.1949e-03], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.2.1.running_mean',\n",
       "              tensor([ 3.6377e-01,  1.7554e-02, -2.6962e-01, -4.1481e-01, -1.6189e-01,\n",
       "                       5.0392e-01,  1.7596e-01, -7.0541e-01,  7.0634e-01,  4.5587e-01,\n",
       "                       5.4911e-01,  1.8238e-01,  3.1880e-01,  5.5257e-01,  7.2893e-01,\n",
       "                       6.6627e-01, -4.4744e-02, -2.5096e-01, -4.2137e-01,  1.9596e-01,\n",
       "                      -1.1878e-03,  3.9145e-01,  7.4479e-01, -2.1830e-01, -3.9026e-01,\n",
       "                      -1.2492e-01,  4.7468e-01,  9.5392e-02,  1.8119e-01, -3.9681e-01,\n",
       "                      -2.7664e-01,  1.2552e+00, -2.8184e-01, -5.0011e-01, -3.7969e-01,\n",
       "                       5.1232e-01,  2.9533e-01, -3.7860e-01, -5.1598e-01, -1.8300e-01,\n",
       "                       4.3152e-03,  1.4463e-01, -4.2384e-01, -3.6366e-02,  1.5020e-01,\n",
       "                      -4.9829e-01, -4.0840e-01, -2.5977e-01, -5.3684e-01,  6.8666e-01,\n",
       "                       1.9049e-01, -8.3944e-01, -4.2900e-01,  1.4235e-01, -4.6562e-01,\n",
       "                       3.2655e-01, -5.0138e-01,  5.2629e-01, -3.9421e-01,  3.3558e-02,\n",
       "                       7.4408e-02,  3.9566e-01, -4.2918e-02, -2.3454e-01,  1.0313e-01,\n",
       "                       4.8544e-02, -3.6417e-01,  3.7146e-01, -6.2069e-01, -2.9958e-01,\n",
       "                      -3.2694e-01,  2.6089e-01,  4.2522e-02, -5.6105e-02, -2.9843e-01,\n",
       "                       5.4353e-01,  1.1431e-01, -3.2288e-01, -5.9292e-02,  1.4410e-01,\n",
       "                       1.4594e-01,  3.7571e-01,  6.5166e-01, -1.1116e-01,  1.0201e-01,\n",
       "                      -1.6946e-01, -3.1272e-01,  9.3765e-01,  2.0867e-01, -2.5698e-01,\n",
       "                       6.0670e-03,  1.0732e-01,  3.0473e-01, -8.4131e-02,  1.2448e-02,\n",
       "                       4.8148e-03,  5.3295e-01,  1.3120e-01,  2.2328e-01,  2.4700e-01,\n",
       "                      -4.6290e-01,  1.7772e-01,  8.1894e-02, -1.4177e-01, -1.0934e-01,\n",
       "                      -4.4043e-02, -3.7988e-01,  6.7852e-01,  6.6260e-01,  4.4203e-01,\n",
       "                       3.3434e-01, -2.4067e-01,  2.0392e-01, -2.2849e-01,  1.5232e-01,\n",
       "                       2.9728e-01, -8.0962e-02, -2.6122e-01, -2.2531e-02, -4.3568e-01,\n",
       "                       4.5757e-02,  3.6668e-01,  7.1696e-01,  3.3430e-01,  1.0712e-01,\n",
       "                      -3.4559e-01,  2.0120e-01,  1.9433e-02, -2.9892e-01, -1.7277e-01,\n",
       "                       1.1715e-01,  7.1933e-01, -1.6211e-01,  2.4701e-01,  7.9156e-02,\n",
       "                      -2.2194e-01,  2.5696e-02, -2.0928e-01, -2.3847e-01,  9.2383e-01,\n",
       "                      -1.7176e-01,  1.0379e-01,  6.6398e-01,  2.1299e-01,  1.8118e-01,\n",
       "                       2.3779e-01,  2.5162e-01,  2.6358e-01, -2.9817e-01,  7.9486e-02,\n",
       "                       3.7910e-01, -3.0363e-01, -8.4003e-02,  1.4260e-01, -1.8461e-01,\n",
       "                      -5.7784e-02, -3.6613e-01,  5.5125e-02, -2.4391e-02, -8.7965e-03,\n",
       "                       2.8361e-01, -2.9177e-01, -5.0725e-01,  1.2631e-01, -9.1693e-01,\n",
       "                      -2.3704e-01,  8.8452e-02,  6.6346e-02, -2.1333e-01, -1.7179e-01,\n",
       "                      -3.4002e-01,  2.6617e-01,  2.9861e-01, -1.9910e-01,  7.3577e-01,\n",
       "                      -6.6514e-01, -6.6696e-01, -1.2186e-01, -2.1923e-02,  2.9851e-01,\n",
       "                       5.2749e-01, -5.0299e-01,  2.8115e-01,  1.4221e-01, -9.6480e-02,\n",
       "                       1.3441e-02,  7.7165e-01, -3.9838e-01,  3.2533e-01,  6.7849e-01,\n",
       "                       3.1344e-01, -3.0429e-01,  3.4668e-01,  4.9948e-01, -4.2529e-03,\n",
       "                       1.2933e-01, -3.9582e-01, -4.5942e-02,  1.0172e-01,  2.3336e-01,\n",
       "                       3.4618e-01, -1.2381e-01, -1.1693e-01,  4.2156e-01, -3.8208e-01,\n",
       "                      -1.0009e-01, -1.5718e-01,  3.1867e-01, -1.1720e-01, -5.1834e-01,\n",
       "                      -7.3052e-01, -6.5495e-01,  1.2811e-02, -4.4319e-01,  3.0355e-02,\n",
       "                      -6.1308e-02, -1.8974e-01,  2.6507e-01,  1.2711e-01, -9.4675e-01,\n",
       "                       2.1744e-01,  4.1437e-01, -5.0084e-02, -2.2246e-02, -2.5358e-01,\n",
       "                       2.5616e-01, -1.9389e-02, -8.3695e-02,  3.4118e-01,  2.7205e-01,\n",
       "                       2.1946e-01, -1.6800e-01,  1.9707e-01,  4.7704e-01, -3.9518e-01,\n",
       "                       7.3016e-02, -8.7250e-02, -1.8092e-01, -1.2146e-01, -2.7383e-01,\n",
       "                       6.4702e-01,  2.3325e-01,  3.9800e-01, -1.2917e-01,  3.7474e-01,\n",
       "                       1.1956e-02, -6.1496e-02, -3.5286e-01,  8.4307e-01,  4.7302e-02,\n",
       "                       5.9140e-01, -4.7060e-01, -3.4064e-01,  3.2771e-01, -2.3994e-01,\n",
       "                       4.8034e-03], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.2.1.running_var',\n",
       "              tensor([0.4599, 0.5193, 0.1771, 0.3985, 0.3347, 0.4226, 0.0982, 0.5156, 0.2875,\n",
       "                      0.3232, 0.3282, 0.1703, 0.2470, 0.2960, 0.5448, 0.2597, 0.2660, 0.3900,\n",
       "                      0.2569, 0.5238, 0.0803, 0.4508, 0.3527, 0.3910, 0.4835, 0.2329, 0.2399,\n",
       "                      0.3063, 0.2538, 0.3270, 0.3776, 0.7894, 0.0958, 0.3482, 0.3627, 0.3982,\n",
       "                      0.3632, 0.1164, 0.2070, 0.7324, 0.2148, 0.4183, 0.2143, 0.4552, 0.3814,\n",
       "                      0.2413, 0.3669, 0.1750, 0.2792, 0.2939, 0.3400, 0.2722, 0.3291, 0.2542,\n",
       "                      0.4558, 0.2856, 0.3468, 0.3955, 0.3432, 0.4203, 0.2492, 0.2213, 0.1166,\n",
       "                      0.0701, 0.4794, 0.3995, 0.2191, 0.2253, 0.4958, 0.2858, 0.3817, 0.3120,\n",
       "                      0.2565, 0.6139, 0.4735, 0.2196, 0.4406, 0.2112, 0.5700, 0.1907, 0.2953,\n",
       "                      0.2449, 0.3661, 0.4390, 0.3839, 0.5576, 0.3281, 0.4393, 0.5962, 0.3219,\n",
       "                      0.4640, 0.0764, 0.4195, 0.4952, 0.2798, 0.2425, 0.3840, 0.0467, 0.1646,\n",
       "                      0.1640, 0.2956, 0.1325, 0.1562, 0.1925, 0.3624, 0.3517, 0.3260, 0.4081,\n",
       "                      0.5305, 0.1350, 0.3864, 0.4156, 0.3144, 0.2105, 0.2436, 0.5096, 0.1165,\n",
       "                      0.1932, 0.1159, 0.4411, 0.2314, 0.5419, 0.6227, 0.2421, 0.3191, 0.4046,\n",
       "                      0.5738, 0.2892, 0.2561, 0.2780, 0.1976, 0.4282, 0.4484, 0.1573, 0.3482,\n",
       "                      0.3932, 0.3251, 0.1870, 0.5274, 0.4046, 0.4978, 0.0945, 0.5531, 0.1566,\n",
       "                      0.1519, 0.6283, 0.4106, 0.3108, 0.1662, 0.2684, 0.5077, 0.2172, 0.3048,\n",
       "                      0.2087, 0.3461, 0.3752, 0.2839, 0.1826, 0.3653, 0.0844, 0.4103, 0.3834,\n",
       "                      0.3789, 0.1545, 0.4832, 0.1594, 0.6762, 0.3914, 0.3739, 0.4262, 0.1582,\n",
       "                      0.0759, 0.1330, 0.2201, 0.6565, 0.4295, 0.4065, 0.3363, 0.4797, 0.2097,\n",
       "                      0.4579, 0.2470, 0.3006, 0.2201, 0.4440, 0.3853, 0.3628, 0.4775, 0.2904,\n",
       "                      0.1953, 0.5650, 0.7159, 0.2510, 0.4040, 0.3468, 0.4739, 0.2371, 0.1211,\n",
       "                      0.4130, 0.1939, 0.1427, 0.2667, 0.1371, 0.2859, 0.2738, 0.3903, 0.1401,\n",
       "                      0.1394, 0.1515, 0.5333, 0.3042, 0.2755, 0.2541, 0.3534, 0.0609, 0.3358,\n",
       "                      0.4918, 0.2806, 0.3696, 0.3182, 0.0893, 0.3698, 0.1025, 0.2177, 0.4522,\n",
       "                      0.2811, 0.1441, 0.2088, 0.3258, 0.3670, 0.1267, 0.2864, 0.4355, 0.2716,\n",
       "                      0.2503, 0.3426, 0.0957, 0.1857, 0.5993, 0.2882, 0.2578, 0.1556, 0.2994,\n",
       "                      0.2280, 0.3436, 0.1469, 0.3648, 0.3834, 0.6300, 0.4562, 0.3652, 0.5238,\n",
       "                      0.3307, 0.3367, 0.3825, 0.2320], dtype=torch.float64)),\n",
       "             ('6.0.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.1.convs.0.0.weight',\n",
       "              tensor([[[-0.0424],\n",
       "                       [-0.0052],\n",
       "                       [-0.0162],\n",
       "                       ...,\n",
       "                       [-0.0172],\n",
       "                       [ 0.0693],\n",
       "                       [ 0.1802]],\n",
       "              \n",
       "                      [[-0.1415],\n",
       "                       [-0.1271],\n",
       "                       [-0.0309],\n",
       "                       ...,\n",
       "                       [-0.0037],\n",
       "                       [-0.0752],\n",
       "                       [ 0.0457]],\n",
       "              \n",
       "                      [[-0.0204],\n",
       "                       [ 0.0124],\n",
       "                       [-0.0841],\n",
       "                       ...,\n",
       "                       [-0.0590],\n",
       "                       [ 0.0378],\n",
       "                       [-0.1357]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0995],\n",
       "                       [-0.0427],\n",
       "                       [ 0.0297],\n",
       "                       ...,\n",
       "                       [ 0.0364],\n",
       "                       [-0.1483],\n",
       "                       [-0.0230]],\n",
       "              \n",
       "                      [[-0.0895],\n",
       "                       [-0.0080],\n",
       "                       [ 0.1440],\n",
       "                       ...,\n",
       "                       [-0.0309],\n",
       "                       [ 0.0486],\n",
       "                       [ 0.1555]],\n",
       "              \n",
       "                      [[ 0.0032],\n",
       "                       [ 0.0161],\n",
       "                       [ 0.1359],\n",
       "                       ...,\n",
       "                       [ 0.0351],\n",
       "                       [ 0.1254],\n",
       "                       [-0.0484]]], dtype=torch.float64)),\n",
       "             ('6.1.convs.0.1.weight',\n",
       "              tensor([0.9556, 1.0019, 1.0087, 0.9839, 0.9734, 0.9625, 0.9381, 0.9673, 0.9806,\n",
       "                      0.9546, 0.9805, 0.9785, 0.9709, 0.9602, 0.9621, 0.9622, 0.9760, 0.9791,\n",
       "                      0.9692, 0.9689, 0.9813, 0.9832, 0.9897, 0.9889, 1.0074, 1.0071, 1.0083,\n",
       "                      0.9977, 0.9713, 0.9936, 0.9776, 0.9781, 0.9790, 0.9894, 0.9832, 0.9624,\n",
       "                      0.9719, 0.9489, 0.9957, 0.9892, 0.9621, 0.9772, 0.9718, 0.9670, 0.9803,\n",
       "                      0.9713, 0.9949, 0.9753, 0.9575, 0.9799, 0.9770, 0.9585, 1.0001, 0.9882,\n",
       "                      0.9535, 0.9676, 0.9700, 0.9936, 0.9713, 0.9549, 0.9795, 0.9669, 0.9713,\n",
       "                      0.9849], dtype=torch.float64)),\n",
       "             ('6.1.convs.0.1.bias',\n",
       "              tensor([-0.0017, -0.0029, -0.0089,  0.0086,  0.0141, -0.0037, -0.0049, -0.0115,\n",
       "                      -0.0026, -0.0092, -0.0023,  0.0075,  0.0085, -0.0089, -0.0108, -0.0087,\n",
       "                      -0.0080, -0.0041, -0.0172, -0.0054,  0.0058,  0.0031, -0.0113,  0.0088,\n",
       "                       0.0167,  0.0095,  0.0253,  0.0136, -0.0010,  0.0148,  0.0083,  0.0097,\n",
       "                       0.0072,  0.0056,  0.0013, -0.0129, -0.0220, -0.0166,  0.0163, -0.0002,\n",
       "                      -0.0046, -0.0087, -0.0122, -0.0059,  0.0129,  0.0026,  0.0159, -0.0054,\n",
       "                      -0.0165, -0.0112,  0.0132,  0.0044,  0.0175,  0.0075, -0.0178, -0.0023,\n",
       "                      -0.0043,  0.0185, -0.0278, -0.0196,  0.0044, -0.0123,  0.0084, -0.0067],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convs.0.1.running_mean',\n",
       "              tensor([-0.4150, -0.2880, -0.8945, -0.3042, -0.3209, -0.3696,  0.1797,  0.3235,\n",
       "                      -0.4861,  0.7383,  0.3577,  0.0531, -0.3761, -0.5580, -0.0362, -0.2112,\n",
       "                      -0.7140,  0.7089,  0.7538, -1.0949, -0.4426, -0.3842, -0.0116, -0.2084,\n",
       "                      -0.0925, -0.8444,  0.4087,  0.2340, -0.1648,  0.3386, -0.2307,  0.0546,\n",
       "                       0.4520, -0.2811, -0.0146,  0.2515,  0.3150, -0.3467, -0.4012, -0.5889,\n",
       "                      -0.3563,  0.1232,  0.3213,  0.2147, -0.1321,  0.8876,  0.4366, -0.4667,\n",
       "                      -0.2859, -0.2934, -0.5439,  0.3009, -0.2590, -0.5371, -0.6992, -0.2741,\n",
       "                       0.6387,  0.0014,  0.6532, -0.2137, -0.0535, -0.3523, -0.2007,  0.1740],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convs.0.1.running_var',\n",
       "              tensor([0.1284, 0.1352, 0.1480, 0.4249, 0.1864, 0.1490, 1.1221, 0.1556, 0.1418,\n",
       "                      1.3059, 0.1094, 0.1480, 0.3749, 0.5922, 0.3826, 0.2936, 0.3074, 0.2663,\n",
       "                      1.5858, 0.1791, 0.1160, 0.1212, 0.1502, 0.2258, 0.1906, 0.1150, 0.2483,\n",
       "                      0.1860, 0.1966, 0.2237, 0.3810, 0.9359, 0.1306, 0.1491, 0.1347, 0.1381,\n",
       "                      0.3361, 0.3937, 0.2071, 0.2376, 0.1224, 0.1280, 0.1185, 0.3536, 0.1533,\n",
       "                      0.1641, 0.3471, 0.1896, 0.5365, 0.0846, 0.1462, 1.3340, 0.1304, 0.1195,\n",
       "                      0.3710, 0.1689, 1.0295, 0.2006, 0.3087, 0.1431, 0.1711, 0.1458, 0.6250,\n",
       "                      0.1392], dtype=torch.float64)),\n",
       "             ('6.1.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.1.convs.1.0.weight',\n",
       "              tensor([[[-2.0950e-01,  5.1853e-02,  1.7200e-01,  2.6316e-02, -5.6596e-03],\n",
       "                       [ 2.4236e-02, -9.5213e-02,  1.2029e-01,  5.4813e-02, -1.4749e-01],\n",
       "                       [-6.5424e-02, -4.0944e-02, -5.1758e-02, -1.0551e-01,  1.6669e-02],\n",
       "                       ...,\n",
       "                       [-1.6925e-01,  8.7979e-02, -1.0981e-01, -7.9609e-02,  9.7839e-02],\n",
       "                       [ 4.6368e-02, -7.2487e-04, -3.8773e-02, -1.1093e-02, -7.0569e-02],\n",
       "                       [-4.8690e-02,  1.0747e-01,  1.2215e-01,  9.5290e-02, -2.9760e-02]],\n",
       "              \n",
       "                      [[ 1.1572e-02,  1.5122e-02,  8.7048e-03,  4.8775e-02,  6.6929e-02],\n",
       "                       [ 6.1570e-02,  8.4607e-02, -1.7447e-02, -7.0495e-02,  2.7752e-02],\n",
       "                       [-8.2153e-02,  2.8278e-02, -2.8629e-02, -4.6675e-03, -5.0332e-02],\n",
       "                       ...,\n",
       "                       [-7.2105e-02,  5.4642e-02, -6.0589e-02,  2.0942e-02, -1.4742e-01],\n",
       "                       [-5.1720e-03,  4.9924e-02, -3.8816e-02,  6.6992e-02, -2.4088e-02],\n",
       "                       [ 1.6673e-02,  7.7642e-02, -1.8007e-02, -4.7000e-02, -4.6770e-02]],\n",
       "              \n",
       "                      [[ 1.0554e-01, -9.4840e-02,  3.5358e-02, -1.0092e-01, -1.0186e-02],\n",
       "                       [-1.1118e-01, -5.9017e-02, -4.2867e-02,  1.9443e-04,  1.7456e-02],\n",
       "                       [ 6.7793e-03,  6.9719e-02,  2.1501e-02, -5.2033e-02, -8.0415e-02],\n",
       "                       ...,\n",
       "                       [ 5.1017e-02, -7.1165e-02,  3.5667e-05, -3.5859e-02,  8.8855e-02],\n",
       "                       [-5.0787e-03, -8.2741e-02, -2.2271e-02, -1.3771e-03, -2.2313e-02],\n",
       "                       [-1.0266e-01, -8.2067e-03,  1.4628e-01,  7.0854e-02,  1.1533e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 7.6572e-02, -1.0005e-01, -8.4468e-02, -6.6984e-02,  8.2237e-03],\n",
       "                       [-7.0071e-02, -4.2501e-02, -6.1198e-02,  2.0228e-02, -7.6715e-02],\n",
       "                       [ 1.0537e-01,  1.1839e-01, -2.3135e-02, -1.3043e-01,  5.2902e-03],\n",
       "                       ...,\n",
       "                       [-1.7547e-01,  3.9171e-02, -1.0876e-01,  6.3565e-02, -1.7522e-01],\n",
       "                       [ 6.0957e-02,  1.6996e-02,  2.4187e-02,  6.2424e-02,  1.1230e-01],\n",
       "                       [ 8.5341e-03,  7.3469e-02, -2.6717e-02,  5.3603e-02, -3.6374e-02]],\n",
       "              \n",
       "                      [[ 2.0410e-01,  8.2785e-02, -1.0192e-01,  5.3371e-02,  4.5274e-02],\n",
       "                       [-5.7510e-02, -2.8322e-03, -6.1027e-02, -9.7454e-02,  9.9822e-02],\n",
       "                       [-1.6745e-02,  1.7708e-02,  2.5208e-02,  7.8046e-03,  1.9021e-02],\n",
       "                       ...,\n",
       "                       [-6.5871e-02,  4.6885e-02, -1.5164e-02, -2.4515e-02,  8.3965e-02],\n",
       "                       [-1.2700e-01, -8.9268e-03,  2.7877e-02,  1.4866e-01, -1.4576e-01],\n",
       "                       [ 1.4306e-02, -2.2543e-02, -3.3897e-02, -1.3741e-02,  1.2444e-01]],\n",
       "              \n",
       "                      [[-1.2861e-01,  3.9379e-02,  2.0283e-02, -1.3749e-01, -8.0337e-02],\n",
       "                       [-1.6939e-02, -8.5982e-02, -2.4563e-02, -7.2682e-02,  3.3371e-02],\n",
       "                       [ 2.8970e-02,  2.6279e-02, -3.8103e-02, -1.1201e-02,  9.8238e-03],\n",
       "                       ...,\n",
       "                       [-4.3107e-02, -4.0265e-02, -1.0508e-01, -9.1465e-03, -6.0057e-02],\n",
       "                       [-1.1010e-01,  5.2762e-02, -1.2893e-02, -4.5244e-02, -1.2957e-01],\n",
       "                       [-1.7820e-02,  5.2013e-02, -1.4101e-01, -6.1925e-02, -1.0389e-01]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convs.1.1.weight',\n",
       "              tensor([0.9720, 0.9679, 0.9775, 0.9749, 0.9609, 0.9971, 0.9576, 0.9889, 0.9624,\n",
       "                      0.9806, 0.9474, 0.9942, 0.9756, 0.9747, 1.0010, 0.9667, 0.9915, 0.9766,\n",
       "                      0.9825, 0.9391, 0.9543, 1.0023, 0.9918, 0.9888, 0.9745, 0.9734, 0.9697,\n",
       "                      0.9500, 0.9360, 0.9752, 0.9605, 0.9960, 0.9776, 0.9678, 0.9754, 0.9702,\n",
       "                      0.9606, 0.9504, 0.9724, 0.9752, 0.9769, 0.9727, 0.9750, 0.9627, 0.9475,\n",
       "                      0.9586, 0.9753, 0.9865, 0.9684, 0.9436, 0.9798, 0.9555, 0.9897, 0.9799,\n",
       "                      0.9643, 0.9637, 0.9406, 0.9663, 0.9615, 0.9387, 0.9585, 0.9988, 0.9785,\n",
       "                      0.9608], dtype=torch.float64)),\n",
       "             ('6.1.convs.1.1.bias',\n",
       "              tensor([ 0.0045, -0.0058,  0.0110, -0.0134,  0.0036,  0.0029, -0.0203,  0.0089,\n",
       "                      -0.0099, -0.0085, -0.0079,  0.0090,  0.0005, -0.0104,  0.0085, -0.0078,\n",
       "                       0.0083,  0.0084, -0.0136, -0.0353, -0.0196,  0.0228, -0.0026,  0.0075,\n",
       "                      -0.0078,  0.0115, -0.0149, -0.0146, -0.0139, -0.0057, -0.0113,  0.0076,\n",
       "                       0.0198,  0.0059,  0.0004,  0.0064, -0.0244, -0.0327, -0.0311, -0.0052,\n",
       "                       0.0024, -0.0007,  0.0068, -0.0120, -0.0167, -0.0146,  0.0064, -0.0074,\n",
       "                      -0.0020, -0.0026,  0.0059, -0.0109,  0.0022, -0.0041,  0.0040, -0.0100,\n",
       "                      -0.0177, -0.0081,  0.0005, -0.0173, -0.0133, -0.0040, -0.0002, -0.0030],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convs.1.1.running_mean',\n",
       "              tensor([-0.1656, -0.6688, -0.4472, -0.1567,  0.7757, -0.5768,  0.2833, -0.3976,\n",
       "                       0.6657, -0.4052,  0.1801, -0.4839, -0.8778, -0.2844, -0.2725, -0.2495,\n",
       "                      -0.1189,  0.8925, -0.3347, -0.2087, -0.4131, -0.1935,  0.0613,  0.2266,\n",
       "                      -0.9533,  0.0056,  0.9228, -0.4401, -1.0035, -0.3009,  0.2633, -0.8557,\n",
       "                      -0.2897,  0.7346, -0.3499,  0.1430,  0.3073,  0.6404,  0.4430,  0.3936,\n",
       "                      -0.5687, -0.5230,  0.4855, -1.0240, -0.3783,  0.0242,  0.0474,  0.2459,\n",
       "                      -0.5932, -0.3431, -0.1530, -0.2717,  0.7636, -0.4168, -0.5561,  0.6566,\n",
       "                       0.3383, -0.0152,  0.0538, -0.4823,  0.7188, -0.0441,  0.2668, -0.7195],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convs.1.1.running_var',\n",
       "              tensor([0.5525, 0.6694, 0.4685, 0.4331, 1.2383, 0.3676, 1.4682, 0.4152, 1.0946,\n",
       "                      0.5143, 0.4961, 0.4534, 0.5306, 0.4656, 0.5585, 0.5626, 0.5448, 0.7693,\n",
       "                      0.4146, 0.6038, 0.5043, 0.7914, 0.4437, 0.3316, 0.5336, 0.4510, 0.4652,\n",
       "                      0.4602, 0.5756, 0.6658, 0.4250, 0.5382, 0.7333, 0.7666, 0.5531, 0.5333,\n",
       "                      0.5438, 0.8516, 0.5218, 0.4936, 0.6635, 0.9291, 0.6418, 0.4868, 0.6685,\n",
       "                      0.5711, 0.3934, 0.4378, 0.3515, 0.8665, 0.6973, 0.4516, 0.4504, 0.4979,\n",
       "                      0.8210, 0.9745, 0.5085, 0.3770, 0.5947, 0.4277, 0.7694, 0.5036, 0.4561,\n",
       "                      0.5399], dtype=torch.float64)),\n",
       "             ('6.1.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.1.convs.2.0.weight',\n",
       "              tensor([[[ 0.0156],\n",
       "                       [ 0.1794],\n",
       "                       [-0.0017],\n",
       "                       ...,\n",
       "                       [ 0.0571],\n",
       "                       [-0.1546],\n",
       "                       [ 0.0860]],\n",
       "              \n",
       "                      [[-0.0700],\n",
       "                       [-0.3171],\n",
       "                       [-0.0454],\n",
       "                       ...,\n",
       "                       [ 0.0552],\n",
       "                       [ 0.1973],\n",
       "                       [-0.0720]],\n",
       "              \n",
       "                      [[ 0.0063],\n",
       "                       [-0.1475],\n",
       "                       [-0.0504],\n",
       "                       ...,\n",
       "                       [ 0.0004],\n",
       "                       [-0.2594],\n",
       "                       [ 0.0226]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0922],\n",
       "                       [ 0.0924],\n",
       "                       [-0.1548],\n",
       "                       ...,\n",
       "                       [-0.0344],\n",
       "                       [-0.0150],\n",
       "                       [ 0.0429]],\n",
       "              \n",
       "                      [[-0.0263],\n",
       "                       [ 0.1360],\n",
       "                       [ 0.1294],\n",
       "                       ...,\n",
       "                       [ 0.0344],\n",
       "                       [-0.1223],\n",
       "                       [-0.0304]],\n",
       "              \n",
       "                      [[-0.2087],\n",
       "                       [-0.1865],\n",
       "                       [-0.2063],\n",
       "                       ...,\n",
       "                       [-0.0782],\n",
       "                       [ 0.1243],\n",
       "                       [ 0.0495]]], dtype=torch.float64)),\n",
       "             ('6.1.convs.2.1.weight',\n",
       "              tensor([-0.0033,  0.0280, -0.0101,  0.0123, -0.0082,  0.0117, -0.0012,  0.0020,\n",
       "                      -0.0283, -0.0020, -0.0126, -0.0198, -0.0071, -0.0270, -0.0178, -0.0426,\n",
       "                      -0.0179, -0.0224, -0.0290,  0.0042, -0.0207,  0.0126, -0.0026, -0.0089,\n",
       "                       0.0133,  0.0036, -0.0023, -0.0093, -0.0019, -0.0075, -0.0134,  0.0242,\n",
       "                      -0.0086,  0.0073, -0.0234,  0.0136, -0.0211,  0.0020, -0.0013, -0.0124,\n",
       "                      -0.0205,  0.0061,  0.0094,  0.0056,  0.0177,  0.0272, -0.0025,  0.0091,\n",
       "                      -0.0312, -0.0045,  0.0278, -0.0252,  0.0041,  0.0226, -0.0026,  0.0049,\n",
       "                      -0.0141, -0.0357,  0.0065,  0.0041,  0.0086, -0.0167,  0.0031,  0.0051,\n",
       "                       0.0217, -0.0179, -0.0220, -0.0261, -0.0020, -0.0360,  0.0092, -0.0024,\n",
       "                      -0.0127,  0.0064,  0.0205, -0.0087,  0.0014, -0.0240,  0.0097, -0.0319,\n",
       "                       0.0042, -0.0075, -0.0158, -0.0147, -0.0129,  0.0066,  0.0042, -0.0085,\n",
       "                       0.0139,  0.0096, -0.0123, -0.0225, -0.0230,  0.0178, -0.0299, -0.0063,\n",
       "                       0.0007, -0.0356, -0.0404,  0.0108, -0.0062,  0.0092, -0.0289,  0.0280,\n",
       "                      -0.0029,  0.0239, -0.0152,  0.0203, -0.0333,  0.0071, -0.0209, -0.0146,\n",
       "                      -0.0406,  0.0116, -0.0093,  0.0121, -0.0390, -0.0209,  0.0047,  0.0246,\n",
       "                      -0.0080, -0.0132, -0.0223,  0.0052, -0.0090,  0.0140,  0.0082,  0.0144,\n",
       "                       0.0374,  0.0013, -0.0153, -0.0033,  0.0109, -0.0022, -0.0115, -0.0100,\n",
       "                      -0.0067, -0.0336,  0.0172, -0.0168,  0.0265,  0.0054, -0.0313,  0.0124,\n",
       "                       0.0044, -0.0070,  0.0099, -0.0236,  0.0139,  0.0043,  0.0085, -0.0046,\n",
       "                      -0.0200, -0.0132, -0.0205,  0.0219,  0.0186, -0.0119, -0.0168, -0.0048,\n",
       "                      -0.0146, -0.0232, -0.0193,  0.0346,  0.0309, -0.0276,  0.0190, -0.0002,\n",
       "                       0.0524,  0.0060, -0.0008,  0.0144, -0.0172,  0.0115, -0.0091, -0.0027,\n",
       "                      -0.0143, -0.0400,  0.0253, -0.0060, -0.0100, -0.0002,  0.0407,  0.0087,\n",
       "                      -0.0047,  0.0200, -0.0264, -0.0025, -0.0068,  0.0231,  0.0017, -0.0234,\n",
       "                      -0.0071, -0.0362, -0.0341,  0.0026,  0.0278,  0.0019, -0.0050,  0.0093,\n",
       "                       0.0108, -0.0234,  0.0132, -0.0211,  0.0109, -0.0061, -0.0059,  0.0157,\n",
       "                       0.0063,  0.0085,  0.0014, -0.0033,  0.0156, -0.0193,  0.0040, -0.0451,\n",
       "                      -0.0060, -0.0167,  0.0249,  0.0014, -0.0168, -0.0038,  0.0080, -0.0166,\n",
       "                       0.0245,  0.0136,  0.0299,  0.0159,  0.0059,  0.0185, -0.0068,  0.0026,\n",
       "                       0.0243, -0.0314,  0.0236, -0.0180,  0.0132,  0.0077, -0.0003,  0.0301,\n",
       "                      -0.0009,  0.0018,  0.0246,  0.0090,  0.0149, -0.0095,  0.0049, -0.0126,\n",
       "                      -0.0120,  0.0106,  0.0088,  0.0144,  0.0105,  0.0286,  0.0085,  0.0058],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convs.2.1.bias',\n",
       "              tensor([-2.5505e-03, -3.9085e-03,  1.9074e-02,  6.6890e-03,  5.5247e-03,\n",
       "                       6.5796e-03,  2.1594e-02,  7.0783e-05,  1.0067e-02,  2.1318e-02,\n",
       "                       8.0090e-03, -3.4694e-03,  1.2609e-02, -8.5750e-03,  2.7168e-03,\n",
       "                       9.3555e-03,  1.7489e-02,  3.0668e-03,  1.6339e-02, -7.5625e-03,\n",
       "                      -2.5801e-03,  1.8615e-03,  2.5624e-03,  6.5700e-03, -4.1444e-03,\n",
       "                      -1.3100e-02,  6.5238e-03,  1.0643e-02,  2.4487e-03, -5.4523e-04,\n",
       "                       1.5786e-03,  9.3900e-03, -4.1642e-03,  1.4596e-02,  1.9135e-02,\n",
       "                       7.7523e-03,  5.3930e-03,  2.6580e-02,  9.6048e-03,  1.3367e-02,\n",
       "                       1.0891e-03,  7.8824e-03, -8.0961e-03,  3.7968e-03,  1.2411e-02,\n",
       "                      -1.1054e-02,  6.7430e-03,  4.8284e-03, -1.1077e-02,  5.4202e-03,\n",
       "                       3.4150e-03,  4.0094e-03,  8.2411e-03,  2.1089e-02,  4.7997e-03,\n",
       "                      -1.5240e-03,  6.4084e-03,  6.3923e-03,  7.1305e-03,  8.4037e-03,\n",
       "                      -4.8076e-03,  1.9170e-03,  3.9693e-03,  1.0386e-02, -3.5333e-03,\n",
       "                       1.1353e-02, -1.1836e-02,  1.4353e-02, -1.0043e-03, -9.0560e-03,\n",
       "                       2.8714e-03,  1.1269e-02,  1.1881e-02, -8.1071e-03,  1.4425e-02,\n",
       "                       1.8357e-02, -1.2862e-03,  9.0661e-04,  4.5088e-03,  7.1408e-03,\n",
       "                       1.1240e-02, -5.0662e-03,  9.4670e-03,  4.5585e-03, -2.5288e-03,\n",
       "                       1.0548e-02,  5.1050e-03,  3.0754e-03,  7.7780e-03,  8.3395e-03,\n",
       "                      -6.3583e-04,  2.1542e-02,  1.7079e-02, -1.7099e-03,  5.2915e-03,\n",
       "                      -1.4536e-02,  2.7706e-03,  5.5363e-03,  1.1953e-02,  7.3071e-03,\n",
       "                       2.5124e-02,  7.9315e-03, -1.6831e-03, -2.2741e-02,  1.0062e-02,\n",
       "                       1.7996e-03,  3.4937e-03, -3.7026e-03,  4.0731e-03,  9.9470e-03,\n",
       "                      -9.0257e-03, -6.2205e-03,  6.0915e-03,  1.5190e-02,  1.3642e-02,\n",
       "                       8.0707e-03,  1.0722e-02,  2.5499e-03,  1.2776e-03, -1.4411e-02,\n",
       "                       3.6701e-03,  1.3693e-02, -2.9845e-03,  2.4139e-03, -1.0482e-02,\n",
       "                       1.4018e-02,  1.8371e-02,  1.7696e-03,  3.3642e-04,  9.8811e-03,\n",
       "                      -3.5170e-04,  1.5895e-02,  1.4677e-02,  1.1777e-02, -4.8551e-05,\n",
       "                      -1.5621e-03,  1.8747e-02,  8.0064e-03,  1.6684e-02,  4.3264e-03,\n",
       "                      -3.0390e-03, -3.6554e-03,  8.3829e-04,  1.0192e-02, -6.2357e-03,\n",
       "                      -1.2813e-03,  2.7329e-03,  1.3295e-03,  1.0005e-02,  1.0223e-02,\n",
       "                       2.5045e-03,  1.2901e-02,  2.9301e-03,  1.5376e-02,  1.8400e-02,\n",
       "                       1.6355e-02, -8.5364e-04,  1.0838e-02, -2.8020e-03, -1.0860e-02,\n",
       "                      -2.1172e-03,  1.6197e-03, -8.0019e-04,  1.7816e-02,  1.1950e-02,\n",
       "                       2.7652e-03, -7.6293e-03,  7.2079e-03,  5.8560e-03,  1.6358e-02,\n",
       "                       5.0898e-03,  9.1835e-03,  1.4028e-02,  8.3954e-03, -1.3888e-02,\n",
       "                      -6.6470e-03, -2.6172e-03,  2.1919e-02,  5.8810e-03,  1.7710e-03,\n",
       "                      -2.2386e-03,  8.8085e-03, -9.0727e-03, -1.0749e-02,  1.6610e-02,\n",
       "                       3.8294e-03,  1.0589e-02,  1.4135e-02, -4.6294e-03,  2.8441e-03,\n",
       "                       7.6860e-03, -4.2460e-03,  1.4274e-02, -1.5621e-02,  1.0205e-02,\n",
       "                       8.9526e-03, -1.6260e-03,  1.4688e-02,  8.6138e-03, -7.4103e-03,\n",
       "                       4.3163e-03,  2.0667e-02,  2.0862e-02,  1.7362e-02,  5.0182e-03,\n",
       "                      -6.5817e-03,  1.4792e-02, -3.6902e-03,  2.1740e-03,  5.8518e-03,\n",
       "                       1.4639e-04,  1.1807e-02,  1.5026e-02,  6.8936e-03,  6.9249e-03,\n",
       "                       9.7913e-03,  3.2702e-03, -7.7497e-05,  6.7784e-03, -1.1610e-03,\n",
       "                      -1.1122e-02, -1.9100e-03,  7.0872e-03,  2.5784e-02, -4.9091e-03,\n",
       "                       5.4790e-03, -1.1933e-03,  3.5152e-03, -1.8601e-02,  7.6930e-03,\n",
       "                       1.7909e-02,  3.7828e-04,  1.0939e-02,  8.6657e-03,  1.0853e-02,\n",
       "                       3.2809e-03,  6.1784e-03, -2.6066e-03,  1.0758e-02,  7.0968e-03,\n",
       "                       9.9172e-03,  2.6979e-03,  4.0690e-03,  1.2734e-03,  4.1193e-03,\n",
       "                       1.4020e-02,  4.5682e-03,  9.6183e-03, -2.9744e-03, -6.3377e-03,\n",
       "                       1.5441e-02,  8.3987e-03,  2.1647e-02,  2.3877e-02,  1.2482e-02,\n",
       "                       2.3371e-03], dtype=torch.float64)),\n",
       "             ('6.1.convs.2.1.running_mean',\n",
       "              tensor([-2.0302e-01,  2.3928e-01,  1.1861e-02, -2.9150e-01, -3.4993e-01,\n",
       "                      -2.2114e-01,  3.3553e-01, -8.5139e-01, -7.8087e-02,  1.8976e-01,\n",
       "                      -4.2974e-01,  1.2698e-01,  2.9693e-01,  2.4106e-01, -3.9244e-01,\n",
       "                       1.9130e-02, -3.1942e-01, -3.7289e-01,  3.6165e-01, -3.5788e-01,\n",
       "                      -7.6797e-02,  1.7820e-01,  2.2462e-01,  6.1932e-01, -6.8466e-01,\n",
       "                       2.9511e-01, -2.2852e-01,  2.1874e-01, -2.1943e-01,  2.1887e-02,\n",
       "                       7.8857e-02,  7.3661e-01,  6.3667e-01, -9.2395e-01,  4.4736e-01,\n",
       "                       7.0950e-01,  5.1350e-01, -5.4435e-01,  1.4070e-02, -2.0086e-01,\n",
       "                       3.9774e-01,  2.9724e-01, -3.4697e-02, -9.6656e-02, -3.4594e-01,\n",
       "                      -1.5180e-01, -1.1198e-01, -6.5215e-02,  9.0198e-02, -6.3278e-03,\n",
       "                      -3.8864e-01, -8.3079e-01, -3.8943e-01, -3.6461e-02, -1.1616e-01,\n",
       "                       7.5818e-01, -1.0705e-01,  1.2509e-02, -7.9266e-02, -2.1095e-01,\n",
       "                      -3.6026e-01, -1.4638e-01,  6.0615e-03,  4.0779e-01, -2.4074e-01,\n",
       "                      -1.6403e-02,  5.7264e-01, -1.2510e-01,  1.9139e-01,  2.3029e-01,\n",
       "                       2.8744e-01,  2.4143e-01, -1.1884e-01, -9.9484e-02, -4.3107e-01,\n",
       "                      -5.1000e-01, -1.2783e-01, -5.5991e-01, -1.2030e-01, -3.5053e-01,\n",
       "                       2.7037e-01, -1.7367e-02,  5.2911e-01,  2.2383e-01, -4.1650e-01,\n",
       "                      -1.7497e-01, -9.1881e-02,  3.9545e-01,  2.2948e-01, -4.3008e-01,\n",
       "                       1.0458e-01, -5.4550e-01,  1.8406e-01,  3.9215e-01,  2.6270e-01,\n",
       "                      -5.1332e-02,  2.5807e-01, -2.5327e-01, -4.9878e-01,  1.8894e-01,\n",
       "                      -6.2112e-01, -1.2263e-03, -3.4638e-01, -1.8756e-01,  2.7836e-01,\n",
       "                      -2.2012e-01, -2.6579e-01,  6.3353e-01,  2.4430e-01,  3.5475e-01,\n",
       "                       5.4465e-02, -1.2562e-02,  1.1921e-01,  1.4617e-01, -7.0777e-01,\n",
       "                      -3.4613e-01,  1.0903e+00,  7.9713e-01, -2.3165e-02,  4.6684e-01,\n",
       "                       1.4032e-01,  1.9835e-01,  3.3332e-01,  5.9843e-01,  1.5499e-01,\n",
       "                       1.8751e-01, -3.2765e-01,  8.0873e-01,  4.8001e-01,  6.7062e-01,\n",
       "                      -1.3014e-02, -2.2429e-01,  5.1441e-01, -3.8093e-01,  1.1214e-01,\n",
       "                       1.1483e-01,  3.2469e-01,  6.3021e-01,  3.4559e-01, -3.4341e-01,\n",
       "                      -9.6259e-01,  1.9911e-01, -9.7398e-01,  2.4920e-02,  4.8902e-02,\n",
       "                       6.4020e-01, -2.0510e-01, -3.4471e-01,  1.2213e-01, -7.2666e-01,\n",
       "                      -4.3484e-01, -3.2729e-01, -6.9196e-02,  3.6942e-01,  4.7587e-01,\n",
       "                       8.2862e-02,  9.5103e-04,  2.2106e-01,  3.0261e-01, -1.4533e-01,\n",
       "                       5.8162e-01,  2.7436e-01,  2.6451e-01, -9.4665e-01, -5.9348e-01,\n",
       "                       4.3466e-01, -2.5857e-01,  4.9502e-01,  1.2646e-01,  8.8504e-02,\n",
       "                      -1.7012e-02,  1.6124e-01, -7.2137e-01,  1.8796e-01,  9.7766e-01,\n",
       "                       8.5715e-01,  3.7755e-01,  1.1222e-01, -3.4441e-01, -2.3366e-01,\n",
       "                      -3.7620e-01, -2.0036e-01,  8.0275e-02,  1.8547e-01, -6.5372e-02,\n",
       "                       2.9282e-01,  3.2096e-01,  2.6789e-01,  3.0135e-01, -2.2187e-01,\n",
       "                       5.1381e-01, -3.7257e-01,  3.3345e-01, -8.3657e-02, -5.8958e-02,\n",
       "                      -5.0750e-01, -1.9216e-01,  6.3049e-01,  3.3090e-01, -2.8191e-02,\n",
       "                       2.2842e-01,  8.6185e-02,  7.8209e-01,  6.1467e-01, -1.1337e+00,\n",
       "                      -3.9464e-01, -2.7485e-01, -1.5055e-02, -1.3589e-03, -3.9779e-01,\n",
       "                      -8.3975e-02,  5.1198e-01, -2.9870e-01,  5.9018e-02,  1.4741e-01,\n",
       "                      -1.7628e-01,  7.5662e-02, -2.7774e-01, -9.5549e-02, -2.1739e-01,\n",
       "                       8.7645e-02,  6.4962e-01,  7.3246e-02, -8.1537e-02, -7.6913e-01,\n",
       "                       3.6128e-02, -3.5163e-02,  4.5012e-01, -2.9773e-01,  8.9025e-01,\n",
       "                      -1.3018e-01,  1.6535e-01, -6.2737e-01,  2.5452e-01,  1.0737e-01,\n",
       "                      -2.8151e-01,  2.4892e-01,  2.7232e-01, -1.1888e-01, -6.7222e-01,\n",
       "                       4.2951e-01, -2.8898e-01, -2.6196e-01,  3.5638e-01, -2.3585e-01,\n",
       "                      -1.6005e-01,  3.4896e-01, -1.6829e-01, -1.1115e-01,  5.6126e-01,\n",
       "                      -7.5377e-01,  1.1297e+00,  1.9611e-01, -1.4428e-02, -1.8066e-02,\n",
       "                       2.6949e-01], dtype=torch.float64)),\n",
       "             ('6.1.convs.2.1.running_var',\n",
       "              tensor([0.5338, 0.5564, 0.2546, 0.4130, 0.1595, 0.5023, 0.3013, 0.5431, 0.3187,\n",
       "                      0.1764, 0.3705, 0.5176, 0.0649, 0.4851, 0.5429, 0.5387, 0.3057, 0.3401,\n",
       "                      0.2875, 0.4934, 0.3816, 0.4963, 0.3320, 0.5129, 0.4949, 0.4840, 0.2788,\n",
       "                      0.2973, 0.2616, 0.1360, 0.6689, 0.4424, 0.6001, 0.3744, 0.3933, 0.3151,\n",
       "                      0.3604, 0.2965, 0.1025, 0.4086, 0.4977, 0.3096, 0.2554, 0.1878, 0.1988,\n",
       "                      0.3923, 0.1056, 0.2473, 0.4625, 0.1310, 0.4256, 0.4927, 0.3224, 0.5657,\n",
       "                      0.3128, 0.2832, 0.4739, 0.3236, 0.5085, 0.2549, 0.1370, 0.4492, 0.2537,\n",
       "                      0.1955, 0.3470, 0.1965, 0.5290, 0.3061, 0.2122, 0.5322, 0.4395, 0.1623,\n",
       "                      0.2025, 0.4709, 0.5198, 0.2841, 0.3031, 0.3044, 0.5058, 0.3360, 0.1811,\n",
       "                      0.2013, 0.3937, 0.4537, 0.5181, 0.7086, 0.3337, 0.3017, 0.5167, 0.1958,\n",
       "                      0.3957, 0.4683, 0.4542, 0.2254, 0.4159, 0.2281, 0.3685, 0.2733, 0.2758,\n",
       "                      0.2399, 0.3942, 0.3792, 0.3470, 0.3256, 0.1442, 0.3583, 0.4504, 0.4712,\n",
       "                      0.3636, 0.2515, 0.3666, 0.4540, 0.8550, 0.3606, 0.3602, 0.4981, 0.3656,\n",
       "                      0.5337, 0.3742, 0.4996, 0.2233, 0.3993, 0.4624, 0.4538, 0.3044, 0.5115,\n",
       "                      0.1800, 0.3015, 0.3347, 0.1906, 0.2489, 0.2185, 0.3307, 0.2586, 0.2936,\n",
       "                      0.2078, 0.1891, 0.4875, 0.5307, 0.2902, 0.6349, 0.2124, 0.5343, 0.4224,\n",
       "                      0.1106, 0.5053, 0.1948, 0.3957, 0.1875, 0.4339, 0.4597, 0.2213, 0.3603,\n",
       "                      0.5677, 0.3849, 0.4209, 0.3428, 0.3273, 0.6189, 0.2013, 0.2600, 0.3837,\n",
       "                      0.2239, 0.7583, 0.7795, 0.6828, 0.5024, 0.5953, 0.4600, 0.3375, 0.1138,\n",
       "                      0.3194, 0.4556, 0.1979, 0.3740, 0.3590, 0.2702, 0.3942, 0.3662, 0.1440,\n",
       "                      0.3228, 0.2679, 0.4051, 0.5852, 0.2131, 0.4362, 0.3384, 0.2164, 0.2297,\n",
       "                      0.5973, 0.2037, 0.5251, 0.2238, 0.4663, 0.4905, 0.1288, 0.4315, 0.3864,\n",
       "                      0.2771, 0.1604, 0.2165, 0.3582, 0.3555, 0.3907, 0.3972, 0.3187, 0.0990,\n",
       "                      0.2445, 0.3006, 0.4075, 0.0440, 0.3822, 0.2202, 0.6097, 0.1305, 0.3992,\n",
       "                      0.2364, 0.3478, 0.3605, 0.4326, 0.2476, 0.2974, 0.2430, 0.3677, 0.4900,\n",
       "                      0.3069, 0.4193, 0.3520, 0.4766, 0.4849, 0.3115, 0.1262, 0.5743, 0.3966,\n",
       "                      0.3361, 0.4644, 0.3764, 0.1543, 0.3860, 0.4361, 0.2029, 0.1290, 0.6413,\n",
       "                      0.2860, 0.2838, 0.3715, 0.1239, 0.5479, 0.2735, 0.5208, 0.6990, 0.4562,\n",
       "                      0.1960, 0.4321, 0.1099, 0.2580], dtype=torch.float64)),\n",
       "             ('6.1.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.1.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0424],\n",
       "                       [-0.0052],\n",
       "                       [-0.0162],\n",
       "                       ...,\n",
       "                       [-0.0172],\n",
       "                       [ 0.0693],\n",
       "                       [ 0.1802]],\n",
       "              \n",
       "                      [[-0.1415],\n",
       "                       [-0.1271],\n",
       "                       [-0.0309],\n",
       "                       ...,\n",
       "                       [-0.0037],\n",
       "                       [-0.0752],\n",
       "                       [ 0.0457]],\n",
       "              \n",
       "                      [[-0.0204],\n",
       "                       [ 0.0124],\n",
       "                       [-0.0841],\n",
       "                       ...,\n",
       "                       [-0.0590],\n",
       "                       [ 0.0378],\n",
       "                       [-0.1357]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0995],\n",
       "                       [-0.0427],\n",
       "                       [ 0.0297],\n",
       "                       ...,\n",
       "                       [ 0.0364],\n",
       "                       [-0.1483],\n",
       "                       [-0.0230]],\n",
       "              \n",
       "                      [[-0.0895],\n",
       "                       [-0.0080],\n",
       "                       [ 0.1440],\n",
       "                       ...,\n",
       "                       [-0.0309],\n",
       "                       [ 0.0486],\n",
       "                       [ 0.1555]],\n",
       "              \n",
       "                      [[ 0.0032],\n",
       "                       [ 0.0161],\n",
       "                       [ 0.1359],\n",
       "                       ...,\n",
       "                       [ 0.0351],\n",
       "                       [ 0.1254],\n",
       "                       [-0.0484]]], dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.0.1.weight',\n",
       "              tensor([0.9556, 1.0019, 1.0087, 0.9839, 0.9734, 0.9625, 0.9381, 0.9673, 0.9806,\n",
       "                      0.9546, 0.9805, 0.9785, 0.9709, 0.9602, 0.9621, 0.9622, 0.9760, 0.9791,\n",
       "                      0.9692, 0.9689, 0.9813, 0.9832, 0.9897, 0.9889, 1.0074, 1.0071, 1.0083,\n",
       "                      0.9977, 0.9713, 0.9936, 0.9776, 0.9781, 0.9790, 0.9894, 0.9832, 0.9624,\n",
       "                      0.9719, 0.9489, 0.9957, 0.9892, 0.9621, 0.9772, 0.9718, 0.9670, 0.9803,\n",
       "                      0.9713, 0.9949, 0.9753, 0.9575, 0.9799, 0.9770, 0.9585, 1.0001, 0.9882,\n",
       "                      0.9535, 0.9676, 0.9700, 0.9936, 0.9713, 0.9549, 0.9795, 0.9669, 0.9713,\n",
       "                      0.9849], dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.0.1.bias',\n",
       "              tensor([-0.0017, -0.0029, -0.0089,  0.0086,  0.0141, -0.0037, -0.0049, -0.0115,\n",
       "                      -0.0026, -0.0092, -0.0023,  0.0075,  0.0085, -0.0089, -0.0108, -0.0087,\n",
       "                      -0.0080, -0.0041, -0.0172, -0.0054,  0.0058,  0.0031, -0.0113,  0.0088,\n",
       "                       0.0167,  0.0095,  0.0253,  0.0136, -0.0010,  0.0148,  0.0083,  0.0097,\n",
       "                       0.0072,  0.0056,  0.0013, -0.0129, -0.0220, -0.0166,  0.0163, -0.0002,\n",
       "                      -0.0046, -0.0087, -0.0122, -0.0059,  0.0129,  0.0026,  0.0159, -0.0054,\n",
       "                      -0.0165, -0.0112,  0.0132,  0.0044,  0.0175,  0.0075, -0.0178, -0.0023,\n",
       "                      -0.0043,  0.0185, -0.0278, -0.0196,  0.0044, -0.0123,  0.0084, -0.0067],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.4150, -0.2880, -0.8945, -0.3042, -0.3209, -0.3696,  0.1797,  0.3235,\n",
       "                      -0.4861,  0.7383,  0.3577,  0.0531, -0.3761, -0.5580, -0.0362, -0.2112,\n",
       "                      -0.7140,  0.7089,  0.7538, -1.0949, -0.4426, -0.3842, -0.0116, -0.2084,\n",
       "                      -0.0925, -0.8444,  0.4087,  0.2340, -0.1648,  0.3386, -0.2307,  0.0546,\n",
       "                       0.4520, -0.2811, -0.0146,  0.2515,  0.3150, -0.3467, -0.4012, -0.5889,\n",
       "                      -0.3563,  0.1232,  0.3213,  0.2147, -0.1321,  0.8876,  0.4366, -0.4667,\n",
       "                      -0.2859, -0.2934, -0.5439,  0.3009, -0.2590, -0.5371, -0.6992, -0.2741,\n",
       "                       0.6387,  0.0014,  0.6532, -0.2137, -0.0535, -0.3523, -0.2007,  0.1740],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.0.1.running_var',\n",
       "              tensor([0.1284, 0.1352, 0.1480, 0.4249, 0.1864, 0.1490, 1.1221, 0.1556, 0.1418,\n",
       "                      1.3059, 0.1094, 0.1480, 0.3749, 0.5922, 0.3826, 0.2936, 0.3074, 0.2663,\n",
       "                      1.5858, 0.1791, 0.1160, 0.1212, 0.1502, 0.2258, 0.1906, 0.1150, 0.2483,\n",
       "                      0.1860, 0.1966, 0.2237, 0.3810, 0.9359, 0.1306, 0.1491, 0.1347, 0.1381,\n",
       "                      0.3361, 0.3937, 0.2071, 0.2376, 0.1224, 0.1280, 0.1185, 0.3536, 0.1533,\n",
       "                      0.1641, 0.3471, 0.1896, 0.5365, 0.0846, 0.1462, 1.3340, 0.1304, 0.1195,\n",
       "                      0.3710, 0.1689, 1.0295, 0.2006, 0.3087, 0.1431, 0.1711, 0.1458, 0.6250,\n",
       "                      0.1392], dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.1.convpath.0.1.0.weight',\n",
       "              tensor([[[-2.0950e-01,  5.1853e-02,  1.7200e-01,  2.6316e-02, -5.6596e-03],\n",
       "                       [ 2.4236e-02, -9.5213e-02,  1.2029e-01,  5.4813e-02, -1.4749e-01],\n",
       "                       [-6.5424e-02, -4.0944e-02, -5.1758e-02, -1.0551e-01,  1.6669e-02],\n",
       "                       ...,\n",
       "                       [-1.6925e-01,  8.7979e-02, -1.0981e-01, -7.9609e-02,  9.7839e-02],\n",
       "                       [ 4.6368e-02, -7.2487e-04, -3.8773e-02, -1.1093e-02, -7.0569e-02],\n",
       "                       [-4.8690e-02,  1.0747e-01,  1.2215e-01,  9.5290e-02, -2.9760e-02]],\n",
       "              \n",
       "                      [[ 1.1572e-02,  1.5122e-02,  8.7048e-03,  4.8775e-02,  6.6929e-02],\n",
       "                       [ 6.1570e-02,  8.4607e-02, -1.7447e-02, -7.0495e-02,  2.7752e-02],\n",
       "                       [-8.2153e-02,  2.8278e-02, -2.8629e-02, -4.6675e-03, -5.0332e-02],\n",
       "                       ...,\n",
       "                       [-7.2105e-02,  5.4642e-02, -6.0589e-02,  2.0942e-02, -1.4742e-01],\n",
       "                       [-5.1720e-03,  4.9924e-02, -3.8816e-02,  6.6992e-02, -2.4088e-02],\n",
       "                       [ 1.6673e-02,  7.7642e-02, -1.8007e-02, -4.7000e-02, -4.6770e-02]],\n",
       "              \n",
       "                      [[ 1.0554e-01, -9.4840e-02,  3.5358e-02, -1.0092e-01, -1.0186e-02],\n",
       "                       [-1.1118e-01, -5.9017e-02, -4.2867e-02,  1.9443e-04,  1.7456e-02],\n",
       "                       [ 6.7793e-03,  6.9719e-02,  2.1501e-02, -5.2033e-02, -8.0415e-02],\n",
       "                       ...,\n",
       "                       [ 5.1017e-02, -7.1165e-02,  3.5667e-05, -3.5859e-02,  8.8855e-02],\n",
       "                       [-5.0787e-03, -8.2741e-02, -2.2271e-02, -1.3771e-03, -2.2313e-02],\n",
       "                       [-1.0266e-01, -8.2067e-03,  1.4628e-01,  7.0854e-02,  1.1533e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 7.6572e-02, -1.0005e-01, -8.4468e-02, -6.6984e-02,  8.2237e-03],\n",
       "                       [-7.0071e-02, -4.2501e-02, -6.1198e-02,  2.0228e-02, -7.6715e-02],\n",
       "                       [ 1.0537e-01,  1.1839e-01, -2.3135e-02, -1.3043e-01,  5.2902e-03],\n",
       "                       ...,\n",
       "                       [-1.7547e-01,  3.9171e-02, -1.0876e-01,  6.3565e-02, -1.7522e-01],\n",
       "                       [ 6.0957e-02,  1.6996e-02,  2.4187e-02,  6.2424e-02,  1.1230e-01],\n",
       "                       [ 8.5341e-03,  7.3469e-02, -2.6717e-02,  5.3603e-02, -3.6374e-02]],\n",
       "              \n",
       "                      [[ 2.0410e-01,  8.2785e-02, -1.0192e-01,  5.3371e-02,  4.5274e-02],\n",
       "                       [-5.7510e-02, -2.8322e-03, -6.1027e-02, -9.7454e-02,  9.9822e-02],\n",
       "                       [-1.6745e-02,  1.7708e-02,  2.5208e-02,  7.8046e-03,  1.9021e-02],\n",
       "                       ...,\n",
       "                       [-6.5871e-02,  4.6885e-02, -1.5164e-02, -2.4515e-02,  8.3965e-02],\n",
       "                       [-1.2700e-01, -8.9268e-03,  2.7877e-02,  1.4866e-01, -1.4576e-01],\n",
       "                       [ 1.4306e-02, -2.2543e-02, -3.3897e-02, -1.3741e-02,  1.2444e-01]],\n",
       "              \n",
       "                      [[-1.2861e-01,  3.9379e-02,  2.0283e-02, -1.3749e-01, -8.0337e-02],\n",
       "                       [-1.6939e-02, -8.5982e-02, -2.4563e-02, -7.2682e-02,  3.3371e-02],\n",
       "                       [ 2.8970e-02,  2.6279e-02, -3.8103e-02, -1.1201e-02,  9.8238e-03],\n",
       "                       ...,\n",
       "                       [-4.3107e-02, -4.0265e-02, -1.0508e-01, -9.1465e-03, -6.0057e-02],\n",
       "                       [-1.1010e-01,  5.2762e-02, -1.2893e-02, -4.5244e-02, -1.2957e-01],\n",
       "                       [-1.7820e-02,  5.2013e-02, -1.4101e-01, -6.1925e-02, -1.0389e-01]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.1.1.weight',\n",
       "              tensor([0.9720, 0.9679, 0.9775, 0.9749, 0.9609, 0.9971, 0.9576, 0.9889, 0.9624,\n",
       "                      0.9806, 0.9474, 0.9942, 0.9756, 0.9747, 1.0010, 0.9667, 0.9915, 0.9766,\n",
       "                      0.9825, 0.9391, 0.9543, 1.0023, 0.9918, 0.9888, 0.9745, 0.9734, 0.9697,\n",
       "                      0.9500, 0.9360, 0.9752, 0.9605, 0.9960, 0.9776, 0.9678, 0.9754, 0.9702,\n",
       "                      0.9606, 0.9504, 0.9724, 0.9752, 0.9769, 0.9727, 0.9750, 0.9627, 0.9475,\n",
       "                      0.9586, 0.9753, 0.9865, 0.9684, 0.9436, 0.9798, 0.9555, 0.9897, 0.9799,\n",
       "                      0.9643, 0.9637, 0.9406, 0.9663, 0.9615, 0.9387, 0.9585, 0.9988, 0.9785,\n",
       "                      0.9608], dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.1.1.bias',\n",
       "              tensor([ 0.0045, -0.0058,  0.0110, -0.0134,  0.0036,  0.0029, -0.0203,  0.0089,\n",
       "                      -0.0099, -0.0085, -0.0079,  0.0090,  0.0005, -0.0104,  0.0085, -0.0078,\n",
       "                       0.0083,  0.0084, -0.0136, -0.0353, -0.0196,  0.0228, -0.0026,  0.0075,\n",
       "                      -0.0078,  0.0115, -0.0149, -0.0146, -0.0139, -0.0057, -0.0113,  0.0076,\n",
       "                       0.0198,  0.0059,  0.0004,  0.0064, -0.0244, -0.0327, -0.0311, -0.0052,\n",
       "                       0.0024, -0.0007,  0.0068, -0.0120, -0.0167, -0.0146,  0.0064, -0.0074,\n",
       "                      -0.0020, -0.0026,  0.0059, -0.0109,  0.0022, -0.0041,  0.0040, -0.0100,\n",
       "                      -0.0177, -0.0081,  0.0005, -0.0173, -0.0133, -0.0040, -0.0002, -0.0030],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.1.1.running_mean',\n",
       "              tensor([-0.1656, -0.6688, -0.4472, -0.1567,  0.7757, -0.5768,  0.2833, -0.3976,\n",
       "                       0.6657, -0.4052,  0.1801, -0.4839, -0.8778, -0.2844, -0.2725, -0.2495,\n",
       "                      -0.1189,  0.8925, -0.3347, -0.2087, -0.4131, -0.1935,  0.0613,  0.2266,\n",
       "                      -0.9533,  0.0056,  0.9228, -0.4401, -1.0035, -0.3009,  0.2633, -0.8557,\n",
       "                      -0.2897,  0.7346, -0.3499,  0.1430,  0.3073,  0.6404,  0.4430,  0.3936,\n",
       "                      -0.5687, -0.5230,  0.4855, -1.0240, -0.3783,  0.0242,  0.0474,  0.2459,\n",
       "                      -0.5932, -0.3431, -0.1530, -0.2717,  0.7636, -0.4168, -0.5561,  0.6566,\n",
       "                       0.3383, -0.0152,  0.0538, -0.4823,  0.7188, -0.0441,  0.2668, -0.7195],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.1.1.running_var',\n",
       "              tensor([0.5525, 0.6694, 0.4685, 0.4331, 1.2383, 0.3676, 1.4682, 0.4152, 1.0946,\n",
       "                      0.5143, 0.4961, 0.4534, 0.5306, 0.4656, 0.5585, 0.5626, 0.5448, 0.7693,\n",
       "                      0.4146, 0.6038, 0.5043, 0.7914, 0.4437, 0.3316, 0.5336, 0.4510, 0.4652,\n",
       "                      0.4602, 0.5756, 0.6658, 0.4250, 0.5382, 0.7333, 0.7666, 0.5531, 0.5333,\n",
       "                      0.5438, 0.8516, 0.5218, 0.4936, 0.6635, 0.9291, 0.6418, 0.4868, 0.6685,\n",
       "                      0.5711, 0.3934, 0.4378, 0.3515, 0.8665, 0.6973, 0.4516, 0.4504, 0.4979,\n",
       "                      0.8210, 0.9745, 0.5085, 0.3770, 0.5947, 0.4277, 0.7694, 0.5036, 0.4561,\n",
       "                      0.5399], dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.1.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0156],\n",
       "                       [ 0.1794],\n",
       "                       [-0.0017],\n",
       "                       ...,\n",
       "                       [ 0.0571],\n",
       "                       [-0.1546],\n",
       "                       [ 0.0860]],\n",
       "              \n",
       "                      [[-0.0700],\n",
       "                       [-0.3171],\n",
       "                       [-0.0454],\n",
       "                       ...,\n",
       "                       [ 0.0552],\n",
       "                       [ 0.1973],\n",
       "                       [-0.0720]],\n",
       "              \n",
       "                      [[ 0.0063],\n",
       "                       [-0.1475],\n",
       "                       [-0.0504],\n",
       "                       ...,\n",
       "                       [ 0.0004],\n",
       "                       [-0.2594],\n",
       "                       [ 0.0226]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0922],\n",
       "                       [ 0.0924],\n",
       "                       [-0.1548],\n",
       "                       ...,\n",
       "                       [-0.0344],\n",
       "                       [-0.0150],\n",
       "                       [ 0.0429]],\n",
       "              \n",
       "                      [[-0.0263],\n",
       "                       [ 0.1360],\n",
       "                       [ 0.1294],\n",
       "                       ...,\n",
       "                       [ 0.0344],\n",
       "                       [-0.1223],\n",
       "                       [-0.0304]],\n",
       "              \n",
       "                      [[-0.2087],\n",
       "                       [-0.1865],\n",
       "                       [-0.2063],\n",
       "                       ...,\n",
       "                       [-0.0782],\n",
       "                       [ 0.1243],\n",
       "                       [ 0.0495]]], dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.2.1.weight',\n",
       "              tensor([-0.0033,  0.0280, -0.0101,  0.0123, -0.0082,  0.0117, -0.0012,  0.0020,\n",
       "                      -0.0283, -0.0020, -0.0126, -0.0198, -0.0071, -0.0270, -0.0178, -0.0426,\n",
       "                      -0.0179, -0.0224, -0.0290,  0.0042, -0.0207,  0.0126, -0.0026, -0.0089,\n",
       "                       0.0133,  0.0036, -0.0023, -0.0093, -0.0019, -0.0075, -0.0134,  0.0242,\n",
       "                      -0.0086,  0.0073, -0.0234,  0.0136, -0.0211,  0.0020, -0.0013, -0.0124,\n",
       "                      -0.0205,  0.0061,  0.0094,  0.0056,  0.0177,  0.0272, -0.0025,  0.0091,\n",
       "                      -0.0312, -0.0045,  0.0278, -0.0252,  0.0041,  0.0226, -0.0026,  0.0049,\n",
       "                      -0.0141, -0.0357,  0.0065,  0.0041,  0.0086, -0.0167,  0.0031,  0.0051,\n",
       "                       0.0217, -0.0179, -0.0220, -0.0261, -0.0020, -0.0360,  0.0092, -0.0024,\n",
       "                      -0.0127,  0.0064,  0.0205, -0.0087,  0.0014, -0.0240,  0.0097, -0.0319,\n",
       "                       0.0042, -0.0075, -0.0158, -0.0147, -0.0129,  0.0066,  0.0042, -0.0085,\n",
       "                       0.0139,  0.0096, -0.0123, -0.0225, -0.0230,  0.0178, -0.0299, -0.0063,\n",
       "                       0.0007, -0.0356, -0.0404,  0.0108, -0.0062,  0.0092, -0.0289,  0.0280,\n",
       "                      -0.0029,  0.0239, -0.0152,  0.0203, -0.0333,  0.0071, -0.0209, -0.0146,\n",
       "                      -0.0406,  0.0116, -0.0093,  0.0121, -0.0390, -0.0209,  0.0047,  0.0246,\n",
       "                      -0.0080, -0.0132, -0.0223,  0.0052, -0.0090,  0.0140,  0.0082,  0.0144,\n",
       "                       0.0374,  0.0013, -0.0153, -0.0033,  0.0109, -0.0022, -0.0115, -0.0100,\n",
       "                      -0.0067, -0.0336,  0.0172, -0.0168,  0.0265,  0.0054, -0.0313,  0.0124,\n",
       "                       0.0044, -0.0070,  0.0099, -0.0236,  0.0139,  0.0043,  0.0085, -0.0046,\n",
       "                      -0.0200, -0.0132, -0.0205,  0.0219,  0.0186, -0.0119, -0.0168, -0.0048,\n",
       "                      -0.0146, -0.0232, -0.0193,  0.0346,  0.0309, -0.0276,  0.0190, -0.0002,\n",
       "                       0.0524,  0.0060, -0.0008,  0.0144, -0.0172,  0.0115, -0.0091, -0.0027,\n",
       "                      -0.0143, -0.0400,  0.0253, -0.0060, -0.0100, -0.0002,  0.0407,  0.0087,\n",
       "                      -0.0047,  0.0200, -0.0264, -0.0025, -0.0068,  0.0231,  0.0017, -0.0234,\n",
       "                      -0.0071, -0.0362, -0.0341,  0.0026,  0.0278,  0.0019, -0.0050,  0.0093,\n",
       "                       0.0108, -0.0234,  0.0132, -0.0211,  0.0109, -0.0061, -0.0059,  0.0157,\n",
       "                       0.0063,  0.0085,  0.0014, -0.0033,  0.0156, -0.0193,  0.0040, -0.0451,\n",
       "                      -0.0060, -0.0167,  0.0249,  0.0014, -0.0168, -0.0038,  0.0080, -0.0166,\n",
       "                       0.0245,  0.0136,  0.0299,  0.0159,  0.0059,  0.0185, -0.0068,  0.0026,\n",
       "                       0.0243, -0.0314,  0.0236, -0.0180,  0.0132,  0.0077, -0.0003,  0.0301,\n",
       "                      -0.0009,  0.0018,  0.0246,  0.0090,  0.0149, -0.0095,  0.0049, -0.0126,\n",
       "                      -0.0120,  0.0106,  0.0088,  0.0144,  0.0105,  0.0286,  0.0085,  0.0058],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.2.1.bias',\n",
       "              tensor([-2.5505e-03, -3.9085e-03,  1.9074e-02,  6.6890e-03,  5.5247e-03,\n",
       "                       6.5796e-03,  2.1594e-02,  7.0783e-05,  1.0067e-02,  2.1318e-02,\n",
       "                       8.0090e-03, -3.4694e-03,  1.2609e-02, -8.5750e-03,  2.7168e-03,\n",
       "                       9.3555e-03,  1.7489e-02,  3.0668e-03,  1.6339e-02, -7.5625e-03,\n",
       "                      -2.5801e-03,  1.8615e-03,  2.5624e-03,  6.5700e-03, -4.1444e-03,\n",
       "                      -1.3100e-02,  6.5238e-03,  1.0643e-02,  2.4487e-03, -5.4523e-04,\n",
       "                       1.5786e-03,  9.3900e-03, -4.1642e-03,  1.4596e-02,  1.9135e-02,\n",
       "                       7.7523e-03,  5.3930e-03,  2.6580e-02,  9.6048e-03,  1.3367e-02,\n",
       "                       1.0891e-03,  7.8824e-03, -8.0961e-03,  3.7968e-03,  1.2411e-02,\n",
       "                      -1.1054e-02,  6.7430e-03,  4.8284e-03, -1.1077e-02,  5.4202e-03,\n",
       "                       3.4150e-03,  4.0094e-03,  8.2411e-03,  2.1089e-02,  4.7997e-03,\n",
       "                      -1.5240e-03,  6.4084e-03,  6.3923e-03,  7.1305e-03,  8.4037e-03,\n",
       "                      -4.8076e-03,  1.9170e-03,  3.9693e-03,  1.0386e-02, -3.5333e-03,\n",
       "                       1.1353e-02, -1.1836e-02,  1.4353e-02, -1.0043e-03, -9.0560e-03,\n",
       "                       2.8714e-03,  1.1269e-02,  1.1881e-02, -8.1071e-03,  1.4425e-02,\n",
       "                       1.8357e-02, -1.2862e-03,  9.0661e-04,  4.5088e-03,  7.1408e-03,\n",
       "                       1.1240e-02, -5.0662e-03,  9.4670e-03,  4.5585e-03, -2.5288e-03,\n",
       "                       1.0548e-02,  5.1050e-03,  3.0754e-03,  7.7780e-03,  8.3395e-03,\n",
       "                      -6.3583e-04,  2.1542e-02,  1.7079e-02, -1.7099e-03,  5.2915e-03,\n",
       "                      -1.4536e-02,  2.7706e-03,  5.5363e-03,  1.1953e-02,  7.3071e-03,\n",
       "                       2.5124e-02,  7.9315e-03, -1.6831e-03, -2.2741e-02,  1.0062e-02,\n",
       "                       1.7996e-03,  3.4937e-03, -3.7026e-03,  4.0731e-03,  9.9470e-03,\n",
       "                      -9.0257e-03, -6.2205e-03,  6.0915e-03,  1.5190e-02,  1.3642e-02,\n",
       "                       8.0707e-03,  1.0722e-02,  2.5499e-03,  1.2776e-03, -1.4411e-02,\n",
       "                       3.6701e-03,  1.3693e-02, -2.9845e-03,  2.4139e-03, -1.0482e-02,\n",
       "                       1.4018e-02,  1.8371e-02,  1.7696e-03,  3.3642e-04,  9.8811e-03,\n",
       "                      -3.5170e-04,  1.5895e-02,  1.4677e-02,  1.1777e-02, -4.8551e-05,\n",
       "                      -1.5621e-03,  1.8747e-02,  8.0064e-03,  1.6684e-02,  4.3264e-03,\n",
       "                      -3.0390e-03, -3.6554e-03,  8.3829e-04,  1.0192e-02, -6.2357e-03,\n",
       "                      -1.2813e-03,  2.7329e-03,  1.3295e-03,  1.0005e-02,  1.0223e-02,\n",
       "                       2.5045e-03,  1.2901e-02,  2.9301e-03,  1.5376e-02,  1.8400e-02,\n",
       "                       1.6355e-02, -8.5364e-04,  1.0838e-02, -2.8020e-03, -1.0860e-02,\n",
       "                      -2.1172e-03,  1.6197e-03, -8.0019e-04,  1.7816e-02,  1.1950e-02,\n",
       "                       2.7652e-03, -7.6293e-03,  7.2079e-03,  5.8560e-03,  1.6358e-02,\n",
       "                       5.0898e-03,  9.1835e-03,  1.4028e-02,  8.3954e-03, -1.3888e-02,\n",
       "                      -6.6470e-03, -2.6172e-03,  2.1919e-02,  5.8810e-03,  1.7710e-03,\n",
       "                      -2.2386e-03,  8.8085e-03, -9.0727e-03, -1.0749e-02,  1.6610e-02,\n",
       "                       3.8294e-03,  1.0589e-02,  1.4135e-02, -4.6294e-03,  2.8441e-03,\n",
       "                       7.6860e-03, -4.2460e-03,  1.4274e-02, -1.5621e-02,  1.0205e-02,\n",
       "                       8.9526e-03, -1.6260e-03,  1.4688e-02,  8.6138e-03, -7.4103e-03,\n",
       "                       4.3163e-03,  2.0667e-02,  2.0862e-02,  1.7362e-02,  5.0182e-03,\n",
       "                      -6.5817e-03,  1.4792e-02, -3.6902e-03,  2.1740e-03,  5.8518e-03,\n",
       "                       1.4639e-04,  1.1807e-02,  1.5026e-02,  6.8936e-03,  6.9249e-03,\n",
       "                       9.7913e-03,  3.2702e-03, -7.7497e-05,  6.7784e-03, -1.1610e-03,\n",
       "                      -1.1122e-02, -1.9100e-03,  7.0872e-03,  2.5784e-02, -4.9091e-03,\n",
       "                       5.4790e-03, -1.1933e-03,  3.5152e-03, -1.8601e-02,  7.6930e-03,\n",
       "                       1.7909e-02,  3.7828e-04,  1.0939e-02,  8.6657e-03,  1.0853e-02,\n",
       "                       3.2809e-03,  6.1784e-03, -2.6066e-03,  1.0758e-02,  7.0968e-03,\n",
       "                       9.9172e-03,  2.6979e-03,  4.0690e-03,  1.2734e-03,  4.1193e-03,\n",
       "                       1.4020e-02,  4.5682e-03,  9.6183e-03, -2.9744e-03, -6.3377e-03,\n",
       "                       1.5441e-02,  8.3987e-03,  2.1647e-02,  2.3877e-02,  1.2482e-02,\n",
       "                       2.3371e-03], dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.2.1.running_mean',\n",
       "              tensor([-2.0302e-01,  2.3928e-01,  1.1861e-02, -2.9150e-01, -3.4993e-01,\n",
       "                      -2.2114e-01,  3.3553e-01, -8.5139e-01, -7.8087e-02,  1.8976e-01,\n",
       "                      -4.2974e-01,  1.2698e-01,  2.9693e-01,  2.4106e-01, -3.9244e-01,\n",
       "                       1.9130e-02, -3.1942e-01, -3.7289e-01,  3.6165e-01, -3.5788e-01,\n",
       "                      -7.6797e-02,  1.7820e-01,  2.2462e-01,  6.1932e-01, -6.8466e-01,\n",
       "                       2.9511e-01, -2.2852e-01,  2.1874e-01, -2.1943e-01,  2.1887e-02,\n",
       "                       7.8857e-02,  7.3661e-01,  6.3667e-01, -9.2395e-01,  4.4736e-01,\n",
       "                       7.0950e-01,  5.1350e-01, -5.4435e-01,  1.4070e-02, -2.0086e-01,\n",
       "                       3.9774e-01,  2.9724e-01, -3.4697e-02, -9.6656e-02, -3.4594e-01,\n",
       "                      -1.5180e-01, -1.1198e-01, -6.5215e-02,  9.0198e-02, -6.3278e-03,\n",
       "                      -3.8864e-01, -8.3079e-01, -3.8943e-01, -3.6461e-02, -1.1616e-01,\n",
       "                       7.5818e-01, -1.0705e-01,  1.2509e-02, -7.9266e-02, -2.1095e-01,\n",
       "                      -3.6026e-01, -1.4638e-01,  6.0615e-03,  4.0779e-01, -2.4074e-01,\n",
       "                      -1.6403e-02,  5.7264e-01, -1.2510e-01,  1.9139e-01,  2.3029e-01,\n",
       "                       2.8744e-01,  2.4143e-01, -1.1884e-01, -9.9484e-02, -4.3107e-01,\n",
       "                      -5.1000e-01, -1.2783e-01, -5.5991e-01, -1.2030e-01, -3.5053e-01,\n",
       "                       2.7037e-01, -1.7367e-02,  5.2911e-01,  2.2383e-01, -4.1650e-01,\n",
       "                      -1.7497e-01, -9.1881e-02,  3.9545e-01,  2.2948e-01, -4.3008e-01,\n",
       "                       1.0458e-01, -5.4550e-01,  1.8406e-01,  3.9215e-01,  2.6270e-01,\n",
       "                      -5.1332e-02,  2.5807e-01, -2.5327e-01, -4.9878e-01,  1.8894e-01,\n",
       "                      -6.2112e-01, -1.2263e-03, -3.4638e-01, -1.8756e-01,  2.7836e-01,\n",
       "                      -2.2012e-01, -2.6579e-01,  6.3353e-01,  2.4430e-01,  3.5475e-01,\n",
       "                       5.4465e-02, -1.2562e-02,  1.1921e-01,  1.4617e-01, -7.0777e-01,\n",
       "                      -3.4613e-01,  1.0903e+00,  7.9713e-01, -2.3165e-02,  4.6684e-01,\n",
       "                       1.4032e-01,  1.9835e-01,  3.3332e-01,  5.9843e-01,  1.5499e-01,\n",
       "                       1.8751e-01, -3.2765e-01,  8.0873e-01,  4.8001e-01,  6.7062e-01,\n",
       "                      -1.3014e-02, -2.2429e-01,  5.1441e-01, -3.8093e-01,  1.1214e-01,\n",
       "                       1.1483e-01,  3.2469e-01,  6.3021e-01,  3.4559e-01, -3.4341e-01,\n",
       "                      -9.6259e-01,  1.9911e-01, -9.7398e-01,  2.4920e-02,  4.8902e-02,\n",
       "                       6.4020e-01, -2.0510e-01, -3.4471e-01,  1.2213e-01, -7.2666e-01,\n",
       "                      -4.3484e-01, -3.2729e-01, -6.9196e-02,  3.6942e-01,  4.7587e-01,\n",
       "                       8.2862e-02,  9.5103e-04,  2.2106e-01,  3.0261e-01, -1.4533e-01,\n",
       "                       5.8162e-01,  2.7436e-01,  2.6451e-01, -9.4665e-01, -5.9348e-01,\n",
       "                       4.3466e-01, -2.5857e-01,  4.9502e-01,  1.2646e-01,  8.8504e-02,\n",
       "                      -1.7012e-02,  1.6124e-01, -7.2137e-01,  1.8796e-01,  9.7766e-01,\n",
       "                       8.5715e-01,  3.7755e-01,  1.1222e-01, -3.4441e-01, -2.3366e-01,\n",
       "                      -3.7620e-01, -2.0036e-01,  8.0275e-02,  1.8547e-01, -6.5372e-02,\n",
       "                       2.9282e-01,  3.2096e-01,  2.6789e-01,  3.0135e-01, -2.2187e-01,\n",
       "                       5.1381e-01, -3.7257e-01,  3.3345e-01, -8.3657e-02, -5.8958e-02,\n",
       "                      -5.0750e-01, -1.9216e-01,  6.3049e-01,  3.3090e-01, -2.8191e-02,\n",
       "                       2.2842e-01,  8.6185e-02,  7.8209e-01,  6.1467e-01, -1.1337e+00,\n",
       "                      -3.9464e-01, -2.7485e-01, -1.5055e-02, -1.3589e-03, -3.9779e-01,\n",
       "                      -8.3975e-02,  5.1198e-01, -2.9870e-01,  5.9018e-02,  1.4741e-01,\n",
       "                      -1.7628e-01,  7.5662e-02, -2.7774e-01, -9.5549e-02, -2.1739e-01,\n",
       "                       8.7645e-02,  6.4962e-01,  7.3246e-02, -8.1537e-02, -7.6913e-01,\n",
       "                       3.6128e-02, -3.5163e-02,  4.5012e-01, -2.9773e-01,  8.9025e-01,\n",
       "                      -1.3018e-01,  1.6535e-01, -6.2737e-01,  2.5452e-01,  1.0737e-01,\n",
       "                      -2.8151e-01,  2.4892e-01,  2.7232e-01, -1.1888e-01, -6.7222e-01,\n",
       "                       4.2951e-01, -2.8898e-01, -2.6196e-01,  3.5638e-01, -2.3585e-01,\n",
       "                      -1.6005e-01,  3.4896e-01, -1.6829e-01, -1.1115e-01,  5.6126e-01,\n",
       "                      -7.5377e-01,  1.1297e+00,  1.9611e-01, -1.4428e-02, -1.8066e-02,\n",
       "                       2.6949e-01], dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.2.1.running_var',\n",
       "              tensor([0.5338, 0.5564, 0.2546, 0.4130, 0.1595, 0.5023, 0.3013, 0.5431, 0.3187,\n",
       "                      0.1764, 0.3705, 0.5176, 0.0649, 0.4851, 0.5429, 0.5387, 0.3057, 0.3401,\n",
       "                      0.2875, 0.4934, 0.3816, 0.4963, 0.3320, 0.5129, 0.4949, 0.4840, 0.2788,\n",
       "                      0.2973, 0.2616, 0.1360, 0.6689, 0.4424, 0.6001, 0.3744, 0.3933, 0.3151,\n",
       "                      0.3604, 0.2965, 0.1025, 0.4086, 0.4977, 0.3096, 0.2554, 0.1878, 0.1988,\n",
       "                      0.3923, 0.1056, 0.2473, 0.4625, 0.1310, 0.4256, 0.4927, 0.3224, 0.5657,\n",
       "                      0.3128, 0.2832, 0.4739, 0.3236, 0.5085, 0.2549, 0.1370, 0.4492, 0.2537,\n",
       "                      0.1955, 0.3470, 0.1965, 0.5290, 0.3061, 0.2122, 0.5322, 0.4395, 0.1623,\n",
       "                      0.2025, 0.4709, 0.5198, 0.2841, 0.3031, 0.3044, 0.5058, 0.3360, 0.1811,\n",
       "                      0.2013, 0.3937, 0.4537, 0.5181, 0.7086, 0.3337, 0.3017, 0.5167, 0.1958,\n",
       "                      0.3957, 0.4683, 0.4542, 0.2254, 0.4159, 0.2281, 0.3685, 0.2733, 0.2758,\n",
       "                      0.2399, 0.3942, 0.3792, 0.3470, 0.3256, 0.1442, 0.3583, 0.4504, 0.4712,\n",
       "                      0.3636, 0.2515, 0.3666, 0.4540, 0.8550, 0.3606, 0.3602, 0.4981, 0.3656,\n",
       "                      0.5337, 0.3742, 0.4996, 0.2233, 0.3993, 0.4624, 0.4538, 0.3044, 0.5115,\n",
       "                      0.1800, 0.3015, 0.3347, 0.1906, 0.2489, 0.2185, 0.3307, 0.2586, 0.2936,\n",
       "                      0.2078, 0.1891, 0.4875, 0.5307, 0.2902, 0.6349, 0.2124, 0.5343, 0.4224,\n",
       "                      0.1106, 0.5053, 0.1948, 0.3957, 0.1875, 0.4339, 0.4597, 0.2213, 0.3603,\n",
       "                      0.5677, 0.3849, 0.4209, 0.3428, 0.3273, 0.6189, 0.2013, 0.2600, 0.3837,\n",
       "                      0.2239, 0.7583, 0.7795, 0.6828, 0.5024, 0.5953, 0.4600, 0.3375, 0.1138,\n",
       "                      0.3194, 0.4556, 0.1979, 0.3740, 0.3590, 0.2702, 0.3942, 0.3662, 0.1440,\n",
       "                      0.3228, 0.2679, 0.4051, 0.5852, 0.2131, 0.4362, 0.3384, 0.2164, 0.2297,\n",
       "                      0.5973, 0.2037, 0.5251, 0.2238, 0.4663, 0.4905, 0.1288, 0.4315, 0.3864,\n",
       "                      0.2771, 0.1604, 0.2165, 0.3582, 0.3555, 0.3907, 0.3972, 0.3187, 0.0990,\n",
       "                      0.2445, 0.3006, 0.4075, 0.0440, 0.3822, 0.2202, 0.6097, 0.1305, 0.3992,\n",
       "                      0.2364, 0.3478, 0.3605, 0.4326, 0.2476, 0.2974, 0.2430, 0.3677, 0.4900,\n",
       "                      0.3069, 0.4193, 0.3520, 0.4766, 0.4849, 0.3115, 0.1262, 0.5743, 0.3966,\n",
       "                      0.3361, 0.4644, 0.3764, 0.1543, 0.3860, 0.4361, 0.2029, 0.1290, 0.6413,\n",
       "                      0.2860, 0.2838, 0.3715, 0.1239, 0.5479, 0.2735, 0.5208, 0.6990, 0.4562,\n",
       "                      0.1960, 0.4321, 0.1099, 0.2580], dtype=torch.float64)),\n",
       "             ('6.1.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.2.convs.0.0.weight',\n",
       "              tensor([[[-0.0565],\n",
       "                       [-0.0505],\n",
       "                       [-0.1425],\n",
       "                       ...,\n",
       "                       [ 0.0184],\n",
       "                       [ 0.0461],\n",
       "                       [-0.0331]],\n",
       "              \n",
       "                      [[ 0.0799],\n",
       "                       [-0.0190],\n",
       "                       [ 0.0703],\n",
       "                       ...,\n",
       "                       [ 0.0497],\n",
       "                       [-0.0004],\n",
       "                       [-0.0778]],\n",
       "              \n",
       "                      [[ 0.0756],\n",
       "                       [ 0.1013],\n",
       "                       [ 0.0731],\n",
       "                       ...,\n",
       "                       [-0.0379],\n",
       "                       [-0.0231],\n",
       "                       [ 0.0515]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0708],\n",
       "                       [-0.1675],\n",
       "                       [ 0.0322],\n",
       "                       ...,\n",
       "                       [ 0.1841],\n",
       "                       [-0.1723],\n",
       "                       [ 0.0598]],\n",
       "              \n",
       "                      [[ 0.1497],\n",
       "                       [-0.0871],\n",
       "                       [ 0.0099],\n",
       "                       ...,\n",
       "                       [ 0.0473],\n",
       "                       [-0.0713],\n",
       "                       [-0.1062]],\n",
       "              \n",
       "                      [[-0.0440],\n",
       "                       [ 0.0326],\n",
       "                       [ 0.1056],\n",
       "                       ...,\n",
       "                       [-0.0556],\n",
       "                       [ 0.0556],\n",
       "                       [-0.1885]]], dtype=torch.float64)),\n",
       "             ('6.2.convs.0.1.weight',\n",
       "              tensor([0.9888, 0.9610, 0.9569, 0.9873, 0.9865, 0.9986, 0.9541, 0.9751, 0.9658,\n",
       "                      0.9597, 0.9952, 0.9636, 0.9876, 0.9771, 0.9680, 0.9833, 0.9687, 0.9905,\n",
       "                      0.9740, 0.9484, 0.9670, 0.9592, 0.9753, 0.9692, 0.9646, 0.9617, 0.9880,\n",
       "                      0.9810, 0.9674, 0.9735, 0.9548, 0.9768, 0.9672, 0.9722, 0.9828, 0.9717,\n",
       "                      0.9767, 0.9855, 0.9532, 0.9746, 0.9953, 0.9690, 0.9691, 0.9922, 0.9784,\n",
       "                      0.9578, 0.9706, 0.9693, 0.9686, 0.9489, 0.9714, 0.9651, 0.9884, 0.9584,\n",
       "                      0.9896, 0.9519, 0.9730, 0.9667, 0.9552, 0.9789, 0.9885, 0.9736, 0.9731,\n",
       "                      0.9608], dtype=torch.float64)),\n",
       "             ('6.2.convs.0.1.bias',\n",
       "              tensor([ 1.1554e-02, -1.6822e-03, -2.7562e-03,  3.4358e-03,  9.6338e-03,\n",
       "                      -7.5445e-03,  7.5815e-03,  1.6349e-03, -8.4027e-03, -1.4825e-03,\n",
       "                       2.7449e-03,  1.0978e-03,  1.9848e-02,  4.3238e-03,  2.4500e-02,\n",
       "                       1.7340e-02,  7.1757e-03,  3.7631e-03, -4.6050e-03, -4.5539e-03,\n",
       "                       1.4733e-02, -2.6916e-03,  1.9335e-02,  7.2475e-03, -2.4447e-02,\n",
       "                      -1.6473e-02,  2.0872e-02,  9.9249e-03, -6.3243e-03,  2.9428e-03,\n",
       "                      -8.3791e-03, -2.2472e-03,  1.9201e-02,  8.5608e-04, -3.1818e-03,\n",
       "                      -1.0603e-02, -9.5419e-03,  1.5490e-02, -3.1767e-03,  1.7913e-02,\n",
       "                       1.1034e-02, -6.2602e-03,  1.4356e-02,  2.5350e-02,  4.7768e-03,\n",
       "                      -3.8693e-03,  9.8540e-03, -8.6633e-03, -6.2785e-03, -1.8505e-02,\n",
       "                      -9.9820e-03, -1.1923e-05,  1.6003e-02, -1.2047e-02,  1.2562e-02,\n",
       "                       4.5174e-03,  8.5935e-03, -6.3272e-03, -1.4336e-03,  2.1240e-02,\n",
       "                       3.5608e-03, -1.0999e-02, -1.5257e-03,  7.5104e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convs.0.1.running_mean',\n",
       "              tensor([-3.2967e-01, -3.9153e-02, -6.6658e-01, -1.4451e-01, -3.7049e-01,\n",
       "                      -1.8816e-01, -5.6564e-02, -6.2019e-01,  8.6744e-01,  5.1065e-01,\n",
       "                       5.1709e-02, -1.3599e-01,  2.7698e-01, -8.5152e-01, -2.5491e-01,\n",
       "                      -1.3458e-01,  5.8681e-02, -7.2455e-01,  1.2618e+00, -2.8236e-01,\n",
       "                      -4.6423e-01, -3.2596e-01, -3.4369e-01,  3.4760e-01,  1.8911e-01,\n",
       "                      -2.1844e-01,  7.1364e-02, -1.5297e-01, -3.9064e-01,  1.8795e-01,\n",
       "                      -6.8499e-01, -7.0110e-01, -7.8917e-01,  2.7971e-01,  3.5106e-01,\n",
       "                      -3.8349e-01,  4.3666e-01, -6.1573e-01, -1.3775e-01, -3.8474e-01,\n",
       "                      -5.5215e-01, -7.2952e-04, -6.2953e-01, -3.3484e-01,  7.0126e-01,\n",
       "                      -7.2212e-01, -3.9999e-01,  4.5686e-02,  1.4969e-01, -3.1667e-01,\n",
       "                       2.4763e-01,  3.2311e-01,  8.9678e-01, -5.2978e-03, -2.5350e-01,\n",
       "                      -7.1559e-01,  1.7360e-01,  1.6877e-01,  1.5529e-01, -7.5959e-01,\n",
       "                      -1.3622e-01, -1.5824e-01, -1.3703e-01,  1.0238e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convs.0.1.running_var',\n",
       "              tensor([0.3285, 0.3413, 0.1737, 0.3383, 0.1023, 0.1168, 0.2615, 0.2192, 1.1763,\n",
       "                      1.8198, 0.2739, 0.0949, 0.1817, 0.2172, 0.3546, 0.1337, 0.1192, 0.0897,\n",
       "                      1.3786, 1.0233, 0.3726, 0.2219, 0.2441, 0.2901, 0.1207, 0.1242, 0.2375,\n",
       "                      0.1079, 0.4603, 0.1063, 0.2290, 0.2517, 0.2216, 0.2103, 0.1326, 0.0678,\n",
       "                      0.0982, 0.1481, 0.4446, 0.1689, 0.1410, 0.2853, 0.5928, 0.1894, 1.0746,\n",
       "                      0.5542, 0.1596, 0.3659, 0.8283, 0.5587, 0.2637, 0.4427, 0.5629, 0.0843,\n",
       "                      0.2756, 0.0880, 0.1890, 0.2800, 0.3641, 0.1700, 0.1601, 0.3774, 0.1645,\n",
       "                      0.2921], dtype=torch.float64)),\n",
       "             ('6.2.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.2.convs.1.0.weight',\n",
       "              tensor([[[ 0.0640,  0.0503, -0.0179, -0.1204,  0.0662],\n",
       "                       [-0.0277,  0.0530, -0.0696,  0.0966,  0.0788],\n",
       "                       [-0.0802, -0.0350, -0.0427, -0.0968,  0.0195],\n",
       "                       ...,\n",
       "                       [-0.0565, -0.0376, -0.0042,  0.1552, -0.0679],\n",
       "                       [-0.0381,  0.0058, -0.0195,  0.1849,  0.0175],\n",
       "                       [-0.0399,  0.1749, -0.0332, -0.0042,  0.1379]],\n",
       "              \n",
       "                      [[-0.0218,  0.0754,  0.1295,  0.1705,  0.0328],\n",
       "                       [-0.0254, -0.0737, -0.0940, -0.0510,  0.0290],\n",
       "                       [ 0.0725, -0.0674, -0.0428, -0.0116, -0.0693],\n",
       "                       ...,\n",
       "                       [-0.0133,  0.0700,  0.0033, -0.0816,  0.0349],\n",
       "                       [ 0.0849,  0.0050, -0.0462, -0.0440,  0.1171],\n",
       "                       [-0.0054, -0.0612, -0.0168, -0.1379,  0.0123]],\n",
       "              \n",
       "                      [[ 0.0157,  0.1279,  0.0245, -0.0729, -0.0894],\n",
       "                       [-0.1057, -0.0653,  0.0606, -0.0190,  0.0418],\n",
       "                       [-0.1371,  0.0737,  0.0561, -0.0092, -0.0349],\n",
       "                       ...,\n",
       "                       [ 0.0511, -0.0160,  0.0816, -0.1216, -0.1560],\n",
       "                       [-0.0967,  0.0492, -0.0260,  0.0109, -0.0239],\n",
       "                       [-0.0196, -0.0609, -0.0373, -0.1247,  0.0432]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0235, -0.1488,  0.0184, -0.0346,  0.0250],\n",
       "                       [ 0.0932, -0.1516, -0.0974, -0.0095,  0.0476],\n",
       "                       [-0.0590, -0.0941,  0.0122, -0.0764,  0.0366],\n",
       "                       ...,\n",
       "                       [-0.0107,  0.0310, -0.0095, -0.0037, -0.2250],\n",
       "                       [-0.0463, -0.0238,  0.1784, -0.0459,  0.0934],\n",
       "                       [-0.0757, -0.1031, -0.0252, -0.0364, -0.1420]],\n",
       "              \n",
       "                      [[ 0.0908,  0.0338,  0.1147, -0.0511, -0.0121],\n",
       "                       [ 0.0419,  0.0296,  0.0499,  0.1017, -0.1364],\n",
       "                       [-0.1014,  0.0257,  0.0062, -0.0811,  0.1540],\n",
       "                       ...,\n",
       "                       [-0.0584, -0.0031, -0.0786, -0.0384,  0.1889],\n",
       "                       [ 0.0092, -0.1163,  0.0110, -0.0132,  0.0251],\n",
       "                       [ 0.1333, -0.0061,  0.1475, -0.0111, -0.0038]],\n",
       "              \n",
       "                      [[-0.1530,  0.0294, -0.0312, -0.1085,  0.0727],\n",
       "                       [ 0.0472, -0.0804, -0.0971,  0.0183, -0.1105],\n",
       "                       [-0.0830, -0.1793, -0.0079,  0.0241, -0.0578],\n",
       "                       ...,\n",
       "                       [ 0.0029,  0.1342,  0.0206,  0.0863,  0.0962],\n",
       "                       [-0.1063, -0.0248,  0.0383,  0.1320,  0.1679],\n",
       "                       [ 0.0563,  0.0553,  0.0082,  0.0663,  0.1152]]], dtype=torch.float64)),\n",
       "             ('6.2.convs.1.1.weight',\n",
       "              tensor([0.9524, 0.9690, 0.9670, 0.9751, 0.9931, 0.9344, 1.0130, 0.9564, 0.9835,\n",
       "                      0.9765, 0.9833, 0.9700, 0.9594, 0.9645, 0.9682, 0.9667, 0.9245, 0.9604,\n",
       "                      0.9985, 0.9499, 0.9425, 0.9916, 0.9515, 0.9483, 0.9705, 0.9623, 0.9695,\n",
       "                      0.9497, 0.9833, 0.9629, 0.9405, 0.9676, 0.9640, 0.9672, 0.9945, 0.9558,\n",
       "                      0.9710, 0.9613, 0.9623, 0.9538, 1.0019, 0.9743, 0.9480, 0.9738, 0.9568,\n",
       "                      0.9477, 0.9596, 0.9819, 0.9575, 0.9939, 0.9720, 0.9466, 0.9592, 0.9637,\n",
       "                      0.9303, 0.9777, 0.9673, 0.9387, 0.9819, 0.9779, 0.9859, 0.9819, 0.9811,\n",
       "                      0.9720], dtype=torch.float64)),\n",
       "             ('6.2.convs.1.1.bias',\n",
       "              tensor([ 2.7470e-03, -1.3765e-02,  6.0983e-03, -4.1245e-04,  5.1237e-03,\n",
       "                      -8.1063e-05, -1.5589e-02,  6.4030e-03,  1.3215e-03,  7.0557e-04,\n",
       "                       6.4068e-03, -1.6382e-02, -1.9350e-02,  1.0091e-02,  8.8647e-03,\n",
       "                       3.3026e-03, -2.7496e-02, -1.7042e-02, -3.3820e-03, -2.7452e-03,\n",
       "                      -1.3998e-02,  2.7501e-03, -3.0523e-02, -3.5469e-02, -3.5460e-04,\n",
       "                       9.6738e-03,  1.3382e-02,  2.7688e-03,  1.0512e-02, -8.7872e-03,\n",
       "                      -1.9938e-02,  1.1889e-02, -3.1059e-02, -2.5302e-02,  8.5192e-03,\n",
       "                      -4.5392e-03,  1.5666e-02, -1.5421e-02, -2.6320e-02, -9.8213e-03,\n",
       "                       1.8944e-02,  4.0188e-03,  6.4368e-03, -4.7974e-03, -2.2776e-02,\n",
       "                      -1.8603e-03, -6.9103e-03,  2.6461e-02, -1.1599e-02, -4.4005e-05,\n",
       "                       3.9116e-03, -1.2824e-03, -8.4190e-03, -2.4090e-02, -1.9181e-02,\n",
       "                       2.9037e-02,  1.8839e-03,  1.1910e-03,  8.6546e-03,  1.9068e-02,\n",
       "                      -6.6260e-03,  2.3253e-02, -1.3991e-02, -4.3950e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convs.1.1.running_mean',\n",
       "              tensor([-0.3747,  0.7249, -0.0904,  0.2532, -0.5003, -0.0956, -0.1688,  0.0421,\n",
       "                       0.3087,  0.8061,  0.2120, -0.1280, -0.1954, -0.6034,  0.2099, -0.4808,\n",
       "                      -0.2288,  0.1844, -0.1454,  0.0414,  0.0970,  0.0087,  0.0031,  0.4263,\n",
       "                      -0.4281,  0.2461, -0.1865, -0.8033,  0.7010, -0.2709, -0.1924,  0.3431,\n",
       "                       0.1772,  0.3815,  0.2237, -0.2250, -0.1793, -0.0759,  0.1836, -0.2223,\n",
       "                       0.5368, -0.1475, -0.0458, -0.1367,  0.7305, -0.7653, -0.3082, -0.2958,\n",
       "                       0.1892,  0.4999,  0.7705,  0.3761, -0.1520, -0.7156, -0.8855,  0.1022,\n",
       "                       0.0028,  0.1753, -0.3458, -0.6135,  1.0683, -1.1924,  0.6468,  0.3145],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convs.1.1.running_var',\n",
       "              tensor([0.4645, 0.7083, 0.6411, 0.6405, 0.5013, 0.4923, 0.5241, 0.5759, 0.5142,\n",
       "                      0.7873, 0.3988, 0.4638, 0.4338, 0.7547, 0.6025, 0.5707, 0.7279, 0.4259,\n",
       "                      0.6474, 0.9526, 0.5976, 0.6822, 1.0449, 0.7574, 0.4651, 0.7870, 0.6851,\n",
       "                      0.7495, 0.9418, 0.2691, 0.7484, 0.7944, 0.8600, 0.3978, 0.3830, 0.4585,\n",
       "                      0.4799, 0.4525, 0.9228, 0.4628, 0.3921, 0.6896, 0.5607, 0.6229, 0.9776,\n",
       "                      0.6091, 0.6134, 0.4779, 0.3467, 0.5241, 0.6906, 0.5199, 0.3914, 0.4744,\n",
       "                      0.5899, 0.6030, 0.6422, 0.7384, 0.4384, 0.4773, 0.5557, 1.0260, 0.5519,\n",
       "                      0.7797], dtype=torch.float64)),\n",
       "             ('6.2.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.2.convs.2.0.weight',\n",
       "              tensor([[[ 0.2244],\n",
       "                       [ 0.2367],\n",
       "                       [ 0.1866],\n",
       "                       ...,\n",
       "                       [ 0.1014],\n",
       "                       [-0.0672],\n",
       "                       [-0.0143]],\n",
       "              \n",
       "                      [[ 0.1361],\n",
       "                       [-0.0172],\n",
       "                       [-0.0235],\n",
       "                       ...,\n",
       "                       [-0.1010],\n",
       "                       [-0.1749],\n",
       "                       [-0.0074]],\n",
       "              \n",
       "                      [[-0.0752],\n",
       "                       [ 0.1052],\n",
       "                       [-0.0228],\n",
       "                       ...,\n",
       "                       [-0.1157],\n",
       "                       [-0.1313],\n",
       "                       [ 0.0004]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1466],\n",
       "                       [-0.3195],\n",
       "                       [ 0.0626],\n",
       "                       ...,\n",
       "                       [-0.1564],\n",
       "                       [ 0.0305],\n",
       "                       [-0.0880]],\n",
       "              \n",
       "                      [[-0.0984],\n",
       "                       [ 0.1059],\n",
       "                       [ 0.1134],\n",
       "                       ...,\n",
       "                       [-0.0243],\n",
       "                       [-0.1528],\n",
       "                       [ 0.0189]],\n",
       "              \n",
       "                      [[-0.2947],\n",
       "                       [ 0.0384],\n",
       "                       [-0.1119],\n",
       "                       ...,\n",
       "                       [ 0.1308],\n",
       "                       [-0.1934],\n",
       "                       [ 0.1931]]], dtype=torch.float64)),\n",
       "             ('6.2.convs.2.1.weight',\n",
       "              tensor([-1.7022e-03, -1.1376e-02, -1.3251e-02,  5.4066e-03,  5.2605e-03,\n",
       "                       2.1662e-02, -1.0669e-03, -1.5245e-02,  8.5076e-03, -4.7421e-03,\n",
       "                       1.2559e-02,  1.7550e-02, -1.6513e-02, -1.0280e-03,  1.5813e-02,\n",
       "                      -5.4644e-02, -3.7853e-02, -1.8809e-04,  1.0351e-02, -3.6274e-03,\n",
       "                      -1.1859e-02, -3.4023e-03, -2.3923e-02, -1.6862e-02, -6.0764e-03,\n",
       "                       8.0165e-03, -8.0430e-03, -2.9811e-03, -1.2213e-02,  1.0960e-03,\n",
       "                      -5.2426e-03,  6.5109e-02, -1.0544e-03, -2.0072e-02, -3.2147e-02,\n",
       "                       8.5112e-04,  2.4154e-03, -2.0200e-02,  1.4544e-02, -1.5003e-02,\n",
       "                       1.8892e-02,  2.6847e-02,  6.2115e-03,  1.6933e-02, -1.0358e-02,\n",
       "                       1.2553e-02,  8.0310e-03,  7.3795e-03, -4.4583e-02, -1.5242e-03,\n",
       "                       8.8975e-03,  1.2235e-02, -8.5119e-03,  5.0601e-03,  6.8982e-03,\n",
       "                       2.8665e-02,  2.0481e-04, -2.2551e-02, -1.7763e-02, -1.6430e-02,\n",
       "                      -2.7394e-02, -1.2619e-02,  5.1490e-03,  2.5771e-03, -3.2446e-02,\n",
       "                       1.6769e-02,  1.1167e-02,  2.5183e-02,  1.1565e-02,  9.0588e-03,\n",
       "                      -1.0020e-02,  3.0873e-02,  1.8678e-02,  1.6038e-02, -2.4860e-02,\n",
       "                      -1.9459e-02,  1.2336e-02, -1.2152e-02,  4.4370e-03, -1.7990e-02,\n",
       "                       9.3680e-03, -5.5566e-03,  1.6287e-02,  1.7906e-02, -1.3730e-02,\n",
       "                       2.0360e-02, -4.1745e-02,  1.9214e-02,  6.0129e-03, -1.8335e-02,\n",
       "                       1.3433e-02,  2.7189e-02,  2.0968e-05,  2.5771e-03, -1.1901e-02,\n",
       "                       5.6859e-03, -1.5649e-02, -1.7254e-02,  1.9577e-02,  1.7229e-02,\n",
       "                       6.8233e-03, -2.2046e-02, -1.6678e-02, -2.5229e-02, -1.0523e-02,\n",
       "                       1.7920e-02,  9.8209e-03, -1.0585e-02,  3.0046e-02,  7.0828e-03,\n",
       "                       1.1450e-02,  1.0226e-02, -1.4789e-03,  9.4695e-03,  7.8820e-03,\n",
       "                       2.8922e-02,  9.2448e-03, -2.1661e-02,  3.3809e-03,  5.0388e-03,\n",
       "                       1.0983e-02, -1.1586e-02,  3.4584e-04, -1.7022e-02,  2.5300e-02,\n",
       "                       2.1670e-02,  1.0669e-02,  1.5832e-03,  1.3557e-02, -1.2687e-02,\n",
       "                       1.1940e-02,  2.5415e-02, -4.0661e-03, -1.5388e-02, -1.9747e-02,\n",
       "                      -2.5839e-02,  7.6751e-03, -1.0887e-02,  1.9855e-02,  1.1414e-02,\n",
       "                      -7.6104e-04,  2.0603e-04, -1.0158e-03, -1.0813e-03, -3.0590e-03,\n",
       "                       4.9907e-03, -1.3375e-02, -1.3059e-02, -2.7876e-02, -1.3792e-03,\n",
       "                      -2.5615e-02, -9.0706e-03,  6.5247e-03, -9.4027e-04, -2.5703e-03,\n",
       "                       4.5885e-03, -6.3975e-03,  1.1728e-03, -3.9283e-03,  3.4310e-03,\n",
       "                      -7.3474e-03,  2.3849e-02,  2.2057e-02,  2.1656e-02, -3.8555e-03,\n",
       "                       1.6120e-02, -3.3966e-03,  2.5070e-03, -7.4572e-03, -9.9572e-03,\n",
       "                       1.5717e-02,  1.4784e-02, -8.6057e-03,  1.9095e-02, -5.4790e-03,\n",
       "                       3.0067e-02, -3.7296e-02,  2.8053e-02,  4.5763e-03,  6.6212e-03,\n",
       "                       4.3536e-03,  6.2611e-03,  9.4757e-03, -7.4222e-03, -7.8226e-03,\n",
       "                       1.7546e-03,  2.4835e-03,  3.4610e-02,  1.4749e-02,  4.1243e-03,\n",
       "                      -2.8901e-03, -1.9672e-02,  1.1439e-02, -2.6164e-02, -2.7266e-02,\n",
       "                      -5.8925e-03, -1.7949e-05, -1.2002e-02,  8.1637e-03,  2.3852e-02,\n",
       "                      -1.7630e-03, -1.0560e-02, -1.0996e-02,  9.7427e-03,  1.1905e-02,\n",
       "                       1.2258e-02, -1.2684e-02,  6.6713e-03, -2.8566e-03,  1.2590e-02,\n",
       "                       1.7187e-02,  3.0867e-03,  2.5546e-03, -3.6672e-03, -2.8883e-03,\n",
       "                       1.3775e-02,  4.5662e-03, -9.9767e-03,  2.0074e-02,  4.2469e-03,\n",
       "                       1.3227e-02, -1.2160e-02, -1.4508e-02,  1.5343e-02,  1.3865e-02,\n",
       "                       1.3456e-02, -3.1871e-03, -3.5910e-03,  5.2389e-02, -6.1178e-04,\n",
       "                       1.5347e-02,  2.6553e-03, -6.7049e-03,  1.2972e-03,  1.6571e-02,\n",
       "                      -2.5664e-02, -6.8891e-03,  1.1461e-02, -3.2691e-03, -2.7285e-02,\n",
       "                       1.8714e-02,  2.5263e-02, -3.5005e-03,  1.2603e-02, -1.2232e-02,\n",
       "                      -1.3414e-02,  2.2626e-03,  2.1878e-03, -1.2032e-02,  4.0404e-02,\n",
       "                       2.4400e-02, -8.6483e-03, -1.0482e-02,  1.7714e-02, -1.3392e-02,\n",
       "                       4.0087e-02], dtype=torch.float64)),\n",
       "             ('6.2.convs.2.1.bias',\n",
       "              tensor([-2.6506e-03, -2.7597e-03,  1.8489e-02,  7.1597e-03,  5.3737e-03,\n",
       "                       3.4115e-03,  2.1322e-02,  7.9633e-04,  1.0076e-02,  2.1337e-02,\n",
       "                       6.5399e-03, -7.9954e-03,  1.2075e-02, -6.2468e-03,  4.7535e-03,\n",
       "                       7.7885e-03,  1.7050e-02, -3.2981e-04,  1.4969e-02, -8.1884e-03,\n",
       "                      -3.8657e-03,  3.2743e-03,  2.0814e-03,  6.6063e-03, -5.2091e-03,\n",
       "                      -1.3007e-02,  6.7238e-03,  1.0376e-02,  1.1016e-03, -1.3589e-03,\n",
       "                       8.1286e-03,  7.9499e-03, -7.9539e-03,  1.6475e-02,  1.7196e-02,\n",
       "                       7.2007e-03,  9.9995e-04,  2.8488e-02,  9.7364e-03,  1.1173e-02,\n",
       "                      -1.7008e-04,  1.5342e-02, -9.6732e-03,  4.3593e-03,  1.1487e-02,\n",
       "                      -1.0231e-02,  7.2345e-03,  4.1771e-03, -1.1182e-02,  7.9030e-03,\n",
       "                       8.4675e-03,  2.2596e-03,  8.3431e-03,  1.6841e-02,  4.1280e-03,\n",
       "                      -1.1390e-03,  7.1495e-03,  5.5032e-03,  7.4040e-03,  8.2298e-03,\n",
       "                      -7.2225e-03,  1.7846e-03, -1.2505e-03,  1.0236e-02, -4.2406e-03,\n",
       "                       1.3371e-02, -1.1343e-02,  1.2300e-02,  4.6490e-03, -9.4152e-03,\n",
       "                       2.4298e-03,  1.1077e-02,  9.0883e-03, -8.3255e-03,  1.4961e-02,\n",
       "                       1.7883e-02, -1.0875e-03,  3.2563e-03,  3.9161e-03,  6.1038e-03,\n",
       "                       1.0946e-02, -5.6871e-03,  8.1497e-03,  2.4928e-03, -6.9493e-04,\n",
       "                       1.1725e-02,  5.1670e-03,  2.9004e-03,  9.7825e-03,  9.7240e-03,\n",
       "                      -2.7851e-03,  2.3168e-02,  1.6959e-02, -3.1885e-04,  1.3151e-03,\n",
       "                      -1.3790e-02,  2.8626e-03,  2.3489e-04,  1.3942e-02,  7.8279e-03,\n",
       "                       2.5351e-02,  6.9576e-03, -1.1933e-03, -4.0229e-03,  9.4992e-03,\n",
       "                       1.4115e-03,  2.5818e-03,  4.1050e-03,  4.2996e-03,  8.3192e-03,\n",
       "                      -7.1330e-03, -6.6807e-03,  6.3420e-03,  1.5616e-02,  1.2415e-02,\n",
       "                       8.0969e-03,  1.1597e-02,  2.6486e-03,  1.2993e-03, -1.5338e-02,\n",
       "                       2.0556e-03,  1.3725e-02,  1.2186e-03,  1.4313e-03, -1.2165e-02,\n",
       "                       1.3019e-02,  1.7083e-02,  2.7128e-03, -1.1586e-03,  9.7261e-03,\n",
       "                      -1.5498e-03,  1.5748e-02,  1.4602e-02,  1.2564e-02,  1.1937e-02,\n",
       "                      -4.9515e-03,  1.8337e-02,  1.2670e-02,  1.6142e-02,  5.3544e-03,\n",
       "                       3.9446e-03, -2.9763e-03, -5.1065e-03,  8.6812e-03, -5.8302e-03,\n",
       "                       9.0792e-03,  3.9068e-04, -2.8040e-03,  1.3666e-02,  1.0866e-02,\n",
       "                       6.6934e-04,  1.3275e-02,  3.8989e-03,  1.5336e-02,  1.4110e-02,\n",
       "                       1.1314e-02,  1.0989e-04,  9.8440e-03, -6.0635e-03, -1.2074e-02,\n",
       "                      -3.7622e-04, -3.5491e-03, -1.6917e-04,  1.6661e-02,  1.2875e-02,\n",
       "                       2.2027e-03, -8.2765e-03,  9.7156e-03,  2.0198e-03,  1.6068e-02,\n",
       "                       5.2907e-03,  6.0659e-03,  1.2907e-02,  8.2801e-03, -1.4323e-02,\n",
       "                      -4.8243e-03, -2.0621e-03,  1.4657e-02,  6.2861e-03,  4.8946e-03,\n",
       "                      -2.3297e-03,  9.3704e-03, -9.0418e-03, -1.0441e-02,  1.8461e-02,\n",
       "                       9.8076e-03,  1.5484e-02,  1.3885e-02, -5.1067e-03, -3.6825e-04,\n",
       "                       7.5573e-03, -2.4969e-03,  1.4309e-02, -1.6113e-02,  8.7284e-03,\n",
       "                       8.9995e-03, -2.4929e-03,  1.5093e-02,  8.7488e-03, -9.1053e-03,\n",
       "                       5.3569e-03,  1.3902e-02,  2.0318e-02,  1.7466e-02,  3.5519e-03,\n",
       "                      -5.6560e-03,  1.4802e-02, -2.3311e-03,  1.1098e-02,  5.1774e-03,\n",
       "                       2.1149e-03,  1.2048e-02,  1.3731e-02,  6.7681e-03,  1.7393e-02,\n",
       "                       1.2463e-03,  3.7993e-03, -1.1772e-03,  5.0294e-03, -1.1857e-03,\n",
       "                      -1.0684e-02, -9.0822e-04,  6.9600e-03,  2.5757e-02, -1.9999e-03,\n",
       "                       4.3512e-03, -9.6917e-04,  2.5704e-03, -1.6033e-02,  1.3199e-02,\n",
       "                       1.6811e-02, -4.8412e-05,  1.1552e-02,  1.1878e-02,  1.1082e-02,\n",
       "                       2.9774e-03,  7.1287e-03, -4.4003e-03,  1.1104e-02,  8.4545e-03,\n",
       "                       9.5603e-03,  2.6524e-03,  3.1871e-03,  1.4453e-02,  3.4078e-03,\n",
       "                       1.3989e-02,  4.8366e-03,  9.8061e-03,  1.7184e-03, -6.5976e-03,\n",
       "                       1.5279e-02,  1.0562e-02,  2.2532e-02,  2.2955e-02,  1.2863e-02,\n",
       "                       2.0834e-03], dtype=torch.float64)),\n",
       "             ('6.2.convs.2.1.running_mean',\n",
       "              tensor([ 0.3522, -0.0813, -0.1304, -0.2954, -0.7640,  0.1023, -0.0973,  0.1243,\n",
       "                      -0.1896, -0.2991, -0.1124,  0.2451, -0.0316,  0.2352, -0.1390,  0.5835,\n",
       "                       0.4169, -0.0889, -0.5751, -0.4950, -0.1464,  0.2097,  0.2573,  0.7620,\n",
       "                       0.3616, -0.3275, -0.0792,  0.0384,  0.0427,  0.4075,  0.5461, -0.2450,\n",
       "                       0.0164,  0.2700, -0.4034,  0.7175, -0.1472, -0.1556, -0.3581, -0.5702,\n",
       "                       0.0107,  0.5626,  0.4257,  0.5722, -0.2764, -0.1523, -0.9421,  0.0461,\n",
       "                      -0.1601,  0.2258, -0.1996, -0.0693, -0.2103, -0.0586, -0.3182, -0.1521,\n",
       "                       0.3878,  0.6814, -0.5350, -0.3652,  0.3349,  0.3229,  0.3232,  0.1635,\n",
       "                       0.2291,  0.1392, -0.0300, -0.5352,  0.4433, -0.3194, -0.1381, -0.3123,\n",
       "                       0.1800,  0.1937,  0.0971, -0.2848,  0.3931,  0.5866,  0.3407, -0.0312,\n",
       "                       0.6719, -0.1162, -0.3073, -0.4684,  0.0644, -0.4033,  0.6510,  0.0240,\n",
       "                       0.4803, -0.1145,  0.0616,  0.5029,  0.0435, -0.1985,  0.2811, -0.0695,\n",
       "                       0.2851,  0.1119,  0.2872,  0.6235, -0.6560,  0.0222, -0.4503,  0.4972,\n",
       "                      -0.1368, -0.1217, -0.1437, -0.5908, -0.7946, -0.1542, -0.3017, -0.8411,\n",
       "                      -0.1843, -0.0681,  0.3614, -0.3598, -0.4919,  0.5461, -0.6681,  0.1425,\n",
       "                      -0.0775, -0.0919, -0.1824, -0.1213, -0.0881, -0.2658, -0.3546, -0.4458,\n",
       "                      -0.3698,  0.7559,  0.1240,  0.4620, -0.1958, -0.0247,  0.0033, -0.1337,\n",
       "                      -0.6016,  0.3826,  0.3471, -0.2096, -0.1403,  0.1143, -0.2747, -0.3022,\n",
       "                      -0.5138,  0.3154,  0.2067, -0.1045, -0.4310,  0.1182, -0.0102,  0.5126,\n",
       "                       0.6497, -0.0100, -0.0527, -0.1573,  0.2576, -0.2350,  0.3723, -0.0509,\n",
       "                      -0.0333, -0.1526, -0.2257, -0.6446, -0.2851,  0.3317, -0.1569,  0.2836,\n",
       "                       0.1165, -0.0604,  0.4053,  0.1025, -0.0403, -0.0850, -0.3558,  0.3271,\n",
       "                      -0.0161, -0.6606, -0.3766, -0.1923,  0.7222, -0.1280, -0.3245,  0.2282,\n",
       "                      -0.2416, -0.2041,  0.5437,  0.3892, -0.1023,  0.4961, -0.6835, -0.0049,\n",
       "                       0.0326, -0.3170, -0.3632,  0.2783,  0.0784,  0.8466, -0.4194,  0.5559,\n",
       "                       0.2646,  0.1389, -0.5192, -0.8104, -0.6475,  0.3737,  0.1195, -0.1991,\n",
       "                      -0.1304, -0.3789, -0.0459,  0.0890, -0.4762,  0.3223,  0.2913, -0.0857,\n",
       "                      -0.2560, -0.3350, -0.2318, -0.5118, -0.1558,  0.1437, -0.0434,  0.5131,\n",
       "                       0.2125, -0.0766, -0.7140,  0.4749,  0.1095,  0.1000,  0.2875,  0.1644,\n",
       "                       0.4801, -0.5007,  0.7435, -0.3381, -0.3252,  0.2114, -0.1248, -0.4524,\n",
       "                       0.5585,  0.0158,  1.2131, -0.0219, -0.6156, -0.0477, -0.0438, -0.4385,\n",
       "                      -0.0255, -0.4030, -0.0832, -0.1656,  0.6168, -0.1050, -0.1869, -0.7728],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convs.2.1.running_var',\n",
       "              tensor([0.2378, 0.4902, 0.3368, 0.5906, 0.3393, 0.2509, 0.0600, 0.2325, 0.2108,\n",
       "                      0.3386, 0.3620, 0.2510, 0.2186, 0.1726, 0.4183, 0.3221, 0.4245, 0.2269,\n",
       "                      0.4129, 0.5467, 0.1195, 0.4282, 0.4757, 0.3516, 0.4977, 0.2466, 0.2125,\n",
       "                      0.0584, 0.1759, 0.2186, 0.7331, 0.3321, 0.1434, 0.5338, 0.5722, 0.4480,\n",
       "                      0.2087, 0.4217, 0.4184, 0.6348, 0.3648, 0.2657, 0.1909, 0.5662, 0.5494,\n",
       "                      0.4367, 0.3972, 0.1830, 0.4380, 0.2261, 0.4417, 0.3027, 0.3028, 0.3174,\n",
       "                      0.1868, 0.4151, 0.3554, 0.3814, 0.9358, 0.4534, 0.2225, 0.2971, 0.2342,\n",
       "                      0.2162, 0.4246, 0.4172, 1.1902, 0.2424, 0.3305, 0.3207, 0.3558, 0.3134,\n",
       "                      0.3076, 0.5999, 0.4427, 0.4164, 0.2763, 0.2535, 0.3296, 0.4463, 0.2715,\n",
       "                      0.4236, 0.3746, 0.5306, 0.5046, 0.3750, 0.4778, 0.4524, 0.4178, 0.3538,\n",
       "                      0.3656, 0.2036, 0.1546, 0.0711, 0.2048, 0.1856, 0.3902, 0.2982, 0.3169,\n",
       "                      0.3354, 0.4942, 0.3836, 0.3643, 0.5595, 0.2144, 0.5039, 0.3139, 0.5496,\n",
       "                      0.9384, 0.2348, 0.4127, 0.2349, 0.2948, 0.2848, 0.3347, 0.6235, 0.4990,\n",
       "                      0.3871, 0.5138, 0.4266, 0.1477, 0.3579, 0.3220, 0.3552, 0.4692, 0.6977,\n",
       "                      0.2203, 0.2437, 0.1521, 0.2410, 0.2712, 0.1746, 0.3575, 0.3617, 0.2571,\n",
       "                      0.3429, 0.2563, 0.4791, 0.2951, 0.3356, 0.1367, 0.1192, 0.2966, 0.1963,\n",
       "                      0.4084, 0.3080, 0.2643, 0.5187, 0.1951, 0.3701, 0.6142, 0.2385, 0.4989,\n",
       "                      0.2441, 0.2401, 0.1438, 0.3080, 0.2142, 0.1981, 0.2093, 0.0906, 0.2960,\n",
       "                      0.2971, 0.3199, 0.3755, 0.5390, 0.4250, 0.2757, 0.4050, 0.2706, 0.4222,\n",
       "                      0.2824, 0.2964, 0.2135, 0.6213, 0.3488, 0.4648, 0.2685, 0.2096, 0.4153,\n",
       "                      0.4092, 0.0872, 0.4577, 0.5605, 0.3782, 0.2821, 0.3524, 0.2713, 0.4215,\n",
       "                      0.2953, 0.2687, 0.2936, 0.1806, 0.4749, 0.2269, 0.2818, 0.1544, 0.3318,\n",
       "                      0.3626, 0.5501, 0.0863, 0.3014, 0.2974, 0.5053, 0.6464, 0.5075, 0.1905,\n",
       "                      0.0869, 0.2248, 0.4334, 0.1802, 0.1772, 0.1590, 0.2956, 0.1407, 0.2136,\n",
       "                      0.3377, 0.4073, 0.4597, 0.5461, 0.1621, 0.3343, 0.2630, 0.4574, 0.2107,\n",
       "                      0.2579, 0.5428, 0.1945, 0.3673, 0.3057, 0.3077, 0.3292, 0.4597, 0.2568,\n",
       "                      0.6644, 0.3426, 0.1052, 0.3926, 0.2360, 0.2873, 0.2087, 0.1994, 0.5011,\n",
       "                      0.3198, 0.4959, 0.2558, 0.1818, 0.2627, 0.1612, 0.3269, 0.6329, 0.3860,\n",
       "                      0.2504, 0.8461, 0.1192, 0.5047], dtype=torch.float64)),\n",
       "             ('6.2.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.2.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0565],\n",
       "                       [-0.0505],\n",
       "                       [-0.1425],\n",
       "                       ...,\n",
       "                       [ 0.0184],\n",
       "                       [ 0.0461],\n",
       "                       [-0.0331]],\n",
       "              \n",
       "                      [[ 0.0799],\n",
       "                       [-0.0190],\n",
       "                       [ 0.0703],\n",
       "                       ...,\n",
       "                       [ 0.0497],\n",
       "                       [-0.0004],\n",
       "                       [-0.0778]],\n",
       "              \n",
       "                      [[ 0.0756],\n",
       "                       [ 0.1013],\n",
       "                       [ 0.0731],\n",
       "                       ...,\n",
       "                       [-0.0379],\n",
       "                       [-0.0231],\n",
       "                       [ 0.0515]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0708],\n",
       "                       [-0.1675],\n",
       "                       [ 0.0322],\n",
       "                       ...,\n",
       "                       [ 0.1841],\n",
       "                       [-0.1723],\n",
       "                       [ 0.0598]],\n",
       "              \n",
       "                      [[ 0.1497],\n",
       "                       [-0.0871],\n",
       "                       [ 0.0099],\n",
       "                       ...,\n",
       "                       [ 0.0473],\n",
       "                       [-0.0713],\n",
       "                       [-0.1062]],\n",
       "              \n",
       "                      [[-0.0440],\n",
       "                       [ 0.0326],\n",
       "                       [ 0.1056],\n",
       "                       ...,\n",
       "                       [-0.0556],\n",
       "                       [ 0.0556],\n",
       "                       [-0.1885]]], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.0.1.weight',\n",
       "              tensor([0.9888, 0.9610, 0.9569, 0.9873, 0.9865, 0.9986, 0.9541, 0.9751, 0.9658,\n",
       "                      0.9597, 0.9952, 0.9636, 0.9876, 0.9771, 0.9680, 0.9833, 0.9687, 0.9905,\n",
       "                      0.9740, 0.9484, 0.9670, 0.9592, 0.9753, 0.9692, 0.9646, 0.9617, 0.9880,\n",
       "                      0.9810, 0.9674, 0.9735, 0.9548, 0.9768, 0.9672, 0.9722, 0.9828, 0.9717,\n",
       "                      0.9767, 0.9855, 0.9532, 0.9746, 0.9953, 0.9690, 0.9691, 0.9922, 0.9784,\n",
       "                      0.9578, 0.9706, 0.9693, 0.9686, 0.9489, 0.9714, 0.9651, 0.9884, 0.9584,\n",
       "                      0.9896, 0.9519, 0.9730, 0.9667, 0.9552, 0.9789, 0.9885, 0.9736, 0.9731,\n",
       "                      0.9608], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.0.1.bias',\n",
       "              tensor([ 1.1554e-02, -1.6822e-03, -2.7562e-03,  3.4358e-03,  9.6338e-03,\n",
       "                      -7.5445e-03,  7.5815e-03,  1.6349e-03, -8.4027e-03, -1.4825e-03,\n",
       "                       2.7449e-03,  1.0978e-03,  1.9848e-02,  4.3238e-03,  2.4500e-02,\n",
       "                       1.7340e-02,  7.1757e-03,  3.7631e-03, -4.6050e-03, -4.5539e-03,\n",
       "                       1.4733e-02, -2.6916e-03,  1.9335e-02,  7.2475e-03, -2.4447e-02,\n",
       "                      -1.6473e-02,  2.0872e-02,  9.9249e-03, -6.3243e-03,  2.9428e-03,\n",
       "                      -8.3791e-03, -2.2472e-03,  1.9201e-02,  8.5608e-04, -3.1818e-03,\n",
       "                      -1.0603e-02, -9.5419e-03,  1.5490e-02, -3.1767e-03,  1.7913e-02,\n",
       "                       1.1034e-02, -6.2602e-03,  1.4356e-02,  2.5350e-02,  4.7768e-03,\n",
       "                      -3.8693e-03,  9.8540e-03, -8.6633e-03, -6.2785e-03, -1.8505e-02,\n",
       "                      -9.9820e-03, -1.1923e-05,  1.6003e-02, -1.2047e-02,  1.2562e-02,\n",
       "                       4.5174e-03,  8.5935e-03, -6.3272e-03, -1.4336e-03,  2.1240e-02,\n",
       "                       3.5608e-03, -1.0999e-02, -1.5257e-03,  7.5104e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.0.1.running_mean',\n",
       "              tensor([-3.2967e-01, -3.9153e-02, -6.6658e-01, -1.4451e-01, -3.7049e-01,\n",
       "                      -1.8816e-01, -5.6564e-02, -6.2019e-01,  8.6744e-01,  5.1065e-01,\n",
       "                       5.1709e-02, -1.3599e-01,  2.7698e-01, -8.5152e-01, -2.5491e-01,\n",
       "                      -1.3458e-01,  5.8681e-02, -7.2455e-01,  1.2618e+00, -2.8236e-01,\n",
       "                      -4.6423e-01, -3.2596e-01, -3.4369e-01,  3.4760e-01,  1.8911e-01,\n",
       "                      -2.1844e-01,  7.1364e-02, -1.5297e-01, -3.9064e-01,  1.8795e-01,\n",
       "                      -6.8499e-01, -7.0110e-01, -7.8917e-01,  2.7971e-01,  3.5106e-01,\n",
       "                      -3.8349e-01,  4.3666e-01, -6.1573e-01, -1.3775e-01, -3.8474e-01,\n",
       "                      -5.5215e-01, -7.2952e-04, -6.2953e-01, -3.3484e-01,  7.0126e-01,\n",
       "                      -7.2212e-01, -3.9999e-01,  4.5686e-02,  1.4969e-01, -3.1667e-01,\n",
       "                       2.4763e-01,  3.2311e-01,  8.9678e-01, -5.2978e-03, -2.5350e-01,\n",
       "                      -7.1559e-01,  1.7360e-01,  1.6877e-01,  1.5529e-01, -7.5959e-01,\n",
       "                      -1.3622e-01, -1.5824e-01, -1.3703e-01,  1.0238e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.0.1.running_var',\n",
       "              tensor([0.3285, 0.3413, 0.1737, 0.3383, 0.1023, 0.1168, 0.2615, 0.2192, 1.1763,\n",
       "                      1.8198, 0.2739, 0.0949, 0.1817, 0.2172, 0.3546, 0.1337, 0.1192, 0.0897,\n",
       "                      1.3786, 1.0233, 0.3726, 0.2219, 0.2441, 0.2901, 0.1207, 0.1242, 0.2375,\n",
       "                      0.1079, 0.4603, 0.1063, 0.2290, 0.2517, 0.2216, 0.2103, 0.1326, 0.0678,\n",
       "                      0.0982, 0.1481, 0.4446, 0.1689, 0.1410, 0.2853, 0.5928, 0.1894, 1.0746,\n",
       "                      0.5542, 0.1596, 0.3659, 0.8283, 0.5587, 0.2637, 0.4427, 0.5629, 0.0843,\n",
       "                      0.2756, 0.0880, 0.1890, 0.2800, 0.3641, 0.1700, 0.1601, 0.3774, 0.1645,\n",
       "                      0.2921], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.2.convpath.0.1.0.weight',\n",
       "              tensor([[[ 0.0640,  0.0503, -0.0179, -0.1204,  0.0662],\n",
       "                       [-0.0277,  0.0530, -0.0696,  0.0966,  0.0788],\n",
       "                       [-0.0802, -0.0350, -0.0427, -0.0968,  0.0195],\n",
       "                       ...,\n",
       "                       [-0.0565, -0.0376, -0.0042,  0.1552, -0.0679],\n",
       "                       [-0.0381,  0.0058, -0.0195,  0.1849,  0.0175],\n",
       "                       [-0.0399,  0.1749, -0.0332, -0.0042,  0.1379]],\n",
       "              \n",
       "                      [[-0.0218,  0.0754,  0.1295,  0.1705,  0.0328],\n",
       "                       [-0.0254, -0.0737, -0.0940, -0.0510,  0.0290],\n",
       "                       [ 0.0725, -0.0674, -0.0428, -0.0116, -0.0693],\n",
       "                       ...,\n",
       "                       [-0.0133,  0.0700,  0.0033, -0.0816,  0.0349],\n",
       "                       [ 0.0849,  0.0050, -0.0462, -0.0440,  0.1171],\n",
       "                       [-0.0054, -0.0612, -0.0168, -0.1379,  0.0123]],\n",
       "              \n",
       "                      [[ 0.0157,  0.1279,  0.0245, -0.0729, -0.0894],\n",
       "                       [-0.1057, -0.0653,  0.0606, -0.0190,  0.0418],\n",
       "                       [-0.1371,  0.0737,  0.0561, -0.0092, -0.0349],\n",
       "                       ...,\n",
       "                       [ 0.0511, -0.0160,  0.0816, -0.1216, -0.1560],\n",
       "                       [-0.0967,  0.0492, -0.0260,  0.0109, -0.0239],\n",
       "                       [-0.0196, -0.0609, -0.0373, -0.1247,  0.0432]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0235, -0.1488,  0.0184, -0.0346,  0.0250],\n",
       "                       [ 0.0932, -0.1516, -0.0974, -0.0095,  0.0476],\n",
       "                       [-0.0590, -0.0941,  0.0122, -0.0764,  0.0366],\n",
       "                       ...,\n",
       "                       [-0.0107,  0.0310, -0.0095, -0.0037, -0.2250],\n",
       "                       [-0.0463, -0.0238,  0.1784, -0.0459,  0.0934],\n",
       "                       [-0.0757, -0.1031, -0.0252, -0.0364, -0.1420]],\n",
       "              \n",
       "                      [[ 0.0908,  0.0338,  0.1147, -0.0511, -0.0121],\n",
       "                       [ 0.0419,  0.0296,  0.0499,  0.1017, -0.1364],\n",
       "                       [-0.1014,  0.0257,  0.0062, -0.0811,  0.1540],\n",
       "                       ...,\n",
       "                       [-0.0584, -0.0031, -0.0786, -0.0384,  0.1889],\n",
       "                       [ 0.0092, -0.1163,  0.0110, -0.0132,  0.0251],\n",
       "                       [ 0.1333, -0.0061,  0.1475, -0.0111, -0.0038]],\n",
       "              \n",
       "                      [[-0.1530,  0.0294, -0.0312, -0.1085,  0.0727],\n",
       "                       [ 0.0472, -0.0804, -0.0971,  0.0183, -0.1105],\n",
       "                       [-0.0830, -0.1793, -0.0079,  0.0241, -0.0578],\n",
       "                       ...,\n",
       "                       [ 0.0029,  0.1342,  0.0206,  0.0863,  0.0962],\n",
       "                       [-0.1063, -0.0248,  0.0383,  0.1320,  0.1679],\n",
       "                       [ 0.0563,  0.0553,  0.0082,  0.0663,  0.1152]]], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.1.1.weight',\n",
       "              tensor([0.9524, 0.9690, 0.9670, 0.9751, 0.9931, 0.9344, 1.0130, 0.9564, 0.9835,\n",
       "                      0.9765, 0.9833, 0.9700, 0.9594, 0.9645, 0.9682, 0.9667, 0.9245, 0.9604,\n",
       "                      0.9985, 0.9499, 0.9425, 0.9916, 0.9515, 0.9483, 0.9705, 0.9623, 0.9695,\n",
       "                      0.9497, 0.9833, 0.9629, 0.9405, 0.9676, 0.9640, 0.9672, 0.9945, 0.9558,\n",
       "                      0.9710, 0.9613, 0.9623, 0.9538, 1.0019, 0.9743, 0.9480, 0.9738, 0.9568,\n",
       "                      0.9477, 0.9596, 0.9819, 0.9575, 0.9939, 0.9720, 0.9466, 0.9592, 0.9637,\n",
       "                      0.9303, 0.9777, 0.9673, 0.9387, 0.9819, 0.9779, 0.9859, 0.9819, 0.9811,\n",
       "                      0.9720], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.1.1.bias',\n",
       "              tensor([ 2.7470e-03, -1.3765e-02,  6.0983e-03, -4.1245e-04,  5.1237e-03,\n",
       "                      -8.1063e-05, -1.5589e-02,  6.4030e-03,  1.3215e-03,  7.0557e-04,\n",
       "                       6.4068e-03, -1.6382e-02, -1.9350e-02,  1.0091e-02,  8.8647e-03,\n",
       "                       3.3026e-03, -2.7496e-02, -1.7042e-02, -3.3820e-03, -2.7452e-03,\n",
       "                      -1.3998e-02,  2.7501e-03, -3.0523e-02, -3.5469e-02, -3.5460e-04,\n",
       "                       9.6738e-03,  1.3382e-02,  2.7688e-03,  1.0512e-02, -8.7872e-03,\n",
       "                      -1.9938e-02,  1.1889e-02, -3.1059e-02, -2.5302e-02,  8.5192e-03,\n",
       "                      -4.5392e-03,  1.5666e-02, -1.5421e-02, -2.6320e-02, -9.8213e-03,\n",
       "                       1.8944e-02,  4.0188e-03,  6.4368e-03, -4.7974e-03, -2.2776e-02,\n",
       "                      -1.8603e-03, -6.9103e-03,  2.6461e-02, -1.1599e-02, -4.4005e-05,\n",
       "                       3.9116e-03, -1.2824e-03, -8.4190e-03, -2.4090e-02, -1.9181e-02,\n",
       "                       2.9037e-02,  1.8839e-03,  1.1910e-03,  8.6546e-03,  1.9068e-02,\n",
       "                      -6.6260e-03,  2.3253e-02, -1.3991e-02, -4.3950e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.1.1.running_mean',\n",
       "              tensor([-0.3747,  0.7249, -0.0904,  0.2532, -0.5003, -0.0956, -0.1688,  0.0421,\n",
       "                       0.3087,  0.8061,  0.2120, -0.1280, -0.1954, -0.6034,  0.2099, -0.4808,\n",
       "                      -0.2288,  0.1844, -0.1454,  0.0414,  0.0970,  0.0087,  0.0031,  0.4263,\n",
       "                      -0.4281,  0.2461, -0.1865, -0.8033,  0.7010, -0.2709, -0.1924,  0.3431,\n",
       "                       0.1772,  0.3815,  0.2237, -0.2250, -0.1793, -0.0759,  0.1836, -0.2223,\n",
       "                       0.5368, -0.1475, -0.0458, -0.1367,  0.7305, -0.7653, -0.3082, -0.2958,\n",
       "                       0.1892,  0.4999,  0.7705,  0.3761, -0.1520, -0.7156, -0.8855,  0.1022,\n",
       "                       0.0028,  0.1753, -0.3458, -0.6135,  1.0683, -1.1924,  0.6468,  0.3145],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.1.1.running_var',\n",
       "              tensor([0.4645, 0.7083, 0.6411, 0.6405, 0.5013, 0.4923, 0.5241, 0.5759, 0.5142,\n",
       "                      0.7873, 0.3988, 0.4638, 0.4338, 0.7547, 0.6025, 0.5707, 0.7279, 0.4259,\n",
       "                      0.6474, 0.9526, 0.5976, 0.6822, 1.0449, 0.7574, 0.4651, 0.7870, 0.6851,\n",
       "                      0.7495, 0.9418, 0.2691, 0.7484, 0.7944, 0.8600, 0.3978, 0.3830, 0.4585,\n",
       "                      0.4799, 0.4525, 0.9228, 0.4628, 0.3921, 0.6896, 0.5607, 0.6229, 0.9776,\n",
       "                      0.6091, 0.6134, 0.4779, 0.3467, 0.5241, 0.6906, 0.5199, 0.3914, 0.4744,\n",
       "                      0.5899, 0.6030, 0.6422, 0.7384, 0.4384, 0.4773, 0.5557, 1.0260, 0.5519,\n",
       "                      0.7797], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.2.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.2244],\n",
       "                       [ 0.2367],\n",
       "                       [ 0.1866],\n",
       "                       ...,\n",
       "                       [ 0.1014],\n",
       "                       [-0.0672],\n",
       "                       [-0.0143]],\n",
       "              \n",
       "                      [[ 0.1361],\n",
       "                       [-0.0172],\n",
       "                       [-0.0235],\n",
       "                       ...,\n",
       "                       [-0.1010],\n",
       "                       [-0.1749],\n",
       "                       [-0.0074]],\n",
       "              \n",
       "                      [[-0.0752],\n",
       "                       [ 0.1052],\n",
       "                       [-0.0228],\n",
       "                       ...,\n",
       "                       [-0.1157],\n",
       "                       [-0.1313],\n",
       "                       [ 0.0004]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1466],\n",
       "                       [-0.3195],\n",
       "                       [ 0.0626],\n",
       "                       ...,\n",
       "                       [-0.1564],\n",
       "                       [ 0.0305],\n",
       "                       [-0.0880]],\n",
       "              \n",
       "                      [[-0.0984],\n",
       "                       [ 0.1059],\n",
       "                       [ 0.1134],\n",
       "                       ...,\n",
       "                       [-0.0243],\n",
       "                       [-0.1528],\n",
       "                       [ 0.0189]],\n",
       "              \n",
       "                      [[-0.2947],\n",
       "                       [ 0.0384],\n",
       "                       [-0.1119],\n",
       "                       ...,\n",
       "                       [ 0.1308],\n",
       "                       [-0.1934],\n",
       "                       [ 0.1931]]], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.2.1.weight',\n",
       "              tensor([-1.7022e-03, -1.1376e-02, -1.3251e-02,  5.4066e-03,  5.2605e-03,\n",
       "                       2.1662e-02, -1.0669e-03, -1.5245e-02,  8.5076e-03, -4.7421e-03,\n",
       "                       1.2559e-02,  1.7550e-02, -1.6513e-02, -1.0280e-03,  1.5813e-02,\n",
       "                      -5.4644e-02, -3.7853e-02, -1.8809e-04,  1.0351e-02, -3.6274e-03,\n",
       "                      -1.1859e-02, -3.4023e-03, -2.3923e-02, -1.6862e-02, -6.0764e-03,\n",
       "                       8.0165e-03, -8.0430e-03, -2.9811e-03, -1.2213e-02,  1.0960e-03,\n",
       "                      -5.2426e-03,  6.5109e-02, -1.0544e-03, -2.0072e-02, -3.2147e-02,\n",
       "                       8.5112e-04,  2.4154e-03, -2.0200e-02,  1.4544e-02, -1.5003e-02,\n",
       "                       1.8892e-02,  2.6847e-02,  6.2115e-03,  1.6933e-02, -1.0358e-02,\n",
       "                       1.2553e-02,  8.0310e-03,  7.3795e-03, -4.4583e-02, -1.5242e-03,\n",
       "                       8.8975e-03,  1.2235e-02, -8.5119e-03,  5.0601e-03,  6.8982e-03,\n",
       "                       2.8665e-02,  2.0481e-04, -2.2551e-02, -1.7763e-02, -1.6430e-02,\n",
       "                      -2.7394e-02, -1.2619e-02,  5.1490e-03,  2.5771e-03, -3.2446e-02,\n",
       "                       1.6769e-02,  1.1167e-02,  2.5183e-02,  1.1565e-02,  9.0588e-03,\n",
       "                      -1.0020e-02,  3.0873e-02,  1.8678e-02,  1.6038e-02, -2.4860e-02,\n",
       "                      -1.9459e-02,  1.2336e-02, -1.2152e-02,  4.4370e-03, -1.7990e-02,\n",
       "                       9.3680e-03, -5.5566e-03,  1.6287e-02,  1.7906e-02, -1.3730e-02,\n",
       "                       2.0360e-02, -4.1745e-02,  1.9214e-02,  6.0129e-03, -1.8335e-02,\n",
       "                       1.3433e-02,  2.7189e-02,  2.0968e-05,  2.5771e-03, -1.1901e-02,\n",
       "                       5.6859e-03, -1.5649e-02, -1.7254e-02,  1.9577e-02,  1.7229e-02,\n",
       "                       6.8233e-03, -2.2046e-02, -1.6678e-02, -2.5229e-02, -1.0523e-02,\n",
       "                       1.7920e-02,  9.8209e-03, -1.0585e-02,  3.0046e-02,  7.0828e-03,\n",
       "                       1.1450e-02,  1.0226e-02, -1.4789e-03,  9.4695e-03,  7.8820e-03,\n",
       "                       2.8922e-02,  9.2448e-03, -2.1661e-02,  3.3809e-03,  5.0388e-03,\n",
       "                       1.0983e-02, -1.1586e-02,  3.4584e-04, -1.7022e-02,  2.5300e-02,\n",
       "                       2.1670e-02,  1.0669e-02,  1.5832e-03,  1.3557e-02, -1.2687e-02,\n",
       "                       1.1940e-02,  2.5415e-02, -4.0661e-03, -1.5388e-02, -1.9747e-02,\n",
       "                      -2.5839e-02,  7.6751e-03, -1.0887e-02,  1.9855e-02,  1.1414e-02,\n",
       "                      -7.6104e-04,  2.0603e-04, -1.0158e-03, -1.0813e-03, -3.0590e-03,\n",
       "                       4.9907e-03, -1.3375e-02, -1.3059e-02, -2.7876e-02, -1.3792e-03,\n",
       "                      -2.5615e-02, -9.0706e-03,  6.5247e-03, -9.4027e-04, -2.5703e-03,\n",
       "                       4.5885e-03, -6.3975e-03,  1.1728e-03, -3.9283e-03,  3.4310e-03,\n",
       "                      -7.3474e-03,  2.3849e-02,  2.2057e-02,  2.1656e-02, -3.8555e-03,\n",
       "                       1.6120e-02, -3.3966e-03,  2.5070e-03, -7.4572e-03, -9.9572e-03,\n",
       "                       1.5717e-02,  1.4784e-02, -8.6057e-03,  1.9095e-02, -5.4790e-03,\n",
       "                       3.0067e-02, -3.7296e-02,  2.8053e-02,  4.5763e-03,  6.6212e-03,\n",
       "                       4.3536e-03,  6.2611e-03,  9.4757e-03, -7.4222e-03, -7.8226e-03,\n",
       "                       1.7546e-03,  2.4835e-03,  3.4610e-02,  1.4749e-02,  4.1243e-03,\n",
       "                      -2.8901e-03, -1.9672e-02,  1.1439e-02, -2.6164e-02, -2.7266e-02,\n",
       "                      -5.8925e-03, -1.7949e-05, -1.2002e-02,  8.1637e-03,  2.3852e-02,\n",
       "                      -1.7630e-03, -1.0560e-02, -1.0996e-02,  9.7427e-03,  1.1905e-02,\n",
       "                       1.2258e-02, -1.2684e-02,  6.6713e-03, -2.8566e-03,  1.2590e-02,\n",
       "                       1.7187e-02,  3.0867e-03,  2.5546e-03, -3.6672e-03, -2.8883e-03,\n",
       "                       1.3775e-02,  4.5662e-03, -9.9767e-03,  2.0074e-02,  4.2469e-03,\n",
       "                       1.3227e-02, -1.2160e-02, -1.4508e-02,  1.5343e-02,  1.3865e-02,\n",
       "                       1.3456e-02, -3.1871e-03, -3.5910e-03,  5.2389e-02, -6.1178e-04,\n",
       "                       1.5347e-02,  2.6553e-03, -6.7049e-03,  1.2972e-03,  1.6571e-02,\n",
       "                      -2.5664e-02, -6.8891e-03,  1.1461e-02, -3.2691e-03, -2.7285e-02,\n",
       "                       1.8714e-02,  2.5263e-02, -3.5005e-03,  1.2603e-02, -1.2232e-02,\n",
       "                      -1.3414e-02,  2.2626e-03,  2.1878e-03, -1.2032e-02,  4.0404e-02,\n",
       "                       2.4400e-02, -8.6483e-03, -1.0482e-02,  1.7714e-02, -1.3392e-02,\n",
       "                       4.0087e-02], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.2.1.bias',\n",
       "              tensor([-2.6506e-03, -2.7597e-03,  1.8489e-02,  7.1597e-03,  5.3737e-03,\n",
       "                       3.4115e-03,  2.1322e-02,  7.9633e-04,  1.0076e-02,  2.1337e-02,\n",
       "                       6.5399e-03, -7.9954e-03,  1.2075e-02, -6.2468e-03,  4.7535e-03,\n",
       "                       7.7885e-03,  1.7050e-02, -3.2981e-04,  1.4969e-02, -8.1884e-03,\n",
       "                      -3.8657e-03,  3.2743e-03,  2.0814e-03,  6.6063e-03, -5.2091e-03,\n",
       "                      -1.3007e-02,  6.7238e-03,  1.0376e-02,  1.1016e-03, -1.3589e-03,\n",
       "                       8.1286e-03,  7.9499e-03, -7.9539e-03,  1.6475e-02,  1.7196e-02,\n",
       "                       7.2007e-03,  9.9995e-04,  2.8488e-02,  9.7364e-03,  1.1173e-02,\n",
       "                      -1.7008e-04,  1.5342e-02, -9.6732e-03,  4.3593e-03,  1.1487e-02,\n",
       "                      -1.0231e-02,  7.2345e-03,  4.1771e-03, -1.1182e-02,  7.9030e-03,\n",
       "                       8.4675e-03,  2.2596e-03,  8.3431e-03,  1.6841e-02,  4.1280e-03,\n",
       "                      -1.1390e-03,  7.1495e-03,  5.5032e-03,  7.4040e-03,  8.2298e-03,\n",
       "                      -7.2225e-03,  1.7846e-03, -1.2505e-03,  1.0236e-02, -4.2406e-03,\n",
       "                       1.3371e-02, -1.1343e-02,  1.2300e-02,  4.6490e-03, -9.4152e-03,\n",
       "                       2.4298e-03,  1.1077e-02,  9.0883e-03, -8.3255e-03,  1.4961e-02,\n",
       "                       1.7883e-02, -1.0875e-03,  3.2563e-03,  3.9161e-03,  6.1038e-03,\n",
       "                       1.0946e-02, -5.6871e-03,  8.1497e-03,  2.4928e-03, -6.9493e-04,\n",
       "                       1.1725e-02,  5.1670e-03,  2.9004e-03,  9.7825e-03,  9.7240e-03,\n",
       "                      -2.7851e-03,  2.3168e-02,  1.6959e-02, -3.1885e-04,  1.3151e-03,\n",
       "                      -1.3790e-02,  2.8626e-03,  2.3489e-04,  1.3942e-02,  7.8279e-03,\n",
       "                       2.5351e-02,  6.9576e-03, -1.1933e-03, -4.0229e-03,  9.4992e-03,\n",
       "                       1.4115e-03,  2.5818e-03,  4.1050e-03,  4.2996e-03,  8.3192e-03,\n",
       "                      -7.1330e-03, -6.6807e-03,  6.3420e-03,  1.5616e-02,  1.2415e-02,\n",
       "                       8.0969e-03,  1.1597e-02,  2.6486e-03,  1.2993e-03, -1.5338e-02,\n",
       "                       2.0556e-03,  1.3725e-02,  1.2186e-03,  1.4313e-03, -1.2165e-02,\n",
       "                       1.3019e-02,  1.7083e-02,  2.7128e-03, -1.1586e-03,  9.7261e-03,\n",
       "                      -1.5498e-03,  1.5748e-02,  1.4602e-02,  1.2564e-02,  1.1937e-02,\n",
       "                      -4.9515e-03,  1.8337e-02,  1.2670e-02,  1.6142e-02,  5.3544e-03,\n",
       "                       3.9446e-03, -2.9763e-03, -5.1065e-03,  8.6812e-03, -5.8302e-03,\n",
       "                       9.0792e-03,  3.9068e-04, -2.8040e-03,  1.3666e-02,  1.0866e-02,\n",
       "                       6.6934e-04,  1.3275e-02,  3.8989e-03,  1.5336e-02,  1.4110e-02,\n",
       "                       1.1314e-02,  1.0989e-04,  9.8440e-03, -6.0635e-03, -1.2074e-02,\n",
       "                      -3.7622e-04, -3.5491e-03, -1.6917e-04,  1.6661e-02,  1.2875e-02,\n",
       "                       2.2027e-03, -8.2765e-03,  9.7156e-03,  2.0198e-03,  1.6068e-02,\n",
       "                       5.2907e-03,  6.0659e-03,  1.2907e-02,  8.2801e-03, -1.4323e-02,\n",
       "                      -4.8243e-03, -2.0621e-03,  1.4657e-02,  6.2861e-03,  4.8946e-03,\n",
       "                      -2.3297e-03,  9.3704e-03, -9.0418e-03, -1.0441e-02,  1.8461e-02,\n",
       "                       9.8076e-03,  1.5484e-02,  1.3885e-02, -5.1067e-03, -3.6825e-04,\n",
       "                       7.5573e-03, -2.4969e-03,  1.4309e-02, -1.6113e-02,  8.7284e-03,\n",
       "                       8.9995e-03, -2.4929e-03,  1.5093e-02,  8.7488e-03, -9.1053e-03,\n",
       "                       5.3569e-03,  1.3902e-02,  2.0318e-02,  1.7466e-02,  3.5519e-03,\n",
       "                      -5.6560e-03,  1.4802e-02, -2.3311e-03,  1.1098e-02,  5.1774e-03,\n",
       "                       2.1149e-03,  1.2048e-02,  1.3731e-02,  6.7681e-03,  1.7393e-02,\n",
       "                       1.2463e-03,  3.7993e-03, -1.1772e-03,  5.0294e-03, -1.1857e-03,\n",
       "                      -1.0684e-02, -9.0822e-04,  6.9600e-03,  2.5757e-02, -1.9999e-03,\n",
       "                       4.3512e-03, -9.6917e-04,  2.5704e-03, -1.6033e-02,  1.3199e-02,\n",
       "                       1.6811e-02, -4.8412e-05,  1.1552e-02,  1.1878e-02,  1.1082e-02,\n",
       "                       2.9774e-03,  7.1287e-03, -4.4003e-03,  1.1104e-02,  8.4545e-03,\n",
       "                       9.5603e-03,  2.6524e-03,  3.1871e-03,  1.4453e-02,  3.4078e-03,\n",
       "                       1.3989e-02,  4.8366e-03,  9.8061e-03,  1.7184e-03, -6.5976e-03,\n",
       "                       1.5279e-02,  1.0562e-02,  2.2532e-02,  2.2955e-02,  1.2863e-02,\n",
       "                       2.0834e-03], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.2.1.running_mean',\n",
       "              tensor([ 0.3522, -0.0813, -0.1304, -0.2954, -0.7640,  0.1023, -0.0973,  0.1243,\n",
       "                      -0.1896, -0.2991, -0.1124,  0.2451, -0.0316,  0.2352, -0.1390,  0.5835,\n",
       "                       0.4169, -0.0889, -0.5751, -0.4950, -0.1464,  0.2097,  0.2573,  0.7620,\n",
       "                       0.3616, -0.3275, -0.0792,  0.0384,  0.0427,  0.4075,  0.5461, -0.2450,\n",
       "                       0.0164,  0.2700, -0.4034,  0.7175, -0.1472, -0.1556, -0.3581, -0.5702,\n",
       "                       0.0107,  0.5626,  0.4257,  0.5722, -0.2764, -0.1523, -0.9421,  0.0461,\n",
       "                      -0.1601,  0.2258, -0.1996, -0.0693, -0.2103, -0.0586, -0.3182, -0.1521,\n",
       "                       0.3878,  0.6814, -0.5350, -0.3652,  0.3349,  0.3229,  0.3232,  0.1635,\n",
       "                       0.2291,  0.1392, -0.0300, -0.5352,  0.4433, -0.3194, -0.1381, -0.3123,\n",
       "                       0.1800,  0.1937,  0.0971, -0.2848,  0.3931,  0.5866,  0.3407, -0.0312,\n",
       "                       0.6719, -0.1162, -0.3073, -0.4684,  0.0644, -0.4033,  0.6510,  0.0240,\n",
       "                       0.4803, -0.1145,  0.0616,  0.5029,  0.0435, -0.1985,  0.2811, -0.0695,\n",
       "                       0.2851,  0.1119,  0.2872,  0.6235, -0.6560,  0.0222, -0.4503,  0.4972,\n",
       "                      -0.1368, -0.1217, -0.1437, -0.5908, -0.7946, -0.1542, -0.3017, -0.8411,\n",
       "                      -0.1843, -0.0681,  0.3614, -0.3598, -0.4919,  0.5461, -0.6681,  0.1425,\n",
       "                      -0.0775, -0.0919, -0.1824, -0.1213, -0.0881, -0.2658, -0.3546, -0.4458,\n",
       "                      -0.3698,  0.7559,  0.1240,  0.4620, -0.1958, -0.0247,  0.0033, -0.1337,\n",
       "                      -0.6016,  0.3826,  0.3471, -0.2096, -0.1403,  0.1143, -0.2747, -0.3022,\n",
       "                      -0.5138,  0.3154,  0.2067, -0.1045, -0.4310,  0.1182, -0.0102,  0.5126,\n",
       "                       0.6497, -0.0100, -0.0527, -0.1573,  0.2576, -0.2350,  0.3723, -0.0509,\n",
       "                      -0.0333, -0.1526, -0.2257, -0.6446, -0.2851,  0.3317, -0.1569,  0.2836,\n",
       "                       0.1165, -0.0604,  0.4053,  0.1025, -0.0403, -0.0850, -0.3558,  0.3271,\n",
       "                      -0.0161, -0.6606, -0.3766, -0.1923,  0.7222, -0.1280, -0.3245,  0.2282,\n",
       "                      -0.2416, -0.2041,  0.5437,  0.3892, -0.1023,  0.4961, -0.6835, -0.0049,\n",
       "                       0.0326, -0.3170, -0.3632,  0.2783,  0.0784,  0.8466, -0.4194,  0.5559,\n",
       "                       0.2646,  0.1389, -0.5192, -0.8104, -0.6475,  0.3737,  0.1195, -0.1991,\n",
       "                      -0.1304, -0.3789, -0.0459,  0.0890, -0.4762,  0.3223,  0.2913, -0.0857,\n",
       "                      -0.2560, -0.3350, -0.2318, -0.5118, -0.1558,  0.1437, -0.0434,  0.5131,\n",
       "                       0.2125, -0.0766, -0.7140,  0.4749,  0.1095,  0.1000,  0.2875,  0.1644,\n",
       "                       0.4801, -0.5007,  0.7435, -0.3381, -0.3252,  0.2114, -0.1248, -0.4524,\n",
       "                       0.5585,  0.0158,  1.2131, -0.0219, -0.6156, -0.0477, -0.0438, -0.4385,\n",
       "                      -0.0255, -0.4030, -0.0832, -0.1656,  0.6168, -0.1050, -0.1869, -0.7728],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.2.1.running_var',\n",
       "              tensor([0.2378, 0.4902, 0.3368, 0.5906, 0.3393, 0.2509, 0.0600, 0.2325, 0.2108,\n",
       "                      0.3386, 0.3620, 0.2510, 0.2186, 0.1726, 0.4183, 0.3221, 0.4245, 0.2269,\n",
       "                      0.4129, 0.5467, 0.1195, 0.4282, 0.4757, 0.3516, 0.4977, 0.2466, 0.2125,\n",
       "                      0.0584, 0.1759, 0.2186, 0.7331, 0.3321, 0.1434, 0.5338, 0.5722, 0.4480,\n",
       "                      0.2087, 0.4217, 0.4184, 0.6348, 0.3648, 0.2657, 0.1909, 0.5662, 0.5494,\n",
       "                      0.4367, 0.3972, 0.1830, 0.4380, 0.2261, 0.4417, 0.3027, 0.3028, 0.3174,\n",
       "                      0.1868, 0.4151, 0.3554, 0.3814, 0.9358, 0.4534, 0.2225, 0.2971, 0.2342,\n",
       "                      0.2162, 0.4246, 0.4172, 1.1902, 0.2424, 0.3305, 0.3207, 0.3558, 0.3134,\n",
       "                      0.3076, 0.5999, 0.4427, 0.4164, 0.2763, 0.2535, 0.3296, 0.4463, 0.2715,\n",
       "                      0.4236, 0.3746, 0.5306, 0.5046, 0.3750, 0.4778, 0.4524, 0.4178, 0.3538,\n",
       "                      0.3656, 0.2036, 0.1546, 0.0711, 0.2048, 0.1856, 0.3902, 0.2982, 0.3169,\n",
       "                      0.3354, 0.4942, 0.3836, 0.3643, 0.5595, 0.2144, 0.5039, 0.3139, 0.5496,\n",
       "                      0.9384, 0.2348, 0.4127, 0.2349, 0.2948, 0.2848, 0.3347, 0.6235, 0.4990,\n",
       "                      0.3871, 0.5138, 0.4266, 0.1477, 0.3579, 0.3220, 0.3552, 0.4692, 0.6977,\n",
       "                      0.2203, 0.2437, 0.1521, 0.2410, 0.2712, 0.1746, 0.3575, 0.3617, 0.2571,\n",
       "                      0.3429, 0.2563, 0.4791, 0.2951, 0.3356, 0.1367, 0.1192, 0.2966, 0.1963,\n",
       "                      0.4084, 0.3080, 0.2643, 0.5187, 0.1951, 0.3701, 0.6142, 0.2385, 0.4989,\n",
       "                      0.2441, 0.2401, 0.1438, 0.3080, 0.2142, 0.1981, 0.2093, 0.0906, 0.2960,\n",
       "                      0.2971, 0.3199, 0.3755, 0.5390, 0.4250, 0.2757, 0.4050, 0.2706, 0.4222,\n",
       "                      0.2824, 0.2964, 0.2135, 0.6213, 0.3488, 0.4648, 0.2685, 0.2096, 0.4153,\n",
       "                      0.4092, 0.0872, 0.4577, 0.5605, 0.3782, 0.2821, 0.3524, 0.2713, 0.4215,\n",
       "                      0.2953, 0.2687, 0.2936, 0.1806, 0.4749, 0.2269, 0.2818, 0.1544, 0.3318,\n",
       "                      0.3626, 0.5501, 0.0863, 0.3014, 0.2974, 0.5053, 0.6464, 0.5075, 0.1905,\n",
       "                      0.0869, 0.2248, 0.4334, 0.1802, 0.1772, 0.1590, 0.2956, 0.1407, 0.2136,\n",
       "                      0.3377, 0.4073, 0.4597, 0.5461, 0.1621, 0.3343, 0.2630, 0.4574, 0.2107,\n",
       "                      0.2579, 0.5428, 0.1945, 0.3673, 0.3057, 0.3077, 0.3292, 0.4597, 0.2568,\n",
       "                      0.6644, 0.3426, 0.1052, 0.3926, 0.2360, 0.2873, 0.2087, 0.1994, 0.5011,\n",
       "                      0.3198, 0.4959, 0.2558, 0.1818, 0.2627, 0.1612, 0.3269, 0.6329, 0.3860,\n",
       "                      0.2504, 0.8461, 0.1192, 0.5047], dtype=torch.float64)),\n",
       "             ('6.2.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.3.convs.0.0.weight',\n",
       "              tensor([[[ 0.0836],\n",
       "                       [-0.0142],\n",
       "                       [-0.2330],\n",
       "                       ...,\n",
       "                       [ 0.0220],\n",
       "                       [-0.0216],\n",
       "                       [ 0.1154]],\n",
       "              \n",
       "                      [[ 0.0897],\n",
       "                       [-0.0583],\n",
       "                       [-0.0872],\n",
       "                       ...,\n",
       "                       [ 0.0294],\n",
       "                       [-0.0127],\n",
       "                       [ 0.0977]],\n",
       "              \n",
       "                      [[ 0.1077],\n",
       "                       [ 0.0071],\n",
       "                       [-0.0889],\n",
       "                       ...,\n",
       "                       [ 0.1597],\n",
       "                       [-0.0588],\n",
       "                       [-0.0419]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0384],\n",
       "                       [-0.0324],\n",
       "                       [-0.0878],\n",
       "                       ...,\n",
       "                       [ 0.1114],\n",
       "                       [ 0.0493],\n",
       "                       [-0.0550]],\n",
       "              \n",
       "                      [[-0.0477],\n",
       "                       [-0.0720],\n",
       "                       [-0.0068],\n",
       "                       ...,\n",
       "                       [-0.0667],\n",
       "                       [-0.0595],\n",
       "                       [-0.0101]],\n",
       "              \n",
       "                      [[ 0.0441],\n",
       "                       [-0.0778],\n",
       "                       [-0.0917],\n",
       "                       ...,\n",
       "                       [-0.0944],\n",
       "                       [ 0.0606],\n",
       "                       [-0.1236]]], dtype=torch.float64)),\n",
       "             ('6.3.convs.0.1.weight',\n",
       "              tensor([0.9935, 0.9731, 0.9612, 0.9738, 0.9545, 0.9781, 0.9811, 0.9550, 0.9498,\n",
       "                      0.9865, 0.9717, 0.9801, 0.9979, 0.9713, 0.9737, 0.9673, 0.9912, 0.9685,\n",
       "                      0.9740, 0.9688, 0.9852, 0.9917, 0.9636, 0.9742, 0.9627, 0.9533, 0.9680,\n",
       "                      0.9567, 0.9669, 0.9962, 0.9536, 0.9725, 0.9687, 0.9831, 0.9744, 0.9902,\n",
       "                      0.9760, 0.9582, 0.9558, 0.9759, 0.9432, 0.9873, 0.9957, 0.9624, 0.9565,\n",
       "                      0.9778, 0.9841, 0.9503, 0.9769, 0.9862, 0.9582, 0.9417, 0.9666, 0.9403,\n",
       "                      0.9589, 0.9697, 0.9408, 0.9820, 0.9826, 0.9694, 0.9604, 0.9714, 0.9497,\n",
       "                      0.9740], dtype=torch.float64)),\n",
       "             ('6.3.convs.0.1.bias',\n",
       "              tensor([ 0.0049,  0.0009,  0.0009,  0.0042,  0.0016, -0.0095,  0.0054, -0.0155,\n",
       "                       0.0024,  0.0267,  0.0041, -0.0051,  0.0226, -0.0117,  0.0080, -0.0095,\n",
       "                       0.0065, -0.0084,  0.0097, -0.0190,  0.0117,  0.0155, -0.0041,  0.0208,\n",
       "                       0.0037,  0.0010,  0.0303, -0.0134, -0.0065,  0.0315, -0.0169,  0.0191,\n",
       "                      -0.0140,  0.0043,  0.0091,  0.0245,  0.0149, -0.0093, -0.0061,  0.0071,\n",
       "                      -0.0196,  0.0135,  0.0201, -0.0065, -0.0124, -0.0202, -0.0006, -0.0115,\n",
       "                       0.0025,  0.0042, -0.0105, -0.0219,  0.0026, -0.0188, -0.0108, -0.0028,\n",
       "                       0.0005, -0.0061,  0.0174,  0.0042, -0.0018, -0.0101, -0.0141,  0.0005],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convs.0.1.running_mean',\n",
       "              tensor([-0.1689, -0.6454,  0.5007, -0.6568, -0.5218,  0.2219,  0.6869,  1.0033,\n",
       "                      -0.4050, -0.4411,  0.3008,  0.4656,  0.1833, -0.4233, -0.1463, -0.8737,\n",
       "                       0.3207, -0.3210, -0.5028, -0.2203,  0.9405, -0.1224,  0.5320, -0.6759,\n",
       "                      -0.4003, -1.3419, -0.7312,  0.2378, -0.5220, -0.0550, -0.3125, -0.0616,\n",
       "                       0.2173,  0.5440, -0.7067, -0.4562,  0.4488, -0.8552, -1.0228, -0.0434,\n",
       "                       0.2758,  0.3100, -0.0106, -0.5302, -0.2465,  0.7208, -0.5049, -0.3898,\n",
       "                       0.3156, -0.8468, -0.0516, -0.3231, -0.5626, -0.5411,  0.5492, -0.1812,\n",
       "                      -0.1690,  0.3352,  0.1052, -0.7155,  0.3739,  0.3544, -0.1342, -0.6355],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convs.0.1.running_var',\n",
       "              tensor([0.2957, 0.1850, 0.6652, 0.1615, 0.1821, 0.1174, 0.1498, 0.9403, 0.2352,\n",
       "                      0.1613, 0.1707, 0.1140, 0.2361, 0.3256, 0.2065, 0.3258, 0.1653, 0.1706,\n",
       "                      0.1365, 0.2307, 0.1310, 0.1917, 0.2583, 0.5242, 0.1197, 0.5175, 1.2508,\n",
       "                      0.0833, 0.6942, 0.2924, 0.7822, 0.1226, 0.1766, 0.1477, 0.1564, 0.2425,\n",
       "                      0.1206, 0.7851, 0.4172, 0.4345, 0.5028, 0.2169, 0.2132, 0.9674, 0.3974,\n",
       "                      0.1051, 0.1339, 0.3912, 0.3281, 0.1969, 0.2259, 0.2053, 0.2290, 0.2571,\n",
       "                      0.7919, 0.1274, 0.2036, 0.1188, 0.1055, 0.4394, 0.3305, 0.4820, 0.3490,\n",
       "                      0.4003], dtype=torch.float64)),\n",
       "             ('6.3.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.3.convs.1.0.weight',\n",
       "              tensor([[[ 4.5031e-02, -6.3458e-02, -6.3075e-02, -1.6577e-02,  5.6874e-02],\n",
       "                       [ 2.0491e-02, -2.6789e-02, -3.9041e-02,  1.5200e-02, -5.2503e-02],\n",
       "                       [ 1.9974e-02,  5.6953e-02,  4.5140e-02,  4.4333e-02, -1.0485e-01],\n",
       "                       ...,\n",
       "                       [ 9.7279e-02, -1.6135e-02, -2.0964e-02,  7.8871e-02, -1.7372e-03],\n",
       "                       [-9.4632e-02, -5.1138e-02, -5.7390e-02, -8.4832e-02, -5.1471e-02],\n",
       "                       [-4.3466e-03, -9.9913e-03,  1.4457e-01,  8.2719e-02, -1.1791e-01]],\n",
       "              \n",
       "                      [[-1.8770e-03,  4.1147e-03,  4.7226e-02,  8.6625e-02,  2.8036e-02],\n",
       "                       [ 3.2393e-02,  6.5667e-02, -2.3525e-02,  2.1569e-02,  2.3630e-02],\n",
       "                       [-2.7386e-02, -9.6487e-02, -1.9150e-02, -2.6737e-03, -7.6384e-02],\n",
       "                       ...,\n",
       "                       [-4.4700e-02,  2.5130e-02, -2.2918e-02, -6.3791e-02, -7.8412e-02],\n",
       "                       [ 5.3158e-02,  1.3616e-04,  1.0444e-01,  1.5605e-01, -6.6482e-02],\n",
       "                       [-6.2230e-03,  3.8805e-02, -5.4779e-02,  4.8002e-02,  5.7375e-02]],\n",
       "              \n",
       "                      [[-1.4027e-02, -5.6741e-02,  2.0611e-01, -9.8751e-02, -1.6259e-01],\n",
       "                       [ 6.5376e-02,  5.7862e-02, -2.7659e-02, -4.5727e-02, -1.5635e-01],\n",
       "                       [-3.7132e-02,  6.7694e-03, -1.8052e-02, -1.2627e-01,  2.8058e-02],\n",
       "                       ...,\n",
       "                       [ 5.7850e-02,  6.0785e-02, -6.1765e-02, -6.7465e-02, -4.7162e-03],\n",
       "                       [ 2.1174e-02,  1.1555e-02, -1.6849e-02,  2.9702e-02, -9.2858e-02],\n",
       "                       [-1.2654e-01, -4.5266e-02, -3.7955e-02,  3.1690e-02, -1.2174e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-3.9478e-02,  1.0042e-01, -8.3087e-02,  4.0227e-03, -6.9969e-02],\n",
       "                       [-6.1648e-02, -7.0065e-02, -6.9993e-02, -7.2487e-03,  7.3063e-02],\n",
       "                       [ 1.0302e-01, -2.9896e-02, -4.4484e-02, -1.1333e-01, -5.4941e-02],\n",
       "                       ...,\n",
       "                       [-2.3024e-03,  3.8355e-02,  2.2813e-02, -8.2025e-02,  3.9636e-02],\n",
       "                       [-7.8375e-02, -1.0918e-01,  7.3916e-02, -5.5115e-02, -6.6182e-02],\n",
       "                       [ 4.9850e-02,  1.5487e-02, -3.5750e-02, -6.2412e-03,  3.0324e-02]],\n",
       "              \n",
       "                      [[-2.8848e-02,  7.6258e-02,  2.3487e-02, -1.7766e-02,  5.5746e-02],\n",
       "                       [-1.4409e-01,  7.5147e-02, -2.4324e-02,  1.8695e-02, -9.0342e-02],\n",
       "                       [-4.0029e-02, -7.8973e-03,  2.9468e-02,  1.0257e-02, -4.5983e-02],\n",
       "                       ...,\n",
       "                       [ 6.9523e-02, -1.2981e-01,  4.3978e-02,  4.7004e-02, -1.5814e-01],\n",
       "                       [ 5.6193e-02,  6.7428e-02,  8.7977e-02, -6.6451e-02, -1.1659e-01],\n",
       "                       [ 6.6541e-03,  8.6018e-02,  1.7445e-01,  3.7791e-02,  4.5388e-02]],\n",
       "              \n",
       "                      [[ 1.9111e-02,  8.4569e-02,  9.3869e-02, -1.4621e-02,  2.5622e-02],\n",
       "                       [-2.1762e-03,  2.6920e-02, -5.7559e-02,  6.0002e-02, -8.6922e-02],\n",
       "                       [-2.2274e-02, -7.2869e-02,  2.4974e-02, -9.8059e-02, -1.1518e-01],\n",
       "                       ...,\n",
       "                       [-1.1634e-01, -1.4494e-01,  2.5907e-03,  3.9700e-03, -1.0767e-01],\n",
       "                       [ 7.5978e-03, -1.0776e-02,  3.6922e-02,  5.9500e-03, -8.0243e-02],\n",
       "                       [-1.2482e-01, -8.9399e-02, -9.5219e-02,  6.8358e-02, -4.5209e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convs.1.1.weight',\n",
       "              tensor([0.9680, 0.9565, 0.9494, 0.9710, 0.9973, 0.9857, 0.9568, 0.9794, 0.9721,\n",
       "                      0.9667, 0.9802, 0.9445, 0.9960, 0.9518, 0.9400, 0.9668, 0.9868, 0.9472,\n",
       "                      0.9522, 0.9545, 0.9489, 0.9434, 0.9712, 0.9665, 0.9481, 1.0015, 0.9505,\n",
       "                      0.9442, 0.9477, 0.9436, 0.9783, 0.9651, 0.9572, 0.9627, 0.9491, 0.9419,\n",
       "                      0.9517, 0.9593, 0.9588, 0.9845, 0.9700, 0.9549, 0.9760, 0.9631, 0.9469,\n",
       "                      0.9668, 0.9415, 0.9701, 0.9775, 0.9446, 0.9570, 0.9635, 0.9743, 0.9721,\n",
       "                      1.0181, 0.9883, 0.9804, 0.9659, 0.9889, 0.9456, 0.9781, 0.9373, 0.9710,\n",
       "                      0.9605], dtype=torch.float64)),\n",
       "             ('6.3.convs.1.1.bias',\n",
       "              tensor([-0.0030,  0.0023,  0.0096, -0.0051, -0.0052, -0.0087, -0.0128, -0.0167,\n",
       "                       0.0082, -0.0094,  0.0257, -0.0099,  0.0172, -0.0264, -0.0208, -0.0011,\n",
       "                       0.0078, -0.0333, -0.0157, -0.0061, -0.0270, -0.0129,  0.0003, -0.0076,\n",
       "                      -0.0169,  0.0250, -0.0265, -0.0228, -0.0229, -0.0067, -0.0105,  0.0138,\n",
       "                      -0.0258, -0.0145, -0.0125, -0.0164, -0.0027, -0.0085, -0.0033, -0.0064,\n",
       "                      -0.0261, -0.0053,  0.0048,  0.0069, -0.0281, -0.0302, -0.0325, -0.0138,\n",
       "                       0.0056, -0.0046, -0.0017,  0.0157, -0.0130,  0.0142,  0.0096,  0.0095,\n",
       "                       0.0096, -0.0097,  0.0218, -0.0215,  0.0114, -0.0255,  0.0010,  0.0027],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convs.1.1.running_mean',\n",
       "              tensor([ 2.3425e-01,  3.7149e-01,  4.3241e-01,  8.3932e-02, -4.2117e-01,\n",
       "                      -4.5153e-02, -8.0430e-01,  2.1780e-01, -1.6376e-01, -1.0474e-01,\n",
       "                      -6.1503e-01, -5.3871e-01, -2.4249e-01,  6.5866e-01, -7.0890e-01,\n",
       "                      -3.3458e-01,  1.4502e-01, -4.5255e-01, -3.4243e-01, -5.7911e-01,\n",
       "                      -6.2067e-01, -1.4191e-01,  2.0950e-01, -8.8122e-01,  1.0047e-01,\n",
       "                      -1.5438e+00, -7.5754e-01, -3.7798e-02, -5.3896e-01, -2.6246e-01,\n",
       "                       6.6092e-01, -1.7345e-01,  8.6860e-01, -2.6438e-01, -2.0020e-01,\n",
       "                       1.5678e-01,  8.9396e-02,  3.1140e-01,  2.9925e-01,  7.2220e-02,\n",
       "                       1.1998e+00, -2.3521e-01,  3.8395e-01,  8.7388e-04, -2.8525e-02,\n",
       "                      -2.0763e-02, -2.8935e-01, -3.0140e-01,  1.1521e+00, -5.0367e-01,\n",
       "                       2.7059e-01,  1.8194e-01, -4.8049e-01, -2.0566e-01, -3.2340e-01,\n",
       "                      -4.2698e-01, -2.9017e-01, -8.7020e-01, -9.4385e-01,  4.9539e-01,\n",
       "                      -4.2253e-01, -7.6930e-01, -5.5113e-02, -2.9616e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convs.1.1.running_var',\n",
       "              tensor([0.5746, 0.4747, 0.5640, 0.6424, 0.3706, 0.6119, 0.4254, 0.5075, 0.5688,\n",
       "                      0.4522, 0.4759, 0.4375, 0.3805, 0.5140, 0.4898, 0.4796, 0.3944, 0.4470,\n",
       "                      0.6586, 0.5441, 0.4637, 0.4697, 0.3897, 0.4250, 0.4211, 0.4002, 0.7138,\n",
       "                      0.5290, 0.3935, 0.6045, 0.4530, 0.8621, 0.4318, 0.5820, 0.5275, 0.3842,\n",
       "                      0.3985, 0.3439, 0.7150, 0.3545, 0.5025, 0.4816, 0.5740, 0.4801, 0.6412,\n",
       "                      0.3365, 0.6341, 0.4325, 0.4430, 0.6994, 0.2934, 0.5097, 0.3342, 0.6173,\n",
       "                      0.3313, 0.5447, 0.5178, 0.3036, 0.3872, 0.3721, 0.5089, 0.5584, 0.4697,\n",
       "                      0.7280], dtype=torch.float64)),\n",
       "             ('6.3.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.3.convs.2.0.weight',\n",
       "              tensor([[[-0.1076],\n",
       "                       [-0.0879],\n",
       "                       [-0.0580],\n",
       "                       ...,\n",
       "                       [ 0.0500],\n",
       "                       [ 0.0128],\n",
       "                       [ 0.0263]],\n",
       "              \n",
       "                      [[-0.2342],\n",
       "                       [-0.0028],\n",
       "                       [-0.2151],\n",
       "                       ...,\n",
       "                       [ 0.0490],\n",
       "                       [ 0.1289],\n",
       "                       [ 0.0080]],\n",
       "              \n",
       "                      [[ 0.1034],\n",
       "                       [ 0.0496],\n",
       "                       [-0.0758],\n",
       "                       ...,\n",
       "                       [-0.0451],\n",
       "                       [-0.1655],\n",
       "                       [-0.0212]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1794],\n",
       "                       [-0.0978],\n",
       "                       [-0.3339],\n",
       "                       ...,\n",
       "                       [ 0.0715],\n",
       "                       [-0.0033],\n",
       "                       [-0.0014]],\n",
       "              \n",
       "                      [[-0.0183],\n",
       "                       [-0.1509],\n",
       "                       [ 0.1345],\n",
       "                       ...,\n",
       "                       [ 0.0299],\n",
       "                       [-0.0301],\n",
       "                       [-0.0818]],\n",
       "              \n",
       "                      [[ 0.2681],\n",
       "                       [ 0.3150],\n",
       "                       [ 0.0174],\n",
       "                       ...,\n",
       "                       [ 0.2031],\n",
       "                       [-0.0307],\n",
       "                       [ 0.0048]]], dtype=torch.float64)),\n",
       "             ('6.3.convs.2.1.weight',\n",
       "              tensor([ 7.9271e-03,  1.4752e-02, -2.4944e-02,  1.0540e-02, -1.6292e-02,\n",
       "                      -1.5966e-02,  3.2396e-02, -1.2903e-02, -7.2734e-04, -4.3549e-02,\n",
       "                      -1.0139e-02, -6.7067e-03, -2.5998e-03,  1.0467e-02,  6.9312e-03,\n",
       "                      -4.5640e-02,  2.0227e-02,  1.8202e-02, -2.0453e-02, -1.0500e-03,\n",
       "                      -7.1799e-03, -1.4364e-02,  1.0086e-04, -1.5460e-02, -2.9384e-02,\n",
       "                      -1.2352e-02,  1.8998e-02,  3.4095e-03, -9.8179e-03, -3.6893e-03,\n",
       "                      -2.2751e-02,  2.7015e-02,  9.8841e-03,  1.5321e-02, -3.2800e-02,\n",
       "                       1.7462e-03,  4.4897e-03, -5.2315e-04, -9.0990e-03,  1.0988e-02,\n",
       "                       2.2826e-02,  3.2831e-02, -5.3111e-03, -8.6741e-04, -1.6954e-02,\n",
       "                      -6.4237e-03, -4.5184e-03, -2.1553e-03,  1.9586e-02,  2.0786e-03,\n",
       "                       7.2736e-03,  2.4172e-02,  1.8243e-02,  3.1963e-02,  8.5083e-03,\n",
       "                       6.1561e-02,  5.6541e-03,  3.3565e-02, -2.1821e-02,  7.7970e-03,\n",
       "                      -9.6951e-03, -1.2799e-02, -7.0902e-03, -1.3442e-02, -1.5165e-02,\n",
       "                       3.2970e-02, -1.3717e-03, -2.3781e-02,  3.1767e-02, -3.0989e-02,\n",
       "                       1.8659e-02, -1.5683e-02,  6.2696e-03, -1.0108e-02,  2.3595e-02,\n",
       "                      -2.0985e-02,  1.1475e-03, -5.1191e-03,  1.9089e-03, -6.1693e-03,\n",
       "                       1.2506e-03,  1.4818e-02, -2.6806e-02, -2.3726e-02,  1.1694e-03,\n",
       "                      -3.3108e-02, -2.6355e-02,  8.1053e-03, -1.3698e-02,  1.8181e-03,\n",
       "                      -4.5789e-03, -1.7559e-02, -2.6936e-02,  3.1706e-04, -1.3582e-02,\n",
       "                      -1.0437e-02, -1.9103e-02, -1.6111e-02,  1.5976e-02, -1.2342e-02,\n",
       "                      -1.5933e-02, -2.2652e-02, -1.7446e-02, -4.4654e-02,  1.6962e-02,\n",
       "                      -1.6748e-02,  1.5351e-02, -5.8498e-03,  5.8600e-03,  1.1966e-02,\n",
       "                      -7.9705e-03,  9.1065e-03, -2.8181e-02,  2.5419e-02, -4.4393e-03,\n",
       "                       2.8749e-02,  4.2918e-03,  2.2072e-03,  1.5599e-02, -1.1009e-02,\n",
       "                      -8.2406e-03,  4.6298e-02, -1.5521e-02,  9.4074e-03,  2.6572e-02,\n",
       "                      -1.3178e-02, -1.0459e-02,  1.7976e-02, -2.4415e-03,  1.6718e-02,\n",
       "                       1.8723e-02,  7.3763e-03,  1.3920e-02,  1.6652e-02,  1.6086e-02,\n",
       "                      -9.1912e-03, -3.6401e-02,  7.3499e-03, -2.3338e-02,  1.6216e-02,\n",
       "                      -3.6649e-03,  1.9585e-03,  8.6547e-03,  1.5867e-03,  1.8214e-02,\n",
       "                      -3.9011e-03, -3.4455e-03,  1.3634e-02,  3.0101e-02,  1.8651e-02,\n",
       "                       2.5530e-02,  2.8263e-03, -3.8641e-03,  2.9694e-02, -1.4794e-02,\n",
       "                       2.0702e-03,  3.5324e-03, -1.5048e-02, -2.2033e-03,  4.3454e-04,\n",
       "                      -3.4054e-03, -3.5716e-03, -2.8820e-02, -1.0530e-02, -3.8970e-03,\n",
       "                       6.6733e-05, -2.5009e-03, -3.4745e-02,  1.2368e-03,  3.0235e-02,\n",
       "                       2.3713e-02, -1.9599e-02,  9.5653e-03, -1.7575e-02,  3.2235e-04,\n",
       "                      -2.1831e-03, -1.5232e-02, -2.2780e-04,  3.2814e-02, -2.0912e-02,\n",
       "                      -1.6513e-02, -1.2591e-02, -1.9934e-02,  1.3690e-02, -1.7553e-02,\n",
       "                       2.1786e-04,  6.8375e-03,  1.0423e-02, -1.0923e-02,  8.3421e-03,\n",
       "                      -7.9088e-03,  6.8457e-03,  1.9326e-02,  3.0229e-02,  9.8381e-03,\n",
       "                      -2.2590e-03, -1.2541e-02,  1.0267e-02,  2.2497e-02,  6.8712e-03,\n",
       "                       7.9821e-03,  5.9914e-03, -1.2369e-02, -2.6366e-02,  2.3968e-02,\n",
       "                      -1.6106e-02,  1.4658e-02,  3.2371e-03, -2.8337e-02, -2.1815e-02,\n",
       "                      -1.1108e-02, -1.4792e-02, -9.9776e-03,  5.9600e-03,  2.0668e-02,\n",
       "                      -2.3164e-02,  6.9716e-04,  6.8160e-04,  2.1876e-02,  4.4789e-03,\n",
       "                       1.8181e-03,  2.1077e-02, -2.7272e-03, -3.8133e-02,  1.1089e-02,\n",
       "                      -7.2474e-03, -3.6176e-03,  4.6825e-03,  2.1195e-03, -3.5034e-03,\n",
       "                       1.4512e-02, -3.9083e-03, -2.5785e-02, -2.2522e-02,  1.7175e-02,\n",
       "                       1.7519e-02, -1.1759e-03,  4.7351e-03,  2.8044e-03, -8.2294e-03,\n",
       "                       2.8937e-02, -1.6456e-02,  1.3573e-02,  1.7298e-02,  9.1072e-03,\n",
       "                       2.6329e-02,  1.8432e-02, -2.6275e-02, -6.1240e-03, -5.0538e-02,\n",
       "                       7.8578e-03, -1.4737e-02, -1.5483e-02, -4.0752e-02,  5.3759e-03,\n",
       "                       2.3468e-02], dtype=torch.float64)),\n",
       "             ('6.3.convs.2.1.bias',\n",
       "              tensor([-2.5797e-03, -6.4166e-03,  1.7968e-02,  9.6252e-03,  4.8672e-03,\n",
       "                       1.7111e-03,  2.1250e-02,  1.3986e-03,  7.2805e-03,  2.1452e-02,\n",
       "                       1.2049e-02, -8.7455e-03,  1.0498e-02, -7.0585e-03,  3.5840e-03,\n",
       "                       6.6433e-03,  1.8841e-02, -1.1966e-03,  1.6624e-02, -8.6635e-03,\n",
       "                      -1.4258e-03,  2.9578e-03,  2.0191e-03,  7.5122e-03, -6.2062e-03,\n",
       "                      -1.3662e-02,  7.8087e-03,  1.0927e-02,  2.4027e-03, -1.8442e-03,\n",
       "                       9.1861e-03,  9.4733e-03, -8.5312e-03,  1.6039e-02,  1.5431e-02,\n",
       "                       7.0945e-03,  1.2773e-03,  2.4802e-02,  9.6879e-03,  1.3565e-02,\n",
       "                       1.0158e-03,  8.0390e-03, -9.3413e-03,  9.7143e-04,  7.6194e-03,\n",
       "                      -1.1149e-02,  5.3431e-03,  4.1254e-03, -1.1173e-02,  8.6138e-03,\n",
       "                       8.5550e-03,  3.5668e-03,  8.6429e-03,  1.5206e-02,  5.3058e-03,\n",
       "                       5.9685e-04,  6.2454e-03,  3.0971e-03,  7.7455e-03,  6.7122e-03,\n",
       "                      -6.9629e-03,  9.6579e-04, -1.9555e-03,  1.0024e-02, -4.3331e-03,\n",
       "                       1.4677e-02, -1.2219e-02,  1.4050e-02,  3.1068e-03, -1.0353e-02,\n",
       "                       3.2450e-03,  1.9400e-03,  2.8112e-03, -7.9846e-03,  1.5279e-02,\n",
       "                       1.2359e-02,  9.4672e-04,  5.0230e-03,  3.8470e-03,  3.8547e-03,\n",
       "                       1.0760e-02, -5.5447e-03,  7.2977e-03,  4.9505e-03, -1.4065e-03,\n",
       "                       1.5111e-02,  2.4747e-03,  7.0994e-04,  9.7134e-03,  9.2644e-03,\n",
       "                      -6.6351e-05,  2.3230e-02,  1.6856e-02, -6.2465e-04,  9.1547e-04,\n",
       "                      -1.3152e-02,  3.9805e-03, -2.3112e-03,  1.8073e-02, -1.6151e-04,\n",
       "                       2.4512e-02,  5.2652e-03, -4.6760e-03, -7.9471e-03,  1.5674e-02,\n",
       "                       1.5860e-04,  3.2319e-04,  3.8463e-03,  4.1308e-03,  8.1087e-03,\n",
       "                      -7.1594e-03, -6.7726e-03,  4.7677e-03,  1.5856e-02,  1.2056e-02,\n",
       "                       7.8134e-03,  1.1585e-02,  3.0279e-03,  1.6566e-03, -1.5232e-02,\n",
       "                       2.4739e-03,  1.4688e-02,  1.9706e-03, -2.2335e-03, -1.0827e-02,\n",
       "                       1.2731e-02,  1.6649e-02,  2.5848e-03, -1.0972e-03,  1.0482e-02,\n",
       "                       2.3559e-03,  1.7923e-02,  1.4908e-02,  1.2129e-02,  1.9872e-02,\n",
       "                      -5.5732e-03,  1.7946e-02,  1.0659e-02,  1.6815e-02,  1.3415e-02,\n",
       "                       2.9935e-03, -2.8692e-03, -6.2181e-03,  8.4919e-03, -1.1181e-02,\n",
       "                       9.1374e-03,  7.5024e-04, -1.9775e-03,  1.0768e-02,  1.0696e-02,\n",
       "                       5.5905e-03,  1.1978e-02,  2.6439e-03,  1.5226e-02,  1.3163e-02,\n",
       "                       9.9906e-03,  6.4174e-04,  7.8299e-03, -7.2982e-03, -1.1654e-02,\n",
       "                      -5.0409e-04, -5.7676e-03,  3.5750e-03,  1.3752e-02,  1.2173e-02,\n",
       "                       1.9156e-03, -8.2165e-03,  9.1166e-03,  5.5799e-04,  1.5762e-02,\n",
       "                       4.8862e-03,  3.4844e-03,  1.3013e-02,  8.5047e-03, -1.3988e-02,\n",
       "                       7.5465e-03,  4.8147e-04,  1.2440e-02,  5.6185e-03,  6.7487e-03,\n",
       "                      -1.6659e-03,  9.2644e-03, -8.1001e-03, -1.0956e-02,  1.7238e-02,\n",
       "                       9.5468e-03,  1.5040e-02,  1.5780e-02, -2.5404e-03,  4.0520e-03,\n",
       "                       6.8105e-03, -1.4866e-03,  1.4260e-02, -1.7143e-02,  8.4410e-03,\n",
       "                       8.9528e-03, -2.2591e-03,  1.5966e-02,  9.2660e-03, -3.8299e-03,\n",
       "                       5.2248e-03,  1.5178e-02,  2.0447e-02,  1.7305e-02,  3.1560e-03,\n",
       "                      -3.1190e-03,  1.4590e-02, -4.3336e-03,  1.1115e-02,  5.5736e-03,\n",
       "                      -1.4519e-03,  1.2063e-02,  1.3603e-02,  6.2508e-03,  1.6845e-02,\n",
       "                       1.1002e-02,  3.8736e-03, -1.9929e-03,  4.7750e-03, -2.3595e-04,\n",
       "                      -1.2766e-02,  1.1142e-03,  6.8171e-03,  2.5343e-02, -1.7622e-03,\n",
       "                       2.0054e-03, -2.6380e-03,  1.6573e-03, -1.4969e-02,  1.4265e-02,\n",
       "                       1.3984e-02, -2.2679e-04,  1.1407e-02,  1.3016e-02,  7.6625e-03,\n",
       "                       3.9857e-03,  7.0756e-03, -3.9548e-03,  1.1298e-02,  1.0375e-02,\n",
       "                       5.8061e-03,  2.0565e-03,  2.8068e-03,  1.7745e-02,  2.9343e-03,\n",
       "                       1.4018e-02,  4.8125e-03,  9.8152e-03,  2.6523e-03, -8.0405e-03,\n",
       "                       1.6091e-02,  1.0336e-02,  2.1011e-02,  2.3282e-02,  1.1866e-02,\n",
       "                       1.2871e-02], dtype=torch.float64)),\n",
       "             ('6.3.convs.2.1.running_mean',\n",
       "              tensor([-0.2267,  0.5422, -0.3213, -0.4263,  0.0984, -0.4728,  0.0652,  1.0632,\n",
       "                       0.0396, -0.3144,  0.1486,  0.4458, -0.2995, -0.1862, -0.0224,  0.0589,\n",
       "                      -0.0301,  0.1369, -0.5435,  0.1346, -0.2618, -0.0212, -0.3196,  0.6038,\n",
       "                       0.0203,  0.0999,  0.2791,  0.0769, -0.0639,  0.1187,  0.3009, -1.2147,\n",
       "                       0.0548, -0.4886,  0.6524,  0.1250,  0.1078, -0.1685, -0.0134,  0.0649,\n",
       "                      -0.2516, -0.2236, -0.5682,  0.0142, -0.7515, -0.0452, -0.3235, -0.4087,\n",
       "                       0.2204,  0.0308, -0.2752,  0.8270,  0.2894, -0.3734,  0.0138,  0.2118,\n",
       "                      -0.8439, -0.3997,  0.0901, -0.0333, -0.0534,  0.0550, -0.1423,  0.4303,\n",
       "                       0.1166, -0.1768,  0.0517,  0.2433,  0.0671, -0.1288, -0.2415, -0.0478,\n",
       "                       0.1379, -0.4132, -0.2211, -0.1956, -0.2170, -0.3617, -0.4722,  0.1780,\n",
       "                       0.2271, -0.0401,  1.1079, -0.3459,  0.4742, -0.4362, -0.3101,  0.2097,\n",
       "                       0.3725,  0.0055, -0.3125,  0.1083,  0.3245, -0.1293,  0.2052,  0.4252,\n",
       "                       0.6518, -0.2515,  0.3633, -0.1881,  0.1247, -0.1707, -0.7745,  0.9025,\n",
       "                      -0.0674,  0.1191,  0.0908,  0.2016, -0.6305, -0.0916,  0.4997,  0.6293,\n",
       "                      -0.2252, -0.1997,  0.2519, -0.0738, -0.3401, -0.3462, -0.5845, -0.1075,\n",
       "                       0.1403, -0.2271, -0.1481, -0.0731, -0.1917, -1.0139, -0.1228,  0.1721,\n",
       "                      -0.0847, -0.6929,  0.6839,  0.3688, -0.1183,  0.0117,  0.7924, -0.1750,\n",
       "                      -0.5865,  0.3880, -0.3170,  0.4644, -0.1108, -0.0901,  0.4010, -0.0916,\n",
       "                      -0.3747,  0.3213, -0.9464,  0.8493,  0.9863,  0.0258,  1.1218, -0.1840,\n",
       "                       0.2322, -0.2805,  0.0937, -0.0591, -0.0811,  0.4331,  0.4479,  0.0387,\n",
       "                      -0.1105, -0.2983,  0.1763,  0.3549,  0.1889,  0.3164,  0.1144,  0.3418,\n",
       "                      -0.4611, -0.1635,  0.0971, -0.0387,  0.2837, -0.0441,  0.0814, -0.4246,\n",
       "                       0.1223, -0.4369,  0.0525, -0.1465, -0.2343,  0.2440, -0.7122, -0.0932,\n",
       "                       0.2462,  0.2852,  0.1129, -0.1174, -0.2790,  0.4488, -0.0545, -0.3631,\n",
       "                       0.4095, -0.4082,  0.0627,  0.3342, -0.2570,  0.3475, -0.4352,  0.3147,\n",
       "                       0.9032, -0.0280,  0.0565,  0.5175, -0.5945, -0.1374, -0.8371, -0.0728,\n",
       "                       0.0571, -0.6066, -0.2512, -0.4747,  0.1756, -0.2084, -0.0068, -0.4700,\n",
       "                       0.5443,  0.7048, -0.8123,  0.1890, -0.2087,  0.0978,  0.1175,  0.0488,\n",
       "                      -0.3868, -0.1939,  0.1089, -0.4571, -0.0613, -0.3399,  0.4603,  0.1733,\n",
       "                      -0.3530,  0.1698, -0.3653, -0.4882,  0.0573, -0.0095,  0.3071,  0.3315,\n",
       "                       0.3030, -0.5403,  0.0657,  0.1266,  0.0201,  0.0203, -0.0623, -0.2637,\n",
       "                      -0.3389,  0.3613, -0.1978,  0.2255,  0.3015,  0.4886,  0.4628,  0.4543],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convs.2.1.running_var',\n",
       "              tensor([0.4341, 0.5010, 0.5003, 0.4717, 0.3296, 0.2574, 0.3748, 0.6318, 0.2433,\n",
       "                      0.4302, 0.2385, 0.3211, 0.0777, 0.2710, 0.4782, 0.3720, 0.3314, 0.3843,\n",
       "                      0.3304, 0.1331, 0.2116, 0.4893, 0.3066, 0.2812, 0.4371, 0.1976, 0.3328,\n",
       "                      0.1834, 0.1537, 0.2551, 0.5762, 0.6211, 0.3570, 0.3631, 0.5047, 0.2072,\n",
       "                      0.1735, 0.1507, 0.4816, 0.3639, 0.5588, 0.5165, 0.1427, 0.1776, 0.3557,\n",
       "                      0.2238, 0.3823, 0.2334, 0.6126, 0.2091, 0.2440, 0.4523, 0.5193, 0.4251,\n",
       "                      0.3072, 0.3365, 0.5630, 0.3503, 0.3632, 0.3673, 0.0628, 0.5931, 0.2075,\n",
       "                      0.3491, 0.4900, 0.2878, 0.2552, 0.4274, 0.3382, 0.6454, 0.2184, 0.2065,\n",
       "                      0.1440, 0.3929, 0.5260, 0.3500, 0.1571, 0.2379, 0.2796, 0.3024, 0.3227,\n",
       "                      0.2230, 0.7174, 0.3552, 0.4536, 0.4973, 0.5176, 0.3347, 0.3335, 0.1594,\n",
       "                      0.6222, 0.1895, 0.4836, 0.2193, 0.2678, 0.2000, 0.5660, 0.3048, 0.3450,\n",
       "                      0.3924, 0.3225, 0.3510, 0.2847, 0.3685, 0.3997, 0.3987, 0.3094, 0.2452,\n",
       "                      0.4192, 0.1789, 0.1316, 0.5826, 0.6280, 0.4521, 0.2742, 0.6394, 0.2055,\n",
       "                      0.2683, 0.4585, 0.2726, 0.0637, 0.3251, 0.6829, 0.2007, 0.1782, 0.4782,\n",
       "                      0.4326, 0.2947, 0.1405, 0.6025, 0.3042, 0.1580, 0.3477, 0.4006, 0.4220,\n",
       "                      0.0915, 0.6197, 0.2680, 0.4636, 0.3206, 0.1654, 0.0536, 0.2961, 0.0555,\n",
       "                      0.2196, 0.3075, 0.2937, 0.4027, 0.5107, 0.2758, 0.5003, 0.1201, 0.3101,\n",
       "                      0.4930, 0.4281, 0.3523, 0.2032, 0.3536, 0.3066, 0.1138, 0.1840, 0.1884,\n",
       "                      0.3643, 0.3074, 0.2156, 0.2430, 0.6827, 0.5311, 0.2100, 0.2853, 0.3571,\n",
       "                      0.3646, 0.4040, 0.2706, 0.2679, 0.3508, 0.3773, 0.5498, 0.4243, 0.2326,\n",
       "                      0.3234, 0.2553, 0.6887, 0.5037, 0.1880, 0.4436, 0.4816, 0.2002, 0.2692,\n",
       "                      0.1627, 0.2520, 0.5069, 0.5069, 0.6947, 0.3158, 0.3466, 0.5558, 0.2225,\n",
       "                      0.5419, 0.2837, 0.2488, 0.2575, 0.3021, 0.4223, 0.3250, 0.4568, 0.5204,\n",
       "                      0.0493, 0.3865, 0.5032, 0.1194, 0.3346, 0.1460, 0.3589, 0.2040, 0.2098,\n",
       "                      0.3106, 0.2590, 0.6542, 0.2730, 0.0955, 0.3001, 0.0792, 0.4771, 0.2620,\n",
       "                      0.3220, 0.1112, 0.1713, 0.3128, 0.5375, 0.2936, 0.1748, 0.5022, 0.3253,\n",
       "                      0.2516, 0.4851, 0.2133, 0.2062, 0.4364, 0.2585, 0.2966, 0.3104, 0.4686,\n",
       "                      0.2842, 0.1494, 0.3829, 0.3308, 0.2755, 0.0891, 0.2700, 0.4172, 0.4015,\n",
       "                      0.2388, 0.4631, 0.3016, 0.4052], dtype=torch.float64)),\n",
       "             ('6.3.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.3.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.0836],\n",
       "                       [-0.0142],\n",
       "                       [-0.2330],\n",
       "                       ...,\n",
       "                       [ 0.0220],\n",
       "                       [-0.0216],\n",
       "                       [ 0.1154]],\n",
       "              \n",
       "                      [[ 0.0897],\n",
       "                       [-0.0583],\n",
       "                       [-0.0872],\n",
       "                       ...,\n",
       "                       [ 0.0294],\n",
       "                       [-0.0127],\n",
       "                       [ 0.0977]],\n",
       "              \n",
       "                      [[ 0.1077],\n",
       "                       [ 0.0071],\n",
       "                       [-0.0889],\n",
       "                       ...,\n",
       "                       [ 0.1597],\n",
       "                       [-0.0588],\n",
       "                       [-0.0419]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0384],\n",
       "                       [-0.0324],\n",
       "                       [-0.0878],\n",
       "                       ...,\n",
       "                       [ 0.1114],\n",
       "                       [ 0.0493],\n",
       "                       [-0.0550]],\n",
       "              \n",
       "                      [[-0.0477],\n",
       "                       [-0.0720],\n",
       "                       [-0.0068],\n",
       "                       ...,\n",
       "                       [-0.0667],\n",
       "                       [-0.0595],\n",
       "                       [-0.0101]],\n",
       "              \n",
       "                      [[ 0.0441],\n",
       "                       [-0.0778],\n",
       "                       [-0.0917],\n",
       "                       ...,\n",
       "                       [-0.0944],\n",
       "                       [ 0.0606],\n",
       "                       [-0.1236]]], dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.0.1.weight',\n",
       "              tensor([0.9935, 0.9731, 0.9612, 0.9738, 0.9545, 0.9781, 0.9811, 0.9550, 0.9498,\n",
       "                      0.9865, 0.9717, 0.9801, 0.9979, 0.9713, 0.9737, 0.9673, 0.9912, 0.9685,\n",
       "                      0.9740, 0.9688, 0.9852, 0.9917, 0.9636, 0.9742, 0.9627, 0.9533, 0.9680,\n",
       "                      0.9567, 0.9669, 0.9962, 0.9536, 0.9725, 0.9687, 0.9831, 0.9744, 0.9902,\n",
       "                      0.9760, 0.9582, 0.9558, 0.9759, 0.9432, 0.9873, 0.9957, 0.9624, 0.9565,\n",
       "                      0.9778, 0.9841, 0.9503, 0.9769, 0.9862, 0.9582, 0.9417, 0.9666, 0.9403,\n",
       "                      0.9589, 0.9697, 0.9408, 0.9820, 0.9826, 0.9694, 0.9604, 0.9714, 0.9497,\n",
       "                      0.9740], dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0049,  0.0009,  0.0009,  0.0042,  0.0016, -0.0095,  0.0054, -0.0155,\n",
       "                       0.0024,  0.0267,  0.0041, -0.0051,  0.0226, -0.0117,  0.0080, -0.0095,\n",
       "                       0.0065, -0.0084,  0.0097, -0.0190,  0.0117,  0.0155, -0.0041,  0.0208,\n",
       "                       0.0037,  0.0010,  0.0303, -0.0134, -0.0065,  0.0315, -0.0169,  0.0191,\n",
       "                      -0.0140,  0.0043,  0.0091,  0.0245,  0.0149, -0.0093, -0.0061,  0.0071,\n",
       "                      -0.0196,  0.0135,  0.0201, -0.0065, -0.0124, -0.0202, -0.0006, -0.0115,\n",
       "                       0.0025,  0.0042, -0.0105, -0.0219,  0.0026, -0.0188, -0.0108, -0.0028,\n",
       "                       0.0005, -0.0061,  0.0174,  0.0042, -0.0018, -0.0101, -0.0141,  0.0005],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.1689, -0.6454,  0.5007, -0.6568, -0.5218,  0.2219,  0.6869,  1.0033,\n",
       "                      -0.4050, -0.4411,  0.3008,  0.4656,  0.1833, -0.4233, -0.1463, -0.8737,\n",
       "                       0.3207, -0.3210, -0.5028, -0.2203,  0.9405, -0.1224,  0.5320, -0.6759,\n",
       "                      -0.4003, -1.3419, -0.7312,  0.2378, -0.5220, -0.0550, -0.3125, -0.0616,\n",
       "                       0.2173,  0.5440, -0.7067, -0.4562,  0.4488, -0.8552, -1.0228, -0.0434,\n",
       "                       0.2758,  0.3100, -0.0106, -0.5302, -0.2465,  0.7208, -0.5049, -0.3898,\n",
       "                       0.3156, -0.8468, -0.0516, -0.3231, -0.5626, -0.5411,  0.5492, -0.1812,\n",
       "                      -0.1690,  0.3352,  0.1052, -0.7155,  0.3739,  0.3544, -0.1342, -0.6355],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.0.1.running_var',\n",
       "              tensor([0.2957, 0.1850, 0.6652, 0.1615, 0.1821, 0.1174, 0.1498, 0.9403, 0.2352,\n",
       "                      0.1613, 0.1707, 0.1140, 0.2361, 0.3256, 0.2065, 0.3258, 0.1653, 0.1706,\n",
       "                      0.1365, 0.2307, 0.1310, 0.1917, 0.2583, 0.5242, 0.1197, 0.5175, 1.2508,\n",
       "                      0.0833, 0.6942, 0.2924, 0.7822, 0.1226, 0.1766, 0.1477, 0.1564, 0.2425,\n",
       "                      0.1206, 0.7851, 0.4172, 0.4345, 0.5028, 0.2169, 0.2132, 0.9674, 0.3974,\n",
       "                      0.1051, 0.1339, 0.3912, 0.3281, 0.1969, 0.2259, 0.2053, 0.2290, 0.2571,\n",
       "                      0.7919, 0.1274, 0.2036, 0.1188, 0.1055, 0.4394, 0.3305, 0.4820, 0.3490,\n",
       "                      0.4003], dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.3.convpath.0.1.0.weight',\n",
       "              tensor([[[ 4.5031e-02, -6.3458e-02, -6.3075e-02, -1.6577e-02,  5.6874e-02],\n",
       "                       [ 2.0491e-02, -2.6789e-02, -3.9041e-02,  1.5200e-02, -5.2503e-02],\n",
       "                       [ 1.9974e-02,  5.6953e-02,  4.5140e-02,  4.4333e-02, -1.0485e-01],\n",
       "                       ...,\n",
       "                       [ 9.7279e-02, -1.6135e-02, -2.0964e-02,  7.8871e-02, -1.7372e-03],\n",
       "                       [-9.4632e-02, -5.1138e-02, -5.7390e-02, -8.4832e-02, -5.1471e-02],\n",
       "                       [-4.3466e-03, -9.9913e-03,  1.4457e-01,  8.2719e-02, -1.1791e-01]],\n",
       "              \n",
       "                      [[-1.8770e-03,  4.1147e-03,  4.7226e-02,  8.6625e-02,  2.8036e-02],\n",
       "                       [ 3.2393e-02,  6.5667e-02, -2.3525e-02,  2.1569e-02,  2.3630e-02],\n",
       "                       [-2.7386e-02, -9.6487e-02, -1.9150e-02, -2.6737e-03, -7.6384e-02],\n",
       "                       ...,\n",
       "                       [-4.4700e-02,  2.5130e-02, -2.2918e-02, -6.3791e-02, -7.8412e-02],\n",
       "                       [ 5.3158e-02,  1.3616e-04,  1.0444e-01,  1.5605e-01, -6.6482e-02],\n",
       "                       [-6.2230e-03,  3.8805e-02, -5.4779e-02,  4.8002e-02,  5.7375e-02]],\n",
       "              \n",
       "                      [[-1.4027e-02, -5.6741e-02,  2.0611e-01, -9.8751e-02, -1.6259e-01],\n",
       "                       [ 6.5376e-02,  5.7862e-02, -2.7659e-02, -4.5727e-02, -1.5635e-01],\n",
       "                       [-3.7132e-02,  6.7694e-03, -1.8052e-02, -1.2627e-01,  2.8058e-02],\n",
       "                       ...,\n",
       "                       [ 5.7850e-02,  6.0785e-02, -6.1765e-02, -6.7465e-02, -4.7162e-03],\n",
       "                       [ 2.1174e-02,  1.1555e-02, -1.6849e-02,  2.9702e-02, -9.2858e-02],\n",
       "                       [-1.2654e-01, -4.5266e-02, -3.7955e-02,  3.1690e-02, -1.2174e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-3.9478e-02,  1.0042e-01, -8.3087e-02,  4.0227e-03, -6.9969e-02],\n",
       "                       [-6.1648e-02, -7.0065e-02, -6.9993e-02, -7.2487e-03,  7.3063e-02],\n",
       "                       [ 1.0302e-01, -2.9896e-02, -4.4484e-02, -1.1333e-01, -5.4941e-02],\n",
       "                       ...,\n",
       "                       [-2.3024e-03,  3.8355e-02,  2.2813e-02, -8.2025e-02,  3.9636e-02],\n",
       "                       [-7.8375e-02, -1.0918e-01,  7.3916e-02, -5.5115e-02, -6.6182e-02],\n",
       "                       [ 4.9850e-02,  1.5487e-02, -3.5750e-02, -6.2412e-03,  3.0324e-02]],\n",
       "              \n",
       "                      [[-2.8848e-02,  7.6258e-02,  2.3487e-02, -1.7766e-02,  5.5746e-02],\n",
       "                       [-1.4409e-01,  7.5147e-02, -2.4324e-02,  1.8695e-02, -9.0342e-02],\n",
       "                       [-4.0029e-02, -7.8973e-03,  2.9468e-02,  1.0257e-02, -4.5983e-02],\n",
       "                       ...,\n",
       "                       [ 6.9523e-02, -1.2981e-01,  4.3978e-02,  4.7004e-02, -1.5814e-01],\n",
       "                       [ 5.6193e-02,  6.7428e-02,  8.7977e-02, -6.6451e-02, -1.1659e-01],\n",
       "                       [ 6.6541e-03,  8.6018e-02,  1.7445e-01,  3.7791e-02,  4.5388e-02]],\n",
       "              \n",
       "                      [[ 1.9111e-02,  8.4569e-02,  9.3869e-02, -1.4621e-02,  2.5622e-02],\n",
       "                       [-2.1762e-03,  2.6920e-02, -5.7559e-02,  6.0002e-02, -8.6922e-02],\n",
       "                       [-2.2274e-02, -7.2869e-02,  2.4974e-02, -9.8059e-02, -1.1518e-01],\n",
       "                       ...,\n",
       "                       [-1.1634e-01, -1.4494e-01,  2.5907e-03,  3.9700e-03, -1.0767e-01],\n",
       "                       [ 7.5978e-03, -1.0776e-02,  3.6922e-02,  5.9500e-03, -8.0243e-02],\n",
       "                       [-1.2482e-01, -8.9399e-02, -9.5219e-02,  6.8358e-02, -4.5209e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.1.1.weight',\n",
       "              tensor([0.9680, 0.9565, 0.9494, 0.9710, 0.9973, 0.9857, 0.9568, 0.9794, 0.9721,\n",
       "                      0.9667, 0.9802, 0.9445, 0.9960, 0.9518, 0.9400, 0.9668, 0.9868, 0.9472,\n",
       "                      0.9522, 0.9545, 0.9489, 0.9434, 0.9712, 0.9665, 0.9481, 1.0015, 0.9505,\n",
       "                      0.9442, 0.9477, 0.9436, 0.9783, 0.9651, 0.9572, 0.9627, 0.9491, 0.9419,\n",
       "                      0.9517, 0.9593, 0.9588, 0.9845, 0.9700, 0.9549, 0.9760, 0.9631, 0.9469,\n",
       "                      0.9668, 0.9415, 0.9701, 0.9775, 0.9446, 0.9570, 0.9635, 0.9743, 0.9721,\n",
       "                      1.0181, 0.9883, 0.9804, 0.9659, 0.9889, 0.9456, 0.9781, 0.9373, 0.9710,\n",
       "                      0.9605], dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.1.1.bias',\n",
       "              tensor([-0.0030,  0.0023,  0.0096, -0.0051, -0.0052, -0.0087, -0.0128, -0.0167,\n",
       "                       0.0082, -0.0094,  0.0257, -0.0099,  0.0172, -0.0264, -0.0208, -0.0011,\n",
       "                       0.0078, -0.0333, -0.0157, -0.0061, -0.0270, -0.0129,  0.0003, -0.0076,\n",
       "                      -0.0169,  0.0250, -0.0265, -0.0228, -0.0229, -0.0067, -0.0105,  0.0138,\n",
       "                      -0.0258, -0.0145, -0.0125, -0.0164, -0.0027, -0.0085, -0.0033, -0.0064,\n",
       "                      -0.0261, -0.0053,  0.0048,  0.0069, -0.0281, -0.0302, -0.0325, -0.0138,\n",
       "                       0.0056, -0.0046, -0.0017,  0.0157, -0.0130,  0.0142,  0.0096,  0.0095,\n",
       "                       0.0096, -0.0097,  0.0218, -0.0215,  0.0114, -0.0255,  0.0010,  0.0027],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.1.1.running_mean',\n",
       "              tensor([ 2.3425e-01,  3.7149e-01,  4.3241e-01,  8.3932e-02, -4.2117e-01,\n",
       "                      -4.5153e-02, -8.0430e-01,  2.1780e-01, -1.6376e-01, -1.0474e-01,\n",
       "                      -6.1503e-01, -5.3871e-01, -2.4249e-01,  6.5866e-01, -7.0890e-01,\n",
       "                      -3.3458e-01,  1.4502e-01, -4.5255e-01, -3.4243e-01, -5.7911e-01,\n",
       "                      -6.2067e-01, -1.4191e-01,  2.0950e-01, -8.8122e-01,  1.0047e-01,\n",
       "                      -1.5438e+00, -7.5754e-01, -3.7798e-02, -5.3896e-01, -2.6246e-01,\n",
       "                       6.6092e-01, -1.7345e-01,  8.6860e-01, -2.6438e-01, -2.0020e-01,\n",
       "                       1.5678e-01,  8.9396e-02,  3.1140e-01,  2.9925e-01,  7.2220e-02,\n",
       "                       1.1998e+00, -2.3521e-01,  3.8395e-01,  8.7388e-04, -2.8525e-02,\n",
       "                      -2.0763e-02, -2.8935e-01, -3.0140e-01,  1.1521e+00, -5.0367e-01,\n",
       "                       2.7059e-01,  1.8194e-01, -4.8049e-01, -2.0566e-01, -3.2340e-01,\n",
       "                      -4.2698e-01, -2.9017e-01, -8.7020e-01, -9.4385e-01,  4.9539e-01,\n",
       "                      -4.2253e-01, -7.6930e-01, -5.5113e-02, -2.9616e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.1.1.running_var',\n",
       "              tensor([0.5746, 0.4747, 0.5640, 0.6424, 0.3706, 0.6119, 0.4254, 0.5075, 0.5688,\n",
       "                      0.4522, 0.4759, 0.4375, 0.3805, 0.5140, 0.4898, 0.4796, 0.3944, 0.4470,\n",
       "                      0.6586, 0.5441, 0.4637, 0.4697, 0.3897, 0.4250, 0.4211, 0.4002, 0.7138,\n",
       "                      0.5290, 0.3935, 0.6045, 0.4530, 0.8621, 0.4318, 0.5820, 0.5275, 0.3842,\n",
       "                      0.3985, 0.3439, 0.7150, 0.3545, 0.5025, 0.4816, 0.5740, 0.4801, 0.6412,\n",
       "                      0.3365, 0.6341, 0.4325, 0.4430, 0.6994, 0.2934, 0.5097, 0.3342, 0.6173,\n",
       "                      0.3313, 0.5447, 0.5178, 0.3036, 0.3872, 0.3721, 0.5089, 0.5584, 0.4697,\n",
       "                      0.7280], dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.3.convpath.0.2.0.weight',\n",
       "              tensor([[[-0.1076],\n",
       "                       [-0.0879],\n",
       "                       [-0.0580],\n",
       "                       ...,\n",
       "                       [ 0.0500],\n",
       "                       [ 0.0128],\n",
       "                       [ 0.0263]],\n",
       "              \n",
       "                      [[-0.2342],\n",
       "                       [-0.0028],\n",
       "                       [-0.2151],\n",
       "                       ...,\n",
       "                       [ 0.0490],\n",
       "                       [ 0.1289],\n",
       "                       [ 0.0080]],\n",
       "              \n",
       "                      [[ 0.1034],\n",
       "                       [ 0.0496],\n",
       "                       [-0.0758],\n",
       "                       ...,\n",
       "                       [-0.0451],\n",
       "                       [-0.1655],\n",
       "                       [-0.0212]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1794],\n",
       "                       [-0.0978],\n",
       "                       [-0.3339],\n",
       "                       ...,\n",
       "                       [ 0.0715],\n",
       "                       [-0.0033],\n",
       "                       [-0.0014]],\n",
       "              \n",
       "                      [[-0.0183],\n",
       "                       [-0.1509],\n",
       "                       [ 0.1345],\n",
       "                       ...,\n",
       "                       [ 0.0299],\n",
       "                       [-0.0301],\n",
       "                       [-0.0818]],\n",
       "              \n",
       "                      [[ 0.2681],\n",
       "                       [ 0.3150],\n",
       "                       [ 0.0174],\n",
       "                       ...,\n",
       "                       [ 0.2031],\n",
       "                       [-0.0307],\n",
       "                       [ 0.0048]]], dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.2.1.weight',\n",
       "              tensor([ 7.9271e-03,  1.4752e-02, -2.4944e-02,  1.0540e-02, -1.6292e-02,\n",
       "                      -1.5966e-02,  3.2396e-02, -1.2903e-02, -7.2734e-04, -4.3549e-02,\n",
       "                      -1.0139e-02, -6.7067e-03, -2.5998e-03,  1.0467e-02,  6.9312e-03,\n",
       "                      -4.5640e-02,  2.0227e-02,  1.8202e-02, -2.0453e-02, -1.0500e-03,\n",
       "                      -7.1799e-03, -1.4364e-02,  1.0086e-04, -1.5460e-02, -2.9384e-02,\n",
       "                      -1.2352e-02,  1.8998e-02,  3.4095e-03, -9.8179e-03, -3.6893e-03,\n",
       "                      -2.2751e-02,  2.7015e-02,  9.8841e-03,  1.5321e-02, -3.2800e-02,\n",
       "                       1.7462e-03,  4.4897e-03, -5.2315e-04, -9.0990e-03,  1.0988e-02,\n",
       "                       2.2826e-02,  3.2831e-02, -5.3111e-03, -8.6741e-04, -1.6954e-02,\n",
       "                      -6.4237e-03, -4.5184e-03, -2.1553e-03,  1.9586e-02,  2.0786e-03,\n",
       "                       7.2736e-03,  2.4172e-02,  1.8243e-02,  3.1963e-02,  8.5083e-03,\n",
       "                       6.1561e-02,  5.6541e-03,  3.3565e-02, -2.1821e-02,  7.7970e-03,\n",
       "                      -9.6951e-03, -1.2799e-02, -7.0902e-03, -1.3442e-02, -1.5165e-02,\n",
       "                       3.2970e-02, -1.3717e-03, -2.3781e-02,  3.1767e-02, -3.0989e-02,\n",
       "                       1.8659e-02, -1.5683e-02,  6.2696e-03, -1.0108e-02,  2.3595e-02,\n",
       "                      -2.0985e-02,  1.1475e-03, -5.1191e-03,  1.9089e-03, -6.1693e-03,\n",
       "                       1.2506e-03,  1.4818e-02, -2.6806e-02, -2.3726e-02,  1.1694e-03,\n",
       "                      -3.3108e-02, -2.6355e-02,  8.1053e-03, -1.3698e-02,  1.8181e-03,\n",
       "                      -4.5789e-03, -1.7559e-02, -2.6936e-02,  3.1706e-04, -1.3582e-02,\n",
       "                      -1.0437e-02, -1.9103e-02, -1.6111e-02,  1.5976e-02, -1.2342e-02,\n",
       "                      -1.5933e-02, -2.2652e-02, -1.7446e-02, -4.4654e-02,  1.6962e-02,\n",
       "                      -1.6748e-02,  1.5351e-02, -5.8498e-03,  5.8600e-03,  1.1966e-02,\n",
       "                      -7.9705e-03,  9.1065e-03, -2.8181e-02,  2.5419e-02, -4.4393e-03,\n",
       "                       2.8749e-02,  4.2918e-03,  2.2072e-03,  1.5599e-02, -1.1009e-02,\n",
       "                      -8.2406e-03,  4.6298e-02, -1.5521e-02,  9.4074e-03,  2.6572e-02,\n",
       "                      -1.3178e-02, -1.0459e-02,  1.7976e-02, -2.4415e-03,  1.6718e-02,\n",
       "                       1.8723e-02,  7.3763e-03,  1.3920e-02,  1.6652e-02,  1.6086e-02,\n",
       "                      -9.1912e-03, -3.6401e-02,  7.3499e-03, -2.3338e-02,  1.6216e-02,\n",
       "                      -3.6649e-03,  1.9585e-03,  8.6547e-03,  1.5867e-03,  1.8214e-02,\n",
       "                      -3.9011e-03, -3.4455e-03,  1.3634e-02,  3.0101e-02,  1.8651e-02,\n",
       "                       2.5530e-02,  2.8263e-03, -3.8641e-03,  2.9694e-02, -1.4794e-02,\n",
       "                       2.0702e-03,  3.5324e-03, -1.5048e-02, -2.2033e-03,  4.3454e-04,\n",
       "                      -3.4054e-03, -3.5716e-03, -2.8820e-02, -1.0530e-02, -3.8970e-03,\n",
       "                       6.6733e-05, -2.5009e-03, -3.4745e-02,  1.2368e-03,  3.0235e-02,\n",
       "                       2.3713e-02, -1.9599e-02,  9.5653e-03, -1.7575e-02,  3.2235e-04,\n",
       "                      -2.1831e-03, -1.5232e-02, -2.2780e-04,  3.2814e-02, -2.0912e-02,\n",
       "                      -1.6513e-02, -1.2591e-02, -1.9934e-02,  1.3690e-02, -1.7553e-02,\n",
       "                       2.1786e-04,  6.8375e-03,  1.0423e-02, -1.0923e-02,  8.3421e-03,\n",
       "                      -7.9088e-03,  6.8457e-03,  1.9326e-02,  3.0229e-02,  9.8381e-03,\n",
       "                      -2.2590e-03, -1.2541e-02,  1.0267e-02,  2.2497e-02,  6.8712e-03,\n",
       "                       7.9821e-03,  5.9914e-03, -1.2369e-02, -2.6366e-02,  2.3968e-02,\n",
       "                      -1.6106e-02,  1.4658e-02,  3.2371e-03, -2.8337e-02, -2.1815e-02,\n",
       "                      -1.1108e-02, -1.4792e-02, -9.9776e-03,  5.9600e-03,  2.0668e-02,\n",
       "                      -2.3164e-02,  6.9716e-04,  6.8160e-04,  2.1876e-02,  4.4789e-03,\n",
       "                       1.8181e-03,  2.1077e-02, -2.7272e-03, -3.8133e-02,  1.1089e-02,\n",
       "                      -7.2474e-03, -3.6176e-03,  4.6825e-03,  2.1195e-03, -3.5034e-03,\n",
       "                       1.4512e-02, -3.9083e-03, -2.5785e-02, -2.2522e-02,  1.7175e-02,\n",
       "                       1.7519e-02, -1.1759e-03,  4.7351e-03,  2.8044e-03, -8.2294e-03,\n",
       "                       2.8937e-02, -1.6456e-02,  1.3573e-02,  1.7298e-02,  9.1072e-03,\n",
       "                       2.6329e-02,  1.8432e-02, -2.6275e-02, -6.1240e-03, -5.0538e-02,\n",
       "                       7.8578e-03, -1.4737e-02, -1.5483e-02, -4.0752e-02,  5.3759e-03,\n",
       "                       2.3468e-02], dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.2.1.bias',\n",
       "              tensor([-2.5797e-03, -6.4166e-03,  1.7968e-02,  9.6252e-03,  4.8672e-03,\n",
       "                       1.7111e-03,  2.1250e-02,  1.3986e-03,  7.2805e-03,  2.1452e-02,\n",
       "                       1.2049e-02, -8.7455e-03,  1.0498e-02, -7.0585e-03,  3.5840e-03,\n",
       "                       6.6433e-03,  1.8841e-02, -1.1966e-03,  1.6624e-02, -8.6635e-03,\n",
       "                      -1.4258e-03,  2.9578e-03,  2.0191e-03,  7.5122e-03, -6.2062e-03,\n",
       "                      -1.3662e-02,  7.8087e-03,  1.0927e-02,  2.4027e-03, -1.8442e-03,\n",
       "                       9.1861e-03,  9.4733e-03, -8.5312e-03,  1.6039e-02,  1.5431e-02,\n",
       "                       7.0945e-03,  1.2773e-03,  2.4802e-02,  9.6879e-03,  1.3565e-02,\n",
       "                       1.0158e-03,  8.0390e-03, -9.3413e-03,  9.7143e-04,  7.6194e-03,\n",
       "                      -1.1149e-02,  5.3431e-03,  4.1254e-03, -1.1173e-02,  8.6138e-03,\n",
       "                       8.5550e-03,  3.5668e-03,  8.6429e-03,  1.5206e-02,  5.3058e-03,\n",
       "                       5.9685e-04,  6.2454e-03,  3.0971e-03,  7.7455e-03,  6.7122e-03,\n",
       "                      -6.9629e-03,  9.6579e-04, -1.9555e-03,  1.0024e-02, -4.3331e-03,\n",
       "                       1.4677e-02, -1.2219e-02,  1.4050e-02,  3.1068e-03, -1.0353e-02,\n",
       "                       3.2450e-03,  1.9400e-03,  2.8112e-03, -7.9846e-03,  1.5279e-02,\n",
       "                       1.2359e-02,  9.4672e-04,  5.0230e-03,  3.8470e-03,  3.8547e-03,\n",
       "                       1.0760e-02, -5.5447e-03,  7.2977e-03,  4.9505e-03, -1.4065e-03,\n",
       "                       1.5111e-02,  2.4747e-03,  7.0994e-04,  9.7134e-03,  9.2644e-03,\n",
       "                      -6.6351e-05,  2.3230e-02,  1.6856e-02, -6.2465e-04,  9.1547e-04,\n",
       "                      -1.3152e-02,  3.9805e-03, -2.3112e-03,  1.8073e-02, -1.6151e-04,\n",
       "                       2.4512e-02,  5.2652e-03, -4.6760e-03, -7.9471e-03,  1.5674e-02,\n",
       "                       1.5860e-04,  3.2319e-04,  3.8463e-03,  4.1308e-03,  8.1087e-03,\n",
       "                      -7.1594e-03, -6.7726e-03,  4.7677e-03,  1.5856e-02,  1.2056e-02,\n",
       "                       7.8134e-03,  1.1585e-02,  3.0279e-03,  1.6566e-03, -1.5232e-02,\n",
       "                       2.4739e-03,  1.4688e-02,  1.9706e-03, -2.2335e-03, -1.0827e-02,\n",
       "                       1.2731e-02,  1.6649e-02,  2.5848e-03, -1.0972e-03,  1.0482e-02,\n",
       "                       2.3559e-03,  1.7923e-02,  1.4908e-02,  1.2129e-02,  1.9872e-02,\n",
       "                      -5.5732e-03,  1.7946e-02,  1.0659e-02,  1.6815e-02,  1.3415e-02,\n",
       "                       2.9935e-03, -2.8692e-03, -6.2181e-03,  8.4919e-03, -1.1181e-02,\n",
       "                       9.1374e-03,  7.5024e-04, -1.9775e-03,  1.0768e-02,  1.0696e-02,\n",
       "                       5.5905e-03,  1.1978e-02,  2.6439e-03,  1.5226e-02,  1.3163e-02,\n",
       "                       9.9906e-03,  6.4174e-04,  7.8299e-03, -7.2982e-03, -1.1654e-02,\n",
       "                      -5.0409e-04, -5.7676e-03,  3.5750e-03,  1.3752e-02,  1.2173e-02,\n",
       "                       1.9156e-03, -8.2165e-03,  9.1166e-03,  5.5799e-04,  1.5762e-02,\n",
       "                       4.8862e-03,  3.4844e-03,  1.3013e-02,  8.5047e-03, -1.3988e-02,\n",
       "                       7.5465e-03,  4.8147e-04,  1.2440e-02,  5.6185e-03,  6.7487e-03,\n",
       "                      -1.6659e-03,  9.2644e-03, -8.1001e-03, -1.0956e-02,  1.7238e-02,\n",
       "                       9.5468e-03,  1.5040e-02,  1.5780e-02, -2.5404e-03,  4.0520e-03,\n",
       "                       6.8105e-03, -1.4866e-03,  1.4260e-02, -1.7143e-02,  8.4410e-03,\n",
       "                       8.9528e-03, -2.2591e-03,  1.5966e-02,  9.2660e-03, -3.8299e-03,\n",
       "                       5.2248e-03,  1.5178e-02,  2.0447e-02,  1.7305e-02,  3.1560e-03,\n",
       "                      -3.1190e-03,  1.4590e-02, -4.3336e-03,  1.1115e-02,  5.5736e-03,\n",
       "                      -1.4519e-03,  1.2063e-02,  1.3603e-02,  6.2508e-03,  1.6845e-02,\n",
       "                       1.1002e-02,  3.8736e-03, -1.9929e-03,  4.7750e-03, -2.3595e-04,\n",
       "                      -1.2766e-02,  1.1142e-03,  6.8171e-03,  2.5343e-02, -1.7622e-03,\n",
       "                       2.0054e-03, -2.6380e-03,  1.6573e-03, -1.4969e-02,  1.4265e-02,\n",
       "                       1.3984e-02, -2.2679e-04,  1.1407e-02,  1.3016e-02,  7.6625e-03,\n",
       "                       3.9857e-03,  7.0756e-03, -3.9548e-03,  1.1298e-02,  1.0375e-02,\n",
       "                       5.8061e-03,  2.0565e-03,  2.8068e-03,  1.7745e-02,  2.9343e-03,\n",
       "                       1.4018e-02,  4.8125e-03,  9.8152e-03,  2.6523e-03, -8.0405e-03,\n",
       "                       1.6091e-02,  1.0336e-02,  2.1011e-02,  2.3282e-02,  1.1866e-02,\n",
       "                       1.2871e-02], dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.2.1.running_mean',\n",
       "              tensor([-0.2267,  0.5422, -0.3213, -0.4263,  0.0984, -0.4728,  0.0652,  1.0632,\n",
       "                       0.0396, -0.3144,  0.1486,  0.4458, -0.2995, -0.1862, -0.0224,  0.0589,\n",
       "                      -0.0301,  0.1369, -0.5435,  0.1346, -0.2618, -0.0212, -0.3196,  0.6038,\n",
       "                       0.0203,  0.0999,  0.2791,  0.0769, -0.0639,  0.1187,  0.3009, -1.2147,\n",
       "                       0.0548, -0.4886,  0.6524,  0.1250,  0.1078, -0.1685, -0.0134,  0.0649,\n",
       "                      -0.2516, -0.2236, -0.5682,  0.0142, -0.7515, -0.0452, -0.3235, -0.4087,\n",
       "                       0.2204,  0.0308, -0.2752,  0.8270,  0.2894, -0.3734,  0.0138,  0.2118,\n",
       "                      -0.8439, -0.3997,  0.0901, -0.0333, -0.0534,  0.0550, -0.1423,  0.4303,\n",
       "                       0.1166, -0.1768,  0.0517,  0.2433,  0.0671, -0.1288, -0.2415, -0.0478,\n",
       "                       0.1379, -0.4132, -0.2211, -0.1956, -0.2170, -0.3617, -0.4722,  0.1780,\n",
       "                       0.2271, -0.0401,  1.1079, -0.3459,  0.4742, -0.4362, -0.3101,  0.2097,\n",
       "                       0.3725,  0.0055, -0.3125,  0.1083,  0.3245, -0.1293,  0.2052,  0.4252,\n",
       "                       0.6518, -0.2515,  0.3633, -0.1881,  0.1247, -0.1707, -0.7745,  0.9025,\n",
       "                      -0.0674,  0.1191,  0.0908,  0.2016, -0.6305, -0.0916,  0.4997,  0.6293,\n",
       "                      -0.2252, -0.1997,  0.2519, -0.0738, -0.3401, -0.3462, -0.5845, -0.1075,\n",
       "                       0.1403, -0.2271, -0.1481, -0.0731, -0.1917, -1.0139, -0.1228,  0.1721,\n",
       "                      -0.0847, -0.6929,  0.6839,  0.3688, -0.1183,  0.0117,  0.7924, -0.1750,\n",
       "                      -0.5865,  0.3880, -0.3170,  0.4644, -0.1108, -0.0901,  0.4010, -0.0916,\n",
       "                      -0.3747,  0.3213, -0.9464,  0.8493,  0.9863,  0.0258,  1.1218, -0.1840,\n",
       "                       0.2322, -0.2805,  0.0937, -0.0591, -0.0811,  0.4331,  0.4479,  0.0387,\n",
       "                      -0.1105, -0.2983,  0.1763,  0.3549,  0.1889,  0.3164,  0.1144,  0.3418,\n",
       "                      -0.4611, -0.1635,  0.0971, -0.0387,  0.2837, -0.0441,  0.0814, -0.4246,\n",
       "                       0.1223, -0.4369,  0.0525, -0.1465, -0.2343,  0.2440, -0.7122, -0.0932,\n",
       "                       0.2462,  0.2852,  0.1129, -0.1174, -0.2790,  0.4488, -0.0545, -0.3631,\n",
       "                       0.4095, -0.4082,  0.0627,  0.3342, -0.2570,  0.3475, -0.4352,  0.3147,\n",
       "                       0.9032, -0.0280,  0.0565,  0.5175, -0.5945, -0.1374, -0.8371, -0.0728,\n",
       "                       0.0571, -0.6066, -0.2512, -0.4747,  0.1756, -0.2084, -0.0068, -0.4700,\n",
       "                       0.5443,  0.7048, -0.8123,  0.1890, -0.2087,  0.0978,  0.1175,  0.0488,\n",
       "                      -0.3868, -0.1939,  0.1089, -0.4571, -0.0613, -0.3399,  0.4603,  0.1733,\n",
       "                      -0.3530,  0.1698, -0.3653, -0.4882,  0.0573, -0.0095,  0.3071,  0.3315,\n",
       "                       0.3030, -0.5403,  0.0657,  0.1266,  0.0201,  0.0203, -0.0623, -0.2637,\n",
       "                      -0.3389,  0.3613, -0.1978,  0.2255,  0.3015,  0.4886,  0.4628,  0.4543],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.2.1.running_var',\n",
       "              tensor([0.4341, 0.5010, 0.5003, 0.4717, 0.3296, 0.2574, 0.3748, 0.6318, 0.2433,\n",
       "                      0.4302, 0.2385, 0.3211, 0.0777, 0.2710, 0.4782, 0.3720, 0.3314, 0.3843,\n",
       "                      0.3304, 0.1331, 0.2116, 0.4893, 0.3066, 0.2812, 0.4371, 0.1976, 0.3328,\n",
       "                      0.1834, 0.1537, 0.2551, 0.5762, 0.6211, 0.3570, 0.3631, 0.5047, 0.2072,\n",
       "                      0.1735, 0.1507, 0.4816, 0.3639, 0.5588, 0.5165, 0.1427, 0.1776, 0.3557,\n",
       "                      0.2238, 0.3823, 0.2334, 0.6126, 0.2091, 0.2440, 0.4523, 0.5193, 0.4251,\n",
       "                      0.3072, 0.3365, 0.5630, 0.3503, 0.3632, 0.3673, 0.0628, 0.5931, 0.2075,\n",
       "                      0.3491, 0.4900, 0.2878, 0.2552, 0.4274, 0.3382, 0.6454, 0.2184, 0.2065,\n",
       "                      0.1440, 0.3929, 0.5260, 0.3500, 0.1571, 0.2379, 0.2796, 0.3024, 0.3227,\n",
       "                      0.2230, 0.7174, 0.3552, 0.4536, 0.4973, 0.5176, 0.3347, 0.3335, 0.1594,\n",
       "                      0.6222, 0.1895, 0.4836, 0.2193, 0.2678, 0.2000, 0.5660, 0.3048, 0.3450,\n",
       "                      0.3924, 0.3225, 0.3510, 0.2847, 0.3685, 0.3997, 0.3987, 0.3094, 0.2452,\n",
       "                      0.4192, 0.1789, 0.1316, 0.5826, 0.6280, 0.4521, 0.2742, 0.6394, 0.2055,\n",
       "                      0.2683, 0.4585, 0.2726, 0.0637, 0.3251, 0.6829, 0.2007, 0.1782, 0.4782,\n",
       "                      0.4326, 0.2947, 0.1405, 0.6025, 0.3042, 0.1580, 0.3477, 0.4006, 0.4220,\n",
       "                      0.0915, 0.6197, 0.2680, 0.4636, 0.3206, 0.1654, 0.0536, 0.2961, 0.0555,\n",
       "                      0.2196, 0.3075, 0.2937, 0.4027, 0.5107, 0.2758, 0.5003, 0.1201, 0.3101,\n",
       "                      0.4930, 0.4281, 0.3523, 0.2032, 0.3536, 0.3066, 0.1138, 0.1840, 0.1884,\n",
       "                      0.3643, 0.3074, 0.2156, 0.2430, 0.6827, 0.5311, 0.2100, 0.2853, 0.3571,\n",
       "                      0.3646, 0.4040, 0.2706, 0.2679, 0.3508, 0.3773, 0.5498, 0.4243, 0.2326,\n",
       "                      0.3234, 0.2553, 0.6887, 0.5037, 0.1880, 0.4436, 0.4816, 0.2002, 0.2692,\n",
       "                      0.1627, 0.2520, 0.5069, 0.5069, 0.6947, 0.3158, 0.3466, 0.5558, 0.2225,\n",
       "                      0.5419, 0.2837, 0.2488, 0.2575, 0.3021, 0.4223, 0.3250, 0.4568, 0.5204,\n",
       "                      0.0493, 0.3865, 0.5032, 0.1194, 0.3346, 0.1460, 0.3589, 0.2040, 0.2098,\n",
       "                      0.3106, 0.2590, 0.6542, 0.2730, 0.0955, 0.3001, 0.0792, 0.4771, 0.2620,\n",
       "                      0.3220, 0.1112, 0.1713, 0.3128, 0.5375, 0.2936, 0.1748, 0.5022, 0.3253,\n",
       "                      0.2516, 0.4851, 0.2133, 0.2062, 0.4364, 0.2585, 0.2966, 0.3104, 0.4686,\n",
       "                      0.2842, 0.1494, 0.3829, 0.3308, 0.2755, 0.0891, 0.2700, 0.4172, 0.4015,\n",
       "                      0.2388, 0.4631, 0.3016, 0.4052], dtype=torch.float64)),\n",
       "             ('6.3.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.4.convs.0.0.weight',\n",
       "              tensor([[[ 0.1280],\n",
       "                       [-0.1035],\n",
       "                       [-0.1267],\n",
       "                       ...,\n",
       "                       [ 0.0234],\n",
       "                       [-0.1324],\n",
       "                       [-0.0155]],\n",
       "              \n",
       "                      [[-0.0662],\n",
       "                       [ 0.0655],\n",
       "                       [-0.0418],\n",
       "                       ...,\n",
       "                       [ 0.0477],\n",
       "                       [ 0.0338],\n",
       "                       [-0.0227]],\n",
       "              \n",
       "                      [[-0.0016],\n",
       "                       [-0.2553],\n",
       "                       [ 0.1632],\n",
       "                       ...,\n",
       "                       [ 0.0109],\n",
       "                       [ 0.0203],\n",
       "                       [-0.0257]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1318],\n",
       "                       [-0.0291],\n",
       "                       [-0.0040],\n",
       "                       ...,\n",
       "                       [ 0.1129],\n",
       "                       [ 0.0471],\n",
       "                       [ 0.1508]],\n",
       "              \n",
       "                      [[ 0.0143],\n",
       "                       [-0.0080],\n",
       "                       [-0.2073],\n",
       "                       ...,\n",
       "                       [ 0.0025],\n",
       "                       [-0.0724],\n",
       "                       [-0.0636]],\n",
       "              \n",
       "                      [[ 0.0787],\n",
       "                       [ 0.0510],\n",
       "                       [ 0.0584],\n",
       "                       ...,\n",
       "                       [ 0.0343],\n",
       "                       [-0.0017],\n",
       "                       [ 0.1709]]], dtype=torch.float64)),\n",
       "             ('6.4.convs.0.1.weight',\n",
       "              tensor([0.9807, 0.9721, 0.9847, 0.9757, 0.9631, 0.9427, 0.9723, 0.9878, 0.9873,\n",
       "                      0.9670, 0.9786, 0.9806, 0.9669, 0.9876, 0.9624, 0.9503, 0.9845, 0.9650,\n",
       "                      0.9801, 0.9723, 0.9717, 0.9938, 0.9846, 0.9574, 0.9818, 0.9801, 0.9945,\n",
       "                      0.9848, 0.9668, 0.9754, 0.9716, 0.9662, 0.9553, 0.9737, 0.9539, 0.9802,\n",
       "                      0.9842, 0.9895, 0.9575, 0.9840, 0.9647, 0.9551, 0.9717, 0.9806, 0.9823,\n",
       "                      0.9882, 0.9692, 1.0054, 0.9572, 0.9526, 0.9741, 0.9717, 0.9626, 0.9683,\n",
       "                      0.9956, 0.9699, 0.9870, 0.9521, 0.9751, 0.9768, 0.9590, 0.9907, 0.9785,\n",
       "                      0.9806], dtype=torch.float64)),\n",
       "             ('6.4.convs.0.1.bias',\n",
       "              tensor([ 0.0231,  0.0084,  0.0175,  0.0032, -0.0044,  0.0022,  0.0005,  0.0068,\n",
       "                       0.0294, -0.0039,  0.0139,  0.0146,  0.0021, -0.0112, -0.0075, -0.0183,\n",
       "                      -0.0057, -0.0030,  0.0052,  0.0185,  0.0066, -0.0033,  0.0077, -0.0028,\n",
       "                       0.0147,  0.0131,  0.0093,  0.0134, -0.0077,  0.0007,  0.0179, -0.0145,\n",
       "                      -0.0117,  0.0109,  0.0050, -0.0123,  0.0012,  0.0095,  0.0069,  0.0093,\n",
       "                      -0.0238, -0.0028,  0.0161,  0.0110,  0.0203, -0.0077,  0.0140,  0.0006,\n",
       "                       0.0025,  0.0003, -0.0101, -0.0079, -0.0035, -0.0043,  0.0112, -0.0049,\n",
       "                       0.0020, -0.0036,  0.0011,  0.0058, -0.0036,  0.0191, -0.0133,  0.0172],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convs.0.1.running_mean',\n",
       "              tensor([-0.4632,  0.1254, -0.2832,  0.2285, -0.4278,  0.2034,  0.6618,  0.1904,\n",
       "                       0.2264,  0.0017,  0.6837, -0.1792, -0.1299,  0.4395,  0.3017,  0.3805,\n",
       "                       0.2763, -0.6976, -0.4208, -0.2723, -0.7767, -0.2275, -0.5867,  0.3027,\n",
       "                       0.0678,  0.7659, -0.0750,  0.3878, -0.4447, -0.0967, -0.3339,  0.6166,\n",
       "                      -0.1603,  0.0918, -0.6660, -0.2460,  0.4202,  0.9156, -0.7886,  0.7088,\n",
       "                       0.3207, -0.8936,  0.0956, -0.4044, -0.0597,  0.7690,  0.3459, -0.0099,\n",
       "                       0.0109, -0.3409,  0.3994, -0.3050, -0.7988,  0.9873,  0.1096, -0.0741,\n",
       "                       0.0498, -0.3661, -0.3707, -0.0149, -0.6798,  0.0506,  0.0972,  0.2328],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convs.0.1.running_var',\n",
       "              tensor([0.3478, 0.2438, 0.2253, 0.1620, 0.1947, 0.6998, 0.4111, 0.2117, 0.1464,\n",
       "                      0.1023, 0.1456, 0.2223, 0.1159, 0.1351, 0.1883, 0.1088, 0.1631, 0.2100,\n",
       "                      0.1679, 0.1516, 0.4105, 0.1724, 0.3009, 0.2516, 0.1694, 0.1956, 0.1129,\n",
       "                      0.2155, 0.1152, 0.1496, 0.2730, 0.2059, 0.1170, 0.2246, 0.7556, 0.1561,\n",
       "                      0.4204, 0.3233, 0.2207, 0.2742, 0.1411, 0.1675, 0.2316, 0.0967, 0.3162,\n",
       "                      0.4024, 0.5191, 0.1587, 0.1848, 0.2976, 0.8460, 0.1420, 0.3716, 0.3126,\n",
       "                      0.1283, 0.2314, 0.1193, 0.2613, 0.2010, 0.1078, 0.1955, 0.2995, 0.1385,\n",
       "                      0.2758], dtype=torch.float64)),\n",
       "             ('6.4.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.4.convs.1.0.weight',\n",
       "              tensor([[[-0.1009,  0.0396, -0.0098,  0.0778,  0.0400],\n",
       "                       [ 0.0229, -0.0880, -0.0927, -0.0935,  0.0848],\n",
       "                       [-0.0767,  0.0681,  0.0920, -0.1410, -0.0927],\n",
       "                       ...,\n",
       "                       [-0.0512,  0.1677,  0.0994, -0.0141,  0.0300],\n",
       "                       [-0.0760, -0.0037, -0.0808, -0.0341,  0.1678],\n",
       "                       [-0.1196, -0.0016, -0.1586,  0.0782,  0.0169]],\n",
       "              \n",
       "                      [[ 0.0108,  0.0159,  0.0184, -0.0552, -0.1591],\n",
       "                       [-0.0429,  0.0586, -0.0309,  0.0274,  0.0171],\n",
       "                       [ 0.0439,  0.0376,  0.0414, -0.0188,  0.0524],\n",
       "                       ...,\n",
       "                       [ 0.0145, -0.0361,  0.0838, -0.1250,  0.0598],\n",
       "                       [-0.0951, -0.1479, -0.0316, -0.0466, -0.0092],\n",
       "                       [-0.0773,  0.0057, -0.0394,  0.0655, -0.0480]],\n",
       "              \n",
       "                      [[ 0.0376, -0.0342,  0.0334, -0.0860,  0.0487],\n",
       "                       [ 0.0154, -0.0532,  0.0683,  0.0355, -0.0254],\n",
       "                       [ 0.0809,  0.0056,  0.0085,  0.1268, -0.1113],\n",
       "                       ...,\n",
       "                       [-0.0021,  0.0458, -0.0546, -0.0760,  0.1382],\n",
       "                       [-0.0579,  0.0031,  0.0618,  0.1125, -0.0129],\n",
       "                       [ 0.0688, -0.1407,  0.0624, -0.0104,  0.1265]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0013,  0.0037,  0.0856,  0.1482, -0.0292],\n",
       "                       [-0.0881, -0.0076, -0.1153,  0.0297, -0.1292],\n",
       "                       [ 0.0674, -0.0180,  0.0214,  0.0931,  0.1507],\n",
       "                       ...,\n",
       "                       [-0.1210,  0.0269, -0.0213,  0.0953, -0.1508],\n",
       "                       [ 0.0710, -0.0595, -0.0486, -0.0358,  0.0326],\n",
       "                       [ 0.0008,  0.0471, -0.0873,  0.1042, -0.0103]],\n",
       "              \n",
       "                      [[ 0.0133, -0.1807, -0.0205, -0.0349, -0.0361],\n",
       "                       [ 0.0168, -0.0922, -0.0075, -0.0230, -0.0077],\n",
       "                       [-0.1613, -0.0623,  0.1027, -0.0887, -0.0915],\n",
       "                       ...,\n",
       "                       [ 0.1921, -0.0446, -0.0346, -0.0087, -0.1432],\n",
       "                       [ 0.0472,  0.0879,  0.0978, -0.1704, -0.0623],\n",
       "                       [ 0.1263,  0.0488, -0.0005, -0.1189, -0.0551]],\n",
       "              \n",
       "                      [[-0.0630, -0.0381, -0.0110, -0.0004, -0.1338],\n",
       "                       [ 0.0687,  0.0397,  0.1359, -0.0807, -0.0480],\n",
       "                       [-0.1538,  0.0459, -0.1119, -0.1158, -0.0047],\n",
       "                       ...,\n",
       "                       [ 0.0625,  0.0423, -0.1700, -0.1070,  0.0294],\n",
       "                       [-0.1350,  0.0003,  0.0328,  0.0574, -0.0229],\n",
       "                       [-0.0210, -0.0804,  0.0550, -0.0938,  0.0052]]], dtype=torch.float64)),\n",
       "             ('6.4.convs.1.1.weight',\n",
       "              tensor([0.9490, 0.9618, 0.9643, 0.9565, 0.9953, 0.9524, 0.9949, 0.9843, 0.9873,\n",
       "                      0.9507, 0.9973, 0.9819, 0.9750, 0.9403, 0.9757, 1.0033, 0.9857, 0.9775,\n",
       "                      0.9479, 0.9468, 0.9538, 0.9975, 0.9537, 0.9758, 0.9871, 0.9519, 0.9517,\n",
       "                      0.9497, 0.9672, 0.9589, 0.9285, 0.9483, 0.9615, 0.9537, 0.9729, 0.9673,\n",
       "                      1.0058, 0.9735, 1.0046, 0.9411, 0.9842, 0.9448, 0.9451, 0.9805, 0.9532,\n",
       "                      0.9596, 0.9459, 0.9615, 1.0006, 0.9495, 0.9503, 0.9809, 0.9946, 0.9711,\n",
       "                      0.9747, 0.9663, 0.9565, 0.9702, 0.9744, 0.9638, 0.9725, 0.9726, 0.9660,\n",
       "                      0.9129], dtype=torch.float64)),\n",
       "             ('6.4.convs.1.1.bias',\n",
       "              tensor([ 0.0017, -0.0114, -0.0090, -0.0182, -0.0016, -0.0167,  0.0117,  0.0108,\n",
       "                       0.0028, -0.0185,  0.0053, -0.0097, -0.0044, -0.0147, -0.0088, -0.0060,\n",
       "                       0.0046,  0.0070, -0.0080, -0.0199, -0.0267,  0.0001, -0.0241,  0.0119,\n",
       "                       0.0002, -0.0099, -0.0102, -0.0166, -0.0084, -0.0016, -0.0240,  0.0022,\n",
       "                       0.0062, -0.0156,  0.0039, -0.0083,  0.0126, -0.0183,  0.0080, -0.0134,\n",
       "                       0.0148, -0.0238,  0.0015,  0.0038, -0.0218, -0.0044, -0.0049, -0.0166,\n",
       "                       0.0053, -0.0194, -0.0119, -0.0195,  0.0126, -0.0081,  0.0068, -0.0047,\n",
       "                      -0.0144, -0.0002,  0.0217, -0.0168, -0.0189,  0.0076, -0.0035, -0.0436],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convs.1.1.running_mean',\n",
       "              tensor([ 0.0520, -0.3497,  0.2465,  0.5670, -0.1592,  1.0190, -0.3990, -1.3045,\n",
       "                       0.5461, -0.5007, -0.1933,  0.1321,  0.5867, -0.3740,  0.4004, -0.4818,\n",
       "                      -0.0083, -0.3740,  0.0236,  0.1452, -0.0501, -0.1232,  0.2434, -0.1064,\n",
       "                      -0.5605, -0.7148, -0.4565, -0.5675,  0.3973, -0.2842,  0.3199,  0.2826,\n",
       "                      -0.0827,  0.0302, -0.6990,  0.4517,  0.5122, -0.5620, -0.7103, -0.4283,\n",
       "                      -0.5415,  0.4392, -1.0027,  0.7853, -0.1548,  0.1258, -0.8138,  0.0936,\n",
       "                      -0.8065,  0.1128, -0.0932, -0.3343, -0.7423,  0.4191,  0.7258, -0.4051,\n",
       "                       0.2153, -0.1921, -0.2375,  0.0686,  0.2159,  0.1159, -0.0996, -0.1184],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convs.1.1.running_var',\n",
       "              tensor([1.0626, 0.5801, 0.6503, 0.9425, 0.4242, 0.5902, 0.4234, 0.8099, 0.6436,\n",
       "                      0.3924, 0.4306, 0.4521, 0.7153, 0.5366, 0.4428, 0.5372, 0.4932, 0.9594,\n",
       "                      0.7078, 0.6520, 0.6870, 0.6246, 0.6585, 0.7185, 0.5546, 0.7186, 0.8713,\n",
       "                      0.6144, 0.9297, 0.5674, 0.7979, 0.5965, 0.5661, 0.5799, 0.5042, 0.5999,\n",
       "                      0.5258, 0.5599, 0.5901, 0.6729, 0.9104, 0.7179, 1.1477, 0.5352, 0.8912,\n",
       "                      0.5603, 0.7482, 0.5773, 0.5991, 0.5261, 0.6770, 0.4682, 0.5949, 0.6587,\n",
       "                      0.6382, 0.4620, 0.4947, 0.5200, 0.5374, 0.5990, 0.6383, 0.5406, 0.4891,\n",
       "                      0.5751], dtype=torch.float64)),\n",
       "             ('6.4.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.4.convs.2.0.weight',\n",
       "              tensor([[[-0.0250],\n",
       "                       [-0.1015],\n",
       "                       [ 0.0820],\n",
       "                       ...,\n",
       "                       [ 0.0650],\n",
       "                       [-0.0890],\n",
       "                       [-0.0026]],\n",
       "              \n",
       "                      [[ 0.1290],\n",
       "                       [-0.2047],\n",
       "                       [ 0.0978],\n",
       "                       ...,\n",
       "                       [ 0.1049],\n",
       "                       [ 0.0355],\n",
       "                       [-0.0473]],\n",
       "              \n",
       "                      [[-0.0280],\n",
       "                       [ 0.0822],\n",
       "                       [ 0.1379],\n",
       "                       ...,\n",
       "                       [ 0.3214],\n",
       "                       [ 0.1775],\n",
       "                       [-0.0158]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0762],\n",
       "                       [-0.0503],\n",
       "                       [-0.0580],\n",
       "                       ...,\n",
       "                       [ 0.0658],\n",
       "                       [-0.1374],\n",
       "                       [-0.0721]],\n",
       "              \n",
       "                      [[ 0.0442],\n",
       "                       [-0.1015],\n",
       "                       [-0.0833],\n",
       "                       ...,\n",
       "                       [ 0.0022],\n",
       "                       [ 0.0476],\n",
       "                       [ 0.0433]],\n",
       "              \n",
       "                      [[ 0.0341],\n",
       "                       [ 0.0254],\n",
       "                       [ 0.0146],\n",
       "                       ...,\n",
       "                       [-0.0757],\n",
       "                       [ 0.0988],\n",
       "                       [-0.2498]]], dtype=torch.float64)),\n",
       "             ('6.4.convs.2.1.weight',\n",
       "              tensor([-0.0011, -0.0479, -0.0201,  0.0160,  0.0068, -0.0148,  0.0082, -0.0030,\n",
       "                      -0.0180,  0.0132, -0.0259,  0.0088, -0.0107, -0.0015,  0.0107,  0.0286,\n",
       "                      -0.0261,  0.0115,  0.0083, -0.0051, -0.0113, -0.0046,  0.0135,  0.0067,\n",
       "                      -0.0220, -0.0050,  0.0052, -0.0052,  0.0071, -0.0080,  0.0073, -0.0215,\n",
       "                      -0.0235, -0.0184,  0.0125,  0.0064,  0.0063,  0.0332, -0.0236, -0.0033,\n",
       "                      -0.0119, -0.0168,  0.0142,  0.0036, -0.0057, -0.0072, -0.0131,  0.0179,\n",
       "                      -0.0249, -0.0043,  0.0108, -0.0013,  0.0071,  0.0055, -0.0088, -0.0206,\n",
       "                      -0.0092,  0.0001, -0.0202,  0.0064,  0.0071, -0.0079, -0.0008, -0.0016,\n",
       "                      -0.0124, -0.0144,  0.0160, -0.0350,  0.0270, -0.0359,  0.0041, -0.0147,\n",
       "                       0.0056, -0.0142,  0.0213, -0.0318,  0.0168,  0.0263, -0.0007,  0.0293,\n",
       "                       0.0070, -0.0078,  0.0083,  0.0019, -0.0058,  0.0052,  0.0215, -0.0028,\n",
       "                       0.0479, -0.0037, -0.0111,  0.0345, -0.0226,  0.0209, -0.0114,  0.0079,\n",
       "                       0.0301, -0.0178, -0.0196,  0.0275, -0.0087,  0.0043, -0.0014, -0.0294,\n",
       "                      -0.0147,  0.0415,  0.0185,  0.0046,  0.0017,  0.0207, -0.0186,  0.0057,\n",
       "                      -0.0069,  0.0448,  0.0028,  0.0037, -0.0237,  0.0362, -0.0187,  0.0092,\n",
       "                       0.0193, -0.0005, -0.0075,  0.0195,  0.0235,  0.0443,  0.0180, -0.0195,\n",
       "                       0.0217,  0.0087,  0.0118,  0.0253,  0.0193,  0.0175, -0.0098,  0.0027,\n",
       "                      -0.0065,  0.0210, -0.0177,  0.0076, -0.0089, -0.0003,  0.0013, -0.0146,\n",
       "                       0.0088, -0.0106, -0.0135,  0.0165,  0.0004, -0.0232,  0.0007,  0.0097,\n",
       "                      -0.0303,  0.0294, -0.0061,  0.0088,  0.0110,  0.0155, -0.0024,  0.0074,\n",
       "                       0.0199, -0.0048,  0.0156,  0.0182, -0.0261, -0.0236, -0.0208,  0.0117,\n",
       "                      -0.0065, -0.0118, -0.0203, -0.0021,  0.0209,  0.0124, -0.0115, -0.0097,\n",
       "                       0.0209, -0.0109,  0.0285, -0.0239, -0.0137,  0.0038, -0.0142,  0.0075,\n",
       "                       0.0060,  0.0348,  0.0179, -0.0271, -0.0088, -0.0101,  0.0257, -0.0072,\n",
       "                       0.0388, -0.0050,  0.0307,  0.0232, -0.0081,  0.0033, -0.0053, -0.0152,\n",
       "                       0.0019, -0.0301,  0.0160,  0.0028, -0.0024,  0.0135, -0.0110,  0.0100,\n",
       "                      -0.0009,  0.0225, -0.0051, -0.0140, -0.0033, -0.0232, -0.0243, -0.0016,\n",
       "                      -0.0181,  0.0059, -0.0318,  0.0182,  0.0135,  0.0002, -0.0116, -0.0438,\n",
       "                       0.0155, -0.0041,  0.0100,  0.0062, -0.0251, -0.0057,  0.0244, -0.0029,\n",
       "                       0.0138,  0.0174, -0.0226,  0.0022,  0.0054,  0.0005, -0.0127, -0.0399,\n",
       "                       0.0104,  0.0035, -0.0016, -0.0032,  0.0158,  0.0068, -0.0008,  0.0151,\n",
       "                      -0.0097, -0.0069, -0.0213, -0.0070, -0.0096, -0.0086,  0.0038,  0.0115],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convs.2.1.bias',\n",
       "              tensor([-1.8370e-03, -2.6875e-03,  1.5379e-02,  1.2035e-02,  4.9408e-03,\n",
       "                       1.2134e-03,  1.6583e-02,  1.2081e-03,  9.5634e-03,  2.0832e-02,\n",
       "                       1.2867e-02, -1.0210e-02,  1.0119e-02, -6.8539e-03,  4.7702e-03,\n",
       "                       5.3555e-03,  1.9853e-02, -3.0166e-03,  1.4356e-02, -8.5206e-03,\n",
       "                      -2.6003e-03,  3.7214e-03,  1.6397e-03,  7.2353e-03, -6.6857e-03,\n",
       "                      -1.4696e-02,  5.3495e-03,  1.0900e-02,  1.4468e-03, -9.7419e-04,\n",
       "                       4.3466e-03,  1.0235e-02, -7.8811e-03,  1.6031e-02,  1.2407e-02,\n",
       "                       6.7733e-03, -7.6309e-04,  2.3151e-02,  9.3699e-03,  1.2561e-02,\n",
       "                       8.4103e-04,  2.2984e-02, -1.0065e-02,  1.0576e-03,  5.2806e-03,\n",
       "                      -1.0564e-02,  7.5361e-03,  3.1138e-03, -1.1481e-02,  1.0546e-02,\n",
       "                       8.3467e-03,  1.1713e-02,  9.0517e-03,  1.3792e-02,  5.4382e-03,\n",
       "                       9.8816e-03,  7.3442e-03,  2.7423e-03,  9.5493e-03,  5.6132e-03,\n",
       "                      -3.9700e-03,  2.7289e-03, -1.9820e-03,  9.1470e-03, -4.1751e-03,\n",
       "                       1.5072e-02, -1.1553e-02,  1.3178e-02, -3.0353e-05, -1.1024e-02,\n",
       "                       3.0832e-03,  2.1578e-03,  4.1882e-03, -7.9632e-03,  1.4675e-02,\n",
       "                       9.4079e-03,  5.2735e-04,  2.4768e-03,  4.5680e-03,  6.0121e-03,\n",
       "                       1.0969e-02, -5.3145e-03,  6.8254e-03,  3.7663e-03, -1.8369e-03,\n",
       "                       1.4304e-02,  1.6385e-03,  1.0812e-03,  9.0085e-03,  8.3380e-03,\n",
       "                      -5.8234e-04,  2.3383e-02,  1.7966e-02, -1.7059e-03,  4.8624e-03,\n",
       "                      -1.4463e-02,  5.6700e-03, -1.6406e-03,  1.7180e-02,  5.1274e-03,\n",
       "                       2.4426e-02,  2.9203e-03, -2.1263e-03,  2.7024e-04,  1.5335e-02,\n",
       "                      -1.0046e-04, -5.4698e-04,  3.4165e-03,  4.5562e-03,  6.4173e-03,\n",
       "                      -7.2215e-03, -7.4533e-03,  3.0880e-03,  1.6115e-02,  1.1805e-02,\n",
       "                       6.7155e-03,  1.1963e-02,  3.0259e-03,  2.8999e-03, -1.5330e-02,\n",
       "                       2.2357e-03,  7.7554e-03,  2.1973e-03, -3.1272e-03, -8.5270e-03,\n",
       "                       1.3134e-02,  1.5939e-02,  4.8649e-03, -8.4191e-04,  1.5522e-02,\n",
       "                       4.1832e-03,  1.8042e-02,  1.5133e-02,  8.3510e-03,  1.7760e-02,\n",
       "                      -7.8655e-03,  1.5849e-02,  7.6290e-03,  1.6681e-02,  1.1034e-02,\n",
       "                       1.9224e-03, -2.6729e-03,  1.4353e-02,  7.9760e-03, -1.1313e-02,\n",
       "                       8.1680e-03,  1.1053e-03, -2.6305e-03,  1.0372e-02,  9.1032e-03,\n",
       "                       4.3696e-03,  1.2062e-02,  3.6035e-03,  1.5166e-02,  1.4700e-02,\n",
       "                       8.5381e-03,  1.7248e-04,  7.2469e-03, -4.0253e-03, -1.0292e-02,\n",
       "                       1.3818e-03, -6.4041e-03,  1.9709e-03,  1.3232e-02,  1.2248e-02,\n",
       "                       1.2898e-03, -6.7087e-03,  8.6962e-03,  4.5678e-04,  1.6007e-02,\n",
       "                       5.1131e-03,  9.2164e-03,  1.3119e-02,  9.9323e-03, -1.4023e-02,\n",
       "                       6.8301e-03,  2.5819e-05,  1.1927e-02,  5.3145e-03,  5.7587e-03,\n",
       "                      -2.4298e-03,  1.0922e-02, -8.6950e-03, -1.0278e-02,  1.8226e-02,\n",
       "                       9.3580e-03,  1.4619e-02,  1.5217e-02, -1.8821e-03,  2.8029e-03,\n",
       "                       6.2048e-03,  1.0225e-03,  1.4009e-02, -9.7795e-03,  8.8851e-03,\n",
       "                       8.1547e-03, -2.1327e-03,  1.6713e-02,  1.0295e-02, -1.1045e-03,\n",
       "                       5.1762e-03,  1.5567e-02,  2.0571e-02,  1.7335e-02,  6.9624e-04,\n",
       "                      -3.5247e-03,  1.3890e-02, -3.6876e-03,  8.4294e-03,  5.8960e-03,\n",
       "                       2.0546e-03,  1.2638e-02,  1.3217e-02,  6.4027e-03,  1.7988e-02,\n",
       "                       4.1882e-03,  4.2172e-03, -3.0074e-03,  5.6205e-03, -4.0968e-04,\n",
       "                      -1.4860e-02,  2.7172e-03,  6.6953e-03,  2.4314e-02, -2.0668e-03,\n",
       "                       2.1919e-03, -2.8550e-03,  1.8016e-03, -1.4178e-02,  1.4157e-02,\n",
       "                       1.4764e-02, -5.3188e-04,  1.0742e-02,  1.1818e-02,  4.9984e-03,\n",
       "                       5.8159e-03,  7.7722e-03, -5.2791e-03,  1.0704e-02,  1.1160e-02,\n",
       "                       2.8725e-03,  4.0150e-03,  4.6042e-03,  7.7357e-03,  2.0129e-03,\n",
       "                       1.5003e-02,  9.2370e-04,  9.8652e-03,  2.9754e-03, -9.1533e-03,\n",
       "                       1.6761e-02,  1.6266e-02,  1.9418e-02,  1.7963e-02,  1.1984e-02,\n",
       "                       9.2275e-03], dtype=torch.float64)),\n",
       "             ('6.4.convs.2.1.running_mean',\n",
       "              tensor([-0.3974,  0.1077, -0.2802, -0.1166, -0.3220, -0.3529,  0.2312,  0.7063,\n",
       "                      -0.2523,  0.1950,  0.1701, -0.2574,  0.6776,  0.4325,  0.1331, -0.0290,\n",
       "                       0.5061,  0.3579, -0.1989,  0.7621, -0.3798,  0.2630, -0.0853,  0.4532,\n",
       "                      -0.0416, -0.3358,  0.5746, -0.0730,  0.0841,  0.1087, -0.5156,  0.1337,\n",
       "                      -0.2527,  0.1759,  0.3452, -0.7231,  0.0842,  0.1331,  0.2891,  0.4821,\n",
       "                       0.7246,  0.2932, -0.3362,  0.4722,  0.0842,  0.1145, -0.7889, -0.0069,\n",
       "                      -0.1401,  0.6070,  0.5296, -0.4861,  0.0054, -0.7023,  0.2118, -0.3339,\n",
       "                       0.9015,  1.0911, -0.5373,  0.6277, -0.0784,  0.3673,  0.1592,  0.0747,\n",
       "                       0.3963, -0.3667,  0.6330,  0.0582, -0.1076, -0.1507, -0.0446,  0.6002,\n",
       "                      -0.3472, -0.1630,  0.7214, -0.5755, -0.2325,  0.0797, -0.0833,  0.0694,\n",
       "                       0.1554,  0.1512, -0.4663, -1.1767,  0.1685,  0.2629, -0.4775, -0.2025,\n",
       "                       0.0101, -0.1029, -0.4431,  0.0650,  0.9164,  0.2291,  0.6091, -0.2324,\n",
       "                      -0.0886,  0.0518, -0.0926,  0.0344,  0.1858,  0.0606, -0.0819,  0.0348,\n",
       "                       0.0800, -0.2929, -0.2003,  0.1831, -0.1717,  0.0143,  0.3365,  0.5760,\n",
       "                      -0.2220, -0.1969,  0.2613, -0.0582,  0.4463,  0.1057,  0.1847,  0.3174,\n",
       "                      -0.1975,  0.2046,  0.5035, -0.4142, -0.4236, -0.2447, -0.1490,  0.3458,\n",
       "                      -0.2327,  0.1259,  0.1543, -0.0733,  0.0867,  0.3355, -0.2515, -0.0154,\n",
       "                       0.5075,  0.0990, -0.1883,  0.0694,  0.8120, -0.1108,  0.0098, -0.4889,\n",
       "                      -0.0717,  0.5576, -0.3773,  0.6690, -0.3063, -0.3096,  0.2689, -0.3294,\n",
       "                       0.2039, -0.5384, -0.0503, -0.0396, -0.2377, -0.1569, -0.1366,  0.3667,\n",
       "                       0.0411,  0.3711,  0.0060,  0.5850, -0.6389, -0.0365, -0.5077, -0.1886,\n",
       "                      -0.3189,  0.8862, -0.3756,  0.1034,  0.1739, -0.0364,  0.3530, -0.6078,\n",
       "                      -0.1116, -0.1238, -0.7973,  0.6964,  0.1805, -0.6911, -0.0254,  0.2004,\n",
       "                       0.1116, -0.5385, -0.0997, -0.0338,  0.1931, -0.2240, -0.6057,  0.4758,\n",
       "                      -0.0143, -0.7082,  0.7428, -0.1877,  0.0836, -0.6641,  0.1989, -0.7697,\n",
       "                       0.0991, -0.0792, -0.0984,  0.2259,  0.2277, -0.1197,  0.2570, -0.1575,\n",
       "                       0.1485, -0.5174, -0.3400,  0.0772, -0.2050,  0.3241,  0.0155,  0.0784,\n",
       "                      -0.3682, -0.2941,  0.5220, -0.2272, -0.0152,  0.1009,  0.1004,  0.0857,\n",
       "                      -0.0244, -0.2347,  0.5105,  0.1286,  0.4996, -0.7752, -0.2557,  0.4114,\n",
       "                      -0.3314,  0.0551, -0.2931, -0.0989,  0.2606,  0.0200, -0.6242, -0.3107,\n",
       "                       0.3429,  0.2048,  0.9197, -0.0703, -0.1459,  0.1527, -0.0396,  0.3572,\n",
       "                       0.0118,  0.7326, -0.1131, -0.0231,  0.0151,  0.5911, -0.1402, -0.6342],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convs.2.1.running_var',\n",
       "              tensor([0.1472, 0.3486, 0.3716, 0.4395, 0.2278, 0.2498, 0.3794, 0.3718, 0.2803,\n",
       "                      0.5386, 0.3291, 0.2888, 0.2754, 0.3337, 0.4292, 0.8511, 0.3940, 0.1962,\n",
       "                      0.2334, 0.4054, 0.2737, 0.4964, 0.3211, 0.3978, 0.5242, 0.2952, 0.3626,\n",
       "                      0.1308, 0.1969, 0.3664, 0.4631, 0.2625, 0.1587, 0.3955, 0.4356, 0.3696,\n",
       "                      0.2841, 0.2831, 0.3106, 0.4150, 0.5758, 0.4147, 0.1488, 0.3322, 0.5514,\n",
       "                      0.3669, 0.3603, 0.2739, 0.6134, 0.3705, 0.2440, 0.3284, 0.2875, 0.3740,\n",
       "                      0.4224, 0.5076, 0.3784, 0.5399, 0.4553, 0.4227, 0.0906, 0.2788, 0.1779,\n",
       "                      0.1031, 0.5642, 0.3690, 0.5450, 0.5527, 0.3077, 0.5021, 0.3690, 0.3127,\n",
       "                      0.3319, 0.4763, 0.5411, 0.4104, 0.5561, 0.2190, 0.4986, 0.4855, 0.2188,\n",
       "                      0.1709, 0.5330, 0.5350, 0.2796, 0.5786, 0.2239, 0.1199, 0.5622, 0.2679,\n",
       "                      0.5376, 0.3589, 0.3462, 0.2620, 0.4688, 0.1897, 0.7321, 0.3546, 0.2433,\n",
       "                      0.3423, 0.4263, 0.2544, 0.1348, 0.3485, 0.2557, 0.4167, 0.3867, 0.3730,\n",
       "                      0.1049, 0.2623, 0.2799, 0.3925, 0.4872, 0.4792, 0.2730, 0.4597, 0.5872,\n",
       "                      0.4667, 0.2628, 0.3703, 0.1727, 0.4204, 0.4452, 0.2528, 0.3729, 0.4062,\n",
       "                      0.2096, 0.3934, 0.2032, 0.2258, 0.1944, 0.3173, 0.6244, 0.2070, 0.1861,\n",
       "                      0.1173, 0.1743, 0.3277, 0.4274, 0.1691, 0.3133, 0.1068, 0.1015, 0.1829,\n",
       "                      0.1817, 0.3939, 0.2331, 0.2442, 0.1533, 0.4312, 0.5259, 0.3514, 0.4361,\n",
       "                      0.5202, 0.1493, 0.2379, 0.2297, 0.2928, 0.4470, 0.2550, 0.4084, 0.2241,\n",
       "                      0.3954, 0.5241, 0.4574, 0.5664, 0.4213, 0.2277, 0.1479, 0.6103, 0.2624,\n",
       "                      0.0888, 0.3613, 0.1309, 0.3847, 0.7010, 0.2637, 0.1558, 0.4992, 0.4508,\n",
       "                      0.3919, 0.1336, 0.4430, 0.3949, 0.2622, 0.3572, 0.1893, 0.2983, 0.2198,\n",
       "                      0.2234, 0.4277, 0.3513, 0.3864, 0.5135, 0.3570, 0.5219, 0.3487, 0.3159,\n",
       "                      0.4473, 0.4838, 0.2142, 0.3459, 0.3073, 0.2444, 0.2054, 0.4050, 0.3725,\n",
       "                      0.0875, 0.1595, 0.4734, 0.1919, 0.2168, 0.1162, 0.5572, 0.3566, 0.1770,\n",
       "                      0.4158, 0.0842, 0.5791, 0.4591, 0.2192, 0.2521, 0.1524, 0.3314, 0.6056,\n",
       "                      0.2725, 0.3667, 0.0607, 0.4667, 0.5683, 0.3986, 0.4278, 0.4730, 0.3376,\n",
       "                      0.2636, 0.3059, 0.1421, 0.1268, 0.5653, 0.4599, 0.3672, 0.2235, 0.2915,\n",
       "                      0.1495, 0.2015, 0.2248, 0.2086, 0.4980, 0.2256, 0.3493, 0.4005, 0.3727,\n",
       "                      0.2864, 0.3785, 0.1070, 0.3987], dtype=torch.float64)),\n",
       "             ('6.4.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.4.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.1280],\n",
       "                       [-0.1035],\n",
       "                       [-0.1267],\n",
       "                       ...,\n",
       "                       [ 0.0234],\n",
       "                       [-0.1324],\n",
       "                       [-0.0155]],\n",
       "              \n",
       "                      [[-0.0662],\n",
       "                       [ 0.0655],\n",
       "                       [-0.0418],\n",
       "                       ...,\n",
       "                       [ 0.0477],\n",
       "                       [ 0.0338],\n",
       "                       [-0.0227]],\n",
       "              \n",
       "                      [[-0.0016],\n",
       "                       [-0.2553],\n",
       "                       [ 0.1632],\n",
       "                       ...,\n",
       "                       [ 0.0109],\n",
       "                       [ 0.0203],\n",
       "                       [-0.0257]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1318],\n",
       "                       [-0.0291],\n",
       "                       [-0.0040],\n",
       "                       ...,\n",
       "                       [ 0.1129],\n",
       "                       [ 0.0471],\n",
       "                       [ 0.1508]],\n",
       "              \n",
       "                      [[ 0.0143],\n",
       "                       [-0.0080],\n",
       "                       [-0.2073],\n",
       "                       ...,\n",
       "                       [ 0.0025],\n",
       "                       [-0.0724],\n",
       "                       [-0.0636]],\n",
       "              \n",
       "                      [[ 0.0787],\n",
       "                       [ 0.0510],\n",
       "                       [ 0.0584],\n",
       "                       ...,\n",
       "                       [ 0.0343],\n",
       "                       [-0.0017],\n",
       "                       [ 0.1709]]], dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.0.1.weight',\n",
       "              tensor([0.9807, 0.9721, 0.9847, 0.9757, 0.9631, 0.9427, 0.9723, 0.9878, 0.9873,\n",
       "                      0.9670, 0.9786, 0.9806, 0.9669, 0.9876, 0.9624, 0.9503, 0.9845, 0.9650,\n",
       "                      0.9801, 0.9723, 0.9717, 0.9938, 0.9846, 0.9574, 0.9818, 0.9801, 0.9945,\n",
       "                      0.9848, 0.9668, 0.9754, 0.9716, 0.9662, 0.9553, 0.9737, 0.9539, 0.9802,\n",
       "                      0.9842, 0.9895, 0.9575, 0.9840, 0.9647, 0.9551, 0.9717, 0.9806, 0.9823,\n",
       "                      0.9882, 0.9692, 1.0054, 0.9572, 0.9526, 0.9741, 0.9717, 0.9626, 0.9683,\n",
       "                      0.9956, 0.9699, 0.9870, 0.9521, 0.9751, 0.9768, 0.9590, 0.9907, 0.9785,\n",
       "                      0.9806], dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0231,  0.0084,  0.0175,  0.0032, -0.0044,  0.0022,  0.0005,  0.0068,\n",
       "                       0.0294, -0.0039,  0.0139,  0.0146,  0.0021, -0.0112, -0.0075, -0.0183,\n",
       "                      -0.0057, -0.0030,  0.0052,  0.0185,  0.0066, -0.0033,  0.0077, -0.0028,\n",
       "                       0.0147,  0.0131,  0.0093,  0.0134, -0.0077,  0.0007,  0.0179, -0.0145,\n",
       "                      -0.0117,  0.0109,  0.0050, -0.0123,  0.0012,  0.0095,  0.0069,  0.0093,\n",
       "                      -0.0238, -0.0028,  0.0161,  0.0110,  0.0203, -0.0077,  0.0140,  0.0006,\n",
       "                       0.0025,  0.0003, -0.0101, -0.0079, -0.0035, -0.0043,  0.0112, -0.0049,\n",
       "                       0.0020, -0.0036,  0.0011,  0.0058, -0.0036,  0.0191, -0.0133,  0.0172],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.4632,  0.1254, -0.2832,  0.2285, -0.4278,  0.2034,  0.6618,  0.1904,\n",
       "                       0.2264,  0.0017,  0.6837, -0.1792, -0.1299,  0.4395,  0.3017,  0.3805,\n",
       "                       0.2763, -0.6976, -0.4208, -0.2723, -0.7767, -0.2275, -0.5867,  0.3027,\n",
       "                       0.0678,  0.7659, -0.0750,  0.3878, -0.4447, -0.0967, -0.3339,  0.6166,\n",
       "                      -0.1603,  0.0918, -0.6660, -0.2460,  0.4202,  0.9156, -0.7886,  0.7088,\n",
       "                       0.3207, -0.8936,  0.0956, -0.4044, -0.0597,  0.7690,  0.3459, -0.0099,\n",
       "                       0.0109, -0.3409,  0.3994, -0.3050, -0.7988,  0.9873,  0.1096, -0.0741,\n",
       "                       0.0498, -0.3661, -0.3707, -0.0149, -0.6798,  0.0506,  0.0972,  0.2328],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.0.1.running_var',\n",
       "              tensor([0.3478, 0.2438, 0.2253, 0.1620, 0.1947, 0.6998, 0.4111, 0.2117, 0.1464,\n",
       "                      0.1023, 0.1456, 0.2223, 0.1159, 0.1351, 0.1883, 0.1088, 0.1631, 0.2100,\n",
       "                      0.1679, 0.1516, 0.4105, 0.1724, 0.3009, 0.2516, 0.1694, 0.1956, 0.1129,\n",
       "                      0.2155, 0.1152, 0.1496, 0.2730, 0.2059, 0.1170, 0.2246, 0.7556, 0.1561,\n",
       "                      0.4204, 0.3233, 0.2207, 0.2742, 0.1411, 0.1675, 0.2316, 0.0967, 0.3162,\n",
       "                      0.4024, 0.5191, 0.1587, 0.1848, 0.2976, 0.8460, 0.1420, 0.3716, 0.3126,\n",
       "                      0.1283, 0.2314, 0.1193, 0.2613, 0.2010, 0.1078, 0.1955, 0.2995, 0.1385,\n",
       "                      0.2758], dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.4.convpath.0.1.0.weight',\n",
       "              tensor([[[-0.1009,  0.0396, -0.0098,  0.0778,  0.0400],\n",
       "                       [ 0.0229, -0.0880, -0.0927, -0.0935,  0.0848],\n",
       "                       [-0.0767,  0.0681,  0.0920, -0.1410, -0.0927],\n",
       "                       ...,\n",
       "                       [-0.0512,  0.1677,  0.0994, -0.0141,  0.0300],\n",
       "                       [-0.0760, -0.0037, -0.0808, -0.0341,  0.1678],\n",
       "                       [-0.1196, -0.0016, -0.1586,  0.0782,  0.0169]],\n",
       "              \n",
       "                      [[ 0.0108,  0.0159,  0.0184, -0.0552, -0.1591],\n",
       "                       [-0.0429,  0.0586, -0.0309,  0.0274,  0.0171],\n",
       "                       [ 0.0439,  0.0376,  0.0414, -0.0188,  0.0524],\n",
       "                       ...,\n",
       "                       [ 0.0145, -0.0361,  0.0838, -0.1250,  0.0598],\n",
       "                       [-0.0951, -0.1479, -0.0316, -0.0466, -0.0092],\n",
       "                       [-0.0773,  0.0057, -0.0394,  0.0655, -0.0480]],\n",
       "              \n",
       "                      [[ 0.0376, -0.0342,  0.0334, -0.0860,  0.0487],\n",
       "                       [ 0.0154, -0.0532,  0.0683,  0.0355, -0.0254],\n",
       "                       [ 0.0809,  0.0056,  0.0085,  0.1268, -0.1113],\n",
       "                       ...,\n",
       "                       [-0.0021,  0.0458, -0.0546, -0.0760,  0.1382],\n",
       "                       [-0.0579,  0.0031,  0.0618,  0.1125, -0.0129],\n",
       "                       [ 0.0688, -0.1407,  0.0624, -0.0104,  0.1265]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0013,  0.0037,  0.0856,  0.1482, -0.0292],\n",
       "                       [-0.0881, -0.0076, -0.1153,  0.0297, -0.1292],\n",
       "                       [ 0.0674, -0.0180,  0.0214,  0.0931,  0.1507],\n",
       "                       ...,\n",
       "                       [-0.1210,  0.0269, -0.0213,  0.0953, -0.1508],\n",
       "                       [ 0.0710, -0.0595, -0.0486, -0.0358,  0.0326],\n",
       "                       [ 0.0008,  0.0471, -0.0873,  0.1042, -0.0103]],\n",
       "              \n",
       "                      [[ 0.0133, -0.1807, -0.0205, -0.0349, -0.0361],\n",
       "                       [ 0.0168, -0.0922, -0.0075, -0.0230, -0.0077],\n",
       "                       [-0.1613, -0.0623,  0.1027, -0.0887, -0.0915],\n",
       "                       ...,\n",
       "                       [ 0.1921, -0.0446, -0.0346, -0.0087, -0.1432],\n",
       "                       [ 0.0472,  0.0879,  0.0978, -0.1704, -0.0623],\n",
       "                       [ 0.1263,  0.0488, -0.0005, -0.1189, -0.0551]],\n",
       "              \n",
       "                      [[-0.0630, -0.0381, -0.0110, -0.0004, -0.1338],\n",
       "                       [ 0.0687,  0.0397,  0.1359, -0.0807, -0.0480],\n",
       "                       [-0.1538,  0.0459, -0.1119, -0.1158, -0.0047],\n",
       "                       ...,\n",
       "                       [ 0.0625,  0.0423, -0.1700, -0.1070,  0.0294],\n",
       "                       [-0.1350,  0.0003,  0.0328,  0.0574, -0.0229],\n",
       "                       [-0.0210, -0.0804,  0.0550, -0.0938,  0.0052]]], dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.1.1.weight',\n",
       "              tensor([0.9490, 0.9618, 0.9643, 0.9565, 0.9953, 0.9524, 0.9949, 0.9843, 0.9873,\n",
       "                      0.9507, 0.9973, 0.9819, 0.9750, 0.9403, 0.9757, 1.0033, 0.9857, 0.9775,\n",
       "                      0.9479, 0.9468, 0.9538, 0.9975, 0.9537, 0.9758, 0.9871, 0.9519, 0.9517,\n",
       "                      0.9497, 0.9672, 0.9589, 0.9285, 0.9483, 0.9615, 0.9537, 0.9729, 0.9673,\n",
       "                      1.0058, 0.9735, 1.0046, 0.9411, 0.9842, 0.9448, 0.9451, 0.9805, 0.9532,\n",
       "                      0.9596, 0.9459, 0.9615, 1.0006, 0.9495, 0.9503, 0.9809, 0.9946, 0.9711,\n",
       "                      0.9747, 0.9663, 0.9565, 0.9702, 0.9744, 0.9638, 0.9725, 0.9726, 0.9660,\n",
       "                      0.9129], dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.1.1.bias',\n",
       "              tensor([ 0.0017, -0.0114, -0.0090, -0.0182, -0.0016, -0.0167,  0.0117,  0.0108,\n",
       "                       0.0028, -0.0185,  0.0053, -0.0097, -0.0044, -0.0147, -0.0088, -0.0060,\n",
       "                       0.0046,  0.0070, -0.0080, -0.0199, -0.0267,  0.0001, -0.0241,  0.0119,\n",
       "                       0.0002, -0.0099, -0.0102, -0.0166, -0.0084, -0.0016, -0.0240,  0.0022,\n",
       "                       0.0062, -0.0156,  0.0039, -0.0083,  0.0126, -0.0183,  0.0080, -0.0134,\n",
       "                       0.0148, -0.0238,  0.0015,  0.0038, -0.0218, -0.0044, -0.0049, -0.0166,\n",
       "                       0.0053, -0.0194, -0.0119, -0.0195,  0.0126, -0.0081,  0.0068, -0.0047,\n",
       "                      -0.0144, -0.0002,  0.0217, -0.0168, -0.0189,  0.0076, -0.0035, -0.0436],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.0520, -0.3497,  0.2465,  0.5670, -0.1592,  1.0190, -0.3990, -1.3045,\n",
       "                       0.5461, -0.5007, -0.1933,  0.1321,  0.5867, -0.3740,  0.4004, -0.4818,\n",
       "                      -0.0083, -0.3740,  0.0236,  0.1452, -0.0501, -0.1232,  0.2434, -0.1064,\n",
       "                      -0.5605, -0.7148, -0.4565, -0.5675,  0.3973, -0.2842,  0.3199,  0.2826,\n",
       "                      -0.0827,  0.0302, -0.6990,  0.4517,  0.5122, -0.5620, -0.7103, -0.4283,\n",
       "                      -0.5415,  0.4392, -1.0027,  0.7853, -0.1548,  0.1258, -0.8138,  0.0936,\n",
       "                      -0.8065,  0.1128, -0.0932, -0.3343, -0.7423,  0.4191,  0.7258, -0.4051,\n",
       "                       0.2153, -0.1921, -0.2375,  0.0686,  0.2159,  0.1159, -0.0996, -0.1184],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.1.1.running_var',\n",
       "              tensor([1.0626, 0.5801, 0.6503, 0.9425, 0.4242, 0.5902, 0.4234, 0.8099, 0.6436,\n",
       "                      0.3924, 0.4306, 0.4521, 0.7153, 0.5366, 0.4428, 0.5372, 0.4932, 0.9594,\n",
       "                      0.7078, 0.6520, 0.6870, 0.6246, 0.6585, 0.7185, 0.5546, 0.7186, 0.8713,\n",
       "                      0.6144, 0.9297, 0.5674, 0.7979, 0.5965, 0.5661, 0.5799, 0.5042, 0.5999,\n",
       "                      0.5258, 0.5599, 0.5901, 0.6729, 0.9104, 0.7179, 1.1477, 0.5352, 0.8912,\n",
       "                      0.5603, 0.7482, 0.5773, 0.5991, 0.5261, 0.6770, 0.4682, 0.5949, 0.6587,\n",
       "                      0.6382, 0.4620, 0.4947, 0.5200, 0.5374, 0.5990, 0.6383, 0.5406, 0.4891,\n",
       "                      0.5751], dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.4.convpath.0.2.0.weight',\n",
       "              tensor([[[-0.0250],\n",
       "                       [-0.1015],\n",
       "                       [ 0.0820],\n",
       "                       ...,\n",
       "                       [ 0.0650],\n",
       "                       [-0.0890],\n",
       "                       [-0.0026]],\n",
       "              \n",
       "                      [[ 0.1290],\n",
       "                       [-0.2047],\n",
       "                       [ 0.0978],\n",
       "                       ...,\n",
       "                       [ 0.1049],\n",
       "                       [ 0.0355],\n",
       "                       [-0.0473]],\n",
       "              \n",
       "                      [[-0.0280],\n",
       "                       [ 0.0822],\n",
       "                       [ 0.1379],\n",
       "                       ...,\n",
       "                       [ 0.3214],\n",
       "                       [ 0.1775],\n",
       "                       [-0.0158]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0762],\n",
       "                       [-0.0503],\n",
       "                       [-0.0580],\n",
       "                       ...,\n",
       "                       [ 0.0658],\n",
       "                       [-0.1374],\n",
       "                       [-0.0721]],\n",
       "              \n",
       "                      [[ 0.0442],\n",
       "                       [-0.1015],\n",
       "                       [-0.0833],\n",
       "                       ...,\n",
       "                       [ 0.0022],\n",
       "                       [ 0.0476],\n",
       "                       [ 0.0433]],\n",
       "              \n",
       "                      [[ 0.0341],\n",
       "                       [ 0.0254],\n",
       "                       [ 0.0146],\n",
       "                       ...,\n",
       "                       [-0.0757],\n",
       "                       [ 0.0988],\n",
       "                       [-0.2498]]], dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.2.1.weight',\n",
       "              tensor([-0.0011, -0.0479, -0.0201,  0.0160,  0.0068, -0.0148,  0.0082, -0.0030,\n",
       "                      -0.0180,  0.0132, -0.0259,  0.0088, -0.0107, -0.0015,  0.0107,  0.0286,\n",
       "                      -0.0261,  0.0115,  0.0083, -0.0051, -0.0113, -0.0046,  0.0135,  0.0067,\n",
       "                      -0.0220, -0.0050,  0.0052, -0.0052,  0.0071, -0.0080,  0.0073, -0.0215,\n",
       "                      -0.0235, -0.0184,  0.0125,  0.0064,  0.0063,  0.0332, -0.0236, -0.0033,\n",
       "                      -0.0119, -0.0168,  0.0142,  0.0036, -0.0057, -0.0072, -0.0131,  0.0179,\n",
       "                      -0.0249, -0.0043,  0.0108, -0.0013,  0.0071,  0.0055, -0.0088, -0.0206,\n",
       "                      -0.0092,  0.0001, -0.0202,  0.0064,  0.0071, -0.0079, -0.0008, -0.0016,\n",
       "                      -0.0124, -0.0144,  0.0160, -0.0350,  0.0270, -0.0359,  0.0041, -0.0147,\n",
       "                       0.0056, -0.0142,  0.0213, -0.0318,  0.0168,  0.0263, -0.0007,  0.0293,\n",
       "                       0.0070, -0.0078,  0.0083,  0.0019, -0.0058,  0.0052,  0.0215, -0.0028,\n",
       "                       0.0479, -0.0037, -0.0111,  0.0345, -0.0226,  0.0209, -0.0114,  0.0079,\n",
       "                       0.0301, -0.0178, -0.0196,  0.0275, -0.0087,  0.0043, -0.0014, -0.0294,\n",
       "                      -0.0147,  0.0415,  0.0185,  0.0046,  0.0017,  0.0207, -0.0186,  0.0057,\n",
       "                      -0.0069,  0.0448,  0.0028,  0.0037, -0.0237,  0.0362, -0.0187,  0.0092,\n",
       "                       0.0193, -0.0005, -0.0075,  0.0195,  0.0235,  0.0443,  0.0180, -0.0195,\n",
       "                       0.0217,  0.0087,  0.0118,  0.0253,  0.0193,  0.0175, -0.0098,  0.0027,\n",
       "                      -0.0065,  0.0210, -0.0177,  0.0076, -0.0089, -0.0003,  0.0013, -0.0146,\n",
       "                       0.0088, -0.0106, -0.0135,  0.0165,  0.0004, -0.0232,  0.0007,  0.0097,\n",
       "                      -0.0303,  0.0294, -0.0061,  0.0088,  0.0110,  0.0155, -0.0024,  0.0074,\n",
       "                       0.0199, -0.0048,  0.0156,  0.0182, -0.0261, -0.0236, -0.0208,  0.0117,\n",
       "                      -0.0065, -0.0118, -0.0203, -0.0021,  0.0209,  0.0124, -0.0115, -0.0097,\n",
       "                       0.0209, -0.0109,  0.0285, -0.0239, -0.0137,  0.0038, -0.0142,  0.0075,\n",
       "                       0.0060,  0.0348,  0.0179, -0.0271, -0.0088, -0.0101,  0.0257, -0.0072,\n",
       "                       0.0388, -0.0050,  0.0307,  0.0232, -0.0081,  0.0033, -0.0053, -0.0152,\n",
       "                       0.0019, -0.0301,  0.0160,  0.0028, -0.0024,  0.0135, -0.0110,  0.0100,\n",
       "                      -0.0009,  0.0225, -0.0051, -0.0140, -0.0033, -0.0232, -0.0243, -0.0016,\n",
       "                      -0.0181,  0.0059, -0.0318,  0.0182,  0.0135,  0.0002, -0.0116, -0.0438,\n",
       "                       0.0155, -0.0041,  0.0100,  0.0062, -0.0251, -0.0057,  0.0244, -0.0029,\n",
       "                       0.0138,  0.0174, -0.0226,  0.0022,  0.0054,  0.0005, -0.0127, -0.0399,\n",
       "                       0.0104,  0.0035, -0.0016, -0.0032,  0.0158,  0.0068, -0.0008,  0.0151,\n",
       "                      -0.0097, -0.0069, -0.0213, -0.0070, -0.0096, -0.0086,  0.0038,  0.0115],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.2.1.bias',\n",
       "              tensor([-1.8370e-03, -2.6875e-03,  1.5379e-02,  1.2035e-02,  4.9408e-03,\n",
       "                       1.2134e-03,  1.6583e-02,  1.2081e-03,  9.5634e-03,  2.0832e-02,\n",
       "                       1.2867e-02, -1.0210e-02,  1.0119e-02, -6.8539e-03,  4.7702e-03,\n",
       "                       5.3555e-03,  1.9853e-02, -3.0166e-03,  1.4356e-02, -8.5206e-03,\n",
       "                      -2.6003e-03,  3.7214e-03,  1.6397e-03,  7.2353e-03, -6.6857e-03,\n",
       "                      -1.4696e-02,  5.3495e-03,  1.0900e-02,  1.4468e-03, -9.7419e-04,\n",
       "                       4.3466e-03,  1.0235e-02, -7.8811e-03,  1.6031e-02,  1.2407e-02,\n",
       "                       6.7733e-03, -7.6309e-04,  2.3151e-02,  9.3699e-03,  1.2561e-02,\n",
       "                       8.4103e-04,  2.2984e-02, -1.0065e-02,  1.0576e-03,  5.2806e-03,\n",
       "                      -1.0564e-02,  7.5361e-03,  3.1138e-03, -1.1481e-02,  1.0546e-02,\n",
       "                       8.3467e-03,  1.1713e-02,  9.0517e-03,  1.3792e-02,  5.4382e-03,\n",
       "                       9.8816e-03,  7.3442e-03,  2.7423e-03,  9.5493e-03,  5.6132e-03,\n",
       "                      -3.9700e-03,  2.7289e-03, -1.9820e-03,  9.1470e-03, -4.1751e-03,\n",
       "                       1.5072e-02, -1.1553e-02,  1.3178e-02, -3.0353e-05, -1.1024e-02,\n",
       "                       3.0832e-03,  2.1578e-03,  4.1882e-03, -7.9632e-03,  1.4675e-02,\n",
       "                       9.4079e-03,  5.2735e-04,  2.4768e-03,  4.5680e-03,  6.0121e-03,\n",
       "                       1.0969e-02, -5.3145e-03,  6.8254e-03,  3.7663e-03, -1.8369e-03,\n",
       "                       1.4304e-02,  1.6385e-03,  1.0812e-03,  9.0085e-03,  8.3380e-03,\n",
       "                      -5.8234e-04,  2.3383e-02,  1.7966e-02, -1.7059e-03,  4.8624e-03,\n",
       "                      -1.4463e-02,  5.6700e-03, -1.6406e-03,  1.7180e-02,  5.1274e-03,\n",
       "                       2.4426e-02,  2.9203e-03, -2.1263e-03,  2.7024e-04,  1.5335e-02,\n",
       "                      -1.0046e-04, -5.4698e-04,  3.4165e-03,  4.5562e-03,  6.4173e-03,\n",
       "                      -7.2215e-03, -7.4533e-03,  3.0880e-03,  1.6115e-02,  1.1805e-02,\n",
       "                       6.7155e-03,  1.1963e-02,  3.0259e-03,  2.8999e-03, -1.5330e-02,\n",
       "                       2.2357e-03,  7.7554e-03,  2.1973e-03, -3.1272e-03, -8.5270e-03,\n",
       "                       1.3134e-02,  1.5939e-02,  4.8649e-03, -8.4191e-04,  1.5522e-02,\n",
       "                       4.1832e-03,  1.8042e-02,  1.5133e-02,  8.3510e-03,  1.7760e-02,\n",
       "                      -7.8655e-03,  1.5849e-02,  7.6290e-03,  1.6681e-02,  1.1034e-02,\n",
       "                       1.9224e-03, -2.6729e-03,  1.4353e-02,  7.9760e-03, -1.1313e-02,\n",
       "                       8.1680e-03,  1.1053e-03, -2.6305e-03,  1.0372e-02,  9.1032e-03,\n",
       "                       4.3696e-03,  1.2062e-02,  3.6035e-03,  1.5166e-02,  1.4700e-02,\n",
       "                       8.5381e-03,  1.7248e-04,  7.2469e-03, -4.0253e-03, -1.0292e-02,\n",
       "                       1.3818e-03, -6.4041e-03,  1.9709e-03,  1.3232e-02,  1.2248e-02,\n",
       "                       1.2898e-03, -6.7087e-03,  8.6962e-03,  4.5678e-04,  1.6007e-02,\n",
       "                       5.1131e-03,  9.2164e-03,  1.3119e-02,  9.9323e-03, -1.4023e-02,\n",
       "                       6.8301e-03,  2.5819e-05,  1.1927e-02,  5.3145e-03,  5.7587e-03,\n",
       "                      -2.4298e-03,  1.0922e-02, -8.6950e-03, -1.0278e-02,  1.8226e-02,\n",
       "                       9.3580e-03,  1.4619e-02,  1.5217e-02, -1.8821e-03,  2.8029e-03,\n",
       "                       6.2048e-03,  1.0225e-03,  1.4009e-02, -9.7795e-03,  8.8851e-03,\n",
       "                       8.1547e-03, -2.1327e-03,  1.6713e-02,  1.0295e-02, -1.1045e-03,\n",
       "                       5.1762e-03,  1.5567e-02,  2.0571e-02,  1.7335e-02,  6.9624e-04,\n",
       "                      -3.5247e-03,  1.3890e-02, -3.6876e-03,  8.4294e-03,  5.8960e-03,\n",
       "                       2.0546e-03,  1.2638e-02,  1.3217e-02,  6.4027e-03,  1.7988e-02,\n",
       "                       4.1882e-03,  4.2172e-03, -3.0074e-03,  5.6205e-03, -4.0968e-04,\n",
       "                      -1.4860e-02,  2.7172e-03,  6.6953e-03,  2.4314e-02, -2.0668e-03,\n",
       "                       2.1919e-03, -2.8550e-03,  1.8016e-03, -1.4178e-02,  1.4157e-02,\n",
       "                       1.4764e-02, -5.3188e-04,  1.0742e-02,  1.1818e-02,  4.9984e-03,\n",
       "                       5.8159e-03,  7.7722e-03, -5.2791e-03,  1.0704e-02,  1.1160e-02,\n",
       "                       2.8725e-03,  4.0150e-03,  4.6042e-03,  7.7357e-03,  2.0129e-03,\n",
       "                       1.5003e-02,  9.2370e-04,  9.8652e-03,  2.9754e-03, -9.1533e-03,\n",
       "                       1.6761e-02,  1.6266e-02,  1.9418e-02,  1.7963e-02,  1.1984e-02,\n",
       "                       9.2275e-03], dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.2.1.running_mean',\n",
       "              tensor([-0.3974,  0.1077, -0.2802, -0.1166, -0.3220, -0.3529,  0.2312,  0.7063,\n",
       "                      -0.2523,  0.1950,  0.1701, -0.2574,  0.6776,  0.4325,  0.1331, -0.0290,\n",
       "                       0.5061,  0.3579, -0.1989,  0.7621, -0.3798,  0.2630, -0.0853,  0.4532,\n",
       "                      -0.0416, -0.3358,  0.5746, -0.0730,  0.0841,  0.1087, -0.5156,  0.1337,\n",
       "                      -0.2527,  0.1759,  0.3452, -0.7231,  0.0842,  0.1331,  0.2891,  0.4821,\n",
       "                       0.7246,  0.2932, -0.3362,  0.4722,  0.0842,  0.1145, -0.7889, -0.0069,\n",
       "                      -0.1401,  0.6070,  0.5296, -0.4861,  0.0054, -0.7023,  0.2118, -0.3339,\n",
       "                       0.9015,  1.0911, -0.5373,  0.6277, -0.0784,  0.3673,  0.1592,  0.0747,\n",
       "                       0.3963, -0.3667,  0.6330,  0.0582, -0.1076, -0.1507, -0.0446,  0.6002,\n",
       "                      -0.3472, -0.1630,  0.7214, -0.5755, -0.2325,  0.0797, -0.0833,  0.0694,\n",
       "                       0.1554,  0.1512, -0.4663, -1.1767,  0.1685,  0.2629, -0.4775, -0.2025,\n",
       "                       0.0101, -0.1029, -0.4431,  0.0650,  0.9164,  0.2291,  0.6091, -0.2324,\n",
       "                      -0.0886,  0.0518, -0.0926,  0.0344,  0.1858,  0.0606, -0.0819,  0.0348,\n",
       "                       0.0800, -0.2929, -0.2003,  0.1831, -0.1717,  0.0143,  0.3365,  0.5760,\n",
       "                      -0.2220, -0.1969,  0.2613, -0.0582,  0.4463,  0.1057,  0.1847,  0.3174,\n",
       "                      -0.1975,  0.2046,  0.5035, -0.4142, -0.4236, -0.2447, -0.1490,  0.3458,\n",
       "                      -0.2327,  0.1259,  0.1543, -0.0733,  0.0867,  0.3355, -0.2515, -0.0154,\n",
       "                       0.5075,  0.0990, -0.1883,  0.0694,  0.8120, -0.1108,  0.0098, -0.4889,\n",
       "                      -0.0717,  0.5576, -0.3773,  0.6690, -0.3063, -0.3096,  0.2689, -0.3294,\n",
       "                       0.2039, -0.5384, -0.0503, -0.0396, -0.2377, -0.1569, -0.1366,  0.3667,\n",
       "                       0.0411,  0.3711,  0.0060,  0.5850, -0.6389, -0.0365, -0.5077, -0.1886,\n",
       "                      -0.3189,  0.8862, -0.3756,  0.1034,  0.1739, -0.0364,  0.3530, -0.6078,\n",
       "                      -0.1116, -0.1238, -0.7973,  0.6964,  0.1805, -0.6911, -0.0254,  0.2004,\n",
       "                       0.1116, -0.5385, -0.0997, -0.0338,  0.1931, -0.2240, -0.6057,  0.4758,\n",
       "                      -0.0143, -0.7082,  0.7428, -0.1877,  0.0836, -0.6641,  0.1989, -0.7697,\n",
       "                       0.0991, -0.0792, -0.0984,  0.2259,  0.2277, -0.1197,  0.2570, -0.1575,\n",
       "                       0.1485, -0.5174, -0.3400,  0.0772, -0.2050,  0.3241,  0.0155,  0.0784,\n",
       "                      -0.3682, -0.2941,  0.5220, -0.2272, -0.0152,  0.1009,  0.1004,  0.0857,\n",
       "                      -0.0244, -0.2347,  0.5105,  0.1286,  0.4996, -0.7752, -0.2557,  0.4114,\n",
       "                      -0.3314,  0.0551, -0.2931, -0.0989,  0.2606,  0.0200, -0.6242, -0.3107,\n",
       "                       0.3429,  0.2048,  0.9197, -0.0703, -0.1459,  0.1527, -0.0396,  0.3572,\n",
       "                       0.0118,  0.7326, -0.1131, -0.0231,  0.0151,  0.5911, -0.1402, -0.6342],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.2.1.running_var',\n",
       "              tensor([0.1472, 0.3486, 0.3716, 0.4395, 0.2278, 0.2498, 0.3794, 0.3718, 0.2803,\n",
       "                      0.5386, 0.3291, 0.2888, 0.2754, 0.3337, 0.4292, 0.8511, 0.3940, 0.1962,\n",
       "                      0.2334, 0.4054, 0.2737, 0.4964, 0.3211, 0.3978, 0.5242, 0.2952, 0.3626,\n",
       "                      0.1308, 0.1969, 0.3664, 0.4631, 0.2625, 0.1587, 0.3955, 0.4356, 0.3696,\n",
       "                      0.2841, 0.2831, 0.3106, 0.4150, 0.5758, 0.4147, 0.1488, 0.3322, 0.5514,\n",
       "                      0.3669, 0.3603, 0.2739, 0.6134, 0.3705, 0.2440, 0.3284, 0.2875, 0.3740,\n",
       "                      0.4224, 0.5076, 0.3784, 0.5399, 0.4553, 0.4227, 0.0906, 0.2788, 0.1779,\n",
       "                      0.1031, 0.5642, 0.3690, 0.5450, 0.5527, 0.3077, 0.5021, 0.3690, 0.3127,\n",
       "                      0.3319, 0.4763, 0.5411, 0.4104, 0.5561, 0.2190, 0.4986, 0.4855, 0.2188,\n",
       "                      0.1709, 0.5330, 0.5350, 0.2796, 0.5786, 0.2239, 0.1199, 0.5622, 0.2679,\n",
       "                      0.5376, 0.3589, 0.3462, 0.2620, 0.4688, 0.1897, 0.7321, 0.3546, 0.2433,\n",
       "                      0.3423, 0.4263, 0.2544, 0.1348, 0.3485, 0.2557, 0.4167, 0.3867, 0.3730,\n",
       "                      0.1049, 0.2623, 0.2799, 0.3925, 0.4872, 0.4792, 0.2730, 0.4597, 0.5872,\n",
       "                      0.4667, 0.2628, 0.3703, 0.1727, 0.4204, 0.4452, 0.2528, 0.3729, 0.4062,\n",
       "                      0.2096, 0.3934, 0.2032, 0.2258, 0.1944, 0.3173, 0.6244, 0.2070, 0.1861,\n",
       "                      0.1173, 0.1743, 0.3277, 0.4274, 0.1691, 0.3133, 0.1068, 0.1015, 0.1829,\n",
       "                      0.1817, 0.3939, 0.2331, 0.2442, 0.1533, 0.4312, 0.5259, 0.3514, 0.4361,\n",
       "                      0.5202, 0.1493, 0.2379, 0.2297, 0.2928, 0.4470, 0.2550, 0.4084, 0.2241,\n",
       "                      0.3954, 0.5241, 0.4574, 0.5664, 0.4213, 0.2277, 0.1479, 0.6103, 0.2624,\n",
       "                      0.0888, 0.3613, 0.1309, 0.3847, 0.7010, 0.2637, 0.1558, 0.4992, 0.4508,\n",
       "                      0.3919, 0.1336, 0.4430, 0.3949, 0.2622, 0.3572, 0.1893, 0.2983, 0.2198,\n",
       "                      0.2234, 0.4277, 0.3513, 0.3864, 0.5135, 0.3570, 0.5219, 0.3487, 0.3159,\n",
       "                      0.4473, 0.4838, 0.2142, 0.3459, 0.3073, 0.2444, 0.2054, 0.4050, 0.3725,\n",
       "                      0.0875, 0.1595, 0.4734, 0.1919, 0.2168, 0.1162, 0.5572, 0.3566, 0.1770,\n",
       "                      0.4158, 0.0842, 0.5791, 0.4591, 0.2192, 0.2521, 0.1524, 0.3314, 0.6056,\n",
       "                      0.2725, 0.3667, 0.0607, 0.4667, 0.5683, 0.3986, 0.4278, 0.4730, 0.3376,\n",
       "                      0.2636, 0.3059, 0.1421, 0.1268, 0.5653, 0.4599, 0.3672, 0.2235, 0.2915,\n",
       "                      0.1495, 0.2015, 0.2248, 0.2086, 0.4980, 0.2256, 0.3493, 0.4005, 0.3727,\n",
       "                      0.2864, 0.3785, 0.1070, 0.3987], dtype=torch.float64)),\n",
       "             ('6.4.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.5.convs.0.0.weight',\n",
       "              tensor([[[-0.0159],\n",
       "                       [ 0.0959],\n",
       "                       [ 0.0464],\n",
       "                       ...,\n",
       "                       [-0.0345],\n",
       "                       [-0.0361],\n",
       "                       [-0.0095]],\n",
       "              \n",
       "                      [[-0.0082],\n",
       "                       [-0.0873],\n",
       "                       [ 0.1419],\n",
       "                       ...,\n",
       "                       [ 0.0476],\n",
       "                       [ 0.1877],\n",
       "                       [-0.2293]],\n",
       "              \n",
       "                      [[ 0.0361],\n",
       "                       [-0.0449],\n",
       "                       [ 0.0379],\n",
       "                       ...,\n",
       "                       [-0.0941],\n",
       "                       [ 0.0118],\n",
       "                       [-0.0568]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1578],\n",
       "                       [-0.1014],\n",
       "                       [-0.0985],\n",
       "                       ...,\n",
       "                       [ 0.0263],\n",
       "                       [-0.0787],\n",
       "                       [-0.0804]],\n",
       "              \n",
       "                      [[ 0.0774],\n",
       "                       [-0.1321],\n",
       "                       [ 0.0956],\n",
       "                       ...,\n",
       "                       [-0.0218],\n",
       "                       [-0.0260],\n",
       "                       [-0.0188]],\n",
       "              \n",
       "                      [[ 0.0756],\n",
       "                       [-0.0247],\n",
       "                       [-0.0297],\n",
       "                       ...,\n",
       "                       [ 0.0865],\n",
       "                       [ 0.1219],\n",
       "                       [-0.0433]]], dtype=torch.float64)),\n",
       "             ('6.5.convs.0.1.weight',\n",
       "              tensor([0.9698, 0.9699, 0.9490, 0.9663, 0.9633, 0.9676, 0.9883, 0.9712, 0.9682,\n",
       "                      0.9791, 0.9616, 0.9649, 0.9606, 0.9528, 0.9664, 1.0263, 0.9790, 0.9987,\n",
       "                      0.9737, 0.9548, 0.9581, 0.9872, 1.0118, 0.9746, 0.9829, 0.9680, 0.9722,\n",
       "                      0.9765, 0.9793, 0.9638, 0.9805, 0.9741, 0.9685, 0.9728, 0.9462, 0.9585,\n",
       "                      0.9784, 0.9931, 0.9571, 0.9883, 0.9809, 0.9737, 0.9720, 0.9975, 0.9671,\n",
       "                      0.9515, 0.9789, 0.9919, 0.9769, 0.9802, 0.9564, 0.9679, 0.9916, 0.9757,\n",
       "                      0.9393, 0.9593, 0.9758, 0.9667, 0.9846, 0.9941, 1.0062, 0.9416, 0.9720,\n",
       "                      0.9351], dtype=torch.float64)),\n",
       "             ('6.5.convs.0.1.bias',\n",
       "              tensor([ 0.0029,  0.0080,  0.0072,  0.0055,  0.0078,  0.0029,  0.0119, -0.0023,\n",
       "                       0.0081,  0.0076,  0.0085,  0.0116,  0.0072, -0.0094, -0.0093,  0.0260,\n",
       "                      -0.0009,  0.0249,  0.0107, -0.0103, -0.0106,  0.0146,  0.0177, -0.0025,\n",
       "                      -0.0099, -0.0008, -0.0145,  0.0041,  0.0185, -0.0100,  0.0205, -0.0082,\n",
       "                       0.0224,  0.0084, -0.0231,  0.0111, -0.0076,  0.0167,  0.0065, -0.0097,\n",
       "                      -0.0050, -0.0082, -0.0003,  0.0200,  0.0069, -0.0307, -0.0131,  0.0215,\n",
       "                      -0.0119,  0.0096, -0.0119, -0.0108,  0.0265, -0.0052, -0.0056, -0.0024,\n",
       "                      -0.0097, -0.0155,  0.0093,  0.0177,  0.0003, -0.0025,  0.0004, -0.0243],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convs.0.1.running_mean',\n",
       "              tensor([ 0.6289,  0.0562,  0.3036, -0.4673,  0.1196, -0.3437,  0.6448, -0.5550,\n",
       "                       0.0174,  0.2705, -1.0050, -0.4373, -0.0208,  1.0133,  0.3290, -0.3679,\n",
       "                       0.3730,  0.3480, -0.7210, -0.8384,  0.2152, -0.1795, -0.5973, -0.0460,\n",
       "                      -0.2679,  0.2367, -0.3585,  0.4268,  0.1556, -0.1696,  0.0507,  0.2252,\n",
       "                      -0.3387, -0.4349,  0.6709, -0.2964,  0.5138,  0.0876,  0.1874,  0.2398,\n",
       "                      -0.1897,  0.3736,  0.0685, -0.4554,  0.6861,  1.1062,  0.9155, -0.7769,\n",
       "                       0.6319,  0.0610,  0.8805, -0.5538,  0.1561,  0.3953, -0.5522,  0.3013,\n",
       "                       0.6577, -0.3548, -0.3693, -0.4058, -0.6066, -0.4633,  0.1709,  0.6844],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convs.0.1.running_var',\n",
       "              tensor([0.1996, 0.2117, 0.3200, 0.2147, 0.1699, 0.1796, 0.3376, 0.1707, 0.1563,\n",
       "                      0.1256, 0.5637, 0.1581, 0.8390, 0.4758, 0.2161, 0.1157, 0.1487, 0.1251,\n",
       "                      0.2467, 0.3396, 0.5314, 0.1280, 0.0927, 0.1690, 0.1306, 0.4552, 0.0634,\n",
       "                      0.1722, 0.8017, 0.1737, 0.6113, 0.1162, 0.1827, 0.1961, 0.1242, 0.2585,\n",
       "                      0.9847, 0.5323, 0.3786, 0.1056, 0.2249, 0.5711, 0.2330, 0.1022, 0.2503,\n",
       "                      0.7001, 0.2299, 0.1263, 1.6804, 0.3714, 0.4519, 0.2089, 0.1189, 0.1122,\n",
       "                      0.1931, 0.2745, 0.3571, 0.1722, 0.3670, 0.1276, 0.1627, 0.3406, 0.1568,\n",
       "                      0.6619], dtype=torch.float64)),\n",
       "             ('6.5.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.5.convs.1.0.weight',\n",
       "              tensor([[[-0.0469,  0.0620,  0.0896, -0.0159, -0.0578],\n",
       "                       [-0.2007, -0.0320,  0.0168,  0.0656,  0.0493],\n",
       "                       [-0.0347,  0.0333,  0.0107, -0.0247, -0.0010],\n",
       "                       ...,\n",
       "                       [ 0.0094, -0.0280, -0.1716, -0.0484,  0.0938],\n",
       "                       [-0.0192,  0.0287,  0.0148,  0.0184,  0.0493],\n",
       "                       [ 0.1046,  0.0407, -0.0652,  0.0161, -0.0574]],\n",
       "              \n",
       "                      [[ 0.0285,  0.0449, -0.0022, -0.0601, -0.0216],\n",
       "                       [-0.0301,  0.0648, -0.0313,  0.0750,  0.0139],\n",
       "                       [ 0.1176, -0.0173, -0.1481, -0.0981, -0.0136],\n",
       "                       ...,\n",
       "                       [-0.1328, -0.0014, -0.0385,  0.0227,  0.0490],\n",
       "                       [-0.1500,  0.0246, -0.0173, -0.0551,  0.0272],\n",
       "                       [-0.0817,  0.0874, -0.0957,  0.0768,  0.1392]],\n",
       "              \n",
       "                      [[ 0.0350, -0.1329,  0.1100, -0.0393,  0.0047],\n",
       "                       [ 0.0572, -0.0430, -0.0515,  0.0057,  0.0666],\n",
       "                       [ 0.0749,  0.1899,  0.0320,  0.0132,  0.1371],\n",
       "                       ...,\n",
       "                       [ 0.0552, -0.0441, -0.1381,  0.0138,  0.0652],\n",
       "                       [ 0.0761, -0.0697,  0.0660, -0.0914, -0.0111],\n",
       "                       [-0.0612,  0.0737,  0.0346, -0.0860, -0.0321]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0534, -0.0471, -0.0225,  0.0921, -0.0139],\n",
       "                       [-0.1966,  0.1848, -0.0647, -0.1086, -0.0737],\n",
       "                       [ 0.1921, -0.0128,  0.0160, -0.0588, -0.1794],\n",
       "                       ...,\n",
       "                       [-0.0194, -0.0011,  0.0822, -0.1450, -0.0185],\n",
       "                       [-0.0848,  0.1030,  0.1008, -0.0007,  0.1412],\n",
       "                       [-0.0218,  0.0906, -0.0930,  0.0175,  0.0472]],\n",
       "              \n",
       "                      [[-0.0925,  0.0878,  0.0055, -0.0226, -0.0392],\n",
       "                       [-0.0791,  0.0301, -0.0399, -0.0821,  0.1582],\n",
       "                       [ 0.0780,  0.0089,  0.0555,  0.0292, -0.0327],\n",
       "                       ...,\n",
       "                       [-0.0304,  0.0652,  0.0845, -0.0118, -0.0925],\n",
       "                       [-0.0663,  0.0998, -0.0152, -0.0046, -0.1432],\n",
       "                       [-0.0433,  0.0106,  0.0961, -0.0291, -0.0429]],\n",
       "              \n",
       "                      [[-0.1359, -0.0836,  0.0608, -0.1169,  0.0488],\n",
       "                       [ 0.0846, -0.1247,  0.0931,  0.0566, -0.0603],\n",
       "                       [ 0.1391,  0.0735, -0.0932,  0.0539,  0.1275],\n",
       "                       ...,\n",
       "                       [-0.0027,  0.0183, -0.1515,  0.1310,  0.0492],\n",
       "                       [-0.0406,  0.1284,  0.0023,  0.0277,  0.0203],\n",
       "                       [-0.0465, -0.0169, -0.0413,  0.0532, -0.0258]]], dtype=torch.float64)),\n",
       "             ('6.5.convs.1.1.weight',\n",
       "              tensor([0.9866, 0.9551, 0.9633, 0.9620, 0.9669, 0.9623, 0.9590, 0.9494, 0.9760,\n",
       "                      0.9734, 0.9512, 0.9907, 0.9916, 0.9903, 0.9243, 0.9717, 0.9820, 0.9616,\n",
       "                      0.9932, 0.9839, 0.9753, 0.9651, 0.9564, 0.9578, 0.9592, 0.9431, 0.9829,\n",
       "                      0.9404, 0.9402, 1.0097, 0.9711, 0.9377, 0.9708, 0.9900, 0.9713, 0.9596,\n",
       "                      0.9559, 0.9666, 0.9822, 0.9464, 0.9589, 0.9544, 0.9912, 0.9783, 0.9498,\n",
       "                      0.9262, 0.9456, 0.9297, 0.9514, 0.9746, 0.9519, 0.9529, 0.9439, 0.9671,\n",
       "                      0.9795, 0.9525, 0.9734, 0.9753, 0.9439, 1.0004, 0.9893, 0.9808, 0.9160,\n",
       "                      1.0033], dtype=torch.float64)),\n",
       "             ('6.5.convs.1.1.bias',\n",
       "              tensor([-0.0061,  0.0062, -0.0270, -0.0155,  0.0010, -0.0245,  0.0085, -0.0290,\n",
       "                       0.0003, -0.0093, -0.0073,  0.0110,  0.0232,  0.0099, -0.0197, -0.0020,\n",
       "                       0.0104, -0.0030,  0.0203,  0.0014, -0.0121, -0.0055,  0.0065, -0.0006,\n",
       "                      -0.0025, -0.0159,  0.0053,  0.0080, -0.0139,  0.0193, -0.0151, -0.0301,\n",
       "                      -0.0219,  0.0183,  0.0124, -0.0274, -0.0250, -0.0095, -0.0007, -0.0188,\n",
       "                      -0.0151, -0.0059,  0.0176,  0.0097, -0.0027, -0.0105,  0.0083, -0.0148,\n",
       "                      -0.0188, -0.0265, -0.0028, -0.0168, -0.0084, -0.0057,  0.0132, -0.0189,\n",
       "                       0.0075,  0.0077, -0.0181,  0.0152,  0.0082, -0.0024, -0.0146,  0.0089],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convs.1.1.running_mean',\n",
       "              tensor([ 0.6885, -1.2877,  0.3191,  0.5982, -0.4933,  0.3985,  0.1076,  0.2197,\n",
       "                       0.1896,  0.4515, -0.6079,  0.4856, -0.7102,  0.3500, -0.1991,  0.1864,\n",
       "                       0.0232, -0.7216, -0.7500,  0.1427,  0.5482,  0.0172, -0.2554, -0.0261,\n",
       "                      -0.8555, -0.5965, -0.0873, -0.4673, -0.7123,  0.0759,  0.6981,  0.0750,\n",
       "                       0.7663, -0.3931, -0.0945,  0.5454, -0.1214, -0.3008, -0.1166,  0.2179,\n",
       "                       0.2983, -0.1267, -1.1962,  0.4033, -0.6889, -0.7182, -0.5579, -0.8400,\n",
       "                      -0.2914,  1.0688, -0.3007, -0.3782, -0.3093,  1.2386, -0.1279, -0.6222,\n",
       "                       0.4311, -0.9213,  0.0225,  0.1456, -0.2438, -0.2756, -0.4038, -1.0030],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convs.1.1.running_var',\n",
       "              tensor([0.5122, 0.9793, 0.5548, 0.9017, 0.5254, 0.7793, 1.0079, 0.8371, 0.5705,\n",
       "                      0.5136, 0.8169, 0.8182, 0.5292, 0.4946, 0.6266, 0.5874, 0.4952, 0.5450,\n",
       "                      0.4956, 0.6343, 0.4036, 0.7054, 0.6085, 0.5657, 1.2514, 0.8176, 0.5660,\n",
       "                      0.6809, 0.9881, 0.5207, 0.8641, 0.3312, 0.9939, 0.5919, 0.7487, 0.8015,\n",
       "                      1.1297, 0.4300, 0.5160, 0.6869, 0.5546, 0.5179, 0.4262, 0.6387, 0.6856,\n",
       "                      1.0306, 0.9522, 1.0984, 0.4906, 1.0767, 0.8956, 0.8615, 0.6042, 0.7023,\n",
       "                      0.7387, 0.6545, 0.4629, 1.0982, 0.5738, 0.5377, 0.6929, 0.4819, 1.7552,\n",
       "                      0.6772], dtype=torch.float64)),\n",
       "             ('6.5.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.5.convs.2.0.weight',\n",
       "              tensor([[[ 0.0007],\n",
       "                       [-0.0225],\n",
       "                       [ 0.0369],\n",
       "                       ...,\n",
       "                       [-0.1321],\n",
       "                       [-0.1222],\n",
       "                       [ 0.1618]],\n",
       "              \n",
       "                      [[-0.0804],\n",
       "                       [-0.0332],\n",
       "                       [-0.2140],\n",
       "                       ...,\n",
       "                       [ 0.0400],\n",
       "                       [-0.1306],\n",
       "                       [-0.2144]],\n",
       "              \n",
       "                      [[ 0.0549],\n",
       "                       [ 0.0320],\n",
       "                       [-0.0821],\n",
       "                       ...,\n",
       "                       [ 0.0321],\n",
       "                       [ 0.0305],\n",
       "                       [-0.0088]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0743],\n",
       "                       [ 0.2200],\n",
       "                       [-0.2823],\n",
       "                       ...,\n",
       "                       [-0.2902],\n",
       "                       [ 0.1863],\n",
       "                       [-0.0793]],\n",
       "              \n",
       "                      [[ 0.2339],\n",
       "                       [-0.2356],\n",
       "                       [ 0.2510],\n",
       "                       ...,\n",
       "                       [ 0.1311],\n",
       "                       [ 0.1117],\n",
       "                       [ 0.0206]],\n",
       "              \n",
       "                      [[ 0.0837],\n",
       "                       [ 0.1134],\n",
       "                       [ 0.1545],\n",
       "                       ...,\n",
       "                       [-0.0509],\n",
       "                       [-0.0122],\n",
       "                       [ 0.0042]]], dtype=torch.float64)),\n",
       "             ('6.5.convs.2.1.weight',\n",
       "              tensor([-0.0001, -0.0071,  0.0082,  0.0218,  0.0208,  0.0266, -0.0033, -0.0165,\n",
       "                       0.0369,  0.0064,  0.0164,  0.0142,  0.0193, -0.0040,  0.0227, -0.0241,\n",
       "                      -0.0193, -0.0007, -0.0040, -0.0178,  0.0197,  0.0307, -0.0016, -0.0154,\n",
       "                       0.0313, -0.0091,  0.0136,  0.0216, -0.0052,  0.0074,  0.0046, -0.0224,\n",
       "                       0.0267, -0.0045, -0.0246,  0.0109,  0.0207, -0.0097, -0.0203, -0.0021,\n",
       "                      -0.0233, -0.0091,  0.0092,  0.0101, -0.0090, -0.0069,  0.0155, -0.0030,\n",
       "                       0.0180, -0.0128, -0.0195,  0.0072, -0.0088,  0.0172, -0.0135,  0.0013,\n",
       "                       0.0223,  0.0198, -0.0169, -0.0200,  0.0105, -0.0012,  0.0061, -0.0065,\n",
       "                       0.0152,  0.0119, -0.0062,  0.0287, -0.0093,  0.0145,  0.0084,  0.0005,\n",
       "                      -0.0020, -0.0442, -0.0163, -0.0096, -0.0010, -0.0007, -0.0051, -0.0174,\n",
       "                      -0.0164, -0.0141, -0.0121,  0.0008, -0.0093, -0.0144,  0.0125,  0.0140,\n",
       "                      -0.0401, -0.0126, -0.0085,  0.0324,  0.0231,  0.0050, -0.0077,  0.0027,\n",
       "                       0.0168,  0.0205,  0.0087,  0.0304,  0.0074,  0.0103, -0.0138,  0.0123,\n",
       "                       0.0037,  0.0075,  0.0071,  0.0034, -0.0065,  0.0242,  0.0010, -0.0063,\n",
       "                      -0.0165,  0.0154,  0.0048, -0.0171, -0.0044,  0.0220,  0.0068, -0.0017,\n",
       "                       0.0210,  0.0069, -0.0095, -0.0119, -0.0189, -0.0132, -0.0175,  0.0125,\n",
       "                      -0.0256, -0.0144, -0.0035, -0.0074,  0.0178,  0.0035,  0.0105,  0.0172,\n",
       "                      -0.0072,  0.0021,  0.0164, -0.0152, -0.0045, -0.0131,  0.0119,  0.0080,\n",
       "                       0.0189, -0.0001,  0.0106, -0.0018, -0.0253,  0.0015,  0.0063, -0.0175,\n",
       "                       0.0273,  0.0155, -0.0046,  0.0007,  0.0050, -0.0153,  0.0231,  0.0093,\n",
       "                      -0.0043,  0.0196,  0.0062,  0.0145, -0.0315,  0.0352,  0.0369, -0.0026,\n",
       "                      -0.0005,  0.0107,  0.0167,  0.0264, -0.0019,  0.0106, -0.0127,  0.0255,\n",
       "                       0.0169,  0.0277, -0.0060,  0.0109, -0.0063,  0.0078,  0.0037, -0.0110,\n",
       "                       0.0137,  0.0207,  0.0143, -0.0032,  0.0215,  0.0086,  0.0290,  0.0238,\n",
       "                       0.0277, -0.0119, -0.0177, -0.0175, -0.0063, -0.0274,  0.0183,  0.0232,\n",
       "                      -0.0022,  0.0091,  0.0226, -0.0306,  0.0113, -0.0112, -0.0269,  0.0103,\n",
       "                      -0.0008, -0.0422, -0.0155, -0.0016,  0.0233, -0.0230,  0.0373, -0.0133,\n",
       "                       0.0031, -0.0163,  0.0296,  0.0169, -0.0090,  0.0124, -0.0115, -0.0125,\n",
       "                      -0.0148, -0.0108, -0.0158, -0.0103,  0.0203, -0.0155,  0.0091, -0.0135,\n",
       "                      -0.0169, -0.0189, -0.0072, -0.0001,  0.0170,  0.0206,  0.0081,  0.0027,\n",
       "                       0.0352,  0.0142, -0.0082,  0.0022, -0.0198, -0.0248, -0.0072, -0.0484,\n",
       "                      -0.0096,  0.0152, -0.0017, -0.0007,  0.0001,  0.0126, -0.0316,  0.0102],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convs.2.1.bias',\n",
       "              tensor([-1.1678e-03, -3.1923e-03,  1.3112e-02,  2.0858e-02,  4.7208e-03,\n",
       "                       4.3608e-04,  1.5750e-02,  1.6490e-03,  9.8747e-03,  2.2442e-02,\n",
       "                       1.3793e-02, -5.5202e-03,  9.0527e-03, -5.6862e-03,  6.9908e-03,\n",
       "                       4.8064e-03,  2.0773e-02, -3.2974e-03,  1.2745e-02, -8.5603e-03,\n",
       "                      -4.9067e-03,  3.5996e-03,  5.5753e-04,  7.2405e-03, -5.7225e-03,\n",
       "                      -1.5083e-02,  5.0426e-03,  1.1423e-02,  1.7953e-03, -2.4789e-03,\n",
       "                       3.9750e-03,  8.0682e-03, -7.7040e-03,  1.7316e-02,  1.4617e-02,\n",
       "                       7.3996e-03, -1.2831e-03,  1.9569e-02,  9.1630e-03,  1.4885e-02,\n",
       "                      -8.3387e-04,  2.5908e-02, -6.4297e-03,  1.2283e-03,  3.1307e-03,\n",
       "                      -8.8600e-03,  2.7441e-03,  4.8239e-03, -1.1548e-02,  1.3157e-02,\n",
       "                       8.5368e-03,  1.2742e-02,  9.1695e-03,  1.4107e-02,  6.0820e-03,\n",
       "                       1.5736e-02,  7.8488e-03,  2.3520e-03,  8.5711e-03,  3.6600e-03,\n",
       "                      -1.2452e-03,  2.8815e-03,  4.8816e-03,  9.4797e-03, -4.1062e-03,\n",
       "                       1.2507e-02, -1.1526e-02,  1.2648e-02, -4.1438e-03, -1.1468e-02,\n",
       "                       3.2367e-03,  6.3141e-03,  2.4182e-03, -7.2418e-03,  1.4082e-02,\n",
       "                       2.4774e-03,  2.5678e-03,  2.4910e-03,  4.3122e-03, -8.6151e-04,\n",
       "                       1.0517e-02, -4.9261e-03,  8.1478e-03,  4.0931e-03, -2.7773e-03,\n",
       "                       1.2507e-02,  1.4951e-03,  2.0740e-03,  1.4591e-02,  6.5104e-03,\n",
       "                      -7.8116e-04,  2.2174e-02,  1.7469e-02, -3.8160e-04,  8.7713e-03,\n",
       "                      -1.5142e-02,  6.4406e-03, -6.3540e-04,  1.1212e-02,  1.0910e-03,\n",
       "                       1.9688e-02,  2.3529e-03, -2.2913e-03, -4.8809e-03,  1.0449e-02,\n",
       "                       4.0728e-04, -3.5230e-04,  3.4947e-03,  4.1352e-03,  3.9265e-03,\n",
       "                      -5.8501e-03, -7.1410e-03,  4.0409e-03,  1.5027e-02,  1.1741e-02,\n",
       "                       6.7241e-03,  1.1544e-02,  2.9570e-03,  2.1605e-03, -1.4881e-02,\n",
       "                       2.2379e-03,  8.3369e-03,  5.6436e-04, -3.0349e-03, -1.1580e-02,\n",
       "                       1.1330e-02,  1.4120e-02,  4.5586e-03,  3.1886e-05,  1.5085e-02,\n",
       "                       2.3358e-02,  1.5722e-02,  1.4378e-02,  5.9259e-03,  1.5272e-02,\n",
       "                      -9.4663e-03,  1.5928e-02,  6.1710e-03,  1.4116e-02,  7.8326e-03,\n",
       "                       9.9809e-03, -3.3011e-03,  1.4455e-02,  7.1306e-03, -8.7077e-03,\n",
       "                       1.4016e-02,  6.2895e-03, -1.6422e-03,  1.0654e-02,  8.9558e-03,\n",
       "                       6.6912e-03,  1.2681e-02,  3.4863e-03,  1.5336e-02,  1.5329e-02,\n",
       "                       8.8705e-03,  8.5649e-04,  7.7767e-03, -3.1015e-03, -9.3596e-03,\n",
       "                       3.1068e-03, -3.1637e-03,  2.1641e-04,  1.3721e-02,  1.2348e-02,\n",
       "                      -2.4406e-04, -7.7747e-03,  9.3160e-03,  8.9869e-04,  1.5482e-02,\n",
       "                       5.1663e-03,  9.8502e-03,  1.0459e-02,  1.0038e-02, -1.3533e-02,\n",
       "                       4.9343e-03, -8.7596e-04,  1.1555e-02,  3.7394e-03,  4.2140e-03,\n",
       "                      -2.6184e-03,  9.5581e-03, -7.9303e-03, -1.0230e-02,  1.8723e-02,\n",
       "                       8.3758e-03,  1.4122e-02,  1.0819e-02, -4.7476e-04,  4.4541e-03,\n",
       "                       6.2162e-03,  1.8599e-03,  1.0383e-02, -7.1263e-03,  4.8448e-03,\n",
       "                       7.5120e-03, -3.3724e-03,  1.9145e-02,  8.2710e-03,  1.9359e-02,\n",
       "                       4.5284e-03,  2.0462e-02,  2.0598e-02,  1.7428e-02,  6.2022e-05,\n",
       "                      -6.3827e-04,  1.4967e-02, -2.8858e-03,  7.2059e-03,  4.4177e-03,\n",
       "                       1.6921e-03,  1.2562e-02,  1.2954e-02,  6.6632e-03,  1.3517e-02,\n",
       "                       5.4235e-03,  3.9152e-03, -2.7745e-03,  3.0169e-03, -1.6081e-04,\n",
       "                      -1.6028e-02,  1.1125e-03,  6.0373e-03,  2.0237e-02, -4.3494e-03,\n",
       "                       3.8112e-03, -2.7621e-03,  1.7193e-03, -1.4179e-02,  1.4331e-02,\n",
       "                       1.2810e-02, -2.0004e-03,  1.0907e-02,  9.4899e-03,  3.5680e-03,\n",
       "                       6.7986e-03,  7.4130e-03, -8.2110e-03,  8.9692e-03,  8.9572e-03,\n",
       "                       1.9057e-03,  4.3985e-03,  4.4228e-03,  7.5920e-03,  2.3147e-03,\n",
       "                       1.5026e-02, -2.5035e-04,  1.0708e-02,  2.8740e-03, -8.9365e-03,\n",
       "                       1.7465e-02,  1.8552e-02,  1.7808e-02,  1.7584e-02,  1.1978e-02,\n",
       "                       9.0722e-03], dtype=torch.float64)),\n",
       "             ('6.5.convs.2.1.running_mean',\n",
       "              tensor([-0.0361,  0.1680, -0.1646,  0.1862,  0.1692,  0.0768,  0.2476, -0.3694,\n",
       "                       0.2180,  0.4591, -0.0384,  0.4116,  0.1827,  0.1186,  0.7991, -0.1803,\n",
       "                      -0.0856,  0.0785, -0.3732,  0.5654, -0.0715, -0.3280, -0.1701,  0.7322,\n",
       "                      -0.8324,  0.0994, -0.6030, -0.1757, -0.4184,  0.3869,  0.4321,  0.0448,\n",
       "                      -0.5696, -0.4391, -0.5532,  0.3704, -0.0467, -0.1026,  0.4465, -0.5886,\n",
       "                       0.5982, -0.5109,  0.0339,  0.4257,  0.0196,  0.5457,  0.7079, -0.0944,\n",
       "                       0.4062,  0.1916, -0.1695,  0.5542,  0.2431, -0.6123,  0.8114,  0.4746,\n",
       "                      -0.0576,  0.0469,  0.6021,  0.1555,  0.0405,  0.0494,  0.5356, -0.0535,\n",
       "                      -0.7021, -0.0441, -0.2569,  0.9482,  0.1479,  0.0841, -0.1419,  0.8612,\n",
       "                      -0.2116, -0.2645, -0.3329, -0.2167, -0.1655, -0.1057, -0.6193,  0.4380,\n",
       "                      -0.0928, -0.2382,  0.5345, -0.4614, -0.0284,  0.1385, -0.3266,  0.2415,\n",
       "                       0.3903, -0.7708, -0.9324,  0.3164,  0.1644,  0.0377, -0.2497,  0.6259,\n",
       "                      -0.4679, -0.0775, -0.2853, -0.2560,  0.3264,  0.1414, -0.1178, -0.0971,\n",
       "                       0.2791, -0.0492,  0.1263,  0.1476,  0.2262,  0.2986,  0.1013, -0.5593,\n",
       "                       0.1161, -0.7467,  0.0815,  0.0659,  0.7355, -0.4172, -0.3645,  0.0763,\n",
       "                      -0.1273,  0.9781, -0.0484, -0.6244, -0.1628, -0.5973,  0.2806,  0.6401,\n",
       "                      -0.0638,  0.4480, -0.3785, -0.0287,  0.0259,  0.1997, -0.3077,  0.1086,\n",
       "                      -0.1784, -0.4023,  0.0107, -0.2770,  0.3481, -0.1480,  0.8255, -0.2505,\n",
       "                       0.0561, -0.1016,  0.6592, -0.3125, -0.9027, -0.3901,  0.3778, -0.0851,\n",
       "                      -0.1515,  0.1321, -0.4119,  0.3111, -0.2307,  0.0767, -0.6245,  0.0281,\n",
       "                      -0.4003, -0.2882, -0.2339, -0.4514,  1.0053, -0.7171, -0.8131,  0.0135,\n",
       "                      -0.1555, -0.0196, -0.0322, -0.3982, -0.2445, -0.0233,  0.0771,  0.1680,\n",
       "                      -0.2456, -0.3945,  0.1377,  0.1009, -0.0892, -0.1152, -0.1389,  0.0714,\n",
       "                      -0.0017, -0.6183, -0.2900, -0.2343, -0.8766,  0.5262, -0.6424, -0.0637,\n",
       "                       0.1023, -1.4370, -0.8441, -0.3755, -0.0906, -0.6952, -0.7279,  0.6015,\n",
       "                       0.2145,  0.1393, -0.3518,  0.6698,  0.2741, -0.4372, -0.4090,  0.0243,\n",
       "                      -0.0687,  0.3457, -0.1099, -0.0027, -0.5067,  0.8749, -0.3518, -0.0383,\n",
       "                      -0.0193, -0.7281,  0.3530, -0.0605, -0.1492, -0.1982, -0.1093,  0.2855,\n",
       "                       0.3502,  0.0152, -0.8461, -0.3615, -0.0848,  0.0210,  0.1633, -0.0032,\n",
       "                       0.2722,  0.1324, -0.0330,  0.2193, -0.4504,  0.3880,  0.9682, -0.1282,\n",
       "                       0.1240,  0.1317, -0.1373,  0.0434, -0.1966,  0.6083, -0.5636,  0.4389,\n",
       "                       0.4036, -0.1270, -0.8223,  0.0600,  0.0596, -0.1677,  0.5905, -0.0665],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convs.2.1.running_var',\n",
       "              tensor([0.1397, 0.5604, 0.1581, 0.3884, 0.3366, 0.2859, 0.3670, 0.4328, 0.2415,\n",
       "                      0.3887, 0.2474, 0.4844, 0.1749, 0.1436, 0.4473, 0.3128, 0.3727, 0.1979,\n",
       "                      0.2311, 0.4493, 0.3325, 0.3443, 0.3211, 0.4673, 0.5442, 0.3565, 0.3445,\n",
       "                      0.3611, 0.3431, 0.2579, 0.3480, 0.5796, 0.3409, 0.2687, 0.4687, 0.4586,\n",
       "                      0.3769, 0.1463, 0.3254, 0.4541, 0.3221, 0.4925, 0.2308, 0.6912, 0.2945,\n",
       "                      0.3488, 0.4200, 0.1980, 0.7530, 0.3342, 0.2181, 0.3332, 0.2866, 0.5371,\n",
       "                      0.4247, 0.3883, 0.3121, 0.2710, 0.4582, 0.2523, 0.3140, 0.0775, 0.3054,\n",
       "                      0.1081, 0.7139, 0.4092, 0.2880, 0.5081, 0.3732, 0.5536, 0.2296, 0.2827,\n",
       "                      0.2353, 0.5687, 0.4606, 0.3634, 0.1712, 0.1268, 0.6385, 0.3082, 0.3096,\n",
       "                      0.1579, 0.4247, 0.2575, 0.4443, 0.7131, 0.5025, 0.3626, 0.4818, 0.4804,\n",
       "                      0.3684, 0.4124, 0.2857, 0.2290, 0.4815, 0.2078, 0.3984, 0.1389, 0.1876,\n",
       "                      0.4210, 0.3745, 0.3359, 0.2730, 0.2130, 0.3158, 0.1287, 0.4849, 0.5211,\n",
       "                      0.2518, 0.3471, 0.1475, 0.3549, 0.5391, 0.4179, 0.5497, 0.5160, 0.4492,\n",
       "                      0.5797, 0.2222, 0.3421, 0.3285, 0.3419, 0.3883, 0.4151, 0.2998, 0.6282,\n",
       "                      0.2886, 0.4031, 0.2554, 0.4954, 0.1408, 0.2014, 0.4737, 0.1443, 0.1878,\n",
       "                      0.4274, 0.2010, 0.2830, 0.3303, 0.2659, 0.3211, 0.3447, 0.3757, 0.2542,\n",
       "                      0.1635, 0.4201, 0.3199, 0.6092, 0.3950, 0.3346, 0.4007, 0.1630, 0.2453,\n",
       "                      0.4922, 0.2011, 0.1639, 0.2569, 0.2182, 0.3577, 0.1246, 0.2104, 0.2572,\n",
       "                      0.3045, 0.3355, 0.7313, 0.5353, 0.5047, 0.1876, 0.2742, 0.3983, 0.3997,\n",
       "                      0.2635, 0.2337, 0.2416, 0.3575, 0.7485, 0.3279, 0.6272, 0.1778, 0.3045,\n",
       "                      0.2869, 0.1915, 0.4269, 0.3705, 0.2517, 0.4039, 0.4680, 0.0831, 0.4340,\n",
       "                      0.3152, 0.3870, 0.3992, 0.4045, 0.4737, 0.3611, 0.6323, 0.2540, 0.5208,\n",
       "                      0.5764, 0.4656, 0.1827, 0.3169, 0.3335, 0.4904, 0.1990, 0.2878, 0.3710,\n",
       "                      0.0941, 0.1493, 0.4490, 0.2366, 0.2705, 0.4054, 0.5103, 0.3166, 0.2974,\n",
       "                      0.2964, 0.4758, 0.2610, 0.3913, 0.3401, 0.1990, 0.1937, 0.4235, 0.5163,\n",
       "                      0.2335, 0.2796, 0.2841, 0.6113, 0.3644, 0.3823, 0.3750, 0.2662, 0.3206,\n",
       "                      0.1455, 0.3110, 0.3324, 0.3319, 0.3935, 0.0495, 0.5328, 0.2288, 0.2699,\n",
       "                      0.2181, 0.3549, 0.3519, 0.2817, 0.5131, 0.1355, 0.5481, 0.3814, 0.4090,\n",
       "                      0.1956, 0.3608, 0.3629, 0.3920], dtype=torch.float64)),\n",
       "             ('6.5.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.5.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0159],\n",
       "                       [ 0.0959],\n",
       "                       [ 0.0464],\n",
       "                       ...,\n",
       "                       [-0.0345],\n",
       "                       [-0.0361],\n",
       "                       [-0.0095]],\n",
       "              \n",
       "                      [[-0.0082],\n",
       "                       [-0.0873],\n",
       "                       [ 0.1419],\n",
       "                       ...,\n",
       "                       [ 0.0476],\n",
       "                       [ 0.1877],\n",
       "                       [-0.2293]],\n",
       "              \n",
       "                      [[ 0.0361],\n",
       "                       [-0.0449],\n",
       "                       [ 0.0379],\n",
       "                       ...,\n",
       "                       [-0.0941],\n",
       "                       [ 0.0118],\n",
       "                       [-0.0568]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1578],\n",
       "                       [-0.1014],\n",
       "                       [-0.0985],\n",
       "                       ...,\n",
       "                       [ 0.0263],\n",
       "                       [-0.0787],\n",
       "                       [-0.0804]],\n",
       "              \n",
       "                      [[ 0.0774],\n",
       "                       [-0.1321],\n",
       "                       [ 0.0956],\n",
       "                       ...,\n",
       "                       [-0.0218],\n",
       "                       [-0.0260],\n",
       "                       [-0.0188]],\n",
       "              \n",
       "                      [[ 0.0756],\n",
       "                       [-0.0247],\n",
       "                       [-0.0297],\n",
       "                       ...,\n",
       "                       [ 0.0865],\n",
       "                       [ 0.1219],\n",
       "                       [-0.0433]]], dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.0.1.weight',\n",
       "              tensor([0.9698, 0.9699, 0.9490, 0.9663, 0.9633, 0.9676, 0.9883, 0.9712, 0.9682,\n",
       "                      0.9791, 0.9616, 0.9649, 0.9606, 0.9528, 0.9664, 1.0263, 0.9790, 0.9987,\n",
       "                      0.9737, 0.9548, 0.9581, 0.9872, 1.0118, 0.9746, 0.9829, 0.9680, 0.9722,\n",
       "                      0.9765, 0.9793, 0.9638, 0.9805, 0.9741, 0.9685, 0.9728, 0.9462, 0.9585,\n",
       "                      0.9784, 0.9931, 0.9571, 0.9883, 0.9809, 0.9737, 0.9720, 0.9975, 0.9671,\n",
       "                      0.9515, 0.9789, 0.9919, 0.9769, 0.9802, 0.9564, 0.9679, 0.9916, 0.9757,\n",
       "                      0.9393, 0.9593, 0.9758, 0.9667, 0.9846, 0.9941, 1.0062, 0.9416, 0.9720,\n",
       "                      0.9351], dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0029,  0.0080,  0.0072,  0.0055,  0.0078,  0.0029,  0.0119, -0.0023,\n",
       "                       0.0081,  0.0076,  0.0085,  0.0116,  0.0072, -0.0094, -0.0093,  0.0260,\n",
       "                      -0.0009,  0.0249,  0.0107, -0.0103, -0.0106,  0.0146,  0.0177, -0.0025,\n",
       "                      -0.0099, -0.0008, -0.0145,  0.0041,  0.0185, -0.0100,  0.0205, -0.0082,\n",
       "                       0.0224,  0.0084, -0.0231,  0.0111, -0.0076,  0.0167,  0.0065, -0.0097,\n",
       "                      -0.0050, -0.0082, -0.0003,  0.0200,  0.0069, -0.0307, -0.0131,  0.0215,\n",
       "                      -0.0119,  0.0096, -0.0119, -0.0108,  0.0265, -0.0052, -0.0056, -0.0024,\n",
       "                      -0.0097, -0.0155,  0.0093,  0.0177,  0.0003, -0.0025,  0.0004, -0.0243],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.6289,  0.0562,  0.3036, -0.4673,  0.1196, -0.3437,  0.6448, -0.5550,\n",
       "                       0.0174,  0.2705, -1.0050, -0.4373, -0.0208,  1.0133,  0.3290, -0.3679,\n",
       "                       0.3730,  0.3480, -0.7210, -0.8384,  0.2152, -0.1795, -0.5973, -0.0460,\n",
       "                      -0.2679,  0.2367, -0.3585,  0.4268,  0.1556, -0.1696,  0.0507,  0.2252,\n",
       "                      -0.3387, -0.4349,  0.6709, -0.2964,  0.5138,  0.0876,  0.1874,  0.2398,\n",
       "                      -0.1897,  0.3736,  0.0685, -0.4554,  0.6861,  1.1062,  0.9155, -0.7769,\n",
       "                       0.6319,  0.0610,  0.8805, -0.5538,  0.1561,  0.3953, -0.5522,  0.3013,\n",
       "                       0.6577, -0.3548, -0.3693, -0.4058, -0.6066, -0.4633,  0.1709,  0.6844],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.0.1.running_var',\n",
       "              tensor([0.1996, 0.2117, 0.3200, 0.2147, 0.1699, 0.1796, 0.3376, 0.1707, 0.1563,\n",
       "                      0.1256, 0.5637, 0.1581, 0.8390, 0.4758, 0.2161, 0.1157, 0.1487, 0.1251,\n",
       "                      0.2467, 0.3396, 0.5314, 0.1280, 0.0927, 0.1690, 0.1306, 0.4552, 0.0634,\n",
       "                      0.1722, 0.8017, 0.1737, 0.6113, 0.1162, 0.1827, 0.1961, 0.1242, 0.2585,\n",
       "                      0.9847, 0.5323, 0.3786, 0.1056, 0.2249, 0.5711, 0.2330, 0.1022, 0.2503,\n",
       "                      0.7001, 0.2299, 0.1263, 1.6804, 0.3714, 0.4519, 0.2089, 0.1189, 0.1122,\n",
       "                      0.1931, 0.2745, 0.3571, 0.1722, 0.3670, 0.1276, 0.1627, 0.3406, 0.1568,\n",
       "                      0.6619], dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.5.convpath.0.1.0.weight',\n",
       "              tensor([[[-0.0469,  0.0620,  0.0896, -0.0159, -0.0578],\n",
       "                       [-0.2007, -0.0320,  0.0168,  0.0656,  0.0493],\n",
       "                       [-0.0347,  0.0333,  0.0107, -0.0247, -0.0010],\n",
       "                       ...,\n",
       "                       [ 0.0094, -0.0280, -0.1716, -0.0484,  0.0938],\n",
       "                       [-0.0192,  0.0287,  0.0148,  0.0184,  0.0493],\n",
       "                       [ 0.1046,  0.0407, -0.0652,  0.0161, -0.0574]],\n",
       "              \n",
       "                      [[ 0.0285,  0.0449, -0.0022, -0.0601, -0.0216],\n",
       "                       [-0.0301,  0.0648, -0.0313,  0.0750,  0.0139],\n",
       "                       [ 0.1176, -0.0173, -0.1481, -0.0981, -0.0136],\n",
       "                       ...,\n",
       "                       [-0.1328, -0.0014, -0.0385,  0.0227,  0.0490],\n",
       "                       [-0.1500,  0.0246, -0.0173, -0.0551,  0.0272],\n",
       "                       [-0.0817,  0.0874, -0.0957,  0.0768,  0.1392]],\n",
       "              \n",
       "                      [[ 0.0350, -0.1329,  0.1100, -0.0393,  0.0047],\n",
       "                       [ 0.0572, -0.0430, -0.0515,  0.0057,  0.0666],\n",
       "                       [ 0.0749,  0.1899,  0.0320,  0.0132,  0.1371],\n",
       "                       ...,\n",
       "                       [ 0.0552, -0.0441, -0.1381,  0.0138,  0.0652],\n",
       "                       [ 0.0761, -0.0697,  0.0660, -0.0914, -0.0111],\n",
       "                       [-0.0612,  0.0737,  0.0346, -0.0860, -0.0321]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0534, -0.0471, -0.0225,  0.0921, -0.0139],\n",
       "                       [-0.1966,  0.1848, -0.0647, -0.1086, -0.0737],\n",
       "                       [ 0.1921, -0.0128,  0.0160, -0.0588, -0.1794],\n",
       "                       ...,\n",
       "                       [-0.0194, -0.0011,  0.0822, -0.1450, -0.0185],\n",
       "                       [-0.0848,  0.1030,  0.1008, -0.0007,  0.1412],\n",
       "                       [-0.0218,  0.0906, -0.0930,  0.0175,  0.0472]],\n",
       "              \n",
       "                      [[-0.0925,  0.0878,  0.0055, -0.0226, -0.0392],\n",
       "                       [-0.0791,  0.0301, -0.0399, -0.0821,  0.1582],\n",
       "                       [ 0.0780,  0.0089,  0.0555,  0.0292, -0.0327],\n",
       "                       ...,\n",
       "                       [-0.0304,  0.0652,  0.0845, -0.0118, -0.0925],\n",
       "                       [-0.0663,  0.0998, -0.0152, -0.0046, -0.1432],\n",
       "                       [-0.0433,  0.0106,  0.0961, -0.0291, -0.0429]],\n",
       "              \n",
       "                      [[-0.1359, -0.0836,  0.0608, -0.1169,  0.0488],\n",
       "                       [ 0.0846, -0.1247,  0.0931,  0.0566, -0.0603],\n",
       "                       [ 0.1391,  0.0735, -0.0932,  0.0539,  0.1275],\n",
       "                       ...,\n",
       "                       [-0.0027,  0.0183, -0.1515,  0.1310,  0.0492],\n",
       "                       [-0.0406,  0.1284,  0.0023,  0.0277,  0.0203],\n",
       "                       [-0.0465, -0.0169, -0.0413,  0.0532, -0.0258]]], dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.1.1.weight',\n",
       "              tensor([0.9866, 0.9551, 0.9633, 0.9620, 0.9669, 0.9623, 0.9590, 0.9494, 0.9760,\n",
       "                      0.9734, 0.9512, 0.9907, 0.9916, 0.9903, 0.9243, 0.9717, 0.9820, 0.9616,\n",
       "                      0.9932, 0.9839, 0.9753, 0.9651, 0.9564, 0.9578, 0.9592, 0.9431, 0.9829,\n",
       "                      0.9404, 0.9402, 1.0097, 0.9711, 0.9377, 0.9708, 0.9900, 0.9713, 0.9596,\n",
       "                      0.9559, 0.9666, 0.9822, 0.9464, 0.9589, 0.9544, 0.9912, 0.9783, 0.9498,\n",
       "                      0.9262, 0.9456, 0.9297, 0.9514, 0.9746, 0.9519, 0.9529, 0.9439, 0.9671,\n",
       "                      0.9795, 0.9525, 0.9734, 0.9753, 0.9439, 1.0004, 0.9893, 0.9808, 0.9160,\n",
       "                      1.0033], dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.1.1.bias',\n",
       "              tensor([-0.0061,  0.0062, -0.0270, -0.0155,  0.0010, -0.0245,  0.0085, -0.0290,\n",
       "                       0.0003, -0.0093, -0.0073,  0.0110,  0.0232,  0.0099, -0.0197, -0.0020,\n",
       "                       0.0104, -0.0030,  0.0203,  0.0014, -0.0121, -0.0055,  0.0065, -0.0006,\n",
       "                      -0.0025, -0.0159,  0.0053,  0.0080, -0.0139,  0.0193, -0.0151, -0.0301,\n",
       "                      -0.0219,  0.0183,  0.0124, -0.0274, -0.0250, -0.0095, -0.0007, -0.0188,\n",
       "                      -0.0151, -0.0059,  0.0176,  0.0097, -0.0027, -0.0105,  0.0083, -0.0148,\n",
       "                      -0.0188, -0.0265, -0.0028, -0.0168, -0.0084, -0.0057,  0.0132, -0.0189,\n",
       "                       0.0075,  0.0077, -0.0181,  0.0152,  0.0082, -0.0024, -0.0146,  0.0089],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.6885, -1.2877,  0.3191,  0.5982, -0.4933,  0.3985,  0.1076,  0.2197,\n",
       "                       0.1896,  0.4515, -0.6079,  0.4856, -0.7102,  0.3500, -0.1991,  0.1864,\n",
       "                       0.0232, -0.7216, -0.7500,  0.1427,  0.5482,  0.0172, -0.2554, -0.0261,\n",
       "                      -0.8555, -0.5965, -0.0873, -0.4673, -0.7123,  0.0759,  0.6981,  0.0750,\n",
       "                       0.7663, -0.3931, -0.0945,  0.5454, -0.1214, -0.3008, -0.1166,  0.2179,\n",
       "                       0.2983, -0.1267, -1.1962,  0.4033, -0.6889, -0.7182, -0.5579, -0.8400,\n",
       "                      -0.2914,  1.0688, -0.3007, -0.3782, -0.3093,  1.2386, -0.1279, -0.6222,\n",
       "                       0.4311, -0.9213,  0.0225,  0.1456, -0.2438, -0.2756, -0.4038, -1.0030],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.1.1.running_var',\n",
       "              tensor([0.5122, 0.9793, 0.5548, 0.9017, 0.5254, 0.7793, 1.0079, 0.8371, 0.5705,\n",
       "                      0.5136, 0.8169, 0.8182, 0.5292, 0.4946, 0.6266, 0.5874, 0.4952, 0.5450,\n",
       "                      0.4956, 0.6343, 0.4036, 0.7054, 0.6085, 0.5657, 1.2514, 0.8176, 0.5660,\n",
       "                      0.6809, 0.9881, 0.5207, 0.8641, 0.3312, 0.9939, 0.5919, 0.7487, 0.8015,\n",
       "                      1.1297, 0.4300, 0.5160, 0.6869, 0.5546, 0.5179, 0.4262, 0.6387, 0.6856,\n",
       "                      1.0306, 0.9522, 1.0984, 0.4906, 1.0767, 0.8956, 0.8615, 0.6042, 0.7023,\n",
       "                      0.7387, 0.6545, 0.4629, 1.0982, 0.5738, 0.5377, 0.6929, 0.4819, 1.7552,\n",
       "                      0.6772], dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.5.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0007],\n",
       "                       [-0.0225],\n",
       "                       [ 0.0369],\n",
       "                       ...,\n",
       "                       [-0.1321],\n",
       "                       [-0.1222],\n",
       "                       [ 0.1618]],\n",
       "              \n",
       "                      [[-0.0804],\n",
       "                       [-0.0332],\n",
       "                       [-0.2140],\n",
       "                       ...,\n",
       "                       [ 0.0400],\n",
       "                       [-0.1306],\n",
       "                       [-0.2144]],\n",
       "              \n",
       "                      [[ 0.0549],\n",
       "                       [ 0.0320],\n",
       "                       [-0.0821],\n",
       "                       ...,\n",
       "                       [ 0.0321],\n",
       "                       [ 0.0305],\n",
       "                       [-0.0088]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0743],\n",
       "                       [ 0.2200],\n",
       "                       [-0.2823],\n",
       "                       ...,\n",
       "                       [-0.2902],\n",
       "                       [ 0.1863],\n",
       "                       [-0.0793]],\n",
       "              \n",
       "                      [[ 0.2339],\n",
       "                       [-0.2356],\n",
       "                       [ 0.2510],\n",
       "                       ...,\n",
       "                       [ 0.1311],\n",
       "                       [ 0.1117],\n",
       "                       [ 0.0206]],\n",
       "              \n",
       "                      [[ 0.0837],\n",
       "                       [ 0.1134],\n",
       "                       [ 0.1545],\n",
       "                       ...,\n",
       "                       [-0.0509],\n",
       "                       [-0.0122],\n",
       "                       [ 0.0042]]], dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.2.1.weight',\n",
       "              tensor([-0.0001, -0.0071,  0.0082,  0.0218,  0.0208,  0.0266, -0.0033, -0.0165,\n",
       "                       0.0369,  0.0064,  0.0164,  0.0142,  0.0193, -0.0040,  0.0227, -0.0241,\n",
       "                      -0.0193, -0.0007, -0.0040, -0.0178,  0.0197,  0.0307, -0.0016, -0.0154,\n",
       "                       0.0313, -0.0091,  0.0136,  0.0216, -0.0052,  0.0074,  0.0046, -0.0224,\n",
       "                       0.0267, -0.0045, -0.0246,  0.0109,  0.0207, -0.0097, -0.0203, -0.0021,\n",
       "                      -0.0233, -0.0091,  0.0092,  0.0101, -0.0090, -0.0069,  0.0155, -0.0030,\n",
       "                       0.0180, -0.0128, -0.0195,  0.0072, -0.0088,  0.0172, -0.0135,  0.0013,\n",
       "                       0.0223,  0.0198, -0.0169, -0.0200,  0.0105, -0.0012,  0.0061, -0.0065,\n",
       "                       0.0152,  0.0119, -0.0062,  0.0287, -0.0093,  0.0145,  0.0084,  0.0005,\n",
       "                      -0.0020, -0.0442, -0.0163, -0.0096, -0.0010, -0.0007, -0.0051, -0.0174,\n",
       "                      -0.0164, -0.0141, -0.0121,  0.0008, -0.0093, -0.0144,  0.0125,  0.0140,\n",
       "                      -0.0401, -0.0126, -0.0085,  0.0324,  0.0231,  0.0050, -0.0077,  0.0027,\n",
       "                       0.0168,  0.0205,  0.0087,  0.0304,  0.0074,  0.0103, -0.0138,  0.0123,\n",
       "                       0.0037,  0.0075,  0.0071,  0.0034, -0.0065,  0.0242,  0.0010, -0.0063,\n",
       "                      -0.0165,  0.0154,  0.0048, -0.0171, -0.0044,  0.0220,  0.0068, -0.0017,\n",
       "                       0.0210,  0.0069, -0.0095, -0.0119, -0.0189, -0.0132, -0.0175,  0.0125,\n",
       "                      -0.0256, -0.0144, -0.0035, -0.0074,  0.0178,  0.0035,  0.0105,  0.0172,\n",
       "                      -0.0072,  0.0021,  0.0164, -0.0152, -0.0045, -0.0131,  0.0119,  0.0080,\n",
       "                       0.0189, -0.0001,  0.0106, -0.0018, -0.0253,  0.0015,  0.0063, -0.0175,\n",
       "                       0.0273,  0.0155, -0.0046,  0.0007,  0.0050, -0.0153,  0.0231,  0.0093,\n",
       "                      -0.0043,  0.0196,  0.0062,  0.0145, -0.0315,  0.0352,  0.0369, -0.0026,\n",
       "                      -0.0005,  0.0107,  0.0167,  0.0264, -0.0019,  0.0106, -0.0127,  0.0255,\n",
       "                       0.0169,  0.0277, -0.0060,  0.0109, -0.0063,  0.0078,  0.0037, -0.0110,\n",
       "                       0.0137,  0.0207,  0.0143, -0.0032,  0.0215,  0.0086,  0.0290,  0.0238,\n",
       "                       0.0277, -0.0119, -0.0177, -0.0175, -0.0063, -0.0274,  0.0183,  0.0232,\n",
       "                      -0.0022,  0.0091,  0.0226, -0.0306,  0.0113, -0.0112, -0.0269,  0.0103,\n",
       "                      -0.0008, -0.0422, -0.0155, -0.0016,  0.0233, -0.0230,  0.0373, -0.0133,\n",
       "                       0.0031, -0.0163,  0.0296,  0.0169, -0.0090,  0.0124, -0.0115, -0.0125,\n",
       "                      -0.0148, -0.0108, -0.0158, -0.0103,  0.0203, -0.0155,  0.0091, -0.0135,\n",
       "                      -0.0169, -0.0189, -0.0072, -0.0001,  0.0170,  0.0206,  0.0081,  0.0027,\n",
       "                       0.0352,  0.0142, -0.0082,  0.0022, -0.0198, -0.0248, -0.0072, -0.0484,\n",
       "                      -0.0096,  0.0152, -0.0017, -0.0007,  0.0001,  0.0126, -0.0316,  0.0102],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.2.1.bias',\n",
       "              tensor([-1.1678e-03, -3.1923e-03,  1.3112e-02,  2.0858e-02,  4.7208e-03,\n",
       "                       4.3608e-04,  1.5750e-02,  1.6490e-03,  9.8747e-03,  2.2442e-02,\n",
       "                       1.3793e-02, -5.5202e-03,  9.0527e-03, -5.6862e-03,  6.9908e-03,\n",
       "                       4.8064e-03,  2.0773e-02, -3.2974e-03,  1.2745e-02, -8.5603e-03,\n",
       "                      -4.9067e-03,  3.5996e-03,  5.5753e-04,  7.2405e-03, -5.7225e-03,\n",
       "                      -1.5083e-02,  5.0426e-03,  1.1423e-02,  1.7953e-03, -2.4789e-03,\n",
       "                       3.9750e-03,  8.0682e-03, -7.7040e-03,  1.7316e-02,  1.4617e-02,\n",
       "                       7.3996e-03, -1.2831e-03,  1.9569e-02,  9.1630e-03,  1.4885e-02,\n",
       "                      -8.3387e-04,  2.5908e-02, -6.4297e-03,  1.2283e-03,  3.1307e-03,\n",
       "                      -8.8600e-03,  2.7441e-03,  4.8239e-03, -1.1548e-02,  1.3157e-02,\n",
       "                       8.5368e-03,  1.2742e-02,  9.1695e-03,  1.4107e-02,  6.0820e-03,\n",
       "                       1.5736e-02,  7.8488e-03,  2.3520e-03,  8.5711e-03,  3.6600e-03,\n",
       "                      -1.2452e-03,  2.8815e-03,  4.8816e-03,  9.4797e-03, -4.1062e-03,\n",
       "                       1.2507e-02, -1.1526e-02,  1.2648e-02, -4.1438e-03, -1.1468e-02,\n",
       "                       3.2367e-03,  6.3141e-03,  2.4182e-03, -7.2418e-03,  1.4082e-02,\n",
       "                       2.4774e-03,  2.5678e-03,  2.4910e-03,  4.3122e-03, -8.6151e-04,\n",
       "                       1.0517e-02, -4.9261e-03,  8.1478e-03,  4.0931e-03, -2.7773e-03,\n",
       "                       1.2507e-02,  1.4951e-03,  2.0740e-03,  1.4591e-02,  6.5104e-03,\n",
       "                      -7.8116e-04,  2.2174e-02,  1.7469e-02, -3.8160e-04,  8.7713e-03,\n",
       "                      -1.5142e-02,  6.4406e-03, -6.3540e-04,  1.1212e-02,  1.0910e-03,\n",
       "                       1.9688e-02,  2.3529e-03, -2.2913e-03, -4.8809e-03,  1.0449e-02,\n",
       "                       4.0728e-04, -3.5230e-04,  3.4947e-03,  4.1352e-03,  3.9265e-03,\n",
       "                      -5.8501e-03, -7.1410e-03,  4.0409e-03,  1.5027e-02,  1.1741e-02,\n",
       "                       6.7241e-03,  1.1544e-02,  2.9570e-03,  2.1605e-03, -1.4881e-02,\n",
       "                       2.2379e-03,  8.3369e-03,  5.6436e-04, -3.0349e-03, -1.1580e-02,\n",
       "                       1.1330e-02,  1.4120e-02,  4.5586e-03,  3.1886e-05,  1.5085e-02,\n",
       "                       2.3358e-02,  1.5722e-02,  1.4378e-02,  5.9259e-03,  1.5272e-02,\n",
       "                      -9.4663e-03,  1.5928e-02,  6.1710e-03,  1.4116e-02,  7.8326e-03,\n",
       "                       9.9809e-03, -3.3011e-03,  1.4455e-02,  7.1306e-03, -8.7077e-03,\n",
       "                       1.4016e-02,  6.2895e-03, -1.6422e-03,  1.0654e-02,  8.9558e-03,\n",
       "                       6.6912e-03,  1.2681e-02,  3.4863e-03,  1.5336e-02,  1.5329e-02,\n",
       "                       8.8705e-03,  8.5649e-04,  7.7767e-03, -3.1015e-03, -9.3596e-03,\n",
       "                       3.1068e-03, -3.1637e-03,  2.1641e-04,  1.3721e-02,  1.2348e-02,\n",
       "                      -2.4406e-04, -7.7747e-03,  9.3160e-03,  8.9869e-04,  1.5482e-02,\n",
       "                       5.1663e-03,  9.8502e-03,  1.0459e-02,  1.0038e-02, -1.3533e-02,\n",
       "                       4.9343e-03, -8.7596e-04,  1.1555e-02,  3.7394e-03,  4.2140e-03,\n",
       "                      -2.6184e-03,  9.5581e-03, -7.9303e-03, -1.0230e-02,  1.8723e-02,\n",
       "                       8.3758e-03,  1.4122e-02,  1.0819e-02, -4.7476e-04,  4.4541e-03,\n",
       "                       6.2162e-03,  1.8599e-03,  1.0383e-02, -7.1263e-03,  4.8448e-03,\n",
       "                       7.5120e-03, -3.3724e-03,  1.9145e-02,  8.2710e-03,  1.9359e-02,\n",
       "                       4.5284e-03,  2.0462e-02,  2.0598e-02,  1.7428e-02,  6.2022e-05,\n",
       "                      -6.3827e-04,  1.4967e-02, -2.8858e-03,  7.2059e-03,  4.4177e-03,\n",
       "                       1.6921e-03,  1.2562e-02,  1.2954e-02,  6.6632e-03,  1.3517e-02,\n",
       "                       5.4235e-03,  3.9152e-03, -2.7745e-03,  3.0169e-03, -1.6081e-04,\n",
       "                      -1.6028e-02,  1.1125e-03,  6.0373e-03,  2.0237e-02, -4.3494e-03,\n",
       "                       3.8112e-03, -2.7621e-03,  1.7193e-03, -1.4179e-02,  1.4331e-02,\n",
       "                       1.2810e-02, -2.0004e-03,  1.0907e-02,  9.4899e-03,  3.5680e-03,\n",
       "                       6.7986e-03,  7.4130e-03, -8.2110e-03,  8.9692e-03,  8.9572e-03,\n",
       "                       1.9057e-03,  4.3985e-03,  4.4228e-03,  7.5920e-03,  2.3147e-03,\n",
       "                       1.5026e-02, -2.5035e-04,  1.0708e-02,  2.8740e-03, -8.9365e-03,\n",
       "                       1.7465e-02,  1.8552e-02,  1.7808e-02,  1.7584e-02,  1.1978e-02,\n",
       "                       9.0722e-03], dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.2.1.running_mean',\n",
       "              tensor([-0.0361,  0.1680, -0.1646,  0.1862,  0.1692,  0.0768,  0.2476, -0.3694,\n",
       "                       0.2180,  0.4591, -0.0384,  0.4116,  0.1827,  0.1186,  0.7991, -0.1803,\n",
       "                      -0.0856,  0.0785, -0.3732,  0.5654, -0.0715, -0.3280, -0.1701,  0.7322,\n",
       "                      -0.8324,  0.0994, -0.6030, -0.1757, -0.4184,  0.3869,  0.4321,  0.0448,\n",
       "                      -0.5696, -0.4391, -0.5532,  0.3704, -0.0467, -0.1026,  0.4465, -0.5886,\n",
       "                       0.5982, -0.5109,  0.0339,  0.4257,  0.0196,  0.5457,  0.7079, -0.0944,\n",
       "                       0.4062,  0.1916, -0.1695,  0.5542,  0.2431, -0.6123,  0.8114,  0.4746,\n",
       "                      -0.0576,  0.0469,  0.6021,  0.1555,  0.0405,  0.0494,  0.5356, -0.0535,\n",
       "                      -0.7021, -0.0441, -0.2569,  0.9482,  0.1479,  0.0841, -0.1419,  0.8612,\n",
       "                      -0.2116, -0.2645, -0.3329, -0.2167, -0.1655, -0.1057, -0.6193,  0.4380,\n",
       "                      -0.0928, -0.2382,  0.5345, -0.4614, -0.0284,  0.1385, -0.3266,  0.2415,\n",
       "                       0.3903, -0.7708, -0.9324,  0.3164,  0.1644,  0.0377, -0.2497,  0.6259,\n",
       "                      -0.4679, -0.0775, -0.2853, -0.2560,  0.3264,  0.1414, -0.1178, -0.0971,\n",
       "                       0.2791, -0.0492,  0.1263,  0.1476,  0.2262,  0.2986,  0.1013, -0.5593,\n",
       "                       0.1161, -0.7467,  0.0815,  0.0659,  0.7355, -0.4172, -0.3645,  0.0763,\n",
       "                      -0.1273,  0.9781, -0.0484, -0.6244, -0.1628, -0.5973,  0.2806,  0.6401,\n",
       "                      -0.0638,  0.4480, -0.3785, -0.0287,  0.0259,  0.1997, -0.3077,  0.1086,\n",
       "                      -0.1784, -0.4023,  0.0107, -0.2770,  0.3481, -0.1480,  0.8255, -0.2505,\n",
       "                       0.0561, -0.1016,  0.6592, -0.3125, -0.9027, -0.3901,  0.3778, -0.0851,\n",
       "                      -0.1515,  0.1321, -0.4119,  0.3111, -0.2307,  0.0767, -0.6245,  0.0281,\n",
       "                      -0.4003, -0.2882, -0.2339, -0.4514,  1.0053, -0.7171, -0.8131,  0.0135,\n",
       "                      -0.1555, -0.0196, -0.0322, -0.3982, -0.2445, -0.0233,  0.0771,  0.1680,\n",
       "                      -0.2456, -0.3945,  0.1377,  0.1009, -0.0892, -0.1152, -0.1389,  0.0714,\n",
       "                      -0.0017, -0.6183, -0.2900, -0.2343, -0.8766,  0.5262, -0.6424, -0.0637,\n",
       "                       0.1023, -1.4370, -0.8441, -0.3755, -0.0906, -0.6952, -0.7279,  0.6015,\n",
       "                       0.2145,  0.1393, -0.3518,  0.6698,  0.2741, -0.4372, -0.4090,  0.0243,\n",
       "                      -0.0687,  0.3457, -0.1099, -0.0027, -0.5067,  0.8749, -0.3518, -0.0383,\n",
       "                      -0.0193, -0.7281,  0.3530, -0.0605, -0.1492, -0.1982, -0.1093,  0.2855,\n",
       "                       0.3502,  0.0152, -0.8461, -0.3615, -0.0848,  0.0210,  0.1633, -0.0032,\n",
       "                       0.2722,  0.1324, -0.0330,  0.2193, -0.4504,  0.3880,  0.9682, -0.1282,\n",
       "                       0.1240,  0.1317, -0.1373,  0.0434, -0.1966,  0.6083, -0.5636,  0.4389,\n",
       "                       0.4036, -0.1270, -0.8223,  0.0600,  0.0596, -0.1677,  0.5905, -0.0665],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.2.1.running_var',\n",
       "              tensor([0.1397, 0.5604, 0.1581, 0.3884, 0.3366, 0.2859, 0.3670, 0.4328, 0.2415,\n",
       "                      0.3887, 0.2474, 0.4844, 0.1749, 0.1436, 0.4473, 0.3128, 0.3727, 0.1979,\n",
       "                      0.2311, 0.4493, 0.3325, 0.3443, 0.3211, 0.4673, 0.5442, 0.3565, 0.3445,\n",
       "                      0.3611, 0.3431, 0.2579, 0.3480, 0.5796, 0.3409, 0.2687, 0.4687, 0.4586,\n",
       "                      0.3769, 0.1463, 0.3254, 0.4541, 0.3221, 0.4925, 0.2308, 0.6912, 0.2945,\n",
       "                      0.3488, 0.4200, 0.1980, 0.7530, 0.3342, 0.2181, 0.3332, 0.2866, 0.5371,\n",
       "                      0.4247, 0.3883, 0.3121, 0.2710, 0.4582, 0.2523, 0.3140, 0.0775, 0.3054,\n",
       "                      0.1081, 0.7139, 0.4092, 0.2880, 0.5081, 0.3732, 0.5536, 0.2296, 0.2827,\n",
       "                      0.2353, 0.5687, 0.4606, 0.3634, 0.1712, 0.1268, 0.6385, 0.3082, 0.3096,\n",
       "                      0.1579, 0.4247, 0.2575, 0.4443, 0.7131, 0.5025, 0.3626, 0.4818, 0.4804,\n",
       "                      0.3684, 0.4124, 0.2857, 0.2290, 0.4815, 0.2078, 0.3984, 0.1389, 0.1876,\n",
       "                      0.4210, 0.3745, 0.3359, 0.2730, 0.2130, 0.3158, 0.1287, 0.4849, 0.5211,\n",
       "                      0.2518, 0.3471, 0.1475, 0.3549, 0.5391, 0.4179, 0.5497, 0.5160, 0.4492,\n",
       "                      0.5797, 0.2222, 0.3421, 0.3285, 0.3419, 0.3883, 0.4151, 0.2998, 0.6282,\n",
       "                      0.2886, 0.4031, 0.2554, 0.4954, 0.1408, 0.2014, 0.4737, 0.1443, 0.1878,\n",
       "                      0.4274, 0.2010, 0.2830, 0.3303, 0.2659, 0.3211, 0.3447, 0.3757, 0.2542,\n",
       "                      0.1635, 0.4201, 0.3199, 0.6092, 0.3950, 0.3346, 0.4007, 0.1630, 0.2453,\n",
       "                      0.4922, 0.2011, 0.1639, 0.2569, 0.2182, 0.3577, 0.1246, 0.2104, 0.2572,\n",
       "                      0.3045, 0.3355, 0.7313, 0.5353, 0.5047, 0.1876, 0.2742, 0.3983, 0.3997,\n",
       "                      0.2635, 0.2337, 0.2416, 0.3575, 0.7485, 0.3279, 0.6272, 0.1778, 0.3045,\n",
       "                      0.2869, 0.1915, 0.4269, 0.3705, 0.2517, 0.4039, 0.4680, 0.0831, 0.4340,\n",
       "                      0.3152, 0.3870, 0.3992, 0.4045, 0.4737, 0.3611, 0.6323, 0.2540, 0.5208,\n",
       "                      0.5764, 0.4656, 0.1827, 0.3169, 0.3335, 0.4904, 0.1990, 0.2878, 0.3710,\n",
       "                      0.0941, 0.1493, 0.4490, 0.2366, 0.2705, 0.4054, 0.5103, 0.3166, 0.2974,\n",
       "                      0.2964, 0.4758, 0.2610, 0.3913, 0.3401, 0.1990, 0.1937, 0.4235, 0.5163,\n",
       "                      0.2335, 0.2796, 0.2841, 0.6113, 0.3644, 0.3823, 0.3750, 0.2662, 0.3206,\n",
       "                      0.1455, 0.3110, 0.3324, 0.3319, 0.3935, 0.0495, 0.5328, 0.2288, 0.2699,\n",
       "                      0.2181, 0.3549, 0.3519, 0.2817, 0.5131, 0.1355, 0.5481, 0.3814, 0.4090,\n",
       "                      0.1956, 0.3608, 0.3629, 0.3920], dtype=torch.float64)),\n",
       "             ('6.5.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.6.convs.0.0.weight',\n",
       "              tensor([[[ 0.0720],\n",
       "                       [-0.0094],\n",
       "                       [-0.1010],\n",
       "                       ...,\n",
       "                       [ 0.1000],\n",
       "                       [ 0.0120],\n",
       "                       [-0.0529]],\n",
       "              \n",
       "                      [[ 0.1434],\n",
       "                       [-0.0673],\n",
       "                       [ 0.0486],\n",
       "                       ...,\n",
       "                       [-0.1109],\n",
       "                       [-0.1072],\n",
       "                       [ 0.1523]],\n",
       "              \n",
       "                      [[-0.0274],\n",
       "                       [ 0.1305],\n",
       "                       [ 0.0422],\n",
       "                       ...,\n",
       "                       [-0.0935],\n",
       "                       [-0.0277],\n",
       "                       [ 0.0125]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1152],\n",
       "                       [-0.0443],\n",
       "                       [-0.0328],\n",
       "                       ...,\n",
       "                       [-0.0579],\n",
       "                       [-0.0156],\n",
       "                       [ 0.1178]],\n",
       "              \n",
       "                      [[-0.0496],\n",
       "                       [-0.0590],\n",
       "                       [ 0.0376],\n",
       "                       ...,\n",
       "                       [ 0.0064],\n",
       "                       [ 0.1038],\n",
       "                       [ 0.0570]],\n",
       "              \n",
       "                      [[-0.1157],\n",
       "                       [-0.0080],\n",
       "                       [-0.0244],\n",
       "                       ...,\n",
       "                       [-0.0049],\n",
       "                       [ 0.0876],\n",
       "                       [-0.0689]]], dtype=torch.float64)),\n",
       "             ('6.6.convs.0.1.weight',\n",
       "              tensor([0.9826, 0.9772, 0.9700, 0.9727, 0.9657, 0.9871, 0.9391, 0.9691, 0.9602,\n",
       "                      0.9748, 0.9704, 0.9805, 0.9726, 0.9909, 0.9539, 0.9664, 0.9866, 0.9800,\n",
       "                      0.9819, 0.9663, 0.9648, 0.9647, 0.9416, 0.9658, 0.9527, 0.9633, 0.9816,\n",
       "                      0.9760, 0.9636, 0.9700, 0.9716, 0.9836, 0.9796, 0.9682, 0.9812, 0.9931,\n",
       "                      0.9679, 0.9763, 0.9484, 0.9725, 0.9796, 0.9580, 0.9717, 0.9802, 0.9836,\n",
       "                      0.9641, 0.9605, 0.9794, 0.9662, 0.9130, 0.9730, 0.9883, 0.9619, 0.9754,\n",
       "                      0.9722, 0.9628, 0.9688, 0.9820, 0.9741, 0.9555, 1.0019, 0.9815, 0.9846,\n",
       "                      0.9716], dtype=torch.float64)),\n",
       "             ('6.6.convs.0.1.bias',\n",
       "              tensor([ 7.9298e-03, -1.6504e-02, -3.5259e-03,  8.8641e-03,  1.7394e-02,\n",
       "                       1.4577e-02,  1.8607e-02,  2.6071e-02, -5.6859e-03,  9.7278e-04,\n",
       "                      -6.0344e-05,  1.3699e-02, -3.1433e-04,  1.9214e-03, -9.2234e-03,\n",
       "                       2.1870e-02,  1.6561e-03, -1.0894e-03, -5.4873e-03,  5.9783e-03,\n",
       "                      -1.8316e-03, -1.3388e-02, -1.1787e-02, -1.6116e-02,  1.4448e-02,\n",
       "                       1.8852e-02,  4.0475e-03,  1.3361e-02, -7.5687e-05, -1.4079e-02,\n",
       "                       9.5640e-03,  3.3048e-04, -5.6489e-03,  6.7681e-03, -4.4522e-03,\n",
       "                       1.4801e-02,  5.8675e-03,  8.8917e-03, -7.7835e-03,  7.5822e-03,\n",
       "                       1.1792e-02,  9.3591e-03,  5.2178e-03, -5.7296e-03, -2.4171e-03,\n",
       "                      -6.0555e-03,  5.0466e-03,  1.2532e-02, -1.7809e-02, -1.4765e-02,\n",
       "                      -8.9848e-03,  2.1055e-02, -1.7801e-02,  1.3745e-02,  1.5941e-02,\n",
       "                      -5.0243e-03, -1.1437e-02,  8.0832e-03,  1.8227e-03, -5.4222e-04,\n",
       "                       1.0704e-03, -3.4518e-03,  4.0056e-03, -6.6958e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convs.0.1.running_mean',\n",
       "              tensor([-5.6386e-01,  1.8281e-01,  7.2954e-01, -3.3039e-02, -2.1434e-01,\n",
       "                      -1.2662e-01, -2.0595e-01,  8.2226e-01,  5.4904e-01,  6.2270e-01,\n",
       "                      -1.0588e-01, -2.1881e-01,  6.6683e-01, -1.2798e+00, -1.1339e+00,\n",
       "                      -3.1620e-01,  5.2261e-01,  6.9635e-01,  3.8158e-01, -2.8051e-01,\n",
       "                       8.0299e-01,  2.6366e-02, -3.3314e-01, -3.3491e-01, -4.9945e-01,\n",
       "                      -6.3491e-01,  1.1841e-01,  2.2493e-01, -1.9744e-01, -1.4084e-03,\n",
       "                       3.7567e-01,  4.7048e-01, -1.5414e-01,  3.9710e-01,  5.0011e-01,\n",
       "                       3.0139e-01, -6.0198e-01, -6.1613e-01, -1.2172e-01,  2.9172e-01,\n",
       "                       1.0950e-01, -2.6238e-01,  1.6658e-02, -7.5101e-02, -2.1099e-01,\n",
       "                      -2.7900e-01, -2.6838e-01, -5.8714e-01, -6.6472e-02, -8.8720e-01,\n",
       "                       4.6803e-01, -7.0157e-01,  1.1955e+00, -4.4172e-01,  5.7278e-01,\n",
       "                      -5.2594e-01,  2.3816e-01,  7.0732e-01, -5.6742e-01,  1.1930e+00,\n",
       "                      -2.5621e-01,  1.0853e+00,  5.9320e-04,  2.5558e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convs.0.1.running_var',\n",
       "              tensor([0.1344, 0.1037, 0.5204, 0.1305, 0.2575, 0.1384, 0.5168, 0.2509, 0.3951,\n",
       "                      0.4697, 0.3493, 0.1233, 0.6185, 0.1642, 0.1972, 0.2624, 0.3477, 0.1635,\n",
       "                      0.1538, 0.0900, 0.1854, 0.2579, 0.6624, 0.1611, 0.1252, 0.8599, 0.1259,\n",
       "                      0.1824, 0.1261, 0.1542, 0.8356, 0.5019, 0.1304, 0.6070, 0.1847, 0.1582,\n",
       "                      0.3802, 0.1243, 0.5342, 0.2432, 0.1892, 0.2450, 0.1238, 0.1986, 0.2761,\n",
       "                      0.5502, 0.3316, 0.2970, 0.1454, 0.9366, 0.1110, 0.0889, 1.0770, 0.2308,\n",
       "                      0.4746, 0.4266, 0.0977, 0.3190, 0.1882, 0.8624, 0.1912, 0.7865, 0.1631,\n",
       "                      0.2162], dtype=torch.float64)),\n",
       "             ('6.6.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.6.convs.1.0.weight',\n",
       "              tensor([[[-3.0066e-02, -5.6900e-02,  1.3447e-02,  6.1007e-02, -2.6408e-02],\n",
       "                       [ 1.1721e-01,  3.3434e-02, -1.4350e-01, -1.6413e-01, -1.4629e-02],\n",
       "                       [-3.3599e-02, -1.1788e-01,  4.2745e-02,  3.7840e-02,  5.7515e-02],\n",
       "                       ...,\n",
       "                       [ 4.2689e-03,  5.0576e-02,  4.5614e-02, -2.5400e-03,  1.0311e-01],\n",
       "                       [-4.6757e-03,  1.2800e-01, -5.6342e-02,  1.1039e-01, -4.3900e-02],\n",
       "                       [ 1.3013e-02,  3.2805e-02, -2.8255e-02,  9.8206e-02,  4.0276e-02]],\n",
       "              \n",
       "                      [[ 3.4694e-02, -1.0677e-02,  5.0294e-02, -3.3899e-02, -4.5415e-02],\n",
       "                       [-1.7111e-02, -1.2753e-01, -4.6275e-02,  4.6827e-02, -4.5796e-02],\n",
       "                       [-9.6119e-02,  2.5448e-03, -1.5157e-02, -3.9769e-02, -5.2438e-02],\n",
       "                       ...,\n",
       "                       [-5.1422e-02,  6.8168e-02, -3.5461e-03, -5.2400e-02, -1.8855e-02],\n",
       "                       [-4.0516e-02,  2.9087e-02,  2.4410e-02,  8.6184e-02, -3.8822e-02],\n",
       "                       [-4.7646e-02, -1.5557e-02, -1.2592e-01, -7.2508e-02,  3.7539e-03]],\n",
       "              \n",
       "                      [[ 5.7398e-02, -8.8282e-03, -2.5414e-02, -4.0253e-02, -1.2181e-01],\n",
       "                       [-2.6151e-02,  1.7202e-02,  6.7190e-02, -8.9942e-02,  6.8232e-02],\n",
       "                       [-9.3214e-02,  2.7760e-03, -1.2508e-01, -5.3354e-02,  7.7526e-02],\n",
       "                       ...,\n",
       "                       [-2.8325e-02,  2.6915e-02, -1.0678e-01,  6.3290e-03, -6.3431e-02],\n",
       "                       [ 4.3636e-02,  4.1843e-03,  7.8167e-02, -1.2920e-01, -3.5783e-02],\n",
       "                       [ 8.8036e-02, -3.9806e-02, -5.0515e-02, -6.3694e-02, -1.1527e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.0272e-01, -6.3537e-02, -7.3089e-02,  9.1197e-02,  8.4952e-02],\n",
       "                       [ 1.6513e-02,  6.2077e-02, -1.1859e-02, -1.1128e-01, -1.1729e-01],\n",
       "                       [ 2.7044e-02,  4.0231e-02,  1.3083e-01,  5.9207e-02, -4.5925e-02],\n",
       "                       ...,\n",
       "                       [-1.5532e-02,  7.5583e-03, -4.4415e-02, -5.0363e-02, -8.7583e-02],\n",
       "                       [-4.4164e-02,  1.9960e-01, -6.2176e-03,  3.8471e-02,  1.0878e-01],\n",
       "                       [-5.8840e-02,  4.9365e-03, -5.0204e-02, -7.9948e-02,  2.7359e-02]],\n",
       "              \n",
       "                      [[-3.6332e-02,  5.3392e-02,  3.7117e-02,  1.1546e-02, -5.2246e-02],\n",
       "                       [ 1.9101e-01,  1.5129e-01,  2.9943e-03,  3.1230e-02, -4.3205e-02],\n",
       "                       [ 3.1995e-03,  1.4586e-01, -8.6100e-03, -2.8414e-02,  4.1754e-02],\n",
       "                       ...,\n",
       "                       [-1.8093e-01,  7.8644e-02,  1.3567e-01, -6.4919e-02, -1.0376e-01],\n",
       "                       [ 2.4963e-02,  4.6311e-02, -6.4594e-02, -1.2299e-01, -1.9182e-02],\n",
       "                       [ 5.3916e-02, -1.4304e-02,  1.3473e-02, -1.0688e-01, -6.1820e-02]],\n",
       "              \n",
       "                      [[ 3.8470e-02,  9.1451e-02,  1.3491e-01,  1.0883e-01,  1.4127e-02],\n",
       "                       [-7.3971e-02,  7.8095e-02,  1.6060e-02,  1.1769e-02, -2.1140e-03],\n",
       "                       [-9.0929e-02,  1.9203e-02, -2.6688e-02, -2.2390e-01,  3.8489e-03],\n",
       "                       ...,\n",
       "                       [-1.9679e-01, -4.6309e-02, -4.9521e-02, -4.8222e-02,  1.0800e-01],\n",
       "                       [ 6.9955e-04,  7.6519e-02, -6.4069e-02,  1.7861e-02,  1.0596e-01],\n",
       "                       [ 4.5725e-02, -7.9735e-02,  1.1775e-04, -3.5031e-02, -2.8898e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convs.1.1.weight',\n",
       "              tensor([0.9680, 0.9587, 0.9682, 0.9753, 0.9702, 0.9587, 0.9913, 0.9515, 0.9494,\n",
       "                      0.9544, 0.9475, 0.9881, 0.9767, 0.9523, 0.9459, 1.0162, 0.9399, 0.9699,\n",
       "                      0.9474, 0.9757, 0.9637, 0.9530, 0.9710, 0.9687, 0.9377, 0.9752, 0.9835,\n",
       "                      0.9622, 1.0168, 0.9539, 0.9566, 0.9384, 0.9664, 0.9498, 0.9305, 0.9308,\n",
       "                      0.9792, 0.9477, 0.9717, 0.9467, 0.9542, 0.9583, 0.9872, 0.9404, 0.9615,\n",
       "                      0.9669, 0.9855, 0.9583, 0.9749, 0.9724, 0.9795, 0.9752, 0.9532, 0.9597,\n",
       "                      0.9783, 0.9754, 0.9642, 0.9502, 0.9550, 0.9724, 0.9720, 1.0049, 0.9688,\n",
       "                      0.9859], dtype=torch.float64)),\n",
       "             ('6.6.convs.1.1.bias',\n",
       "              tensor([-0.0200,  0.0029,  0.0066, -0.0192, -0.0032, -0.0082,  0.0130, -0.0154,\n",
       "                      -0.0034, -0.0145, -0.0106,  0.0144,  0.0066,  0.0024, -0.0312,  0.0195,\n",
       "                      -0.0150,  0.0093,  0.0137, -0.0142, -0.0120, -0.0225,  0.0153,  0.0027,\n",
       "                      -0.0078,  0.0028,  0.0080,  0.0108,  0.0297, -0.0121,  0.0145, -0.0138,\n",
       "                      -0.0132, -0.0116, -0.0212, -0.0114, -0.0149, -0.0134, -0.0005, -0.0060,\n",
       "                      -0.0307,  0.0186,  0.0178, -0.0115,  0.0013, -0.0180,  0.0138,  0.0062,\n",
       "                       0.0083,  0.0159, -0.0168,  0.0167, -0.0120,  0.0249, -0.0004, -0.0107,\n",
       "                      -0.0067,  0.0013, -0.0002,  0.0105, -0.0129,  0.0251, -0.0005,  0.0140],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convs.1.1.running_mean',\n",
       "              tensor([ 0.0941, -0.7252, -0.4760,  0.2748, -0.1647, -0.4858, -0.8490, -0.1793,\n",
       "                      -0.0227, -0.2179, -0.1825, -0.5824,  0.0095, -0.1535,  0.3272,  0.1869,\n",
       "                       0.0271,  0.2549, -0.5281,  0.4292,  0.4128,  1.4082,  0.5958, -0.8053,\n",
       "                      -0.6850, -0.3657, -0.3949, -0.3225, -0.3130,  0.0400, -0.2220, -0.0674,\n",
       "                      -0.1557,  0.2255, -1.0208, -0.1347,  0.4071, -1.0269, -0.2208, -0.2801,\n",
       "                       0.3742, -0.6952, -0.8007, -0.6675, -0.8257,  0.4606, -0.6977, -0.9755,\n",
       "                      -0.3626,  0.1859,  0.1783,  0.6324,  0.3196, -0.4582,  0.1397,  0.8500,\n",
       "                       0.4893, -0.3193, -0.2917, -0.3238,  0.5035, -0.2844,  0.3407, -1.3248],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convs.1.1.running_var',\n",
       "              tensor([0.6036, 0.7538, 0.5866, 0.6633, 0.5593, 0.6855, 0.4369, 0.5545, 0.4075,\n",
       "                      0.7970, 1.0802, 0.5327, 0.5672, 0.5359, 0.5905, 0.5326, 0.4028, 0.6563,\n",
       "                      0.7827, 0.7444, 0.7562, 1.6093, 0.7848, 0.5746, 0.6527, 0.3406, 0.6831,\n",
       "                      0.4689, 0.5869, 0.9397, 0.6967, 0.8706, 0.7356, 1.5085, 0.8688, 0.9156,\n",
       "                      0.6068, 0.7849, 0.6778, 0.6203, 0.7855, 0.6776, 0.4891, 0.9342, 0.5915,\n",
       "                      0.5578, 0.3665, 0.9074, 0.5117, 0.4519, 0.5025, 0.7112, 0.7933, 0.9678,\n",
       "                      0.5106, 0.6453, 0.5198, 0.9181, 0.8019, 0.5727, 0.4667, 0.4739, 0.9411,\n",
       "                      1.4261], dtype=torch.float64)),\n",
       "             ('6.6.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.6.convs.2.0.weight',\n",
       "              tensor([[[-0.1595],\n",
       "                       [-0.0641],\n",
       "                       [ 0.0956],\n",
       "                       ...,\n",
       "                       [-0.0179],\n",
       "                       [-0.0835],\n",
       "                       [-0.0037]],\n",
       "              \n",
       "                      [[-0.0488],\n",
       "                       [-0.1028],\n",
       "                       [ 0.0146],\n",
       "                       ...,\n",
       "                       [-0.0451],\n",
       "                       [ 0.0322],\n",
       "                       [-0.1033]],\n",
       "              \n",
       "                      [[-0.0319],\n",
       "                       [ 0.0127],\n",
       "                       [-0.0140],\n",
       "                       ...,\n",
       "                       [-0.1225],\n",
       "                       [ 0.0479],\n",
       "                       [-0.0291]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1646],\n",
       "                       [-0.0141],\n",
       "                       [-0.1006],\n",
       "                       ...,\n",
       "                       [ 0.1497],\n",
       "                       [ 0.0020],\n",
       "                       [ 0.1797]],\n",
       "              \n",
       "                      [[-0.0715],\n",
       "                       [ 0.0449],\n",
       "                       [ 0.0487],\n",
       "                       ...,\n",
       "                       [ 0.1228],\n",
       "                       [-0.0075],\n",
       "                       [-0.0247]],\n",
       "              \n",
       "                      [[ 0.0327],\n",
       "                       [ 0.0197],\n",
       "                       [-0.0633],\n",
       "                       ...,\n",
       "                       [ 0.1074],\n",
       "                       [-0.0077],\n",
       "                       [-0.0439]]], dtype=torch.float64)),\n",
       "             ('6.6.convs.2.1.weight',\n",
       "              tensor([ 1.0150e-02, -6.9185e-03,  1.3713e-02, -1.0232e-02,  8.5891e-03,\n",
       "                       8.5662e-04,  9.6463e-04,  2.7952e-02, -2.0439e-02, -3.2038e-02,\n",
       "                      -1.0341e-02, -2.8828e-02, -2.2906e-03,  6.5147e-03, -8.0612e-03,\n",
       "                       3.3665e-02, -1.1520e-02, -1.2285e-02, -2.7464e-03, -3.0818e-02,\n",
       "                       1.5915e-02, -2.1413e-02,  9.2876e-03, -5.6457e-03, -2.5190e-02,\n",
       "                      -8.6980e-04, -2.2414e-02,  1.5891e-02,  1.0181e-02,  4.0825e-03,\n",
       "                      -4.9613e-03,  1.1755e-02,  9.6195e-03, -3.5012e-03,  5.8914e-04,\n",
       "                       1.1283e-02,  5.2637e-03,  8.8263e-03,  2.2464e-02, -1.7061e-03,\n",
       "                       2.9880e-03,  2.7630e-03, -1.4922e-02, -7.2432e-04,  1.6037e-03,\n",
       "                       5.6718e-03, -4.7779e-03,  1.6763e-02, -8.7895e-03,  3.4771e-02,\n",
       "                      -8.6616e-03,  9.0280e-03,  9.4141e-03, -1.2205e-02, -1.8254e-02,\n",
       "                       3.6123e-02,  1.7818e-03, -3.3514e-02,  1.9809e-02, -1.1498e-02,\n",
       "                       8.8276e-03, -1.6572e-02,  1.7389e-03, -1.5630e-02, -2.8822e-02,\n",
       "                       2.2343e-02,  9.8016e-04,  2.2395e-02, -2.5321e-02,  3.7378e-02,\n",
       "                      -3.1880e-02,  7.3242e-03,  8.9524e-03, -1.1022e-03, -7.9567e-03,\n",
       "                      -8.1209e-03,  7.4155e-03,  1.6137e-02,  8.0900e-03, -1.1796e-02,\n",
       "                      -2.4412e-02, -8.7004e-03,  7.8374e-03,  8.5154e-03,  3.3320e-02,\n",
       "                       1.3653e-03,  1.2235e-02,  1.1917e-02, -1.4693e-02,  2.4134e-02,\n",
       "                      -2.6067e-03, -1.4748e-02, -3.9695e-02, -6.8339e-03,  6.2063e-03,\n",
       "                      -8.9520e-03,  2.3766e-02, -4.2868e-03, -2.2400e-02,  1.4393e-02,\n",
       "                      -1.2527e-03,  1.2413e-02,  2.4075e-02, -2.0689e-02, -1.4978e-02,\n",
       "                       1.4390e-02,  1.8197e-02, -5.8271e-03,  2.8548e-02, -8.4787e-04,\n",
       "                       9.0904e-03,  1.6414e-02, -2.4509e-03, -3.3220e-02, -2.8567e-02,\n",
       "                       2.0956e-02, -5.7126e-03,  1.2938e-02, -6.8211e-04, -3.5662e-03,\n",
       "                       2.7866e-02,  1.7067e-02, -2.7390e-04,  1.6938e-02, -1.1377e-02,\n",
       "                      -9.3527e-03, -3.1341e-02, -1.3731e-03, -9.3574e-03,  1.1817e-02,\n",
       "                       1.2659e-02,  3.7606e-02, -1.3645e-03, -1.9714e-02, -1.1301e-02,\n",
       "                      -3.3656e-03,  1.2442e-03,  2.0660e-02,  4.1279e-03,  5.7126e-03,\n",
       "                       6.4018e-03, -6.6275e-03,  9.6259e-03, -2.4736e-02,  6.8314e-03,\n",
       "                      -8.6778e-03,  8.6942e-03, -9.4880e-03, -1.9828e-02,  3.7420e-03,\n",
       "                      -4.4454e-03,  1.6157e-02,  3.2540e-03,  1.0921e-02,  1.1020e-02,\n",
       "                       1.3300e-02, -1.1635e-02, -3.0415e-02,  1.2797e-02, -2.3762e-04,\n",
       "                      -2.1016e-02, -5.7868e-03,  3.4032e-03,  1.8778e-02,  2.3184e-02,\n",
       "                       1.7988e-02,  1.8516e-03,  1.7287e-02,  8.5864e-03,  3.8996e-02,\n",
       "                      -9.1970e-03, -1.2124e-02,  1.0203e-02,  2.2397e-03,  1.3022e-02,\n",
       "                      -1.0346e-02, -1.0479e-02,  5.5608e-05,  1.5299e-02,  1.1594e-02,\n",
       "                       1.1107e-02,  1.0029e-02, -1.5271e-02,  1.2404e-03, -3.0976e-03,\n",
       "                      -1.7444e-02, -4.4170e-03, -1.4255e-02,  6.4446e-03,  1.7522e-02,\n",
       "                      -1.6760e-02, -1.3052e-02,  2.0311e-02, -1.4137e-02, -1.4519e-02,\n",
       "                       7.5137e-03, -8.7557e-03,  2.2173e-02,  2.5515e-02, -1.2209e-02,\n",
       "                      -6.2720e-03,  2.4393e-02,  1.8483e-03, -1.5753e-02,  3.3581e-03,\n",
       "                       4.6281e-03,  4.5554e-02, -2.5611e-02,  9.6270e-04, -2.1001e-02,\n",
       "                      -5.6559e-03,  4.5710e-03,  1.1246e-03, -3.6671e-02,  6.7719e-03,\n",
       "                      -1.8243e-02, -5.3325e-03, -5.1157e-03,  2.0348e-02, -1.6542e-02,\n",
       "                       4.7618e-03,  1.1616e-02,  4.1344e-03,  1.6350e-02,  1.5259e-02,\n",
       "                       9.5261e-03,  9.6563e-03,  1.9315e-02, -5.9309e-04, -3.2346e-02,\n",
       "                       1.3660e-03,  9.9181e-03, -6.4819e-03,  2.3366e-02, -8.9760e-03,\n",
       "                      -7.7267e-03,  1.2651e-02,  1.1246e-02, -1.8028e-02, -8.1925e-03,\n",
       "                      -1.1697e-02,  1.0043e-02,  9.9266e-04,  5.6365e-03, -1.3458e-02,\n",
       "                       8.5161e-03, -8.8420e-03, -1.8407e-02,  4.4380e-03, -2.8718e-02,\n",
       "                      -1.1123e-02, -1.9702e-02, -2.6554e-03, -2.2865e-02, -2.9003e-03,\n",
       "                       5.3596e-05], dtype=torch.float64)),\n",
       "             ('6.6.convs.2.1.bias',\n",
       "              tensor([-8.3792e-04,  3.4520e-03,  1.3210e-02,  1.5723e-02,  8.9322e-04,\n",
       "                       4.7988e-03,  1.1738e-02,  1.7120e-03,  2.2046e-03,  2.2611e-02,\n",
       "                       1.4390e-02, -7.9868e-03,  8.1139e-03, -4.6840e-03,  1.1887e-02,\n",
       "                       4.0100e-03,  2.1283e-02, -2.5542e-03,  1.3014e-02, -7.5277e-03,\n",
       "                      -2.8608e-03,  3.0322e-03,  7.0995e-04,  6.4781e-03, -7.5706e-03,\n",
       "                      -1.5647e-02,  3.4617e-03,  8.4863e-03,  5.8509e-04, -2.2938e-03,\n",
       "                       3.9236e-03,  8.7355e-03, -9.6032e-03,  1.8149e-02,  1.2896e-02,\n",
       "                       1.4812e-02, -3.0728e-03,  1.9824e-02,  6.2865e-03,  1.5273e-02,\n",
       "                      -1.2278e-03,  2.3988e-02, -2.9701e-03,  1.8631e-03,  3.4217e-03,\n",
       "                      -9.0559e-03,  1.1670e-02,  5.8815e-03, -1.1538e-02,  1.3021e-02,\n",
       "                       8.1819e-03,  9.5104e-03,  9.6971e-03,  1.1133e-02,  4.3198e-03,\n",
       "                       1.6471e-02,  7.3368e-03,  3.1255e-03,  6.2823e-03,  2.9483e-03,\n",
       "                      -1.7716e-03,  2.8475e-03,  4.9976e-03,  8.9434e-03, -4.0464e-03,\n",
       "                       1.0568e-02, -1.2458e-02,  1.6330e-02, -4.7043e-03, -1.1872e-02,\n",
       "                       2.5532e-03,  5.8576e-03,  1.6502e-03, -7.1843e-03,  1.4609e-02,\n",
       "                      -1.0920e-03,  3.3231e-03,  1.3520e-03,  5.0737e-03,  1.7698e-03,\n",
       "                       1.0323e-02, -5.8991e-03,  8.2852e-03,  4.0855e-03, -4.8411e-03,\n",
       "                       1.2181e-02, -5.5207e-04,  6.4295e-04,  1.3395e-02,  6.5983e-03,\n",
       "                      -8.4500e-04,  1.4904e-02,  1.4938e-02, -3.0558e-03,  9.2375e-03,\n",
       "                      -1.1740e-02,  6.1342e-03,  2.4766e-03,  1.1535e-02, -2.3214e-03,\n",
       "                       1.9170e-02,  1.4898e-03,  5.9829e-03, -4.9193e-04,  1.1518e-02,\n",
       "                       5.8428e-04,  1.3346e-03,  3.2009e-03,  4.6381e-03,  8.4240e-03,\n",
       "                      -7.3728e-03, -7.3230e-03,  5.0754e-03,  2.0944e-02,  1.1596e-02,\n",
       "                       6.6018e-03,  9.5287e-03,  2.8527e-05,  3.4567e-03, -1.4839e-02,\n",
       "                      -1.6093e-05,  8.0401e-03, -1.8009e-03, -2.7852e-03, -1.1983e-02,\n",
       "                       1.0376e-02,  1.4491e-02,  5.2070e-03,  2.4162e-03,  1.6354e-02,\n",
       "                       2.3329e-02,  1.5196e-02,  1.4868e-02,  6.6737e-03,  1.5523e-02,\n",
       "                      -6.6983e-03,  1.5797e-02,  9.1371e-03,  1.0598e-02,  8.8044e-03,\n",
       "                       1.4434e-02, -3.7489e-03,  1.6393e-02,  6.3892e-03, -7.3140e-03,\n",
       "                       1.3741e-02,  3.0642e-03, -1.2913e-03,  8.9991e-03,  9.0917e-03,\n",
       "                       6.3211e-03,  1.3197e-02,  1.3214e-02,  1.3775e-02,  1.5297e-02,\n",
       "                       9.1409e-03,  1.2826e-03,  7.1325e-03, -1.7783e-03, -1.0423e-02,\n",
       "                       4.9193e-03, -4.8071e-03,  6.3248e-04,  1.1793e-02,  1.0697e-02,\n",
       "                       1.2110e-04, -8.8667e-03,  1.1457e-02,  9.8033e-04,  1.6094e-02,\n",
       "                       6.3129e-03,  7.3345e-03,  1.1404e-02,  1.0406e-02, -1.3451e-02,\n",
       "                       2.7757e-03, -6.2231e-04,  1.2838e-02,  3.7241e-03,  4.1717e-03,\n",
       "                      -3.1890e-03,  1.1061e-02, -8.1519e-03, -9.0768e-03,  1.9833e-02,\n",
       "                       7.4087e-03,  1.3363e-02,  1.0722e-02,  2.6543e-03,  2.6333e-03,\n",
       "                       6.1325e-03,  2.3526e-03,  9.8704e-03, -8.1245e-03,  2.4701e-03,\n",
       "                       6.2251e-03, -5.2993e-03,  1.9476e-02,  8.3589e-03,  5.9339e-03,\n",
       "                       3.2769e-03,  2.1492e-02,  1.9525e-02,  1.6423e-02,  4.3670e-04,\n",
       "                      -1.3728e-03,  1.6720e-02, -4.0052e-03,  8.9128e-03,  1.1261e-02,\n",
       "                      -1.2157e-03,  1.1640e-02,  1.4352e-02,  8.0657e-03,  1.5759e-02,\n",
       "                       4.1711e-04,  4.2417e-03, -5.3075e-03,  2.3169e-03, -3.7946e-04,\n",
       "                      -1.4252e-02,  3.1344e-03,  5.3142e-03,  1.8019e-02, -4.9953e-03,\n",
       "                       4.4637e-03, -3.0559e-03,  1.8502e-03, -1.4347e-02,  1.4490e-02,\n",
       "                       8.4647e-03, -1.7278e-03,  1.1873e-02,  6.4378e-03,  2.3101e-03,\n",
       "                       6.9338e-03,  7.6796e-03, -8.8597e-03,  9.5387e-03,  8.5499e-03,\n",
       "                       1.8392e-03,  3.9479e-03,  5.1607e-03,  8.0653e-03, -2.6380e-04,\n",
       "                       1.4907e-02,  1.1049e-04,  9.7957e-03,  3.1189e-03, -8.3708e-03,\n",
       "                       1.7591e-02,  1.8614e-02,  1.5490e-02,  1.6420e-02,  9.7842e-03,\n",
       "                       5.4413e-03], dtype=torch.float64)),\n",
       "             ('6.6.convs.2.1.running_mean',\n",
       "              tensor([ 0.0484, -0.1926,  0.1816,  0.3316, -0.2590,  0.1854, -0.2528, -0.6604,\n",
       "                      -0.2257,  0.1922,  0.4257, -0.4847,  0.0887,  0.0806, -0.1255, -0.1654,\n",
       "                       0.2206,  0.0214, -0.0264,  0.3489, -0.4619,  0.4529,  0.4506,  0.1608,\n",
       "                       0.7995,  0.1404,  0.0711,  0.1421,  0.1377,  0.5238, -0.1551,  0.0569,\n",
       "                      -0.1907,  0.4104,  0.1761,  0.7142, -0.2240, -0.2415,  0.1952, -0.2565,\n",
       "                      -0.3931, -0.2128,  0.1391,  0.0065,  0.3877, -0.6508, -0.1919,  0.0340,\n",
       "                       0.5002, -0.0274,  0.0931,  0.0895,  0.5043,  0.4762, -0.6238,  0.2767,\n",
       "                      -0.1511, -0.2778,  0.3921,  0.2665, -0.0646,  0.2660,  0.5649, -0.2741,\n",
       "                       0.6009,  0.1316, -0.1592,  0.2648, -0.3628,  0.1258,  0.2464,  0.0032,\n",
       "                       0.6792, -0.5942, -0.1350, -0.3891,  0.4269, -0.2334,  0.2270,  0.1406,\n",
       "                      -0.5591, -0.6412, -0.2204, -0.5344,  0.1413,  0.2465,  0.1378, -0.2565,\n",
       "                      -0.4705, -0.0973,  0.1844, -0.3962, -0.3606, -0.7851,  0.0963, -0.1701,\n",
       "                      -0.5814,  0.1935, -0.8287, -0.0381, -0.1375,  0.2189, -0.4572,  0.6118,\n",
       "                      -0.1344,  0.0932, -0.0333,  0.1850, -0.2961, -0.0506, -0.4222,  0.3416,\n",
       "                       0.1064, -0.0942, -0.1910, -0.5448, -0.1406, -0.2246, -0.4124, -0.1428,\n",
       "                      -0.2938,  0.1961,  0.1663,  0.2322,  0.2626, -0.2882,  0.1910,  0.1147,\n",
       "                       0.5079, -0.3926,  0.4819,  0.4328, -0.2235,  0.0330,  0.0825,  0.2507,\n",
       "                      -0.2024, -0.2794, -0.3877,  0.0224,  0.0988,  0.2233,  0.0967,  0.3191,\n",
       "                      -0.0405,  0.1969,  0.0536, -0.7023,  0.0902,  0.1065, -0.5438, -0.5041,\n",
       "                      -0.4060, -0.6975,  0.3338,  0.1671, -0.3657, -0.0663,  0.4046, -0.2703,\n",
       "                      -0.2009, -0.1549,  0.0495,  0.0402, -0.0366,  0.5080,  0.9068, -0.2483,\n",
       "                       0.1388, -0.1797, -0.2635, -0.4339, -0.0016, -0.0620,  0.4554, -0.3511,\n",
       "                       0.6290, -0.0385, -0.3367, -0.2932,  0.6035,  0.6757, -1.0276, -0.2959,\n",
       "                       0.0119,  0.6055,  0.2138,  0.4180, -0.0505,  0.0391,  0.4353,  0.3378,\n",
       "                       0.0899, -0.4953,  0.1470,  0.0720, -0.1669, -0.0405, -0.3347,  0.1149,\n",
       "                       0.5975,  0.2934, -0.1084, -0.5374, -0.4014,  0.1703,  0.2183, -0.1230,\n",
       "                      -0.3695,  0.4564,  0.2788, -0.1397,  0.0234, -0.0727,  0.7962, -0.1117,\n",
       "                       0.4427,  0.0702, -0.8673,  0.3666, -0.2168, -0.3573,  0.3964, -0.3970,\n",
       "                      -0.0211,  0.0339, -0.5008, -0.0428, -0.1548, -0.1057, -0.0539,  0.1592,\n",
       "                       0.7628,  0.3081, -0.1074, -0.1172,  0.3006,  0.4610,  0.1876,  0.3178,\n",
       "                      -0.2453,  0.0965, -0.1813, -0.2003, -0.2240, -0.3855, -0.0112, -0.1242,\n",
       "                      -0.2394,  0.3448, -0.0450,  0.6814, -0.0061,  0.0442, -0.0092,  0.1831],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convs.2.1.running_var',\n",
       "              tensor([0.5060, 0.2928, 0.2521, 0.4997, 0.1346, 0.1000, 0.1168, 0.2703, 0.5808,\n",
       "                      0.3028, 0.2458, 0.3926, 0.1400, 0.2547, 0.4106, 0.3270, 0.3710, 0.7666,\n",
       "                      0.1764, 0.4358, 0.4899, 0.3624, 0.3437, 0.2658, 0.4583, 0.1680, 0.3590,\n",
       "                      0.2896, 0.2077, 0.1671, 0.4181, 0.5252, 0.1416, 0.2487, 0.2686, 0.4966,\n",
       "                      0.2268, 0.1677, 0.2946, 0.3562, 0.3239, 0.1804, 0.2591, 0.3475, 0.3891,\n",
       "                      0.4138, 0.4242, 0.1954, 0.8952, 0.4279, 0.1313, 0.6890, 0.4056, 0.2695,\n",
       "                      0.5453, 0.3662, 0.2550, 0.5828, 0.2958, 0.2703, 0.0883, 0.1876, 0.1781,\n",
       "                      0.4064, 0.6415, 0.6943, 0.2571, 0.3134, 0.4579, 0.6150, 0.4098, 0.6087,\n",
       "                      0.2605, 0.5889, 0.2772, 0.2720, 0.5186, 0.3161, 0.5636, 0.1956, 0.3959,\n",
       "                      0.2378, 0.2326, 0.3771, 0.4046, 0.3989, 0.2930, 0.2763, 0.3002, 0.2368,\n",
       "                      0.2471, 0.2825, 0.4424, 0.3397, 0.0973, 0.2647, 0.4230, 0.1425, 0.2961,\n",
       "                      0.5732, 0.2965, 0.3911, 0.4025, 0.5569, 0.3308, 0.2962, 0.4059, 0.2956,\n",
       "                      0.2929, 0.1580, 0.2754, 0.5503, 0.2243, 0.2799, 0.3702, 0.5863, 0.2564,\n",
       "                      0.3825, 0.2024, 0.5363, 0.2963, 0.3553, 0.1630, 0.4539, 0.2036, 0.7385,\n",
       "                      0.1736, 0.0701, 0.3150, 0.3583, 0.2097, 0.3979, 0.3020, 0.7779, 0.2743,\n",
       "                      0.1458, 0.0742, 0.1964, 0.1535, 0.1818, 0.1685, 0.0873, 0.3572, 0.5351,\n",
       "                      0.2114, 0.4553, 0.1298, 0.7119, 0.2393, 0.3721, 0.4882, 0.3819, 0.1922,\n",
       "                      0.5164, 0.4325, 0.2892, 0.2629, 0.2532, 0.3939, 0.2186, 0.5735, 0.2830,\n",
       "                      0.2749, 0.3364, 0.5277, 0.4928, 0.4210, 0.3123, 0.3560, 0.3859, 0.2993,\n",
       "                      0.1585, 0.4988, 0.2331, 0.4092, 0.4772, 0.2176, 0.2631, 0.5189, 0.2200,\n",
       "                      0.4529, 0.3984, 0.4933, 0.1653, 0.3275, 0.4449, 0.2048, 0.2948, 0.2100,\n",
       "                      0.4726, 0.3029, 0.3962, 0.2390, 0.4861, 0.3897, 0.2782, 0.2649, 0.3535,\n",
       "                      0.2940, 0.2564, 0.2433, 0.3392, 0.1744, 0.4631, 0.2398, 0.3812, 0.2768,\n",
       "                      0.2944, 0.1773, 0.5339, 0.0971, 0.4645, 0.2403, 0.2807, 0.4763, 0.1225,\n",
       "                      0.4769, 0.2908, 0.4497, 0.5328, 0.1445, 0.3494, 0.1842, 0.3403, 0.3770,\n",
       "                      0.2697, 0.2160, 0.3205, 0.3376, 0.4268, 0.2101, 0.3005, 0.4034, 0.5217,\n",
       "                      0.2343, 0.3558, 0.2110, 0.1964, 0.5977, 0.5221, 0.6663, 0.2049, 0.4839,\n",
       "                      0.0876, 0.9857, 0.2702, 0.1396, 0.3188, 0.1138, 0.5938, 0.4612, 0.5259,\n",
       "                      0.1380, 0.3365, 0.2664, 0.0693], dtype=torch.float64)),\n",
       "             ('6.6.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.6.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.0720],\n",
       "                       [-0.0094],\n",
       "                       [-0.1010],\n",
       "                       ...,\n",
       "                       [ 0.1000],\n",
       "                       [ 0.0120],\n",
       "                       [-0.0529]],\n",
       "              \n",
       "                      [[ 0.1434],\n",
       "                       [-0.0673],\n",
       "                       [ 0.0486],\n",
       "                       ...,\n",
       "                       [-0.1109],\n",
       "                       [-0.1072],\n",
       "                       [ 0.1523]],\n",
       "              \n",
       "                      [[-0.0274],\n",
       "                       [ 0.1305],\n",
       "                       [ 0.0422],\n",
       "                       ...,\n",
       "                       [-0.0935],\n",
       "                       [-0.0277],\n",
       "                       [ 0.0125]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1152],\n",
       "                       [-0.0443],\n",
       "                       [-0.0328],\n",
       "                       ...,\n",
       "                       [-0.0579],\n",
       "                       [-0.0156],\n",
       "                       [ 0.1178]],\n",
       "              \n",
       "                      [[-0.0496],\n",
       "                       [-0.0590],\n",
       "                       [ 0.0376],\n",
       "                       ...,\n",
       "                       [ 0.0064],\n",
       "                       [ 0.1038],\n",
       "                       [ 0.0570]],\n",
       "              \n",
       "                      [[-0.1157],\n",
       "                       [-0.0080],\n",
       "                       [-0.0244],\n",
       "                       ...,\n",
       "                       [-0.0049],\n",
       "                       [ 0.0876],\n",
       "                       [-0.0689]]], dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.0.1.weight',\n",
       "              tensor([0.9826, 0.9772, 0.9700, 0.9727, 0.9657, 0.9871, 0.9391, 0.9691, 0.9602,\n",
       "                      0.9748, 0.9704, 0.9805, 0.9726, 0.9909, 0.9539, 0.9664, 0.9866, 0.9800,\n",
       "                      0.9819, 0.9663, 0.9648, 0.9647, 0.9416, 0.9658, 0.9527, 0.9633, 0.9816,\n",
       "                      0.9760, 0.9636, 0.9700, 0.9716, 0.9836, 0.9796, 0.9682, 0.9812, 0.9931,\n",
       "                      0.9679, 0.9763, 0.9484, 0.9725, 0.9796, 0.9580, 0.9717, 0.9802, 0.9836,\n",
       "                      0.9641, 0.9605, 0.9794, 0.9662, 0.9130, 0.9730, 0.9883, 0.9619, 0.9754,\n",
       "                      0.9722, 0.9628, 0.9688, 0.9820, 0.9741, 0.9555, 1.0019, 0.9815, 0.9846,\n",
       "                      0.9716], dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.0.1.bias',\n",
       "              tensor([ 7.9298e-03, -1.6504e-02, -3.5259e-03,  8.8641e-03,  1.7394e-02,\n",
       "                       1.4577e-02,  1.8607e-02,  2.6071e-02, -5.6859e-03,  9.7278e-04,\n",
       "                      -6.0344e-05,  1.3699e-02, -3.1433e-04,  1.9214e-03, -9.2234e-03,\n",
       "                       2.1870e-02,  1.6561e-03, -1.0894e-03, -5.4873e-03,  5.9783e-03,\n",
       "                      -1.8316e-03, -1.3388e-02, -1.1787e-02, -1.6116e-02,  1.4448e-02,\n",
       "                       1.8852e-02,  4.0475e-03,  1.3361e-02, -7.5687e-05, -1.4079e-02,\n",
       "                       9.5640e-03,  3.3048e-04, -5.6489e-03,  6.7681e-03, -4.4522e-03,\n",
       "                       1.4801e-02,  5.8675e-03,  8.8917e-03, -7.7835e-03,  7.5822e-03,\n",
       "                       1.1792e-02,  9.3591e-03,  5.2178e-03, -5.7296e-03, -2.4171e-03,\n",
       "                      -6.0555e-03,  5.0466e-03,  1.2532e-02, -1.7809e-02, -1.4765e-02,\n",
       "                      -8.9848e-03,  2.1055e-02, -1.7801e-02,  1.3745e-02,  1.5941e-02,\n",
       "                      -5.0243e-03, -1.1437e-02,  8.0832e-03,  1.8227e-03, -5.4222e-04,\n",
       "                       1.0704e-03, -3.4518e-03,  4.0056e-03, -6.6958e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.0.1.running_mean',\n",
       "              tensor([-5.6386e-01,  1.8281e-01,  7.2954e-01, -3.3039e-02, -2.1434e-01,\n",
       "                      -1.2662e-01, -2.0595e-01,  8.2226e-01,  5.4904e-01,  6.2270e-01,\n",
       "                      -1.0588e-01, -2.1881e-01,  6.6683e-01, -1.2798e+00, -1.1339e+00,\n",
       "                      -3.1620e-01,  5.2261e-01,  6.9635e-01,  3.8158e-01, -2.8051e-01,\n",
       "                       8.0299e-01,  2.6366e-02, -3.3314e-01, -3.3491e-01, -4.9945e-01,\n",
       "                      -6.3491e-01,  1.1841e-01,  2.2493e-01, -1.9744e-01, -1.4084e-03,\n",
       "                       3.7567e-01,  4.7048e-01, -1.5414e-01,  3.9710e-01,  5.0011e-01,\n",
       "                       3.0139e-01, -6.0198e-01, -6.1613e-01, -1.2172e-01,  2.9172e-01,\n",
       "                       1.0950e-01, -2.6238e-01,  1.6658e-02, -7.5101e-02, -2.1099e-01,\n",
       "                      -2.7900e-01, -2.6838e-01, -5.8714e-01, -6.6472e-02, -8.8720e-01,\n",
       "                       4.6803e-01, -7.0157e-01,  1.1955e+00, -4.4172e-01,  5.7278e-01,\n",
       "                      -5.2594e-01,  2.3816e-01,  7.0732e-01, -5.6742e-01,  1.1930e+00,\n",
       "                      -2.5621e-01,  1.0853e+00,  5.9320e-04,  2.5558e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.0.1.running_var',\n",
       "              tensor([0.1344, 0.1037, 0.5204, 0.1305, 0.2575, 0.1384, 0.5168, 0.2509, 0.3951,\n",
       "                      0.4697, 0.3493, 0.1233, 0.6185, 0.1642, 0.1972, 0.2624, 0.3477, 0.1635,\n",
       "                      0.1538, 0.0900, 0.1854, 0.2579, 0.6624, 0.1611, 0.1252, 0.8599, 0.1259,\n",
       "                      0.1824, 0.1261, 0.1542, 0.8356, 0.5019, 0.1304, 0.6070, 0.1847, 0.1582,\n",
       "                      0.3802, 0.1243, 0.5342, 0.2432, 0.1892, 0.2450, 0.1238, 0.1986, 0.2761,\n",
       "                      0.5502, 0.3316, 0.2970, 0.1454, 0.9366, 0.1110, 0.0889, 1.0770, 0.2308,\n",
       "                      0.4746, 0.4266, 0.0977, 0.3190, 0.1882, 0.8624, 0.1912, 0.7865, 0.1631,\n",
       "                      0.2162], dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.6.convpath.0.1.0.weight',\n",
       "              tensor([[[-3.0066e-02, -5.6900e-02,  1.3447e-02,  6.1007e-02, -2.6408e-02],\n",
       "                       [ 1.1721e-01,  3.3434e-02, -1.4350e-01, -1.6413e-01, -1.4629e-02],\n",
       "                       [-3.3599e-02, -1.1788e-01,  4.2745e-02,  3.7840e-02,  5.7515e-02],\n",
       "                       ...,\n",
       "                       [ 4.2689e-03,  5.0576e-02,  4.5614e-02, -2.5400e-03,  1.0311e-01],\n",
       "                       [-4.6757e-03,  1.2800e-01, -5.6342e-02,  1.1039e-01, -4.3900e-02],\n",
       "                       [ 1.3013e-02,  3.2805e-02, -2.8255e-02,  9.8206e-02,  4.0276e-02]],\n",
       "              \n",
       "                      [[ 3.4694e-02, -1.0677e-02,  5.0294e-02, -3.3899e-02, -4.5415e-02],\n",
       "                       [-1.7111e-02, -1.2753e-01, -4.6275e-02,  4.6827e-02, -4.5796e-02],\n",
       "                       [-9.6119e-02,  2.5448e-03, -1.5157e-02, -3.9769e-02, -5.2438e-02],\n",
       "                       ...,\n",
       "                       [-5.1422e-02,  6.8168e-02, -3.5461e-03, -5.2400e-02, -1.8855e-02],\n",
       "                       [-4.0516e-02,  2.9087e-02,  2.4410e-02,  8.6184e-02, -3.8822e-02],\n",
       "                       [-4.7646e-02, -1.5557e-02, -1.2592e-01, -7.2508e-02,  3.7539e-03]],\n",
       "              \n",
       "                      [[ 5.7398e-02, -8.8282e-03, -2.5414e-02, -4.0253e-02, -1.2181e-01],\n",
       "                       [-2.6151e-02,  1.7202e-02,  6.7190e-02, -8.9942e-02,  6.8232e-02],\n",
       "                       [-9.3214e-02,  2.7760e-03, -1.2508e-01, -5.3354e-02,  7.7526e-02],\n",
       "                       ...,\n",
       "                       [-2.8325e-02,  2.6915e-02, -1.0678e-01,  6.3290e-03, -6.3431e-02],\n",
       "                       [ 4.3636e-02,  4.1843e-03,  7.8167e-02, -1.2920e-01, -3.5783e-02],\n",
       "                       [ 8.8036e-02, -3.9806e-02, -5.0515e-02, -6.3694e-02, -1.1527e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.0272e-01, -6.3537e-02, -7.3089e-02,  9.1197e-02,  8.4952e-02],\n",
       "                       [ 1.6513e-02,  6.2077e-02, -1.1859e-02, -1.1128e-01, -1.1729e-01],\n",
       "                       [ 2.7044e-02,  4.0231e-02,  1.3083e-01,  5.9207e-02, -4.5925e-02],\n",
       "                       ...,\n",
       "                       [-1.5532e-02,  7.5583e-03, -4.4415e-02, -5.0363e-02, -8.7583e-02],\n",
       "                       [-4.4164e-02,  1.9960e-01, -6.2176e-03,  3.8471e-02,  1.0878e-01],\n",
       "                       [-5.8840e-02,  4.9365e-03, -5.0204e-02, -7.9948e-02,  2.7359e-02]],\n",
       "              \n",
       "                      [[-3.6332e-02,  5.3392e-02,  3.7117e-02,  1.1546e-02, -5.2246e-02],\n",
       "                       [ 1.9101e-01,  1.5129e-01,  2.9943e-03,  3.1230e-02, -4.3205e-02],\n",
       "                       [ 3.1995e-03,  1.4586e-01, -8.6100e-03, -2.8414e-02,  4.1754e-02],\n",
       "                       ...,\n",
       "                       [-1.8093e-01,  7.8644e-02,  1.3567e-01, -6.4919e-02, -1.0376e-01],\n",
       "                       [ 2.4963e-02,  4.6311e-02, -6.4594e-02, -1.2299e-01, -1.9182e-02],\n",
       "                       [ 5.3916e-02, -1.4304e-02,  1.3473e-02, -1.0688e-01, -6.1820e-02]],\n",
       "              \n",
       "                      [[ 3.8470e-02,  9.1451e-02,  1.3491e-01,  1.0883e-01,  1.4127e-02],\n",
       "                       [-7.3971e-02,  7.8095e-02,  1.6060e-02,  1.1769e-02, -2.1140e-03],\n",
       "                       [-9.0929e-02,  1.9203e-02, -2.6688e-02, -2.2390e-01,  3.8489e-03],\n",
       "                       ...,\n",
       "                       [-1.9679e-01, -4.6309e-02, -4.9521e-02, -4.8222e-02,  1.0800e-01],\n",
       "                       [ 6.9955e-04,  7.6519e-02, -6.4069e-02,  1.7861e-02,  1.0596e-01],\n",
       "                       [ 4.5725e-02, -7.9735e-02,  1.1775e-04, -3.5031e-02, -2.8898e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.1.1.weight',\n",
       "              tensor([0.9680, 0.9587, 0.9682, 0.9753, 0.9702, 0.9587, 0.9913, 0.9515, 0.9494,\n",
       "                      0.9544, 0.9475, 0.9881, 0.9767, 0.9523, 0.9459, 1.0162, 0.9399, 0.9699,\n",
       "                      0.9474, 0.9757, 0.9637, 0.9530, 0.9710, 0.9687, 0.9377, 0.9752, 0.9835,\n",
       "                      0.9622, 1.0168, 0.9539, 0.9566, 0.9384, 0.9664, 0.9498, 0.9305, 0.9308,\n",
       "                      0.9792, 0.9477, 0.9717, 0.9467, 0.9542, 0.9583, 0.9872, 0.9404, 0.9615,\n",
       "                      0.9669, 0.9855, 0.9583, 0.9749, 0.9724, 0.9795, 0.9752, 0.9532, 0.9597,\n",
       "                      0.9783, 0.9754, 0.9642, 0.9502, 0.9550, 0.9724, 0.9720, 1.0049, 0.9688,\n",
       "                      0.9859], dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.1.1.bias',\n",
       "              tensor([-0.0200,  0.0029,  0.0066, -0.0192, -0.0032, -0.0082,  0.0130, -0.0154,\n",
       "                      -0.0034, -0.0145, -0.0106,  0.0144,  0.0066,  0.0024, -0.0312,  0.0195,\n",
       "                      -0.0150,  0.0093,  0.0137, -0.0142, -0.0120, -0.0225,  0.0153,  0.0027,\n",
       "                      -0.0078,  0.0028,  0.0080,  0.0108,  0.0297, -0.0121,  0.0145, -0.0138,\n",
       "                      -0.0132, -0.0116, -0.0212, -0.0114, -0.0149, -0.0134, -0.0005, -0.0060,\n",
       "                      -0.0307,  0.0186,  0.0178, -0.0115,  0.0013, -0.0180,  0.0138,  0.0062,\n",
       "                       0.0083,  0.0159, -0.0168,  0.0167, -0.0120,  0.0249, -0.0004, -0.0107,\n",
       "                      -0.0067,  0.0013, -0.0002,  0.0105, -0.0129,  0.0251, -0.0005,  0.0140],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.0941, -0.7252, -0.4760,  0.2748, -0.1647, -0.4858, -0.8490, -0.1793,\n",
       "                      -0.0227, -0.2179, -0.1825, -0.5824,  0.0095, -0.1535,  0.3272,  0.1869,\n",
       "                       0.0271,  0.2549, -0.5281,  0.4292,  0.4128,  1.4082,  0.5958, -0.8053,\n",
       "                      -0.6850, -0.3657, -0.3949, -0.3225, -0.3130,  0.0400, -0.2220, -0.0674,\n",
       "                      -0.1557,  0.2255, -1.0208, -0.1347,  0.4071, -1.0269, -0.2208, -0.2801,\n",
       "                       0.3742, -0.6952, -0.8007, -0.6675, -0.8257,  0.4606, -0.6977, -0.9755,\n",
       "                      -0.3626,  0.1859,  0.1783,  0.6324,  0.3196, -0.4582,  0.1397,  0.8500,\n",
       "                       0.4893, -0.3193, -0.2917, -0.3238,  0.5035, -0.2844,  0.3407, -1.3248],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.1.1.running_var',\n",
       "              tensor([0.6036, 0.7538, 0.5866, 0.6633, 0.5593, 0.6855, 0.4369, 0.5545, 0.4075,\n",
       "                      0.7970, 1.0802, 0.5327, 0.5672, 0.5359, 0.5905, 0.5326, 0.4028, 0.6563,\n",
       "                      0.7827, 0.7444, 0.7562, 1.6093, 0.7848, 0.5746, 0.6527, 0.3406, 0.6831,\n",
       "                      0.4689, 0.5869, 0.9397, 0.6967, 0.8706, 0.7356, 1.5085, 0.8688, 0.9156,\n",
       "                      0.6068, 0.7849, 0.6778, 0.6203, 0.7855, 0.6776, 0.4891, 0.9342, 0.5915,\n",
       "                      0.5578, 0.3665, 0.9074, 0.5117, 0.4519, 0.5025, 0.7112, 0.7933, 0.9678,\n",
       "                      0.5106, 0.6453, 0.5198, 0.9181, 0.8019, 0.5727, 0.4667, 0.4739, 0.9411,\n",
       "                      1.4261], dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.6.convpath.0.2.0.weight',\n",
       "              tensor([[[-0.1595],\n",
       "                       [-0.0641],\n",
       "                       [ 0.0956],\n",
       "                       ...,\n",
       "                       [-0.0179],\n",
       "                       [-0.0835],\n",
       "                       [-0.0037]],\n",
       "              \n",
       "                      [[-0.0488],\n",
       "                       [-0.1028],\n",
       "                       [ 0.0146],\n",
       "                       ...,\n",
       "                       [-0.0451],\n",
       "                       [ 0.0322],\n",
       "                       [-0.1033]],\n",
       "              \n",
       "                      [[-0.0319],\n",
       "                       [ 0.0127],\n",
       "                       [-0.0140],\n",
       "                       ...,\n",
       "                       [-0.1225],\n",
       "                       [ 0.0479],\n",
       "                       [-0.0291]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1646],\n",
       "                       [-0.0141],\n",
       "                       [-0.1006],\n",
       "                       ...,\n",
       "                       [ 0.1497],\n",
       "                       [ 0.0020],\n",
       "                       [ 0.1797]],\n",
       "              \n",
       "                      [[-0.0715],\n",
       "                       [ 0.0449],\n",
       "                       [ 0.0487],\n",
       "                       ...,\n",
       "                       [ 0.1228],\n",
       "                       [-0.0075],\n",
       "                       [-0.0247]],\n",
       "              \n",
       "                      [[ 0.0327],\n",
       "                       [ 0.0197],\n",
       "                       [-0.0633],\n",
       "                       ...,\n",
       "                       [ 0.1074],\n",
       "                       [-0.0077],\n",
       "                       [-0.0439]]], dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.2.1.weight',\n",
       "              tensor([ 1.0150e-02, -6.9185e-03,  1.3713e-02, -1.0232e-02,  8.5891e-03,\n",
       "                       8.5662e-04,  9.6463e-04,  2.7952e-02, -2.0439e-02, -3.2038e-02,\n",
       "                      -1.0341e-02, -2.8828e-02, -2.2906e-03,  6.5147e-03, -8.0612e-03,\n",
       "                       3.3665e-02, -1.1520e-02, -1.2285e-02, -2.7464e-03, -3.0818e-02,\n",
       "                       1.5915e-02, -2.1413e-02,  9.2876e-03, -5.6457e-03, -2.5190e-02,\n",
       "                      -8.6980e-04, -2.2414e-02,  1.5891e-02,  1.0181e-02,  4.0825e-03,\n",
       "                      -4.9613e-03,  1.1755e-02,  9.6195e-03, -3.5012e-03,  5.8914e-04,\n",
       "                       1.1283e-02,  5.2637e-03,  8.8263e-03,  2.2464e-02, -1.7061e-03,\n",
       "                       2.9880e-03,  2.7630e-03, -1.4922e-02, -7.2432e-04,  1.6037e-03,\n",
       "                       5.6718e-03, -4.7779e-03,  1.6763e-02, -8.7895e-03,  3.4771e-02,\n",
       "                      -8.6616e-03,  9.0280e-03,  9.4141e-03, -1.2205e-02, -1.8254e-02,\n",
       "                       3.6123e-02,  1.7818e-03, -3.3514e-02,  1.9809e-02, -1.1498e-02,\n",
       "                       8.8276e-03, -1.6572e-02,  1.7389e-03, -1.5630e-02, -2.8822e-02,\n",
       "                       2.2343e-02,  9.8016e-04,  2.2395e-02, -2.5321e-02,  3.7378e-02,\n",
       "                      -3.1880e-02,  7.3242e-03,  8.9524e-03, -1.1022e-03, -7.9567e-03,\n",
       "                      -8.1209e-03,  7.4155e-03,  1.6137e-02,  8.0900e-03, -1.1796e-02,\n",
       "                      -2.4412e-02, -8.7004e-03,  7.8374e-03,  8.5154e-03,  3.3320e-02,\n",
       "                       1.3653e-03,  1.2235e-02,  1.1917e-02, -1.4693e-02,  2.4134e-02,\n",
       "                      -2.6067e-03, -1.4748e-02, -3.9695e-02, -6.8339e-03,  6.2063e-03,\n",
       "                      -8.9520e-03,  2.3766e-02, -4.2868e-03, -2.2400e-02,  1.4393e-02,\n",
       "                      -1.2527e-03,  1.2413e-02,  2.4075e-02, -2.0689e-02, -1.4978e-02,\n",
       "                       1.4390e-02,  1.8197e-02, -5.8271e-03,  2.8548e-02, -8.4787e-04,\n",
       "                       9.0904e-03,  1.6414e-02, -2.4509e-03, -3.3220e-02, -2.8567e-02,\n",
       "                       2.0956e-02, -5.7126e-03,  1.2938e-02, -6.8211e-04, -3.5662e-03,\n",
       "                       2.7866e-02,  1.7067e-02, -2.7390e-04,  1.6938e-02, -1.1377e-02,\n",
       "                      -9.3527e-03, -3.1341e-02, -1.3731e-03, -9.3574e-03,  1.1817e-02,\n",
       "                       1.2659e-02,  3.7606e-02, -1.3645e-03, -1.9714e-02, -1.1301e-02,\n",
       "                      -3.3656e-03,  1.2442e-03,  2.0660e-02,  4.1279e-03,  5.7126e-03,\n",
       "                       6.4018e-03, -6.6275e-03,  9.6259e-03, -2.4736e-02,  6.8314e-03,\n",
       "                      -8.6778e-03,  8.6942e-03, -9.4880e-03, -1.9828e-02,  3.7420e-03,\n",
       "                      -4.4454e-03,  1.6157e-02,  3.2540e-03,  1.0921e-02,  1.1020e-02,\n",
       "                       1.3300e-02, -1.1635e-02, -3.0415e-02,  1.2797e-02, -2.3762e-04,\n",
       "                      -2.1016e-02, -5.7868e-03,  3.4032e-03,  1.8778e-02,  2.3184e-02,\n",
       "                       1.7988e-02,  1.8516e-03,  1.7287e-02,  8.5864e-03,  3.8996e-02,\n",
       "                      -9.1970e-03, -1.2124e-02,  1.0203e-02,  2.2397e-03,  1.3022e-02,\n",
       "                      -1.0346e-02, -1.0479e-02,  5.5608e-05,  1.5299e-02,  1.1594e-02,\n",
       "                       1.1107e-02,  1.0029e-02, -1.5271e-02,  1.2404e-03, -3.0976e-03,\n",
       "                      -1.7444e-02, -4.4170e-03, -1.4255e-02,  6.4446e-03,  1.7522e-02,\n",
       "                      -1.6760e-02, -1.3052e-02,  2.0311e-02, -1.4137e-02, -1.4519e-02,\n",
       "                       7.5137e-03, -8.7557e-03,  2.2173e-02,  2.5515e-02, -1.2209e-02,\n",
       "                      -6.2720e-03,  2.4393e-02,  1.8483e-03, -1.5753e-02,  3.3581e-03,\n",
       "                       4.6281e-03,  4.5554e-02, -2.5611e-02,  9.6270e-04, -2.1001e-02,\n",
       "                      -5.6559e-03,  4.5710e-03,  1.1246e-03, -3.6671e-02,  6.7719e-03,\n",
       "                      -1.8243e-02, -5.3325e-03, -5.1157e-03,  2.0348e-02, -1.6542e-02,\n",
       "                       4.7618e-03,  1.1616e-02,  4.1344e-03,  1.6350e-02,  1.5259e-02,\n",
       "                       9.5261e-03,  9.6563e-03,  1.9315e-02, -5.9309e-04, -3.2346e-02,\n",
       "                       1.3660e-03,  9.9181e-03, -6.4819e-03,  2.3366e-02, -8.9760e-03,\n",
       "                      -7.7267e-03,  1.2651e-02,  1.1246e-02, -1.8028e-02, -8.1925e-03,\n",
       "                      -1.1697e-02,  1.0043e-02,  9.9266e-04,  5.6365e-03, -1.3458e-02,\n",
       "                       8.5161e-03, -8.8420e-03, -1.8407e-02,  4.4380e-03, -2.8718e-02,\n",
       "                      -1.1123e-02, -1.9702e-02, -2.6554e-03, -2.2865e-02, -2.9003e-03,\n",
       "                       5.3596e-05], dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.2.1.bias',\n",
       "              tensor([-8.3792e-04,  3.4520e-03,  1.3210e-02,  1.5723e-02,  8.9322e-04,\n",
       "                       4.7988e-03,  1.1738e-02,  1.7120e-03,  2.2046e-03,  2.2611e-02,\n",
       "                       1.4390e-02, -7.9868e-03,  8.1139e-03, -4.6840e-03,  1.1887e-02,\n",
       "                       4.0100e-03,  2.1283e-02, -2.5542e-03,  1.3014e-02, -7.5277e-03,\n",
       "                      -2.8608e-03,  3.0322e-03,  7.0995e-04,  6.4781e-03, -7.5706e-03,\n",
       "                      -1.5647e-02,  3.4617e-03,  8.4863e-03,  5.8509e-04, -2.2938e-03,\n",
       "                       3.9236e-03,  8.7355e-03, -9.6032e-03,  1.8149e-02,  1.2896e-02,\n",
       "                       1.4812e-02, -3.0728e-03,  1.9824e-02,  6.2865e-03,  1.5273e-02,\n",
       "                      -1.2278e-03,  2.3988e-02, -2.9701e-03,  1.8631e-03,  3.4217e-03,\n",
       "                      -9.0559e-03,  1.1670e-02,  5.8815e-03, -1.1538e-02,  1.3021e-02,\n",
       "                       8.1819e-03,  9.5104e-03,  9.6971e-03,  1.1133e-02,  4.3198e-03,\n",
       "                       1.6471e-02,  7.3368e-03,  3.1255e-03,  6.2823e-03,  2.9483e-03,\n",
       "                      -1.7716e-03,  2.8475e-03,  4.9976e-03,  8.9434e-03, -4.0464e-03,\n",
       "                       1.0568e-02, -1.2458e-02,  1.6330e-02, -4.7043e-03, -1.1872e-02,\n",
       "                       2.5532e-03,  5.8576e-03,  1.6502e-03, -7.1843e-03,  1.4609e-02,\n",
       "                      -1.0920e-03,  3.3231e-03,  1.3520e-03,  5.0737e-03,  1.7698e-03,\n",
       "                       1.0323e-02, -5.8991e-03,  8.2852e-03,  4.0855e-03, -4.8411e-03,\n",
       "                       1.2181e-02, -5.5207e-04,  6.4295e-04,  1.3395e-02,  6.5983e-03,\n",
       "                      -8.4500e-04,  1.4904e-02,  1.4938e-02, -3.0558e-03,  9.2375e-03,\n",
       "                      -1.1740e-02,  6.1342e-03,  2.4766e-03,  1.1535e-02, -2.3214e-03,\n",
       "                       1.9170e-02,  1.4898e-03,  5.9829e-03, -4.9193e-04,  1.1518e-02,\n",
       "                       5.8428e-04,  1.3346e-03,  3.2009e-03,  4.6381e-03,  8.4240e-03,\n",
       "                      -7.3728e-03, -7.3230e-03,  5.0754e-03,  2.0944e-02,  1.1596e-02,\n",
       "                       6.6018e-03,  9.5287e-03,  2.8527e-05,  3.4567e-03, -1.4839e-02,\n",
       "                      -1.6093e-05,  8.0401e-03, -1.8009e-03, -2.7852e-03, -1.1983e-02,\n",
       "                       1.0376e-02,  1.4491e-02,  5.2070e-03,  2.4162e-03,  1.6354e-02,\n",
       "                       2.3329e-02,  1.5196e-02,  1.4868e-02,  6.6737e-03,  1.5523e-02,\n",
       "                      -6.6983e-03,  1.5797e-02,  9.1371e-03,  1.0598e-02,  8.8044e-03,\n",
       "                       1.4434e-02, -3.7489e-03,  1.6393e-02,  6.3892e-03, -7.3140e-03,\n",
       "                       1.3741e-02,  3.0642e-03, -1.2913e-03,  8.9991e-03,  9.0917e-03,\n",
       "                       6.3211e-03,  1.3197e-02,  1.3214e-02,  1.3775e-02,  1.5297e-02,\n",
       "                       9.1409e-03,  1.2826e-03,  7.1325e-03, -1.7783e-03, -1.0423e-02,\n",
       "                       4.9193e-03, -4.8071e-03,  6.3248e-04,  1.1793e-02,  1.0697e-02,\n",
       "                       1.2110e-04, -8.8667e-03,  1.1457e-02,  9.8033e-04,  1.6094e-02,\n",
       "                       6.3129e-03,  7.3345e-03,  1.1404e-02,  1.0406e-02, -1.3451e-02,\n",
       "                       2.7757e-03, -6.2231e-04,  1.2838e-02,  3.7241e-03,  4.1717e-03,\n",
       "                      -3.1890e-03,  1.1061e-02, -8.1519e-03, -9.0768e-03,  1.9833e-02,\n",
       "                       7.4087e-03,  1.3363e-02,  1.0722e-02,  2.6543e-03,  2.6333e-03,\n",
       "                       6.1325e-03,  2.3526e-03,  9.8704e-03, -8.1245e-03,  2.4701e-03,\n",
       "                       6.2251e-03, -5.2993e-03,  1.9476e-02,  8.3589e-03,  5.9339e-03,\n",
       "                       3.2769e-03,  2.1492e-02,  1.9525e-02,  1.6423e-02,  4.3670e-04,\n",
       "                      -1.3728e-03,  1.6720e-02, -4.0052e-03,  8.9128e-03,  1.1261e-02,\n",
       "                      -1.2157e-03,  1.1640e-02,  1.4352e-02,  8.0657e-03,  1.5759e-02,\n",
       "                       4.1711e-04,  4.2417e-03, -5.3075e-03,  2.3169e-03, -3.7946e-04,\n",
       "                      -1.4252e-02,  3.1344e-03,  5.3142e-03,  1.8019e-02, -4.9953e-03,\n",
       "                       4.4637e-03, -3.0559e-03,  1.8502e-03, -1.4347e-02,  1.4490e-02,\n",
       "                       8.4647e-03, -1.7278e-03,  1.1873e-02,  6.4378e-03,  2.3101e-03,\n",
       "                       6.9338e-03,  7.6796e-03, -8.8597e-03,  9.5387e-03,  8.5499e-03,\n",
       "                       1.8392e-03,  3.9479e-03,  5.1607e-03,  8.0653e-03, -2.6380e-04,\n",
       "                       1.4907e-02,  1.1049e-04,  9.7957e-03,  3.1189e-03, -8.3708e-03,\n",
       "                       1.7591e-02,  1.8614e-02,  1.5490e-02,  1.6420e-02,  9.7842e-03,\n",
       "                       5.4413e-03], dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.2.1.running_mean',\n",
       "              tensor([ 0.0484, -0.1926,  0.1816,  0.3316, -0.2590,  0.1854, -0.2528, -0.6604,\n",
       "                      -0.2257,  0.1922,  0.4257, -0.4847,  0.0887,  0.0806, -0.1255, -0.1654,\n",
       "                       0.2206,  0.0214, -0.0264,  0.3489, -0.4619,  0.4529,  0.4506,  0.1608,\n",
       "                       0.7995,  0.1404,  0.0711,  0.1421,  0.1377,  0.5238, -0.1551,  0.0569,\n",
       "                      -0.1907,  0.4104,  0.1761,  0.7142, -0.2240, -0.2415,  0.1952, -0.2565,\n",
       "                      -0.3931, -0.2128,  0.1391,  0.0065,  0.3877, -0.6508, -0.1919,  0.0340,\n",
       "                       0.5002, -0.0274,  0.0931,  0.0895,  0.5043,  0.4762, -0.6238,  0.2767,\n",
       "                      -0.1511, -0.2778,  0.3921,  0.2665, -0.0646,  0.2660,  0.5649, -0.2741,\n",
       "                       0.6009,  0.1316, -0.1592,  0.2648, -0.3628,  0.1258,  0.2464,  0.0032,\n",
       "                       0.6792, -0.5942, -0.1350, -0.3891,  0.4269, -0.2334,  0.2270,  0.1406,\n",
       "                      -0.5591, -0.6412, -0.2204, -0.5344,  0.1413,  0.2465,  0.1378, -0.2565,\n",
       "                      -0.4705, -0.0973,  0.1844, -0.3962, -0.3606, -0.7851,  0.0963, -0.1701,\n",
       "                      -0.5814,  0.1935, -0.8287, -0.0381, -0.1375,  0.2189, -0.4572,  0.6118,\n",
       "                      -0.1344,  0.0932, -0.0333,  0.1850, -0.2961, -0.0506, -0.4222,  0.3416,\n",
       "                       0.1064, -0.0942, -0.1910, -0.5448, -0.1406, -0.2246, -0.4124, -0.1428,\n",
       "                      -0.2938,  0.1961,  0.1663,  0.2322,  0.2626, -0.2882,  0.1910,  0.1147,\n",
       "                       0.5079, -0.3926,  0.4819,  0.4328, -0.2235,  0.0330,  0.0825,  0.2507,\n",
       "                      -0.2024, -0.2794, -0.3877,  0.0224,  0.0988,  0.2233,  0.0967,  0.3191,\n",
       "                      -0.0405,  0.1969,  0.0536, -0.7023,  0.0902,  0.1065, -0.5438, -0.5041,\n",
       "                      -0.4060, -0.6975,  0.3338,  0.1671, -0.3657, -0.0663,  0.4046, -0.2703,\n",
       "                      -0.2009, -0.1549,  0.0495,  0.0402, -0.0366,  0.5080,  0.9068, -0.2483,\n",
       "                       0.1388, -0.1797, -0.2635, -0.4339, -0.0016, -0.0620,  0.4554, -0.3511,\n",
       "                       0.6290, -0.0385, -0.3367, -0.2932,  0.6035,  0.6757, -1.0276, -0.2959,\n",
       "                       0.0119,  0.6055,  0.2138,  0.4180, -0.0505,  0.0391,  0.4353,  0.3378,\n",
       "                       0.0899, -0.4953,  0.1470,  0.0720, -0.1669, -0.0405, -0.3347,  0.1149,\n",
       "                       0.5975,  0.2934, -0.1084, -0.5374, -0.4014,  0.1703,  0.2183, -0.1230,\n",
       "                      -0.3695,  0.4564,  0.2788, -0.1397,  0.0234, -0.0727,  0.7962, -0.1117,\n",
       "                       0.4427,  0.0702, -0.8673,  0.3666, -0.2168, -0.3573,  0.3964, -0.3970,\n",
       "                      -0.0211,  0.0339, -0.5008, -0.0428, -0.1548, -0.1057, -0.0539,  0.1592,\n",
       "                       0.7628,  0.3081, -0.1074, -0.1172,  0.3006,  0.4610,  0.1876,  0.3178,\n",
       "                      -0.2453,  0.0965, -0.1813, -0.2003, -0.2240, -0.3855, -0.0112, -0.1242,\n",
       "                      -0.2394,  0.3448, -0.0450,  0.6814, -0.0061,  0.0442, -0.0092,  0.1831],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.2.1.running_var',\n",
       "              tensor([0.5060, 0.2928, 0.2521, 0.4997, 0.1346, 0.1000, 0.1168, 0.2703, 0.5808,\n",
       "                      0.3028, 0.2458, 0.3926, 0.1400, 0.2547, 0.4106, 0.3270, 0.3710, 0.7666,\n",
       "                      0.1764, 0.4358, 0.4899, 0.3624, 0.3437, 0.2658, 0.4583, 0.1680, 0.3590,\n",
       "                      0.2896, 0.2077, 0.1671, 0.4181, 0.5252, 0.1416, 0.2487, 0.2686, 0.4966,\n",
       "                      0.2268, 0.1677, 0.2946, 0.3562, 0.3239, 0.1804, 0.2591, 0.3475, 0.3891,\n",
       "                      0.4138, 0.4242, 0.1954, 0.8952, 0.4279, 0.1313, 0.6890, 0.4056, 0.2695,\n",
       "                      0.5453, 0.3662, 0.2550, 0.5828, 0.2958, 0.2703, 0.0883, 0.1876, 0.1781,\n",
       "                      0.4064, 0.6415, 0.6943, 0.2571, 0.3134, 0.4579, 0.6150, 0.4098, 0.6087,\n",
       "                      0.2605, 0.5889, 0.2772, 0.2720, 0.5186, 0.3161, 0.5636, 0.1956, 0.3959,\n",
       "                      0.2378, 0.2326, 0.3771, 0.4046, 0.3989, 0.2930, 0.2763, 0.3002, 0.2368,\n",
       "                      0.2471, 0.2825, 0.4424, 0.3397, 0.0973, 0.2647, 0.4230, 0.1425, 0.2961,\n",
       "                      0.5732, 0.2965, 0.3911, 0.4025, 0.5569, 0.3308, 0.2962, 0.4059, 0.2956,\n",
       "                      0.2929, 0.1580, 0.2754, 0.5503, 0.2243, 0.2799, 0.3702, 0.5863, 0.2564,\n",
       "                      0.3825, 0.2024, 0.5363, 0.2963, 0.3553, 0.1630, 0.4539, 0.2036, 0.7385,\n",
       "                      0.1736, 0.0701, 0.3150, 0.3583, 0.2097, 0.3979, 0.3020, 0.7779, 0.2743,\n",
       "                      0.1458, 0.0742, 0.1964, 0.1535, 0.1818, 0.1685, 0.0873, 0.3572, 0.5351,\n",
       "                      0.2114, 0.4553, 0.1298, 0.7119, 0.2393, 0.3721, 0.4882, 0.3819, 0.1922,\n",
       "                      0.5164, 0.4325, 0.2892, 0.2629, 0.2532, 0.3939, 0.2186, 0.5735, 0.2830,\n",
       "                      0.2749, 0.3364, 0.5277, 0.4928, 0.4210, 0.3123, 0.3560, 0.3859, 0.2993,\n",
       "                      0.1585, 0.4988, 0.2331, 0.4092, 0.4772, 0.2176, 0.2631, 0.5189, 0.2200,\n",
       "                      0.4529, 0.3984, 0.4933, 0.1653, 0.3275, 0.4449, 0.2048, 0.2948, 0.2100,\n",
       "                      0.4726, 0.3029, 0.3962, 0.2390, 0.4861, 0.3897, 0.2782, 0.2649, 0.3535,\n",
       "                      0.2940, 0.2564, 0.2433, 0.3392, 0.1744, 0.4631, 0.2398, 0.3812, 0.2768,\n",
       "                      0.2944, 0.1773, 0.5339, 0.0971, 0.4645, 0.2403, 0.2807, 0.4763, 0.1225,\n",
       "                      0.4769, 0.2908, 0.4497, 0.5328, 0.1445, 0.3494, 0.1842, 0.3403, 0.3770,\n",
       "                      0.2697, 0.2160, 0.3205, 0.3376, 0.4268, 0.2101, 0.3005, 0.4034, 0.5217,\n",
       "                      0.2343, 0.3558, 0.2110, 0.1964, 0.5977, 0.5221, 0.6663, 0.2049, 0.4839,\n",
       "                      0.0876, 0.9857, 0.2702, 0.1396, 0.3188, 0.1138, 0.5938, 0.4612, 0.5259,\n",
       "                      0.1380, 0.3365, 0.2664, 0.0693], dtype=torch.float64)),\n",
       "             ('6.6.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.7.convs.0.0.weight',\n",
       "              tensor([[[ 0.0036],\n",
       "                       [ 0.0511],\n",
       "                       [ 0.0028],\n",
       "                       ...,\n",
       "                       [-0.0313],\n",
       "                       [ 0.0247],\n",
       "                       [-0.0941]],\n",
       "              \n",
       "                      [[ 0.1071],\n",
       "                       [-0.0338],\n",
       "                       [-0.0449],\n",
       "                       ...,\n",
       "                       [ 0.0546],\n",
       "                       [ 0.0115],\n",
       "                       [ 0.0233]],\n",
       "              \n",
       "                      [[-0.1518],\n",
       "                       [-0.0357],\n",
       "                       [ 0.0094],\n",
       "                       ...,\n",
       "                       [-0.0946],\n",
       "                       [-0.1985],\n",
       "                       [-0.0267]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0988],\n",
       "                       [ 0.0083],\n",
       "                       [-0.1697],\n",
       "                       ...,\n",
       "                       [-0.0075],\n",
       "                       [ 0.1128],\n",
       "                       [-0.0732]],\n",
       "              \n",
       "                      [[-0.0474],\n",
       "                       [ 0.0256],\n",
       "                       [-0.0122],\n",
       "                       ...,\n",
       "                       [ 0.0858],\n",
       "                       [-0.0795],\n",
       "                       [-0.0920]],\n",
       "              \n",
       "                      [[ 0.0310],\n",
       "                       [ 0.0110],\n",
       "                       [ 0.0396],\n",
       "                       ...,\n",
       "                       [ 0.0069],\n",
       "                       [ 0.0966],\n",
       "                       [-0.0250]]], dtype=torch.float64)),\n",
       "             ('6.7.convs.0.1.weight',\n",
       "              tensor([1.0092, 0.9771, 0.9662, 0.9659, 0.9897, 0.9591, 0.9641, 0.9586, 0.9697,\n",
       "                      0.9677, 0.9641, 0.9755, 0.9775, 0.9753, 0.9701, 0.9801, 0.9814, 0.9696,\n",
       "                      0.9719, 0.9538, 0.9716, 0.9806, 0.9509, 0.9683, 0.9908, 0.9587, 0.9647,\n",
       "                      0.9898, 0.9796, 0.9570, 0.9657, 0.9903, 0.9774, 0.9639, 0.9829, 0.9768,\n",
       "                      0.9662, 0.9695, 0.9547, 0.9966, 0.9855, 0.9658, 0.9589, 0.9964, 0.9760,\n",
       "                      0.9701, 0.9924, 0.9467, 0.9859, 0.9763, 0.9852, 0.9704, 0.9560, 0.9680,\n",
       "                      0.9877, 0.9593, 0.9637, 0.9697, 0.9758, 0.9844, 0.9901, 0.9739, 0.9951,\n",
       "                      0.9823], dtype=torch.float64)),\n",
       "             ('6.7.convs.0.1.bias',\n",
       "              tensor([ 0.0088,  0.0015,  0.0130, -0.0094, -0.0120, -0.0068, -0.0032, -0.0185,\n",
       "                       0.0069, -0.0063, -0.0046,  0.0146,  0.0104, -0.0059,  0.0187,  0.0003,\n",
       "                      -0.0042,  0.0099, -0.0079,  0.0138, -0.0124, -0.0003, -0.0069,  0.0107,\n",
       "                       0.0233, -0.0117, -0.0354,  0.0088, -0.0217, -0.0304, -0.0043,  0.0092,\n",
       "                       0.0100, -0.0040,  0.0014, -0.0075, -0.0004, -0.0169, -0.0035,  0.0226,\n",
       "                       0.0109,  0.0037, -0.0106,  0.0139, -0.0015, -0.0102, -0.0053,  0.0062,\n",
       "                      -0.0085, -0.0195,  0.0149, -0.0066,  0.0011,  0.0076,  0.0231, -0.0053,\n",
       "                      -0.0196,  0.0124,  0.0180,  0.0110,  0.0100, -0.0140,  0.0269,  0.0047],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convs.0.1.running_mean',\n",
       "              tensor([-4.4709e-01,  3.2206e-01,  1.0960e-01, -4.2228e-01,  2.9116e-01,\n",
       "                      -2.3160e-01, -4.1198e-02, -3.1612e-01, -7.0481e-02, -1.9745e-01,\n",
       "                      -9.3042e-01,  1.6199e-01, -6.2554e-01, -5.8980e-01,  8.8372e-01,\n",
       "                       8.8947e-01,  6.5809e-01, -8.4591e-02,  5.3461e-01, -9.0810e-01,\n",
       "                      -5.5649e-02, -1.0478e-01,  5.7140e-01,  8.4632e-01, -6.0553e-01,\n",
       "                      -1.2738e+00,  5.4283e-01, -3.9438e-01,  8.2325e-02,  9.6874e-01,\n",
       "                       1.1020e+00,  1.1073e-01, -4.1470e-01,  1.8697e-02, -6.8545e-01,\n",
       "                      -2.8432e-01, -5.8978e-01, -1.8468e-01, -3.6847e-01,  7.4530e-01,\n",
       "                      -5.5156e-01, -1.1988e-01, -6.0985e-02, -2.7134e-01, -1.2102e-01,\n",
       "                      -2.9494e-02, -5.2589e-01, -6.3264e-01,  1.7223e-01, -6.2544e-01,\n",
       "                      -1.2528e-01,  1.8312e-01, -1.1026e+00,  2.1019e-01, -4.5637e-01,\n",
       "                       7.4434e-01, -5.0559e-01,  3.1560e-01, -3.5955e-01, -1.2320e-01,\n",
       "                      -1.1136e-03,  2.1425e-01, -9.4900e-01,  3.7618e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convs.0.1.running_var',\n",
       "              tensor([0.0986, 0.2058, 0.5031, 0.3456, 0.0835, 0.3940, 0.1304, 0.1035, 0.1561,\n",
       "                      0.1784, 0.2891, 0.2451, 0.1126, 0.1908, 0.6008, 0.5388, 0.3412, 0.1749,\n",
       "                      0.4356, 0.5420, 0.1034, 0.1150, 0.4273, 0.1447, 0.7029, 0.2361, 0.7409,\n",
       "                      0.1626, 0.2049, 0.8326, 0.5391, 0.1129, 0.5372, 0.1509, 0.0980, 0.2431,\n",
       "                      0.1887, 0.1394, 0.2727, 0.1722, 0.1566, 0.1334, 0.2688, 0.1299, 0.0916,\n",
       "                      0.1377, 0.0975, 0.5128, 0.0850, 0.1087, 0.1034, 0.1730, 0.3888, 0.4493,\n",
       "                      0.1583, 0.4558, 0.1691, 0.3245, 0.1524, 0.0867, 0.1146, 0.4909, 0.1611,\n",
       "                      0.1774], dtype=torch.float64)),\n",
       "             ('6.7.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.7.convs.1.0.weight',\n",
       "              tensor([[[ 1.2412e-01, -1.4575e-01, -5.3326e-03,  1.1730e-01,  1.4899e-01],\n",
       "                       [ 3.8330e-02, -1.1052e-01, -1.2683e-01, -1.9285e-02,  2.4551e-02],\n",
       "                       [ 5.1682e-02, -7.2520e-02, -6.3742e-02,  2.0752e-02,  4.3689e-02],\n",
       "                       ...,\n",
       "                       [ 1.8805e-03,  2.3706e-03, -3.2104e-02,  1.2766e-01,  1.3889e-02],\n",
       "                       [ 1.2221e-01,  2.7751e-02,  1.8221e-02, -6.5439e-02, -1.5686e-02],\n",
       "                       [-2.9641e-02,  2.8005e-02,  4.9285e-02,  3.4803e-02, -6.1880e-02]],\n",
       "              \n",
       "                      [[ 6.5340e-02, -3.2313e-03,  2.4173e-02,  1.8863e-02, -5.3450e-02],\n",
       "                       [ 5.5821e-02, -2.0517e-01,  4.9215e-02, -1.1132e-02, -4.0468e-02],\n",
       "                       [-2.3987e-01,  2.3344e-02,  9.7126e-02,  3.5584e-02, -2.8119e-02],\n",
       "                       ...,\n",
       "                       [-2.2060e-02,  7.0075e-02,  2.9676e-02,  1.6899e-01,  6.7768e-02],\n",
       "                       [-1.2153e-01,  9.9617e-02,  5.6672e-02, -6.0307e-03,  1.9294e-02],\n",
       "                       [ 3.0212e-02,  8.8563e-02, -2.0466e-01, -1.3635e-02, -1.4361e-01]],\n",
       "              \n",
       "                      [[-2.7867e-02,  1.3783e-01, -1.3297e-01, -1.3861e-01, -1.1029e-02],\n",
       "                       [ 2.0313e-02, -9.1026e-03,  4.6112e-02, -4.5050e-02, -2.4769e-03],\n",
       "                       [-1.4907e-02, -1.0210e-01,  3.9924e-02,  4.4094e-02, -2.0041e-02],\n",
       "                       ...,\n",
       "                       [-4.6338e-02,  1.2205e-01,  1.0770e-01, -1.5950e-03, -4.8658e-02],\n",
       "                       [ 9.8997e-02,  7.1829e-03,  1.4762e-01,  1.1187e-01, -6.8476e-02],\n",
       "                       [ 3.3564e-02, -1.8746e-02,  8.8012e-02, -6.6003e-02,  1.3959e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.1264e-01, -8.6263e-02, -8.6817e-02, -3.3818e-02, -1.1265e-01],\n",
       "                       [-1.8666e-04, -1.0181e-04, -1.0996e-01, -1.4141e-01,  4.1286e-02],\n",
       "                       [-1.3787e-01, -2.8461e-02,  1.2039e-01,  4.2411e-02,  1.3354e-02],\n",
       "                       ...,\n",
       "                       [ 1.1489e-02, -6.3584e-02, -5.0882e-02, -1.8576e-01, -4.8135e-02],\n",
       "                       [-9.2282e-02, -6.1507e-02, -5.9662e-02,  8.7831e-02, -5.1142e-03],\n",
       "                       [-6.3506e-02, -5.6199e-02,  2.8567e-02, -1.0404e-02, -8.5436e-02]],\n",
       "              \n",
       "                      [[ 7.4452e-03,  4.8705e-02, -8.8329e-02,  1.1623e-01,  1.2001e-01],\n",
       "                       [-6.6653e-02,  2.8182e-02,  8.5429e-02,  5.3588e-03, -8.6607e-02],\n",
       "                       [ 7.0300e-02,  1.1531e-01,  1.9382e-02, -7.5359e-02, -8.1458e-02],\n",
       "                       ...,\n",
       "                       [-1.5523e-01, -8.2766e-02,  8.0274e-02,  4.9847e-02,  5.9008e-02],\n",
       "                       [-2.9197e-04, -3.8981e-03, -7.4774e-02, -1.3034e-01, -1.3672e-01],\n",
       "                       [ 9.1060e-02, -8.2616e-02, -1.0709e-01,  1.2206e-01, -7.6210e-02]],\n",
       "              \n",
       "                      [[-8.3405e-02, -1.7157e-01,  7.9575e-02, -6.5555e-02, -7.5904e-03],\n",
       "                       [ 1.6140e-01, -1.4048e-01,  5.3992e-02, -4.9909e-02, -1.0861e-01],\n",
       "                       [ 2.0310e-02,  1.0672e-01,  1.5073e-02,  2.9792e-02, -5.5447e-03],\n",
       "                       ...,\n",
       "                       [ 3.0940e-02, -1.0294e-01, -3.5059e-02, -7.3661e-02, -5.8832e-02],\n",
       "                       [-2.7469e-02, -4.4009e-02,  2.1994e-02, -5.5769e-02, -1.1637e-01],\n",
       "                       [-1.1300e-01, -1.1986e-03,  2.1710e-02,  1.1594e-02, -1.7025e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convs.1.1.weight',\n",
       "              tensor([0.9898, 0.9804, 0.9557, 0.9557, 0.9742, 0.9635, 0.9893, 0.9810, 0.9807,\n",
       "                      0.9568, 0.9905, 0.9392, 0.9299, 0.9653, 0.9865, 0.9610, 0.9838, 0.9563,\n",
       "                      0.9681, 0.9355, 0.9748, 0.9658, 0.9842, 0.9547, 0.9440, 0.9668, 0.9509,\n",
       "                      1.0212, 0.9698, 0.9772, 0.9688, 0.9705, 1.0089, 0.9422, 0.9700, 0.9782,\n",
       "                      0.9598, 0.9448, 0.9637, 0.9634, 0.9368, 0.9577, 0.9656, 0.9451, 0.9467,\n",
       "                      0.9381, 0.9567, 0.9806, 1.0139, 0.9760, 0.9686, 0.9241, 0.9693, 0.9613,\n",
       "                      0.9571, 0.9580, 1.0190, 0.9173, 0.9746, 0.9845, 0.9855, 0.9758, 0.9914,\n",
       "                      0.9639], dtype=torch.float64)),\n",
       "             ('6.7.convs.1.1.bias',\n",
       "              tensor([ 1.7705e-05, -8.3008e-03, -8.9500e-03, -1.1600e-02,  1.3772e-03,\n",
       "                      -1.4480e-02,  6.3453e-03,  1.1437e-02,  9.4652e-03,  1.6378e-03,\n",
       "                       1.4161e-02, -3.4924e-02,  2.4510e-03, -1.0505e-02,  1.6462e-02,\n",
       "                       1.4814e-03,  2.4546e-03, -6.0179e-04,  1.0428e-02, -1.4090e-02,\n",
       "                       9.6360e-03, -2.4580e-02,  1.8338e-03, -9.9366e-03, -1.8377e-02,\n",
       "                      -1.1654e-02, -6.2127e-03,  2.5345e-02, -2.2487e-02,  4.1988e-03,\n",
       "                      -1.4058e-03, -1.4298e-02,  1.5386e-02, -1.9182e-02, -1.4748e-02,\n",
       "                      -1.3501e-02, -2.0651e-02, -3.2022e-02, -1.9587e-02, -3.8651e-04,\n",
       "                       1.8055e-03, -7.2941e-03, -2.1827e-02, -2.1465e-02, -8.8045e-03,\n",
       "                      -1.6548e-02, -1.3357e-02,  2.4029e-03, -9.6427e-04,  5.0055e-03,\n",
       "                      -7.4223e-03, -1.8886e-02, -1.0791e-02, -1.0968e-02, -2.4477e-02,\n",
       "                       1.5383e-03,  1.4176e-02, -1.1780e-02, -1.8627e-02,  8.8022e-03,\n",
       "                      -2.2120e-03,  1.1865e-03,  1.6239e-02,  4.1783e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convs.1.1.running_mean',\n",
       "              tensor([ 0.6763,  0.0578, -0.0053,  0.3731, -0.2817,  0.7373,  0.0637, -0.3054,\n",
       "                      -0.6437,  0.5518, -0.2666, -0.6452, -0.2400,  0.1034, -0.5692, -0.2805,\n",
       "                       0.6150, -0.1274,  0.0621, -0.8910,  0.2998, -0.4710,  0.1468,  0.2788,\n",
       "                      -0.4233, -0.7493,  1.1968,  0.3071, -0.0312, -0.6981,  0.8295, -0.3217,\n",
       "                      -0.2529, -0.4806,  0.3241, -0.4653, -0.0445, -0.0626, -0.6874, -0.0265,\n",
       "                      -0.7829,  0.4947,  0.8369,  1.0345, -0.0674, -0.1988,  0.1449,  0.3052,\n",
       "                      -0.2444,  0.5238, -0.5866, -0.4534, -0.5170,  0.6356,  0.0155,  0.8364,\n",
       "                      -0.8019, -0.5732, -0.2875,  0.0413, -0.0495, -0.6168, -0.3610, -1.0018],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convs.1.1.running_var',\n",
       "              tensor([0.5579, 0.6839, 0.5906, 0.6224, 0.3973, 0.4943, 0.4226, 0.4361, 0.4040,\n",
       "                      0.4330, 0.4934, 0.7146, 0.5885, 0.5839, 0.5970, 0.5087, 0.5757, 0.4699,\n",
       "                      0.4642, 0.6962, 0.9654, 0.5364, 0.4381, 0.6028, 0.5308, 0.5356, 0.6284,\n",
       "                      0.4491, 0.6183, 0.3979, 0.4790, 0.4408, 0.4883, 0.7334, 0.4007, 0.5635,\n",
       "                      0.5321, 1.1600, 0.7589, 0.5066, 0.5667, 0.6680, 0.8357, 0.7251, 0.5130,\n",
       "                      0.7356, 0.6498, 0.6084, 0.6986, 0.6872, 0.5915, 0.4531, 1.1778, 0.7638,\n",
       "                      0.7015, 0.5247, 0.4970, 0.9974, 0.4244, 0.4558, 0.5693, 0.6700, 0.4813,\n",
       "                      0.6685], dtype=torch.float64)),\n",
       "             ('6.7.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.7.convs.2.0.weight',\n",
       "              tensor([[[ 0.0307],\n",
       "                       [ 0.0978],\n",
       "                       [-0.0232],\n",
       "                       ...,\n",
       "                       [-0.0448],\n",
       "                       [ 0.1130],\n",
       "                       [ 0.0750]],\n",
       "              \n",
       "                      [[-0.1199],\n",
       "                       [-0.0124],\n",
       "                       [ 0.0272],\n",
       "                       ...,\n",
       "                       [-0.1239],\n",
       "                       [-0.1719],\n",
       "                       [ 0.2395]],\n",
       "              \n",
       "                      [[ 0.2251],\n",
       "                       [ 0.1154],\n",
       "                       [ 0.1930],\n",
       "                       ...,\n",
       "                       [ 0.0430],\n",
       "                       [-0.0167],\n",
       "                       [ 0.0704]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0380],\n",
       "                       [-0.0914],\n",
       "                       [-0.1436],\n",
       "                       ...,\n",
       "                       [ 0.0092],\n",
       "                       [-0.0122],\n",
       "                       [-0.0521]],\n",
       "              \n",
       "                      [[-0.0386],\n",
       "                       [-0.1712],\n",
       "                       [ 0.3236],\n",
       "                       ...,\n",
       "                       [-0.0435],\n",
       "                       [ 0.0551],\n",
       "                       [-0.3284]],\n",
       "              \n",
       "                      [[ 0.0118],\n",
       "                       [-0.0019],\n",
       "                       [ 0.0355],\n",
       "                       ...,\n",
       "                       [ 0.0263],\n",
       "                       [ 0.1237],\n",
       "                       [-0.0376]]], dtype=torch.float64)),\n",
       "             ('6.7.convs.2.1.weight',\n",
       "              tensor([-0.0027, -0.0072,  0.0034,  0.0026, -0.0096,  0.0179,  0.0225,  0.0139,\n",
       "                       0.0148,  0.0590, -0.0233,  0.0062,  0.0317, -0.0154,  0.0134, -0.0442,\n",
       "                       0.0194,  0.0018, -0.0285,  0.0219, -0.0269, -0.0152, -0.0150, -0.0281,\n",
       "                      -0.0029,  0.0091, -0.0048,  0.0155,  0.0056, -0.0238,  0.0160, -0.0311,\n",
       "                      -0.0100, -0.0139,  0.0302, -0.0047,  0.0228,  0.0119,  0.0073,  0.0071,\n",
       "                      -0.0206,  0.0224, -0.0108, -0.0021,  0.0187,  0.0079,  0.0176,  0.0065,\n",
       "                       0.0145, -0.0209, -0.0111, -0.0065,  0.0517,  0.0116, -0.0090, -0.0313,\n",
       "                       0.0172,  0.0195, -0.0054,  0.0134, -0.0033, -0.0225, -0.0033,  0.0005,\n",
       "                       0.0134, -0.0171,  0.0085,  0.0383, -0.0034, -0.0172,  0.0092, -0.0047,\n",
       "                       0.0141,  0.0156, -0.0024, -0.0080,  0.0176,  0.0052,  0.0207,  0.0096,\n",
       "                      -0.0142, -0.0073, -0.0009,  0.0122, -0.0063, -0.0334,  0.0207,  0.0121,\n",
       "                       0.0031, -0.0140,  0.0244,  0.0085, -0.0097, -0.0052, -0.0160,  0.0087,\n",
       "                      -0.0061, -0.0181,  0.0182,  0.0094, -0.0050, -0.0372,  0.0071, -0.0371,\n",
       "                      -0.0192, -0.0198, -0.0189, -0.0215,  0.0281, -0.0043, -0.0009,  0.0184,\n",
       "                      -0.0055, -0.0248,  0.0171,  0.0178, -0.0197, -0.0160, -0.0084, -0.0046,\n",
       "                       0.0067, -0.0081, -0.0039, -0.0168,  0.0089, -0.0031,  0.0177, -0.0286,\n",
       "                       0.0026,  0.0093, -0.0336,  0.0413,  0.0361,  0.0182, -0.0305, -0.0003,\n",
       "                       0.0193, -0.0019,  0.0172,  0.0249, -0.0076,  0.0014, -0.0128,  0.0097,\n",
       "                       0.0042, -0.0061, -0.0177, -0.0429, -0.0143,  0.0116,  0.0095, -0.0071,\n",
       "                       0.0106,  0.0065,  0.0155,  0.0034,  0.0108, -0.0147, -0.0051,  0.0294,\n",
       "                       0.0208, -0.0096,  0.0026,  0.0219, -0.0065,  0.0065,  0.0338, -0.0018,\n",
       "                       0.0024,  0.0172,  0.0130,  0.0023,  0.0192, -0.0047, -0.0393, -0.0183,\n",
       "                       0.0169, -0.0144,  0.0007,  0.0171, -0.0059,  0.0185, -0.0008,  0.0097,\n",
       "                       0.0104,  0.0293, -0.0143, -0.0109, -0.0206, -0.0014,  0.0184, -0.0142,\n",
       "                      -0.0182, -0.0191,  0.0098, -0.0166, -0.0107,  0.0636, -0.0131, -0.0144,\n",
       "                      -0.0208,  0.0289,  0.0305, -0.0209,  0.0181, -0.0160, -0.0105, -0.0180,\n",
       "                       0.0064, -0.0031,  0.0020, -0.0096,  0.0212,  0.0183, -0.0058,  0.0070,\n",
       "                       0.0321,  0.0069,  0.0005,  0.0322,  0.0096,  0.0212,  0.0160,  0.0088,\n",
       "                       0.0087, -0.0073, -0.0146, -0.0208, -0.0165, -0.0273,  0.0244, -0.0143,\n",
       "                       0.0307, -0.0223,  0.0019,  0.0184, -0.0154, -0.0196, -0.0037, -0.0030,\n",
       "                      -0.0172, -0.0193,  0.0317,  0.0036,  0.0067, -0.0023, -0.0173, -0.0065,\n",
       "                       0.0259,  0.0143, -0.0013, -0.0075,  0.0311, -0.0264, -0.0201, -0.0214],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convs.2.1.bias',\n",
       "              tensor([-6.4310e-04,  3.0266e-03,  1.3523e-02,  1.4955e-02,  1.3641e-03,\n",
       "                       1.9735e-03,  1.1713e-02,  2.0105e-04,  8.8579e-03,  2.3631e-02,\n",
       "                       1.4349e-02, -7.5146e-03,  7.0602e-03, -4.0048e-03,  8.2470e-03,\n",
       "                       3.5324e-03,  2.3340e-02, -3.0539e-03,  1.3073e-02, -3.9840e-03,\n",
       "                      -3.1628e-03,  2.1535e-03,  1.3177e-03,  6.2361e-03, -3.9429e-03,\n",
       "                      -1.6749e-02,  3.7209e-03,  9.4102e-03, -5.2147e-05, -4.2308e-03,\n",
       "                       4.3546e-03,  9.0270e-03, -7.4598e-03,  1.8011e-02,  1.2783e-02,\n",
       "                       1.5365e-02,  3.1660e-03,  1.9537e-02,  6.6100e-03,  1.5355e-02,\n",
       "                       8.2375e-04,  2.2604e-02, -3.0727e-03,  1.4347e-03,  3.9175e-03,\n",
       "                      -1.0694e-02,  9.7227e-03,  3.7379e-03, -1.0614e-02,  9.8711e-03,\n",
       "                       8.6267e-03,  9.2707e-03,  9.5532e-03,  1.0918e-02,  7.9944e-03,\n",
       "                       1.5720e-02,  8.2192e-03,  2.4069e-03,  1.0538e-02,  2.2151e-03,\n",
       "                      -5.6736e-03,  2.4276e-03,  4.6402e-03,  8.6080e-03, -3.9128e-03,\n",
       "                       5.4495e-03, -1.1817e-02,  1.3345e-02,  1.6804e-03, -1.2255e-02,\n",
       "                       1.7006e-03,  8.1716e-03,  7.1207e-04, -7.0969e-03,  1.4879e-02,\n",
       "                       3.5225e-03,  3.5022e-03, -7.6848e-04,  6.0321e-03,  1.0899e-03,\n",
       "                       1.0637e-02, -4.5603e-03,  9.2227e-03,  4.2682e-03, -4.5702e-03,\n",
       "                       1.2254e-02,  1.0245e-03,  1.1379e-03,  1.7409e-02,  3.7657e-03,\n",
       "                      -8.7677e-04,  1.4606e-02,  1.3548e-02, -1.1512e-03,  9.5210e-03,\n",
       "                      -1.2912e-02,  1.3969e-02,  5.5293e-03,  9.4927e-03, -3.2621e-03,\n",
       "                       1.9079e-02,  5.5719e-03,  1.5951e-03,  1.0800e-02,  7.4802e-03,\n",
       "                      -2.1610e-03, -6.0193e-04,  3.5014e-03,  4.3637e-03,  9.1421e-03,\n",
       "                      -9.8225e-03, -7.8711e-03,  5.1215e-03,  1.8343e-02,  1.4099e-02,\n",
       "                       6.5407e-03,  9.2268e-03,  1.7546e-03,  3.7921e-03, -1.4732e-02,\n",
       "                       2.4878e-03,  9.6280e-03, -1.3666e-03, -1.5058e-03, -1.2413e-02,\n",
       "                       9.9689e-03,  1.2171e-02,  5.1879e-03,  2.8381e-03,  1.7530e-02,\n",
       "                       2.2984e-02,  1.5166e-02,  1.5671e-02,  8.1236e-03,  1.4446e-02,\n",
       "                      -6.7558e-03,  1.6293e-02,  9.0098e-03,  1.2868e-02,  8.2508e-03,\n",
       "                       1.5619e-02, -2.9553e-03,  1.6187e-02,  5.7071e-03, -5.3338e-03,\n",
       "                       1.3729e-02,  2.3573e-03, -1.7476e-03,  6.9092e-03,  9.2034e-03,\n",
       "                       6.6413e-03,  1.1541e-02,  1.2157e-02,  1.3217e-02,  1.5129e-02,\n",
       "                       8.6912e-03,  1.0545e-03,  4.7117e-03, -2.6611e-03, -1.0338e-02,\n",
       "                       2.1897e-03, -2.4989e-03,  1.7499e-03,  9.1321e-03,  9.3041e-03,\n",
       "                      -6.9190e-04, -1.0907e-02,  1.0950e-02,  9.5735e-04,  1.6206e-02,\n",
       "                       5.3129e-03,  6.0487e-03,  1.2237e-02,  1.0375e-02, -1.2957e-02,\n",
       "                      -8.2148e-04,  7.8217e-04,  1.2156e-02,  3.2341e-03,  7.0064e-03,\n",
       "                      -3.6960e-03,  1.1346e-02, -7.3027e-03, -8.7408e-03,  1.9468e-02,\n",
       "                       7.2535e-03,  1.3081e-02,  9.9193e-03,  5.1627e-03,  1.2959e-02,\n",
       "                       6.4913e-03,  3.7420e-03,  1.0763e-02, -5.3347e-03, -1.0886e-03,\n",
       "                       7.5504e-03, -2.6032e-03,  2.0513e-02,  7.8173e-03,  1.9035e-02,\n",
       "                       3.1612e-03,  2.3347e-02,  1.9537e-02,  2.0485e-02,  1.4688e-03,\n",
       "                      -3.3145e-03,  1.4129e-02, -7.1476e-03,  8.9060e-03,  1.3974e-02,\n",
       "                       2.5388e-03,  1.1654e-02,  1.4502e-02,  9.4520e-03,  1.0603e-02,\n",
       "                      -2.2536e-04,  4.5945e-03, -4.9269e-03,  2.4814e-03, -1.2555e-04,\n",
       "                      -1.2941e-02,  3.7497e-03,  4.9243e-03,  2.3294e-02, -5.0601e-03,\n",
       "                       3.1189e-03, -3.6558e-03,  1.1761e-03, -1.5428e-02,  1.3770e-02,\n",
       "                       8.6235e-03, -1.5004e-03,  1.1128e-02,  2.9118e-03,  2.4640e-03,\n",
       "                       7.7806e-03,  7.7242e-03, -7.3132e-03,  1.0462e-02,  5.2491e-03,\n",
       "                       2.5547e-03,  3.1126e-03,  4.9114e-03,  8.1383e-03,  1.9295e-03,\n",
       "                       1.5132e-02,  2.3174e-03,  9.1508e-03,  1.0946e-03, -8.9490e-03,\n",
       "                       1.7439e-02,  2.2255e-02,  1.6314e-02,  1.6748e-02,  9.9298e-03,\n",
       "                       6.0093e-03], dtype=torch.float64)),\n",
       "             ('6.7.convs.2.1.running_mean',\n",
       "              tensor([ 1.1512e-01, -1.2408e-01,  1.5560e-02, -8.5132e-01, -3.5015e-01,\n",
       "                       4.2217e-02,  1.2696e-01, -7.7264e-01, -1.6587e-01,  4.5704e-01,\n",
       "                       1.8437e-01, -2.0660e-01,  1.8374e-01,  4.2693e-01,  2.3723e-01,\n",
       "                       4.1612e-01,  2.6384e-01, -6.5560e-02,  3.6698e-01, -1.1522e-01,\n",
       "                       4.1765e-01, -2.7076e-02, -6.7437e-01,  6.6193e-01, -2.9848e-01,\n",
       "                      -2.4320e-02, -5.2726e-01, -2.6279e-01, -1.9906e-01,  2.1640e-01,\n",
       "                       2.4205e-01,  7.3942e-01, -4.3810e-01, -4.2748e-01,  9.7373e-01,\n",
       "                       4.6799e-02, -1.1484e-01,  1.9489e-01, -9.9132e-03, -2.1565e-01,\n",
       "                      -3.7611e-03, -2.0207e-01,  4.1583e-01,  1.0388e-01, -1.8847e-01,\n",
       "                       5.9116e-01,  7.7558e-01,  1.8660e-02,  6.1626e-01,  4.5345e-02,\n",
       "                       1.9901e-01, -2.9076e-01, -6.0460e-01, -4.8277e-01, -4.7542e-01,\n",
       "                      -6.3918e-01, -3.8531e-01, -9.7001e-01,  1.5485e-01, -3.9927e-01,\n",
       "                      -8.8332e-02,  1.5185e-01, -2.2313e-01,  8.5599e-02, -5.2458e-01,\n",
       "                      -2.3378e-01, -2.2279e-01,  1.9789e-02, -7.0119e-01,  2.5366e-02,\n",
       "                       3.8578e-01,  1.2038e-01,  2.3105e-01,  2.8917e-01, -3.9217e-01,\n",
       "                       2.2373e-01, -7.5155e-01,  1.3956e-01,  2.8009e-01,  2.9260e-01,\n",
       "                       3.3937e-02,  7.4909e-02, -5.6992e-02, -3.9280e-01, -1.8434e-01,\n",
       "                       8.0144e-01,  3.0549e-01, -1.0238e-02, -2.0356e-01, -2.1057e-01,\n",
       "                       1.9111e-01,  4.2198e-01,  1.5288e-01,  1.4493e-01,  4.0992e-02,\n",
       "                       7.3222e-02,  5.2985e-02, -4.6559e-01,  9.3975e-02, -6.7458e-01,\n",
       "                       3.8736e-01, -2.9781e-01,  4.2128e-01, -9.1290e-02, -4.8175e-01,\n",
       "                       6.7395e-02, -4.4238e-01, -4.1089e-01, -3.8686e-02, -4.1475e-01,\n",
       "                       3.6315e-01,  8.0348e-01, -2.1372e-01,  5.6031e-01,  7.4356e-01,\n",
       "                      -7.8413e-01, -7.2186e-02, -3.9836e-01,  4.1905e-01, -3.6362e-01,\n",
       "                      -2.4260e-01,  2.8073e-01,  3.7776e-01, -5.3364e-01,  8.3810e-02,\n",
       "                      -2.7595e-01, -4.9132e-01, -2.2815e-01, -2.9682e-01, -3.7972e-01,\n",
       "                       3.6437e-01,  2.2522e-02,  4.9806e-02, -1.7390e-01, -3.9235e-02,\n",
       "                      -1.8719e-01, -3.1922e-01,  4.5318e-01, -2.6429e-01, -1.5119e-01,\n",
       "                       1.2889e-01,  1.2184e-01,  3.2751e-01,  2.9640e-01, -1.4548e-02,\n",
       "                       8.6737e-02,  4.9984e-02, -4.8113e-01, -1.9177e-01,  2.4673e-02,\n",
       "                      -4.4606e-02,  8.5359e-01,  3.5509e-02, -1.2024e+00, -7.1799e-02,\n",
       "                       2.8443e-01, -3.4485e-01, -2.1267e-01,  5.2309e-01,  7.7542e-01,\n",
       "                       1.7128e-01,  6.7273e-01, -4.0564e-01,  3.0869e-01,  3.0037e-02,\n",
       "                      -2.1506e-01, -3.0321e-01,  1.7760e-02, -7.1043e-01, -7.5932e-01,\n",
       "                      -5.2463e-01,  9.7043e-02,  1.9130e-01, -2.1352e-01, -1.5883e-01,\n",
       "                      -9.1983e-02,  2.0166e-01,  7.6388e-01, -3.0779e-01,  3.4648e-02,\n",
       "                      -2.2712e-01, -1.8830e-01, -9.3982e-02,  3.6128e-01,  5.3542e-02,\n",
       "                       6.5232e-01,  3.7795e-01,  9.1646e-01,  4.2479e-01, -1.1099e-01,\n",
       "                       2.3958e-01,  5.0025e-01,  5.2223e-01, -7.7900e-01,  1.0615e+00,\n",
       "                       4.9611e-01,  5.0739e-01, -2.3274e-01,  4.7762e-01,  2.6956e-01,\n",
       "                      -1.5073e-02,  1.5371e-01, -3.0923e-01,  2.7307e-02,  2.8011e-01,\n",
       "                       1.0251e-03,  1.9787e-01,  6.5064e-02, -2.2209e-01,  2.9206e-01,\n",
       "                       4.9768e-02, -3.2531e-01,  5.9996e-02,  5.2804e-01,  1.4994e-01,\n",
       "                      -6.9907e-01,  2.1000e-01,  2.6851e-01, -6.0916e-02, -1.1554e-01,\n",
       "                       5.8100e-02,  5.3631e-01,  1.2036e-01,  5.0412e-01, -5.6109e-01,\n",
       "                       7.9764e-02, -2.5969e-01, -4.1700e-01,  5.2554e-02, -1.4842e-01,\n",
       "                      -1.7673e-01,  2.0233e-02,  3.8279e-01, -9.5141e-01, -9.7629e-02,\n",
       "                      -2.5934e-01, -4.9792e-01, -3.0665e-01,  3.6194e-01,  2.3216e-01,\n",
       "                      -4.1103e-01,  4.3288e-01,  1.9449e-01,  1.8349e-01, -4.2285e-01,\n",
       "                       1.2935e-01,  2.4047e-01,  2.7934e-01, -1.8135e-01,  1.6763e-01,\n",
       "                       3.2113e-01,  8.6672e-01, -4.9214e-01, -1.8051e-01, -2.7455e-01,\n",
       "                      -2.3996e-02], dtype=torch.float64)),\n",
       "             ('6.7.convs.2.1.running_var',\n",
       "              tensor([0.1763, 0.2902, 0.1368, 0.3435, 0.2298, 0.4274, 0.3648, 0.3360, 0.3056,\n",
       "                      0.3993, 0.4764, 0.4587, 0.2467, 0.3302, 0.7383, 0.3946, 0.3114, 0.3322,\n",
       "                      0.3356, 0.4499, 0.6490, 0.3187, 0.4116, 0.4618, 0.2705, 0.1629, 0.3687,\n",
       "                      0.3091, 0.3695, 0.4162, 0.3992, 0.6415, 0.2321, 0.4860, 0.4676, 0.3051,\n",
       "                      0.3844, 0.2864, 0.3057, 0.4422, 0.2759, 0.5380, 0.4338, 0.2321, 0.4479,\n",
       "                      0.4959, 0.5419, 0.1503, 0.6391, 0.2968, 0.3082, 0.4063, 0.4344, 0.2169,\n",
       "                      0.7768, 0.4015, 0.5011, 0.7171, 0.5609, 0.3848, 0.1397, 0.3559, 0.1262,\n",
       "                      0.0762, 0.4903, 0.3040, 0.5215, 0.5612, 0.5729, 0.6270, 0.3288, 0.0524,\n",
       "                      0.4380, 0.5868, 0.3569, 0.1323, 0.6394, 0.1275, 0.4430, 0.1727, 0.4795,\n",
       "                      0.1815, 0.1507, 0.4827, 0.3130, 0.5819, 0.3847, 0.4898, 0.1871, 0.3617,\n",
       "                      0.4780, 0.4848, 0.2842, 0.2618, 0.4814, 0.1643, 0.4439, 0.4564, 0.3517,\n",
       "                      0.4019, 0.4228, 0.3466, 0.4442, 0.3137, 0.2915, 0.2062, 0.5094, 0.4589,\n",
       "                      0.3910, 0.2185, 0.2913, 0.6120, 0.3326, 0.3221, 0.4527, 1.0174, 0.3833,\n",
       "                      0.3956, 0.3401, 0.3829, 0.2587, 0.3914, 0.4963, 0.3290, 0.0334, 0.5787,\n",
       "                      0.2445, 0.3282, 0.1185, 0.3047, 0.2896, 0.4533, 0.6680, 0.2997, 0.2964,\n",
       "                      0.0905, 0.5363, 0.3147, 0.4183, 0.3169, 0.4233, 0.0761, 0.4567, 0.3016,\n",
       "                      0.1323, 0.5570, 0.1476, 0.4955, 0.2168, 0.2828, 0.6189, 0.4081, 0.2556,\n",
       "                      0.4254, 0.3023, 0.2096, 0.4307, 0.4043, 0.1449, 0.3941, 0.2938, 0.3435,\n",
       "                      0.2143, 0.4787, 0.3204, 0.5016, 0.5651, 0.2621, 0.4173, 0.5410, 0.3802,\n",
       "                      0.2864, 0.3719, 0.1569, 0.5917, 0.8820, 0.3565, 0.3000, 0.3099, 0.2438,\n",
       "                      0.4095, 0.3067, 0.3394, 0.5169, 0.1664, 0.5502, 0.4005, 0.2460, 0.3348,\n",
       "                      0.1205, 0.4364, 0.2886, 0.3837, 0.3965, 0.4111, 0.6575, 0.4061, 0.6476,\n",
       "                      0.3361, 0.2952, 0.5413, 0.6347, 0.2222, 0.3544, 0.2595, 0.4361, 0.1314,\n",
       "                      0.2743, 0.1941, 0.2709, 0.0599, 0.2339, 0.3215, 0.3650, 0.1493, 0.2679,\n",
       "                      0.5326, 0.2014, 0.0928, 0.3139, 0.3788, 0.4031, 0.2918, 0.2270, 0.5664,\n",
       "                      0.1987, 0.2120, 0.4421, 0.4900, 0.6519, 0.4197, 0.4528, 0.5932, 0.4342,\n",
       "                      0.1531, 0.3731, 0.2432, 0.3530, 0.3094, 0.2008, 0.3349, 0.3511, 0.5080,\n",
       "                      0.1615, 0.2013, 0.2903, 0.5566, 0.2432, 0.2517, 0.4269, 0.2402, 0.4185,\n",
       "                      0.3184, 0.4683, 0.3454, 0.1831], dtype=torch.float64)),\n",
       "             ('6.7.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.7.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.0036],\n",
       "                       [ 0.0511],\n",
       "                       [ 0.0028],\n",
       "                       ...,\n",
       "                       [-0.0313],\n",
       "                       [ 0.0247],\n",
       "                       [-0.0941]],\n",
       "              \n",
       "                      [[ 0.1071],\n",
       "                       [-0.0338],\n",
       "                       [-0.0449],\n",
       "                       ...,\n",
       "                       [ 0.0546],\n",
       "                       [ 0.0115],\n",
       "                       [ 0.0233]],\n",
       "              \n",
       "                      [[-0.1518],\n",
       "                       [-0.0357],\n",
       "                       [ 0.0094],\n",
       "                       ...,\n",
       "                       [-0.0946],\n",
       "                       [-0.1985],\n",
       "                       [-0.0267]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0988],\n",
       "                       [ 0.0083],\n",
       "                       [-0.1697],\n",
       "                       ...,\n",
       "                       [-0.0075],\n",
       "                       [ 0.1128],\n",
       "                       [-0.0732]],\n",
       "              \n",
       "                      [[-0.0474],\n",
       "                       [ 0.0256],\n",
       "                       [-0.0122],\n",
       "                       ...,\n",
       "                       [ 0.0858],\n",
       "                       [-0.0795],\n",
       "                       [-0.0920]],\n",
       "              \n",
       "                      [[ 0.0310],\n",
       "                       [ 0.0110],\n",
       "                       [ 0.0396],\n",
       "                       ...,\n",
       "                       [ 0.0069],\n",
       "                       [ 0.0966],\n",
       "                       [-0.0250]]], dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.0.1.weight',\n",
       "              tensor([1.0092, 0.9771, 0.9662, 0.9659, 0.9897, 0.9591, 0.9641, 0.9586, 0.9697,\n",
       "                      0.9677, 0.9641, 0.9755, 0.9775, 0.9753, 0.9701, 0.9801, 0.9814, 0.9696,\n",
       "                      0.9719, 0.9538, 0.9716, 0.9806, 0.9509, 0.9683, 0.9908, 0.9587, 0.9647,\n",
       "                      0.9898, 0.9796, 0.9570, 0.9657, 0.9903, 0.9774, 0.9639, 0.9829, 0.9768,\n",
       "                      0.9662, 0.9695, 0.9547, 0.9966, 0.9855, 0.9658, 0.9589, 0.9964, 0.9760,\n",
       "                      0.9701, 0.9924, 0.9467, 0.9859, 0.9763, 0.9852, 0.9704, 0.9560, 0.9680,\n",
       "                      0.9877, 0.9593, 0.9637, 0.9697, 0.9758, 0.9844, 0.9901, 0.9739, 0.9951,\n",
       "                      0.9823], dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0088,  0.0015,  0.0130, -0.0094, -0.0120, -0.0068, -0.0032, -0.0185,\n",
       "                       0.0069, -0.0063, -0.0046,  0.0146,  0.0104, -0.0059,  0.0187,  0.0003,\n",
       "                      -0.0042,  0.0099, -0.0079,  0.0138, -0.0124, -0.0003, -0.0069,  0.0107,\n",
       "                       0.0233, -0.0117, -0.0354,  0.0088, -0.0217, -0.0304, -0.0043,  0.0092,\n",
       "                       0.0100, -0.0040,  0.0014, -0.0075, -0.0004, -0.0169, -0.0035,  0.0226,\n",
       "                       0.0109,  0.0037, -0.0106,  0.0139, -0.0015, -0.0102, -0.0053,  0.0062,\n",
       "                      -0.0085, -0.0195,  0.0149, -0.0066,  0.0011,  0.0076,  0.0231, -0.0053,\n",
       "                      -0.0196,  0.0124,  0.0180,  0.0110,  0.0100, -0.0140,  0.0269,  0.0047],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.0.1.running_mean',\n",
       "              tensor([-4.4709e-01,  3.2206e-01,  1.0960e-01, -4.2228e-01,  2.9116e-01,\n",
       "                      -2.3160e-01, -4.1198e-02, -3.1612e-01, -7.0481e-02, -1.9745e-01,\n",
       "                      -9.3042e-01,  1.6199e-01, -6.2554e-01, -5.8980e-01,  8.8372e-01,\n",
       "                       8.8947e-01,  6.5809e-01, -8.4591e-02,  5.3461e-01, -9.0810e-01,\n",
       "                      -5.5649e-02, -1.0478e-01,  5.7140e-01,  8.4632e-01, -6.0553e-01,\n",
       "                      -1.2738e+00,  5.4283e-01, -3.9438e-01,  8.2325e-02,  9.6874e-01,\n",
       "                       1.1020e+00,  1.1073e-01, -4.1470e-01,  1.8697e-02, -6.8545e-01,\n",
       "                      -2.8432e-01, -5.8978e-01, -1.8468e-01, -3.6847e-01,  7.4530e-01,\n",
       "                      -5.5156e-01, -1.1988e-01, -6.0985e-02, -2.7134e-01, -1.2102e-01,\n",
       "                      -2.9494e-02, -5.2589e-01, -6.3264e-01,  1.7223e-01, -6.2544e-01,\n",
       "                      -1.2528e-01,  1.8312e-01, -1.1026e+00,  2.1019e-01, -4.5637e-01,\n",
       "                       7.4434e-01, -5.0559e-01,  3.1560e-01, -3.5955e-01, -1.2320e-01,\n",
       "                      -1.1136e-03,  2.1425e-01, -9.4900e-01,  3.7618e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.0.1.running_var',\n",
       "              tensor([0.0986, 0.2058, 0.5031, 0.3456, 0.0835, 0.3940, 0.1304, 0.1035, 0.1561,\n",
       "                      0.1784, 0.2891, 0.2451, 0.1126, 0.1908, 0.6008, 0.5388, 0.3412, 0.1749,\n",
       "                      0.4356, 0.5420, 0.1034, 0.1150, 0.4273, 0.1447, 0.7029, 0.2361, 0.7409,\n",
       "                      0.1626, 0.2049, 0.8326, 0.5391, 0.1129, 0.5372, 0.1509, 0.0980, 0.2431,\n",
       "                      0.1887, 0.1394, 0.2727, 0.1722, 0.1566, 0.1334, 0.2688, 0.1299, 0.0916,\n",
       "                      0.1377, 0.0975, 0.5128, 0.0850, 0.1087, 0.1034, 0.1730, 0.3888, 0.4493,\n",
       "                      0.1583, 0.4558, 0.1691, 0.3245, 0.1524, 0.0867, 0.1146, 0.4909, 0.1611,\n",
       "                      0.1774], dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.7.convpath.0.1.0.weight',\n",
       "              tensor([[[ 1.2412e-01, -1.4575e-01, -5.3326e-03,  1.1730e-01,  1.4899e-01],\n",
       "                       [ 3.8330e-02, -1.1052e-01, -1.2683e-01, -1.9285e-02,  2.4551e-02],\n",
       "                       [ 5.1682e-02, -7.2520e-02, -6.3742e-02,  2.0752e-02,  4.3689e-02],\n",
       "                       ...,\n",
       "                       [ 1.8805e-03,  2.3706e-03, -3.2104e-02,  1.2766e-01,  1.3889e-02],\n",
       "                       [ 1.2221e-01,  2.7751e-02,  1.8221e-02, -6.5439e-02, -1.5686e-02],\n",
       "                       [-2.9641e-02,  2.8005e-02,  4.9285e-02,  3.4803e-02, -6.1880e-02]],\n",
       "              \n",
       "                      [[ 6.5340e-02, -3.2313e-03,  2.4173e-02,  1.8863e-02, -5.3450e-02],\n",
       "                       [ 5.5821e-02, -2.0517e-01,  4.9215e-02, -1.1132e-02, -4.0468e-02],\n",
       "                       [-2.3987e-01,  2.3344e-02,  9.7126e-02,  3.5584e-02, -2.8119e-02],\n",
       "                       ...,\n",
       "                       [-2.2060e-02,  7.0075e-02,  2.9676e-02,  1.6899e-01,  6.7768e-02],\n",
       "                       [-1.2153e-01,  9.9617e-02,  5.6672e-02, -6.0307e-03,  1.9294e-02],\n",
       "                       [ 3.0212e-02,  8.8563e-02, -2.0466e-01, -1.3635e-02, -1.4361e-01]],\n",
       "              \n",
       "                      [[-2.7867e-02,  1.3783e-01, -1.3297e-01, -1.3861e-01, -1.1029e-02],\n",
       "                       [ 2.0313e-02, -9.1026e-03,  4.6112e-02, -4.5050e-02, -2.4769e-03],\n",
       "                       [-1.4907e-02, -1.0210e-01,  3.9924e-02,  4.4094e-02, -2.0041e-02],\n",
       "                       ...,\n",
       "                       [-4.6338e-02,  1.2205e-01,  1.0770e-01, -1.5950e-03, -4.8658e-02],\n",
       "                       [ 9.8997e-02,  7.1829e-03,  1.4762e-01,  1.1187e-01, -6.8476e-02],\n",
       "                       [ 3.3564e-02, -1.8746e-02,  8.8012e-02, -6.6003e-02,  1.3959e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.1264e-01, -8.6263e-02, -8.6817e-02, -3.3818e-02, -1.1265e-01],\n",
       "                       [-1.8666e-04, -1.0181e-04, -1.0996e-01, -1.4141e-01,  4.1286e-02],\n",
       "                       [-1.3787e-01, -2.8461e-02,  1.2039e-01,  4.2411e-02,  1.3354e-02],\n",
       "                       ...,\n",
       "                       [ 1.1489e-02, -6.3584e-02, -5.0882e-02, -1.8576e-01, -4.8135e-02],\n",
       "                       [-9.2282e-02, -6.1507e-02, -5.9662e-02,  8.7831e-02, -5.1142e-03],\n",
       "                       [-6.3506e-02, -5.6199e-02,  2.8567e-02, -1.0404e-02, -8.5436e-02]],\n",
       "              \n",
       "                      [[ 7.4452e-03,  4.8705e-02, -8.8329e-02,  1.1623e-01,  1.2001e-01],\n",
       "                       [-6.6653e-02,  2.8182e-02,  8.5429e-02,  5.3588e-03, -8.6607e-02],\n",
       "                       [ 7.0300e-02,  1.1531e-01,  1.9382e-02, -7.5359e-02, -8.1458e-02],\n",
       "                       ...,\n",
       "                       [-1.5523e-01, -8.2766e-02,  8.0274e-02,  4.9847e-02,  5.9008e-02],\n",
       "                       [-2.9197e-04, -3.8981e-03, -7.4774e-02, -1.3034e-01, -1.3672e-01],\n",
       "                       [ 9.1060e-02, -8.2616e-02, -1.0709e-01,  1.2206e-01, -7.6210e-02]],\n",
       "              \n",
       "                      [[-8.3405e-02, -1.7157e-01,  7.9575e-02, -6.5555e-02, -7.5904e-03],\n",
       "                       [ 1.6140e-01, -1.4048e-01,  5.3992e-02, -4.9909e-02, -1.0861e-01],\n",
       "                       [ 2.0310e-02,  1.0672e-01,  1.5073e-02,  2.9792e-02, -5.5447e-03],\n",
       "                       ...,\n",
       "                       [ 3.0940e-02, -1.0294e-01, -3.5059e-02, -7.3661e-02, -5.8832e-02],\n",
       "                       [-2.7469e-02, -4.4009e-02,  2.1994e-02, -5.5769e-02, -1.1637e-01],\n",
       "                       [-1.1300e-01, -1.1986e-03,  2.1710e-02,  1.1594e-02, -1.7025e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.1.1.weight',\n",
       "              tensor([0.9898, 0.9804, 0.9557, 0.9557, 0.9742, 0.9635, 0.9893, 0.9810, 0.9807,\n",
       "                      0.9568, 0.9905, 0.9392, 0.9299, 0.9653, 0.9865, 0.9610, 0.9838, 0.9563,\n",
       "                      0.9681, 0.9355, 0.9748, 0.9658, 0.9842, 0.9547, 0.9440, 0.9668, 0.9509,\n",
       "                      1.0212, 0.9698, 0.9772, 0.9688, 0.9705, 1.0089, 0.9422, 0.9700, 0.9782,\n",
       "                      0.9598, 0.9448, 0.9637, 0.9634, 0.9368, 0.9577, 0.9656, 0.9451, 0.9467,\n",
       "                      0.9381, 0.9567, 0.9806, 1.0139, 0.9760, 0.9686, 0.9241, 0.9693, 0.9613,\n",
       "                      0.9571, 0.9580, 1.0190, 0.9173, 0.9746, 0.9845, 0.9855, 0.9758, 0.9914,\n",
       "                      0.9639], dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.1.1.bias',\n",
       "              tensor([ 1.7705e-05, -8.3008e-03, -8.9500e-03, -1.1600e-02,  1.3772e-03,\n",
       "                      -1.4480e-02,  6.3453e-03,  1.1437e-02,  9.4652e-03,  1.6378e-03,\n",
       "                       1.4161e-02, -3.4924e-02,  2.4510e-03, -1.0505e-02,  1.6462e-02,\n",
       "                       1.4814e-03,  2.4546e-03, -6.0179e-04,  1.0428e-02, -1.4090e-02,\n",
       "                       9.6360e-03, -2.4580e-02,  1.8338e-03, -9.9366e-03, -1.8377e-02,\n",
       "                      -1.1654e-02, -6.2127e-03,  2.5345e-02, -2.2487e-02,  4.1988e-03,\n",
       "                      -1.4058e-03, -1.4298e-02,  1.5386e-02, -1.9182e-02, -1.4748e-02,\n",
       "                      -1.3501e-02, -2.0651e-02, -3.2022e-02, -1.9587e-02, -3.8651e-04,\n",
       "                       1.8055e-03, -7.2941e-03, -2.1827e-02, -2.1465e-02, -8.8045e-03,\n",
       "                      -1.6548e-02, -1.3357e-02,  2.4029e-03, -9.6427e-04,  5.0055e-03,\n",
       "                      -7.4223e-03, -1.8886e-02, -1.0791e-02, -1.0968e-02, -2.4477e-02,\n",
       "                       1.5383e-03,  1.4176e-02, -1.1780e-02, -1.8627e-02,  8.8022e-03,\n",
       "                      -2.2120e-03,  1.1865e-03,  1.6239e-02,  4.1783e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.6763,  0.0578, -0.0053,  0.3731, -0.2817,  0.7373,  0.0637, -0.3054,\n",
       "                      -0.6437,  0.5518, -0.2666, -0.6452, -0.2400,  0.1034, -0.5692, -0.2805,\n",
       "                       0.6150, -0.1274,  0.0621, -0.8910,  0.2998, -0.4710,  0.1468,  0.2788,\n",
       "                      -0.4233, -0.7493,  1.1968,  0.3071, -0.0312, -0.6981,  0.8295, -0.3217,\n",
       "                      -0.2529, -0.4806,  0.3241, -0.4653, -0.0445, -0.0626, -0.6874, -0.0265,\n",
       "                      -0.7829,  0.4947,  0.8369,  1.0345, -0.0674, -0.1988,  0.1449,  0.3052,\n",
       "                      -0.2444,  0.5238, -0.5866, -0.4534, -0.5170,  0.6356,  0.0155,  0.8364,\n",
       "                      -0.8019, -0.5732, -0.2875,  0.0413, -0.0495, -0.6168, -0.3610, -1.0018],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.1.1.running_var',\n",
       "              tensor([0.5579, 0.6839, 0.5906, 0.6224, 0.3973, 0.4943, 0.4226, 0.4361, 0.4040,\n",
       "                      0.4330, 0.4934, 0.7146, 0.5885, 0.5839, 0.5970, 0.5087, 0.5757, 0.4699,\n",
       "                      0.4642, 0.6962, 0.9654, 0.5364, 0.4381, 0.6028, 0.5308, 0.5356, 0.6284,\n",
       "                      0.4491, 0.6183, 0.3979, 0.4790, 0.4408, 0.4883, 0.7334, 0.4007, 0.5635,\n",
       "                      0.5321, 1.1600, 0.7589, 0.5066, 0.5667, 0.6680, 0.8357, 0.7251, 0.5130,\n",
       "                      0.7356, 0.6498, 0.6084, 0.6986, 0.6872, 0.5915, 0.4531, 1.1778, 0.7638,\n",
       "                      0.7015, 0.5247, 0.4970, 0.9974, 0.4244, 0.4558, 0.5693, 0.6700, 0.4813,\n",
       "                      0.6685], dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.7.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0307],\n",
       "                       [ 0.0978],\n",
       "                       [-0.0232],\n",
       "                       ...,\n",
       "                       [-0.0448],\n",
       "                       [ 0.1130],\n",
       "                       [ 0.0750]],\n",
       "              \n",
       "                      [[-0.1199],\n",
       "                       [-0.0124],\n",
       "                       [ 0.0272],\n",
       "                       ...,\n",
       "                       [-0.1239],\n",
       "                       [-0.1719],\n",
       "                       [ 0.2395]],\n",
       "              \n",
       "                      [[ 0.2251],\n",
       "                       [ 0.1154],\n",
       "                       [ 0.1930],\n",
       "                       ...,\n",
       "                       [ 0.0430],\n",
       "                       [-0.0167],\n",
       "                       [ 0.0704]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0380],\n",
       "                       [-0.0914],\n",
       "                       [-0.1436],\n",
       "                       ...,\n",
       "                       [ 0.0092],\n",
       "                       [-0.0122],\n",
       "                       [-0.0521]],\n",
       "              \n",
       "                      [[-0.0386],\n",
       "                       [-0.1712],\n",
       "                       [ 0.3236],\n",
       "                       ...,\n",
       "                       [-0.0435],\n",
       "                       [ 0.0551],\n",
       "                       [-0.3284]],\n",
       "              \n",
       "                      [[ 0.0118],\n",
       "                       [-0.0019],\n",
       "                       [ 0.0355],\n",
       "                       ...,\n",
       "                       [ 0.0263],\n",
       "                       [ 0.1237],\n",
       "                       [-0.0376]]], dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.2.1.weight',\n",
       "              tensor([-0.0027, -0.0072,  0.0034,  0.0026, -0.0096,  0.0179,  0.0225,  0.0139,\n",
       "                       0.0148,  0.0590, -0.0233,  0.0062,  0.0317, -0.0154,  0.0134, -0.0442,\n",
       "                       0.0194,  0.0018, -0.0285,  0.0219, -0.0269, -0.0152, -0.0150, -0.0281,\n",
       "                      -0.0029,  0.0091, -0.0048,  0.0155,  0.0056, -0.0238,  0.0160, -0.0311,\n",
       "                      -0.0100, -0.0139,  0.0302, -0.0047,  0.0228,  0.0119,  0.0073,  0.0071,\n",
       "                      -0.0206,  0.0224, -0.0108, -0.0021,  0.0187,  0.0079,  0.0176,  0.0065,\n",
       "                       0.0145, -0.0209, -0.0111, -0.0065,  0.0517,  0.0116, -0.0090, -0.0313,\n",
       "                       0.0172,  0.0195, -0.0054,  0.0134, -0.0033, -0.0225, -0.0033,  0.0005,\n",
       "                       0.0134, -0.0171,  0.0085,  0.0383, -0.0034, -0.0172,  0.0092, -0.0047,\n",
       "                       0.0141,  0.0156, -0.0024, -0.0080,  0.0176,  0.0052,  0.0207,  0.0096,\n",
       "                      -0.0142, -0.0073, -0.0009,  0.0122, -0.0063, -0.0334,  0.0207,  0.0121,\n",
       "                       0.0031, -0.0140,  0.0244,  0.0085, -0.0097, -0.0052, -0.0160,  0.0087,\n",
       "                      -0.0061, -0.0181,  0.0182,  0.0094, -0.0050, -0.0372,  0.0071, -0.0371,\n",
       "                      -0.0192, -0.0198, -0.0189, -0.0215,  0.0281, -0.0043, -0.0009,  0.0184,\n",
       "                      -0.0055, -0.0248,  0.0171,  0.0178, -0.0197, -0.0160, -0.0084, -0.0046,\n",
       "                       0.0067, -0.0081, -0.0039, -0.0168,  0.0089, -0.0031,  0.0177, -0.0286,\n",
       "                       0.0026,  0.0093, -0.0336,  0.0413,  0.0361,  0.0182, -0.0305, -0.0003,\n",
       "                       0.0193, -0.0019,  0.0172,  0.0249, -0.0076,  0.0014, -0.0128,  0.0097,\n",
       "                       0.0042, -0.0061, -0.0177, -0.0429, -0.0143,  0.0116,  0.0095, -0.0071,\n",
       "                       0.0106,  0.0065,  0.0155,  0.0034,  0.0108, -0.0147, -0.0051,  0.0294,\n",
       "                       0.0208, -0.0096,  0.0026,  0.0219, -0.0065,  0.0065,  0.0338, -0.0018,\n",
       "                       0.0024,  0.0172,  0.0130,  0.0023,  0.0192, -0.0047, -0.0393, -0.0183,\n",
       "                       0.0169, -0.0144,  0.0007,  0.0171, -0.0059,  0.0185, -0.0008,  0.0097,\n",
       "                       0.0104,  0.0293, -0.0143, -0.0109, -0.0206, -0.0014,  0.0184, -0.0142,\n",
       "                      -0.0182, -0.0191,  0.0098, -0.0166, -0.0107,  0.0636, -0.0131, -0.0144,\n",
       "                      -0.0208,  0.0289,  0.0305, -0.0209,  0.0181, -0.0160, -0.0105, -0.0180,\n",
       "                       0.0064, -0.0031,  0.0020, -0.0096,  0.0212,  0.0183, -0.0058,  0.0070,\n",
       "                       0.0321,  0.0069,  0.0005,  0.0322,  0.0096,  0.0212,  0.0160,  0.0088,\n",
       "                       0.0087, -0.0073, -0.0146, -0.0208, -0.0165, -0.0273,  0.0244, -0.0143,\n",
       "                       0.0307, -0.0223,  0.0019,  0.0184, -0.0154, -0.0196, -0.0037, -0.0030,\n",
       "                      -0.0172, -0.0193,  0.0317,  0.0036,  0.0067, -0.0023, -0.0173, -0.0065,\n",
       "                       0.0259,  0.0143, -0.0013, -0.0075,  0.0311, -0.0264, -0.0201, -0.0214],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.2.1.bias',\n",
       "              tensor([-6.4310e-04,  3.0266e-03,  1.3523e-02,  1.4955e-02,  1.3641e-03,\n",
       "                       1.9735e-03,  1.1713e-02,  2.0105e-04,  8.8579e-03,  2.3631e-02,\n",
       "                       1.4349e-02, -7.5146e-03,  7.0602e-03, -4.0048e-03,  8.2470e-03,\n",
       "                       3.5324e-03,  2.3340e-02, -3.0539e-03,  1.3073e-02, -3.9840e-03,\n",
       "                      -3.1628e-03,  2.1535e-03,  1.3177e-03,  6.2361e-03, -3.9429e-03,\n",
       "                      -1.6749e-02,  3.7209e-03,  9.4102e-03, -5.2147e-05, -4.2308e-03,\n",
       "                       4.3546e-03,  9.0270e-03, -7.4598e-03,  1.8011e-02,  1.2783e-02,\n",
       "                       1.5365e-02,  3.1660e-03,  1.9537e-02,  6.6100e-03,  1.5355e-02,\n",
       "                       8.2375e-04,  2.2604e-02, -3.0727e-03,  1.4347e-03,  3.9175e-03,\n",
       "                      -1.0694e-02,  9.7227e-03,  3.7379e-03, -1.0614e-02,  9.8711e-03,\n",
       "                       8.6267e-03,  9.2707e-03,  9.5532e-03,  1.0918e-02,  7.9944e-03,\n",
       "                       1.5720e-02,  8.2192e-03,  2.4069e-03,  1.0538e-02,  2.2151e-03,\n",
       "                      -5.6736e-03,  2.4276e-03,  4.6402e-03,  8.6080e-03, -3.9128e-03,\n",
       "                       5.4495e-03, -1.1817e-02,  1.3345e-02,  1.6804e-03, -1.2255e-02,\n",
       "                       1.7006e-03,  8.1716e-03,  7.1207e-04, -7.0969e-03,  1.4879e-02,\n",
       "                       3.5225e-03,  3.5022e-03, -7.6848e-04,  6.0321e-03,  1.0899e-03,\n",
       "                       1.0637e-02, -4.5603e-03,  9.2227e-03,  4.2682e-03, -4.5702e-03,\n",
       "                       1.2254e-02,  1.0245e-03,  1.1379e-03,  1.7409e-02,  3.7657e-03,\n",
       "                      -8.7677e-04,  1.4606e-02,  1.3548e-02, -1.1512e-03,  9.5210e-03,\n",
       "                      -1.2912e-02,  1.3969e-02,  5.5293e-03,  9.4927e-03, -3.2621e-03,\n",
       "                       1.9079e-02,  5.5719e-03,  1.5951e-03,  1.0800e-02,  7.4802e-03,\n",
       "                      -2.1610e-03, -6.0193e-04,  3.5014e-03,  4.3637e-03,  9.1421e-03,\n",
       "                      -9.8225e-03, -7.8711e-03,  5.1215e-03,  1.8343e-02,  1.4099e-02,\n",
       "                       6.5407e-03,  9.2268e-03,  1.7546e-03,  3.7921e-03, -1.4732e-02,\n",
       "                       2.4878e-03,  9.6280e-03, -1.3666e-03, -1.5058e-03, -1.2413e-02,\n",
       "                       9.9689e-03,  1.2171e-02,  5.1879e-03,  2.8381e-03,  1.7530e-02,\n",
       "                       2.2984e-02,  1.5166e-02,  1.5671e-02,  8.1236e-03,  1.4446e-02,\n",
       "                      -6.7558e-03,  1.6293e-02,  9.0098e-03,  1.2868e-02,  8.2508e-03,\n",
       "                       1.5619e-02, -2.9553e-03,  1.6187e-02,  5.7071e-03, -5.3338e-03,\n",
       "                       1.3729e-02,  2.3573e-03, -1.7476e-03,  6.9092e-03,  9.2034e-03,\n",
       "                       6.6413e-03,  1.1541e-02,  1.2157e-02,  1.3217e-02,  1.5129e-02,\n",
       "                       8.6912e-03,  1.0545e-03,  4.7117e-03, -2.6611e-03, -1.0338e-02,\n",
       "                       2.1897e-03, -2.4989e-03,  1.7499e-03,  9.1321e-03,  9.3041e-03,\n",
       "                      -6.9190e-04, -1.0907e-02,  1.0950e-02,  9.5735e-04,  1.6206e-02,\n",
       "                       5.3129e-03,  6.0487e-03,  1.2237e-02,  1.0375e-02, -1.2957e-02,\n",
       "                      -8.2148e-04,  7.8217e-04,  1.2156e-02,  3.2341e-03,  7.0064e-03,\n",
       "                      -3.6960e-03,  1.1346e-02, -7.3027e-03, -8.7408e-03,  1.9468e-02,\n",
       "                       7.2535e-03,  1.3081e-02,  9.9193e-03,  5.1627e-03,  1.2959e-02,\n",
       "                       6.4913e-03,  3.7420e-03,  1.0763e-02, -5.3347e-03, -1.0886e-03,\n",
       "                       7.5504e-03, -2.6032e-03,  2.0513e-02,  7.8173e-03,  1.9035e-02,\n",
       "                       3.1612e-03,  2.3347e-02,  1.9537e-02,  2.0485e-02,  1.4688e-03,\n",
       "                      -3.3145e-03,  1.4129e-02, -7.1476e-03,  8.9060e-03,  1.3974e-02,\n",
       "                       2.5388e-03,  1.1654e-02,  1.4502e-02,  9.4520e-03,  1.0603e-02,\n",
       "                      -2.2536e-04,  4.5945e-03, -4.9269e-03,  2.4814e-03, -1.2555e-04,\n",
       "                      -1.2941e-02,  3.7497e-03,  4.9243e-03,  2.3294e-02, -5.0601e-03,\n",
       "                       3.1189e-03, -3.6558e-03,  1.1761e-03, -1.5428e-02,  1.3770e-02,\n",
       "                       8.6235e-03, -1.5004e-03,  1.1128e-02,  2.9118e-03,  2.4640e-03,\n",
       "                       7.7806e-03,  7.7242e-03, -7.3132e-03,  1.0462e-02,  5.2491e-03,\n",
       "                       2.5547e-03,  3.1126e-03,  4.9114e-03,  8.1383e-03,  1.9295e-03,\n",
       "                       1.5132e-02,  2.3174e-03,  9.1508e-03,  1.0946e-03, -8.9490e-03,\n",
       "                       1.7439e-02,  2.2255e-02,  1.6314e-02,  1.6748e-02,  9.9298e-03,\n",
       "                       6.0093e-03], dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.2.1.running_mean',\n",
       "              tensor([ 1.1512e-01, -1.2408e-01,  1.5560e-02, -8.5132e-01, -3.5015e-01,\n",
       "                       4.2217e-02,  1.2696e-01, -7.7264e-01, -1.6587e-01,  4.5704e-01,\n",
       "                       1.8437e-01, -2.0660e-01,  1.8374e-01,  4.2693e-01,  2.3723e-01,\n",
       "                       4.1612e-01,  2.6384e-01, -6.5560e-02,  3.6698e-01, -1.1522e-01,\n",
       "                       4.1765e-01, -2.7076e-02, -6.7437e-01,  6.6193e-01, -2.9848e-01,\n",
       "                      -2.4320e-02, -5.2726e-01, -2.6279e-01, -1.9906e-01,  2.1640e-01,\n",
       "                       2.4205e-01,  7.3942e-01, -4.3810e-01, -4.2748e-01,  9.7373e-01,\n",
       "                       4.6799e-02, -1.1484e-01,  1.9489e-01, -9.9132e-03, -2.1565e-01,\n",
       "                      -3.7611e-03, -2.0207e-01,  4.1583e-01,  1.0388e-01, -1.8847e-01,\n",
       "                       5.9116e-01,  7.7558e-01,  1.8660e-02,  6.1626e-01,  4.5345e-02,\n",
       "                       1.9901e-01, -2.9076e-01, -6.0460e-01, -4.8277e-01, -4.7542e-01,\n",
       "                      -6.3918e-01, -3.8531e-01, -9.7001e-01,  1.5485e-01, -3.9927e-01,\n",
       "                      -8.8332e-02,  1.5185e-01, -2.2313e-01,  8.5599e-02, -5.2458e-01,\n",
       "                      -2.3378e-01, -2.2279e-01,  1.9789e-02, -7.0119e-01,  2.5366e-02,\n",
       "                       3.8578e-01,  1.2038e-01,  2.3105e-01,  2.8917e-01, -3.9217e-01,\n",
       "                       2.2373e-01, -7.5155e-01,  1.3956e-01,  2.8009e-01,  2.9260e-01,\n",
       "                       3.3937e-02,  7.4909e-02, -5.6992e-02, -3.9280e-01, -1.8434e-01,\n",
       "                       8.0144e-01,  3.0549e-01, -1.0238e-02, -2.0356e-01, -2.1057e-01,\n",
       "                       1.9111e-01,  4.2198e-01,  1.5288e-01,  1.4493e-01,  4.0992e-02,\n",
       "                       7.3222e-02,  5.2985e-02, -4.6559e-01,  9.3975e-02, -6.7458e-01,\n",
       "                       3.8736e-01, -2.9781e-01,  4.2128e-01, -9.1290e-02, -4.8175e-01,\n",
       "                       6.7395e-02, -4.4238e-01, -4.1089e-01, -3.8686e-02, -4.1475e-01,\n",
       "                       3.6315e-01,  8.0348e-01, -2.1372e-01,  5.6031e-01,  7.4356e-01,\n",
       "                      -7.8413e-01, -7.2186e-02, -3.9836e-01,  4.1905e-01, -3.6362e-01,\n",
       "                      -2.4260e-01,  2.8073e-01,  3.7776e-01, -5.3364e-01,  8.3810e-02,\n",
       "                      -2.7595e-01, -4.9132e-01, -2.2815e-01, -2.9682e-01, -3.7972e-01,\n",
       "                       3.6437e-01,  2.2522e-02,  4.9806e-02, -1.7390e-01, -3.9235e-02,\n",
       "                      -1.8719e-01, -3.1922e-01,  4.5318e-01, -2.6429e-01, -1.5119e-01,\n",
       "                       1.2889e-01,  1.2184e-01,  3.2751e-01,  2.9640e-01, -1.4548e-02,\n",
       "                       8.6737e-02,  4.9984e-02, -4.8113e-01, -1.9177e-01,  2.4673e-02,\n",
       "                      -4.4606e-02,  8.5359e-01,  3.5509e-02, -1.2024e+00, -7.1799e-02,\n",
       "                       2.8443e-01, -3.4485e-01, -2.1267e-01,  5.2309e-01,  7.7542e-01,\n",
       "                       1.7128e-01,  6.7273e-01, -4.0564e-01,  3.0869e-01,  3.0037e-02,\n",
       "                      -2.1506e-01, -3.0321e-01,  1.7760e-02, -7.1043e-01, -7.5932e-01,\n",
       "                      -5.2463e-01,  9.7043e-02,  1.9130e-01, -2.1352e-01, -1.5883e-01,\n",
       "                      -9.1983e-02,  2.0166e-01,  7.6388e-01, -3.0779e-01,  3.4648e-02,\n",
       "                      -2.2712e-01, -1.8830e-01, -9.3982e-02,  3.6128e-01,  5.3542e-02,\n",
       "                       6.5232e-01,  3.7795e-01,  9.1646e-01,  4.2479e-01, -1.1099e-01,\n",
       "                       2.3958e-01,  5.0025e-01,  5.2223e-01, -7.7900e-01,  1.0615e+00,\n",
       "                       4.9611e-01,  5.0739e-01, -2.3274e-01,  4.7762e-01,  2.6956e-01,\n",
       "                      -1.5073e-02,  1.5371e-01, -3.0923e-01,  2.7307e-02,  2.8011e-01,\n",
       "                       1.0251e-03,  1.9787e-01,  6.5064e-02, -2.2209e-01,  2.9206e-01,\n",
       "                       4.9768e-02, -3.2531e-01,  5.9996e-02,  5.2804e-01,  1.4994e-01,\n",
       "                      -6.9907e-01,  2.1000e-01,  2.6851e-01, -6.0916e-02, -1.1554e-01,\n",
       "                       5.8100e-02,  5.3631e-01,  1.2036e-01,  5.0412e-01, -5.6109e-01,\n",
       "                       7.9764e-02, -2.5969e-01, -4.1700e-01,  5.2554e-02, -1.4842e-01,\n",
       "                      -1.7673e-01,  2.0233e-02,  3.8279e-01, -9.5141e-01, -9.7629e-02,\n",
       "                      -2.5934e-01, -4.9792e-01, -3.0665e-01,  3.6194e-01,  2.3216e-01,\n",
       "                      -4.1103e-01,  4.3288e-01,  1.9449e-01,  1.8349e-01, -4.2285e-01,\n",
       "                       1.2935e-01,  2.4047e-01,  2.7934e-01, -1.8135e-01,  1.6763e-01,\n",
       "                       3.2113e-01,  8.6672e-01, -4.9214e-01, -1.8051e-01, -2.7455e-01,\n",
       "                      -2.3996e-02], dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.2.1.running_var',\n",
       "              tensor([0.1763, 0.2902, 0.1368, 0.3435, 0.2298, 0.4274, 0.3648, 0.3360, 0.3056,\n",
       "                      0.3993, 0.4764, 0.4587, 0.2467, 0.3302, 0.7383, 0.3946, 0.3114, 0.3322,\n",
       "                      0.3356, 0.4499, 0.6490, 0.3187, 0.4116, 0.4618, 0.2705, 0.1629, 0.3687,\n",
       "                      0.3091, 0.3695, 0.4162, 0.3992, 0.6415, 0.2321, 0.4860, 0.4676, 0.3051,\n",
       "                      0.3844, 0.2864, 0.3057, 0.4422, 0.2759, 0.5380, 0.4338, 0.2321, 0.4479,\n",
       "                      0.4959, 0.5419, 0.1503, 0.6391, 0.2968, 0.3082, 0.4063, 0.4344, 0.2169,\n",
       "                      0.7768, 0.4015, 0.5011, 0.7171, 0.5609, 0.3848, 0.1397, 0.3559, 0.1262,\n",
       "                      0.0762, 0.4903, 0.3040, 0.5215, 0.5612, 0.5729, 0.6270, 0.3288, 0.0524,\n",
       "                      0.4380, 0.5868, 0.3569, 0.1323, 0.6394, 0.1275, 0.4430, 0.1727, 0.4795,\n",
       "                      0.1815, 0.1507, 0.4827, 0.3130, 0.5819, 0.3847, 0.4898, 0.1871, 0.3617,\n",
       "                      0.4780, 0.4848, 0.2842, 0.2618, 0.4814, 0.1643, 0.4439, 0.4564, 0.3517,\n",
       "                      0.4019, 0.4228, 0.3466, 0.4442, 0.3137, 0.2915, 0.2062, 0.5094, 0.4589,\n",
       "                      0.3910, 0.2185, 0.2913, 0.6120, 0.3326, 0.3221, 0.4527, 1.0174, 0.3833,\n",
       "                      0.3956, 0.3401, 0.3829, 0.2587, 0.3914, 0.4963, 0.3290, 0.0334, 0.5787,\n",
       "                      0.2445, 0.3282, 0.1185, 0.3047, 0.2896, 0.4533, 0.6680, 0.2997, 0.2964,\n",
       "                      0.0905, 0.5363, 0.3147, 0.4183, 0.3169, 0.4233, 0.0761, 0.4567, 0.3016,\n",
       "                      0.1323, 0.5570, 0.1476, 0.4955, 0.2168, 0.2828, 0.6189, 0.4081, 0.2556,\n",
       "                      0.4254, 0.3023, 0.2096, 0.4307, 0.4043, 0.1449, 0.3941, 0.2938, 0.3435,\n",
       "                      0.2143, 0.4787, 0.3204, 0.5016, 0.5651, 0.2621, 0.4173, 0.5410, 0.3802,\n",
       "                      0.2864, 0.3719, 0.1569, 0.5917, 0.8820, 0.3565, 0.3000, 0.3099, 0.2438,\n",
       "                      0.4095, 0.3067, 0.3394, 0.5169, 0.1664, 0.5502, 0.4005, 0.2460, 0.3348,\n",
       "                      0.1205, 0.4364, 0.2886, 0.3837, 0.3965, 0.4111, 0.6575, 0.4061, 0.6476,\n",
       "                      0.3361, 0.2952, 0.5413, 0.6347, 0.2222, 0.3544, 0.2595, 0.4361, 0.1314,\n",
       "                      0.2743, 0.1941, 0.2709, 0.0599, 0.2339, 0.3215, 0.3650, 0.1493, 0.2679,\n",
       "                      0.5326, 0.2014, 0.0928, 0.3139, 0.3788, 0.4031, 0.2918, 0.2270, 0.5664,\n",
       "                      0.1987, 0.2120, 0.4421, 0.4900, 0.6519, 0.4197, 0.4528, 0.5932, 0.4342,\n",
       "                      0.1531, 0.3731, 0.2432, 0.3530, 0.3094, 0.2008, 0.3349, 0.3511, 0.5080,\n",
       "                      0.1615, 0.2013, 0.2903, 0.5566, 0.2432, 0.2517, 0.4269, 0.2402, 0.4185,\n",
       "                      0.3184, 0.4683, 0.3454, 0.1831], dtype=torch.float64)),\n",
       "             ('6.7.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.8.convs.0.0.weight',\n",
       "              tensor([[[ 0.0887],\n",
       "                       [ 0.1908],\n",
       "                       [ 0.0004],\n",
       "                       ...,\n",
       "                       [-0.1929],\n",
       "                       [-0.0329],\n",
       "                       [-0.1482]],\n",
       "              \n",
       "                      [[ 0.0307],\n",
       "                       [-0.0216],\n",
       "                       [ 0.0644],\n",
       "                       ...,\n",
       "                       [-0.0112],\n",
       "                       [ 0.0572],\n",
       "                       [-0.0078]],\n",
       "              \n",
       "                      [[ 0.0191],\n",
       "                       [-0.0794],\n",
       "                       [ 0.1195],\n",
       "                       ...,\n",
       "                       [ 0.0226],\n",
       "                       [ 0.1501],\n",
       "                       [-0.0330]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1072],\n",
       "                       [-0.1276],\n",
       "                       [-0.0823],\n",
       "                       ...,\n",
       "                       [ 0.0120],\n",
       "                       [ 0.0449],\n",
       "                       [ 0.1959]],\n",
       "              \n",
       "                      [[ 0.0403],\n",
       "                       [-0.0069],\n",
       "                       [-0.0745],\n",
       "                       ...,\n",
       "                       [-0.0265],\n",
       "                       [-0.0248],\n",
       "                       [ 0.1112]],\n",
       "              \n",
       "                      [[ 0.1272],\n",
       "                       [-0.0481],\n",
       "                       [ 0.0945],\n",
       "                       ...,\n",
       "                       [-0.1008],\n",
       "                       [ 0.0964],\n",
       "                       [-0.0450]]], dtype=torch.float64)),\n",
       "             ('6.8.convs.0.1.weight',\n",
       "              tensor([0.9432, 0.9569, 0.9626, 0.9683, 0.9310, 0.9730, 0.9851, 0.9899, 0.9576,\n",
       "                      0.9435, 0.9778, 0.9775, 0.9517, 0.9398, 0.9644, 0.9703, 0.9685, 0.9793,\n",
       "                      0.9998, 0.9856, 0.9785, 0.9639, 0.9547, 0.9304, 0.9758, 0.9599, 0.9863,\n",
       "                      0.9660, 0.9646, 0.9637, 0.9421, 0.9563, 0.9599, 0.9494, 0.9684, 0.9598,\n",
       "                      0.9766, 0.9847, 0.9537, 0.9395, 0.9668, 0.9661, 0.9245, 0.9577, 0.9434,\n",
       "                      0.9514, 0.9694, 0.9903, 0.9736, 0.9632, 0.9549, 0.9508, 0.9575, 0.9883,\n",
       "                      0.9784, 0.9684, 0.9587, 0.9708, 0.9473, 0.9809, 0.9349, 0.9334, 0.9571,\n",
       "                      0.9861], dtype=torch.float64)),\n",
       "             ('6.8.convs.0.1.bias',\n",
       "              tensor([ 3.1957e-02,  1.0140e-02, -1.6584e-03, -1.0707e-02,  7.1319e-03,\n",
       "                       7.3430e-03,  2.6610e-02,  2.0424e-02,  3.4163e-03, -2.4627e-02,\n",
       "                       5.8369e-03,  2.2534e-02, -3.6009e-03, -2.1155e-02,  2.1622e-02,\n",
       "                      -5.5873e-03,  4.1890e-03,  1.1985e-02,  3.1749e-02,  1.2038e-02,\n",
       "                      -2.6527e-03,  1.9104e-06,  1.1475e-02, -2.4049e-03,  1.8556e-02,\n",
       "                       2.0758e-03,  1.2750e-02, -5.8136e-03, -4.4656e-03, -1.1002e-02,\n",
       "                      -4.6054e-02, -1.1836e-02,  2.6681e-03,  7.7375e-03, -2.9621e-03,\n",
       "                      -2.4369e-03,  4.0917e-02,  1.3131e-02, -1.0694e-02,  1.4191e-03,\n",
       "                      -2.2527e-02,  3.8883e-03,  1.4124e-02, -7.3241e-04, -6.1489e-03,\n",
       "                      -2.5508e-04,  2.3807e-03,  7.3859e-03,  2.2536e-02, -2.4591e-02,\n",
       "                       7.5150e-03,  2.1880e-02,  1.9122e-02,  3.9752e-03,  1.6702e-02,\n",
       "                       8.1483e-03, -1.5730e-02,  6.9830e-03,  1.1226e-02,  1.4420e-02,\n",
       "                      -3.0214e-02, -1.9035e-02, -7.4814e-03,  1.1744e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convs.0.1.running_mean',\n",
       "              tensor([-0.2204, -0.0278,  0.6457,  0.0336, -0.8354, -0.0798,  0.1228, -0.2911,\n",
       "                      -0.0618, -0.2694, -0.6318, -0.4279, -0.0570, -0.2815,  0.1825,  1.1432,\n",
       "                       0.0067, -0.5452, -0.4348,  0.0697,  0.2302, -0.8138,  0.7798, -0.7765,\n",
       "                       0.1846,  0.2630, -0.6822,  0.5416,  0.8783,  0.5059,  1.1241,  0.8124,\n",
       "                      -0.1576, -0.2033,  0.5400, -0.0798, -0.5909,  0.4723, -0.2114, -0.3814,\n",
       "                       1.2772, -0.7225, -1.8504, -0.5363,  0.2021, -0.4371,  1.3005,  0.3725,\n",
       "                       0.6895,  0.4853,  1.2390, -0.3840, -0.1612,  0.4755, -0.2910,  0.5571,\n",
       "                       1.4032, -0.0836, -0.1793,  0.0949,  1.1415,  0.1029, -0.8563, -0.0079],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convs.0.1.running_var',\n",
       "              tensor([0.4582, 0.1025, 0.5356, 0.1875, 0.4602, 0.1749, 0.2905, 0.4761, 0.2384,\n",
       "                      0.2034, 0.1193, 0.1812, 0.2275, 0.1862, 0.1612, 0.4259, 0.2005, 0.1092,\n",
       "                      0.0852, 0.1384, 0.1522, 0.1879, 0.1098, 0.3722, 0.1840, 0.0961, 0.1130,\n",
       "                      0.1514, 0.2868, 0.1737, 0.4457, 0.9146, 0.4892, 0.1985, 0.3453, 0.0886,\n",
       "                      0.2218, 0.7072, 0.1335, 0.3276, 0.4631, 0.1154, 0.7546, 0.2176, 0.3564,\n",
       "                      0.6445, 0.5307, 0.1086, 0.2054, 0.2893, 0.9250, 0.2823, 0.3166, 0.1220,\n",
       "                      0.1646, 0.5879, 0.5408, 0.1074, 0.3481, 0.1272, 1.5457, 0.2720, 0.1630,\n",
       "                      0.1514], dtype=torch.float64)),\n",
       "             ('6.8.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.8.convs.1.0.weight',\n",
       "              tensor([[[-0.0518,  0.0130,  0.0303, -0.0033,  0.0088],\n",
       "                       [ 0.0079, -0.0090, -0.1094,  0.0184, -0.0313],\n",
       "                       [-0.0506, -0.0159,  0.0017, -0.0637, -0.0266],\n",
       "                       ...,\n",
       "                       [-0.1071, -0.0035, -0.0646,  0.0441,  0.0364],\n",
       "                       [ 0.0847, -0.0741, -0.0224,  0.1212,  0.0829],\n",
       "                       [-0.0498, -0.0430,  0.0048,  0.0112, -0.1283]],\n",
       "              \n",
       "                      [[-0.0391,  0.0046,  0.0049, -0.0219, -0.0021],\n",
       "                       [ 0.0583, -0.0112,  0.0816, -0.0234,  0.0174],\n",
       "                       [-0.0777, -0.1587,  0.0602, -0.1133,  0.2556],\n",
       "                       ...,\n",
       "                       [ 0.0020,  0.0465, -0.1044,  0.0383,  0.0902],\n",
       "                       [ 0.0343,  0.0458, -0.0417,  0.0445,  0.0563],\n",
       "                       [ 0.1732,  0.1177, -0.0525,  0.1464, -0.0788]],\n",
       "              \n",
       "                      [[ 0.0322,  0.0898,  0.0767, -0.0267,  0.0408],\n",
       "                       [ 0.0743,  0.0236,  0.0147, -0.0565,  0.0610],\n",
       "                       [-0.1611,  0.2096,  0.0791,  0.0728,  0.0279],\n",
       "                       ...,\n",
       "                       [-0.0043, -0.0694, -0.0986,  0.0419,  0.1003],\n",
       "                       [-0.0048,  0.0044,  0.1156,  0.0230, -0.0379],\n",
       "                       [ 0.0152,  0.0301, -0.0630,  0.0004, -0.0766]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0630, -0.0219, -0.0319, -0.0581, -0.0456],\n",
       "                       [-0.0712,  0.0174, -0.1281, -0.0300, -0.0455],\n",
       "                       [ 0.0344,  0.0816, -0.0424, -0.0353, -0.0677],\n",
       "                       ...,\n",
       "                       [ 0.0751,  0.0141, -0.0146, -0.0573,  0.0082],\n",
       "                       [ 0.0400,  0.1133, -0.0071,  0.0310, -0.0379],\n",
       "                       [-0.0820, -0.0514, -0.0392, -0.0518, -0.0698]],\n",
       "              \n",
       "                      [[ 0.0050,  0.1157,  0.0725,  0.1076, -0.0227],\n",
       "                       [ 0.0059, -0.0630,  0.0211,  0.0814, -0.1217],\n",
       "                       [-0.1179, -0.0032, -0.1050, -0.0140, -0.1057],\n",
       "                       ...,\n",
       "                       [ 0.0331,  0.0176, -0.0088,  0.0416,  0.0565],\n",
       "                       [-0.1267, -0.0988, -0.0760, -0.0111,  0.0099],\n",
       "                       [ 0.0289,  0.1339,  0.1049, -0.0289,  0.0315]],\n",
       "              \n",
       "                      [[ 0.0555,  0.0048,  0.0929, -0.2199,  0.1547],\n",
       "                       [-0.0288,  0.0533, -0.0920,  0.0339, -0.0652],\n",
       "                       [-0.0466, -0.0596, -0.0319,  0.0675,  0.0960],\n",
       "                       ...,\n",
       "                       [-0.1127,  0.1021, -0.1163,  0.0227, -0.0102],\n",
       "                       [ 0.0334, -0.0106,  0.0057,  0.0829,  0.0593],\n",
       "                       [-0.1318, -0.0246, -0.0258, -0.0428, -0.0154]]], dtype=torch.float64)),\n",
       "             ('6.8.convs.1.1.weight',\n",
       "              tensor([0.9278, 0.9500, 0.9551, 0.9541, 0.9388, 0.9921, 0.9598, 0.9534, 0.9565,\n",
       "                      0.9248, 0.9488, 0.9669, 0.9173, 0.9720, 0.9524, 0.9150, 0.9493, 0.9581,\n",
       "                      0.9647, 0.9338, 0.9757, 0.9542, 0.9513, 0.9656, 0.9632, 0.9724, 0.9585,\n",
       "                      0.9527, 0.9482, 0.9589, 0.9281, 0.9948, 0.9660, 0.9435, 0.9560, 0.9793,\n",
       "                      0.9356, 0.9536, 1.0001, 0.9809, 0.9506, 0.9503, 0.9945, 0.9674, 0.9510,\n",
       "                      0.9493, 0.9584, 0.9512, 0.9450, 0.9519, 0.9568, 0.9763, 0.9774, 0.9326,\n",
       "                      0.9630, 0.9604, 0.9735, 0.9399, 0.9568, 0.9392, 0.9693, 1.0034, 0.9666,\n",
       "                      0.9075], dtype=torch.float64)),\n",
       "             ('6.8.convs.1.1.bias',\n",
       "              tensor([-0.0088, -0.0028, -0.0014,  0.0045, -0.0145,  0.0160, -0.0064,  0.0038,\n",
       "                      -0.0168, -0.0129, -0.0181,  0.0070, -0.0226, -0.0031,  0.0045, -0.0261,\n",
       "                      -0.0199, -0.0048,  0.0068, -0.0377,  0.0149,  0.0051,  0.0070, -0.0243,\n",
       "                       0.0128, -0.0056, -0.0150, -0.0004,  0.0118,  0.0154, -0.0149,  0.0052,\n",
       "                       0.0122, -0.0018, -0.0049,  0.0053, -0.0112, -0.0059,  0.0028, -0.0050,\n",
       "                      -0.0138,  0.0017,  0.0344,  0.0010,  0.0092, -0.0243, -0.0063, -0.0213,\n",
       "                       0.0029, -0.0055,  0.0131, -0.0009, -0.0124, -0.0060, -0.0158, -0.0096,\n",
       "                       0.0107, -0.0114, -0.0173, -0.0238, -0.0017,  0.0032,  0.0090, -0.0083],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convs.1.1.running_mean',\n",
       "              tensor([-1.6298,  0.5967, -0.2267, -0.1021, -0.6781, -0.4661,  0.1649, -0.5324,\n",
       "                      -0.2398, -0.5106,  0.8791,  0.2589, -0.4289, -0.1792,  0.2552, -0.2599,\n",
       "                       0.1087,  0.8097,  0.1797,  0.0409,  0.1093, -0.4343, -0.3386,  0.4378,\n",
       "                      -1.3861, -0.6613,  0.5684,  0.0300, -0.0107,  0.2593, -0.0712, -0.0664,\n",
       "                      -0.1594, -0.6737, -0.4002,  0.3974,  0.1830, -0.4593,  0.0969, -0.6035,\n",
       "                       0.8069, -0.1840,  0.1336,  0.2122, -1.0001,  0.4269,  0.2946,  0.2759,\n",
       "                      -0.1767,  0.2423, -0.2035, -0.0995,  0.3086,  0.1128,  0.2670,  0.2479,\n",
       "                       0.4058,  0.1430,  1.0256, -0.2720,  0.4635,  0.0147,  0.3127, -0.1612],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convs.1.1.running_var',\n",
       "              tensor([1.4099, 0.8047, 0.4382, 0.4238, 0.5661, 0.5920, 0.7461, 0.5145, 0.5038,\n",
       "                      0.8165, 0.5047, 0.7378, 0.7954, 0.5966, 0.5340, 1.1785, 0.4054, 0.6506,\n",
       "                      0.6381, 0.5328, 0.5028, 0.5062, 0.9323, 0.4126, 0.5714, 0.3687, 0.5791,\n",
       "                      0.4191, 0.4472, 0.5699, 0.5047, 0.4863, 0.4551, 0.7216, 0.5317, 0.6278,\n",
       "                      0.7575, 0.5333, 0.4858, 0.6514, 0.8848, 0.5382, 0.4358, 0.5524, 0.9425,\n",
       "                      0.9093, 0.4492, 0.3963, 0.4348, 0.5894, 0.5349, 0.4678, 0.5427, 1.0316,\n",
       "                      0.3913, 0.9412, 0.5207, 0.6250, 0.5527, 0.6484, 0.6759, 0.3738, 0.5024,\n",
       "                      0.8171], dtype=torch.float64)),\n",
       "             ('6.8.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.8.convs.2.0.weight',\n",
       "              tensor([[[ 0.0015],\n",
       "                       [ 0.0618],\n",
       "                       [-0.1841],\n",
       "                       ...,\n",
       "                       [-0.0679],\n",
       "                       [-0.0676],\n",
       "                       [-0.0832]],\n",
       "              \n",
       "                      [[ 0.0505],\n",
       "                       [ 0.0263],\n",
       "                       [-0.1381],\n",
       "                       ...,\n",
       "                       [-0.1041],\n",
       "                       [ 0.1079],\n",
       "                       [ 0.0236]],\n",
       "              \n",
       "                      [[-0.1187],\n",
       "                       [ 0.0748],\n",
       "                       [ 0.1667],\n",
       "                       ...,\n",
       "                       [ 0.0186],\n",
       "                       [ 0.3160],\n",
       "                       [ 0.0510]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.2023],\n",
       "                       [-0.0581],\n",
       "                       [-0.0273],\n",
       "                       ...,\n",
       "                       [-0.0748],\n",
       "                       [ 0.0278],\n",
       "                       [ 0.0081]],\n",
       "              \n",
       "                      [[ 0.0643],\n",
       "                       [ 0.0100],\n",
       "                       [-0.0992],\n",
       "                       ...,\n",
       "                       [-0.1634],\n",
       "                       [ 0.1541],\n",
       "                       [-0.0571]],\n",
       "              \n",
       "                      [[-0.0304],\n",
       "                       [-0.1885],\n",
       "                       [ 0.2055],\n",
       "                       ...,\n",
       "                       [-0.0573],\n",
       "                       [ 0.1835],\n",
       "                       [ 0.1255]]], dtype=torch.float64)),\n",
       "             ('6.8.convs.2.1.weight',\n",
       "              tensor([-2.0660e-03,  6.1894e-04,  6.3250e-03,  1.7064e-02, -1.0099e-02,\n",
       "                       1.7673e-02, -3.9634e-03, -4.3932e-02, -1.2278e-02,  6.6614e-04,\n",
       "                      -4.8536e-03,  2.8817e-02, -1.1313e-02, -6.4411e-03, -2.0540e-02,\n",
       "                       3.7784e-02, -1.2620e-02,  5.0773e-03, -1.0444e-02, -2.1709e-03,\n",
       "                       7.8726e-03, -4.7571e-03, -2.9992e-03, -5.1889e-03,  1.7685e-02,\n",
       "                       1.2147e-02, -8.9687e-03,  1.3441e-02,  6.2530e-03,  1.8847e-02,\n",
       "                      -1.5009e-02, -9.7421e-03, -8.4602e-04, -2.3385e-02,  9.1652e-03,\n",
       "                       1.2196e-03, -1.6587e-02, -9.9816e-03,  8.8335e-03,  3.7598e-03,\n",
       "                      -9.4836e-03,  8.7293e-03,  2.1139e-02, -2.7109e-02, -1.3489e-02,\n",
       "                      -9.9482e-03,  1.4132e-02,  2.8747e-02,  2.0804e-02,  6.0150e-03,\n",
       "                       2.7892e-02,  1.1385e-02, -1.9096e-04,  1.4533e-02,  1.6828e-02,\n",
       "                       5.2330e-02,  5.3676e-03,  1.5263e-02,  3.8217e-03,  1.1180e-03,\n",
       "                       5.4495e-03, -1.5431e-02,  4.9208e-03, -1.2997e-02,  9.7065e-03,\n",
       "                      -2.1196e-03, -9.5240e-03,  5.1660e-03,  2.1239e-02, -7.1946e-03,\n",
       "                       2.4575e-02,  2.1187e-02,  1.6203e-03, -9.2737e-04, -9.9068e-03,\n",
       "                       8.1525e-03,  2.1399e-02,  3.1293e-02, -4.1452e-03,  2.5280e-02,\n",
       "                      -1.4889e-02,  2.9710e-02,  2.2623e-02,  1.7331e-02, -2.1384e-02,\n",
       "                      -1.2634e-02,  1.7030e-03, -3.5038e-02,  1.5710e-03, -2.2587e-02,\n",
       "                      -7.5919e-03,  1.1272e-02, -8.4926e-03, -3.2500e-03, -4.8428e-03,\n",
       "                       2.2297e-02, -2.0893e-02, -1.4037e-02, -9.2617e-03,  1.3383e-02,\n",
       "                      -5.2591e-03,  2.2231e-02, -1.8991e-04, -1.8237e-02, -1.5163e-02,\n",
       "                      -1.8749e-02,  1.1699e-03,  8.8025e-03,  2.2007e-02,  1.8458e-02,\n",
       "                       2.2396e-05, -8.8249e-03, -1.9638e-02, -7.0404e-03,  1.0568e-02,\n",
       "                      -9.4188e-03, -2.9178e-03, -7.9452e-03,  1.4475e-02,  1.4389e-02,\n",
       "                       1.1300e-02, -1.5614e-02, -1.3186e-02, -1.2972e-02,  3.3864e-03,\n",
       "                       4.2606e-03,  3.0071e-02,  1.6589e-02, -1.3806e-02, -1.0296e-02,\n",
       "                       8.7019e-03, -3.9943e-03, -1.0120e-02,  2.5465e-03,  1.1756e-02,\n",
       "                       1.6570e-02, -1.4678e-02,  1.7318e-02, -4.3515e-03,  9.9493e-03,\n",
       "                       6.3169e-03, -1.9369e-02,  1.0131e-02,  4.9987e-03,  9.5437e-03,\n",
       "                       5.4485e-03, -2.0513e-02, -1.0796e-02,  7.6728e-03,  2.1991e-03,\n",
       "                       1.8767e-02, -3.6478e-03, -3.7939e-02, -1.1497e-02, -2.0247e-03,\n",
       "                       1.1245e-02, -1.0048e-02, -5.9844e-03, -1.7954e-02, -2.5308e-03,\n",
       "                      -7.8639e-03, -2.1146e-02,  6.5625e-03, -3.7818e-02, -3.1265e-02,\n",
       "                       2.0494e-02, -6.8358e-03, -2.1304e-02,  2.4668e-02, -2.2074e-02,\n",
       "                       7.6657e-04,  7.2933e-03,  4.7382e-03,  3.4108e-02,  2.0982e-02,\n",
       "                      -6.7730e-03, -4.7803e-03, -4.4514e-03, -1.7506e-03, -2.0707e-02,\n",
       "                       9.4255e-03, -1.4542e-02, -2.2228e-02, -1.0310e-02,  2.6845e-02,\n",
       "                      -4.6161e-04, -1.3318e-02,  9.7507e-03, -5.7632e-04,  1.2703e-02,\n",
       "                       6.8255e-03,  3.1781e-03, -4.1467e-02, -1.6447e-03, -1.0374e-02,\n",
       "                       2.5607e-02,  1.2754e-03,  8.0096e-03,  1.1529e-02, -1.0046e-02,\n",
       "                      -7.8666e-05, -1.5904e-02, -5.1813e-03, -2.2866e-02, -1.3025e-02,\n",
       "                      -9.0697e-03, -9.5688e-03, -1.4253e-03, -1.0787e-02, -9.0183e-03,\n",
       "                      -2.3644e-02,  1.0649e-02,  5.6574e-03,  2.1107e-02, -9.9541e-03,\n",
       "                      -8.3224e-03,  1.4262e-02,  1.1781e-02,  8.4630e-03,  3.3506e-02,\n",
       "                       2.7988e-03,  9.4050e-04, -8.3739e-04,  1.8818e-02,  7.9902e-03,\n",
       "                       2.7959e-02, -5.3950e-03, -5.4555e-03, -7.4225e-03, -6.0851e-03,\n",
       "                      -7.8907e-03, -1.0638e-03,  2.8860e-02,  3.3249e-02,  1.1778e-02,\n",
       "                       1.5321e-03, -2.7062e-02,  1.8792e-03,  3.1795e-02,  2.9848e-03,\n",
       "                      -1.1837e-03, -2.6049e-02,  4.5981e-03, -7.0127e-03, -1.2022e-02,\n",
       "                      -1.9621e-02, -5.9119e-03,  6.3127e-03,  4.7713e-03,  3.5127e-02,\n",
       "                      -4.3142e-03,  1.0485e-02, -6.9682e-03,  1.6972e-03,  6.8555e-03,\n",
       "                      -9.9427e-03], dtype=torch.float64)),\n",
       "             ('6.8.convs.2.1.bias',\n",
       "              tensor([-0.0004,  0.0032,  0.0135,  0.0151,  0.0008,  0.0096,  0.0081, -0.0006,\n",
       "                       0.0102,  0.0146,  0.0140, -0.0067,  0.0067, -0.0039,  0.0099,  0.0041,\n",
       "                       0.0233, -0.0028,  0.0107, -0.0033, -0.0036,  0.0012,  0.0033,  0.0054,\n",
       "                      -0.0070, -0.0169,  0.0024,  0.0033, -0.0003,  0.0018,  0.0056,  0.0093,\n",
       "                      -0.0065,  0.0181,  0.0095,  0.0156,  0.0026,  0.0160,  0.0051,  0.0152,\n",
       "                       0.0002,  0.0197, -0.0114,  0.0020,  0.0048, -0.0102,  0.0085,  0.0027,\n",
       "                      -0.0110,  0.0088,  0.0088,  0.0077,  0.0059,  0.0104,  0.0074,  0.0144,\n",
       "                       0.0084,  0.0010,  0.0119,  0.0019, -0.0053,  0.0016,  0.0044,  0.0085,\n",
       "                      -0.0049,  0.0057, -0.0109,  0.0147,  0.0002, -0.0128,  0.0030,  0.0083,\n",
       "                       0.0011, -0.0070,  0.0149,  0.0019,  0.0035,  0.0080,  0.0066,  0.0011,\n",
       "                       0.0094, -0.0057,  0.0097,  0.0047, -0.0034,  0.0181,  0.0001,  0.0021,\n",
       "                       0.0173,  0.0037,  0.0014,  0.0142,  0.0129, -0.0010,  0.0098, -0.0133,\n",
       "                       0.0099,  0.0029,  0.0088, -0.0027,  0.0192,  0.0141,  0.0037,  0.0090,\n",
       "                       0.0049, -0.0013, -0.0012,  0.0031,  0.0052,  0.0099, -0.0088, -0.0063,\n",
       "                       0.0053,  0.0184,  0.0120,  0.0064,  0.0081,  0.0024,  0.0047, -0.0157,\n",
       "                       0.0039,  0.0095, -0.0010, -0.0018, -0.0139,  0.0101,  0.0168,  0.0038,\n",
       "                       0.0030,  0.0172,  0.0085,  0.0138,  0.0146,  0.0108,  0.0149, -0.0082,\n",
       "                       0.0155,  0.0092,  0.0136,  0.0066,  0.0154, -0.0035,  0.0181,  0.0047,\n",
       "                      -0.0082,  0.0140, -0.0005, -0.0013,  0.0067,  0.0115,  0.0062,  0.0120,\n",
       "                       0.0123,  0.0132,  0.0123,  0.0086, -0.0006,  0.0027, -0.0018, -0.0114,\n",
       "                       0.0024, -0.0011,  0.0006,  0.0076,  0.0106, -0.0016, -0.0117,  0.0105,\n",
       "                       0.0009,  0.0165,  0.0046,  0.0046,  0.0120,  0.0105, -0.0135, -0.0006,\n",
       "                       0.0010,  0.0110,  0.0023,  0.0067, -0.0049,  0.0111, -0.0064, -0.0093,\n",
       "                       0.0194,  0.0074,  0.0140,  0.0109,  0.0025,  0.0120,  0.0072,  0.0026,\n",
       "                       0.0095, -0.0056, -0.0011,  0.0072, -0.0013,  0.0126,  0.0068,  0.0216,\n",
       "                       0.0008,  0.0223,  0.0202,  0.0229, -0.0002, -0.0038,  0.0110, -0.0039,\n",
       "                       0.0085,  0.0141,  0.0043,  0.0113,  0.0141,  0.0079,  0.0096, -0.0028,\n",
       "                       0.0043, -0.0052,  0.0023, -0.0013, -0.0132,  0.0028,  0.0042,  0.0219,\n",
       "                      -0.0047,  0.0020, -0.0040,  0.0006, -0.0151,  0.0148,  0.0076, -0.0026,\n",
       "                       0.0111, -0.0020,  0.0023,  0.0080,  0.0080, -0.0030,  0.0104,  0.0045,\n",
       "                       0.0020,  0.0014,  0.0021,  0.0086,  0.0021,  0.0151,  0.0051,  0.0079,\n",
       "                      -0.0009, -0.0093,  0.0170,  0.0228,  0.0151,  0.0149,  0.0099,  0.0021],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convs.2.1.running_mean',\n",
       "              tensor([ 0.1159, -0.0137,  0.7410, -0.1477,  0.1661,  0.3967,  0.0793,  0.5611,\n",
       "                       0.1799, -0.0319, -0.2336,  0.5195, -0.1289, -0.2306, -0.6580, -0.5116,\n",
       "                       0.6962, -0.2890, -0.1711, -0.2023,  0.1790, -0.1867, -0.4372,  0.0428,\n",
       "                       0.1156,  0.2690, -0.4055, -0.3229, -0.3581,  0.2676, -0.2529,  0.4645,\n",
       "                      -0.4268, -0.0861, -0.5112, -0.3824,  0.7574,  0.1442, -0.0995,  0.4144,\n",
       "                      -0.0211, -0.2888, -0.1424, -0.1503, -0.4178,  0.8322,  0.4718,  0.0326,\n",
       "                       0.7618,  0.3057, -0.2362,  0.1053,  0.2424, -0.7095,  0.1386,  0.1266,\n",
       "                       0.5873, -0.0427,  0.1808,  0.3648,  0.1174,  0.0725, -0.2795, -0.0715,\n",
       "                       0.5193, -0.3861,  0.1673,  0.4257,  0.4400, -0.7069, -0.4454, -0.4281,\n",
       "                      -0.1290, -0.0208,  0.1143, -0.0503,  0.0045, -0.2067, -0.4642, -0.2433,\n",
       "                       0.0459,  0.7877,  0.0177, -0.3648,  0.1846,  0.4169, -0.4395, -0.5843,\n",
       "                       0.4567,  0.1417, -0.2083,  0.3490,  0.9426,  0.4789,  0.0276, -0.3291,\n",
       "                       0.8330,  0.2574, -0.1018,  0.1159,  0.1421,  0.2113,  0.0988,  0.3412,\n",
       "                      -0.4689,  0.3106, -0.4914,  0.5967,  0.0604,  0.3448,  0.1001, -0.3982,\n",
       "                       0.6446, -0.6103, -0.1370,  0.5919,  0.4898, -0.1291,  0.4969,  0.4277,\n",
       "                       0.2939, -0.1940, -0.2985,  0.2395, -0.1858, -0.3411, -0.0987,  0.4775,\n",
       "                      -0.0458,  0.0413, -0.0783, -0.4770,  0.6629, -0.1620,  0.4461, -0.1445,\n",
       "                       0.4373, -0.1012, -0.4723,  0.1519, -0.2175,  0.1791,  0.6385, -0.2598,\n",
       "                       0.4639,  0.2256, -0.2096, -0.3468,  0.3014,  0.1304, -0.5765,  0.3320,\n",
       "                       0.0998,  0.9359, -0.2059, -0.3830, -0.0552,  0.2897,  0.2846, -0.2405,\n",
       "                      -0.0312, -0.1150, -0.1814,  0.0879,  0.4565, -0.1194, -0.6060,  0.3909,\n",
       "                       0.1161,  0.2754,  0.1099,  0.0951, -0.2478,  0.1738,  0.3808, -0.6703,\n",
       "                       0.1280,  0.2567, -0.1922, -0.0896, -0.0561, -0.2262, -0.1623,  0.2551,\n",
       "                       0.1890, -0.2617, -0.4779, -0.1666, -0.2761, -0.1823,  0.0244, -0.3476,\n",
       "                      -0.2363,  0.0819, -0.7079,  0.0135,  0.0767,  0.0320, -0.8805, -0.0924,\n",
       "                       0.4949, -0.4137,  0.2967, -0.4493,  0.6838,  0.0081, -0.1819,  0.1645,\n",
       "                      -0.4065,  0.2712, -0.1391,  0.2511, -0.0148, -0.1054,  0.0798,  0.0577,\n",
       "                      -0.0445,  0.0234, -0.3032, -0.2490,  0.7021, -0.3016,  0.2569,  0.4965,\n",
       "                      -0.6610,  0.2484, -0.1657, -0.0385, -0.1808,  0.0191, -0.3352, -0.3096,\n",
       "                      -0.0980,  0.3494, -0.3370, -0.7736,  0.1320,  0.3128,  0.3571,  0.4100,\n",
       "                      -0.3632,  0.3412,  0.2022, -0.0113,  0.1776,  0.3120, -0.0322,  0.6727,\n",
       "                       0.4840,  0.2677,  0.4133, -0.8062,  0.2835,  0.0728, -0.1637,  0.0375],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convs.2.1.running_var',\n",
       "              tensor([0.3131, 0.2214, 0.4029, 0.3736, 0.2030, 0.6149, 0.1290, 0.3326, 0.2118,\n",
       "                      0.2424, 0.4482, 0.3895, 0.1123, 0.1762, 0.5959, 0.4870, 0.5400, 0.2294,\n",
       "                      0.2258, 0.2409, 0.2662, 0.2771, 0.5799, 0.2755, 0.5192, 0.3729, 0.3981,\n",
       "                      0.4239, 0.3520, 0.5760, 0.3890, 0.2803, 0.1983, 0.7171, 0.3963, 0.2549,\n",
       "                      0.3774, 0.1636, 0.2394, 0.5444, 0.3875, 0.1465, 0.3366, 0.5421, 0.4360,\n",
       "                      0.4335, 0.4146, 0.2315, 0.5576, 0.4395, 0.2119, 0.3486, 0.3084, 0.4547,\n",
       "                      0.4153, 0.3878, 0.2441, 0.5182, 0.3914, 0.3755, 0.3423, 0.3149, 0.1911,\n",
       "                      0.1972, 0.4211, 0.2972, 0.2511, 0.2881, 0.3434, 0.6015, 0.4407, 0.3647,\n",
       "                      0.0646, 0.3392, 0.6173, 0.0527, 0.5048, 0.3148, 0.3481, 0.2721, 0.4421,\n",
       "                      0.3588, 0.2930, 0.5231, 0.5032, 0.3703, 0.1605, 0.5395, 0.4735, 0.2658,\n",
       "                      0.5975, 0.1284, 0.4673, 0.1443, 0.1685, 0.6273, 0.4873, 0.3019, 0.1427,\n",
       "                      0.2882, 0.3931, 0.3412, 0.1803, 0.2269, 0.1602, 0.2294, 0.2659, 0.4944,\n",
       "                      0.3455, 0.2896, 0.0716, 0.6064, 0.4627, 0.2357, 0.3840, 0.5266, 0.2983,\n",
       "                      0.3467, 0.2290, 0.4340, 0.1351, 0.5061, 0.3095, 0.2900, 0.0330, 0.4188,\n",
       "                      0.2931, 0.2847, 0.2788, 0.3848, 0.1568, 0.4488, 0.5208, 0.1838, 0.4784,\n",
       "                      0.1478, 0.2446, 0.5200, 0.3699, 0.1732, 0.2872, 0.2159, 0.3063, 0.1164,\n",
       "                      0.3239, 0.3604, 0.1791, 0.2543, 0.2354, 0.3987, 0.3668, 0.1216, 0.3318,\n",
       "                      0.4317, 0.1393, 0.2775, 0.3093, 0.1151, 0.4070, 0.0447, 0.2356, 0.7675,\n",
       "                      0.2077, 0.4274, 0.6192, 0.2019, 0.5733, 0.3382, 0.3867, 0.5960, 0.0860,\n",
       "                      0.2045, 0.1622, 0.3619, 0.4721, 0.5748, 0.2399, 0.1650, 0.2395, 0.2019,\n",
       "                      0.4937, 0.3256, 0.3229, 0.4685, 0.3831, 0.4127, 0.5499, 0.3474, 0.1676,\n",
       "                      0.2568, 0.2955, 0.3824, 0.4490, 0.3106, 0.4571, 0.3477, 0.3462, 0.2034,\n",
       "                      0.3862, 0.3842, 0.2164, 0.6655, 0.3199, 0.4448, 0.2740, 0.4521, 0.3082,\n",
       "                      0.0527, 0.3335, 0.3234, 0.1416, 0.4814, 0.1701, 0.3295, 0.0600, 0.1818,\n",
       "                      0.3069, 0.2889, 0.3005, 0.5281, 0.2835, 0.2013, 0.0670, 0.5376, 0.5892,\n",
       "                      0.2222, 0.2181, 0.1420, 0.5640, 0.3340, 0.2773, 0.1507, 0.3601, 0.3815,\n",
       "                      0.5260, 0.2706, 0.4315, 0.2458, 0.5923, 0.1059, 0.1006, 0.1753, 0.2817,\n",
       "                      0.0482, 0.2484, 0.4449, 0.3710, 0.1765, 0.1929, 0.3517, 0.2442, 0.3323,\n",
       "                      0.3718, 0.1559, 0.2805, 0.2836], dtype=torch.float64)),\n",
       "             ('6.8.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.8.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.0887],\n",
       "                       [ 0.1908],\n",
       "                       [ 0.0004],\n",
       "                       ...,\n",
       "                       [-0.1929],\n",
       "                       [-0.0329],\n",
       "                       [-0.1482]],\n",
       "              \n",
       "                      [[ 0.0307],\n",
       "                       [-0.0216],\n",
       "                       [ 0.0644],\n",
       "                       ...,\n",
       "                       [-0.0112],\n",
       "                       [ 0.0572],\n",
       "                       [-0.0078]],\n",
       "              \n",
       "                      [[ 0.0191],\n",
       "                       [-0.0794],\n",
       "                       [ 0.1195],\n",
       "                       ...,\n",
       "                       [ 0.0226],\n",
       "                       [ 0.1501],\n",
       "                       [-0.0330]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1072],\n",
       "                       [-0.1276],\n",
       "                       [-0.0823],\n",
       "                       ...,\n",
       "                       [ 0.0120],\n",
       "                       [ 0.0449],\n",
       "                       [ 0.1959]],\n",
       "              \n",
       "                      [[ 0.0403],\n",
       "                       [-0.0069],\n",
       "                       [-0.0745],\n",
       "                       ...,\n",
       "                       [-0.0265],\n",
       "                       [-0.0248],\n",
       "                       [ 0.1112]],\n",
       "              \n",
       "                      [[ 0.1272],\n",
       "                       [-0.0481],\n",
       "                       [ 0.0945],\n",
       "                       ...,\n",
       "                       [-0.1008],\n",
       "                       [ 0.0964],\n",
       "                       [-0.0450]]], dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.0.1.weight',\n",
       "              tensor([0.9432, 0.9569, 0.9626, 0.9683, 0.9310, 0.9730, 0.9851, 0.9899, 0.9576,\n",
       "                      0.9435, 0.9778, 0.9775, 0.9517, 0.9398, 0.9644, 0.9703, 0.9685, 0.9793,\n",
       "                      0.9998, 0.9856, 0.9785, 0.9639, 0.9547, 0.9304, 0.9758, 0.9599, 0.9863,\n",
       "                      0.9660, 0.9646, 0.9637, 0.9421, 0.9563, 0.9599, 0.9494, 0.9684, 0.9598,\n",
       "                      0.9766, 0.9847, 0.9537, 0.9395, 0.9668, 0.9661, 0.9245, 0.9577, 0.9434,\n",
       "                      0.9514, 0.9694, 0.9903, 0.9736, 0.9632, 0.9549, 0.9508, 0.9575, 0.9883,\n",
       "                      0.9784, 0.9684, 0.9587, 0.9708, 0.9473, 0.9809, 0.9349, 0.9334, 0.9571,\n",
       "                      0.9861], dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.0.1.bias',\n",
       "              tensor([ 3.1957e-02,  1.0140e-02, -1.6584e-03, -1.0707e-02,  7.1319e-03,\n",
       "                       7.3430e-03,  2.6610e-02,  2.0424e-02,  3.4163e-03, -2.4627e-02,\n",
       "                       5.8369e-03,  2.2534e-02, -3.6009e-03, -2.1155e-02,  2.1622e-02,\n",
       "                      -5.5873e-03,  4.1890e-03,  1.1985e-02,  3.1749e-02,  1.2038e-02,\n",
       "                      -2.6527e-03,  1.9104e-06,  1.1475e-02, -2.4049e-03,  1.8556e-02,\n",
       "                       2.0758e-03,  1.2750e-02, -5.8136e-03, -4.4656e-03, -1.1002e-02,\n",
       "                      -4.6054e-02, -1.1836e-02,  2.6681e-03,  7.7375e-03, -2.9621e-03,\n",
       "                      -2.4369e-03,  4.0917e-02,  1.3131e-02, -1.0694e-02,  1.4191e-03,\n",
       "                      -2.2527e-02,  3.8883e-03,  1.4124e-02, -7.3241e-04, -6.1489e-03,\n",
       "                      -2.5508e-04,  2.3807e-03,  7.3859e-03,  2.2536e-02, -2.4591e-02,\n",
       "                       7.5150e-03,  2.1880e-02,  1.9122e-02,  3.9752e-03,  1.6702e-02,\n",
       "                       8.1483e-03, -1.5730e-02,  6.9830e-03,  1.1226e-02,  1.4420e-02,\n",
       "                      -3.0214e-02, -1.9035e-02, -7.4814e-03,  1.1744e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.2204, -0.0278,  0.6457,  0.0336, -0.8354, -0.0798,  0.1228, -0.2911,\n",
       "                      -0.0618, -0.2694, -0.6318, -0.4279, -0.0570, -0.2815,  0.1825,  1.1432,\n",
       "                       0.0067, -0.5452, -0.4348,  0.0697,  0.2302, -0.8138,  0.7798, -0.7765,\n",
       "                       0.1846,  0.2630, -0.6822,  0.5416,  0.8783,  0.5059,  1.1241,  0.8124,\n",
       "                      -0.1576, -0.2033,  0.5400, -0.0798, -0.5909,  0.4723, -0.2114, -0.3814,\n",
       "                       1.2772, -0.7225, -1.8504, -0.5363,  0.2021, -0.4371,  1.3005,  0.3725,\n",
       "                       0.6895,  0.4853,  1.2390, -0.3840, -0.1612,  0.4755, -0.2910,  0.5571,\n",
       "                       1.4032, -0.0836, -0.1793,  0.0949,  1.1415,  0.1029, -0.8563, -0.0079],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.0.1.running_var',\n",
       "              tensor([0.4582, 0.1025, 0.5356, 0.1875, 0.4602, 0.1749, 0.2905, 0.4761, 0.2384,\n",
       "                      0.2034, 0.1193, 0.1812, 0.2275, 0.1862, 0.1612, 0.4259, 0.2005, 0.1092,\n",
       "                      0.0852, 0.1384, 0.1522, 0.1879, 0.1098, 0.3722, 0.1840, 0.0961, 0.1130,\n",
       "                      0.1514, 0.2868, 0.1737, 0.4457, 0.9146, 0.4892, 0.1985, 0.3453, 0.0886,\n",
       "                      0.2218, 0.7072, 0.1335, 0.3276, 0.4631, 0.1154, 0.7546, 0.2176, 0.3564,\n",
       "                      0.6445, 0.5307, 0.1086, 0.2054, 0.2893, 0.9250, 0.2823, 0.3166, 0.1220,\n",
       "                      0.1646, 0.5879, 0.5408, 0.1074, 0.3481, 0.1272, 1.5457, 0.2720, 0.1630,\n",
       "                      0.1514], dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.8.convpath.0.1.0.weight',\n",
       "              tensor([[[-0.0518,  0.0130,  0.0303, -0.0033,  0.0088],\n",
       "                       [ 0.0079, -0.0090, -0.1094,  0.0184, -0.0313],\n",
       "                       [-0.0506, -0.0159,  0.0017, -0.0637, -0.0266],\n",
       "                       ...,\n",
       "                       [-0.1071, -0.0035, -0.0646,  0.0441,  0.0364],\n",
       "                       [ 0.0847, -0.0741, -0.0224,  0.1212,  0.0829],\n",
       "                       [-0.0498, -0.0430,  0.0048,  0.0112, -0.1283]],\n",
       "              \n",
       "                      [[-0.0391,  0.0046,  0.0049, -0.0219, -0.0021],\n",
       "                       [ 0.0583, -0.0112,  0.0816, -0.0234,  0.0174],\n",
       "                       [-0.0777, -0.1587,  0.0602, -0.1133,  0.2556],\n",
       "                       ...,\n",
       "                       [ 0.0020,  0.0465, -0.1044,  0.0383,  0.0902],\n",
       "                       [ 0.0343,  0.0458, -0.0417,  0.0445,  0.0563],\n",
       "                       [ 0.1732,  0.1177, -0.0525,  0.1464, -0.0788]],\n",
       "              \n",
       "                      [[ 0.0322,  0.0898,  0.0767, -0.0267,  0.0408],\n",
       "                       [ 0.0743,  0.0236,  0.0147, -0.0565,  0.0610],\n",
       "                       [-0.1611,  0.2096,  0.0791,  0.0728,  0.0279],\n",
       "                       ...,\n",
       "                       [-0.0043, -0.0694, -0.0986,  0.0419,  0.1003],\n",
       "                       [-0.0048,  0.0044,  0.1156,  0.0230, -0.0379],\n",
       "                       [ 0.0152,  0.0301, -0.0630,  0.0004, -0.0766]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0630, -0.0219, -0.0319, -0.0581, -0.0456],\n",
       "                       [-0.0712,  0.0174, -0.1281, -0.0300, -0.0455],\n",
       "                       [ 0.0344,  0.0816, -0.0424, -0.0353, -0.0677],\n",
       "                       ...,\n",
       "                       [ 0.0751,  0.0141, -0.0146, -0.0573,  0.0082],\n",
       "                       [ 0.0400,  0.1133, -0.0071,  0.0310, -0.0379],\n",
       "                       [-0.0820, -0.0514, -0.0392, -0.0518, -0.0698]],\n",
       "              \n",
       "                      [[ 0.0050,  0.1157,  0.0725,  0.1076, -0.0227],\n",
       "                       [ 0.0059, -0.0630,  0.0211,  0.0814, -0.1217],\n",
       "                       [-0.1179, -0.0032, -0.1050, -0.0140, -0.1057],\n",
       "                       ...,\n",
       "                       [ 0.0331,  0.0176, -0.0088,  0.0416,  0.0565],\n",
       "                       [-0.1267, -0.0988, -0.0760, -0.0111,  0.0099],\n",
       "                       [ 0.0289,  0.1339,  0.1049, -0.0289,  0.0315]],\n",
       "              \n",
       "                      [[ 0.0555,  0.0048,  0.0929, -0.2199,  0.1547],\n",
       "                       [-0.0288,  0.0533, -0.0920,  0.0339, -0.0652],\n",
       "                       [-0.0466, -0.0596, -0.0319,  0.0675,  0.0960],\n",
       "                       ...,\n",
       "                       [-0.1127,  0.1021, -0.1163,  0.0227, -0.0102],\n",
       "                       [ 0.0334, -0.0106,  0.0057,  0.0829,  0.0593],\n",
       "                       [-0.1318, -0.0246, -0.0258, -0.0428, -0.0154]]], dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.1.1.weight',\n",
       "              tensor([0.9278, 0.9500, 0.9551, 0.9541, 0.9388, 0.9921, 0.9598, 0.9534, 0.9565,\n",
       "                      0.9248, 0.9488, 0.9669, 0.9173, 0.9720, 0.9524, 0.9150, 0.9493, 0.9581,\n",
       "                      0.9647, 0.9338, 0.9757, 0.9542, 0.9513, 0.9656, 0.9632, 0.9724, 0.9585,\n",
       "                      0.9527, 0.9482, 0.9589, 0.9281, 0.9948, 0.9660, 0.9435, 0.9560, 0.9793,\n",
       "                      0.9356, 0.9536, 1.0001, 0.9809, 0.9506, 0.9503, 0.9945, 0.9674, 0.9510,\n",
       "                      0.9493, 0.9584, 0.9512, 0.9450, 0.9519, 0.9568, 0.9763, 0.9774, 0.9326,\n",
       "                      0.9630, 0.9604, 0.9735, 0.9399, 0.9568, 0.9392, 0.9693, 1.0034, 0.9666,\n",
       "                      0.9075], dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.1.1.bias',\n",
       "              tensor([-0.0088, -0.0028, -0.0014,  0.0045, -0.0145,  0.0160, -0.0064,  0.0038,\n",
       "                      -0.0168, -0.0129, -0.0181,  0.0070, -0.0226, -0.0031,  0.0045, -0.0261,\n",
       "                      -0.0199, -0.0048,  0.0068, -0.0377,  0.0149,  0.0051,  0.0070, -0.0243,\n",
       "                       0.0128, -0.0056, -0.0150, -0.0004,  0.0118,  0.0154, -0.0149,  0.0052,\n",
       "                       0.0122, -0.0018, -0.0049,  0.0053, -0.0112, -0.0059,  0.0028, -0.0050,\n",
       "                      -0.0138,  0.0017,  0.0344,  0.0010,  0.0092, -0.0243, -0.0063, -0.0213,\n",
       "                       0.0029, -0.0055,  0.0131, -0.0009, -0.0124, -0.0060, -0.0158, -0.0096,\n",
       "                       0.0107, -0.0114, -0.0173, -0.0238, -0.0017,  0.0032,  0.0090, -0.0083],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.1.1.running_mean',\n",
       "              tensor([-1.6298,  0.5967, -0.2267, -0.1021, -0.6781, -0.4661,  0.1649, -0.5324,\n",
       "                      -0.2398, -0.5106,  0.8791,  0.2589, -0.4289, -0.1792,  0.2552, -0.2599,\n",
       "                       0.1087,  0.8097,  0.1797,  0.0409,  0.1093, -0.4343, -0.3386,  0.4378,\n",
       "                      -1.3861, -0.6613,  0.5684,  0.0300, -0.0107,  0.2593, -0.0712, -0.0664,\n",
       "                      -0.1594, -0.6737, -0.4002,  0.3974,  0.1830, -0.4593,  0.0969, -0.6035,\n",
       "                       0.8069, -0.1840,  0.1336,  0.2122, -1.0001,  0.4269,  0.2946,  0.2759,\n",
       "                      -0.1767,  0.2423, -0.2035, -0.0995,  0.3086,  0.1128,  0.2670,  0.2479,\n",
       "                       0.4058,  0.1430,  1.0256, -0.2720,  0.4635,  0.0147,  0.3127, -0.1612],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.1.1.running_var',\n",
       "              tensor([1.4099, 0.8047, 0.4382, 0.4238, 0.5661, 0.5920, 0.7461, 0.5145, 0.5038,\n",
       "                      0.8165, 0.5047, 0.7378, 0.7954, 0.5966, 0.5340, 1.1785, 0.4054, 0.6506,\n",
       "                      0.6381, 0.5328, 0.5028, 0.5062, 0.9323, 0.4126, 0.5714, 0.3687, 0.5791,\n",
       "                      0.4191, 0.4472, 0.5699, 0.5047, 0.4863, 0.4551, 0.7216, 0.5317, 0.6278,\n",
       "                      0.7575, 0.5333, 0.4858, 0.6514, 0.8848, 0.5382, 0.4358, 0.5524, 0.9425,\n",
       "                      0.9093, 0.4492, 0.3963, 0.4348, 0.5894, 0.5349, 0.4678, 0.5427, 1.0316,\n",
       "                      0.3913, 0.9412, 0.5207, 0.6250, 0.5527, 0.6484, 0.6759, 0.3738, 0.5024,\n",
       "                      0.8171], dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.8.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0015],\n",
       "                       [ 0.0618],\n",
       "                       [-0.1841],\n",
       "                       ...,\n",
       "                       [-0.0679],\n",
       "                       [-0.0676],\n",
       "                       [-0.0832]],\n",
       "              \n",
       "                      [[ 0.0505],\n",
       "                       [ 0.0263],\n",
       "                       [-0.1381],\n",
       "                       ...,\n",
       "                       [-0.1041],\n",
       "                       [ 0.1079],\n",
       "                       [ 0.0236]],\n",
       "              \n",
       "                      [[-0.1187],\n",
       "                       [ 0.0748],\n",
       "                       [ 0.1667],\n",
       "                       ...,\n",
       "                       [ 0.0186],\n",
       "                       [ 0.3160],\n",
       "                       [ 0.0510]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.2023],\n",
       "                       [-0.0581],\n",
       "                       [-0.0273],\n",
       "                       ...,\n",
       "                       [-0.0748],\n",
       "                       [ 0.0278],\n",
       "                       [ 0.0081]],\n",
       "              \n",
       "                      [[ 0.0643],\n",
       "                       [ 0.0100],\n",
       "                       [-0.0992],\n",
       "                       ...,\n",
       "                       [-0.1634],\n",
       "                       [ 0.1541],\n",
       "                       [-0.0571]],\n",
       "              \n",
       "                      [[-0.0304],\n",
       "                       [-0.1885],\n",
       "                       [ 0.2055],\n",
       "                       ...,\n",
       "                       [-0.0573],\n",
       "                       [ 0.1835],\n",
       "                       [ 0.1255]]], dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.2.1.weight',\n",
       "              tensor([-2.0660e-03,  6.1894e-04,  6.3250e-03,  1.7064e-02, -1.0099e-02,\n",
       "                       1.7673e-02, -3.9634e-03, -4.3932e-02, -1.2278e-02,  6.6614e-04,\n",
       "                      -4.8536e-03,  2.8817e-02, -1.1313e-02, -6.4411e-03, -2.0540e-02,\n",
       "                       3.7784e-02, -1.2620e-02,  5.0773e-03, -1.0444e-02, -2.1709e-03,\n",
       "                       7.8726e-03, -4.7571e-03, -2.9992e-03, -5.1889e-03,  1.7685e-02,\n",
       "                       1.2147e-02, -8.9687e-03,  1.3441e-02,  6.2530e-03,  1.8847e-02,\n",
       "                      -1.5009e-02, -9.7421e-03, -8.4602e-04, -2.3385e-02,  9.1652e-03,\n",
       "                       1.2196e-03, -1.6587e-02, -9.9816e-03,  8.8335e-03,  3.7598e-03,\n",
       "                      -9.4836e-03,  8.7293e-03,  2.1139e-02, -2.7109e-02, -1.3489e-02,\n",
       "                      -9.9482e-03,  1.4132e-02,  2.8747e-02,  2.0804e-02,  6.0150e-03,\n",
       "                       2.7892e-02,  1.1385e-02, -1.9096e-04,  1.4533e-02,  1.6828e-02,\n",
       "                       5.2330e-02,  5.3676e-03,  1.5263e-02,  3.8217e-03,  1.1180e-03,\n",
       "                       5.4495e-03, -1.5431e-02,  4.9208e-03, -1.2997e-02,  9.7065e-03,\n",
       "                      -2.1196e-03, -9.5240e-03,  5.1660e-03,  2.1239e-02, -7.1946e-03,\n",
       "                       2.4575e-02,  2.1187e-02,  1.6203e-03, -9.2737e-04, -9.9068e-03,\n",
       "                       8.1525e-03,  2.1399e-02,  3.1293e-02, -4.1452e-03,  2.5280e-02,\n",
       "                      -1.4889e-02,  2.9710e-02,  2.2623e-02,  1.7331e-02, -2.1384e-02,\n",
       "                      -1.2634e-02,  1.7030e-03, -3.5038e-02,  1.5710e-03, -2.2587e-02,\n",
       "                      -7.5919e-03,  1.1272e-02, -8.4926e-03, -3.2500e-03, -4.8428e-03,\n",
       "                       2.2297e-02, -2.0893e-02, -1.4037e-02, -9.2617e-03,  1.3383e-02,\n",
       "                      -5.2591e-03,  2.2231e-02, -1.8991e-04, -1.8237e-02, -1.5163e-02,\n",
       "                      -1.8749e-02,  1.1699e-03,  8.8025e-03,  2.2007e-02,  1.8458e-02,\n",
       "                       2.2396e-05, -8.8249e-03, -1.9638e-02, -7.0404e-03,  1.0568e-02,\n",
       "                      -9.4188e-03, -2.9178e-03, -7.9452e-03,  1.4475e-02,  1.4389e-02,\n",
       "                       1.1300e-02, -1.5614e-02, -1.3186e-02, -1.2972e-02,  3.3864e-03,\n",
       "                       4.2606e-03,  3.0071e-02,  1.6589e-02, -1.3806e-02, -1.0296e-02,\n",
       "                       8.7019e-03, -3.9943e-03, -1.0120e-02,  2.5465e-03,  1.1756e-02,\n",
       "                       1.6570e-02, -1.4678e-02,  1.7318e-02, -4.3515e-03,  9.9493e-03,\n",
       "                       6.3169e-03, -1.9369e-02,  1.0131e-02,  4.9987e-03,  9.5437e-03,\n",
       "                       5.4485e-03, -2.0513e-02, -1.0796e-02,  7.6728e-03,  2.1991e-03,\n",
       "                       1.8767e-02, -3.6478e-03, -3.7939e-02, -1.1497e-02, -2.0247e-03,\n",
       "                       1.1245e-02, -1.0048e-02, -5.9844e-03, -1.7954e-02, -2.5308e-03,\n",
       "                      -7.8639e-03, -2.1146e-02,  6.5625e-03, -3.7818e-02, -3.1265e-02,\n",
       "                       2.0494e-02, -6.8358e-03, -2.1304e-02,  2.4668e-02, -2.2074e-02,\n",
       "                       7.6657e-04,  7.2933e-03,  4.7382e-03,  3.4108e-02,  2.0982e-02,\n",
       "                      -6.7730e-03, -4.7803e-03, -4.4514e-03, -1.7506e-03, -2.0707e-02,\n",
       "                       9.4255e-03, -1.4542e-02, -2.2228e-02, -1.0310e-02,  2.6845e-02,\n",
       "                      -4.6161e-04, -1.3318e-02,  9.7507e-03, -5.7632e-04,  1.2703e-02,\n",
       "                       6.8255e-03,  3.1781e-03, -4.1467e-02, -1.6447e-03, -1.0374e-02,\n",
       "                       2.5607e-02,  1.2754e-03,  8.0096e-03,  1.1529e-02, -1.0046e-02,\n",
       "                      -7.8666e-05, -1.5904e-02, -5.1813e-03, -2.2866e-02, -1.3025e-02,\n",
       "                      -9.0697e-03, -9.5688e-03, -1.4253e-03, -1.0787e-02, -9.0183e-03,\n",
       "                      -2.3644e-02,  1.0649e-02,  5.6574e-03,  2.1107e-02, -9.9541e-03,\n",
       "                      -8.3224e-03,  1.4262e-02,  1.1781e-02,  8.4630e-03,  3.3506e-02,\n",
       "                       2.7988e-03,  9.4050e-04, -8.3739e-04,  1.8818e-02,  7.9902e-03,\n",
       "                       2.7959e-02, -5.3950e-03, -5.4555e-03, -7.4225e-03, -6.0851e-03,\n",
       "                      -7.8907e-03, -1.0638e-03,  2.8860e-02,  3.3249e-02,  1.1778e-02,\n",
       "                       1.5321e-03, -2.7062e-02,  1.8792e-03,  3.1795e-02,  2.9848e-03,\n",
       "                      -1.1837e-03, -2.6049e-02,  4.5981e-03, -7.0127e-03, -1.2022e-02,\n",
       "                      -1.9621e-02, -5.9119e-03,  6.3127e-03,  4.7713e-03,  3.5127e-02,\n",
       "                      -4.3142e-03,  1.0485e-02, -6.9682e-03,  1.6972e-03,  6.8555e-03,\n",
       "                      -9.9427e-03], dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.2.1.bias',\n",
       "              tensor([-0.0004,  0.0032,  0.0135,  0.0151,  0.0008,  0.0096,  0.0081, -0.0006,\n",
       "                       0.0102,  0.0146,  0.0140, -0.0067,  0.0067, -0.0039,  0.0099,  0.0041,\n",
       "                       0.0233, -0.0028,  0.0107, -0.0033, -0.0036,  0.0012,  0.0033,  0.0054,\n",
       "                      -0.0070, -0.0169,  0.0024,  0.0033, -0.0003,  0.0018,  0.0056,  0.0093,\n",
       "                      -0.0065,  0.0181,  0.0095,  0.0156,  0.0026,  0.0160,  0.0051,  0.0152,\n",
       "                       0.0002,  0.0197, -0.0114,  0.0020,  0.0048, -0.0102,  0.0085,  0.0027,\n",
       "                      -0.0110,  0.0088,  0.0088,  0.0077,  0.0059,  0.0104,  0.0074,  0.0144,\n",
       "                       0.0084,  0.0010,  0.0119,  0.0019, -0.0053,  0.0016,  0.0044,  0.0085,\n",
       "                      -0.0049,  0.0057, -0.0109,  0.0147,  0.0002, -0.0128,  0.0030,  0.0083,\n",
       "                       0.0011, -0.0070,  0.0149,  0.0019,  0.0035,  0.0080,  0.0066,  0.0011,\n",
       "                       0.0094, -0.0057,  0.0097,  0.0047, -0.0034,  0.0181,  0.0001,  0.0021,\n",
       "                       0.0173,  0.0037,  0.0014,  0.0142,  0.0129, -0.0010,  0.0098, -0.0133,\n",
       "                       0.0099,  0.0029,  0.0088, -0.0027,  0.0192,  0.0141,  0.0037,  0.0090,\n",
       "                       0.0049, -0.0013, -0.0012,  0.0031,  0.0052,  0.0099, -0.0088, -0.0063,\n",
       "                       0.0053,  0.0184,  0.0120,  0.0064,  0.0081,  0.0024,  0.0047, -0.0157,\n",
       "                       0.0039,  0.0095, -0.0010, -0.0018, -0.0139,  0.0101,  0.0168,  0.0038,\n",
       "                       0.0030,  0.0172,  0.0085,  0.0138,  0.0146,  0.0108,  0.0149, -0.0082,\n",
       "                       0.0155,  0.0092,  0.0136,  0.0066,  0.0154, -0.0035,  0.0181,  0.0047,\n",
       "                      -0.0082,  0.0140, -0.0005, -0.0013,  0.0067,  0.0115,  0.0062,  0.0120,\n",
       "                       0.0123,  0.0132,  0.0123,  0.0086, -0.0006,  0.0027, -0.0018, -0.0114,\n",
       "                       0.0024, -0.0011,  0.0006,  0.0076,  0.0106, -0.0016, -0.0117,  0.0105,\n",
       "                       0.0009,  0.0165,  0.0046,  0.0046,  0.0120,  0.0105, -0.0135, -0.0006,\n",
       "                       0.0010,  0.0110,  0.0023,  0.0067, -0.0049,  0.0111, -0.0064, -0.0093,\n",
       "                       0.0194,  0.0074,  0.0140,  0.0109,  0.0025,  0.0120,  0.0072,  0.0026,\n",
       "                       0.0095, -0.0056, -0.0011,  0.0072, -0.0013,  0.0126,  0.0068,  0.0216,\n",
       "                       0.0008,  0.0223,  0.0202,  0.0229, -0.0002, -0.0038,  0.0110, -0.0039,\n",
       "                       0.0085,  0.0141,  0.0043,  0.0113,  0.0141,  0.0079,  0.0096, -0.0028,\n",
       "                       0.0043, -0.0052,  0.0023, -0.0013, -0.0132,  0.0028,  0.0042,  0.0219,\n",
       "                      -0.0047,  0.0020, -0.0040,  0.0006, -0.0151,  0.0148,  0.0076, -0.0026,\n",
       "                       0.0111, -0.0020,  0.0023,  0.0080,  0.0080, -0.0030,  0.0104,  0.0045,\n",
       "                       0.0020,  0.0014,  0.0021,  0.0086,  0.0021,  0.0151,  0.0051,  0.0079,\n",
       "                      -0.0009, -0.0093,  0.0170,  0.0228,  0.0151,  0.0149,  0.0099,  0.0021],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.2.1.running_mean',\n",
       "              tensor([ 0.1159, -0.0137,  0.7410, -0.1477,  0.1661,  0.3967,  0.0793,  0.5611,\n",
       "                       0.1799, -0.0319, -0.2336,  0.5195, -0.1289, -0.2306, -0.6580, -0.5116,\n",
       "                       0.6962, -0.2890, -0.1711, -0.2023,  0.1790, -0.1867, -0.4372,  0.0428,\n",
       "                       0.1156,  0.2690, -0.4055, -0.3229, -0.3581,  0.2676, -0.2529,  0.4645,\n",
       "                      -0.4268, -0.0861, -0.5112, -0.3824,  0.7574,  0.1442, -0.0995,  0.4144,\n",
       "                      -0.0211, -0.2888, -0.1424, -0.1503, -0.4178,  0.8322,  0.4718,  0.0326,\n",
       "                       0.7618,  0.3057, -0.2362,  0.1053,  0.2424, -0.7095,  0.1386,  0.1266,\n",
       "                       0.5873, -0.0427,  0.1808,  0.3648,  0.1174,  0.0725, -0.2795, -0.0715,\n",
       "                       0.5193, -0.3861,  0.1673,  0.4257,  0.4400, -0.7069, -0.4454, -0.4281,\n",
       "                      -0.1290, -0.0208,  0.1143, -0.0503,  0.0045, -0.2067, -0.4642, -0.2433,\n",
       "                       0.0459,  0.7877,  0.0177, -0.3648,  0.1846,  0.4169, -0.4395, -0.5843,\n",
       "                       0.4567,  0.1417, -0.2083,  0.3490,  0.9426,  0.4789,  0.0276, -0.3291,\n",
       "                       0.8330,  0.2574, -0.1018,  0.1159,  0.1421,  0.2113,  0.0988,  0.3412,\n",
       "                      -0.4689,  0.3106, -0.4914,  0.5967,  0.0604,  0.3448,  0.1001, -0.3982,\n",
       "                       0.6446, -0.6103, -0.1370,  0.5919,  0.4898, -0.1291,  0.4969,  0.4277,\n",
       "                       0.2939, -0.1940, -0.2985,  0.2395, -0.1858, -0.3411, -0.0987,  0.4775,\n",
       "                      -0.0458,  0.0413, -0.0783, -0.4770,  0.6629, -0.1620,  0.4461, -0.1445,\n",
       "                       0.4373, -0.1012, -0.4723,  0.1519, -0.2175,  0.1791,  0.6385, -0.2598,\n",
       "                       0.4639,  0.2256, -0.2096, -0.3468,  0.3014,  0.1304, -0.5765,  0.3320,\n",
       "                       0.0998,  0.9359, -0.2059, -0.3830, -0.0552,  0.2897,  0.2846, -0.2405,\n",
       "                      -0.0312, -0.1150, -0.1814,  0.0879,  0.4565, -0.1194, -0.6060,  0.3909,\n",
       "                       0.1161,  0.2754,  0.1099,  0.0951, -0.2478,  0.1738,  0.3808, -0.6703,\n",
       "                       0.1280,  0.2567, -0.1922, -0.0896, -0.0561, -0.2262, -0.1623,  0.2551,\n",
       "                       0.1890, -0.2617, -0.4779, -0.1666, -0.2761, -0.1823,  0.0244, -0.3476,\n",
       "                      -0.2363,  0.0819, -0.7079,  0.0135,  0.0767,  0.0320, -0.8805, -0.0924,\n",
       "                       0.4949, -0.4137,  0.2967, -0.4493,  0.6838,  0.0081, -0.1819,  0.1645,\n",
       "                      -0.4065,  0.2712, -0.1391,  0.2511, -0.0148, -0.1054,  0.0798,  0.0577,\n",
       "                      -0.0445,  0.0234, -0.3032, -0.2490,  0.7021, -0.3016,  0.2569,  0.4965,\n",
       "                      -0.6610,  0.2484, -0.1657, -0.0385, -0.1808,  0.0191, -0.3352, -0.3096,\n",
       "                      -0.0980,  0.3494, -0.3370, -0.7736,  0.1320,  0.3128,  0.3571,  0.4100,\n",
       "                      -0.3632,  0.3412,  0.2022, -0.0113,  0.1776,  0.3120, -0.0322,  0.6727,\n",
       "                       0.4840,  0.2677,  0.4133, -0.8062,  0.2835,  0.0728, -0.1637,  0.0375],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.2.1.running_var',\n",
       "              tensor([0.3131, 0.2214, 0.4029, 0.3736, 0.2030, 0.6149, 0.1290, 0.3326, 0.2118,\n",
       "                      0.2424, 0.4482, 0.3895, 0.1123, 0.1762, 0.5959, 0.4870, 0.5400, 0.2294,\n",
       "                      0.2258, 0.2409, 0.2662, 0.2771, 0.5799, 0.2755, 0.5192, 0.3729, 0.3981,\n",
       "                      0.4239, 0.3520, 0.5760, 0.3890, 0.2803, 0.1983, 0.7171, 0.3963, 0.2549,\n",
       "                      0.3774, 0.1636, 0.2394, 0.5444, 0.3875, 0.1465, 0.3366, 0.5421, 0.4360,\n",
       "                      0.4335, 0.4146, 0.2315, 0.5576, 0.4395, 0.2119, 0.3486, 0.3084, 0.4547,\n",
       "                      0.4153, 0.3878, 0.2441, 0.5182, 0.3914, 0.3755, 0.3423, 0.3149, 0.1911,\n",
       "                      0.1972, 0.4211, 0.2972, 0.2511, 0.2881, 0.3434, 0.6015, 0.4407, 0.3647,\n",
       "                      0.0646, 0.3392, 0.6173, 0.0527, 0.5048, 0.3148, 0.3481, 0.2721, 0.4421,\n",
       "                      0.3588, 0.2930, 0.5231, 0.5032, 0.3703, 0.1605, 0.5395, 0.4735, 0.2658,\n",
       "                      0.5975, 0.1284, 0.4673, 0.1443, 0.1685, 0.6273, 0.4873, 0.3019, 0.1427,\n",
       "                      0.2882, 0.3931, 0.3412, 0.1803, 0.2269, 0.1602, 0.2294, 0.2659, 0.4944,\n",
       "                      0.3455, 0.2896, 0.0716, 0.6064, 0.4627, 0.2357, 0.3840, 0.5266, 0.2983,\n",
       "                      0.3467, 0.2290, 0.4340, 0.1351, 0.5061, 0.3095, 0.2900, 0.0330, 0.4188,\n",
       "                      0.2931, 0.2847, 0.2788, 0.3848, 0.1568, 0.4488, 0.5208, 0.1838, 0.4784,\n",
       "                      0.1478, 0.2446, 0.5200, 0.3699, 0.1732, 0.2872, 0.2159, 0.3063, 0.1164,\n",
       "                      0.3239, 0.3604, 0.1791, 0.2543, 0.2354, 0.3987, 0.3668, 0.1216, 0.3318,\n",
       "                      0.4317, 0.1393, 0.2775, 0.3093, 0.1151, 0.4070, 0.0447, 0.2356, 0.7675,\n",
       "                      0.2077, 0.4274, 0.6192, 0.2019, 0.5733, 0.3382, 0.3867, 0.5960, 0.0860,\n",
       "                      0.2045, 0.1622, 0.3619, 0.4721, 0.5748, 0.2399, 0.1650, 0.2395, 0.2019,\n",
       "                      0.4937, 0.3256, 0.3229, 0.4685, 0.3831, 0.4127, 0.5499, 0.3474, 0.1676,\n",
       "                      0.2568, 0.2955, 0.3824, 0.4490, 0.3106, 0.4571, 0.3477, 0.3462, 0.2034,\n",
       "                      0.3862, 0.3842, 0.2164, 0.6655, 0.3199, 0.4448, 0.2740, 0.4521, 0.3082,\n",
       "                      0.0527, 0.3335, 0.3234, 0.1416, 0.4814, 0.1701, 0.3295, 0.0600, 0.1818,\n",
       "                      0.3069, 0.2889, 0.3005, 0.5281, 0.2835, 0.2013, 0.0670, 0.5376, 0.5892,\n",
       "                      0.2222, 0.2181, 0.1420, 0.5640, 0.3340, 0.2773, 0.1507, 0.3601, 0.3815,\n",
       "                      0.5260, 0.2706, 0.4315, 0.2458, 0.5923, 0.1059, 0.1006, 0.1753, 0.2817,\n",
       "                      0.0482, 0.2484, 0.4449, 0.3710, 0.1765, 0.1929, 0.3517, 0.2442, 0.3323,\n",
       "                      0.3718, 0.1559, 0.2805, 0.2836], dtype=torch.float64)),\n",
       "             ('6.8.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.9.convs.0.0.weight',\n",
       "              tensor([[[-0.0813],\n",
       "                       [ 0.0610],\n",
       "                       [-0.0926],\n",
       "                       ...,\n",
       "                       [-0.0010],\n",
       "                       [ 0.0468],\n",
       "                       [-0.0065]],\n",
       "              \n",
       "                      [[ 0.1631],\n",
       "                       [ 0.0335],\n",
       "                       [ 0.0903],\n",
       "                       ...,\n",
       "                       [ 0.1104],\n",
       "                       [ 0.0539],\n",
       "                       [-0.0513]],\n",
       "              \n",
       "                      [[ 0.0223],\n",
       "                       [-0.0326],\n",
       "                       [-0.0781],\n",
       "                       ...,\n",
       "                       [ 0.0177],\n",
       "                       [-0.1569],\n",
       "                       [ 0.0532]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0231],\n",
       "                       [ 0.1380],\n",
       "                       [ 0.0566],\n",
       "                       ...,\n",
       "                       [ 0.0244],\n",
       "                       [-0.1035],\n",
       "                       [-0.0193]],\n",
       "              \n",
       "                      [[ 0.1010],\n",
       "                       [-0.0405],\n",
       "                       [ 0.0025],\n",
       "                       ...,\n",
       "                       [-0.0571],\n",
       "                       [-0.1015],\n",
       "                       [ 0.0298]],\n",
       "              \n",
       "                      [[-0.0005],\n",
       "                       [ 0.0264],\n",
       "                       [-0.0925],\n",
       "                       ...,\n",
       "                       [ 0.0210],\n",
       "                       [ 0.0282],\n",
       "                       [-0.0404]]], dtype=torch.float64)),\n",
       "             ('6.9.convs.0.1.weight',\n",
       "              tensor([0.9750, 0.9819, 0.9649, 0.9776, 0.9871, 0.9467, 0.9595, 0.9758, 1.0028,\n",
       "                      0.9632, 0.9893, 0.9389, 0.9785, 0.9899, 0.9649, 0.9732, 0.9734, 0.9575,\n",
       "                      0.9941, 0.9702, 0.9553, 0.9850, 0.9682, 0.9923, 0.9465, 0.9507, 0.9835,\n",
       "                      0.9816, 0.9771, 0.9428, 0.9717, 0.9623, 0.9523, 0.9815, 0.9632, 0.9720,\n",
       "                      0.9552, 0.9900, 0.9657, 0.9680, 0.9769, 0.9607, 0.9654, 0.9850, 0.9596,\n",
       "                      0.9854, 0.9849, 0.9691, 0.9443, 0.9693, 0.9721, 0.9748, 0.9836, 0.9763,\n",
       "                      0.9679, 0.9778, 0.9940, 0.9622, 0.9825, 0.9556, 0.9634, 0.9741, 0.9662,\n",
       "                      0.9424], dtype=torch.float64)),\n",
       "             ('6.9.convs.0.1.bias',\n",
       "              tensor([ 1.2720e-02, -3.1621e-03, -5.3963e-03, -4.0528e-03,  1.7812e-03,\n",
       "                      -2.4145e-02,  2.7870e-03, -3.8004e-03,  2.2681e-03,  5.0583e-03,\n",
       "                       1.5305e-02, -1.8052e-02,  1.2570e-02, -1.5111e-02, -2.7473e-03,\n",
       "                       1.8942e-03, -1.1458e-02, -1.1732e-02,  2.9528e-02,  1.1348e-03,\n",
       "                      -1.3661e-02,  1.0696e-02,  2.9996e-03,  9.0068e-03, -1.1412e-02,\n",
       "                      -8.1377e-03, -3.0630e-03,  9.3411e-04,  1.2722e-02, -1.8332e-03,\n",
       "                       3.0892e-02, -1.5897e-02, -1.5398e-02,  9.6534e-03, -2.6470e-03,\n",
       "                       7.5174e-03, -3.3340e-03,  8.7480e-03, -1.3130e-02, -3.0183e-03,\n",
       "                       1.4194e-02, -3.4733e-03,  3.5211e-03,  3.3736e-03, -6.8094e-03,\n",
       "                      -4.1734e-03,  1.6319e-02,  1.0342e-03,  5.2933e-03,  2.1836e-03,\n",
       "                      -4.6685e-03,  1.0572e-02,  8.4254e-03,  1.9179e-02, -1.4815e-02,\n",
       "                       3.7394e-05,  1.5185e-02, -3.2271e-03,  2.3928e-03,  4.0501e-03,\n",
       "                       1.9671e-02, -2.0330e-02, -1.9237e-02,  4.9478e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convs.0.1.running_mean',\n",
       "              tensor([-5.1299e-01,  2.1893e-01, -2.2575e-01, -6.0247e-01,  4.1847e-01,\n",
       "                       8.5130e-01,  3.8063e-01, -1.1130e-02,  9.5625e-01,  3.2814e-01,\n",
       "                       1.4986e-01, -4.3955e-01,  1.5870e-02,  3.6438e-01, -4.8804e-01,\n",
       "                       8.7743e-01, -3.6821e-01,  1.0809e+00,  6.3100e-01, -4.2783e-01,\n",
       "                       1.1584e-01, -6.1395e-01,  1.0540e-01, -2.3331e-01, -9.3521e-01,\n",
       "                       7.2648e-01,  1.0963e-01,  9.6573e-01, -2.1461e-02, -5.1821e-02,\n",
       "                      -4.2013e-01,  1.5057e-01, -1.4243e-01,  1.2127e-01, -1.1201e+00,\n",
       "                       5.7285e-01, -5.5514e-04, -3.9032e-01, -1.4426e-01,  4.6195e-01,\n",
       "                      -7.8567e-03,  6.7652e-01, -1.5185e+00,  4.2479e-03, -4.0399e-01,\n",
       "                      -6.5788e-02,  3.2118e-01, -2.3551e-03, -6.1577e-01, -1.7627e-01,\n",
       "                      -1.4676e-01, -7.0901e-01, -2.8145e-01,  5.9551e-01,  5.9078e-01,\n",
       "                      -6.4628e-02, -4.6498e-01,  1.3718e-01,  9.6977e-02,  3.1492e-01,\n",
       "                      -4.5557e-02,  7.8428e-01,  5.0170e-01, -5.4388e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convs.0.1.running_var',\n",
       "              tensor([0.2462, 0.3808, 0.2727, 0.2755, 0.1013, 0.9384, 0.2195, 0.1275, 0.1446,\n",
       "                      0.4254, 0.1599, 0.3240, 0.2067, 0.1295, 0.1214, 0.1466, 0.1249, 0.4835,\n",
       "                      0.1151, 0.1273, 0.2318, 0.2259, 0.1636, 0.0779, 0.4462, 0.5663, 0.1118,\n",
       "                      0.1338, 0.1290, 0.2601, 0.2451, 0.3338, 0.2074, 0.1195, 0.1043, 0.1824,\n",
       "                      0.3848, 0.2102, 0.2994, 0.5008, 0.1136, 0.7953, 0.1328, 0.1803, 0.1153,\n",
       "                      0.1446, 0.2042, 0.1558, 0.4887, 0.1309, 0.1366, 0.1614, 0.1149, 0.2081,\n",
       "                      0.7528, 0.1145, 0.1437, 0.4131, 0.3380, 0.3017, 0.2566, 0.1229, 0.1149,\n",
       "                      0.8034], dtype=torch.float64)),\n",
       "             ('6.9.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.9.convs.1.0.weight',\n",
       "              tensor([[[-0.0375, -0.0436,  0.1358,  0.0026, -0.0103],\n",
       "                       [ 0.1822,  0.0703, -0.1437, -0.0380,  0.0550],\n",
       "                       [ 0.0140, -0.0111, -0.0070, -0.1559,  0.0123],\n",
       "                       ...,\n",
       "                       [-0.1447,  0.1245,  0.0411, -0.0129, -0.1039],\n",
       "                       [ 0.0174, -0.0908,  0.0043, -0.1087, -0.1515],\n",
       "                       [-0.0010, -0.0775, -0.0219, -0.0696,  0.0306]],\n",
       "              \n",
       "                      [[-0.0341,  0.0068, -0.0217,  0.0647,  0.0235],\n",
       "                       [-0.0950, -0.1610,  0.0076, -0.0661, -0.0067],\n",
       "                       [ 0.1058,  0.0332,  0.0235,  0.1473, -0.0424],\n",
       "                       ...,\n",
       "                       [ 0.0376, -0.0129,  0.0148, -0.0103,  0.0428],\n",
       "                       [-0.1770,  0.0480, -0.0097,  0.0857, -0.0996],\n",
       "                       [ 0.1425,  0.0803,  0.0381,  0.1541, -0.0931]],\n",
       "              \n",
       "                      [[ 0.0214,  0.0125,  0.0488, -0.0231, -0.0332],\n",
       "                       [ 0.1249,  0.0729, -0.0125,  0.0653,  0.0047],\n",
       "                       [-0.0869, -0.1084, -0.0604, -0.0563, -0.0303],\n",
       "                       ...,\n",
       "                       [-0.0623, -0.0984,  0.1214, -0.0181,  0.0268],\n",
       "                       [-0.1094,  0.0629,  0.1208,  0.0964, -0.0058],\n",
       "                       [-0.0580, -0.0348,  0.1308,  0.0524,  0.0527]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0712,  0.0538, -0.0044, -0.0373,  0.1484],\n",
       "                       [-0.1403, -0.0338,  0.0162,  0.0637, -0.0987],\n",
       "                       [ 0.0461, -0.0691, -0.2055, -0.0315, -0.0023],\n",
       "                       ...,\n",
       "                       [-0.1200,  0.0239,  0.0774, -0.0476,  0.0003],\n",
       "                       [-0.0211, -0.1110, -0.1346, -0.0744, -0.0921],\n",
       "                       [ 0.0624,  0.0962,  0.0043,  0.1145, -0.0743]],\n",
       "              \n",
       "                      [[-0.0120,  0.0767, -0.0028,  0.0145,  0.0977],\n",
       "                       [-0.0431, -0.0102, -0.0652, -0.0951,  0.0675],\n",
       "                       [ 0.0216,  0.0194, -0.0389, -0.1032, -0.0460],\n",
       "                       ...,\n",
       "                       [ 0.0792, -0.1153, -0.0698,  0.0975,  0.0158],\n",
       "                       [-0.0884,  0.0936,  0.0910, -0.0802,  0.0101],\n",
       "                       [-0.0253, -0.0336,  0.0245, -0.0596, -0.0593]],\n",
       "              \n",
       "                      [[-0.0532,  0.0435,  0.2633, -0.0868,  0.1731],\n",
       "                       [ 0.0842, -0.0355,  0.0880,  0.1475,  0.1062],\n",
       "                       [ 0.0087,  0.1173,  0.0910, -0.1063, -0.0219],\n",
       "                       ...,\n",
       "                       [-0.0810, -0.0384,  0.0367, -0.0159,  0.1417],\n",
       "                       [ 0.0524,  0.0835, -0.0103,  0.1464,  0.0845],\n",
       "                       [ 0.0081, -0.0855, -0.0378,  0.0202,  0.0901]]], dtype=torch.float64)),\n",
       "             ('6.9.convs.1.1.weight',\n",
       "              tensor([1.0122, 0.9534, 0.9696, 0.9633, 0.9643, 1.0124, 0.9534, 0.9577, 0.9762,\n",
       "                      0.9636, 0.9512, 0.9230, 0.9639, 0.9538, 0.9679, 0.9504, 0.9591, 0.9583,\n",
       "                      0.9664, 0.9653, 0.9647, 0.9833, 0.9629, 0.9912, 0.9715, 0.9796, 0.9683,\n",
       "                      0.9589, 0.9363, 0.9612, 0.9594, 0.9842, 0.9726, 0.9626, 1.0199, 0.9679,\n",
       "                      0.9765, 0.9893, 0.9534, 0.9179, 0.9577, 0.9812, 0.9508, 0.9425, 0.9622,\n",
       "                      0.9914, 0.9875, 0.9605, 0.9697, 0.9573, 0.9798, 0.9693, 0.9878, 0.9776,\n",
       "                      0.9646, 0.9734, 0.9695, 0.9810, 0.9722, 0.9479, 0.9644, 0.9433, 0.9418,\n",
       "                      0.9432], dtype=torch.float64)),\n",
       "             ('6.9.convs.1.1.bias',\n",
       "              tensor([ 0.0243, -0.0026,  0.0020, -0.0055, -0.0125,  0.0327, -0.0025, -0.0050,\n",
       "                      -0.0023, -0.0125, -0.0225, -0.0294,  0.0046, -0.0092, -0.0133,  0.0023,\n",
       "                       0.0005, -0.0103,  0.0023,  0.0133, -0.0190,  0.0003, -0.0049, -0.0057,\n",
       "                      -0.0149,  0.0024, -0.0065, -0.0153, -0.0130,  0.0037, -0.0174,  0.0121,\n",
       "                       0.0083, -0.0075,  0.0121, -0.0063, -0.0003,  0.0060, -0.0161, -0.0155,\n",
       "                      -0.0109,  0.0043, -0.0284, -0.0300, -0.0262,  0.0230,  0.0070,  0.0077,\n",
       "                      -0.0011, -0.0060,  0.0124, -0.0075,  0.0320,  0.0162, -0.0057, -0.0250,\n",
       "                       0.0126,  0.0154,  0.0065, -0.0282, -0.0216, -0.0183, -0.0059, -0.0290],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convs.1.1.running_mean',\n",
       "              tensor([-1.2514,  0.0662, -0.3021, -0.1990,  1.2269, -0.8138, -0.3655,  0.0439,\n",
       "                      -0.8457, -0.0487, -0.5501,  0.0947, -0.4014,  0.1619,  0.5045, -0.6021,\n",
       "                      -0.8322, -0.6092,  0.9667, -0.4734,  0.2212, -0.5115, -1.0419,  0.2626,\n",
       "                      -0.0119, -0.1979,  0.4004,  0.5910, -0.6113, -0.0663,  0.5426,  0.2087,\n",
       "                       0.6633,  0.0207, -0.2110, -0.2268,  0.7308, -0.5353,  0.1103, -0.3382,\n",
       "                       0.5863,  1.0467,  0.2675,  0.6656,  0.1332, -0.1556, -0.1738, -0.1929,\n",
       "                       0.6005, -0.4710,  0.2127, -0.2831, -0.2715, -0.7200, -0.0334,  0.7627,\n",
       "                      -0.8695, -0.5102, -0.2038,  0.2374,  0.3683, -1.1049, -0.4220, -0.1263],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convs.1.1.running_var',\n",
       "              tensor([0.4951, 0.5551, 0.5161, 0.7929, 0.6730, 0.8803, 0.5287, 0.4668, 0.7212,\n",
       "                      0.4924, 0.8019, 0.7413, 1.0987, 0.7438, 0.4537, 0.8554, 0.6237, 0.6271,\n",
       "                      0.5643, 0.4603, 0.5157, 0.5985, 0.5596, 0.4932, 0.8332, 0.4350, 0.5210,\n",
       "                      0.6271, 0.5215, 0.7864, 0.7577, 0.4459, 0.5980, 0.7107, 0.4871, 0.4155,\n",
       "                      0.5383, 0.7093, 0.6683, 0.4401, 1.0233, 0.4873, 0.5053, 0.6209, 0.3728,\n",
       "                      0.4552, 0.5253, 0.4817, 0.6232, 0.6157, 0.7725, 0.5324, 0.7049, 0.5713,\n",
       "                      0.6358, 0.6494, 0.4572, 0.6735, 0.4575, 0.5501, 0.5756, 0.7872, 0.5334,\n",
       "                      0.9152], dtype=torch.float64)),\n",
       "             ('6.9.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.9.convs.2.0.weight',\n",
       "              tensor([[[ 0.0893],\n",
       "                       [-0.0455],\n",
       "                       [-0.2674],\n",
       "                       ...,\n",
       "                       [ 0.1167],\n",
       "                       [-0.0836],\n",
       "                       [ 0.2465]],\n",
       "              \n",
       "                      [[-0.2033],\n",
       "                       [ 0.0706],\n",
       "                       [-0.1168],\n",
       "                       ...,\n",
       "                       [-0.0581],\n",
       "                       [ 0.1263],\n",
       "                       [ 0.0072]],\n",
       "              \n",
       "                      [[-0.0705],\n",
       "                       [-0.0357],\n",
       "                       [ 0.1340],\n",
       "                       ...,\n",
       "                       [ 0.1086],\n",
       "                       [ 0.1340],\n",
       "                       [ 0.0703]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0073],\n",
       "                       [-0.0165],\n",
       "                       [-0.1484],\n",
       "                       ...,\n",
       "                       [ 0.0422],\n",
       "                       [-0.0156],\n",
       "                       [ 0.0365]],\n",
       "              \n",
       "                      [[-0.0883],\n",
       "                       [ 0.0145],\n",
       "                       [ 0.0252],\n",
       "                       ...,\n",
       "                       [-0.0438],\n",
       "                       [ 0.0520],\n",
       "                       [-0.0764]],\n",
       "              \n",
       "                      [[-0.1101],\n",
       "                       [-0.0844],\n",
       "                       [-0.0323],\n",
       "                       ...,\n",
       "                       [ 0.0104],\n",
       "                       [-0.0811],\n",
       "                       [-0.0769]]], dtype=torch.float64)),\n",
       "             ('6.9.convs.2.1.weight',\n",
       "              tensor([ 3.8197e-02,  2.1366e-02,  2.4696e-02,  1.4561e-02, -6.2829e-03,\n",
       "                       2.0589e-02, -2.8215e-04,  6.6789e-03, -1.7766e-02, -1.9854e-02,\n",
       "                       3.2550e-03, -2.2405e-03,  8.2939e-03, -8.2569e-04, -8.4355e-04,\n",
       "                      -5.2118e-02,  5.4740e-03,  1.9636e-03, -9.1535e-03,  2.5672e-02,\n",
       "                      -5.5989e-03, -9.4478e-03,  1.5207e-03, -2.0959e-02,  1.0322e-02,\n",
       "                       1.7054e-04, -3.0756e-03, -1.1003e-02,  1.6626e-03,  1.2533e-02,\n",
       "                       4.0056e-02,  1.5763e-02, -1.0410e-02,  1.4234e-02, -2.7693e-02,\n",
       "                      -1.1018e-02, -2.2641e-02, -6.7160e-03, -1.2052e-02, -3.3082e-02,\n",
       "                       5.9991e-03, -8.8727e-03, -3.3118e-02, -3.2117e-03, -9.7912e-03,\n",
       "                       1.3251e-02,  2.3738e-02, -9.1586e-03,  2.3567e-03,  6.8963e-03,\n",
       "                       1.5196e-03,  3.2188e-02, -1.8743e-05,  1.8416e-02, -2.1405e-02,\n",
       "                       5.7661e-03, -4.9039e-03,  1.9656e-02,  3.9762e-03, -1.1368e-02,\n",
       "                       1.2981e-02, -1.8732e-03,  2.0916e-02, -6.4356e-03, -2.7787e-02,\n",
       "                      -8.9875e-03,  1.4702e-02,  2.1318e-02, -2.4436e-02,  1.4646e-02,\n",
       "                       5.4845e-03,  5.2684e-03,  1.6982e-02, -3.8205e-03,  2.0069e-02,\n",
       "                       1.4001e-02,  2.0501e-02,  1.8135e-02,  2.7525e-02,  1.4677e-02,\n",
       "                      -7.2911e-03, -6.9844e-03, -8.7730e-03, -4.4011e-03, -1.8420e-02,\n",
       "                      -2.7725e-02,  2.7036e-02,  4.7727e-04, -1.3584e-03, -2.1909e-02,\n",
       "                      -2.3168e-03, -1.7575e-03,  1.6877e-02, -2.5837e-03,  2.1309e-02,\n",
       "                       7.9868e-04,  4.7593e-03,  5.0303e-03,  1.9330e-02, -1.0573e-02,\n",
       "                       2.8600e-04,  1.3909e-02,  2.4698e-02, -6.4631e-03, -8.4863e-03,\n",
       "                       1.5554e-02,  6.1310e-03, -1.3418e-02,  1.1456e-02, -1.2268e-02,\n",
       "                      -1.1725e-02, -7.2832e-04, -1.7940e-02, -1.4059e-02,  1.5236e-02,\n",
       "                       1.4531e-02, -7.3030e-03,  1.3628e-02, -5.6375e-03,  5.0602e-03,\n",
       "                      -2.0684e-02, -1.5507e-03,  4.7530e-03, -8.6688e-03, -1.0095e-02,\n",
       "                       7.6345e-03,  2.4969e-03, -2.5301e-02,  1.5391e-02,  6.2170e-03,\n",
       "                       1.1334e-02,  8.4427e-04, -1.2570e-02,  1.1552e-02, -9.7551e-03,\n",
       "                       4.4813e-03,  4.0318e-02, -1.6385e-02,  1.3779e-02,  1.4663e-02,\n",
       "                      -5.1428e-04,  1.6617e-02, -9.6113e-03, -9.9553e-03,  1.1362e-02,\n",
       "                      -1.9588e-02, -6.3355e-03,  7.2053e-03, -2.0011e-02, -8.3248e-03,\n",
       "                      -2.6182e-02, -1.9902e-04, -1.1457e-02,  1.7781e-02, -2.1089e-03,\n",
       "                       1.3304e-02, -3.0273e-03, -2.2991e-02,  2.0670e-02, -1.5204e-02,\n",
       "                      -2.1731e-02,  8.4588e-03,  2.7016e-03,  5.1305e-04,  1.8516e-02,\n",
       "                       1.1654e-02, -6.0683e-03,  2.1588e-02,  1.3673e-02,  2.2667e-02,\n",
       "                      -5.0496e-03,  1.3705e-02, -2.6801e-02,  7.4720e-03,  1.9639e-03,\n",
       "                       1.5954e-02, -2.0386e-02,  4.7803e-02,  7.6350e-04,  9.5020e-03,\n",
       "                       3.2695e-03,  1.4055e-04,  4.9750e-03,  1.9632e-02,  2.1211e-02,\n",
       "                      -8.1133e-03,  7.4683e-03, -4.1438e-03,  8.7901e-03,  5.2431e-03,\n",
       "                      -2.1540e-03, -4.5825e-03, -2.8451e-02, -2.8668e-02,  2.0430e-02,\n",
       "                       2.1461e-02, -9.6153e-03, -2.3711e-02,  5.8847e-03, -6.9132e-03,\n",
       "                       5.2752e-03, -3.0356e-02,  1.9696e-02, -9.9085e-03,  1.4255e-02,\n",
       "                       5.4290e-03,  2.0562e-02,  1.9429e-02, -6.4988e-03,  1.4216e-02,\n",
       "                      -6.9774e-03, -1.3568e-02, -1.1343e-02, -1.4171e-02,  1.5999e-02,\n",
       "                       7.3574e-03, -6.1076e-03,  2.1894e-02,  6.7295e-03, -2.2721e-04,\n",
       "                      -1.0427e-02, -5.6908e-03,  6.9117e-03,  1.8961e-02,  4.8462e-04,\n",
       "                       7.7365e-04, -1.3075e-04,  1.1878e-02,  3.8245e-03, -1.2529e-02,\n",
       "                       4.3224e-03,  1.1561e-02,  4.1882e-02,  1.5538e-02,  1.4056e-02,\n",
       "                      -1.7800e-02, -1.2519e-02, -2.3626e-02, -1.4380e-02,  1.2683e-02,\n",
       "                      -1.3807e-02,  1.9819e-02, -2.5073e-02, -4.2987e-02, -1.3713e-02,\n",
       "                      -9.6242e-03,  1.1155e-02, -2.1724e-02,  1.1837e-02, -4.4349e-03,\n",
       "                      -2.6107e-02,  2.7170e-02,  9.4104e-03, -1.3384e-03,  2.2749e-02,\n",
       "                       2.3418e-03], dtype=torch.float64)),\n",
       "             ('6.9.convs.2.1.bias',\n",
       "              tensor([-6.4846e-04,  3.4670e-03,  1.3560e-02,  1.3903e-02,  1.0323e-03,\n",
       "                       1.3111e-02,  7.6078e-03, -7.1756e-04,  1.2451e-02,  1.4780e-02,\n",
       "                       1.3135e-02, -7.5430e-03,  8.1079e-03, -3.5415e-03,  1.1186e-02,\n",
       "                       4.0195e-03,  2.2127e-02, -3.6439e-03,  1.0206e-02, -2.1828e-03,\n",
       "                      -3.5464e-03,  1.6337e-03,  2.8847e-03,  5.6239e-03,  2.1583e-03,\n",
       "                      -1.6947e-02,  1.1932e-03,  6.8007e-03, -1.7143e-03, -3.1892e-03,\n",
       "                       3.3445e-03,  7.4800e-03, -5.6142e-03,  1.8470e-02,  8.8573e-03,\n",
       "                       1.6069e-02,  3.8610e-03,  2.0562e-02,  5.7403e-03,  1.5740e-02,\n",
       "                      -3.9430e-04,  2.0469e-02, -7.2633e-03,  7.7431e-05,  3.5858e-03,\n",
       "                      -9.0705e-03,  3.0999e-03,  2.8893e-03, -1.1129e-02,  9.1805e-03,\n",
       "                       1.0326e-02,  7.3620e-03,  7.6639e-03,  1.0123e-02,  4.9705e-03,\n",
       "                       2.0092e-02,  8.8805e-03,  1.8766e-03,  1.2297e-02,  8.3502e-04,\n",
       "                      -2.5419e-03,  9.3884e-04,  4.7181e-03,  8.7003e-03, -5.0107e-03,\n",
       "                       6.2617e-03, -1.1034e-02,  1.5183e-02,  2.7905e-03, -1.3341e-02,\n",
       "                       4.4583e-03,  2.7764e-03,  1.4734e-03, -6.8418e-03,  1.4786e-02,\n",
       "                       2.2719e-03,  4.4943e-03,  6.9237e-03,  4.1080e-03,  1.8831e-03,\n",
       "                       7.8287e-03, -6.3343e-03,  1.0328e-02,  4.7032e-03, -3.8044e-03,\n",
       "                       1.9094e-02, -8.4135e-04, -1.9934e-03,  1.7345e-02,  1.4599e-03,\n",
       "                       9.6969e-04,  8.9588e-03,  1.0819e-02, -8.3166e-04,  1.0169e-02,\n",
       "                      -1.5017e-02,  1.0828e-02,  1.9028e-03,  8.1641e-03, -1.2069e-03,\n",
       "                       1.9103e-02,  1.3743e-02,  4.5405e-03,  8.1596e-03,  2.8097e-03,\n",
       "                      -1.6397e-03, -1.5450e-03,  2.6037e-03,  5.3576e-03,  8.4291e-03,\n",
       "                      -1.0479e-02, -7.0350e-03,  5.6558e-03,  1.8411e-02,  1.1956e-02,\n",
       "                       5.3564e-03,  8.9365e-03,  2.3824e-03,  5.4456e-03, -1.6324e-02,\n",
       "                       1.5570e-03,  8.4389e-03, -7.0661e-04, -1.8132e-03, -5.9987e-03,\n",
       "                       9.4284e-03,  1.5256e-02,  6.3889e-03,  3.3287e-03,  1.7133e-02,\n",
       "                       1.0354e-02,  1.4330e-02,  1.3853e-02,  1.1783e-02,  1.6198e-02,\n",
       "                      -8.6506e-03,  1.5983e-02,  7.1688e-03,  1.3772e-02,  4.4455e-03,\n",
       "                       1.6668e-02, -5.3644e-03,  1.7795e-02,  4.4281e-03, -9.2293e-03,\n",
       "                       1.2964e-02, -6.2488e-04, -2.8342e-04,  1.2235e-02,  1.0201e-02,\n",
       "                       5.9463e-03,  1.2033e-02,  1.2914e-02,  1.2968e-02,  1.2481e-02,\n",
       "                       9.6396e-03,  3.2761e-04,  4.3209e-03, -1.3388e-03, -1.2766e-02,\n",
       "                       4.3126e-03, -3.1320e-03,  2.6008e-05,  9.4736e-03,  1.4805e-02,\n",
       "                      -2.8470e-03, -1.1368e-02,  1.2965e-02, -1.1121e-03,  1.8382e-02,\n",
       "                       4.5141e-03,  1.8434e-03,  1.2704e-02,  1.1463e-02, -1.3834e-02,\n",
       "                      -8.7677e-04, -7.2587e-04,  1.1072e-02,  2.4293e-03,  4.0718e-03,\n",
       "                      -5.8031e-03,  1.0492e-02, -6.6294e-03, -8.9262e-03,  1.9337e-02,\n",
       "                       7.2007e-03,  1.4884e-02,  9.1093e-03,  3.1240e-03,  7.0490e-03,\n",
       "                       6.8572e-03,  2.2262e-03,  1.0290e-02, -6.0214e-03,  4.4594e-03,\n",
       "                       5.3444e-03, -5.1600e-03,  1.0863e-02,  7.8465e-03,  1.6185e-02,\n",
       "                       1.2771e-03,  2.3475e-02,  2.1071e-02,  2.1209e-02,  2.6302e-03,\n",
       "                      -2.8398e-03,  8.8677e-03, -3.9001e-03,  6.8875e-03,  1.3522e-02,\n",
       "                       6.1550e-03,  1.1425e-02,  1.4341e-02,  7.3221e-03,  8.2503e-03,\n",
       "                      -3.2638e-04,  2.2783e-03, -1.3564e-03,  2.9843e-03, -1.4735e-03,\n",
       "                      -1.3981e-02,  1.2161e-03,  4.0684e-03,  1.8059e-02, -4.0838e-03,\n",
       "                       2.8558e-03, -3.7181e-03, -2.7040e-04, -1.4946e-02,  1.4309e-02,\n",
       "                       5.7225e-03, -2.0625e-03,  7.8892e-03,  5.3784e-03,  2.4442e-03,\n",
       "                       7.9535e-03,  6.6799e-03, -4.6101e-03,  1.2040e-02,  4.3402e-03,\n",
       "                       1.1283e-03,  4.2626e-04,  2.4149e-03,  8.8295e-03,  4.7386e-03,\n",
       "                       1.3292e-02,  4.6131e-03,  7.5871e-03, -8.0850e-04, -9.1783e-03,\n",
       "                       1.7131e-02,  2.1774e-02,  2.0271e-02,  1.4859e-02,  9.6975e-03,\n",
       "                       1.2369e-03], dtype=torch.float64)),\n",
       "             ('6.9.convs.2.1.running_mean',\n",
       "              tensor([-0.1147, -0.4197,  0.1856,  0.1600,  0.2017, -0.3548, -0.2849, -0.2420,\n",
       "                       0.1832, -0.7393, -0.0484,  0.0668, -0.3063, -0.1696,  0.4185,  1.4938,\n",
       "                       0.0752, -0.1952,  0.0146, -0.8348, -0.1308,  0.6076,  0.2876,  0.3286,\n",
       "                      -0.4414, -0.2555, -0.3208, -0.1436, -0.2482,  0.3056, -0.0332, -0.3530,\n",
       "                      -0.1061, -0.1616, -0.0986, -0.1400,  0.1554, -0.2614, -0.5994, -0.0546,\n",
       "                      -0.4695, -0.0484,  0.0255,  0.2898,  0.2685, -0.6784,  0.2800, -0.0976,\n",
       "                      -0.3457,  0.2126,  0.0305,  0.7658,  0.2623, -0.0713, -0.8933, -0.4809,\n",
       "                      -0.0042,  0.3441, -0.3661, -0.2123,  0.1557,  0.4125, -0.1666,  0.1306,\n",
       "                       0.5786,  0.1405, -0.0231,  0.0765, -0.0091, -0.1122,  0.2508, -0.1710,\n",
       "                      -0.1152, -0.0963, -0.4225,  0.5683,  0.2269,  0.2038,  0.7734, -0.3499,\n",
       "                       0.0233,  0.1448, -0.2664,  0.2740,  0.3847, -0.1142, -0.3360,  0.0627,\n",
       "                      -0.1295, -0.4552,  0.0774, -0.0260,  0.2801,  0.1809,  0.1028,  0.1019,\n",
       "                       0.0068, -0.3263,  0.0792, -0.0847,  0.2248,  0.5321,  0.2797,  0.1087,\n",
       "                       0.1056,  0.1422, -0.0532, -0.3065, -0.5281, -0.4906,  0.3444, -0.4464,\n",
       "                       0.5022,  0.2156,  0.4486, -0.5130,  0.2573,  0.5147, -0.2340,  0.1568,\n",
       "                      -0.2512, -0.4811, -0.3822,  0.7150,  0.0380, -0.0926,  0.1554, -0.2932,\n",
       "                      -0.0347, -0.0567,  0.2579,  0.2368, -0.3463, -0.0242,  0.2719,  0.2137,\n",
       "                       0.1343, -0.0277,  0.6522,  0.4034, -0.2241, -0.3542, -0.0213,  0.0394,\n",
       "                       0.1192, -0.0051, -0.2208,  0.9563,  0.2515, -0.2958,  0.3882,  0.2171,\n",
       "                      -0.2739, -0.4189,  0.3423,  0.6098, -0.1191,  0.3831,  0.1518, -0.5003,\n",
       "                       0.0916, -0.2091,  0.1989,  0.2209, -0.0519,  0.0627, -0.0144,  0.2527,\n",
       "                      -0.5587, -0.2902, -0.1265,  0.2108, -0.0807,  0.2127,  0.2084, -0.0287,\n",
       "                       0.2230, -0.2488,  0.0266,  0.0351,  0.8118, -0.0022,  0.3518,  0.0087,\n",
       "                       0.3701, -0.1938,  0.4315, -0.3034, -0.1270, -0.1790, -0.5028,  0.7335,\n",
       "                      -0.2608, -0.1508,  0.1336,  0.0768, -0.3157, -0.2619, -0.6927, -0.3791,\n",
       "                      -0.0610,  0.1268, -0.0597,  0.3434,  0.2909, -0.3056,  0.5169, -0.1156,\n",
       "                      -0.0429, -0.4485,  0.1017,  0.0873, -0.4607,  0.0906,  0.5384, -0.3130,\n",
       "                      -0.3855,  0.0149, -0.3241,  0.5847, -0.2137, -0.1886,  0.0791,  0.5524,\n",
       "                      -0.1036, -0.3656, -0.3034,  0.6169, -0.0711, -0.1529, -0.2413, -0.3578,\n",
       "                       0.0816, -0.1168, -0.4330, -0.2819,  0.0120, -0.3821, -0.2923,  0.5618,\n",
       "                      -0.1914,  0.3470,  0.3961,  0.2907, -0.0484,  0.0759,  0.2851,  0.1941,\n",
       "                       0.1031, -0.0488,  0.2944, -0.2256, -0.0739,  0.0652, -0.4319, -0.0753],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convs.2.1.running_var',\n",
       "              tensor([0.4803, 0.5478, 0.4625, 0.3673, 0.1948, 0.2871, 0.1768, 0.3114, 0.3147,\n",
       "                      0.8863, 0.0980, 0.4286, 0.1232, 0.1722, 0.2081, 0.5771, 0.2073, 0.2113,\n",
       "                      0.1340, 0.4499, 0.2137, 0.4084, 0.2078, 0.3653, 0.4133, 0.1126, 0.2002,\n",
       "                      0.2677, 0.1279, 0.5691, 0.2992, 0.6103, 0.0756, 0.4039, 0.2903, 0.3548,\n",
       "                      0.3748, 0.2422, 0.5304, 0.5673, 0.5298, 0.1313, 0.3278, 0.3795, 0.3627,\n",
       "                      0.3433, 0.2928, 0.1844, 0.3451, 0.2010, 0.2011, 0.5306, 0.3434, 0.3450,\n",
       "                      0.4072, 0.1961, 0.4315, 0.5280, 0.4315, 0.4961, 0.1577, 0.1158, 0.3670,\n",
       "                      0.2104, 0.4688, 0.1069, 0.4705, 0.4134, 0.4165, 0.4189, 0.4089, 0.2667,\n",
       "                      0.1970, 0.4285, 0.5902, 0.3144, 0.6138, 0.2077, 0.4767, 0.1663, 0.1981,\n",
       "                      0.3499, 0.1911, 0.3684, 0.4142, 0.4183, 0.4339, 0.2023, 0.3758, 0.3068,\n",
       "                      0.3147, 0.1258, 0.2441, 0.1655, 0.3332, 0.2130, 0.4478, 0.3991, 0.4338,\n",
       "                      0.1957, 0.3035, 0.4672, 0.2368, 0.2352, 0.1689, 0.2376, 0.1583, 0.5390,\n",
       "                      0.2454, 0.2871, 0.1673, 0.4166, 0.4412, 0.3265, 0.4863, 0.4778, 0.4208,\n",
       "                      0.3350, 0.2198, 0.2302, 0.2356, 0.3902, 0.2601, 0.2968, 0.3177, 0.4056,\n",
       "                      0.1246, 0.2656, 0.2487, 0.4658, 0.2180, 0.2710, 0.3628, 0.1668, 0.2449,\n",
       "                      0.0676, 0.4741, 0.3067, 0.4366, 0.2359, 0.1120, 0.3539, 0.3944, 0.2258,\n",
       "                      0.3504, 0.4846, 0.1943, 0.4633, 0.1682, 0.4215, 0.4680, 0.1953, 0.2594,\n",
       "                      0.4176, 0.2188, 0.3408, 0.2014, 0.4109, 0.3926, 0.3819, 0.2703, 0.2993,\n",
       "                      0.1883, 0.1662, 0.4236, 0.3287, 0.4012, 0.3746, 0.3899, 0.4601, 0.4296,\n",
       "                      0.2782, 0.5423, 0.4095, 0.5457, 1.0451, 0.4015, 0.5590, 0.1655, 0.2209,\n",
       "                      0.4795, 0.1139, 0.2623, 0.3971, 0.3237, 0.5345, 0.3264, 0.1880, 0.3865,\n",
       "                      0.1408, 0.1883, 0.3963, 0.3412, 0.3708, 0.3337, 0.6031, 0.3492, 0.4676,\n",
       "                      0.2792, 0.4250, 0.1088, 0.5088, 0.4109, 0.2139, 0.2385, 0.2611, 0.2457,\n",
       "                      0.2573, 0.1701, 0.4551, 0.0689, 0.1759, 0.3959, 0.3574, 0.3201, 0.3698,\n",
       "                      0.5916, 0.3713, 0.3145, 0.3787, 0.3560, 0.1390, 0.1719, 0.4745, 0.3214,\n",
       "                      0.1735, 0.2497, 0.3693, 0.5153, 0.5044, 0.1635, 0.2772, 0.3693, 0.4279,\n",
       "                      0.4518, 0.7858, 0.1138, 0.4074, 0.5333, 0.3842, 0.4550, 0.3329, 0.6317,\n",
       "                      0.3377, 0.3532, 0.1406, 0.3594, 0.4929, 0.2524, 0.5136, 0.5394, 0.4202,\n",
       "                      0.2679, 0.2038, 0.2785, 0.3282], dtype=torch.float64)),\n",
       "             ('6.9.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.9.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0813],\n",
       "                       [ 0.0610],\n",
       "                       [-0.0926],\n",
       "                       ...,\n",
       "                       [-0.0010],\n",
       "                       [ 0.0468],\n",
       "                       [-0.0065]],\n",
       "              \n",
       "                      [[ 0.1631],\n",
       "                       [ 0.0335],\n",
       "                       [ 0.0903],\n",
       "                       ...,\n",
       "                       [ 0.1104],\n",
       "                       [ 0.0539],\n",
       "                       [-0.0513]],\n",
       "              \n",
       "                      [[ 0.0223],\n",
       "                       [-0.0326],\n",
       "                       [-0.0781],\n",
       "                       ...,\n",
       "                       [ 0.0177],\n",
       "                       [-0.1569],\n",
       "                       [ 0.0532]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0231],\n",
       "                       [ 0.1380],\n",
       "                       [ 0.0566],\n",
       "                       ...,\n",
       "                       [ 0.0244],\n",
       "                       [-0.1035],\n",
       "                       [-0.0193]],\n",
       "              \n",
       "                      [[ 0.1010],\n",
       "                       [-0.0405],\n",
       "                       [ 0.0025],\n",
       "                       ...,\n",
       "                       [-0.0571],\n",
       "                       [-0.1015],\n",
       "                       [ 0.0298]],\n",
       "              \n",
       "                      [[-0.0005],\n",
       "                       [ 0.0264],\n",
       "                       [-0.0925],\n",
       "                       ...,\n",
       "                       [ 0.0210],\n",
       "                       [ 0.0282],\n",
       "                       [-0.0404]]], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.0.1.weight',\n",
       "              tensor([0.9750, 0.9819, 0.9649, 0.9776, 0.9871, 0.9467, 0.9595, 0.9758, 1.0028,\n",
       "                      0.9632, 0.9893, 0.9389, 0.9785, 0.9899, 0.9649, 0.9732, 0.9734, 0.9575,\n",
       "                      0.9941, 0.9702, 0.9553, 0.9850, 0.9682, 0.9923, 0.9465, 0.9507, 0.9835,\n",
       "                      0.9816, 0.9771, 0.9428, 0.9717, 0.9623, 0.9523, 0.9815, 0.9632, 0.9720,\n",
       "                      0.9552, 0.9900, 0.9657, 0.9680, 0.9769, 0.9607, 0.9654, 0.9850, 0.9596,\n",
       "                      0.9854, 0.9849, 0.9691, 0.9443, 0.9693, 0.9721, 0.9748, 0.9836, 0.9763,\n",
       "                      0.9679, 0.9778, 0.9940, 0.9622, 0.9825, 0.9556, 0.9634, 0.9741, 0.9662,\n",
       "                      0.9424], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.0.1.bias',\n",
       "              tensor([ 1.2720e-02, -3.1621e-03, -5.3963e-03, -4.0528e-03,  1.7812e-03,\n",
       "                      -2.4145e-02,  2.7870e-03, -3.8004e-03,  2.2681e-03,  5.0583e-03,\n",
       "                       1.5305e-02, -1.8052e-02,  1.2570e-02, -1.5111e-02, -2.7473e-03,\n",
       "                       1.8942e-03, -1.1458e-02, -1.1732e-02,  2.9528e-02,  1.1348e-03,\n",
       "                      -1.3661e-02,  1.0696e-02,  2.9996e-03,  9.0068e-03, -1.1412e-02,\n",
       "                      -8.1377e-03, -3.0630e-03,  9.3411e-04,  1.2722e-02, -1.8332e-03,\n",
       "                       3.0892e-02, -1.5897e-02, -1.5398e-02,  9.6534e-03, -2.6470e-03,\n",
       "                       7.5174e-03, -3.3340e-03,  8.7480e-03, -1.3130e-02, -3.0183e-03,\n",
       "                       1.4194e-02, -3.4733e-03,  3.5211e-03,  3.3736e-03, -6.8094e-03,\n",
       "                      -4.1734e-03,  1.6319e-02,  1.0342e-03,  5.2933e-03,  2.1836e-03,\n",
       "                      -4.6685e-03,  1.0572e-02,  8.4254e-03,  1.9179e-02, -1.4815e-02,\n",
       "                       3.7394e-05,  1.5185e-02, -3.2271e-03,  2.3928e-03,  4.0501e-03,\n",
       "                       1.9671e-02, -2.0330e-02, -1.9237e-02,  4.9478e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.0.1.running_mean',\n",
       "              tensor([-5.1299e-01,  2.1893e-01, -2.2575e-01, -6.0247e-01,  4.1847e-01,\n",
       "                       8.5130e-01,  3.8063e-01, -1.1130e-02,  9.5625e-01,  3.2814e-01,\n",
       "                       1.4986e-01, -4.3955e-01,  1.5870e-02,  3.6438e-01, -4.8804e-01,\n",
       "                       8.7743e-01, -3.6821e-01,  1.0809e+00,  6.3100e-01, -4.2783e-01,\n",
       "                       1.1584e-01, -6.1395e-01,  1.0540e-01, -2.3331e-01, -9.3521e-01,\n",
       "                       7.2648e-01,  1.0963e-01,  9.6573e-01, -2.1461e-02, -5.1821e-02,\n",
       "                      -4.2013e-01,  1.5057e-01, -1.4243e-01,  1.2127e-01, -1.1201e+00,\n",
       "                       5.7285e-01, -5.5514e-04, -3.9032e-01, -1.4426e-01,  4.6195e-01,\n",
       "                      -7.8567e-03,  6.7652e-01, -1.5185e+00,  4.2479e-03, -4.0399e-01,\n",
       "                      -6.5788e-02,  3.2118e-01, -2.3551e-03, -6.1577e-01, -1.7627e-01,\n",
       "                      -1.4676e-01, -7.0901e-01, -2.8145e-01,  5.9551e-01,  5.9078e-01,\n",
       "                      -6.4628e-02, -4.6498e-01,  1.3718e-01,  9.6977e-02,  3.1492e-01,\n",
       "                      -4.5557e-02,  7.8428e-01,  5.0170e-01, -5.4388e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.0.1.running_var',\n",
       "              tensor([0.2462, 0.3808, 0.2727, 0.2755, 0.1013, 0.9384, 0.2195, 0.1275, 0.1446,\n",
       "                      0.4254, 0.1599, 0.3240, 0.2067, 0.1295, 0.1214, 0.1466, 0.1249, 0.4835,\n",
       "                      0.1151, 0.1273, 0.2318, 0.2259, 0.1636, 0.0779, 0.4462, 0.5663, 0.1118,\n",
       "                      0.1338, 0.1290, 0.2601, 0.2451, 0.3338, 0.2074, 0.1195, 0.1043, 0.1824,\n",
       "                      0.3848, 0.2102, 0.2994, 0.5008, 0.1136, 0.7953, 0.1328, 0.1803, 0.1153,\n",
       "                      0.1446, 0.2042, 0.1558, 0.4887, 0.1309, 0.1366, 0.1614, 0.1149, 0.2081,\n",
       "                      0.7528, 0.1145, 0.1437, 0.4131, 0.3380, 0.3017, 0.2566, 0.1229, 0.1149,\n",
       "                      0.8034], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.9.convpath.0.1.0.weight',\n",
       "              tensor([[[-0.0375, -0.0436,  0.1358,  0.0026, -0.0103],\n",
       "                       [ 0.1822,  0.0703, -0.1437, -0.0380,  0.0550],\n",
       "                       [ 0.0140, -0.0111, -0.0070, -0.1559,  0.0123],\n",
       "                       ...,\n",
       "                       [-0.1447,  0.1245,  0.0411, -0.0129, -0.1039],\n",
       "                       [ 0.0174, -0.0908,  0.0043, -0.1087, -0.1515],\n",
       "                       [-0.0010, -0.0775, -0.0219, -0.0696,  0.0306]],\n",
       "              \n",
       "                      [[-0.0341,  0.0068, -0.0217,  0.0647,  0.0235],\n",
       "                       [-0.0950, -0.1610,  0.0076, -0.0661, -0.0067],\n",
       "                       [ 0.1058,  0.0332,  0.0235,  0.1473, -0.0424],\n",
       "                       ...,\n",
       "                       [ 0.0376, -0.0129,  0.0148, -0.0103,  0.0428],\n",
       "                       [-0.1770,  0.0480, -0.0097,  0.0857, -0.0996],\n",
       "                       [ 0.1425,  0.0803,  0.0381,  0.1541, -0.0931]],\n",
       "              \n",
       "                      [[ 0.0214,  0.0125,  0.0488, -0.0231, -0.0332],\n",
       "                       [ 0.1249,  0.0729, -0.0125,  0.0653,  0.0047],\n",
       "                       [-0.0869, -0.1084, -0.0604, -0.0563, -0.0303],\n",
       "                       ...,\n",
       "                       [-0.0623, -0.0984,  0.1214, -0.0181,  0.0268],\n",
       "                       [-0.1094,  0.0629,  0.1208,  0.0964, -0.0058],\n",
       "                       [-0.0580, -0.0348,  0.1308,  0.0524,  0.0527]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0712,  0.0538, -0.0044, -0.0373,  0.1484],\n",
       "                       [-0.1403, -0.0338,  0.0162,  0.0637, -0.0987],\n",
       "                       [ 0.0461, -0.0691, -0.2055, -0.0315, -0.0023],\n",
       "                       ...,\n",
       "                       [-0.1200,  0.0239,  0.0774, -0.0476,  0.0003],\n",
       "                       [-0.0211, -0.1110, -0.1346, -0.0744, -0.0921],\n",
       "                       [ 0.0624,  0.0962,  0.0043,  0.1145, -0.0743]],\n",
       "              \n",
       "                      [[-0.0120,  0.0767, -0.0028,  0.0145,  0.0977],\n",
       "                       [-0.0431, -0.0102, -0.0652, -0.0951,  0.0675],\n",
       "                       [ 0.0216,  0.0194, -0.0389, -0.1032, -0.0460],\n",
       "                       ...,\n",
       "                       [ 0.0792, -0.1153, -0.0698,  0.0975,  0.0158],\n",
       "                       [-0.0884,  0.0936,  0.0910, -0.0802,  0.0101],\n",
       "                       [-0.0253, -0.0336,  0.0245, -0.0596, -0.0593]],\n",
       "              \n",
       "                      [[-0.0532,  0.0435,  0.2633, -0.0868,  0.1731],\n",
       "                       [ 0.0842, -0.0355,  0.0880,  0.1475,  0.1062],\n",
       "                       [ 0.0087,  0.1173,  0.0910, -0.1063, -0.0219],\n",
       "                       ...,\n",
       "                       [-0.0810, -0.0384,  0.0367, -0.0159,  0.1417],\n",
       "                       [ 0.0524,  0.0835, -0.0103,  0.1464,  0.0845],\n",
       "                       [ 0.0081, -0.0855, -0.0378,  0.0202,  0.0901]]], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.1.1.weight',\n",
       "              tensor([1.0122, 0.9534, 0.9696, 0.9633, 0.9643, 1.0124, 0.9534, 0.9577, 0.9762,\n",
       "                      0.9636, 0.9512, 0.9230, 0.9639, 0.9538, 0.9679, 0.9504, 0.9591, 0.9583,\n",
       "                      0.9664, 0.9653, 0.9647, 0.9833, 0.9629, 0.9912, 0.9715, 0.9796, 0.9683,\n",
       "                      0.9589, 0.9363, 0.9612, 0.9594, 0.9842, 0.9726, 0.9626, 1.0199, 0.9679,\n",
       "                      0.9765, 0.9893, 0.9534, 0.9179, 0.9577, 0.9812, 0.9508, 0.9425, 0.9622,\n",
       "                      0.9914, 0.9875, 0.9605, 0.9697, 0.9573, 0.9798, 0.9693, 0.9878, 0.9776,\n",
       "                      0.9646, 0.9734, 0.9695, 0.9810, 0.9722, 0.9479, 0.9644, 0.9433, 0.9418,\n",
       "                      0.9432], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.1.1.bias',\n",
       "              tensor([ 0.0243, -0.0026,  0.0020, -0.0055, -0.0125,  0.0327, -0.0025, -0.0050,\n",
       "                      -0.0023, -0.0125, -0.0225, -0.0294,  0.0046, -0.0092, -0.0133,  0.0023,\n",
       "                       0.0005, -0.0103,  0.0023,  0.0133, -0.0190,  0.0003, -0.0049, -0.0057,\n",
       "                      -0.0149,  0.0024, -0.0065, -0.0153, -0.0130,  0.0037, -0.0174,  0.0121,\n",
       "                       0.0083, -0.0075,  0.0121, -0.0063, -0.0003,  0.0060, -0.0161, -0.0155,\n",
       "                      -0.0109,  0.0043, -0.0284, -0.0300, -0.0262,  0.0230,  0.0070,  0.0077,\n",
       "                      -0.0011, -0.0060,  0.0124, -0.0075,  0.0320,  0.0162, -0.0057, -0.0250,\n",
       "                       0.0126,  0.0154,  0.0065, -0.0282, -0.0216, -0.0183, -0.0059, -0.0290],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.1.1.running_mean',\n",
       "              tensor([-1.2514,  0.0662, -0.3021, -0.1990,  1.2269, -0.8138, -0.3655,  0.0439,\n",
       "                      -0.8457, -0.0487, -0.5501,  0.0947, -0.4014,  0.1619,  0.5045, -0.6021,\n",
       "                      -0.8322, -0.6092,  0.9667, -0.4734,  0.2212, -0.5115, -1.0419,  0.2626,\n",
       "                      -0.0119, -0.1979,  0.4004,  0.5910, -0.6113, -0.0663,  0.5426,  0.2087,\n",
       "                       0.6633,  0.0207, -0.2110, -0.2268,  0.7308, -0.5353,  0.1103, -0.3382,\n",
       "                       0.5863,  1.0467,  0.2675,  0.6656,  0.1332, -0.1556, -0.1738, -0.1929,\n",
       "                       0.6005, -0.4710,  0.2127, -0.2831, -0.2715, -0.7200, -0.0334,  0.7627,\n",
       "                      -0.8695, -0.5102, -0.2038,  0.2374,  0.3683, -1.1049, -0.4220, -0.1263],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.1.1.running_var',\n",
       "              tensor([0.4951, 0.5551, 0.5161, 0.7929, 0.6730, 0.8803, 0.5287, 0.4668, 0.7212,\n",
       "                      0.4924, 0.8019, 0.7413, 1.0987, 0.7438, 0.4537, 0.8554, 0.6237, 0.6271,\n",
       "                      0.5643, 0.4603, 0.5157, 0.5985, 0.5596, 0.4932, 0.8332, 0.4350, 0.5210,\n",
       "                      0.6271, 0.5215, 0.7864, 0.7577, 0.4459, 0.5980, 0.7107, 0.4871, 0.4155,\n",
       "                      0.5383, 0.7093, 0.6683, 0.4401, 1.0233, 0.4873, 0.5053, 0.6209, 0.3728,\n",
       "                      0.4552, 0.5253, 0.4817, 0.6232, 0.6157, 0.7725, 0.5324, 0.7049, 0.5713,\n",
       "                      0.6358, 0.6494, 0.4572, 0.6735, 0.4575, 0.5501, 0.5756, 0.7872, 0.5334,\n",
       "                      0.9152], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.9.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0893],\n",
       "                       [-0.0455],\n",
       "                       [-0.2674],\n",
       "                       ...,\n",
       "                       [ 0.1167],\n",
       "                       [-0.0836],\n",
       "                       [ 0.2465]],\n",
       "              \n",
       "                      [[-0.2033],\n",
       "                       [ 0.0706],\n",
       "                       [-0.1168],\n",
       "                       ...,\n",
       "                       [-0.0581],\n",
       "                       [ 0.1263],\n",
       "                       [ 0.0072]],\n",
       "              \n",
       "                      [[-0.0705],\n",
       "                       [-0.0357],\n",
       "                       [ 0.1340],\n",
       "                       ...,\n",
       "                       [ 0.1086],\n",
       "                       [ 0.1340],\n",
       "                       [ 0.0703]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0073],\n",
       "                       [-0.0165],\n",
       "                       [-0.1484],\n",
       "                       ...,\n",
       "                       [ 0.0422],\n",
       "                       [-0.0156],\n",
       "                       [ 0.0365]],\n",
       "              \n",
       "                      [[-0.0883],\n",
       "                       [ 0.0145],\n",
       "                       [ 0.0252],\n",
       "                       ...,\n",
       "                       [-0.0438],\n",
       "                       [ 0.0520],\n",
       "                       [-0.0764]],\n",
       "              \n",
       "                      [[-0.1101],\n",
       "                       [-0.0844],\n",
       "                       [-0.0323],\n",
       "                       ...,\n",
       "                       [ 0.0104],\n",
       "                       [-0.0811],\n",
       "                       [-0.0769]]], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.2.1.weight',\n",
       "              tensor([ 3.8197e-02,  2.1366e-02,  2.4696e-02,  1.4561e-02, -6.2829e-03,\n",
       "                       2.0589e-02, -2.8215e-04,  6.6789e-03, -1.7766e-02, -1.9854e-02,\n",
       "                       3.2550e-03, -2.2405e-03,  8.2939e-03, -8.2569e-04, -8.4355e-04,\n",
       "                      -5.2118e-02,  5.4740e-03,  1.9636e-03, -9.1535e-03,  2.5672e-02,\n",
       "                      -5.5989e-03, -9.4478e-03,  1.5207e-03, -2.0959e-02,  1.0322e-02,\n",
       "                       1.7054e-04, -3.0756e-03, -1.1003e-02,  1.6626e-03,  1.2533e-02,\n",
       "                       4.0056e-02,  1.5763e-02, -1.0410e-02,  1.4234e-02, -2.7693e-02,\n",
       "                      -1.1018e-02, -2.2641e-02, -6.7160e-03, -1.2052e-02, -3.3082e-02,\n",
       "                       5.9991e-03, -8.8727e-03, -3.3118e-02, -3.2117e-03, -9.7912e-03,\n",
       "                       1.3251e-02,  2.3738e-02, -9.1586e-03,  2.3567e-03,  6.8963e-03,\n",
       "                       1.5196e-03,  3.2188e-02, -1.8743e-05,  1.8416e-02, -2.1405e-02,\n",
       "                       5.7661e-03, -4.9039e-03,  1.9656e-02,  3.9762e-03, -1.1368e-02,\n",
       "                       1.2981e-02, -1.8732e-03,  2.0916e-02, -6.4356e-03, -2.7787e-02,\n",
       "                      -8.9875e-03,  1.4702e-02,  2.1318e-02, -2.4436e-02,  1.4646e-02,\n",
       "                       5.4845e-03,  5.2684e-03,  1.6982e-02, -3.8205e-03,  2.0069e-02,\n",
       "                       1.4001e-02,  2.0501e-02,  1.8135e-02,  2.7525e-02,  1.4677e-02,\n",
       "                      -7.2911e-03, -6.9844e-03, -8.7730e-03, -4.4011e-03, -1.8420e-02,\n",
       "                      -2.7725e-02,  2.7036e-02,  4.7727e-04, -1.3584e-03, -2.1909e-02,\n",
       "                      -2.3168e-03, -1.7575e-03,  1.6877e-02, -2.5837e-03,  2.1309e-02,\n",
       "                       7.9868e-04,  4.7593e-03,  5.0303e-03,  1.9330e-02, -1.0573e-02,\n",
       "                       2.8600e-04,  1.3909e-02,  2.4698e-02, -6.4631e-03, -8.4863e-03,\n",
       "                       1.5554e-02,  6.1310e-03, -1.3418e-02,  1.1456e-02, -1.2268e-02,\n",
       "                      -1.1725e-02, -7.2832e-04, -1.7940e-02, -1.4059e-02,  1.5236e-02,\n",
       "                       1.4531e-02, -7.3030e-03,  1.3628e-02, -5.6375e-03,  5.0602e-03,\n",
       "                      -2.0684e-02, -1.5507e-03,  4.7530e-03, -8.6688e-03, -1.0095e-02,\n",
       "                       7.6345e-03,  2.4969e-03, -2.5301e-02,  1.5391e-02,  6.2170e-03,\n",
       "                       1.1334e-02,  8.4427e-04, -1.2570e-02,  1.1552e-02, -9.7551e-03,\n",
       "                       4.4813e-03,  4.0318e-02, -1.6385e-02,  1.3779e-02,  1.4663e-02,\n",
       "                      -5.1428e-04,  1.6617e-02, -9.6113e-03, -9.9553e-03,  1.1362e-02,\n",
       "                      -1.9588e-02, -6.3355e-03,  7.2053e-03, -2.0011e-02, -8.3248e-03,\n",
       "                      -2.6182e-02, -1.9902e-04, -1.1457e-02,  1.7781e-02, -2.1089e-03,\n",
       "                       1.3304e-02, -3.0273e-03, -2.2991e-02,  2.0670e-02, -1.5204e-02,\n",
       "                      -2.1731e-02,  8.4588e-03,  2.7016e-03,  5.1305e-04,  1.8516e-02,\n",
       "                       1.1654e-02, -6.0683e-03,  2.1588e-02,  1.3673e-02,  2.2667e-02,\n",
       "                      -5.0496e-03,  1.3705e-02, -2.6801e-02,  7.4720e-03,  1.9639e-03,\n",
       "                       1.5954e-02, -2.0386e-02,  4.7803e-02,  7.6350e-04,  9.5020e-03,\n",
       "                       3.2695e-03,  1.4055e-04,  4.9750e-03,  1.9632e-02,  2.1211e-02,\n",
       "                      -8.1133e-03,  7.4683e-03, -4.1438e-03,  8.7901e-03,  5.2431e-03,\n",
       "                      -2.1540e-03, -4.5825e-03, -2.8451e-02, -2.8668e-02,  2.0430e-02,\n",
       "                       2.1461e-02, -9.6153e-03, -2.3711e-02,  5.8847e-03, -6.9132e-03,\n",
       "                       5.2752e-03, -3.0356e-02,  1.9696e-02, -9.9085e-03,  1.4255e-02,\n",
       "                       5.4290e-03,  2.0562e-02,  1.9429e-02, -6.4988e-03,  1.4216e-02,\n",
       "                      -6.9774e-03, -1.3568e-02, -1.1343e-02, -1.4171e-02,  1.5999e-02,\n",
       "                       7.3574e-03, -6.1076e-03,  2.1894e-02,  6.7295e-03, -2.2721e-04,\n",
       "                      -1.0427e-02, -5.6908e-03,  6.9117e-03,  1.8961e-02,  4.8462e-04,\n",
       "                       7.7365e-04, -1.3075e-04,  1.1878e-02,  3.8245e-03, -1.2529e-02,\n",
       "                       4.3224e-03,  1.1561e-02,  4.1882e-02,  1.5538e-02,  1.4056e-02,\n",
       "                      -1.7800e-02, -1.2519e-02, -2.3626e-02, -1.4380e-02,  1.2683e-02,\n",
       "                      -1.3807e-02,  1.9819e-02, -2.5073e-02, -4.2987e-02, -1.3713e-02,\n",
       "                      -9.6242e-03,  1.1155e-02, -2.1724e-02,  1.1837e-02, -4.4349e-03,\n",
       "                      -2.6107e-02,  2.7170e-02,  9.4104e-03, -1.3384e-03,  2.2749e-02,\n",
       "                       2.3418e-03], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.2.1.bias',\n",
       "              tensor([-6.4846e-04,  3.4670e-03,  1.3560e-02,  1.3903e-02,  1.0323e-03,\n",
       "                       1.3111e-02,  7.6078e-03, -7.1756e-04,  1.2451e-02,  1.4780e-02,\n",
       "                       1.3135e-02, -7.5430e-03,  8.1079e-03, -3.5415e-03,  1.1186e-02,\n",
       "                       4.0195e-03,  2.2127e-02, -3.6439e-03,  1.0206e-02, -2.1828e-03,\n",
       "                      -3.5464e-03,  1.6337e-03,  2.8847e-03,  5.6239e-03,  2.1583e-03,\n",
       "                      -1.6947e-02,  1.1932e-03,  6.8007e-03, -1.7143e-03, -3.1892e-03,\n",
       "                       3.3445e-03,  7.4800e-03, -5.6142e-03,  1.8470e-02,  8.8573e-03,\n",
       "                       1.6069e-02,  3.8610e-03,  2.0562e-02,  5.7403e-03,  1.5740e-02,\n",
       "                      -3.9430e-04,  2.0469e-02, -7.2633e-03,  7.7431e-05,  3.5858e-03,\n",
       "                      -9.0705e-03,  3.0999e-03,  2.8893e-03, -1.1129e-02,  9.1805e-03,\n",
       "                       1.0326e-02,  7.3620e-03,  7.6639e-03,  1.0123e-02,  4.9705e-03,\n",
       "                       2.0092e-02,  8.8805e-03,  1.8766e-03,  1.2297e-02,  8.3502e-04,\n",
       "                      -2.5419e-03,  9.3884e-04,  4.7181e-03,  8.7003e-03, -5.0107e-03,\n",
       "                       6.2617e-03, -1.1034e-02,  1.5183e-02,  2.7905e-03, -1.3341e-02,\n",
       "                       4.4583e-03,  2.7764e-03,  1.4734e-03, -6.8418e-03,  1.4786e-02,\n",
       "                       2.2719e-03,  4.4943e-03,  6.9237e-03,  4.1080e-03,  1.8831e-03,\n",
       "                       7.8287e-03, -6.3343e-03,  1.0328e-02,  4.7032e-03, -3.8044e-03,\n",
       "                       1.9094e-02, -8.4135e-04, -1.9934e-03,  1.7345e-02,  1.4599e-03,\n",
       "                       9.6969e-04,  8.9588e-03,  1.0819e-02, -8.3166e-04,  1.0169e-02,\n",
       "                      -1.5017e-02,  1.0828e-02,  1.9028e-03,  8.1641e-03, -1.2069e-03,\n",
       "                       1.9103e-02,  1.3743e-02,  4.5405e-03,  8.1596e-03,  2.8097e-03,\n",
       "                      -1.6397e-03, -1.5450e-03,  2.6037e-03,  5.3576e-03,  8.4291e-03,\n",
       "                      -1.0479e-02, -7.0350e-03,  5.6558e-03,  1.8411e-02,  1.1956e-02,\n",
       "                       5.3564e-03,  8.9365e-03,  2.3824e-03,  5.4456e-03, -1.6324e-02,\n",
       "                       1.5570e-03,  8.4389e-03, -7.0661e-04, -1.8132e-03, -5.9987e-03,\n",
       "                       9.4284e-03,  1.5256e-02,  6.3889e-03,  3.3287e-03,  1.7133e-02,\n",
       "                       1.0354e-02,  1.4330e-02,  1.3853e-02,  1.1783e-02,  1.6198e-02,\n",
       "                      -8.6506e-03,  1.5983e-02,  7.1688e-03,  1.3772e-02,  4.4455e-03,\n",
       "                       1.6668e-02, -5.3644e-03,  1.7795e-02,  4.4281e-03, -9.2293e-03,\n",
       "                       1.2964e-02, -6.2488e-04, -2.8342e-04,  1.2235e-02,  1.0201e-02,\n",
       "                       5.9463e-03,  1.2033e-02,  1.2914e-02,  1.2968e-02,  1.2481e-02,\n",
       "                       9.6396e-03,  3.2761e-04,  4.3209e-03, -1.3388e-03, -1.2766e-02,\n",
       "                       4.3126e-03, -3.1320e-03,  2.6008e-05,  9.4736e-03,  1.4805e-02,\n",
       "                      -2.8470e-03, -1.1368e-02,  1.2965e-02, -1.1121e-03,  1.8382e-02,\n",
       "                       4.5141e-03,  1.8434e-03,  1.2704e-02,  1.1463e-02, -1.3834e-02,\n",
       "                      -8.7677e-04, -7.2587e-04,  1.1072e-02,  2.4293e-03,  4.0718e-03,\n",
       "                      -5.8031e-03,  1.0492e-02, -6.6294e-03, -8.9262e-03,  1.9337e-02,\n",
       "                       7.2007e-03,  1.4884e-02,  9.1093e-03,  3.1240e-03,  7.0490e-03,\n",
       "                       6.8572e-03,  2.2262e-03,  1.0290e-02, -6.0214e-03,  4.4594e-03,\n",
       "                       5.3444e-03, -5.1600e-03,  1.0863e-02,  7.8465e-03,  1.6185e-02,\n",
       "                       1.2771e-03,  2.3475e-02,  2.1071e-02,  2.1209e-02,  2.6302e-03,\n",
       "                      -2.8398e-03,  8.8677e-03, -3.9001e-03,  6.8875e-03,  1.3522e-02,\n",
       "                       6.1550e-03,  1.1425e-02,  1.4341e-02,  7.3221e-03,  8.2503e-03,\n",
       "                      -3.2638e-04,  2.2783e-03, -1.3564e-03,  2.9843e-03, -1.4735e-03,\n",
       "                      -1.3981e-02,  1.2161e-03,  4.0684e-03,  1.8059e-02, -4.0838e-03,\n",
       "                       2.8558e-03, -3.7181e-03, -2.7040e-04, -1.4946e-02,  1.4309e-02,\n",
       "                       5.7225e-03, -2.0625e-03,  7.8892e-03,  5.3784e-03,  2.4442e-03,\n",
       "                       7.9535e-03,  6.6799e-03, -4.6101e-03,  1.2040e-02,  4.3402e-03,\n",
       "                       1.1283e-03,  4.2626e-04,  2.4149e-03,  8.8295e-03,  4.7386e-03,\n",
       "                       1.3292e-02,  4.6131e-03,  7.5871e-03, -8.0850e-04, -9.1783e-03,\n",
       "                       1.7131e-02,  2.1774e-02,  2.0271e-02,  1.4859e-02,  9.6975e-03,\n",
       "                       1.2369e-03], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.2.1.running_mean',\n",
       "              tensor([-0.1147, -0.4197,  0.1856,  0.1600,  0.2017, -0.3548, -0.2849, -0.2420,\n",
       "                       0.1832, -0.7393, -0.0484,  0.0668, -0.3063, -0.1696,  0.4185,  1.4938,\n",
       "                       0.0752, -0.1952,  0.0146, -0.8348, -0.1308,  0.6076,  0.2876,  0.3286,\n",
       "                      -0.4414, -0.2555, -0.3208, -0.1436, -0.2482,  0.3056, -0.0332, -0.3530,\n",
       "                      -0.1061, -0.1616, -0.0986, -0.1400,  0.1554, -0.2614, -0.5994, -0.0546,\n",
       "                      -0.4695, -0.0484,  0.0255,  0.2898,  0.2685, -0.6784,  0.2800, -0.0976,\n",
       "                      -0.3457,  0.2126,  0.0305,  0.7658,  0.2623, -0.0713, -0.8933, -0.4809,\n",
       "                      -0.0042,  0.3441, -0.3661, -0.2123,  0.1557,  0.4125, -0.1666,  0.1306,\n",
       "                       0.5786,  0.1405, -0.0231,  0.0765, -0.0091, -0.1122,  0.2508, -0.1710,\n",
       "                      -0.1152, -0.0963, -0.4225,  0.5683,  0.2269,  0.2038,  0.7734, -0.3499,\n",
       "                       0.0233,  0.1448, -0.2664,  0.2740,  0.3847, -0.1142, -0.3360,  0.0627,\n",
       "                      -0.1295, -0.4552,  0.0774, -0.0260,  0.2801,  0.1809,  0.1028,  0.1019,\n",
       "                       0.0068, -0.3263,  0.0792, -0.0847,  0.2248,  0.5321,  0.2797,  0.1087,\n",
       "                       0.1056,  0.1422, -0.0532, -0.3065, -0.5281, -0.4906,  0.3444, -0.4464,\n",
       "                       0.5022,  0.2156,  0.4486, -0.5130,  0.2573,  0.5147, -0.2340,  0.1568,\n",
       "                      -0.2512, -0.4811, -0.3822,  0.7150,  0.0380, -0.0926,  0.1554, -0.2932,\n",
       "                      -0.0347, -0.0567,  0.2579,  0.2368, -0.3463, -0.0242,  0.2719,  0.2137,\n",
       "                       0.1343, -0.0277,  0.6522,  0.4034, -0.2241, -0.3542, -0.0213,  0.0394,\n",
       "                       0.1192, -0.0051, -0.2208,  0.9563,  0.2515, -0.2958,  0.3882,  0.2171,\n",
       "                      -0.2739, -0.4189,  0.3423,  0.6098, -0.1191,  0.3831,  0.1518, -0.5003,\n",
       "                       0.0916, -0.2091,  0.1989,  0.2209, -0.0519,  0.0627, -0.0144,  0.2527,\n",
       "                      -0.5587, -0.2902, -0.1265,  0.2108, -0.0807,  0.2127,  0.2084, -0.0287,\n",
       "                       0.2230, -0.2488,  0.0266,  0.0351,  0.8118, -0.0022,  0.3518,  0.0087,\n",
       "                       0.3701, -0.1938,  0.4315, -0.3034, -0.1270, -0.1790, -0.5028,  0.7335,\n",
       "                      -0.2608, -0.1508,  0.1336,  0.0768, -0.3157, -0.2619, -0.6927, -0.3791,\n",
       "                      -0.0610,  0.1268, -0.0597,  0.3434,  0.2909, -0.3056,  0.5169, -0.1156,\n",
       "                      -0.0429, -0.4485,  0.1017,  0.0873, -0.4607,  0.0906,  0.5384, -0.3130,\n",
       "                      -0.3855,  0.0149, -0.3241,  0.5847, -0.2137, -0.1886,  0.0791,  0.5524,\n",
       "                      -0.1036, -0.3656, -0.3034,  0.6169, -0.0711, -0.1529, -0.2413, -0.3578,\n",
       "                       0.0816, -0.1168, -0.4330, -0.2819,  0.0120, -0.3821, -0.2923,  0.5618,\n",
       "                      -0.1914,  0.3470,  0.3961,  0.2907, -0.0484,  0.0759,  0.2851,  0.1941,\n",
       "                       0.1031, -0.0488,  0.2944, -0.2256, -0.0739,  0.0652, -0.4319, -0.0753],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.2.1.running_var',\n",
       "              tensor([0.4803, 0.5478, 0.4625, 0.3673, 0.1948, 0.2871, 0.1768, 0.3114, 0.3147,\n",
       "                      0.8863, 0.0980, 0.4286, 0.1232, 0.1722, 0.2081, 0.5771, 0.2073, 0.2113,\n",
       "                      0.1340, 0.4499, 0.2137, 0.4084, 0.2078, 0.3653, 0.4133, 0.1126, 0.2002,\n",
       "                      0.2677, 0.1279, 0.5691, 0.2992, 0.6103, 0.0756, 0.4039, 0.2903, 0.3548,\n",
       "                      0.3748, 0.2422, 0.5304, 0.5673, 0.5298, 0.1313, 0.3278, 0.3795, 0.3627,\n",
       "                      0.3433, 0.2928, 0.1844, 0.3451, 0.2010, 0.2011, 0.5306, 0.3434, 0.3450,\n",
       "                      0.4072, 0.1961, 0.4315, 0.5280, 0.4315, 0.4961, 0.1577, 0.1158, 0.3670,\n",
       "                      0.2104, 0.4688, 0.1069, 0.4705, 0.4134, 0.4165, 0.4189, 0.4089, 0.2667,\n",
       "                      0.1970, 0.4285, 0.5902, 0.3144, 0.6138, 0.2077, 0.4767, 0.1663, 0.1981,\n",
       "                      0.3499, 0.1911, 0.3684, 0.4142, 0.4183, 0.4339, 0.2023, 0.3758, 0.3068,\n",
       "                      0.3147, 0.1258, 0.2441, 0.1655, 0.3332, 0.2130, 0.4478, 0.3991, 0.4338,\n",
       "                      0.1957, 0.3035, 0.4672, 0.2368, 0.2352, 0.1689, 0.2376, 0.1583, 0.5390,\n",
       "                      0.2454, 0.2871, 0.1673, 0.4166, 0.4412, 0.3265, 0.4863, 0.4778, 0.4208,\n",
       "                      0.3350, 0.2198, 0.2302, 0.2356, 0.3902, 0.2601, 0.2968, 0.3177, 0.4056,\n",
       "                      0.1246, 0.2656, 0.2487, 0.4658, 0.2180, 0.2710, 0.3628, 0.1668, 0.2449,\n",
       "                      0.0676, 0.4741, 0.3067, 0.4366, 0.2359, 0.1120, 0.3539, 0.3944, 0.2258,\n",
       "                      0.3504, 0.4846, 0.1943, 0.4633, 0.1682, 0.4215, 0.4680, 0.1953, 0.2594,\n",
       "                      0.4176, 0.2188, 0.3408, 0.2014, 0.4109, 0.3926, 0.3819, 0.2703, 0.2993,\n",
       "                      0.1883, 0.1662, 0.4236, 0.3287, 0.4012, 0.3746, 0.3899, 0.4601, 0.4296,\n",
       "                      0.2782, 0.5423, 0.4095, 0.5457, 1.0451, 0.4015, 0.5590, 0.1655, 0.2209,\n",
       "                      0.4795, 0.1139, 0.2623, 0.3971, 0.3237, 0.5345, 0.3264, 0.1880, 0.3865,\n",
       "                      0.1408, 0.1883, 0.3963, 0.3412, 0.3708, 0.3337, 0.6031, 0.3492, 0.4676,\n",
       "                      0.2792, 0.4250, 0.1088, 0.5088, 0.4109, 0.2139, 0.2385, 0.2611, 0.2457,\n",
       "                      0.2573, 0.1701, 0.4551, 0.0689, 0.1759, 0.3959, 0.3574, 0.3201, 0.3698,\n",
       "                      0.5916, 0.3713, 0.3145, 0.3787, 0.3560, 0.1390, 0.1719, 0.4745, 0.3214,\n",
       "                      0.1735, 0.2497, 0.3693, 0.5153, 0.5044, 0.1635, 0.2772, 0.3693, 0.4279,\n",
       "                      0.4518, 0.7858, 0.1138, 0.4074, 0.5333, 0.3842, 0.4550, 0.3329, 0.6317,\n",
       "                      0.3377, 0.3532, 0.1406, 0.3594, 0.4929, 0.2524, 0.5136, 0.5394, 0.4202,\n",
       "                      0.2679, 0.2038, 0.2785, 0.3282], dtype=torch.float64)),\n",
       "             ('6.9.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.10.convs.0.0.weight',\n",
       "              tensor([[[ 5.3001e-02],\n",
       "                       [ 5.1272e-02],\n",
       "                       [-1.8943e-02],\n",
       "                       ...,\n",
       "                       [ 2.4716e-02],\n",
       "                       [ 2.8205e-02],\n",
       "                       [ 1.3569e-01]],\n",
       "              \n",
       "                      [[ 5.7943e-02],\n",
       "                       [-6.3280e-02],\n",
       "                       [ 1.6232e-02],\n",
       "                       ...,\n",
       "                       [ 5.2459e-02],\n",
       "                       [-6.3835e-02],\n",
       "                       [ 4.8409e-02]],\n",
       "              \n",
       "                      [[ 3.2850e-02],\n",
       "                       [-1.7670e-01],\n",
       "                       [ 2.1905e-02],\n",
       "                       ...,\n",
       "                       [ 4.4218e-02],\n",
       "                       [ 6.3894e-02],\n",
       "                       [-2.0578e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 7.2022e-02],\n",
       "                       [ 1.4206e-02],\n",
       "                       [-5.0822e-02],\n",
       "                       ...,\n",
       "                       [ 3.2147e-02],\n",
       "                       [-1.8324e-02],\n",
       "                       [-1.6928e-02]],\n",
       "              \n",
       "                      [[ 8.7296e-02],\n",
       "                       [-4.3677e-02],\n",
       "                       [ 3.3087e-02],\n",
       "                       ...,\n",
       "                       [-8.9813e-02],\n",
       "                       [ 6.3145e-02],\n",
       "                       [-4.2425e-02]],\n",
       "              \n",
       "                      [[ 2.0281e-03],\n",
       "                       [-3.6634e-05],\n",
       "                       [ 1.7222e-01],\n",
       "                       ...,\n",
       "                       [-1.5494e-02],\n",
       "                       [ 8.0183e-02],\n",
       "                       [ 1.3786e-01]]], dtype=torch.float64)),\n",
       "             ('6.10.convs.0.1.weight',\n",
       "              tensor([0.9761, 0.9647, 0.9646, 0.9977, 1.0027, 0.9771, 0.9800, 0.9729, 0.9764,\n",
       "                      0.9411, 0.9793, 0.9648, 0.9732, 0.9549, 0.9648, 0.9778, 0.9948, 0.9920,\n",
       "                      0.9640, 0.9602, 0.9723, 0.9681, 0.9584, 1.0106, 0.9796, 0.9547, 1.0054,\n",
       "                      0.9699, 0.9842, 0.9972, 0.9735, 0.9792, 0.9563, 0.9732, 0.9663, 0.9644,\n",
       "                      0.9616, 0.9730, 0.9675, 0.9625, 0.9969, 0.9961, 0.9765, 0.9802, 0.9680,\n",
       "                      0.9787, 0.9896, 0.9960, 0.9961, 0.9659, 0.9677, 0.9514, 0.9971, 0.9549,\n",
       "                      0.9693, 0.9544, 0.9718, 0.9691, 0.9759, 0.9560, 0.9648, 0.9811, 0.9814,\n",
       "                      0.9558], dtype=torch.float64)),\n",
       "             ('6.10.convs.0.1.bias',\n",
       "              tensor([-0.0062, -0.0043, -0.0192,  0.0215,  0.0105,  0.0115,  0.0042, -0.0032,\n",
       "                       0.0220, -0.0178, -0.0044,  0.0153,  0.0239, -0.0038, -0.0082,  0.0243,\n",
       "                       0.0202,  0.0194,  0.0146, -0.0048,  0.0061, -0.0081, -0.0051,  0.0247,\n",
       "                       0.0074,  0.0132,  0.0277,  0.0038, -0.0004,  0.0364,  0.0012, -0.0044,\n",
       "                      -0.0061,  0.0169, -0.0103, -0.0108, -0.0137, -0.0135,  0.0239, -0.0124,\n",
       "                       0.0185,  0.0322,  0.0052,  0.0059,  0.0160,  0.0073,  0.0013,  0.0045,\n",
       "                       0.0278, -0.0109, -0.0147, -0.0044,  0.0156, -0.0091, -0.0028, -0.0025,\n",
       "                       0.0140,  0.0015, -0.0070, -0.0055,  0.0080,  0.0134, -0.0120, -0.0090],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.10.convs.0.1.running_mean',\n",
       "              tensor([ 0.0851,  0.1362,  1.1821, -0.1744, -0.0653, -0.4568, -0.1044,  1.5376,\n",
       "                      -0.6681,  1.5421,  0.2019,  0.6653, -1.2714, -0.1918, -0.2303, -0.1038,\n",
       "                      -0.6344, -0.6344,  0.7560, -0.8433,  0.2658,  0.5114, -0.2615,  0.1207,\n",
       "                       0.2419, -0.2890, -0.6004, -0.1606, -0.5961,  0.0796,  0.4721,  0.5530,\n",
       "                       0.2738, -0.4581,  0.2339,  0.5347, -0.0533, -0.6945,  0.1588, -0.5252,\n",
       "                      -0.6424, -0.2035,  0.0025, -0.1813, -0.2180, -0.0381, -0.5110,  0.0414,\n",
       "                      -0.8994, -0.0787,  0.5291,  0.0046, -0.4013, -0.3067,  0.4259, -0.2342,\n",
       "                       0.1026,  0.3998, -0.9588, -0.0718, -1.0658, -0.6128,  1.3851,  0.5635],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.10.convs.0.1.running_var',\n",
       "              tensor([0.2075, 0.1780, 0.3544, 0.2462, 0.1225, 0.1398, 0.1361, 1.5115, 0.1946,\n",
       "                      1.6075, 0.2783, 0.2215, 0.4317, 0.2211, 0.3148, 0.2696, 0.1128, 0.2005,\n",
       "                      0.2412, 0.4072, 0.1412, 0.8247, 0.5862, 0.1213, 0.2463, 0.4062, 0.1269,\n",
       "                      0.2243, 0.1076, 0.2449, 0.2198, 0.2023, 0.5002, 0.2317, 0.3742, 0.3920,\n",
       "                      0.2172, 0.1581, 0.0851, 0.1756, 0.1484, 0.1947, 0.1141, 0.3521, 0.2023,\n",
       "                      0.2105, 0.1509, 0.1691, 0.0952, 0.1439, 0.2637, 0.6856, 0.1059, 0.1499,\n",
       "                      0.2030, 0.0992, 0.2251, 0.2923, 0.4499, 0.2593, 0.4148, 0.2528, 0.5615,\n",
       "                      0.6002], dtype=torch.float64)),\n",
       "             ('6.10.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.10.convs.1.0.weight',\n",
       "              tensor([[[ 0.0826,  0.0750,  0.0228,  0.0698,  0.0649],\n",
       "                       [ 0.0153, -0.0929,  0.0216,  0.0377,  0.1532],\n",
       "                       [-0.0722, -0.0893, -0.1422,  0.0668, -0.1166],\n",
       "                       ...,\n",
       "                       [-0.1447, -0.0873,  0.0406,  0.0233,  0.0740],\n",
       "                       [ 0.0137, -0.0728,  0.0168, -0.0616, -0.0075],\n",
       "                       [-0.0269, -0.0355,  0.0754, -0.1133, -0.0195]],\n",
       "              \n",
       "                      [[-0.0596, -0.1007,  0.0120, -0.0124,  0.0380],\n",
       "                       [-0.0967,  0.0928,  0.0795,  0.0528,  0.0194],\n",
       "                       [ 0.0194, -0.0077, -0.0564, -0.0904, -0.1240],\n",
       "                       ...,\n",
       "                       [-0.0433, -0.0591, -0.1491,  0.0217,  0.0718],\n",
       "                       [-0.0213, -0.1208, -0.0256, -0.0895,  0.0479],\n",
       "                       [ 0.0402,  0.1456,  0.0895,  0.0109,  0.1030]],\n",
       "              \n",
       "                      [[ 0.0733, -0.0582, -0.0385,  0.0029,  0.0186],\n",
       "                       [ 0.0231,  0.0651,  0.0639,  0.1665,  0.0704],\n",
       "                       [ 0.0948, -0.0609, -0.1184, -0.0489,  0.0720],\n",
       "                       ...,\n",
       "                       [ 0.0088, -0.0404,  0.0280, -0.0296, -0.1209],\n",
       "                       [-0.0740,  0.0258, -0.0802, -0.0934,  0.0126],\n",
       "                       [-0.0336,  0.0618, -0.0700, -0.0925,  0.0064]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0528,  0.0317,  0.0551,  0.0407, -0.1539],\n",
       "                       [-0.0543,  0.0325,  0.0744,  0.0389,  0.1441],\n",
       "                       [-0.1047, -0.0849,  0.0807, -0.0975, -0.0493],\n",
       "                       ...,\n",
       "                       [ 0.1104, -0.0267, -0.0580, -0.0039, -0.1336],\n",
       "                       [ 0.0614,  0.0425,  0.0111, -0.0265,  0.1284],\n",
       "                       [ 0.0433,  0.0160, -0.0872,  0.1225, -0.0439]],\n",
       "              \n",
       "                      [[-0.0261, -0.0056, -0.0654, -0.0859,  0.0652],\n",
       "                       [-0.0291,  0.0285,  0.0541,  0.0416,  0.0197],\n",
       "                       [-0.1106, -0.2368, -0.0391,  0.0458,  0.1310],\n",
       "                       ...,\n",
       "                       [-0.1518,  0.0199, -0.1015, -0.0462,  0.0056],\n",
       "                       [ 0.0215,  0.0452,  0.0252,  0.0221, -0.0094],\n",
       "                       [-0.0929,  0.0013, -0.1021, -0.0710, -0.0472]],\n",
       "              \n",
       "                      [[ 0.0155,  0.0565,  0.0123,  0.0180, -0.1621],\n",
       "                       [ 0.0997,  0.0388, -0.0266, -0.0228,  0.0018],\n",
       "                       [-0.1008, -0.1550, -0.1184, -0.2444, -0.0671],\n",
       "                       ...,\n",
       "                       [ 0.0992, -0.1436,  0.0875, -0.0306,  0.1076],\n",
       "                       [-0.0567,  0.0806, -0.0124,  0.0722,  0.0503],\n",
       "                       [ 0.0919, -0.0561,  0.0182,  0.0457,  0.0400]]], dtype=torch.float64)),\n",
       "             ('6.10.convs.1.1.weight',\n",
       "              tensor([0.9843, 0.9771, 0.9389, 0.9296, 0.9613, 0.9532, 0.9630, 0.9553, 1.0097,\n",
       "                      0.9687, 0.9531, 0.9632, 0.9478, 0.9671, 0.9602, 0.9635, 0.9475, 0.9510,\n",
       "                      0.9420, 0.9615, 0.9554, 0.9806, 0.9963, 0.9300, 0.9560, 0.9829, 0.9949,\n",
       "                      0.9794, 0.9807, 0.9653, 0.9616, 0.9386, 0.9906, 0.9458, 0.9425, 0.9558,\n",
       "                      0.9591, 0.9932, 1.0054, 0.9593, 0.9550, 0.9495, 0.9477, 0.9575, 0.9782,\n",
       "                      0.9635, 0.9846, 0.9404, 0.9947, 0.9624, 0.9255, 0.9537, 0.9385, 0.9304,\n",
       "                      0.9719, 0.9792, 1.0084, 0.9497, 0.9683, 0.9727, 0.9633, 0.9756, 0.9931,\n",
       "                      0.9784], dtype=torch.float64)),\n",
       "             ('6.10.convs.1.1.bias',\n",
       "              tensor([ 0.0157, -0.0278, -0.0068, -0.0094, -0.0125, -0.0033, -0.0201, -0.0042,\n",
       "                      -0.0033, -0.0019,  0.0059, -0.0271, -0.0027, -0.0010, -0.0165, -0.0320,\n",
       "                      -0.0256, -0.0118, -0.0092,  0.0082, -0.0143,  0.0017,  0.0144, -0.0165,\n",
       "                      -0.0242, -0.0087,  0.0246, -0.0076,  0.0051, -0.0104, -0.0024, -0.0241,\n",
       "                       0.0030, -0.0071, -0.0205,  0.0134, -0.0302,  0.0043,  0.0242, -0.0137,\n",
       "                      -0.0159, -0.0104, -0.0250, -0.0340,  0.0002,  0.0073,  0.0042, -0.0267,\n",
       "                      -0.0129, -0.0010, -0.0269, -0.0039, -0.0198, -0.0181, -0.0052,  0.0024,\n",
       "                      -0.0061, -0.0087, -0.0110, -0.0023, -0.0061,  0.0011, -0.0065,  0.0144],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.10.convs.1.1.running_mean',\n",
       "              tensor([ 0.0187,  0.2259,  0.2150, -1.0941,  0.6182, -0.0773, -0.4612, -0.2403,\n",
       "                      -0.3761, -0.4489, -0.4950,  1.0450, -0.7571, -0.3510,  0.3584, -0.2392,\n",
       "                       0.3453,  0.3259,  0.5222, -0.4038, -0.8119, -0.7961,  0.4897, -1.0529,\n",
       "                      -0.4908,  0.3785, -0.0859, -0.5807, -0.7508, -0.5342, -0.4863,  0.3372,\n",
       "                       0.6826,  0.2338, -0.6086, -0.1205,  0.0786,  0.2197,  0.7343,  0.3162,\n",
       "                      -0.0494, -0.0666, -0.8932,  0.6783,  0.2522, -0.2925, -0.0483, -0.6740,\n",
       "                      -0.4905, -0.1910, -0.3267, -0.5483,  0.2979, -0.1600,  0.0428, -0.1494,\n",
       "                      -0.4107, -1.1245,  0.3102,  0.3486, -0.1278, -0.1558, -0.3634,  0.1078],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.10.convs.1.1.running_var',\n",
       "              tensor([0.5527, 0.3774, 0.7526, 0.8442, 0.7330, 0.5664, 0.7094, 0.5574, 0.5508,\n",
       "                      0.6127, 0.7145, 0.9200, 0.5266, 0.5878, 0.5787, 0.6866, 0.7206, 0.6839,\n",
       "                      2.1087, 0.5224, 0.7808, 0.8901, 0.6228, 0.7270, 0.6302, 0.5375, 0.5395,\n",
       "                      0.4998, 0.7418, 0.6076, 0.6234, 0.4750, 0.4875, 0.7924, 0.6141, 0.7703,\n",
       "                      0.5388, 0.4119, 0.4038, 0.5959, 0.5061, 0.6636, 0.5149, 0.8990, 0.4423,\n",
       "                      0.6233, 0.3774, 0.4376, 0.4759, 0.6566, 0.6653, 0.4274, 0.9510, 0.6285,\n",
       "                      0.6155, 0.4104, 0.4113, 0.6362, 0.9603, 0.4578, 0.4799, 0.3548, 0.5579,\n",
       "                      0.5769], dtype=torch.float64)),\n",
       "             ('6.10.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.10.convs.2.0.weight',\n",
       "              tensor([[[ 0.2122],\n",
       "                       [ 0.0268],\n",
       "                       [ 0.0150],\n",
       "                       ...,\n",
       "                       [ 0.0067],\n",
       "                       [-0.1124],\n",
       "                       [-0.2242]],\n",
       "              \n",
       "                      [[-0.1059],\n",
       "                       [ 0.0927],\n",
       "                       [-0.0035],\n",
       "                       ...,\n",
       "                       [-0.0038],\n",
       "                       [ 0.0482],\n",
       "                       [-0.3961]],\n",
       "              \n",
       "                      [[ 0.0258],\n",
       "                       [-0.0312],\n",
       "                       [-0.0507],\n",
       "                       ...,\n",
       "                       [ 0.0615],\n",
       "                       [ 0.0151],\n",
       "                       [-0.1351]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.2670],\n",
       "                       [-0.1374],\n",
       "                       [ 0.0363],\n",
       "                       ...,\n",
       "                       [-0.1588],\n",
       "                       [ 0.0924],\n",
       "                       [-0.0818]],\n",
       "              \n",
       "                      [[ 0.2567],\n",
       "                       [ 0.2478],\n",
       "                       [ 0.0953],\n",
       "                       ...,\n",
       "                       [-0.1857],\n",
       "                       [-0.2397],\n",
       "                       [-0.1418]],\n",
       "              \n",
       "                      [[ 0.0365],\n",
       "                       [ 0.0354],\n",
       "                       [ 0.1555],\n",
       "                       ...,\n",
       "                       [-0.0695],\n",
       "                       [ 0.0791],\n",
       "                       [-0.1659]]], dtype=torch.float64)),\n",
       "             ('6.10.convs.2.1.weight',\n",
       "              tensor([ 3.4072e-03, -1.2247e-02, -2.4161e-02, -2.7273e-04, -9.3331e-03,\n",
       "                       1.0570e-02,  1.4263e-02, -3.9445e-02, -7.2664e-03,  2.6008e-02,\n",
       "                      -2.1712e-02, -7.5450e-03,  2.0206e-02,  2.8890e-05,  2.0473e-02,\n",
       "                      -3.6217e-02, -3.1956e-02, -2.4624e-02,  3.3658e-03, -2.1315e-02,\n",
       "                       2.6538e-02,  1.5955e-02, -6.5937e-03, -2.1108e-02, -1.0326e-02,\n",
       "                      -2.0038e-02, -2.0217e-02, -7.3655e-03, -7.6255e-03, -8.6981e-03,\n",
       "                       1.8087e-02, -8.9053e-03, -1.3330e-02, -2.2761e-02, -1.3948e-02,\n",
       "                       2.0025e-02, -7.0666e-04, -2.4147e-02, -1.6121e-02, -1.5117e-02,\n",
       "                       1.0130e-02, -3.3159e-02,  1.8177e-02, -4.0222e-03,  2.6264e-02,\n",
       "                      -1.6140e-02, -6.5510e-03,  9.9583e-04, -4.0450e-03, -8.8346e-03,\n",
       "                       9.5506e-03, -5.2296e-03,  3.6607e-03,  1.4062e-02, -7.7209e-04,\n",
       "                      -1.4152e-02, -2.7755e-02,  8.0897e-03, -1.4775e-02, -1.0350e-02,\n",
       "                      -1.0600e-02,  8.8873e-03, -1.1732e-03,  7.1229e-03, -2.3113e-02,\n",
       "                      -3.1991e-02,  1.2511e-02,  1.8373e-02,  5.9849e-03, -1.0396e-02,\n",
       "                       7.9709e-03, -2.6618e-02, -4.4113e-03,  2.1236e-02,  1.3796e-02,\n",
       "                      -3.2869e-02,  6.6936e-03,  6.8765e-04,  1.4736e-02, -1.0892e-02,\n",
       "                      -1.1828e-02, -2.5184e-02, -1.4756e-02, -7.2027e-03,  9.2075e-03,\n",
       "                      -7.2813e-03,  5.3349e-03, -2.4958e-02, -1.2517e-02, -2.1349e-02,\n",
       "                       2.5620e-03, -6.9599e-05, -3.3621e-02,  8.3162e-03,  2.2684e-02,\n",
       "                       1.2405e-02,  3.3170e-03, -1.0054e-02,  1.6713e-04,  2.8225e-02,\n",
       "                       2.7370e-02, -8.6707e-03, -2.9238e-03,  1.2424e-02, -2.0158e-02,\n",
       "                      -2.8109e-02,  9.6405e-03,  8.8105e-03, -1.6848e-02,  2.3961e-02,\n",
       "                      -1.8228e-02,  9.2832e-03,  1.3457e-02,  3.6695e-02, -4.6360e-03,\n",
       "                      -1.4240e-02,  6.7069e-04, -3.4919e-02,  2.0982e-02,  2.6532e-04,\n",
       "                       3.9353e-03, -1.1445e-02, -2.8107e-03, -5.8135e-03, -2.9242e-02,\n",
       "                      -1.0877e-02,  1.9695e-02, -5.4900e-03, -7.4701e-03, -2.6370e-02,\n",
       "                      -3.9218e-03,  2.7932e-02,  8.1563e-03,  1.2044e-02, -4.4135e-03,\n",
       "                      -1.8723e-02, -1.0345e-02,  1.9427e-03,  4.3735e-02, -2.2981e-02,\n",
       "                      -2.1402e-02,  2.6798e-02,  3.0212e-02,  1.9308e-02,  7.0345e-04,\n",
       "                      -2.2224e-02,  9.0207e-03,  3.2886e-02,  1.1560e-02, -2.1491e-02,\n",
       "                       8.6478e-04,  2.4280e-02, -1.3888e-02, -3.6991e-02, -1.5033e-02,\n",
       "                      -1.9430e-02,  6.0777e-03,  4.9210e-03, -1.6575e-02,  6.4252e-03,\n",
       "                       1.5046e-02,  2.5336e-02, -9.5295e-03,  2.9799e-02,  3.8882e-02,\n",
       "                       1.4259e-02,  1.0982e-02,  9.2096e-03, -4.9746e-02,  2.9889e-02,\n",
       "                      -1.6953e-02,  4.4672e-03, -3.4920e-02,  4.1083e-03, -3.3216e-02,\n",
       "                       4.0766e-04,  5.9614e-02, -1.8276e-03,  2.1305e-02, -2.1283e-02,\n",
       "                      -1.1979e-02,  2.6840e-02, -5.3218e-03, -1.6319e-02, -3.6670e-02,\n",
       "                       1.0133e-02, -1.0708e-02, -3.5065e-02,  9.7089e-04,  1.1724e-02,\n",
       "                       1.7143e-02, -2.2267e-02,  6.4238e-03,  2.6369e-02,  1.6521e-02,\n",
       "                       1.0338e-03,  2.0108e-02,  2.5012e-02,  6.3948e-03, -1.8919e-02,\n",
       "                       7.6865e-04,  4.3738e-02, -6.6710e-03,  1.9074e-02,  4.0113e-02,\n",
       "                       4.2010e-03,  8.4241e-03, -2.2260e-02,  5.6589e-03, -1.2826e-02,\n",
       "                       3.4103e-02,  2.9219e-02,  1.6980e-03,  2.5113e-02, -7.7743e-03,\n",
       "                      -1.1834e-02,  3.1183e-03, -2.9594e-02,  2.3550e-02,  2.0443e-02,\n",
       "                      -1.3179e-02, -1.9991e-02, -7.1188e-04, -9.6507e-03,  1.3069e-02,\n",
       "                       2.0176e-02,  1.9741e-04,  1.1626e-04,  1.1369e-03, -1.0526e-02,\n",
       "                       4.1153e-03,  1.0016e-02,  1.0788e-02, -2.6078e-02,  2.0431e-02,\n",
       "                       1.8057e-02, -2.3363e-02, -6.2282e-03, -1.8878e-02, -1.2228e-02,\n",
       "                       2.3205e-02, -2.6446e-02, -1.3008e-02,  4.6080e-03,  1.8209e-02,\n",
       "                      -8.3547e-03,  1.7536e-02,  1.6987e-02, -5.0215e-03, -2.9718e-02,\n",
       "                       7.6276e-03, -5.4648e-03,  1.0720e-02, -2.5892e-02, -5.9801e-03,\n",
       "                      -3.2465e-03], dtype=torch.float64)),\n",
       "             ('6.10.convs.2.1.bias',\n",
       "              tensor([-2.4520e-03,  9.3828e-03,  1.1827e-02,  1.4305e-02,  5.7263e-04,\n",
       "                       9.9432e-03,  7.8757e-03, -6.7982e-04,  1.3137e-02,  1.5580e-02,\n",
       "                       1.3035e-02, -7.1952e-03,  9.3554e-03, -3.1480e-03,  1.1207e-02,\n",
       "                       2.7954e-03,  2.5311e-02, -1.9796e-03,  1.0127e-02, -7.7204e-04,\n",
       "                      -5.7045e-03,  1.2678e-03,  2.2362e-03,  6.0595e-03,  1.2055e-03,\n",
       "                      -1.5665e-02,  1.2548e-03,  6.4631e-03, -5.7722e-04, -4.4758e-03,\n",
       "                       3.3551e-03,  6.6531e-03, -5.1956e-03,  1.9016e-02,  7.6056e-03,\n",
       "                       1.6356e-02, -2.5679e-03,  2.3019e-02,  6.2591e-03,  1.3306e-02,\n",
       "                       7.7784e-04,  2.0809e-02, -8.5351e-03,  3.6030e-04,  3.9428e-03,\n",
       "                      -1.0247e-02,  6.6507e-03,  2.2572e-03, -1.1072e-02,  8.7657e-03,\n",
       "                       9.8873e-03,  5.1570e-03,  6.8206e-03,  1.0484e-02,  7.5549e-03,\n",
       "                       2.1297e-02,  9.4322e-03,  7.8660e-04,  1.2240e-02, -1.9337e-03,\n",
       "                      -4.0754e-03, -1.1740e-04,  6.7466e-03,  8.3507e-03, -4.8535e-03,\n",
       "                       6.3213e-03, -1.0384e-02,  1.5721e-02,  5.6857e-03, -1.3249e-02,\n",
       "                       8.8401e-03,  1.1107e-03,  1.6528e-03, -7.1821e-03,  1.4928e-02,\n",
       "                       5.1701e-04,  4.2543e-03,  6.3536e-03,  3.9085e-03,  4.4996e-03,\n",
       "                       6.4784e-03, -4.8751e-03,  1.0519e-02,  4.7066e-03, -4.2368e-03,\n",
       "                       1.9380e-02,  6.8053e-05, -6.0837e-03,  1.5958e-02,  9.5383e-04,\n",
       "                       1.2503e-03,  8.9366e-03,  1.1762e-02, -2.6870e-03,  1.0650e-02,\n",
       "                      -1.1184e-02,  1.1059e-02,  1.0312e-03,  1.8005e-02, -2.0933e-04,\n",
       "                       1.9040e-02,  1.3786e-02,  5.4997e-03,  8.4945e-03,  2.2343e-03,\n",
       "                      -8.4431e-04, -2.6019e-03,  2.7357e-03,  6.3142e-03,  8.2236e-03,\n",
       "                      -9.1302e-03, -5.8475e-03,  4.7060e-03,  1.8580e-02,  1.2242e-02,\n",
       "                       4.6164e-03,  1.1558e-02,  2.5087e-03,  5.3575e-03, -1.6675e-02,\n",
       "                       1.8842e-03,  8.4092e-03, -1.1372e-03, -2.8038e-03, -6.4122e-03,\n",
       "                       1.1889e-02,  1.3904e-02,  6.1809e-03,  4.4040e-03,  1.6077e-02,\n",
       "                       5.8161e-03,  1.4293e-02,  1.3822e-02,  1.0933e-02,  1.3112e-02,\n",
       "                      -1.1239e-02,  9.5890e-03,  5.7606e-03,  1.3627e-02,  1.5528e-03,\n",
       "                       1.6533e-02, -6.8476e-03,  1.7336e-02,  4.9267e-03, -6.3504e-03,\n",
       "                       1.4112e-02, -2.5164e-03,  5.0150e-04,  1.2105e-02,  9.7691e-03,\n",
       "                       5.1218e-03,  1.2296e-02,  9.9202e-03,  1.3127e-02,  1.2484e-02,\n",
       "                       9.8004e-03, -7.1805e-04,  4.3005e-03, -8.5380e-04, -1.4589e-02,\n",
       "                       4.6953e-03, -3.5371e-03, -1.5377e-04,  9.2811e-03,  1.6039e-02,\n",
       "                      -1.7357e-03, -1.2054e-02,  1.1148e-02, -1.6139e-04,  1.7936e-02,\n",
       "                       4.0661e-03,  2.1218e-03,  1.2853e-02,  1.2826e-02, -1.4234e-02,\n",
       "                       9.8502e-03,  7.6915e-04,  1.5784e-02,  2.4466e-03,  4.0880e-03,\n",
       "                      -5.2457e-03,  1.0351e-02, -6.2538e-03, -6.2423e-03,  1.9942e-02,\n",
       "                       7.2980e-03,  1.4964e-02,  9.5317e-03,  2.0691e-03,  7.2173e-03,\n",
       "                       5.8195e-03,  3.1460e-03,  8.2391e-03, -3.1033e-03,  3.8725e-03,\n",
       "                       6.2505e-03,  1.4530e-03,  5.7315e-03,  7.6802e-03,  1.5267e-02,\n",
       "                       2.2702e-03,  2.4098e-02,  2.1030e-02,  2.1161e-02,  5.8232e-03,\n",
       "                      -2.5579e-03,  7.4089e-03, -6.7027e-03,  5.9084e-03,  1.2503e-02,\n",
       "                       2.3454e-03,  1.1529e-02,  1.2954e-02,  7.5688e-03,  9.0912e-03,\n",
       "                       6.8166e-04,  1.3938e-03,  3.3354e-03,  4.0235e-03, -8.9321e-04,\n",
       "                      -1.1845e-02,  1.2893e-03,  3.7736e-03,  1.5616e-02, -2.7008e-03,\n",
       "                       3.7025e-03, -6.4905e-03,  2.1488e-05, -1.4322e-02,  1.4243e-02,\n",
       "                       5.2897e-03, -1.6429e-03,  1.0459e-02,  1.5137e-03,  2.0016e-03,\n",
       "                       9.3301e-03,  5.6510e-03, -3.1151e-03,  9.7082e-03,  4.6617e-03,\n",
       "                      -1.7597e-03,  1.3862e-03,  2.9500e-03,  4.4948e-03,  4.7447e-03,\n",
       "                       1.2681e-02,  4.0472e-03,  6.2626e-03, -1.4298e-03, -8.1937e-03,\n",
       "                       1.7483e-02,  2.0551e-02,  1.9907e-02,  1.4824e-02,  1.0463e-02,\n",
       "                       1.9561e-03], dtype=torch.float64)),\n",
       "             ('6.10.convs.2.1.running_mean',\n",
       "              tensor([ 5.6178e-01, -6.8782e-02,  2.0185e-01, -1.0731e+00,  2.1853e-01,\n",
       "                       1.0268e-01,  3.1078e-01,  7.5156e-01, -2.7289e-01,  6.0628e-01,\n",
       "                       5.3843e-01,  2.3213e-02, -3.6861e-01, -1.9925e-01,  7.4187e-01,\n",
       "                       5.7917e-01, -1.4652e-01,  4.5110e-01, -2.0102e-01, -2.4776e-02,\n",
       "                      -5.4560e-01, -3.4819e-01, -2.4555e-02,  8.4035e-01,  5.1256e-01,\n",
       "                      -2.5530e-02, -6.6425e-01,  1.7140e-01, -3.6024e-02, -4.1857e-02,\n",
       "                       6.1711e-01, -3.2143e-01, -1.0766e-02,  7.1144e-02,  8.3222e-02,\n",
       "                      -1.7820e-01, -1.9300e-01,  1.1062e-01,  8.8481e-01, -1.1790e+00,\n",
       "                      -7.5397e-01, -6.5807e-02, -3.5305e-01, -8.2003e-01,  1.2736e-01,\n",
       "                       1.2127e-01, -1.8146e-01, -9.0870e-02, -4.3714e-01, -6.1128e-01,\n",
       "                       2.4646e-01,  3.3453e-01,  1.2928e-01, -7.0750e-01,  4.4211e-01,\n",
       "                      -6.0625e-01,  5.1679e-01, -2.3441e-01, -8.2725e-01,  2.4390e-01,\n",
       "                      -2.5875e-01,  4.0395e-01, -6.4828e-01,  9.6058e-02,  2.0129e+00,\n",
       "                      -3.1218e-01,  1.8265e-02, -4.0407e-01,  6.6116e-03,  7.0741e-04,\n",
       "                       3.3268e-01, -1.2381e-01, -2.3007e-01,  7.7390e-02, -1.9671e-02,\n",
       "                      -8.2887e-01,  1.5198e-01, -3.0169e-01, -1.6719e-01,  3.0638e-01,\n",
       "                       3.4561e-01, -6.9595e-02, -3.3553e-01,  4.8904e-01, -1.6266e-01,\n",
       "                       2.3538e-01,  3.3497e-01, -5.4051e-01, -3.1362e-01, -1.3964e-01,\n",
       "                      -1.4191e-01,  9.0241e-03, -3.8299e-01, -3.7548e-01, -5.6345e-01,\n",
       "                      -5.6286e-01, -6.2053e-01,  2.7359e-01, -4.2809e-01, -3.7582e-02,\n",
       "                      -1.0939e-01, -2.4208e-01,  2.9761e-01,  2.6711e-01, -4.7773e-01,\n",
       "                      -4.7574e-01,  5.6905e-01,  3.7813e-01,  6.8381e-02,  2.9791e-01,\n",
       "                      -9.5990e-02,  5.5716e-01,  2.0655e-02,  1.3228e-02,  1.8174e-01,\n",
       "                       1.4467e+00, -3.6937e-01,  3.7790e-01, -2.4552e-01, -8.5553e-01,\n",
       "                       5.2369e-02, -4.4341e-01,  7.0195e-01, -1.3534e-01, -2.0126e-02,\n",
       "                       3.4482e-01,  4.0006e-01, -3.3399e-01, -2.5200e-02,  6.1621e-01,\n",
       "                       1.8634e-02, -1.0667e+00, -1.4345e-01,  2.9528e-01,  3.7303e-01,\n",
       "                      -5.7134e-01,  1.3169e-01, -5.8520e-02, -1.5251e-01, -4.0592e-01,\n",
       "                       5.2759e-01,  1.7364e-01,  8.3115e-01, -1.7131e-01, -2.2589e-01,\n",
       "                       1.2261e-01,  2.8909e-02,  6.1361e-01,  1.9334e-01,  6.4483e-02,\n",
       "                      -1.4849e-01,  4.2095e-02, -1.2642e-02, -6.3184e-01, -1.8436e-01,\n",
       "                       7.5699e-01, -2.7381e-01, -2.7729e-01,  7.4777e-01, -2.3450e-01,\n",
       "                       4.7544e-01, -3.8753e-01, -5.5739e-04,  8.7439e-03, -6.0848e-01,\n",
       "                       4.5884e-01, -6.8655e-01, -4.0494e-02,  5.8855e-01,  1.3876e-01,\n",
       "                      -3.4544e-01,  1.4734e-01, -4.9312e-01,  6.7195e-02, -7.8062e-02,\n",
       "                      -4.4475e-01,  2.0063e-01, -6.8710e-02, -4.9961e-01, -1.6415e-01,\n",
       "                      -1.1533e+00,  1.3045e-01,  2.3187e-01, -9.4491e-02,  9.5673e-02,\n",
       "                      -3.7021e-01,  6.2191e-01, -7.6247e-02, -2.7160e-02,  2.2064e-01,\n",
       "                      -1.4251e-01,  7.0665e-01,  4.8022e-01,  5.1456e-01,  5.9403e-02,\n",
       "                       9.6319e-02,  6.7817e-01,  7.5896e-01,  1.0440e-01, -8.2626e-01,\n",
       "                      -2.1037e-02, -2.5634e-01,  2.5498e-01,  4.9004e-01,  1.6474e-01,\n",
       "                      -4.2712e-03, -4.1767e-01, -2.6839e-02,  3.7826e-01, -3.4818e-01,\n",
       "                       3.7059e-01,  1.0642e-01, -6.6875e-02, -6.1889e-04, -1.1302e-01,\n",
       "                      -1.9289e-01,  1.4715e-01,  4.0603e-01, -1.5767e-01, -7.7226e-03,\n",
       "                      -1.9936e-01, -4.2945e-02, -3.8162e-01,  2.2403e-01, -4.3285e-01,\n",
       "                      -2.0797e-01,  4.9482e-01, -9.4220e-02,  6.4867e-01, -8.5883e-01,\n",
       "                       2.3201e-01, -3.9931e-01, -1.6298e-01, -4.6695e-01, -7.5557e-01,\n",
       "                      -1.3703e-01, -4.4461e-02, -4.4358e-01, -4.8746e-01, -2.0755e-02,\n",
       "                       5.6262e-01, -2.7123e-01,  1.9958e-01, -8.9495e-02, -3.4848e-01,\n",
       "                       8.0554e-01,  1.8498e-01, -5.2496e-01,  7.8764e-05,  2.1356e-01,\n",
       "                       9.6534e-02, -7.5191e-02, -1.7334e-01,  2.4495e-01,  3.2189e-01,\n",
       "                      -6.2282e-01], dtype=torch.float64)),\n",
       "             ('6.10.convs.2.1.running_var',\n",
       "              tensor([0.6414, 0.3865, 0.2646, 0.5096, 0.4047, 0.1970, 0.3226, 0.5637, 0.3440,\n",
       "                      0.3541, 0.4674, 0.3225, 0.1961, 0.1173, 0.5818, 0.5889, 0.4848, 0.4777,\n",
       "                      0.2309, 0.7209, 0.4128, 0.5210, 0.2913, 0.6647, 0.3132, 0.2866, 0.6578,\n",
       "                      0.5395, 0.2824, 0.1886, 0.4176, 0.3766, 0.2507, 0.3825, 0.4105, 0.3394,\n",
       "                      0.1934, 0.3391, 0.5375, 0.5433, 0.2968, 0.4990, 0.2610, 0.4648, 0.4129,\n",
       "                      0.3881, 0.2339, 0.0946, 0.4866, 0.3744, 0.2706, 0.3314, 0.2142, 0.2408,\n",
       "                      0.4084, 0.4188, 0.7038, 0.2284, 0.3762, 0.1916, 0.2609, 0.1654, 0.1990,\n",
       "                      0.1289, 0.8634, 0.3761, 0.2976, 0.2396, 0.1889, 0.4088, 0.3160, 0.1541,\n",
       "                      0.0417, 0.3735, 0.3887, 0.3390, 0.1843, 0.0834, 0.3020, 0.1834, 0.1979,\n",
       "                      0.3647, 0.3858, 0.3345, 0.2233, 0.3868, 0.1747, 0.4079, 0.3515, 0.2489,\n",
       "                      0.3010, 0.0881, 0.5005, 0.1223, 0.2784, 0.2946, 0.5440, 0.3266, 0.2057,\n",
       "                      0.2562, 0.5064, 0.3070, 0.1140, 0.1560, 0.2148, 0.3614, 0.4097, 0.3100,\n",
       "                      0.5722, 0.2523, 0.1679, 0.3997, 0.3828, 0.4530, 0.2136, 0.3676, 0.0991,\n",
       "                      0.6538, 0.4771, 0.4951, 0.2567, 0.3742, 0.1669, 0.3427, 0.3490, 0.4726,\n",
       "                      0.3186, 0.2675, 0.0856, 0.3531, 0.1977, 0.2559, 0.3485, 0.2448, 0.1307,\n",
       "                      0.3590, 0.4089, 0.3407, 0.4064, 0.3257, 0.3726, 0.2805, 0.4574, 0.5170,\n",
       "                      0.1330, 0.3319, 0.0519, 0.3706, 0.2655, 0.3802, 0.3535, 0.2284, 0.2750,\n",
       "                      0.3911, 0.3946, 0.4676, 0.1197, 0.3369, 0.4623, 0.1608, 0.1480, 0.3302,\n",
       "                      0.2723, 0.4390, 0.5125, 0.3372, 0.4923, 0.3396, 0.3069, 0.3190, 0.4701,\n",
       "                      0.1405, 0.4134, 0.1572, 0.4722, 0.3488, 0.3847, 0.0824, 0.5984, 0.3066,\n",
       "                      0.5788, 0.3256, 0.4023, 0.4478, 0.5611, 0.2623, 0.5534, 0.2696, 0.1722,\n",
       "                      0.3553, 0.2713, 0.4837, 0.2472, 0.5842, 0.4377, 0.2905, 0.4765, 0.7614,\n",
       "                      0.3932, 0.5070, 0.1500, 0.4627, 0.2270, 0.3273, 0.4728, 0.3960, 0.2141,\n",
       "                      0.2091, 0.3392, 0.5939, 0.1966, 0.3834, 0.0813, 0.3618, 0.0824, 0.1792,\n",
       "                      0.3296, 0.2856, 0.3791, 0.6279, 0.2755, 0.4400, 0.1532, 0.3508, 0.4913,\n",
       "                      0.4238, 0.4194, 0.2251, 0.4307, 0.3805, 0.2169, 0.5264, 0.4282, 0.4021,\n",
       "                      0.4860, 0.2623, 0.5181, 0.2361, 0.4318, 0.3855, 0.3994, 0.2376, 0.3360,\n",
       "                      0.1627, 0.3166, 0.1957, 0.2909, 0.5306, 0.0904, 0.4314, 0.3043, 0.3069,\n",
       "                      0.1932, 0.4822, 0.3189, 0.1674], dtype=torch.float64)),\n",
       "             ('6.10.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.10.convpath.0.0.0.weight',\n",
       "              tensor([[[ 5.3001e-02],\n",
       "                       [ 5.1272e-02],\n",
       "                       [-1.8943e-02],\n",
       "                       ...,\n",
       "                       [ 2.4716e-02],\n",
       "                       [ 2.8205e-02],\n",
       "                       [ 1.3569e-01]],\n",
       "              \n",
       "                      [[ 5.7943e-02],\n",
       "                       [-6.3280e-02],\n",
       "                       [ 1.6232e-02],\n",
       "                       ...,\n",
       "                       [ 5.2459e-02],\n",
       "                       [-6.3835e-02],\n",
       "                       [ 4.8409e-02]],\n",
       "              \n",
       "                      [[ 3.2850e-02],\n",
       "                       [-1.7670e-01],\n",
       "                       [ 2.1905e-02],\n",
       "                       ...,\n",
       "                       [ 4.4218e-02],\n",
       "                       [ 6.3894e-02],\n",
       "                       [-2.0578e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 7.2022e-02],\n",
       "                       [ 1.4206e-02],\n",
       "                       [-5.0822e-02],\n",
       "                       ...,\n",
       "                       [ 3.2147e-02],\n",
       "                       [-1.8324e-02],\n",
       "                       [-1.6928e-02]],\n",
       "              \n",
       "                      [[ 8.7296e-02],\n",
       "                       [-4.3677e-02],\n",
       "                       [ 3.3087e-02],\n",
       "                       ...,\n",
       "                       [-8.9813e-02],\n",
       "                       [ 6.3145e-02],\n",
       "                       [-4.2425e-02]],\n",
       "              \n",
       "                      [[ 2.0281e-03],\n",
       "                       [-3.6634e-05],\n",
       "                       [ 1.7222e-01],\n",
       "                       ...,\n",
       "                       [-1.5494e-02],\n",
       "                       [ 8.0183e-02],\n",
       "                       [ 1.3786e-01]]], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.0.1.weight',\n",
       "              tensor([0.9761, 0.9647, 0.9646, 0.9977, 1.0027, 0.9771, 0.9800, 0.9729, 0.9764,\n",
       "                      0.9411, 0.9793, 0.9648, 0.9732, 0.9549, 0.9648, 0.9778, 0.9948, 0.9920,\n",
       "                      0.9640, 0.9602, 0.9723, 0.9681, 0.9584, 1.0106, 0.9796, 0.9547, 1.0054,\n",
       "                      0.9699, 0.9842, 0.9972, 0.9735, 0.9792, 0.9563, 0.9732, 0.9663, 0.9644,\n",
       "                      0.9616, 0.9730, 0.9675, 0.9625, 0.9969, 0.9961, 0.9765, 0.9802, 0.9680,\n",
       "                      0.9787, 0.9896, 0.9960, 0.9961, 0.9659, 0.9677, 0.9514, 0.9971, 0.9549,\n",
       "                      0.9693, 0.9544, 0.9718, 0.9691, 0.9759, 0.9560, 0.9648, 0.9811, 0.9814,\n",
       "                      0.9558], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.0.1.bias',\n",
       "              tensor([-0.0062, -0.0043, -0.0192,  0.0215,  0.0105,  0.0115,  0.0042, -0.0032,\n",
       "                       0.0220, -0.0178, -0.0044,  0.0153,  0.0239, -0.0038, -0.0082,  0.0243,\n",
       "                       0.0202,  0.0194,  0.0146, -0.0048,  0.0061, -0.0081, -0.0051,  0.0247,\n",
       "                       0.0074,  0.0132,  0.0277,  0.0038, -0.0004,  0.0364,  0.0012, -0.0044,\n",
       "                      -0.0061,  0.0169, -0.0103, -0.0108, -0.0137, -0.0135,  0.0239, -0.0124,\n",
       "                       0.0185,  0.0322,  0.0052,  0.0059,  0.0160,  0.0073,  0.0013,  0.0045,\n",
       "                       0.0278, -0.0109, -0.0147, -0.0044,  0.0156, -0.0091, -0.0028, -0.0025,\n",
       "                       0.0140,  0.0015, -0.0070, -0.0055,  0.0080,  0.0134, -0.0120, -0.0090],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.0851,  0.1362,  1.1821, -0.1744, -0.0653, -0.4568, -0.1044,  1.5376,\n",
       "                      -0.6681,  1.5421,  0.2019,  0.6653, -1.2714, -0.1918, -0.2303, -0.1038,\n",
       "                      -0.6344, -0.6344,  0.7560, -0.8433,  0.2658,  0.5114, -0.2615,  0.1207,\n",
       "                       0.2419, -0.2890, -0.6004, -0.1606, -0.5961,  0.0796,  0.4721,  0.5530,\n",
       "                       0.2738, -0.4581,  0.2339,  0.5347, -0.0533, -0.6945,  0.1588, -0.5252,\n",
       "                      -0.6424, -0.2035,  0.0025, -0.1813, -0.2180, -0.0381, -0.5110,  0.0414,\n",
       "                      -0.8994, -0.0787,  0.5291,  0.0046, -0.4013, -0.3067,  0.4259, -0.2342,\n",
       "                       0.1026,  0.3998, -0.9588, -0.0718, -1.0658, -0.6128,  1.3851,  0.5635],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.0.1.running_var',\n",
       "              tensor([0.2075, 0.1780, 0.3544, 0.2462, 0.1225, 0.1398, 0.1361, 1.5115, 0.1946,\n",
       "                      1.6075, 0.2783, 0.2215, 0.4317, 0.2211, 0.3148, 0.2696, 0.1128, 0.2005,\n",
       "                      0.2412, 0.4072, 0.1412, 0.8247, 0.5862, 0.1213, 0.2463, 0.4062, 0.1269,\n",
       "                      0.2243, 0.1076, 0.2449, 0.2198, 0.2023, 0.5002, 0.2317, 0.3742, 0.3920,\n",
       "                      0.2172, 0.1581, 0.0851, 0.1756, 0.1484, 0.1947, 0.1141, 0.3521, 0.2023,\n",
       "                      0.2105, 0.1509, 0.1691, 0.0952, 0.1439, 0.2637, 0.6856, 0.1059, 0.1499,\n",
       "                      0.2030, 0.0992, 0.2251, 0.2923, 0.4499, 0.2593, 0.4148, 0.2528, 0.5615,\n",
       "                      0.6002], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.10.convpath.0.1.0.weight',\n",
       "              tensor([[[ 0.0826,  0.0750,  0.0228,  0.0698,  0.0649],\n",
       "                       [ 0.0153, -0.0929,  0.0216,  0.0377,  0.1532],\n",
       "                       [-0.0722, -0.0893, -0.1422,  0.0668, -0.1166],\n",
       "                       ...,\n",
       "                       [-0.1447, -0.0873,  0.0406,  0.0233,  0.0740],\n",
       "                       [ 0.0137, -0.0728,  0.0168, -0.0616, -0.0075],\n",
       "                       [-0.0269, -0.0355,  0.0754, -0.1133, -0.0195]],\n",
       "              \n",
       "                      [[-0.0596, -0.1007,  0.0120, -0.0124,  0.0380],\n",
       "                       [-0.0967,  0.0928,  0.0795,  0.0528,  0.0194],\n",
       "                       [ 0.0194, -0.0077, -0.0564, -0.0904, -0.1240],\n",
       "                       ...,\n",
       "                       [-0.0433, -0.0591, -0.1491,  0.0217,  0.0718],\n",
       "                       [-0.0213, -0.1208, -0.0256, -0.0895,  0.0479],\n",
       "                       [ 0.0402,  0.1456,  0.0895,  0.0109,  0.1030]],\n",
       "              \n",
       "                      [[ 0.0733, -0.0582, -0.0385,  0.0029,  0.0186],\n",
       "                       [ 0.0231,  0.0651,  0.0639,  0.1665,  0.0704],\n",
       "                       [ 0.0948, -0.0609, -0.1184, -0.0489,  0.0720],\n",
       "                       ...,\n",
       "                       [ 0.0088, -0.0404,  0.0280, -0.0296, -0.1209],\n",
       "                       [-0.0740,  0.0258, -0.0802, -0.0934,  0.0126],\n",
       "                       [-0.0336,  0.0618, -0.0700, -0.0925,  0.0064]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0528,  0.0317,  0.0551,  0.0407, -0.1539],\n",
       "                       [-0.0543,  0.0325,  0.0744,  0.0389,  0.1441],\n",
       "                       [-0.1047, -0.0849,  0.0807, -0.0975, -0.0493],\n",
       "                       ...,\n",
       "                       [ 0.1104, -0.0267, -0.0580, -0.0039, -0.1336],\n",
       "                       [ 0.0614,  0.0425,  0.0111, -0.0265,  0.1284],\n",
       "                       [ 0.0433,  0.0160, -0.0872,  0.1225, -0.0439]],\n",
       "              \n",
       "                      [[-0.0261, -0.0056, -0.0654, -0.0859,  0.0652],\n",
       "                       [-0.0291,  0.0285,  0.0541,  0.0416,  0.0197],\n",
       "                       [-0.1106, -0.2368, -0.0391,  0.0458,  0.1310],\n",
       "                       ...,\n",
       "                       [-0.1518,  0.0199, -0.1015, -0.0462,  0.0056],\n",
       "                       [ 0.0215,  0.0452,  0.0252,  0.0221, -0.0094],\n",
       "                       [-0.0929,  0.0013, -0.1021, -0.0710, -0.0472]],\n",
       "              \n",
       "                      [[ 0.0155,  0.0565,  0.0123,  0.0180, -0.1621],\n",
       "                       [ 0.0997,  0.0388, -0.0266, -0.0228,  0.0018],\n",
       "                       [-0.1008, -0.1550, -0.1184, -0.2444, -0.0671],\n",
       "                       ...,\n",
       "                       [ 0.0992, -0.1436,  0.0875, -0.0306,  0.1076],\n",
       "                       [-0.0567,  0.0806, -0.0124,  0.0722,  0.0503],\n",
       "                       [ 0.0919, -0.0561,  0.0182,  0.0457,  0.0400]]], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.1.1.weight',\n",
       "              tensor([0.9843, 0.9771, 0.9389, 0.9296, 0.9613, 0.9532, 0.9630, 0.9553, 1.0097,\n",
       "                      0.9687, 0.9531, 0.9632, 0.9478, 0.9671, 0.9602, 0.9635, 0.9475, 0.9510,\n",
       "                      0.9420, 0.9615, 0.9554, 0.9806, 0.9963, 0.9300, 0.9560, 0.9829, 0.9949,\n",
       "                      0.9794, 0.9807, 0.9653, 0.9616, 0.9386, 0.9906, 0.9458, 0.9425, 0.9558,\n",
       "                      0.9591, 0.9932, 1.0054, 0.9593, 0.9550, 0.9495, 0.9477, 0.9575, 0.9782,\n",
       "                      0.9635, 0.9846, 0.9404, 0.9947, 0.9624, 0.9255, 0.9537, 0.9385, 0.9304,\n",
       "                      0.9719, 0.9792, 1.0084, 0.9497, 0.9683, 0.9727, 0.9633, 0.9756, 0.9931,\n",
       "                      0.9784], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.1.1.bias',\n",
       "              tensor([ 0.0157, -0.0278, -0.0068, -0.0094, -0.0125, -0.0033, -0.0201, -0.0042,\n",
       "                      -0.0033, -0.0019,  0.0059, -0.0271, -0.0027, -0.0010, -0.0165, -0.0320,\n",
       "                      -0.0256, -0.0118, -0.0092,  0.0082, -0.0143,  0.0017,  0.0144, -0.0165,\n",
       "                      -0.0242, -0.0087,  0.0246, -0.0076,  0.0051, -0.0104, -0.0024, -0.0241,\n",
       "                       0.0030, -0.0071, -0.0205,  0.0134, -0.0302,  0.0043,  0.0242, -0.0137,\n",
       "                      -0.0159, -0.0104, -0.0250, -0.0340,  0.0002,  0.0073,  0.0042, -0.0267,\n",
       "                      -0.0129, -0.0010, -0.0269, -0.0039, -0.0198, -0.0181, -0.0052,  0.0024,\n",
       "                      -0.0061, -0.0087, -0.0110, -0.0023, -0.0061,  0.0011, -0.0065,  0.0144],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.0187,  0.2259,  0.2150, -1.0941,  0.6182, -0.0773, -0.4612, -0.2403,\n",
       "                      -0.3761, -0.4489, -0.4950,  1.0450, -0.7571, -0.3510,  0.3584, -0.2392,\n",
       "                       0.3453,  0.3259,  0.5222, -0.4038, -0.8119, -0.7961,  0.4897, -1.0529,\n",
       "                      -0.4908,  0.3785, -0.0859, -0.5807, -0.7508, -0.5342, -0.4863,  0.3372,\n",
       "                       0.6826,  0.2338, -0.6086, -0.1205,  0.0786,  0.2197,  0.7343,  0.3162,\n",
       "                      -0.0494, -0.0666, -0.8932,  0.6783,  0.2522, -0.2925, -0.0483, -0.6740,\n",
       "                      -0.4905, -0.1910, -0.3267, -0.5483,  0.2979, -0.1600,  0.0428, -0.1494,\n",
       "                      -0.4107, -1.1245,  0.3102,  0.3486, -0.1278, -0.1558, -0.3634,  0.1078],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.1.1.running_var',\n",
       "              tensor([0.5527, 0.3774, 0.7526, 0.8442, 0.7330, 0.5664, 0.7094, 0.5574, 0.5508,\n",
       "                      0.6127, 0.7145, 0.9200, 0.5266, 0.5878, 0.5787, 0.6866, 0.7206, 0.6839,\n",
       "                      2.1087, 0.5224, 0.7808, 0.8901, 0.6228, 0.7270, 0.6302, 0.5375, 0.5395,\n",
       "                      0.4998, 0.7418, 0.6076, 0.6234, 0.4750, 0.4875, 0.7924, 0.6141, 0.7703,\n",
       "                      0.5388, 0.4119, 0.4038, 0.5959, 0.5061, 0.6636, 0.5149, 0.8990, 0.4423,\n",
       "                      0.6233, 0.3774, 0.4376, 0.4759, 0.6566, 0.6653, 0.4274, 0.9510, 0.6285,\n",
       "                      0.6155, 0.4104, 0.4113, 0.6362, 0.9603, 0.4578, 0.4799, 0.3548, 0.5579,\n",
       "                      0.5769], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.10.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.2122],\n",
       "                       [ 0.0268],\n",
       "                       [ 0.0150],\n",
       "                       ...,\n",
       "                       [ 0.0067],\n",
       "                       [-0.1124],\n",
       "                       [-0.2242]],\n",
       "              \n",
       "                      [[-0.1059],\n",
       "                       [ 0.0927],\n",
       "                       [-0.0035],\n",
       "                       ...,\n",
       "                       [-0.0038],\n",
       "                       [ 0.0482],\n",
       "                       [-0.3961]],\n",
       "              \n",
       "                      [[ 0.0258],\n",
       "                       [-0.0312],\n",
       "                       [-0.0507],\n",
       "                       ...,\n",
       "                       [ 0.0615],\n",
       "                       [ 0.0151],\n",
       "                       [-0.1351]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.2670],\n",
       "                       [-0.1374],\n",
       "                       [ 0.0363],\n",
       "                       ...,\n",
       "                       [-0.1588],\n",
       "                       [ 0.0924],\n",
       "                       [-0.0818]],\n",
       "              \n",
       "                      [[ 0.2567],\n",
       "                       [ 0.2478],\n",
       "                       [ 0.0953],\n",
       "                       ...,\n",
       "                       [-0.1857],\n",
       "                       [-0.2397],\n",
       "                       [-0.1418]],\n",
       "              \n",
       "                      [[ 0.0365],\n",
       "                       [ 0.0354],\n",
       "                       [ 0.1555],\n",
       "                       ...,\n",
       "                       [-0.0695],\n",
       "                       [ 0.0791],\n",
       "                       [-0.1659]]], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.2.1.weight',\n",
       "              tensor([ 3.4072e-03, -1.2247e-02, -2.4161e-02, -2.7273e-04, -9.3331e-03,\n",
       "                       1.0570e-02,  1.4263e-02, -3.9445e-02, -7.2664e-03,  2.6008e-02,\n",
       "                      -2.1712e-02, -7.5450e-03,  2.0206e-02,  2.8890e-05,  2.0473e-02,\n",
       "                      -3.6217e-02, -3.1956e-02, -2.4624e-02,  3.3658e-03, -2.1315e-02,\n",
       "                       2.6538e-02,  1.5955e-02, -6.5937e-03, -2.1108e-02, -1.0326e-02,\n",
       "                      -2.0038e-02, -2.0217e-02, -7.3655e-03, -7.6255e-03, -8.6981e-03,\n",
       "                       1.8087e-02, -8.9053e-03, -1.3330e-02, -2.2761e-02, -1.3948e-02,\n",
       "                       2.0025e-02, -7.0666e-04, -2.4147e-02, -1.6121e-02, -1.5117e-02,\n",
       "                       1.0130e-02, -3.3159e-02,  1.8177e-02, -4.0222e-03,  2.6264e-02,\n",
       "                      -1.6140e-02, -6.5510e-03,  9.9583e-04, -4.0450e-03, -8.8346e-03,\n",
       "                       9.5506e-03, -5.2296e-03,  3.6607e-03,  1.4062e-02, -7.7209e-04,\n",
       "                      -1.4152e-02, -2.7755e-02,  8.0897e-03, -1.4775e-02, -1.0350e-02,\n",
       "                      -1.0600e-02,  8.8873e-03, -1.1732e-03,  7.1229e-03, -2.3113e-02,\n",
       "                      -3.1991e-02,  1.2511e-02,  1.8373e-02,  5.9849e-03, -1.0396e-02,\n",
       "                       7.9709e-03, -2.6618e-02, -4.4113e-03,  2.1236e-02,  1.3796e-02,\n",
       "                      -3.2869e-02,  6.6936e-03,  6.8765e-04,  1.4736e-02, -1.0892e-02,\n",
       "                      -1.1828e-02, -2.5184e-02, -1.4756e-02, -7.2027e-03,  9.2075e-03,\n",
       "                      -7.2813e-03,  5.3349e-03, -2.4958e-02, -1.2517e-02, -2.1349e-02,\n",
       "                       2.5620e-03, -6.9599e-05, -3.3621e-02,  8.3162e-03,  2.2684e-02,\n",
       "                       1.2405e-02,  3.3170e-03, -1.0054e-02,  1.6713e-04,  2.8225e-02,\n",
       "                       2.7370e-02, -8.6707e-03, -2.9238e-03,  1.2424e-02, -2.0158e-02,\n",
       "                      -2.8109e-02,  9.6405e-03,  8.8105e-03, -1.6848e-02,  2.3961e-02,\n",
       "                      -1.8228e-02,  9.2832e-03,  1.3457e-02,  3.6695e-02, -4.6360e-03,\n",
       "                      -1.4240e-02,  6.7069e-04, -3.4919e-02,  2.0982e-02,  2.6532e-04,\n",
       "                       3.9353e-03, -1.1445e-02, -2.8107e-03, -5.8135e-03, -2.9242e-02,\n",
       "                      -1.0877e-02,  1.9695e-02, -5.4900e-03, -7.4701e-03, -2.6370e-02,\n",
       "                      -3.9218e-03,  2.7932e-02,  8.1563e-03,  1.2044e-02, -4.4135e-03,\n",
       "                      -1.8723e-02, -1.0345e-02,  1.9427e-03,  4.3735e-02, -2.2981e-02,\n",
       "                      -2.1402e-02,  2.6798e-02,  3.0212e-02,  1.9308e-02,  7.0345e-04,\n",
       "                      -2.2224e-02,  9.0207e-03,  3.2886e-02,  1.1560e-02, -2.1491e-02,\n",
       "                       8.6478e-04,  2.4280e-02, -1.3888e-02, -3.6991e-02, -1.5033e-02,\n",
       "                      -1.9430e-02,  6.0777e-03,  4.9210e-03, -1.6575e-02,  6.4252e-03,\n",
       "                       1.5046e-02,  2.5336e-02, -9.5295e-03,  2.9799e-02,  3.8882e-02,\n",
       "                       1.4259e-02,  1.0982e-02,  9.2096e-03, -4.9746e-02,  2.9889e-02,\n",
       "                      -1.6953e-02,  4.4672e-03, -3.4920e-02,  4.1083e-03, -3.3216e-02,\n",
       "                       4.0766e-04,  5.9614e-02, -1.8276e-03,  2.1305e-02, -2.1283e-02,\n",
       "                      -1.1979e-02,  2.6840e-02, -5.3218e-03, -1.6319e-02, -3.6670e-02,\n",
       "                       1.0133e-02, -1.0708e-02, -3.5065e-02,  9.7089e-04,  1.1724e-02,\n",
       "                       1.7143e-02, -2.2267e-02,  6.4238e-03,  2.6369e-02,  1.6521e-02,\n",
       "                       1.0338e-03,  2.0108e-02,  2.5012e-02,  6.3948e-03, -1.8919e-02,\n",
       "                       7.6865e-04,  4.3738e-02, -6.6710e-03,  1.9074e-02,  4.0113e-02,\n",
       "                       4.2010e-03,  8.4241e-03, -2.2260e-02,  5.6589e-03, -1.2826e-02,\n",
       "                       3.4103e-02,  2.9219e-02,  1.6980e-03,  2.5113e-02, -7.7743e-03,\n",
       "                      -1.1834e-02,  3.1183e-03, -2.9594e-02,  2.3550e-02,  2.0443e-02,\n",
       "                      -1.3179e-02, -1.9991e-02, -7.1188e-04, -9.6507e-03,  1.3069e-02,\n",
       "                       2.0176e-02,  1.9741e-04,  1.1626e-04,  1.1369e-03, -1.0526e-02,\n",
       "                       4.1153e-03,  1.0016e-02,  1.0788e-02, -2.6078e-02,  2.0431e-02,\n",
       "                       1.8057e-02, -2.3363e-02, -6.2282e-03, -1.8878e-02, -1.2228e-02,\n",
       "                       2.3205e-02, -2.6446e-02, -1.3008e-02,  4.6080e-03,  1.8209e-02,\n",
       "                      -8.3547e-03,  1.7536e-02,  1.6987e-02, -5.0215e-03, -2.9718e-02,\n",
       "                       7.6276e-03, -5.4648e-03,  1.0720e-02, -2.5892e-02, -5.9801e-03,\n",
       "                      -3.2465e-03], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.2.1.bias',\n",
       "              tensor([-2.4520e-03,  9.3828e-03,  1.1827e-02,  1.4305e-02,  5.7263e-04,\n",
       "                       9.9432e-03,  7.8757e-03, -6.7982e-04,  1.3137e-02,  1.5580e-02,\n",
       "                       1.3035e-02, -7.1952e-03,  9.3554e-03, -3.1480e-03,  1.1207e-02,\n",
       "                       2.7954e-03,  2.5311e-02, -1.9796e-03,  1.0127e-02, -7.7204e-04,\n",
       "                      -5.7045e-03,  1.2678e-03,  2.2362e-03,  6.0595e-03,  1.2055e-03,\n",
       "                      -1.5665e-02,  1.2548e-03,  6.4631e-03, -5.7722e-04, -4.4758e-03,\n",
       "                       3.3551e-03,  6.6531e-03, -5.1956e-03,  1.9016e-02,  7.6056e-03,\n",
       "                       1.6356e-02, -2.5679e-03,  2.3019e-02,  6.2591e-03,  1.3306e-02,\n",
       "                       7.7784e-04,  2.0809e-02, -8.5351e-03,  3.6030e-04,  3.9428e-03,\n",
       "                      -1.0247e-02,  6.6507e-03,  2.2572e-03, -1.1072e-02,  8.7657e-03,\n",
       "                       9.8873e-03,  5.1570e-03,  6.8206e-03,  1.0484e-02,  7.5549e-03,\n",
       "                       2.1297e-02,  9.4322e-03,  7.8660e-04,  1.2240e-02, -1.9337e-03,\n",
       "                      -4.0754e-03, -1.1740e-04,  6.7466e-03,  8.3507e-03, -4.8535e-03,\n",
       "                       6.3213e-03, -1.0384e-02,  1.5721e-02,  5.6857e-03, -1.3249e-02,\n",
       "                       8.8401e-03,  1.1107e-03,  1.6528e-03, -7.1821e-03,  1.4928e-02,\n",
       "                       5.1701e-04,  4.2543e-03,  6.3536e-03,  3.9085e-03,  4.4996e-03,\n",
       "                       6.4784e-03, -4.8751e-03,  1.0519e-02,  4.7066e-03, -4.2368e-03,\n",
       "                       1.9380e-02,  6.8053e-05, -6.0837e-03,  1.5958e-02,  9.5383e-04,\n",
       "                       1.2503e-03,  8.9366e-03,  1.1762e-02, -2.6870e-03,  1.0650e-02,\n",
       "                      -1.1184e-02,  1.1059e-02,  1.0312e-03,  1.8005e-02, -2.0933e-04,\n",
       "                       1.9040e-02,  1.3786e-02,  5.4997e-03,  8.4945e-03,  2.2343e-03,\n",
       "                      -8.4431e-04, -2.6019e-03,  2.7357e-03,  6.3142e-03,  8.2236e-03,\n",
       "                      -9.1302e-03, -5.8475e-03,  4.7060e-03,  1.8580e-02,  1.2242e-02,\n",
       "                       4.6164e-03,  1.1558e-02,  2.5087e-03,  5.3575e-03, -1.6675e-02,\n",
       "                       1.8842e-03,  8.4092e-03, -1.1372e-03, -2.8038e-03, -6.4122e-03,\n",
       "                       1.1889e-02,  1.3904e-02,  6.1809e-03,  4.4040e-03,  1.6077e-02,\n",
       "                       5.8161e-03,  1.4293e-02,  1.3822e-02,  1.0933e-02,  1.3112e-02,\n",
       "                      -1.1239e-02,  9.5890e-03,  5.7606e-03,  1.3627e-02,  1.5528e-03,\n",
       "                       1.6533e-02, -6.8476e-03,  1.7336e-02,  4.9267e-03, -6.3504e-03,\n",
       "                       1.4112e-02, -2.5164e-03,  5.0150e-04,  1.2105e-02,  9.7691e-03,\n",
       "                       5.1218e-03,  1.2296e-02,  9.9202e-03,  1.3127e-02,  1.2484e-02,\n",
       "                       9.8004e-03, -7.1805e-04,  4.3005e-03, -8.5380e-04, -1.4589e-02,\n",
       "                       4.6953e-03, -3.5371e-03, -1.5377e-04,  9.2811e-03,  1.6039e-02,\n",
       "                      -1.7357e-03, -1.2054e-02,  1.1148e-02, -1.6139e-04,  1.7936e-02,\n",
       "                       4.0661e-03,  2.1218e-03,  1.2853e-02,  1.2826e-02, -1.4234e-02,\n",
       "                       9.8502e-03,  7.6915e-04,  1.5784e-02,  2.4466e-03,  4.0880e-03,\n",
       "                      -5.2457e-03,  1.0351e-02, -6.2538e-03, -6.2423e-03,  1.9942e-02,\n",
       "                       7.2980e-03,  1.4964e-02,  9.5317e-03,  2.0691e-03,  7.2173e-03,\n",
       "                       5.8195e-03,  3.1460e-03,  8.2391e-03, -3.1033e-03,  3.8725e-03,\n",
       "                       6.2505e-03,  1.4530e-03,  5.7315e-03,  7.6802e-03,  1.5267e-02,\n",
       "                       2.2702e-03,  2.4098e-02,  2.1030e-02,  2.1161e-02,  5.8232e-03,\n",
       "                      -2.5579e-03,  7.4089e-03, -6.7027e-03,  5.9084e-03,  1.2503e-02,\n",
       "                       2.3454e-03,  1.1529e-02,  1.2954e-02,  7.5688e-03,  9.0912e-03,\n",
       "                       6.8166e-04,  1.3938e-03,  3.3354e-03,  4.0235e-03, -8.9321e-04,\n",
       "                      -1.1845e-02,  1.2893e-03,  3.7736e-03,  1.5616e-02, -2.7008e-03,\n",
       "                       3.7025e-03, -6.4905e-03,  2.1488e-05, -1.4322e-02,  1.4243e-02,\n",
       "                       5.2897e-03, -1.6429e-03,  1.0459e-02,  1.5137e-03,  2.0016e-03,\n",
       "                       9.3301e-03,  5.6510e-03, -3.1151e-03,  9.7082e-03,  4.6617e-03,\n",
       "                      -1.7597e-03,  1.3862e-03,  2.9500e-03,  4.4948e-03,  4.7447e-03,\n",
       "                       1.2681e-02,  4.0472e-03,  6.2626e-03, -1.4298e-03, -8.1937e-03,\n",
       "                       1.7483e-02,  2.0551e-02,  1.9907e-02,  1.4824e-02,  1.0463e-02,\n",
       "                       1.9561e-03], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.2.1.running_mean',\n",
       "              tensor([ 5.6178e-01, -6.8782e-02,  2.0185e-01, -1.0731e+00,  2.1853e-01,\n",
       "                       1.0268e-01,  3.1078e-01,  7.5156e-01, -2.7289e-01,  6.0628e-01,\n",
       "                       5.3843e-01,  2.3213e-02, -3.6861e-01, -1.9925e-01,  7.4187e-01,\n",
       "                       5.7917e-01, -1.4652e-01,  4.5110e-01, -2.0102e-01, -2.4776e-02,\n",
       "                      -5.4560e-01, -3.4819e-01, -2.4555e-02,  8.4035e-01,  5.1256e-01,\n",
       "                      -2.5530e-02, -6.6425e-01,  1.7140e-01, -3.6024e-02, -4.1857e-02,\n",
       "                       6.1711e-01, -3.2143e-01, -1.0766e-02,  7.1144e-02,  8.3222e-02,\n",
       "                      -1.7820e-01, -1.9300e-01,  1.1062e-01,  8.8481e-01, -1.1790e+00,\n",
       "                      -7.5397e-01, -6.5807e-02, -3.5305e-01, -8.2003e-01,  1.2736e-01,\n",
       "                       1.2127e-01, -1.8146e-01, -9.0870e-02, -4.3714e-01, -6.1128e-01,\n",
       "                       2.4646e-01,  3.3453e-01,  1.2928e-01, -7.0750e-01,  4.4211e-01,\n",
       "                      -6.0625e-01,  5.1679e-01, -2.3441e-01, -8.2725e-01,  2.4390e-01,\n",
       "                      -2.5875e-01,  4.0395e-01, -6.4828e-01,  9.6058e-02,  2.0129e+00,\n",
       "                      -3.1218e-01,  1.8265e-02, -4.0407e-01,  6.6116e-03,  7.0741e-04,\n",
       "                       3.3268e-01, -1.2381e-01, -2.3007e-01,  7.7390e-02, -1.9671e-02,\n",
       "                      -8.2887e-01,  1.5198e-01, -3.0169e-01, -1.6719e-01,  3.0638e-01,\n",
       "                       3.4561e-01, -6.9595e-02, -3.3553e-01,  4.8904e-01, -1.6266e-01,\n",
       "                       2.3538e-01,  3.3497e-01, -5.4051e-01, -3.1362e-01, -1.3964e-01,\n",
       "                      -1.4191e-01,  9.0241e-03, -3.8299e-01, -3.7548e-01, -5.6345e-01,\n",
       "                      -5.6286e-01, -6.2053e-01,  2.7359e-01, -4.2809e-01, -3.7582e-02,\n",
       "                      -1.0939e-01, -2.4208e-01,  2.9761e-01,  2.6711e-01, -4.7773e-01,\n",
       "                      -4.7574e-01,  5.6905e-01,  3.7813e-01,  6.8381e-02,  2.9791e-01,\n",
       "                      -9.5990e-02,  5.5716e-01,  2.0655e-02,  1.3228e-02,  1.8174e-01,\n",
       "                       1.4467e+00, -3.6937e-01,  3.7790e-01, -2.4552e-01, -8.5553e-01,\n",
       "                       5.2369e-02, -4.4341e-01,  7.0195e-01, -1.3534e-01, -2.0126e-02,\n",
       "                       3.4482e-01,  4.0006e-01, -3.3399e-01, -2.5200e-02,  6.1621e-01,\n",
       "                       1.8634e-02, -1.0667e+00, -1.4345e-01,  2.9528e-01,  3.7303e-01,\n",
       "                      -5.7134e-01,  1.3169e-01, -5.8520e-02, -1.5251e-01, -4.0592e-01,\n",
       "                       5.2759e-01,  1.7364e-01,  8.3115e-01, -1.7131e-01, -2.2589e-01,\n",
       "                       1.2261e-01,  2.8909e-02,  6.1361e-01,  1.9334e-01,  6.4483e-02,\n",
       "                      -1.4849e-01,  4.2095e-02, -1.2642e-02, -6.3184e-01, -1.8436e-01,\n",
       "                       7.5699e-01, -2.7381e-01, -2.7729e-01,  7.4777e-01, -2.3450e-01,\n",
       "                       4.7544e-01, -3.8753e-01, -5.5739e-04,  8.7439e-03, -6.0848e-01,\n",
       "                       4.5884e-01, -6.8655e-01, -4.0494e-02,  5.8855e-01,  1.3876e-01,\n",
       "                      -3.4544e-01,  1.4734e-01, -4.9312e-01,  6.7195e-02, -7.8062e-02,\n",
       "                      -4.4475e-01,  2.0063e-01, -6.8710e-02, -4.9961e-01, -1.6415e-01,\n",
       "                      -1.1533e+00,  1.3045e-01,  2.3187e-01, -9.4491e-02,  9.5673e-02,\n",
       "                      -3.7021e-01,  6.2191e-01, -7.6247e-02, -2.7160e-02,  2.2064e-01,\n",
       "                      -1.4251e-01,  7.0665e-01,  4.8022e-01,  5.1456e-01,  5.9403e-02,\n",
       "                       9.6319e-02,  6.7817e-01,  7.5896e-01,  1.0440e-01, -8.2626e-01,\n",
       "                      -2.1037e-02, -2.5634e-01,  2.5498e-01,  4.9004e-01,  1.6474e-01,\n",
       "                      -4.2712e-03, -4.1767e-01, -2.6839e-02,  3.7826e-01, -3.4818e-01,\n",
       "                       3.7059e-01,  1.0642e-01, -6.6875e-02, -6.1889e-04, -1.1302e-01,\n",
       "                      -1.9289e-01,  1.4715e-01,  4.0603e-01, -1.5767e-01, -7.7226e-03,\n",
       "                      -1.9936e-01, -4.2945e-02, -3.8162e-01,  2.2403e-01, -4.3285e-01,\n",
       "                      -2.0797e-01,  4.9482e-01, -9.4220e-02,  6.4867e-01, -8.5883e-01,\n",
       "                       2.3201e-01, -3.9931e-01, -1.6298e-01, -4.6695e-01, -7.5557e-01,\n",
       "                      -1.3703e-01, -4.4461e-02, -4.4358e-01, -4.8746e-01, -2.0755e-02,\n",
       "                       5.6262e-01, -2.7123e-01,  1.9958e-01, -8.9495e-02, -3.4848e-01,\n",
       "                       8.0554e-01,  1.8498e-01, -5.2496e-01,  7.8764e-05,  2.1356e-01,\n",
       "                       9.6534e-02, -7.5191e-02, -1.7334e-01,  2.4495e-01,  3.2189e-01,\n",
       "                      -6.2282e-01], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.2.1.running_var',\n",
       "              tensor([0.6414, 0.3865, 0.2646, 0.5096, 0.4047, 0.1970, 0.3226, 0.5637, 0.3440,\n",
       "                      0.3541, 0.4674, 0.3225, 0.1961, 0.1173, 0.5818, 0.5889, 0.4848, 0.4777,\n",
       "                      0.2309, 0.7209, 0.4128, 0.5210, 0.2913, 0.6647, 0.3132, 0.2866, 0.6578,\n",
       "                      0.5395, 0.2824, 0.1886, 0.4176, 0.3766, 0.2507, 0.3825, 0.4105, 0.3394,\n",
       "                      0.1934, 0.3391, 0.5375, 0.5433, 0.2968, 0.4990, 0.2610, 0.4648, 0.4129,\n",
       "                      0.3881, 0.2339, 0.0946, 0.4866, 0.3744, 0.2706, 0.3314, 0.2142, 0.2408,\n",
       "                      0.4084, 0.4188, 0.7038, 0.2284, 0.3762, 0.1916, 0.2609, 0.1654, 0.1990,\n",
       "                      0.1289, 0.8634, 0.3761, 0.2976, 0.2396, 0.1889, 0.4088, 0.3160, 0.1541,\n",
       "                      0.0417, 0.3735, 0.3887, 0.3390, 0.1843, 0.0834, 0.3020, 0.1834, 0.1979,\n",
       "                      0.3647, 0.3858, 0.3345, 0.2233, 0.3868, 0.1747, 0.4079, 0.3515, 0.2489,\n",
       "                      0.3010, 0.0881, 0.5005, 0.1223, 0.2784, 0.2946, 0.5440, 0.3266, 0.2057,\n",
       "                      0.2562, 0.5064, 0.3070, 0.1140, 0.1560, 0.2148, 0.3614, 0.4097, 0.3100,\n",
       "                      0.5722, 0.2523, 0.1679, 0.3997, 0.3828, 0.4530, 0.2136, 0.3676, 0.0991,\n",
       "                      0.6538, 0.4771, 0.4951, 0.2567, 0.3742, 0.1669, 0.3427, 0.3490, 0.4726,\n",
       "                      0.3186, 0.2675, 0.0856, 0.3531, 0.1977, 0.2559, 0.3485, 0.2448, 0.1307,\n",
       "                      0.3590, 0.4089, 0.3407, 0.4064, 0.3257, 0.3726, 0.2805, 0.4574, 0.5170,\n",
       "                      0.1330, 0.3319, 0.0519, 0.3706, 0.2655, 0.3802, 0.3535, 0.2284, 0.2750,\n",
       "                      0.3911, 0.3946, 0.4676, 0.1197, 0.3369, 0.4623, 0.1608, 0.1480, 0.3302,\n",
       "                      0.2723, 0.4390, 0.5125, 0.3372, 0.4923, 0.3396, 0.3069, 0.3190, 0.4701,\n",
       "                      0.1405, 0.4134, 0.1572, 0.4722, 0.3488, 0.3847, 0.0824, 0.5984, 0.3066,\n",
       "                      0.5788, 0.3256, 0.4023, 0.4478, 0.5611, 0.2623, 0.5534, 0.2696, 0.1722,\n",
       "                      0.3553, 0.2713, 0.4837, 0.2472, 0.5842, 0.4377, 0.2905, 0.4765, 0.7614,\n",
       "                      0.3932, 0.5070, 0.1500, 0.4627, 0.2270, 0.3273, 0.4728, 0.3960, 0.2141,\n",
       "                      0.2091, 0.3392, 0.5939, 0.1966, 0.3834, 0.0813, 0.3618, 0.0824, 0.1792,\n",
       "                      0.3296, 0.2856, 0.3791, 0.6279, 0.2755, 0.4400, 0.1532, 0.3508, 0.4913,\n",
       "                      0.4238, 0.4194, 0.2251, 0.4307, 0.3805, 0.2169, 0.5264, 0.4282, 0.4021,\n",
       "                      0.4860, 0.2623, 0.5181, 0.2361, 0.4318, 0.3855, 0.3994, 0.2376, 0.3360,\n",
       "                      0.1627, 0.3166, 0.1957, 0.2909, 0.5306, 0.0904, 0.4314, 0.3043, 0.3069,\n",
       "                      0.1932, 0.4822, 0.3189, 0.1674], dtype=torch.float64)),\n",
       "             ('6.10.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.11.convs.0.0.weight',\n",
       "              tensor([[[ 0.0154],\n",
       "                       [-0.0892],\n",
       "                       [-0.0168],\n",
       "                       ...,\n",
       "                       [ 0.0576],\n",
       "                       [-0.0533],\n",
       "                       [-0.0429]],\n",
       "              \n",
       "                      [[ 0.0828],\n",
       "                       [ 0.0308],\n",
       "                       [-0.1305],\n",
       "                       ...,\n",
       "                       [ 0.0635],\n",
       "                       [-0.0497],\n",
       "                       [ 0.0555]],\n",
       "              \n",
       "                      [[ 0.0704],\n",
       "                       [-0.0243],\n",
       "                       [ 0.0156],\n",
       "                       ...,\n",
       "                       [ 0.1265],\n",
       "                       [-0.0188],\n",
       "                       [-0.0606]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0218],\n",
       "                       [-0.0390],\n",
       "                       [ 0.2252],\n",
       "                       ...,\n",
       "                       [-0.0789],\n",
       "                       [-0.0200],\n",
       "                       [ 0.0347]],\n",
       "              \n",
       "                      [[ 0.1816],\n",
       "                       [-0.0967],\n",
       "                       [ 0.1080],\n",
       "                       ...,\n",
       "                       [-0.1956],\n",
       "                       [ 0.0873],\n",
       "                       [-0.0842]],\n",
       "              \n",
       "                      [[-0.0525],\n",
       "                       [ 0.2406],\n",
       "                       [-0.0742],\n",
       "                       ...,\n",
       "                       [ 0.0058],\n",
       "                       [-0.0531],\n",
       "                       [-0.1727]]], dtype=torch.float64)),\n",
       "             ('6.11.convs.0.1.weight',\n",
       "              tensor([0.9596, 0.9934, 0.9685, 0.9600, 0.9796, 0.9957, 0.9836, 0.9597, 0.9823,\n",
       "                      0.9913, 1.0027, 0.9769, 0.9645, 1.0102, 1.0212, 0.9701, 0.9957, 0.9628,\n",
       "                      0.9860, 0.9736, 0.9548, 0.9611, 0.9547, 0.9813, 0.9858, 0.9365, 0.9604,\n",
       "                      0.9404, 0.9735, 0.9664, 0.9631, 0.9603, 0.9786, 0.9689, 0.9417, 0.9934,\n",
       "                      0.9648, 0.9770, 0.9708, 0.9909, 0.9685, 0.9773, 0.9691, 0.9820, 0.9597,\n",
       "                      0.9574, 0.9955, 1.0087, 0.9527, 0.9812, 0.9746, 0.9523, 0.9837, 1.0006,\n",
       "                      0.9724, 0.9674, 0.9542, 0.9719, 0.9766, 0.9627, 0.9540, 0.9976, 0.9806,\n",
       "                      0.9635], dtype=torch.float64)),\n",
       "             ('6.11.convs.0.1.bias',\n",
       "              tensor([-0.0107,  0.0104, -0.0121, -0.0005,  0.0199,  0.0104, -0.0085, -0.0123,\n",
       "                      -0.0101,  0.0068,  0.0012,  0.0063, -0.0050,  0.0176,  0.0203,  0.0073,\n",
       "                       0.0096, -0.0027,  0.0075,  0.0069, -0.0050, -0.0132, -0.0021,  0.0021,\n",
       "                      -0.0044, -0.0118, -0.0145, -0.0015, -0.0029, -0.0021,  0.0017,  0.0052,\n",
       "                       0.0099,  0.0065, -0.0168, -0.0130, -0.0187, -0.0004, -0.0026,  0.0141,\n",
       "                       0.0053,  0.0042, -0.0060, -0.0028, -0.0035, -0.0080,  0.0356,  0.0225,\n",
       "                       0.0015,  0.0026,  0.0061,  0.0069,  0.0186,  0.0019, -0.0150, -0.0068,\n",
       "                      -0.0269,  0.0091, -0.0032,  0.0009, -0.0025,  0.0170,  0.0210, -0.0041],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convs.0.1.running_mean',\n",
       "              tensor([ 0.4950, -0.2189,  0.5672,  0.2633,  0.1172,  0.0840, -0.6911,  0.2952,\n",
       "                      -0.2401, -0.0879,  0.8806,  0.0823, -0.4327,  0.2016, -0.1877, -0.5493,\n",
       "                       0.0455,  0.0628, -0.1649, -0.0487,  1.1227,  0.6757, -0.8174, -0.2393,\n",
       "                       0.6309, -1.7026, -0.5865, -0.4591, -0.0186,  0.0079, -0.9567,  0.1949,\n",
       "                      -0.3394,  0.3199, -0.0524, -0.7097, -0.2581, -0.3622,  0.2799, -1.1128,\n",
       "                      -0.6765, -0.7776, -0.4817,  0.0455, -0.6007, -1.1892, -0.5902,  0.2592,\n",
       "                      -0.6991, -0.4447, -0.3765, -0.2652, -0.3499,  0.1095, -0.2441,  0.8194,\n",
       "                       0.8722, -0.2361, -0.3028, -0.1793,  0.0786,  0.5229, -0.3110, -0.6732],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convs.0.1.running_var',\n",
       "              tensor([0.6827, 0.1753, 0.4409, 0.5313, 0.1581, 0.2099, 0.1348, 0.1767, 0.1019,\n",
       "                      0.1488, 0.1245, 0.3008, 0.7290, 0.1824, 0.1648, 0.1633, 0.1624, 0.4288,\n",
       "                      0.2120, 0.1079, 0.3726, 0.1751, 0.5771, 0.1126, 0.3439, 0.3083, 0.9508,\n",
       "                      0.5869, 0.4247, 0.3686, 0.3968, 0.8334, 0.3589, 0.2149, 0.1824, 0.1025,\n",
       "                      0.1627, 0.8410, 0.1539, 0.2908, 0.1362, 0.1757, 0.2422, 0.2176, 0.1431,\n",
       "                      0.3602, 0.1249, 0.3043, 0.3525, 0.1683, 0.7416, 0.2500, 0.1035, 0.1107,\n",
       "                      0.4629, 0.2575, 0.3430, 0.2244, 0.1956, 0.2627, 0.3248, 0.1562, 0.1535,\n",
       "                      0.2104], dtype=torch.float64)),\n",
       "             ('6.11.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.11.convs.1.0.weight',\n",
       "              tensor([[[ 0.0854, -0.1115,  0.0910, -0.0257, -0.1021],\n",
       "                       [-0.0465, -0.0519,  0.0335, -0.0106, -0.0021],\n",
       "                       [-0.0080,  0.0325,  0.0157, -0.1898,  0.0446],\n",
       "                       ...,\n",
       "                       [ 0.0029,  0.0233, -0.1042,  0.0265,  0.0019],\n",
       "                       [ 0.1215,  0.0122,  0.0646, -0.0776,  0.0984],\n",
       "                       [ 0.0885,  0.0831,  0.0270,  0.0056, -0.0402]],\n",
       "              \n",
       "                      [[ 0.0468, -0.1644,  0.0471,  0.0381,  0.0812],\n",
       "                       [ 0.0161, -0.1158,  0.0210, -0.0087,  0.0875],\n",
       "                       [-0.0499, -0.1038, -0.0260, -0.0874,  0.0154],\n",
       "                       ...,\n",
       "                       [ 0.0164, -0.0409, -0.0774,  0.0090, -0.0478],\n",
       "                       [ 0.0613,  0.1101, -0.0117,  0.0719,  0.1147],\n",
       "                       [ 0.0128, -0.0990,  0.0429,  0.1194, -0.0578]],\n",
       "              \n",
       "                      [[ 0.0901,  0.1092, -0.0311,  0.0363,  0.0239],\n",
       "                       [-0.1044,  0.0044,  0.0184, -0.0521,  0.1046],\n",
       "                       [ 0.1063, -0.0056,  0.0597,  0.0506,  0.0896],\n",
       "                       ...,\n",
       "                       [ 0.0290,  0.0758,  0.0007,  0.0491,  0.0408],\n",
       "                       [-0.1737,  0.0390, -0.0331,  0.0662,  0.0338],\n",
       "                       [-0.0736,  0.0315,  0.0377,  0.0785,  0.1469]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1238,  0.0901, -0.0040,  0.0505,  0.0639],\n",
       "                       [-0.1210, -0.0307,  0.0020, -0.1090, -0.1993],\n",
       "                       [-0.0245, -0.0638, -0.0814,  0.0127,  0.0632],\n",
       "                       ...,\n",
       "                       [ 0.0482,  0.1729,  0.0074,  0.0028,  0.1392],\n",
       "                       [ 0.0398, -0.0963, -0.0877, -0.0545, -0.0195],\n",
       "                       [-0.0831, -0.2894, -0.0571,  0.0226,  0.0425]],\n",
       "              \n",
       "                      [[-0.0260,  0.0724,  0.0384, -0.0503, -0.0473],\n",
       "                       [-0.0624, -0.0474, -0.0228, -0.0172, -0.1212],\n",
       "                       [ 0.0401,  0.0483,  0.0364, -0.0898,  0.0597],\n",
       "                       ...,\n",
       "                       [ 0.1320, -0.0026, -0.0678,  0.0190, -0.0085],\n",
       "                       [-0.0574,  0.0399, -0.0299, -0.0481,  0.0328],\n",
       "                       [ 0.0096, -0.0581, -0.0655, -0.1049,  0.0407]],\n",
       "              \n",
       "                      [[-0.0368, -0.0310, -0.0578, -0.0234, -0.0223],\n",
       "                       [ 0.0004,  0.0856,  0.0966, -0.0549,  0.0098],\n",
       "                       [ 0.0087, -0.1206,  0.0490, -0.0564, -0.0399],\n",
       "                       ...,\n",
       "                       [-0.1280, -0.0396, -0.1476, -0.0600,  0.0106],\n",
       "                       [-0.0606,  0.0986,  0.0973, -0.0027, -0.1676],\n",
       "                       [ 0.1519, -0.0333, -0.0685,  0.0084, -0.0105]]], dtype=torch.float64)),\n",
       "             ('6.11.convs.1.1.weight',\n",
       "              tensor([0.9912, 0.9629, 0.9698, 0.9828, 1.0111, 0.9667, 0.9593, 0.9920, 0.9381,\n",
       "                      0.9446, 1.0031, 0.9954, 0.9680, 0.9563, 0.9476, 0.9658, 0.9762, 0.9382,\n",
       "                      0.9707, 0.9592, 0.9647, 0.9743, 0.9415, 0.9884, 0.9507, 0.9862, 0.9512,\n",
       "                      0.9719, 0.9689, 0.9538, 0.9831, 0.9680, 0.9937, 0.9548, 0.9752, 0.9630,\n",
       "                      0.9558, 0.9569, 0.9749, 0.9653, 0.9823, 0.9545, 0.9534, 0.9778, 0.9631,\n",
       "                      0.9571, 0.9585, 0.9838, 0.9633, 0.9653, 0.9623, 0.9589, 0.9706, 0.9679,\n",
       "                      0.9853, 0.9307, 0.9720, 0.9967, 0.9524, 0.9583, 0.9553, 0.9541, 0.9374,\n",
       "                      1.0092], dtype=torch.float64)),\n",
       "             ('6.11.convs.1.1.bias',\n",
       "              tensor([-1.5748e-02,  1.0693e-02, -2.1226e-02, -5.4627e-03,  1.6458e-02,\n",
       "                      -1.9048e-02, -4.5592e-03,  7.3531e-04, -1.3906e-02, -1.9597e-02,\n",
       "                      -4.8206e-03,  2.0287e-02, -2.4424e-03, -6.8188e-03, -9.2368e-03,\n",
       "                      -2.7151e-02, -1.0754e-02, -1.7949e-03, -1.0875e-02, -2.2836e-02,\n",
       "                      -6.3336e-03, -1.4975e-02, -3.1525e-02,  6.8423e-03, -4.3383e-03,\n",
       "                      -1.5958e-02, -1.0923e-02, -9.1247e-03, -1.6129e-02, -1.1178e-03,\n",
       "                       1.4177e-02, -1.2853e-02,  8.0601e-03, -1.7442e-03,  4.6932e-03,\n",
       "                      -9.7305e-04,  1.4720e-02, -9.7800e-05,  1.3503e-02,  1.0583e-02,\n",
       "                       3.7720e-03, -6.8150e-03,  5.2426e-03,  6.2602e-04,  6.0060e-03,\n",
       "                       4.6512e-04, -2.3539e-03,  9.6639e-03, -2.6707e-04, -1.4188e-02,\n",
       "                      -5.7223e-03, -1.7490e-02, -7.8416e-03, -1.1736e-03,  1.8619e-03,\n",
       "                      -1.7604e-02,  1.0150e-02,  3.2062e-03, -3.0847e-03,  1.7742e-02,\n",
       "                      -3.0403e-03, -2.4040e-02, -9.9757e-03,  1.4866e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convs.1.1.running_mean',\n",
       "              tensor([-0.2740, -0.0949,  0.2010,  1.3845,  0.0017,  0.4114,  0.6638,  0.3778,\n",
       "                      -0.3055, -0.1998, -0.1844, -0.4237,  0.4950, -0.2737,  0.0268, -0.2468,\n",
       "                       0.2952, -0.5600,  1.0083, -0.6034, -0.4775,  0.2066, -0.0812, -0.1560,\n",
       "                      -0.2807,  0.6257,  0.2138,  0.1008, -0.3507, -0.7719, -0.8222,  0.6101,\n",
       "                       0.0232,  0.1421, -0.3567, -0.0102,  0.0177, -0.9428, -0.8388,  0.0723,\n",
       "                       0.2523, -0.2253,  0.4645, -0.1973, -0.8947,  0.2235, -0.7461, -0.4665,\n",
       "                      -0.0245,  0.3221, -0.1248,  0.2347, -0.5281, -0.6544,  0.1756, -0.7534,\n",
       "                      -0.3065,  0.1938, -0.4606, -0.3889,  0.2692, -0.6031, -0.5360, -0.5590],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convs.1.1.running_var',\n",
       "              tensor([0.6629, 0.8150, 0.3461, 0.5726, 0.4242, 0.4047, 0.9175, 0.3921, 0.6273,\n",
       "                      0.6134, 0.5717, 0.6220, 0.4768, 0.3834, 0.5831, 0.5335, 0.4269, 0.8289,\n",
       "                      0.5826, 0.4038, 0.7147, 0.3588, 1.0183, 0.6034, 0.6989, 0.3481, 0.6373,\n",
       "                      0.4182, 0.4307, 0.5236, 0.4801, 0.5984, 0.4570, 0.5264, 0.4452, 0.4235,\n",
       "                      0.6046, 0.6539, 0.4712, 0.7682, 0.5044, 0.5716, 0.6081, 0.4782, 0.8307,\n",
       "                      0.9970, 0.5274, 0.5695, 0.6155, 0.5787, 0.5771, 0.5059, 0.9497, 0.4340,\n",
       "                      0.5326, 0.4216, 0.6013, 0.4343, 0.8269, 0.5728, 0.5538, 0.8755, 0.7744,\n",
       "                      0.5532], dtype=torch.float64)),\n",
       "             ('6.11.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.11.convs.2.0.weight',\n",
       "              tensor([[[ 0.1665],\n",
       "                       [ 0.0955],\n",
       "                       [ 0.2971],\n",
       "                       ...,\n",
       "                       [-0.0885],\n",
       "                       [-0.2512],\n",
       "                       [-0.0910]],\n",
       "              \n",
       "                      [[ 0.2374],\n",
       "                       [ 0.0014],\n",
       "                       [-0.1271],\n",
       "                       ...,\n",
       "                       [ 0.1418],\n",
       "                       [-0.3567],\n",
       "                       [ 0.1400]],\n",
       "              \n",
       "                      [[ 0.0375],\n",
       "                       [ 0.0116],\n",
       "                       [ 0.0495],\n",
       "                       ...,\n",
       "                       [ 0.0497],\n",
       "                       [ 0.2188],\n",
       "                       [ 0.0785]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1332],\n",
       "                       [-0.1648],\n",
       "                       [-0.1246],\n",
       "                       ...,\n",
       "                       [ 0.3083],\n",
       "                       [ 0.0573],\n",
       "                       [-0.0667]],\n",
       "              \n",
       "                      [[-0.1650],\n",
       "                       [ 0.1917],\n",
       "                       [ 0.1030],\n",
       "                       ...,\n",
       "                       [-0.1003],\n",
       "                       [ 0.0305],\n",
       "                       [-0.1145]],\n",
       "              \n",
       "                      [[-0.0817],\n",
       "                       [ 0.1569],\n",
       "                       [ 0.1196],\n",
       "                       ...,\n",
       "                       [ 0.0515],\n",
       "                       [-0.1735],\n",
       "                       [-0.1286]]], dtype=torch.float64)),\n",
       "             ('6.11.convs.2.1.weight',\n",
       "              tensor([ 0.0287,  0.0334,  0.0003,  0.0069,  0.0003,  0.0269, -0.0126,  0.0008,\n",
       "                       0.0410, -0.0042,  0.0524,  0.0249, -0.0093, -0.0112,  0.0034,  0.0486,\n",
       "                       0.0303,  0.0005,  0.0088,  0.0021, -0.0181, -0.0403, -0.0247, -0.0085,\n",
       "                       0.0031,  0.0022, -0.0243, -0.0029, -0.0147,  0.0153, -0.0089, -0.0280,\n",
       "                      -0.0057, -0.0098,  0.0081,  0.0091,  0.0104,  0.0160, -0.0080,  0.0301,\n",
       "                       0.0259,  0.0348, -0.0097,  0.0355,  0.0114,  0.0048,  0.0140, -0.0075,\n",
       "                       0.0151, -0.0277,  0.0091,  0.0064, -0.0121, -0.0130, -0.0239,  0.0113,\n",
       "                      -0.0240, -0.0116, -0.0012,  0.0005, -0.0155,  0.0324,  0.0057,  0.0258,\n",
       "                      -0.0352,  0.0194,  0.0159,  0.0366,  0.0391,  0.0181, -0.0033,  0.0135,\n",
       "                       0.0127, -0.0178, -0.0135, -0.0161, -0.0269, -0.0170,  0.0004,  0.0232,\n",
       "                       0.0059, -0.0210, -0.0348, -0.0047,  0.0156, -0.0118,  0.0206,  0.0009,\n",
       "                       0.0046, -0.0057,  0.0039, -0.0109, -0.0031,  0.0172,  0.0233, -0.0212,\n",
       "                       0.0053, -0.0141,  0.0219,  0.0223, -0.0026, -0.0323, -0.0151,  0.0139,\n",
       "                       0.0074, -0.0111,  0.0237, -0.0218,  0.0233, -0.0115,  0.0307, -0.0148,\n",
       "                      -0.0211, -0.0209, -0.0111,  0.0224, -0.0259,  0.0490,  0.0083, -0.0083,\n",
       "                       0.0043,  0.0356, -0.0058,  0.0014,  0.0199,  0.0105, -0.0235,  0.0087,\n",
       "                       0.0162, -0.0141, -0.0016,  0.0174, -0.0121, -0.0089,  0.0133,  0.0101,\n",
       "                       0.0228,  0.0002, -0.0016,  0.0056, -0.0135,  0.0209, -0.0235, -0.0100,\n",
       "                      -0.0020, -0.0221,  0.0342, -0.0215, -0.0015,  0.0139, -0.0310,  0.0325,\n",
       "                      -0.0290, -0.0249, -0.0173,  0.0232,  0.0103,  0.0168,  0.0160,  0.0059,\n",
       "                       0.0007,  0.0088,  0.0130, -0.0097,  0.0070,  0.0026, -0.0141, -0.0006,\n",
       "                      -0.0021, -0.0179,  0.0069, -0.0132,  0.0123,  0.0203, -0.0315, -0.0154,\n",
       "                      -0.0227, -0.0147,  0.0072,  0.0074, -0.0282,  0.0064,  0.0228,  0.0005,\n",
       "                       0.0122, -0.0074,  0.0015, -0.0156,  0.0205,  0.0072,  0.0245,  0.0050,\n",
       "                      -0.0392,  0.0133,  0.0159, -0.0459, -0.0314,  0.0025,  0.0024,  0.0180,\n",
       "                      -0.0067,  0.0284,  0.0295, -0.0149, -0.0010, -0.0365,  0.0099, -0.0068,\n",
       "                       0.0010,  0.0085, -0.0128, -0.0064,  0.0008,  0.0419, -0.0130, -0.0106,\n",
       "                      -0.0170,  0.0097, -0.0085, -0.0269, -0.0009, -0.0016, -0.0377,  0.0054,\n",
       "                      -0.0137,  0.0297, -0.0265,  0.0125, -0.0103,  0.0156,  0.0175,  0.0074,\n",
       "                       0.0199, -0.0169, -0.0022,  0.0262,  0.0093, -0.0014, -0.0037,  0.0275,\n",
       "                      -0.0198,  0.0008,  0.0179,  0.0190,  0.0307, -0.0277,  0.0148, -0.0138,\n",
       "                      -0.0060, -0.0239, -0.0031,  0.0268,  0.0181,  0.0372, -0.0300, -0.0233],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convs.2.1.bias',\n",
       "              tensor([-3.9141e-04,  8.0634e-03,  1.0125e-02,  1.4286e-02,  1.3735e-03,\n",
       "                       5.3951e-03,  7.5824e-03, -6.3267e-04,  9.9568e-03,  1.2924e-02,\n",
       "                       1.3563e-02, -7.5017e-03,  8.4580e-03, -3.2558e-03,  9.9148e-03,\n",
       "                       1.8319e-03,  2.6651e-02, -5.1961e-04,  1.0177e-02, -5.0358e-04,\n",
       "                      -3.1162e-03,  1.1485e-03,  2.3449e-03,  5.7579e-03,  2.0148e-03,\n",
       "                      -1.6503e-02,  2.6855e-03,  3.9335e-03,  5.0946e-03, -2.4864e-03,\n",
       "                       4.5914e-04,  5.7783e-03, -5.6906e-03,  2.0783e-02,  6.2166e-03,\n",
       "                       1.6246e-02, -5.0117e-03,  1.8415e-02,  6.7536e-03,  1.2699e-02,\n",
       "                       1.5044e-03,  2.0635e-02, -1.0137e-02, -7.4635e-04,  3.4748e-03,\n",
       "                      -1.2583e-02,  1.1584e-02,  1.0432e-04, -1.1415e-02,  7.4176e-03,\n",
       "                       9.8773e-03,  4.2872e-03,  6.3857e-03,  1.1473e-02,  7.5385e-03,\n",
       "                       1.9569e-02,  9.6758e-03,  1.7637e-03,  1.2172e-02, -6.1527e-04,\n",
       "                       3.1739e-03,  3.6395e-03,  8.6972e-03,  8.2982e-03, -4.3376e-03,\n",
       "                       6.1956e-03, -1.0330e-02,  1.5533e-02,  5.4485e-03, -1.4536e-02,\n",
       "                       6.5557e-03,  2.1886e-03,  1.2654e-03, -7.3626e-03,  1.3961e-02,\n",
       "                       3.2203e-03,  3.8345e-03,  5.2962e-03,  3.5489e-03,  8.7098e-03,\n",
       "                       5.1441e-03, -5.6493e-03,  1.2580e-02,  4.9796e-03, -4.0797e-03,\n",
       "                       1.9536e-02, -6.4345e-04,  8.5748e-03,  1.5892e-02,  1.1218e-03,\n",
       "                       1.3201e-03,  8.9287e-03,  1.0843e-02, -4.6612e-03,  9.9995e-03,\n",
       "                      -1.3770e-02,  1.0499e-02,  1.1785e-03,  1.8498e-02, -3.4479e-03,\n",
       "                       1.8951e-02,  1.4431e-02,  5.9199e-03,  8.4126e-03,  1.7128e-04,\n",
       "                      -8.5813e-05, -2.8638e-03,  3.3997e-03,  8.3548e-03,  5.2371e-03,\n",
       "                      -1.2303e-02, -8.5048e-03,  5.5197e-03,  1.7341e-02,  1.2428e-02,\n",
       "                       5.6500e-03,  1.1565e-02,  2.2414e-03,  6.1242e-03, -1.6087e-02,\n",
       "                      -6.1538e-04,  8.0821e-03, -1.8215e-03, -2.8419e-03,  3.2766e-03,\n",
       "                       1.1355e-02,  1.1704e-02,  5.3001e-03,  5.8542e-03,  1.4611e-02,\n",
       "                       7.1493e-03,  6.6420e-03,  1.3843e-02,  7.1460e-03,  1.3853e-02,\n",
       "                      -1.1961e-02,  6.4787e-03,  4.9110e-03,  6.9287e-03,  1.0113e-03,\n",
       "                       1.4356e-02, -8.8628e-03,  1.5570e-02,  4.3827e-03, -7.6180e-03,\n",
       "                       1.5298e-02, -2.6279e-03, -7.0567e-04,  1.2226e-02,  1.0264e-02,\n",
       "                       5.6292e-03,  1.4108e-02,  9.7730e-03,  1.2464e-02,  1.3172e-02,\n",
       "                       1.0309e-02, -9.3897e-04,  4.8680e-03, -1.0985e-03, -9.7914e-03,\n",
       "                       1.8173e-03, -3.9861e-03, -2.5794e-03,  8.9996e-03,  1.4294e-02,\n",
       "                      -2.4580e-03, -1.2432e-02,  1.0035e-02,  7.1383e-03,  1.7669e-02,\n",
       "                       3.5820e-03,  2.6287e-03,  6.8362e-03,  1.2864e-02, -1.3407e-02,\n",
       "                       8.9756e-03,  1.5456e-03,  1.5476e-02,  1.1778e-03,  3.0518e-03,\n",
       "                      -6.6359e-03,  1.3613e-02, -3.8887e-03, -7.0535e-03,  1.3730e-02,\n",
       "                       7.4535e-03,  1.5217e-02,  1.0624e-02,  2.7994e-03,  7.9460e-03,\n",
       "                       6.4029e-03,  1.7332e-03,  8.2180e-03,  3.8802e-04,  2.9754e-03,\n",
       "                       5.1203e-03,  5.0671e-03,  4.8154e-03,  7.6486e-03,  1.4512e-02,\n",
       "                       6.9504e-04,  2.4737e-02,  1.9011e-02,  2.1740e-02,  1.2979e-02,\n",
       "                      -3.5348e-03,  8.7237e-03, -9.1532e-03,  7.2170e-03,  1.2567e-02,\n",
       "                       1.6782e-02,  1.0727e-02,  1.3058e-02,  4.3813e-03,  8.6895e-03,\n",
       "                      -9.6833e-04,  3.9261e-03,  1.7278e-02,  5.9452e-03,  2.4141e-03,\n",
       "                      -1.1391e-02,  2.5442e-03,  3.7994e-03,  1.5546e-02, -1.0604e-03,\n",
       "                       4.2490e-03, -7.7515e-03,  7.7381e-04, -1.4722e-02,  1.4590e-02,\n",
       "                       5.2157e-03, -4.1489e-03,  7.5514e-03,  6.9254e-03,  4.2418e-03,\n",
       "                       9.1679e-03,  4.0182e-03, -6.2320e-03,  1.0112e-02,  3.4802e-03,\n",
       "                      -3.5700e-03,  3.8317e-03,  1.0593e-03,  6.4606e-03,  4.8826e-03,\n",
       "                       1.2504e-02,  6.2789e-03,  3.8198e-03, -3.1651e-03, -7.3658e-03,\n",
       "                       1.7694e-02,  2.1122e-02,  2.0354e-02,  1.5853e-02,  8.8716e-03,\n",
       "                       2.8387e-03], dtype=torch.float64)),\n",
       "             ('6.11.convs.2.1.running_mean',\n",
       "              tensor([ 3.4907e-01,  1.0975e+00,  8.3447e-01,  5.2128e-01, -2.9051e-01,\n",
       "                       2.9902e-01, -1.3224e-01,  7.1919e-01,  5.2518e-01, -2.3102e-01,\n",
       "                      -4.8224e-01,  3.0748e-01,  1.5505e-01,  1.1025e-02, -3.3948e-01,\n",
       "                      -1.0461e-01, -5.2431e-01, -3.7457e-02, -9.3342e-02,  3.2749e-01,\n",
       "                       2.8768e-01,  7.4168e-01, -4.5377e-01,  3.5318e-01,  1.3855e-01,\n",
       "                      -8.1217e-02, -4.7301e-01,  1.3861e-01,  9.7304e-02,  3.5675e-01,\n",
       "                       2.9994e-01,  7.1146e-01, -2.0036e-01, -3.2643e-02, -5.1212e-02,\n",
       "                      -2.3895e-01, -2.6988e-01,  3.2192e-01,  4.5530e-02,  1.2316e+00,\n",
       "                      -6.6901e-01,  6.9515e-01,  2.5155e-01,  1.8132e-01, -7.5381e-01,\n",
       "                      -3.9510e-01, -4.4947e-01, -1.7423e-01,  1.7089e-01, -1.4083e-01,\n",
       "                      -3.6898e-01, -3.4458e-01, -1.3817e-01,  1.4257e-01, -4.3154e-04,\n",
       "                      -2.2697e-01,  5.6637e-01,  2.8352e-01,  1.9710e-01,  9.3985e-02,\n",
       "                      -1.2462e-01, -4.6928e-03, -1.4336e-01,  8.6031e-02,  7.3851e-01,\n",
       "                       1.3210e-01,  5.2813e-01, -8.1552e-01,  4.0679e-01,  1.2003e+00,\n",
       "                       1.3908e-01, -4.6754e-01, -7.2263e-02, -4.5304e-01,  5.0017e-01,\n",
       "                       1.3231e-01, -5.2738e-01, -2.5835e-01, -1.4379e-01, -9.5151e-03,\n",
       "                      -4.0354e-01, -3.2201e-01, -4.2015e-01,  4.0586e-02,  3.9121e-02,\n",
       "                      -1.2986e-01,  1.6395e-02,  4.7344e-01,  6.6087e-01, -3.1110e-01,\n",
       "                       7.2352e-01,  4.8726e-02, -1.2104e-01,  4.1115e-01,  4.5737e-02,\n",
       "                       5.1839e-01, -9.1699e-01, -7.8547e-02,  1.0196e-02,  4.4483e-01,\n",
       "                      -3.7035e-01,  2.8131e-01, -1.6556e-01, -3.7337e-01,  1.0925e-01,\n",
       "                      -5.0882e-02,  3.5042e-01, -7.5298e-01, -5.5560e-01,  2.7920e-01,\n",
       "                      -2.0436e-01,  1.5936e-01,  7.3897e-01, -2.0633e-01, -2.2686e-01,\n",
       "                      -3.3010e-01, -9.2319e-02, -7.6125e-01,  2.1368e-01, -1.4402e-01,\n",
       "                      -1.3299e-01, -1.5437e-02, -3.5225e-02,  3.9060e-01,  2.7066e-01,\n",
       "                       3.4418e-01,  3.1973e-01,  2.4917e-01,  2.8555e-01,  2.4531e-02,\n",
       "                      -3.0442e-01, -8.4320e-03,  1.4430e-01, -2.6868e-01,  2.7234e-02,\n",
       "                      -3.1994e-01,  9.4882e-02,  2.7606e-02,  4.5356e-02,  2.9554e-01,\n",
       "                      -3.2703e-01,  2.0529e-01, -2.2938e-01,  1.5854e-01,  1.1606e-01,\n",
       "                       1.0990e+00,  1.0217e-01, -6.3256e-01, -2.8041e-01, -5.9742e-01,\n",
       "                      -4.6316e-01, -4.9943e-01,  3.3065e-01,  4.1759e-01,  2.5410e-01,\n",
       "                       7.3505e-02, -1.9015e-01, -2.3267e-01, -7.0669e-01, -1.1676e-01,\n",
       "                       5.0032e-01, -6.5113e-01, -9.3694e-02,  7.6357e-02, -2.0035e-01,\n",
       "                      -6.4756e-01,  1.3382e+00, -1.3862e-01, -3.0377e-01,  2.7887e-01,\n",
       "                       4.9738e-03, -2.3537e-01,  5.8073e-02,  1.8501e-01,  2.2573e-01,\n",
       "                       1.9967e-01,  8.4538e-01, -1.5261e-01, -6.2222e-01, -4.3743e-01,\n",
       "                      -3.1208e-01,  9.1004e-02,  1.6211e-01, -1.5909e-02,  5.6480e-01,\n",
       "                       2.2774e-01, -1.2508e-01, -2.3965e-01, -1.3479e-01, -2.2823e-01,\n",
       "                       1.6182e-01, -3.9262e-01, -2.8745e-01, -1.6059e-01, -1.7430e-01,\n",
       "                      -5.6459e-01,  1.7784e-01, -1.0801e-01, -5.8403e-01,  2.1295e-02,\n",
       "                      -3.0989e-03,  6.8947e-02, -7.2755e-01,  8.0429e-01,  6.5535e-02,\n",
       "                      -3.8094e-01,  1.7630e-02,  6.5602e-02,  7.6656e-01, -9.7309e-01,\n",
       "                       6.1990e-01,  4.2762e-02,  8.4209e-02, -5.0984e-01,  1.3233e-01,\n",
       "                       5.0768e-01,  1.4121e-01,  1.1936e-01, -5.2422e-01,  1.9140e-01,\n",
       "                       6.9382e-02, -2.3407e-01, -2.3527e-01, -3.0487e-01,  2.8265e-01,\n",
       "                       2.2452e-01, -2.9291e-01,  3.9142e-01,  1.2703e-01,  8.0181e-01,\n",
       "                      -2.4266e-01, -2.5739e-01, -1.2371e-01, -7.5394e-02, -8.5431e-02,\n",
       "                       2.9134e-01,  6.2795e-02,  1.0810e-02, -5.1935e-01,  5.8161e-01,\n",
       "                      -5.7877e-02,  2.2322e-01, -5.8455e-01,  2.9310e-01,  6.1642e-01,\n",
       "                       3.3634e-01,  3.4446e-02, -5.2707e-02, -1.8586e-01,  4.7381e-01,\n",
       "                       2.4695e-01, -1.7676e-01,  1.9784e-01, -4.2809e-01, -1.3898e-01,\n",
       "                      -1.9006e-01], dtype=torch.float64)),\n",
       "             ('6.11.convs.2.1.running_var',\n",
       "              tensor([0.4041, 0.5088, 0.2466, 0.3358, 0.0859, 0.5084, 0.1815, 0.2342, 0.3926,\n",
       "                      0.4455, 0.3380, 0.3973, 0.3118, 0.3324, 0.3818, 0.5277, 0.4144, 0.2324,\n",
       "                      0.2750, 0.2488, 0.4377, 0.5214, 0.4501, 0.3516, 0.5036, 0.1696, 0.3078,\n",
       "                      0.0954, 0.1928, 0.3162, 0.3688, 0.3521, 0.1933, 0.2428, 0.2941, 0.4190,\n",
       "                      0.1252, 0.3590, 0.3396, 0.3514, 0.4784, 0.4142, 0.1818, 0.4453, 0.3781,\n",
       "                      0.4151, 0.2098, 0.2334, 0.3363, 0.3920, 0.3204, 0.3814, 0.3976, 0.2580,\n",
       "                      0.3838, 0.1142, 0.5447, 0.5769, 0.4246, 0.3364, 0.2043, 0.4817, 0.1496,\n",
       "                      0.3479, 0.3235, 0.3930, 0.5187, 0.4929, 0.3724, 0.7292, 0.1621, 0.2560,\n",
       "                      0.1837, 0.5179, 0.3210, 0.1549, 0.5898, 0.1526, 0.5336, 0.3186, 0.2536,\n",
       "                      0.4074, 0.5451, 0.2794, 0.3199, 0.3121, 0.2962, 0.1719, 0.2281, 0.2186,\n",
       "                      0.3387, 0.2662, 0.2532, 0.3475, 0.3452, 0.2794, 0.5138, 0.2463, 0.4809,\n",
       "                      0.3081, 0.3501, 0.4933, 0.2343, 0.2715, 0.2429, 0.2683, 0.4334, 0.7463,\n",
       "                      0.7225, 0.1995, 0.3021, 0.5213, 0.4687, 0.4247, 0.4333, 0.4714, 0.3188,\n",
       "                      0.3949, 0.2066, 0.2932, 0.1162, 0.4556, 0.3654, 0.0972, 0.3851, 0.3361,\n",
       "                      0.3994, 0.2667, 0.3424, 0.1899, 0.0627, 0.4577, 0.2910, 0.4304, 0.2704,\n",
       "                      0.2596, 0.3100, 0.1396, 0.1677, 0.2925, 0.2879, 0.1875, 0.4363, 0.2424,\n",
       "                      0.1326, 0.6246, 0.3400, 0.5680, 0.0618, 0.3628, 0.5246, 0.3419, 0.2571,\n",
       "                      0.5892, 0.4431, 0.4687, 0.1958, 0.3582, 0.3042, 0.0947, 0.2855, 0.3153,\n",
       "                      0.2800, 0.2818, 0.3723, 0.3595, 0.5450, 0.1248, 0.2607, 0.4605, 0.2021,\n",
       "                      0.1692, 0.3475, 0.2850, 0.4515, 0.6024, 0.3446, 0.3902, 0.2548, 0.2524,\n",
       "                      0.4572, 0.3328, 0.2283, 0.2228, 0.2460, 0.2907, 0.1223, 0.2900, 0.2742,\n",
       "                      0.0942, 0.3581, 0.1487, 0.3447, 0.5676, 0.3000, 0.5342, 0.3547, 0.2202,\n",
       "                      0.3219, 0.2116, 0.1768, 0.2955, 0.3635, 0.6483, 0.3323, 0.4829, 0.1149,\n",
       "                      0.0802, 0.2705, 0.4032, 0.1234, 0.1683, 0.1140, 0.4022, 0.2817, 0.2835,\n",
       "                      0.3301, 0.1958, 0.3088, 0.5258, 0.0648, 0.2727, 0.3238, 0.2582, 0.5038,\n",
       "                      0.2845, 0.2742, 0.1998, 0.3688, 0.4831, 0.4021, 0.3616, 0.3976, 0.4253,\n",
       "                      0.1921, 0.4696, 0.2922, 0.1325, 0.2844, 0.3660, 0.2176, 0.1321, 0.4654,\n",
       "                      0.2659, 0.4366, 0.2134, 0.2079, 0.4556, 0.0953, 0.4804, 0.2391, 0.4423,\n",
       "                      0.3008, 0.5873, 0.2853, 0.3567], dtype=torch.float64)),\n",
       "             ('6.11.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.11.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.0154],\n",
       "                       [-0.0892],\n",
       "                       [-0.0168],\n",
       "                       ...,\n",
       "                       [ 0.0576],\n",
       "                       [-0.0533],\n",
       "                       [-0.0429]],\n",
       "              \n",
       "                      [[ 0.0828],\n",
       "                       [ 0.0308],\n",
       "                       [-0.1305],\n",
       "                       ...,\n",
       "                       [ 0.0635],\n",
       "                       [-0.0497],\n",
       "                       [ 0.0555]],\n",
       "              \n",
       "                      [[ 0.0704],\n",
       "                       [-0.0243],\n",
       "                       [ 0.0156],\n",
       "                       ...,\n",
       "                       [ 0.1265],\n",
       "                       [-0.0188],\n",
       "                       [-0.0606]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0218],\n",
       "                       [-0.0390],\n",
       "                       [ 0.2252],\n",
       "                       ...,\n",
       "                       [-0.0789],\n",
       "                       [-0.0200],\n",
       "                       [ 0.0347]],\n",
       "              \n",
       "                      [[ 0.1816],\n",
       "                       [-0.0967],\n",
       "                       [ 0.1080],\n",
       "                       ...,\n",
       "                       [-0.1956],\n",
       "                       [ 0.0873],\n",
       "                       [-0.0842]],\n",
       "              \n",
       "                      [[-0.0525],\n",
       "                       [ 0.2406],\n",
       "                       [-0.0742],\n",
       "                       ...,\n",
       "                       [ 0.0058],\n",
       "                       [-0.0531],\n",
       "                       [-0.1727]]], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.0.1.weight',\n",
       "              tensor([0.9596, 0.9934, 0.9685, 0.9600, 0.9796, 0.9957, 0.9836, 0.9597, 0.9823,\n",
       "                      0.9913, 1.0027, 0.9769, 0.9645, 1.0102, 1.0212, 0.9701, 0.9957, 0.9628,\n",
       "                      0.9860, 0.9736, 0.9548, 0.9611, 0.9547, 0.9813, 0.9858, 0.9365, 0.9604,\n",
       "                      0.9404, 0.9735, 0.9664, 0.9631, 0.9603, 0.9786, 0.9689, 0.9417, 0.9934,\n",
       "                      0.9648, 0.9770, 0.9708, 0.9909, 0.9685, 0.9773, 0.9691, 0.9820, 0.9597,\n",
       "                      0.9574, 0.9955, 1.0087, 0.9527, 0.9812, 0.9746, 0.9523, 0.9837, 1.0006,\n",
       "                      0.9724, 0.9674, 0.9542, 0.9719, 0.9766, 0.9627, 0.9540, 0.9976, 0.9806,\n",
       "                      0.9635], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.0.1.bias',\n",
       "              tensor([-0.0107,  0.0104, -0.0121, -0.0005,  0.0199,  0.0104, -0.0085, -0.0123,\n",
       "                      -0.0101,  0.0068,  0.0012,  0.0063, -0.0050,  0.0176,  0.0203,  0.0073,\n",
       "                       0.0096, -0.0027,  0.0075,  0.0069, -0.0050, -0.0132, -0.0021,  0.0021,\n",
       "                      -0.0044, -0.0118, -0.0145, -0.0015, -0.0029, -0.0021,  0.0017,  0.0052,\n",
       "                       0.0099,  0.0065, -0.0168, -0.0130, -0.0187, -0.0004, -0.0026,  0.0141,\n",
       "                       0.0053,  0.0042, -0.0060, -0.0028, -0.0035, -0.0080,  0.0356,  0.0225,\n",
       "                       0.0015,  0.0026,  0.0061,  0.0069,  0.0186,  0.0019, -0.0150, -0.0068,\n",
       "                      -0.0269,  0.0091, -0.0032,  0.0009, -0.0025,  0.0170,  0.0210, -0.0041],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.4950, -0.2189,  0.5672,  0.2633,  0.1172,  0.0840, -0.6911,  0.2952,\n",
       "                      -0.2401, -0.0879,  0.8806,  0.0823, -0.4327,  0.2016, -0.1877, -0.5493,\n",
       "                       0.0455,  0.0628, -0.1649, -0.0487,  1.1227,  0.6757, -0.8174, -0.2393,\n",
       "                       0.6309, -1.7026, -0.5865, -0.4591, -0.0186,  0.0079, -0.9567,  0.1949,\n",
       "                      -0.3394,  0.3199, -0.0524, -0.7097, -0.2581, -0.3622,  0.2799, -1.1128,\n",
       "                      -0.6765, -0.7776, -0.4817,  0.0455, -0.6007, -1.1892, -0.5902,  0.2592,\n",
       "                      -0.6991, -0.4447, -0.3765, -0.2652, -0.3499,  0.1095, -0.2441,  0.8194,\n",
       "                       0.8722, -0.2361, -0.3028, -0.1793,  0.0786,  0.5229, -0.3110, -0.6732],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.0.1.running_var',\n",
       "              tensor([0.6827, 0.1753, 0.4409, 0.5313, 0.1581, 0.2099, 0.1348, 0.1767, 0.1019,\n",
       "                      0.1488, 0.1245, 0.3008, 0.7290, 0.1824, 0.1648, 0.1633, 0.1624, 0.4288,\n",
       "                      0.2120, 0.1079, 0.3726, 0.1751, 0.5771, 0.1126, 0.3439, 0.3083, 0.9508,\n",
       "                      0.5869, 0.4247, 0.3686, 0.3968, 0.8334, 0.3589, 0.2149, 0.1824, 0.1025,\n",
       "                      0.1627, 0.8410, 0.1539, 0.2908, 0.1362, 0.1757, 0.2422, 0.2176, 0.1431,\n",
       "                      0.3602, 0.1249, 0.3043, 0.3525, 0.1683, 0.7416, 0.2500, 0.1035, 0.1107,\n",
       "                      0.4629, 0.2575, 0.3430, 0.2244, 0.1956, 0.2627, 0.3248, 0.1562, 0.1535,\n",
       "                      0.2104], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.11.convpath.0.1.0.weight',\n",
       "              tensor([[[ 0.0854, -0.1115,  0.0910, -0.0257, -0.1021],\n",
       "                       [-0.0465, -0.0519,  0.0335, -0.0106, -0.0021],\n",
       "                       [-0.0080,  0.0325,  0.0157, -0.1898,  0.0446],\n",
       "                       ...,\n",
       "                       [ 0.0029,  0.0233, -0.1042,  0.0265,  0.0019],\n",
       "                       [ 0.1215,  0.0122,  0.0646, -0.0776,  0.0984],\n",
       "                       [ 0.0885,  0.0831,  0.0270,  0.0056, -0.0402]],\n",
       "              \n",
       "                      [[ 0.0468, -0.1644,  0.0471,  0.0381,  0.0812],\n",
       "                       [ 0.0161, -0.1158,  0.0210, -0.0087,  0.0875],\n",
       "                       [-0.0499, -0.1038, -0.0260, -0.0874,  0.0154],\n",
       "                       ...,\n",
       "                       [ 0.0164, -0.0409, -0.0774,  0.0090, -0.0478],\n",
       "                       [ 0.0613,  0.1101, -0.0117,  0.0719,  0.1147],\n",
       "                       [ 0.0128, -0.0990,  0.0429,  0.1194, -0.0578]],\n",
       "              \n",
       "                      [[ 0.0901,  0.1092, -0.0311,  0.0363,  0.0239],\n",
       "                       [-0.1044,  0.0044,  0.0184, -0.0521,  0.1046],\n",
       "                       [ 0.1063, -0.0056,  0.0597,  0.0506,  0.0896],\n",
       "                       ...,\n",
       "                       [ 0.0290,  0.0758,  0.0007,  0.0491,  0.0408],\n",
       "                       [-0.1737,  0.0390, -0.0331,  0.0662,  0.0338],\n",
       "                       [-0.0736,  0.0315,  0.0377,  0.0785,  0.1469]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1238,  0.0901, -0.0040,  0.0505,  0.0639],\n",
       "                       [-0.1210, -0.0307,  0.0020, -0.1090, -0.1993],\n",
       "                       [-0.0245, -0.0638, -0.0814,  0.0127,  0.0632],\n",
       "                       ...,\n",
       "                       [ 0.0482,  0.1729,  0.0074,  0.0028,  0.1392],\n",
       "                       [ 0.0398, -0.0963, -0.0877, -0.0545, -0.0195],\n",
       "                       [-0.0831, -0.2894, -0.0571,  0.0226,  0.0425]],\n",
       "              \n",
       "                      [[-0.0260,  0.0724,  0.0384, -0.0503, -0.0473],\n",
       "                       [-0.0624, -0.0474, -0.0228, -0.0172, -0.1212],\n",
       "                       [ 0.0401,  0.0483,  0.0364, -0.0898,  0.0597],\n",
       "                       ...,\n",
       "                       [ 0.1320, -0.0026, -0.0678,  0.0190, -0.0085],\n",
       "                       [-0.0574,  0.0399, -0.0299, -0.0481,  0.0328],\n",
       "                       [ 0.0096, -0.0581, -0.0655, -0.1049,  0.0407]],\n",
       "              \n",
       "                      [[-0.0368, -0.0310, -0.0578, -0.0234, -0.0223],\n",
       "                       [ 0.0004,  0.0856,  0.0966, -0.0549,  0.0098],\n",
       "                       [ 0.0087, -0.1206,  0.0490, -0.0564, -0.0399],\n",
       "                       ...,\n",
       "                       [-0.1280, -0.0396, -0.1476, -0.0600,  0.0106],\n",
       "                       [-0.0606,  0.0986,  0.0973, -0.0027, -0.1676],\n",
       "                       [ 0.1519, -0.0333, -0.0685,  0.0084, -0.0105]]], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.1.1.weight',\n",
       "              tensor([0.9912, 0.9629, 0.9698, 0.9828, 1.0111, 0.9667, 0.9593, 0.9920, 0.9381,\n",
       "                      0.9446, 1.0031, 0.9954, 0.9680, 0.9563, 0.9476, 0.9658, 0.9762, 0.9382,\n",
       "                      0.9707, 0.9592, 0.9647, 0.9743, 0.9415, 0.9884, 0.9507, 0.9862, 0.9512,\n",
       "                      0.9719, 0.9689, 0.9538, 0.9831, 0.9680, 0.9937, 0.9548, 0.9752, 0.9630,\n",
       "                      0.9558, 0.9569, 0.9749, 0.9653, 0.9823, 0.9545, 0.9534, 0.9778, 0.9631,\n",
       "                      0.9571, 0.9585, 0.9838, 0.9633, 0.9653, 0.9623, 0.9589, 0.9706, 0.9679,\n",
       "                      0.9853, 0.9307, 0.9720, 0.9967, 0.9524, 0.9583, 0.9553, 0.9541, 0.9374,\n",
       "                      1.0092], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.1.1.bias',\n",
       "              tensor([-1.5748e-02,  1.0693e-02, -2.1226e-02, -5.4627e-03,  1.6458e-02,\n",
       "                      -1.9048e-02, -4.5592e-03,  7.3531e-04, -1.3906e-02, -1.9597e-02,\n",
       "                      -4.8206e-03,  2.0287e-02, -2.4424e-03, -6.8188e-03, -9.2368e-03,\n",
       "                      -2.7151e-02, -1.0754e-02, -1.7949e-03, -1.0875e-02, -2.2836e-02,\n",
       "                      -6.3336e-03, -1.4975e-02, -3.1525e-02,  6.8423e-03, -4.3383e-03,\n",
       "                      -1.5958e-02, -1.0923e-02, -9.1247e-03, -1.6129e-02, -1.1178e-03,\n",
       "                       1.4177e-02, -1.2853e-02,  8.0601e-03, -1.7442e-03,  4.6932e-03,\n",
       "                      -9.7305e-04,  1.4720e-02, -9.7800e-05,  1.3503e-02,  1.0583e-02,\n",
       "                       3.7720e-03, -6.8150e-03,  5.2426e-03,  6.2602e-04,  6.0060e-03,\n",
       "                       4.6512e-04, -2.3539e-03,  9.6639e-03, -2.6707e-04, -1.4188e-02,\n",
       "                      -5.7223e-03, -1.7490e-02, -7.8416e-03, -1.1736e-03,  1.8619e-03,\n",
       "                      -1.7604e-02,  1.0150e-02,  3.2062e-03, -3.0847e-03,  1.7742e-02,\n",
       "                      -3.0403e-03, -2.4040e-02, -9.9757e-03,  1.4866e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.1.1.running_mean',\n",
       "              tensor([-0.2740, -0.0949,  0.2010,  1.3845,  0.0017,  0.4114,  0.6638,  0.3778,\n",
       "                      -0.3055, -0.1998, -0.1844, -0.4237,  0.4950, -0.2737,  0.0268, -0.2468,\n",
       "                       0.2952, -0.5600,  1.0083, -0.6034, -0.4775,  0.2066, -0.0812, -0.1560,\n",
       "                      -0.2807,  0.6257,  0.2138,  0.1008, -0.3507, -0.7719, -0.8222,  0.6101,\n",
       "                       0.0232,  0.1421, -0.3567, -0.0102,  0.0177, -0.9428, -0.8388,  0.0723,\n",
       "                       0.2523, -0.2253,  0.4645, -0.1973, -0.8947,  0.2235, -0.7461, -0.4665,\n",
       "                      -0.0245,  0.3221, -0.1248,  0.2347, -0.5281, -0.6544,  0.1756, -0.7534,\n",
       "                      -0.3065,  0.1938, -0.4606, -0.3889,  0.2692, -0.6031, -0.5360, -0.5590],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.1.1.running_var',\n",
       "              tensor([0.6629, 0.8150, 0.3461, 0.5726, 0.4242, 0.4047, 0.9175, 0.3921, 0.6273,\n",
       "                      0.6134, 0.5717, 0.6220, 0.4768, 0.3834, 0.5831, 0.5335, 0.4269, 0.8289,\n",
       "                      0.5826, 0.4038, 0.7147, 0.3588, 1.0183, 0.6034, 0.6989, 0.3481, 0.6373,\n",
       "                      0.4182, 0.4307, 0.5236, 0.4801, 0.5984, 0.4570, 0.5264, 0.4452, 0.4235,\n",
       "                      0.6046, 0.6539, 0.4712, 0.7682, 0.5044, 0.5716, 0.6081, 0.4782, 0.8307,\n",
       "                      0.9970, 0.5274, 0.5695, 0.6155, 0.5787, 0.5771, 0.5059, 0.9497, 0.4340,\n",
       "                      0.5326, 0.4216, 0.6013, 0.4343, 0.8269, 0.5728, 0.5538, 0.8755, 0.7744,\n",
       "                      0.5532], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.11.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.1665],\n",
       "                       [ 0.0955],\n",
       "                       [ 0.2971],\n",
       "                       ...,\n",
       "                       [-0.0885],\n",
       "                       [-0.2512],\n",
       "                       [-0.0910]],\n",
       "              \n",
       "                      [[ 0.2374],\n",
       "                       [ 0.0014],\n",
       "                       [-0.1271],\n",
       "                       ...,\n",
       "                       [ 0.1418],\n",
       "                       [-0.3567],\n",
       "                       [ 0.1400]],\n",
       "              \n",
       "                      [[ 0.0375],\n",
       "                       [ 0.0116],\n",
       "                       [ 0.0495],\n",
       "                       ...,\n",
       "                       [ 0.0497],\n",
       "                       [ 0.2188],\n",
       "                       [ 0.0785]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1332],\n",
       "                       [-0.1648],\n",
       "                       [-0.1246],\n",
       "                       ...,\n",
       "                       [ 0.3083],\n",
       "                       [ 0.0573],\n",
       "                       [-0.0667]],\n",
       "              \n",
       "                      [[-0.1650],\n",
       "                       [ 0.1917],\n",
       "                       [ 0.1030],\n",
       "                       ...,\n",
       "                       [-0.1003],\n",
       "                       [ 0.0305],\n",
       "                       [-0.1145]],\n",
       "              \n",
       "                      [[-0.0817],\n",
       "                       [ 0.1569],\n",
       "                       [ 0.1196],\n",
       "                       ...,\n",
       "                       [ 0.0515],\n",
       "                       [-0.1735],\n",
       "                       [-0.1286]]], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.2.1.weight',\n",
       "              tensor([ 0.0287,  0.0334,  0.0003,  0.0069,  0.0003,  0.0269, -0.0126,  0.0008,\n",
       "                       0.0410, -0.0042,  0.0524,  0.0249, -0.0093, -0.0112,  0.0034,  0.0486,\n",
       "                       0.0303,  0.0005,  0.0088,  0.0021, -0.0181, -0.0403, -0.0247, -0.0085,\n",
       "                       0.0031,  0.0022, -0.0243, -0.0029, -0.0147,  0.0153, -0.0089, -0.0280,\n",
       "                      -0.0057, -0.0098,  0.0081,  0.0091,  0.0104,  0.0160, -0.0080,  0.0301,\n",
       "                       0.0259,  0.0348, -0.0097,  0.0355,  0.0114,  0.0048,  0.0140, -0.0075,\n",
       "                       0.0151, -0.0277,  0.0091,  0.0064, -0.0121, -0.0130, -0.0239,  0.0113,\n",
       "                      -0.0240, -0.0116, -0.0012,  0.0005, -0.0155,  0.0324,  0.0057,  0.0258,\n",
       "                      -0.0352,  0.0194,  0.0159,  0.0366,  0.0391,  0.0181, -0.0033,  0.0135,\n",
       "                       0.0127, -0.0178, -0.0135, -0.0161, -0.0269, -0.0170,  0.0004,  0.0232,\n",
       "                       0.0059, -0.0210, -0.0348, -0.0047,  0.0156, -0.0118,  0.0206,  0.0009,\n",
       "                       0.0046, -0.0057,  0.0039, -0.0109, -0.0031,  0.0172,  0.0233, -0.0212,\n",
       "                       0.0053, -0.0141,  0.0219,  0.0223, -0.0026, -0.0323, -0.0151,  0.0139,\n",
       "                       0.0074, -0.0111,  0.0237, -0.0218,  0.0233, -0.0115,  0.0307, -0.0148,\n",
       "                      -0.0211, -0.0209, -0.0111,  0.0224, -0.0259,  0.0490,  0.0083, -0.0083,\n",
       "                       0.0043,  0.0356, -0.0058,  0.0014,  0.0199,  0.0105, -0.0235,  0.0087,\n",
       "                       0.0162, -0.0141, -0.0016,  0.0174, -0.0121, -0.0089,  0.0133,  0.0101,\n",
       "                       0.0228,  0.0002, -0.0016,  0.0056, -0.0135,  0.0209, -0.0235, -0.0100,\n",
       "                      -0.0020, -0.0221,  0.0342, -0.0215, -0.0015,  0.0139, -0.0310,  0.0325,\n",
       "                      -0.0290, -0.0249, -0.0173,  0.0232,  0.0103,  0.0168,  0.0160,  0.0059,\n",
       "                       0.0007,  0.0088,  0.0130, -0.0097,  0.0070,  0.0026, -0.0141, -0.0006,\n",
       "                      -0.0021, -0.0179,  0.0069, -0.0132,  0.0123,  0.0203, -0.0315, -0.0154,\n",
       "                      -0.0227, -0.0147,  0.0072,  0.0074, -0.0282,  0.0064,  0.0228,  0.0005,\n",
       "                       0.0122, -0.0074,  0.0015, -0.0156,  0.0205,  0.0072,  0.0245,  0.0050,\n",
       "                      -0.0392,  0.0133,  0.0159, -0.0459, -0.0314,  0.0025,  0.0024,  0.0180,\n",
       "                      -0.0067,  0.0284,  0.0295, -0.0149, -0.0010, -0.0365,  0.0099, -0.0068,\n",
       "                       0.0010,  0.0085, -0.0128, -0.0064,  0.0008,  0.0419, -0.0130, -0.0106,\n",
       "                      -0.0170,  0.0097, -0.0085, -0.0269, -0.0009, -0.0016, -0.0377,  0.0054,\n",
       "                      -0.0137,  0.0297, -0.0265,  0.0125, -0.0103,  0.0156,  0.0175,  0.0074,\n",
       "                       0.0199, -0.0169, -0.0022,  0.0262,  0.0093, -0.0014, -0.0037,  0.0275,\n",
       "                      -0.0198,  0.0008,  0.0179,  0.0190,  0.0307, -0.0277,  0.0148, -0.0138,\n",
       "                      -0.0060, -0.0239, -0.0031,  0.0268,  0.0181,  0.0372, -0.0300, -0.0233],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.2.1.bias',\n",
       "              tensor([-3.9141e-04,  8.0634e-03,  1.0125e-02,  1.4286e-02,  1.3735e-03,\n",
       "                       5.3951e-03,  7.5824e-03, -6.3267e-04,  9.9568e-03,  1.2924e-02,\n",
       "                       1.3563e-02, -7.5017e-03,  8.4580e-03, -3.2558e-03,  9.9148e-03,\n",
       "                       1.8319e-03,  2.6651e-02, -5.1961e-04,  1.0177e-02, -5.0358e-04,\n",
       "                      -3.1162e-03,  1.1485e-03,  2.3449e-03,  5.7579e-03,  2.0148e-03,\n",
       "                      -1.6503e-02,  2.6855e-03,  3.9335e-03,  5.0946e-03, -2.4864e-03,\n",
       "                       4.5914e-04,  5.7783e-03, -5.6906e-03,  2.0783e-02,  6.2166e-03,\n",
       "                       1.6246e-02, -5.0117e-03,  1.8415e-02,  6.7536e-03,  1.2699e-02,\n",
       "                       1.5044e-03,  2.0635e-02, -1.0137e-02, -7.4635e-04,  3.4748e-03,\n",
       "                      -1.2583e-02,  1.1584e-02,  1.0432e-04, -1.1415e-02,  7.4176e-03,\n",
       "                       9.8773e-03,  4.2872e-03,  6.3857e-03,  1.1473e-02,  7.5385e-03,\n",
       "                       1.9569e-02,  9.6758e-03,  1.7637e-03,  1.2172e-02, -6.1527e-04,\n",
       "                       3.1739e-03,  3.6395e-03,  8.6972e-03,  8.2982e-03, -4.3376e-03,\n",
       "                       6.1956e-03, -1.0330e-02,  1.5533e-02,  5.4485e-03, -1.4536e-02,\n",
       "                       6.5557e-03,  2.1886e-03,  1.2654e-03, -7.3626e-03,  1.3961e-02,\n",
       "                       3.2203e-03,  3.8345e-03,  5.2962e-03,  3.5489e-03,  8.7098e-03,\n",
       "                       5.1441e-03, -5.6493e-03,  1.2580e-02,  4.9796e-03, -4.0797e-03,\n",
       "                       1.9536e-02, -6.4345e-04,  8.5748e-03,  1.5892e-02,  1.1218e-03,\n",
       "                       1.3201e-03,  8.9287e-03,  1.0843e-02, -4.6612e-03,  9.9995e-03,\n",
       "                      -1.3770e-02,  1.0499e-02,  1.1785e-03,  1.8498e-02, -3.4479e-03,\n",
       "                       1.8951e-02,  1.4431e-02,  5.9199e-03,  8.4126e-03,  1.7128e-04,\n",
       "                      -8.5813e-05, -2.8638e-03,  3.3997e-03,  8.3548e-03,  5.2371e-03,\n",
       "                      -1.2303e-02, -8.5048e-03,  5.5197e-03,  1.7341e-02,  1.2428e-02,\n",
       "                       5.6500e-03,  1.1565e-02,  2.2414e-03,  6.1242e-03, -1.6087e-02,\n",
       "                      -6.1538e-04,  8.0821e-03, -1.8215e-03, -2.8419e-03,  3.2766e-03,\n",
       "                       1.1355e-02,  1.1704e-02,  5.3001e-03,  5.8542e-03,  1.4611e-02,\n",
       "                       7.1493e-03,  6.6420e-03,  1.3843e-02,  7.1460e-03,  1.3853e-02,\n",
       "                      -1.1961e-02,  6.4787e-03,  4.9110e-03,  6.9287e-03,  1.0113e-03,\n",
       "                       1.4356e-02, -8.8628e-03,  1.5570e-02,  4.3827e-03, -7.6180e-03,\n",
       "                       1.5298e-02, -2.6279e-03, -7.0567e-04,  1.2226e-02,  1.0264e-02,\n",
       "                       5.6292e-03,  1.4108e-02,  9.7730e-03,  1.2464e-02,  1.3172e-02,\n",
       "                       1.0309e-02, -9.3897e-04,  4.8680e-03, -1.0985e-03, -9.7914e-03,\n",
       "                       1.8173e-03, -3.9861e-03, -2.5794e-03,  8.9996e-03,  1.4294e-02,\n",
       "                      -2.4580e-03, -1.2432e-02,  1.0035e-02,  7.1383e-03,  1.7669e-02,\n",
       "                       3.5820e-03,  2.6287e-03,  6.8362e-03,  1.2864e-02, -1.3407e-02,\n",
       "                       8.9756e-03,  1.5456e-03,  1.5476e-02,  1.1778e-03,  3.0518e-03,\n",
       "                      -6.6359e-03,  1.3613e-02, -3.8887e-03, -7.0535e-03,  1.3730e-02,\n",
       "                       7.4535e-03,  1.5217e-02,  1.0624e-02,  2.7994e-03,  7.9460e-03,\n",
       "                       6.4029e-03,  1.7332e-03,  8.2180e-03,  3.8802e-04,  2.9754e-03,\n",
       "                       5.1203e-03,  5.0671e-03,  4.8154e-03,  7.6486e-03,  1.4512e-02,\n",
       "                       6.9504e-04,  2.4737e-02,  1.9011e-02,  2.1740e-02,  1.2979e-02,\n",
       "                      -3.5348e-03,  8.7237e-03, -9.1532e-03,  7.2170e-03,  1.2567e-02,\n",
       "                       1.6782e-02,  1.0727e-02,  1.3058e-02,  4.3813e-03,  8.6895e-03,\n",
       "                      -9.6833e-04,  3.9261e-03,  1.7278e-02,  5.9452e-03,  2.4141e-03,\n",
       "                      -1.1391e-02,  2.5442e-03,  3.7994e-03,  1.5546e-02, -1.0604e-03,\n",
       "                       4.2490e-03, -7.7515e-03,  7.7381e-04, -1.4722e-02,  1.4590e-02,\n",
       "                       5.2157e-03, -4.1489e-03,  7.5514e-03,  6.9254e-03,  4.2418e-03,\n",
       "                       9.1679e-03,  4.0182e-03, -6.2320e-03,  1.0112e-02,  3.4802e-03,\n",
       "                      -3.5700e-03,  3.8317e-03,  1.0593e-03,  6.4606e-03,  4.8826e-03,\n",
       "                       1.2504e-02,  6.2789e-03,  3.8198e-03, -3.1651e-03, -7.3658e-03,\n",
       "                       1.7694e-02,  2.1122e-02,  2.0354e-02,  1.5853e-02,  8.8716e-03,\n",
       "                       2.8387e-03], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.2.1.running_mean',\n",
       "              tensor([ 3.4907e-01,  1.0975e+00,  8.3447e-01,  5.2128e-01, -2.9051e-01,\n",
       "                       2.9902e-01, -1.3224e-01,  7.1919e-01,  5.2518e-01, -2.3102e-01,\n",
       "                      -4.8224e-01,  3.0748e-01,  1.5505e-01,  1.1025e-02, -3.3948e-01,\n",
       "                      -1.0461e-01, -5.2431e-01, -3.7457e-02, -9.3342e-02,  3.2749e-01,\n",
       "                       2.8768e-01,  7.4168e-01, -4.5377e-01,  3.5318e-01,  1.3855e-01,\n",
       "                      -8.1217e-02, -4.7301e-01,  1.3861e-01,  9.7304e-02,  3.5675e-01,\n",
       "                       2.9994e-01,  7.1146e-01, -2.0036e-01, -3.2643e-02, -5.1212e-02,\n",
       "                      -2.3895e-01, -2.6988e-01,  3.2192e-01,  4.5530e-02,  1.2316e+00,\n",
       "                      -6.6901e-01,  6.9515e-01,  2.5155e-01,  1.8132e-01, -7.5381e-01,\n",
       "                      -3.9510e-01, -4.4947e-01, -1.7423e-01,  1.7089e-01, -1.4083e-01,\n",
       "                      -3.6898e-01, -3.4458e-01, -1.3817e-01,  1.4257e-01, -4.3154e-04,\n",
       "                      -2.2697e-01,  5.6637e-01,  2.8352e-01,  1.9710e-01,  9.3985e-02,\n",
       "                      -1.2462e-01, -4.6928e-03, -1.4336e-01,  8.6031e-02,  7.3851e-01,\n",
       "                       1.3210e-01,  5.2813e-01, -8.1552e-01,  4.0679e-01,  1.2003e+00,\n",
       "                       1.3908e-01, -4.6754e-01, -7.2263e-02, -4.5304e-01,  5.0017e-01,\n",
       "                       1.3231e-01, -5.2738e-01, -2.5835e-01, -1.4379e-01, -9.5151e-03,\n",
       "                      -4.0354e-01, -3.2201e-01, -4.2015e-01,  4.0586e-02,  3.9121e-02,\n",
       "                      -1.2986e-01,  1.6395e-02,  4.7344e-01,  6.6087e-01, -3.1110e-01,\n",
       "                       7.2352e-01,  4.8726e-02, -1.2104e-01,  4.1115e-01,  4.5737e-02,\n",
       "                       5.1839e-01, -9.1699e-01, -7.8547e-02,  1.0196e-02,  4.4483e-01,\n",
       "                      -3.7035e-01,  2.8131e-01, -1.6556e-01, -3.7337e-01,  1.0925e-01,\n",
       "                      -5.0882e-02,  3.5042e-01, -7.5298e-01, -5.5560e-01,  2.7920e-01,\n",
       "                      -2.0436e-01,  1.5936e-01,  7.3897e-01, -2.0633e-01, -2.2686e-01,\n",
       "                      -3.3010e-01, -9.2319e-02, -7.6125e-01,  2.1368e-01, -1.4402e-01,\n",
       "                      -1.3299e-01, -1.5437e-02, -3.5225e-02,  3.9060e-01,  2.7066e-01,\n",
       "                       3.4418e-01,  3.1973e-01,  2.4917e-01,  2.8555e-01,  2.4531e-02,\n",
       "                      -3.0442e-01, -8.4320e-03,  1.4430e-01, -2.6868e-01,  2.7234e-02,\n",
       "                      -3.1994e-01,  9.4882e-02,  2.7606e-02,  4.5356e-02,  2.9554e-01,\n",
       "                      -3.2703e-01,  2.0529e-01, -2.2938e-01,  1.5854e-01,  1.1606e-01,\n",
       "                       1.0990e+00,  1.0217e-01, -6.3256e-01, -2.8041e-01, -5.9742e-01,\n",
       "                      -4.6316e-01, -4.9943e-01,  3.3065e-01,  4.1759e-01,  2.5410e-01,\n",
       "                       7.3505e-02, -1.9015e-01, -2.3267e-01, -7.0669e-01, -1.1676e-01,\n",
       "                       5.0032e-01, -6.5113e-01, -9.3694e-02,  7.6357e-02, -2.0035e-01,\n",
       "                      -6.4756e-01,  1.3382e+00, -1.3862e-01, -3.0377e-01,  2.7887e-01,\n",
       "                       4.9738e-03, -2.3537e-01,  5.8073e-02,  1.8501e-01,  2.2573e-01,\n",
       "                       1.9967e-01,  8.4538e-01, -1.5261e-01, -6.2222e-01, -4.3743e-01,\n",
       "                      -3.1208e-01,  9.1004e-02,  1.6211e-01, -1.5909e-02,  5.6480e-01,\n",
       "                       2.2774e-01, -1.2508e-01, -2.3965e-01, -1.3479e-01, -2.2823e-01,\n",
       "                       1.6182e-01, -3.9262e-01, -2.8745e-01, -1.6059e-01, -1.7430e-01,\n",
       "                      -5.6459e-01,  1.7784e-01, -1.0801e-01, -5.8403e-01,  2.1295e-02,\n",
       "                      -3.0989e-03,  6.8947e-02, -7.2755e-01,  8.0429e-01,  6.5535e-02,\n",
       "                      -3.8094e-01,  1.7630e-02,  6.5602e-02,  7.6656e-01, -9.7309e-01,\n",
       "                       6.1990e-01,  4.2762e-02,  8.4209e-02, -5.0984e-01,  1.3233e-01,\n",
       "                       5.0768e-01,  1.4121e-01,  1.1936e-01, -5.2422e-01,  1.9140e-01,\n",
       "                       6.9382e-02, -2.3407e-01, -2.3527e-01, -3.0487e-01,  2.8265e-01,\n",
       "                       2.2452e-01, -2.9291e-01,  3.9142e-01,  1.2703e-01,  8.0181e-01,\n",
       "                      -2.4266e-01, -2.5739e-01, -1.2371e-01, -7.5394e-02, -8.5431e-02,\n",
       "                       2.9134e-01,  6.2795e-02,  1.0810e-02, -5.1935e-01,  5.8161e-01,\n",
       "                      -5.7877e-02,  2.2322e-01, -5.8455e-01,  2.9310e-01,  6.1642e-01,\n",
       "                       3.3634e-01,  3.4446e-02, -5.2707e-02, -1.8586e-01,  4.7381e-01,\n",
       "                       2.4695e-01, -1.7676e-01,  1.9784e-01, -4.2809e-01, -1.3898e-01,\n",
       "                      -1.9006e-01], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.2.1.running_var',\n",
       "              tensor([0.4041, 0.5088, 0.2466, 0.3358, 0.0859, 0.5084, 0.1815, 0.2342, 0.3926,\n",
       "                      0.4455, 0.3380, 0.3973, 0.3118, 0.3324, 0.3818, 0.5277, 0.4144, 0.2324,\n",
       "                      0.2750, 0.2488, 0.4377, 0.5214, 0.4501, 0.3516, 0.5036, 0.1696, 0.3078,\n",
       "                      0.0954, 0.1928, 0.3162, 0.3688, 0.3521, 0.1933, 0.2428, 0.2941, 0.4190,\n",
       "                      0.1252, 0.3590, 0.3396, 0.3514, 0.4784, 0.4142, 0.1818, 0.4453, 0.3781,\n",
       "                      0.4151, 0.2098, 0.2334, 0.3363, 0.3920, 0.3204, 0.3814, 0.3976, 0.2580,\n",
       "                      0.3838, 0.1142, 0.5447, 0.5769, 0.4246, 0.3364, 0.2043, 0.4817, 0.1496,\n",
       "                      0.3479, 0.3235, 0.3930, 0.5187, 0.4929, 0.3724, 0.7292, 0.1621, 0.2560,\n",
       "                      0.1837, 0.5179, 0.3210, 0.1549, 0.5898, 0.1526, 0.5336, 0.3186, 0.2536,\n",
       "                      0.4074, 0.5451, 0.2794, 0.3199, 0.3121, 0.2962, 0.1719, 0.2281, 0.2186,\n",
       "                      0.3387, 0.2662, 0.2532, 0.3475, 0.3452, 0.2794, 0.5138, 0.2463, 0.4809,\n",
       "                      0.3081, 0.3501, 0.4933, 0.2343, 0.2715, 0.2429, 0.2683, 0.4334, 0.7463,\n",
       "                      0.7225, 0.1995, 0.3021, 0.5213, 0.4687, 0.4247, 0.4333, 0.4714, 0.3188,\n",
       "                      0.3949, 0.2066, 0.2932, 0.1162, 0.4556, 0.3654, 0.0972, 0.3851, 0.3361,\n",
       "                      0.3994, 0.2667, 0.3424, 0.1899, 0.0627, 0.4577, 0.2910, 0.4304, 0.2704,\n",
       "                      0.2596, 0.3100, 0.1396, 0.1677, 0.2925, 0.2879, 0.1875, 0.4363, 0.2424,\n",
       "                      0.1326, 0.6246, 0.3400, 0.5680, 0.0618, 0.3628, 0.5246, 0.3419, 0.2571,\n",
       "                      0.5892, 0.4431, 0.4687, 0.1958, 0.3582, 0.3042, 0.0947, 0.2855, 0.3153,\n",
       "                      0.2800, 0.2818, 0.3723, 0.3595, 0.5450, 0.1248, 0.2607, 0.4605, 0.2021,\n",
       "                      0.1692, 0.3475, 0.2850, 0.4515, 0.6024, 0.3446, 0.3902, 0.2548, 0.2524,\n",
       "                      0.4572, 0.3328, 0.2283, 0.2228, 0.2460, 0.2907, 0.1223, 0.2900, 0.2742,\n",
       "                      0.0942, 0.3581, 0.1487, 0.3447, 0.5676, 0.3000, 0.5342, 0.3547, 0.2202,\n",
       "                      0.3219, 0.2116, 0.1768, 0.2955, 0.3635, 0.6483, 0.3323, 0.4829, 0.1149,\n",
       "                      0.0802, 0.2705, 0.4032, 0.1234, 0.1683, 0.1140, 0.4022, 0.2817, 0.2835,\n",
       "                      0.3301, 0.1958, 0.3088, 0.5258, 0.0648, 0.2727, 0.3238, 0.2582, 0.5038,\n",
       "                      0.2845, 0.2742, 0.1998, 0.3688, 0.4831, 0.4021, 0.3616, 0.3976, 0.4253,\n",
       "                      0.1921, 0.4696, 0.2922, 0.1325, 0.2844, 0.3660, 0.2176, 0.1321, 0.4654,\n",
       "                      0.2659, 0.4366, 0.2134, 0.2079, 0.4556, 0.0953, 0.4804, 0.2391, 0.4423,\n",
       "                      0.3008, 0.5873, 0.2853, 0.3567], dtype=torch.float64)),\n",
       "             ('6.11.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.12.convs.0.0.weight',\n",
       "              tensor([[[-0.0688],\n",
       "                       [ 0.0173],\n",
       "                       [-0.0150],\n",
       "                       ...,\n",
       "                       [-0.1434],\n",
       "                       [ 0.0732],\n",
       "                       [ 0.0834]],\n",
       "              \n",
       "                      [[ 0.0636],\n",
       "                       [-0.0964],\n",
       "                       [ 0.0191],\n",
       "                       ...,\n",
       "                       [-0.0721],\n",
       "                       [-0.0149],\n",
       "                       [-0.0249]],\n",
       "              \n",
       "                      [[-0.0309],\n",
       "                       [ 0.0231],\n",
       "                       [ 0.0058],\n",
       "                       ...,\n",
       "                       [-0.0728],\n",
       "                       [-0.0469],\n",
       "                       [-0.0746]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1119],\n",
       "                       [-0.0471],\n",
       "                       [-0.1694],\n",
       "                       ...,\n",
       "                       [-0.0081],\n",
       "                       [-0.0041],\n",
       "                       [-0.0197]],\n",
       "              \n",
       "                      [[ 0.1178],\n",
       "                       [-0.0608],\n",
       "                       [ 0.0560],\n",
       "                       ...,\n",
       "                       [ 0.0591],\n",
       "                       [ 0.0249],\n",
       "                       [-0.0473]],\n",
       "              \n",
       "                      [[ 0.1067],\n",
       "                       [-0.2160],\n",
       "                       [-0.1499],\n",
       "                       ...,\n",
       "                       [-0.0632],\n",
       "                       [-0.0009],\n",
       "                       [ 0.0064]]], dtype=torch.float64)),\n",
       "             ('6.12.convs.0.1.weight',\n",
       "              tensor([0.9793, 0.9858, 0.9421, 0.9929, 1.0062, 0.9816, 0.9431, 0.9761, 0.9678,\n",
       "                      0.9580, 1.0027, 0.9745, 0.9507, 0.9718, 0.9744, 0.9663, 0.9650, 0.9668,\n",
       "                      0.9697, 0.9661, 0.9674, 0.9912, 0.9772, 0.9834, 0.9990, 0.9591, 0.9882,\n",
       "                      0.9731, 0.9708, 0.9896, 0.9724, 0.9704, 0.9711, 0.9619, 0.9749, 0.9770,\n",
       "                      0.9645, 0.9659, 0.9779, 0.9818, 0.9747, 0.9940, 0.9899, 0.9682, 0.9827,\n",
       "                      0.9679, 0.9909, 0.9788, 0.9202, 0.9779, 0.9724, 1.0002, 0.9703, 0.9655,\n",
       "                      0.9570, 0.9803, 0.9931, 0.9642, 0.9822, 0.9646, 0.9927, 0.9654, 0.9393,\n",
       "                      0.9669], dtype=torch.float64)),\n",
       "             ('6.12.convs.0.1.bias',\n",
       "              tensor([ 0.0152,  0.0176, -0.0203,  0.0302,  0.0211,  0.0153, -0.0056, -0.0247,\n",
       "                       0.0118,  0.0003,  0.0345,  0.0169, -0.0162,  0.0091, -0.0164,  0.0181,\n",
       "                       0.0071, -0.0068,  0.0080,  0.0084, -0.0123,  0.0230, -0.0059, -0.0082,\n",
       "                       0.0090, -0.0118,  0.0114,  0.0118,  0.0090,  0.0077,  0.0141,  0.0111,\n",
       "                      -0.0120,  0.0012, -0.0092,  0.0153, -0.0187, -0.0139,  0.0082, -0.0021,\n",
       "                       0.0135,  0.0060, -0.0336, -0.0128,  0.0088,  0.0054,  0.0216,  0.0037,\n",
       "                      -0.0144,  0.0064,  0.0139,  0.0036, -0.0087, -0.0077, -0.0213,  0.0095,\n",
       "                       0.0204, -0.0097, -0.0041, -0.0139,  0.0306,  0.0203, -0.0260,  0.0081],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convs.0.1.running_mean',\n",
       "              tensor([-0.5332, -0.6010,  0.4165, -1.0350,  0.4159,  0.2513, -0.0903, -0.1744,\n",
       "                      -0.2938, -0.0091, -0.0532, -0.0422,  0.8737, -1.1439,  1.3057,  0.1041,\n",
       "                       0.7279, -0.9889, -0.0745,  0.0590, -0.0455, -1.0139,  0.6245, -0.4647,\n",
       "                      -0.3633, -1.1606,  0.1107, -0.1427, -0.2794, -0.7135, -0.8088, -0.5740,\n",
       "                      -0.0075, -0.5612, -0.0704, -0.4165, -0.3024,  0.0695, -0.2785,  0.0186,\n",
       "                      -0.0033,  0.5229,  0.3831,  0.4827,  0.3439, -0.0287, -0.4526,  0.0159,\n",
       "                      -0.6273,  0.0887,  0.8727, -0.3394, -0.4260,  0.3998, -1.1015, -0.3104,\n",
       "                       0.1875, -0.3478, -0.3079,  0.0184, -0.3081, -0.6360,  0.8429,  0.1165],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convs.0.1.running_var',\n",
       "              tensor([0.2153, 0.2243, 0.4917, 0.1777, 0.1228, 0.3646, 1.0509, 0.2096, 0.2503,\n",
       "                      0.1367, 0.3334, 0.2203, 0.6143, 0.4596, 0.2833, 0.2081, 0.5929, 0.1848,\n",
       "                      0.4142, 0.1655, 0.3030, 0.1831, 0.1373, 0.2344, 0.0993, 0.2555, 0.1468,\n",
       "                      0.3382, 0.1737, 0.1317, 0.5765, 0.3156, 0.2321, 0.2572, 0.2599, 0.1347,\n",
       "                      0.2165, 0.1822, 0.1422, 0.1964, 0.1127, 0.2739, 0.1030, 0.5523, 0.2264,\n",
       "                      0.4282, 0.1569, 0.3010, 1.2961, 0.1360, 0.8328, 0.1380, 0.6535, 0.4705,\n",
       "                      0.2673, 0.1179, 0.2291, 0.1956, 0.1638, 0.1472, 0.2305, 0.1769, 1.4008,\n",
       "                      0.1850], dtype=torch.float64)),\n",
       "             ('6.12.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.12.convs.1.0.weight',\n",
       "              tensor([[[-9.7982e-02, -1.2761e-02, -6.6099e-02,  1.1663e-01, -1.4064e-02],\n",
       "                       [-1.0251e-01, -9.8539e-02,  6.1466e-02, -6.2549e-02, -2.1574e-02],\n",
       "                       [ 5.7186e-02,  5.7956e-02, -1.0764e-01,  1.3726e-01,  3.5745e-02],\n",
       "                       ...,\n",
       "                       [-3.5507e-02, -9.2969e-02, -8.2163e-02,  1.8373e-01, -9.4310e-03],\n",
       "                       [-6.0465e-02, -1.8567e-02, -3.0952e-02,  1.6370e-01,  3.6034e-02],\n",
       "                       [ 3.0720e-02,  2.2004e-02,  3.6270e-03, -1.3350e-01,  1.2168e-01]],\n",
       "              \n",
       "                      [[ 1.3370e-02,  4.3619e-03,  7.7166e-02, -8.6199e-02, -9.9938e-02],\n",
       "                       [-1.4915e-02, -2.9636e-02, -1.7970e-01, -8.7397e-02, -2.9516e-02],\n",
       "                       [-9.9077e-02, -1.4389e-01,  1.3561e-01, -3.4435e-02, -4.0424e-02],\n",
       "                       ...,\n",
       "                       [ 5.3762e-02, -2.9169e-02,  8.3221e-02,  3.9154e-02,  7.6082e-02],\n",
       "                       [ 3.1914e-02,  1.0319e-01, -5.5373e-02, -6.3963e-02, -1.2396e-03],\n",
       "                       [-4.0058e-02, -4.1074e-02, -7.4671e-02,  4.1508e-02, -5.5732e-02]],\n",
       "              \n",
       "                      [[-7.8395e-02, -3.6643e-02,  2.1610e-02,  1.0661e-01, -4.0530e-02],\n",
       "                       [-2.0141e-02, -4.3800e-04,  5.9087e-02,  1.5981e-02,  6.0337e-02],\n",
       "                       [ 3.3762e-02, -2.0943e-02, -6.4002e-02,  1.2842e-02, -4.2015e-02],\n",
       "                       ...,\n",
       "                       [ 1.1113e-01, -4.2215e-02,  5.2007e-02,  1.4984e-02, -9.5229e-02],\n",
       "                       [-1.5339e-01,  1.8578e-02,  1.1406e-01,  2.6761e-02,  2.8678e-02],\n",
       "                       [-8.0011e-02, -5.3326e-02,  4.0838e-03,  2.2574e-02,  2.3392e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-6.9709e-03,  7.2196e-02, -1.6725e-02,  9.0950e-02,  1.3865e-01],\n",
       "                       [ 1.5826e-01,  8.4815e-03,  1.3853e-01, -7.0594e-03,  5.1524e-03],\n",
       "                       [-5.7565e-02, -3.9104e-02,  8.2913e-02, -2.1487e-02,  5.7015e-02],\n",
       "                       ...,\n",
       "                       [ 1.7257e-01,  5.1367e-02, -1.3975e-01,  1.0109e-01, -3.2802e-02],\n",
       "                       [-7.4708e-02, -5.9357e-02,  6.4704e-02, -2.3270e-02, -4.4137e-03],\n",
       "                       [-1.2323e-02,  5.4410e-02,  3.8502e-02, -2.7522e-02,  8.8798e-02]],\n",
       "              \n",
       "                      [[ 7.8709e-02,  3.9630e-02, -7.9865e-03,  5.0950e-02,  1.2268e-01],\n",
       "                       [-2.9876e-02,  6.3758e-04,  7.0092e-02, -8.2118e-02, -9.1391e-02],\n",
       "                       [ 7.6682e-02, -1.8632e-02,  4.7409e-02,  9.4682e-02,  9.3635e-02],\n",
       "                       ...,\n",
       "                       [ 8.5360e-02, -5.9873e-02,  1.0453e-01, -2.7172e-02, -3.1872e-03],\n",
       "                       [-7.2148e-03,  1.0446e-02,  5.0150e-02, -2.7209e-02,  1.9987e-03],\n",
       "                       [-1.0219e-01, -6.8400e-02,  2.4034e-02, -1.2183e-03,  7.0378e-03]],\n",
       "              \n",
       "                      [[ 7.5180e-03,  7.1001e-02, -1.2814e-01,  2.0146e-02, -6.5666e-02],\n",
       "                       [-1.1598e-01,  1.3663e-01,  1.8703e-01, -7.9319e-02, -2.5803e-02],\n",
       "                       [ 2.4860e-02,  2.9315e-03,  8.8203e-02, -8.3283e-03, -4.9884e-02],\n",
       "                       ...,\n",
       "                       [-5.8444e-05, -1.6208e-02, -4.2016e-02, -2.3293e-04, -5.8134e-02],\n",
       "                       [-3.1801e-02,  7.1128e-02,  4.9274e-02, -6.8835e-03,  6.1572e-02],\n",
       "                       [ 3.1043e-02, -3.2092e-02, -1.2546e-01,  6.0253e-03,  1.1994e-01]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convs.1.1.weight',\n",
       "              tensor([0.9727, 0.9840, 0.9796, 0.9941, 0.9532, 0.9603, 0.9452, 0.9722, 0.9417,\n",
       "                      0.9682, 0.9613, 0.9770, 0.9584, 0.9599, 0.9627, 0.9902, 1.0144, 0.9612,\n",
       "                      0.9503, 0.9543, 0.9639, 0.9526, 0.9711, 0.9664, 0.9383, 0.9562, 0.9569,\n",
       "                      0.9619, 0.9755, 0.9605, 0.9621, 1.0033, 0.9588, 0.9698, 0.9776, 0.9520,\n",
       "                      0.9810, 0.9803, 0.9994, 0.9801, 0.9548, 0.9874, 0.9612, 0.9967, 0.9625,\n",
       "                      0.9882, 0.9556, 0.9615, 0.9689, 0.9437, 1.0050, 0.9610, 0.9465, 0.9830,\n",
       "                      0.9372, 0.9765, 0.9470, 0.9552, 0.9649, 0.9725, 0.9534, 0.9733, 0.9731,\n",
       "                      0.9774], dtype=torch.float64)),\n",
       "             ('6.12.convs.1.1.bias',\n",
       "              tensor([-0.0153,  0.0058,  0.0003, -0.0060,  0.0036, -0.0165, -0.0073,  0.0012,\n",
       "                      -0.0087, -0.0165, -0.0252,  0.0165, -0.0342,  0.0058,  0.0005, -0.0091,\n",
       "                       0.0293, -0.0177, -0.0143, -0.0212, -0.0146, -0.0334,  0.0051, -0.0251,\n",
       "                      -0.0109, -0.0313, -0.0217, -0.0116, -0.0025, -0.0087, -0.0085,  0.0123,\n",
       "                      -0.0101,  0.0026, -0.0030,  0.0107,  0.0129, -0.0006, -0.0061, -0.0005,\n",
       "                      -0.0163,  0.0128, -0.0111,  0.0302,  0.0068,  0.0010, -0.0077, -0.0036,\n",
       "                      -0.0173, -0.0139, -0.0076, -0.0533, -0.0227,  0.0029, -0.0203, -0.0022,\n",
       "                      -0.0113, -0.0313, -0.0190,  0.0043, -0.0230, -0.0135,  0.0009,  0.0093],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convs.1.1.running_mean',\n",
       "              tensor([ 1.2463,  0.2691,  0.2006,  0.6099, -0.7010,  0.2026, -0.2258, -0.0429,\n",
       "                      -0.0074,  0.5334, -0.4643, -0.2287,  0.0568, -0.5103, -0.3855,  0.0943,\n",
       "                      -0.5141,  0.0113, -0.5586, -0.1022,  0.2446,  0.2875, -0.5562,  0.6388,\n",
       "                       0.1918,  0.2068,  0.2429, -0.6888, -0.0700,  0.5268,  0.2255,  0.4996,\n",
       "                      -0.3366, -1.1653, -0.0834, -0.5605,  0.3329, -0.0566,  0.1109,  0.3425,\n",
       "                      -0.1902, -0.0698, -0.2286, -0.8737, -0.0582, -0.0644, -1.3233,  0.0579,\n",
       "                       0.5339,  0.2005,  0.1695,  0.4966,  0.4083, -0.6585, -0.4888,  0.0511,\n",
       "                      -0.1164,  0.6424,  0.5446, -0.3016, -0.2471,  0.7757,  0.4093, -0.6232],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convs.1.1.running_var',\n",
       "              tensor([0.7758, 0.5843, 0.5248, 0.4503, 0.6307, 0.4795, 0.3695, 0.4656, 0.4163,\n",
       "                      0.6106, 0.7637, 0.4951, 0.4428, 1.0930, 0.5325, 0.5584, 0.5000, 0.5542,\n",
       "                      0.4828, 0.6982, 0.6061, 0.5412, 0.6219, 0.4847, 0.7456, 0.5069, 0.4489,\n",
       "                      0.4655, 0.4122, 0.4522, 0.6073, 0.4349, 0.6295, 0.4845, 1.1838, 0.6203,\n",
       "                      0.5063, 0.4700, 0.4704, 0.3182, 0.5585, 0.4173, 0.4882, 0.8518, 0.3987,\n",
       "                      0.6489, 0.5742, 0.4507, 0.7601, 0.4160, 0.5150, 0.7346, 0.6092, 0.6886,\n",
       "                      1.1726, 0.4357, 0.6276, 0.7141, 0.6504, 0.4412, 0.5721, 0.4725, 0.6901,\n",
       "                      0.3921], dtype=torch.float64)),\n",
       "             ('6.12.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.12.convs.2.0.weight',\n",
       "              tensor([[[ 4.2645e-02],\n",
       "                       [-4.4919e-02],\n",
       "                       [ 9.1611e-02],\n",
       "                       ...,\n",
       "                       [ 1.8184e-01],\n",
       "                       [ 4.4987e-02],\n",
       "                       [-7.1846e-02]],\n",
       "              \n",
       "                      [[-5.2676e-02],\n",
       "                       [-3.0656e-02],\n",
       "                       [-9.9997e-02],\n",
       "                       ...,\n",
       "                       [-2.5832e-03],\n",
       "                       [ 2.9083e-01],\n",
       "                       [-9.7800e-02]],\n",
       "              \n",
       "                      [[ 5.0634e-02],\n",
       "                       [ 4.2759e-02],\n",
       "                       [ 1.7114e-01],\n",
       "                       ...,\n",
       "                       [-2.1405e-04],\n",
       "                       [ 1.3658e-01],\n",
       "                       [ 8.1322e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.6691e-01],\n",
       "                       [ 2.2944e-01],\n",
       "                       [ 9.7645e-04],\n",
       "                       ...,\n",
       "                       [ 6.8186e-02],\n",
       "                       [-1.1157e-01],\n",
       "                       [ 5.7341e-02]],\n",
       "              \n",
       "                      [[ 3.2393e-02],\n",
       "                       [-6.8236e-02],\n",
       "                       [ 1.1008e-01],\n",
       "                       ...,\n",
       "                       [ 3.1608e-02],\n",
       "                       [-1.3980e-01],\n",
       "                       [ 8.9334e-02]],\n",
       "              \n",
       "                      [[-2.2162e-02],\n",
       "                       [-1.0166e-02],\n",
       "                       [ 2.3773e-01],\n",
       "                       ...,\n",
       "                       [-4.0543e-02],\n",
       "                       [-1.6363e-01],\n",
       "                       [ 1.0111e-01]]], dtype=torch.float64)),\n",
       "             ('6.12.convs.2.1.weight',\n",
       "              tensor([ 4.3333e-03, -3.2985e-02,  3.9914e-03, -2.6680e-04,  1.3390e-02,\n",
       "                       5.7171e-03,  2.5363e-02,  1.4338e-02, -2.0090e-02, -2.2176e-03,\n",
       "                       9.1880e-03, -3.7147e-02,  1.0612e-02, -1.9335e-03, -5.7457e-03,\n",
       "                       1.7238e-02,  2.5920e-02,  7.0679e-03,  1.3227e-02,  2.9495e-02,\n",
       "                      -7.9638e-03,  1.7731e-02,  4.5621e-03,  1.3678e-02,  5.9185e-03,\n",
       "                       1.7896e-02,  9.2414e-03,  1.3525e-02,  1.6675e-02, -2.6282e-02,\n",
       "                       3.5259e-05,  1.6538e-02, -1.3696e-02,  1.9330e-02,  2.7159e-02,\n",
       "                       2.2065e-02,  1.1225e-02,  1.0586e-02, -2.6503e-02, -4.3072e-02,\n",
       "                       2.3337e-03, -3.3425e-02, -3.1829e-02,  2.3749e-03, -7.8579e-03,\n",
       "                      -1.0979e-02,  5.4345e-03,  6.3433e-03, -5.2358e-02,  1.4357e-02,\n",
       "                       1.2711e-02,  1.3936e-03,  1.0062e-02, -1.7712e-02, -8.6028e-03,\n",
       "                      -2.2248e-02, -7.1339e-03, -7.2612e-03,  2.3742e-03,  1.2199e-02,\n",
       "                       4.7175e-03, -9.7278e-03,  7.1659e-03,  1.6170e-03,  6.4444e-03,\n",
       "                       1.0993e-02,  7.1212e-03, -2.1645e-02,  2.4415e-03,  1.7752e-02,\n",
       "                       4.2838e-03,  1.2279e-02,  7.4552e-03, -2.1457e-02,  7.0103e-03,\n",
       "                       1.2902e-02,  2.3184e-02,  9.0124e-03, -1.0797e-03,  1.6717e-02,\n",
       "                       7.3032e-03, -1.2958e-02,  8.5208e-03, -1.1383e-02, -5.2576e-03,\n",
       "                       5.8323e-03, -3.4887e-03,  3.4044e-02, -1.6613e-02, -2.3611e-03,\n",
       "                      -1.4635e-02, -2.7882e-02, -1.0064e-02,  1.1715e-02,  1.7560e-02,\n",
       "                       2.7311e-03, -2.3777e-02, -2.2234e-02, -5.5099e-03,  1.1357e-02,\n",
       "                       2.5698e-02, -3.9072e-03,  2.1077e-02, -3.5788e-02, -1.9684e-02,\n",
       "                       1.4666e-02, -8.2681e-03,  2.3861e-02,  2.6581e-02, -1.3678e-02,\n",
       "                      -1.5686e-02, -1.1667e-02,  3.5243e-03,  1.1915e-02,  3.7788e-02,\n",
       "                       1.4163e-02,  9.0875e-03,  1.8285e-02,  1.9371e-02, -1.9560e-02,\n",
       "                       2.2672e-02,  5.7491e-03, -2.3855e-02,  1.8731e-02, -6.7731e-04,\n",
       "                      -3.1417e-02,  1.0569e-02, -2.8762e-03,  9.5676e-03,  1.5725e-02,\n",
       "                       5.6691e-03, -1.2855e-03,  1.9320e-02,  1.3017e-02, -2.3978e-02,\n",
       "                       2.2088e-02, -3.0879e-02,  1.8831e-02,  2.7621e-03,  1.7204e-02,\n",
       "                       7.7387e-03, -2.0760e-03,  2.5390e-02,  7.3766e-03,  1.0156e-02,\n",
       "                      -1.2003e-02,  1.5718e-02,  3.8513e-03, -1.8115e-02, -2.7875e-02,\n",
       "                      -7.2305e-03, -2.0790e-02,  7.2825e-03, -2.8709e-02, -3.7876e-02,\n",
       "                      -6.8566e-03,  9.1621e-03,  1.5685e-02, -1.7024e-02, -1.2376e-03,\n",
       "                      -2.0125e-02, -8.5298e-03, -2.8956e-03,  2.0038e-02, -1.8752e-02,\n",
       "                      -1.1455e-02,  6.8390e-03,  5.1941e-03, -8.6517e-03,  1.8406e-02,\n",
       "                      -1.0333e-02,  5.1810e-03,  1.0007e-02,  2.0577e-02, -2.2655e-02,\n",
       "                       3.7010e-03, -5.8759e-03,  8.3018e-03, -8.6059e-03,  1.1485e-02,\n",
       "                      -5.3462e-04,  1.8886e-02,  1.2490e-03,  7.4949e-03, -2.2191e-03,\n",
       "                       6.7708e-03, -1.6585e-02,  1.2357e-02, -1.1070e-02, -1.4082e-02,\n",
       "                       7.6563e-04, -9.5342e-03, -4.0074e-02, -4.3340e-02, -2.0792e-02,\n",
       "                      -1.1328e-02,  3.4753e-02,  5.3701e-03, -2.5156e-02, -1.3349e-02,\n",
       "                      -5.8134e-03, -3.2724e-02, -2.4255e-02,  1.5011e-02,  1.6584e-02,\n",
       "                       1.1896e-02,  3.8396e-03,  1.0835e-02,  3.9661e-03, -1.9407e-02,\n",
       "                      -7.8115e-03, -3.0624e-02,  4.0959e-02,  2.6369e-02, -1.7248e-02,\n",
       "                      -2.3680e-04, -1.4952e-02,  1.7921e-02, -2.8126e-02, -3.4492e-02,\n",
       "                       1.4971e-02, -2.0886e-02, -5.4711e-03,  1.1128e-02, -2.2040e-02,\n",
       "                      -8.8091e-03,  3.3865e-03, -3.1624e-03, -2.1064e-02, -2.5997e-02,\n",
       "                      -6.1313e-03,  5.7078e-03,  2.3235e-02,  3.4079e-03, -8.3955e-03,\n",
       "                      -1.7391e-02,  9.7061e-04,  2.1430e-02, -1.3030e-02, -3.8849e-02,\n",
       "                      -2.2701e-03,  2.1835e-02,  1.6006e-02,  5.3944e-03,  2.2795e-02,\n",
       "                       8.8596e-03, -9.8455e-03, -1.0179e-02, -2.1849e-02,  2.8151e-02,\n",
       "                       2.9802e-02,  1.9166e-02, -2.7278e-02, -5.1191e-03, -8.8329e-03,\n",
       "                       6.1739e-03], dtype=torch.float64)),\n",
       "             ('6.12.convs.2.1.bias',\n",
       "              tensor([-2.5600e-04,  1.7020e-02,  1.0045e-02,  1.4077e-02,  2.1968e-03,\n",
       "                       7.5821e-03,  7.3552e-03, -6.8334e-04,  7.3275e-03,  1.4333e-02,\n",
       "                       1.5833e-02, -5.8730e-03,  8.1243e-03, -4.2887e-03,  9.5703e-03,\n",
       "                       2.4902e-04,  2.4685e-02, -9.6970e-04,  9.9541e-03, -3.2593e-03,\n",
       "                      -3.8560e-03,  4.8604e-04,  4.7689e-03,  6.7267e-03,  5.6186e-03,\n",
       "                      -1.6607e-02,  5.4133e-03,  6.2940e-03,  2.9117e-03, -1.7983e-03,\n",
       "                       1.7642e-03,  6.9711e-03, -1.2844e-03,  2.0768e-02,  5.8349e-03,\n",
       "                       1.6876e-02, -4.8159e-03,  1.8574e-02,  6.5640e-03,  1.2572e-02,\n",
       "                       7.8595e-04,  1.9110e-02, -9.6012e-03, -1.6159e-03,  7.9766e-03,\n",
       "                      -1.2446e-02,  1.4124e-02, -9.4082e-04, -1.2313e-02,  7.6576e-03,\n",
       "                       8.6440e-03,  4.1945e-03,  8.4791e-03,  1.3316e-02,  2.9959e-03,\n",
       "                       1.8845e-02,  9.5597e-03,  1.3199e-03,  1.2198e-02, -2.2303e-03,\n",
       "                       1.1571e-03,  1.5151e-03,  9.3999e-03,  9.4843e-03, -4.6687e-03,\n",
       "                       3.7606e-03, -1.0555e-02,  1.6097e-02, -5.9984e-04, -1.4805e-02,\n",
       "                       7.0054e-03,  3.3655e-03,  4.3141e-05, -7.8689e-03,  1.3777e-02,\n",
       "                       8.5932e-03,  2.4855e-03,  1.0963e-03,  3.4996e-03,  1.4961e-02,\n",
       "                       5.9398e-03, -6.7026e-03,  1.0933e-02,  5.1164e-03, -2.6523e-03,\n",
       "                       1.6488e-02,  1.1068e-03,  1.0784e-02,  1.5853e-02,  2.2014e-03,\n",
       "                       1.2374e-03,  9.3275e-03,  1.0455e-02,  9.5208e-04,  9.8636e-03,\n",
       "                      -1.4447e-02,  1.0779e-02,  6.5399e-03,  2.0659e-02,  3.8402e-03,\n",
       "                       1.8976e-02,  1.5091e-02,  5.1299e-03,  7.7587e-03, -2.0852e-03,\n",
       "                      -7.5260e-04, -4.1723e-03,  8.7620e-03,  9.1412e-03,  4.5257e-03,\n",
       "                      -1.3500e-02, -8.3322e-03,  5.3216e-03,  2.0198e-02,  1.4477e-02,\n",
       "                       5.0377e-03,  1.1875e-02,  3.9472e-03,  6.6442e-03, -1.4596e-02,\n",
       "                       3.3788e-04,  9.5697e-03, -8.3387e-04, -2.2317e-03,  2.4434e-04,\n",
       "                       1.1601e-02,  9.2506e-03,  5.2181e-03,  5.9043e-03,  1.3239e-02,\n",
       "                       7.2757e-03,  7.3823e-03,  1.3766e-02,  4.6326e-03,  1.6891e-02,\n",
       "                      -1.0387e-02,  8.0736e-03,  3.3363e-03,  6.1905e-03,  9.3296e-04,\n",
       "                       1.2954e-02, -8.0869e-03,  1.7141e-02,  3.9806e-03, -7.8536e-03,\n",
       "                       1.5639e-02,  4.1875e-03,  2.0371e-03,  1.2778e-02,  8.8516e-03,\n",
       "                       1.4130e-02,  1.6991e-02,  5.4017e-03,  1.2235e-02,  1.3049e-02,\n",
       "                       5.2551e-03, -1.4156e-03,  3.4166e-03, -3.7861e-04, -1.1388e-02,\n",
       "                       4.2257e-03, -4.9475e-03, -2.5110e-03,  1.0504e-02,  1.3990e-02,\n",
       "                      -2.6560e-03, -1.2329e-02,  1.0394e-02,  7.3265e-03,  2.1756e-02,\n",
       "                       1.8259e-03,  1.0314e-03,  5.3184e-03,  1.4547e-02, -1.3551e-02,\n",
       "                       1.0348e-02,  1.5567e-03,  1.5888e-02,  8.0573e-04,  4.9805e-03,\n",
       "                      -6.0100e-03,  1.3268e-02, -5.1664e-03, -8.5644e-03,  1.1752e-02,\n",
       "                       7.6632e-03,  1.5471e-02,  1.0756e-02,  4.7474e-03,  6.8514e-03,\n",
       "                       5.8507e-03,  3.1228e-03,  9.7273e-03,  1.4821e-04,  1.7491e-03,\n",
       "                       7.2844e-03,  1.6729e-02,  3.4953e-03,  7.5682e-03,  1.4828e-02,\n",
       "                      -9.7120e-04,  2.5077e-02,  1.7338e-02,  1.9577e-02,  1.4727e-02,\n",
       "                      -1.4192e-03,  7.4099e-03, -9.1286e-03,  6.5704e-03,  1.2738e-02,\n",
       "                       8.5957e-03,  1.0890e-02,  1.2723e-02,  1.5806e-03,  1.0670e-02,\n",
       "                       1.1850e-03,  5.3435e-03,  2.1925e-02,  5.9399e-03,  2.2693e-03,\n",
       "                      -5.3717e-03,  9.6136e-04,  2.1991e-03,  1.5042e-02,  2.2005e-03,\n",
       "                       3.8303e-03, -7.5251e-03, -5.3439e-04, -1.1964e-02,  1.4300e-02,\n",
       "                       5.6032e-03, -3.6194e-03,  5.8316e-03,  1.2587e-02,  1.0643e-03,\n",
       "                       8.0725e-03,  3.8096e-03,  5.2157e-03,  9.9200e-03,  1.0016e-02,\n",
       "                      -3.7368e-03,  3.2172e-03, -1.8096e-03,  1.4063e-02, -7.9539e-04,\n",
       "                       1.2141e-02,  4.6286e-03,  3.8485e-03, -1.0175e-02, -8.1536e-03,\n",
       "                       1.7679e-02,  2.4662e-02,  2.0427e-02,  1.7683e-02,  5.7350e-03,\n",
       "                       3.6259e-03], dtype=torch.float64)),\n",
       "             ('6.12.convs.2.1.running_mean',\n",
       "              tensor([ 1.4753e-01, -3.0601e-01,  5.1817e-01,  4.1692e-01, -4.3183e-01,\n",
       "                      -2.1904e-01, -2.0195e-01, -1.0384e-01, -6.5060e-01, -4.7379e-01,\n",
       "                       3.0915e-01, -2.8250e-01,  1.3103e-02, -3.4402e-03, -4.5476e-01,\n",
       "                       1.6426e-01, -4.3117e-01,  2.3470e-01,  1.2453e-01,  3.6012e-01,\n",
       "                      -1.4442e-01,  2.0722e-01,  1.7161e-01, -1.7708e-01, -4.3544e-01,\n",
       "                       2.2440e-01,  4.2157e-01,  5.0408e-01,  6.6446e-01,  2.3939e-01,\n",
       "                      -2.4536e-01, -6.4491e-01,  1.4516e-01, -2.6177e-01, -1.2848e-01,\n",
       "                       2.8047e-01, -4.7213e-01, -9.6812e-01, -1.9556e-03, -6.3206e-02,\n",
       "                      -3.8405e-01,  4.8359e-01,  8.2157e-01,  4.5880e-01,  4.5355e-01,\n",
       "                       4.2089e-01,  1.7443e-01,  2.1376e-01,  1.6487e-01, -4.9049e-01,\n",
       "                      -4.9801e-02, -1.4256e-01, -4.4200e-01,  1.3034e+00, -1.2064e+00,\n",
       "                       3.4899e-01,  8.4597e-01,  1.8325e-02, -9.6387e-01,  7.0111e-01,\n",
       "                       1.5948e-01,  2.0721e-01, -2.2218e-01, -1.7130e-01, -6.9824e-01,\n",
       "                       5.5967e-01,  5.5855e-02, -1.8150e-01, -9.3013e-01,  4.4247e-01,\n",
       "                      -1.1931e-01,  1.4947e-01, -2.2282e-01, -3.4601e-01, -1.3687e-01,\n",
       "                       5.2105e-02, -1.7660e-01, -6.7380e-01, -3.3463e-01, -8.6035e-02,\n",
       "                      -8.7581e-01,  3.2253e-01,  6.0354e-01,  6.4281e-01, -5.8594e-01,\n",
       "                      -5.3835e-01,  5.0381e-01,  6.1174e-01, -9.1578e-02,  4.5787e-02,\n",
       "                       7.8894e-02, -9.1025e-02, -6.4429e-01, -4.3106e-01, -5.7191e-01,\n",
       "                      -8.9322e-02, -5.4603e-01, -4.1528e-01,  2.1133e-01,  5.2052e-02,\n",
       "                      -5.5254e-01, -5.7469e-01,  1.6737e-01, -2.3617e-01, -2.6254e-01,\n",
       "                      -2.5764e-01, -4.3746e-01, -2.9873e-01, -6.1210e-01,  4.8055e-01,\n",
       "                       7.1081e-02, -7.8498e-01,  6.4950e-01, -4.2057e-01,  7.0114e-01,\n",
       "                      -9.7119e-02, -4.1169e-01, -9.8688e-02, -7.0832e-01,  3.3856e-01,\n",
       "                      -3.6173e-01, -3.0683e-01, -1.9966e-01,  8.7885e-01, -2.1811e-01,\n",
       "                       5.9722e-02, -3.0662e-01, -4.1434e-01, -6.2363e-01, -1.1739e-01,\n",
       "                      -4.0327e-02,  1.1750e-03, -8.5319e-01, -2.4438e-01,  7.5235e-01,\n",
       "                      -3.8232e-01,  1.3725e-01,  6.2136e-01,  6.7773e-01,  7.9686e-01,\n",
       "                      -8.3322e-02, -1.3326e-01,  2.4364e-01, -4.5360e-01,  8.0759e-01,\n",
       "                      -1.2880e-01,  1.7840e-01,  1.4535e-01,  7.0434e-02,  3.1018e-01,\n",
       "                       3.5097e-01, -6.4020e-01, -2.7085e-01,  6.3063e-01,  1.3747e-01,\n",
       "                      -2.2307e-01,  3.2277e-01,  3.8238e-01,  4.0447e-01,  6.1100e-02,\n",
       "                      -8.0286e-01,  1.0218e-01,  1.7010e-01, -5.4063e-03,  7.2750e-01,\n",
       "                      -4.8741e-01, -7.0680e-04,  4.0081e-01,  1.7672e-02,  8.6178e-01,\n",
       "                      -3.6781e-01,  3.9942e-01, -1.1741e-01,  7.9297e-01, -5.2318e-01,\n",
       "                      -4.5091e-01,  1.5177e-01,  1.5965e-01,  6.4706e-02,  2.3996e-01,\n",
       "                       1.7680e-01, -1.5895e-01,  2.6762e-01,  4.7472e-01,  3.6022e-01,\n",
       "                      -7.2934e-01,  7.0720e-01, -6.1017e-01,  3.5189e-01, -9.7853e-03,\n",
       "                      -1.9449e-01,  8.0933e-01, -1.0425e-01,  3.6561e-01,  6.2799e-01,\n",
       "                       4.4417e-01, -1.0560e-01, -2.8244e-01,  1.2358e-01,  1.9057e-01,\n",
       "                      -3.2314e-01,  2.2405e-01,  3.5805e-01, -6.9201e-01, -1.2915e-01,\n",
       "                       3.6469e-01, -3.0913e-02,  1.6540e-01,  1.2815e-01,  9.2675e-02,\n",
       "                       6.8621e-02,  1.2617e-01, -3.3290e-01,  4.9898e-01,  3.1051e-02,\n",
       "                       3.3834e-01, -5.5665e-01,  3.8894e-01,  6.5896e-01,  2.3898e-01,\n",
       "                       1.7422e-02,  3.5232e-01, -1.4835e-01,  3.9643e-01,  5.5990e-02,\n",
       "                      -8.2668e-01, -5.3417e-01, -5.6419e-02, -4.0678e-01, -3.7904e-01,\n",
       "                      -4.4497e-01, -4.3355e-02,  4.0113e-01, -3.3066e-01, -3.6132e-01,\n",
       "                       2.4055e-01, -4.7341e-01,  2.8538e-01, -8.2936e-01,  1.6485e-01,\n",
       "                      -5.5315e-01,  1.9013e-01, -6.6564e-01,  4.4754e-01, -4.4832e-01,\n",
       "                       2.9771e-02, -3.3644e-01, -5.9301e-01,  5.8840e-02,  3.8288e-02,\n",
       "                       5.1611e-02, -2.7410e-01, -8.6876e-02,  2.9932e-01,  2.2284e-01,\n",
       "                       2.3446e-01], dtype=torch.float64)),\n",
       "             ('6.12.convs.2.1.running_var',\n",
       "              tensor([0.3350, 0.4503, 0.3777, 0.2177, 0.3207, 0.1474, 0.4416, 0.1513, 0.2863,\n",
       "                      0.2286, 0.2043, 0.3801, 0.1718, 0.2988, 0.5335, 0.5760, 0.4489, 0.3237,\n",
       "                      0.2729, 0.5978, 0.2859, 0.3018, 0.4265, 0.2910, 0.2641, 0.2614, 0.3065,\n",
       "                      0.5153, 0.4380, 0.4443, 0.2279, 0.2849, 0.1423, 0.5226, 0.4146, 0.4074,\n",
       "                      0.2059, 0.3746, 0.3234, 0.4652, 0.3472, 0.3741, 0.3484, 0.4082, 0.3783,\n",
       "                      0.5932, 0.3533, 0.2218, 0.6305, 0.3294, 0.2853, 0.2677, 0.2416, 0.5568,\n",
       "                      0.3251, 0.3260, 0.3530, 0.6326, 0.5305, 0.3249, 0.1226, 0.2612, 0.2000,\n",
       "                      0.2177, 0.4144, 0.1071, 0.1756, 0.4027, 0.3514, 0.3843, 0.4361, 0.3753,\n",
       "                      0.1187, 0.5673, 0.5123, 0.1927, 0.5193, 0.4015, 0.3666, 0.1315, 0.3815,\n",
       "                      0.3982, 0.3193, 0.4592, 0.2200, 0.3698, 0.1644, 0.3850, 0.6212, 0.1188,\n",
       "                      0.4956, 0.5812, 0.5067, 0.3136, 0.5115, 0.1096, 0.5300, 0.2123, 0.0905,\n",
       "                      0.2473, 0.4239, 0.2464, 0.4142, 0.4949, 0.2562, 0.3198, 0.3961, 0.3760,\n",
       "                      0.4912, 0.3838, 0.2860, 0.5370, 0.2939, 0.3092, 0.4675, 0.4980, 0.4219,\n",
       "                      0.5931, 0.6321, 0.3104, 0.1622, 0.2184, 0.4998, 0.4400, 0.1929, 0.4879,\n",
       "                      0.2311, 0.1799, 0.2539, 0.4469, 0.0249, 0.1327, 0.4234, 0.1463, 0.4570,\n",
       "                      0.2362, 0.3333, 0.2238, 0.3357, 0.4647, 0.2632, 0.2340, 0.4119, 0.1367,\n",
       "                      0.2742, 0.3951, 0.3601, 0.5575, 0.2958, 0.5227, 0.3917, 0.3341, 0.2593,\n",
       "                      0.7426, 0.3549, 0.2147, 0.2287, 0.2589, 0.7083, 0.0556, 0.4847, 0.1636,\n",
       "                      0.1447, 0.4965, 0.4337, 0.3081, 0.4970, 0.3441, 0.3585, 0.4207, 0.1982,\n",
       "                      0.1102, 0.2390, 0.4796, 0.3769, 0.4840, 0.2099, 0.2077, 0.3524, 0.1851,\n",
       "                      0.2189, 0.3197, 0.3173, 0.3261, 0.1426, 0.3154, 0.2969, 0.2029, 0.6535,\n",
       "                      0.3368, 0.1074, 0.3799, 0.2907, 0.4698, 0.4837, 0.2754, 0.5035, 0.3669,\n",
       "                      0.4373, 0.4542, 0.2091, 0.6810, 0.3802, 0.3311, 0.3434, 0.3487, 0.1582,\n",
       "                      0.0636, 0.0855, 0.5924, 0.0801, 0.3918, 0.3443, 0.4168, 0.3292, 0.1314,\n",
       "                      0.6064, 0.3128, 0.3684, 0.5052, 0.3849, 0.4695, 0.0811, 0.3297, 0.4834,\n",
       "                      0.3965, 0.2263, 0.2799, 0.3948, 0.5244, 0.2479, 0.1348, 0.4891, 0.1633,\n",
       "                      0.2855, 0.6305, 0.3246, 0.2866, 0.6562, 0.3896, 0.3554, 0.3373, 0.3958,\n",
       "                      0.3256, 0.2976, 0.3648, 0.4963, 0.3051, 0.2849, 0.3910, 0.3885, 0.5122,\n",
       "                      0.2935, 0.1862, 0.2973, 0.2718], dtype=torch.float64)),\n",
       "             ('6.12.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.12.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0688],\n",
       "                       [ 0.0173],\n",
       "                       [-0.0150],\n",
       "                       ...,\n",
       "                       [-0.1434],\n",
       "                       [ 0.0732],\n",
       "                       [ 0.0834]],\n",
       "              \n",
       "                      [[ 0.0636],\n",
       "                       [-0.0964],\n",
       "                       [ 0.0191],\n",
       "                       ...,\n",
       "                       [-0.0721],\n",
       "                       [-0.0149],\n",
       "                       [-0.0249]],\n",
       "              \n",
       "                      [[-0.0309],\n",
       "                       [ 0.0231],\n",
       "                       [ 0.0058],\n",
       "                       ...,\n",
       "                       [-0.0728],\n",
       "                       [-0.0469],\n",
       "                       [-0.0746]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1119],\n",
       "                       [-0.0471],\n",
       "                       [-0.1694],\n",
       "                       ...,\n",
       "                       [-0.0081],\n",
       "                       [-0.0041],\n",
       "                       [-0.0197]],\n",
       "              \n",
       "                      [[ 0.1178],\n",
       "                       [-0.0608],\n",
       "                       [ 0.0560],\n",
       "                       ...,\n",
       "                       [ 0.0591],\n",
       "                       [ 0.0249],\n",
       "                       [-0.0473]],\n",
       "              \n",
       "                      [[ 0.1067],\n",
       "                       [-0.2160],\n",
       "                       [-0.1499],\n",
       "                       ...,\n",
       "                       [-0.0632],\n",
       "                       [-0.0009],\n",
       "                       [ 0.0064]]], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.0.1.weight',\n",
       "              tensor([0.9793, 0.9858, 0.9421, 0.9929, 1.0062, 0.9816, 0.9431, 0.9761, 0.9678,\n",
       "                      0.9580, 1.0027, 0.9745, 0.9507, 0.9718, 0.9744, 0.9663, 0.9650, 0.9668,\n",
       "                      0.9697, 0.9661, 0.9674, 0.9912, 0.9772, 0.9834, 0.9990, 0.9591, 0.9882,\n",
       "                      0.9731, 0.9708, 0.9896, 0.9724, 0.9704, 0.9711, 0.9619, 0.9749, 0.9770,\n",
       "                      0.9645, 0.9659, 0.9779, 0.9818, 0.9747, 0.9940, 0.9899, 0.9682, 0.9827,\n",
       "                      0.9679, 0.9909, 0.9788, 0.9202, 0.9779, 0.9724, 1.0002, 0.9703, 0.9655,\n",
       "                      0.9570, 0.9803, 0.9931, 0.9642, 0.9822, 0.9646, 0.9927, 0.9654, 0.9393,\n",
       "                      0.9669], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0152,  0.0176, -0.0203,  0.0302,  0.0211,  0.0153, -0.0056, -0.0247,\n",
       "                       0.0118,  0.0003,  0.0345,  0.0169, -0.0162,  0.0091, -0.0164,  0.0181,\n",
       "                       0.0071, -0.0068,  0.0080,  0.0084, -0.0123,  0.0230, -0.0059, -0.0082,\n",
       "                       0.0090, -0.0118,  0.0114,  0.0118,  0.0090,  0.0077,  0.0141,  0.0111,\n",
       "                      -0.0120,  0.0012, -0.0092,  0.0153, -0.0187, -0.0139,  0.0082, -0.0021,\n",
       "                       0.0135,  0.0060, -0.0336, -0.0128,  0.0088,  0.0054,  0.0216,  0.0037,\n",
       "                      -0.0144,  0.0064,  0.0139,  0.0036, -0.0087, -0.0077, -0.0213,  0.0095,\n",
       "                       0.0204, -0.0097, -0.0041, -0.0139,  0.0306,  0.0203, -0.0260,  0.0081],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.5332, -0.6010,  0.4165, -1.0350,  0.4159,  0.2513, -0.0903, -0.1744,\n",
       "                      -0.2938, -0.0091, -0.0532, -0.0422,  0.8737, -1.1439,  1.3057,  0.1041,\n",
       "                       0.7279, -0.9889, -0.0745,  0.0590, -0.0455, -1.0139,  0.6245, -0.4647,\n",
       "                      -0.3633, -1.1606,  0.1107, -0.1427, -0.2794, -0.7135, -0.8088, -0.5740,\n",
       "                      -0.0075, -0.5612, -0.0704, -0.4165, -0.3024,  0.0695, -0.2785,  0.0186,\n",
       "                      -0.0033,  0.5229,  0.3831,  0.4827,  0.3439, -0.0287, -0.4526,  0.0159,\n",
       "                      -0.6273,  0.0887,  0.8727, -0.3394, -0.4260,  0.3998, -1.1015, -0.3104,\n",
       "                       0.1875, -0.3478, -0.3079,  0.0184, -0.3081, -0.6360,  0.8429,  0.1165],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.0.1.running_var',\n",
       "              tensor([0.2153, 0.2243, 0.4917, 0.1777, 0.1228, 0.3646, 1.0509, 0.2096, 0.2503,\n",
       "                      0.1367, 0.3334, 0.2203, 0.6143, 0.4596, 0.2833, 0.2081, 0.5929, 0.1848,\n",
       "                      0.4142, 0.1655, 0.3030, 0.1831, 0.1373, 0.2344, 0.0993, 0.2555, 0.1468,\n",
       "                      0.3382, 0.1737, 0.1317, 0.5765, 0.3156, 0.2321, 0.2572, 0.2599, 0.1347,\n",
       "                      0.2165, 0.1822, 0.1422, 0.1964, 0.1127, 0.2739, 0.1030, 0.5523, 0.2264,\n",
       "                      0.4282, 0.1569, 0.3010, 1.2961, 0.1360, 0.8328, 0.1380, 0.6535, 0.4705,\n",
       "                      0.2673, 0.1179, 0.2291, 0.1956, 0.1638, 0.1472, 0.2305, 0.1769, 1.4008,\n",
       "                      0.1850], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.12.convpath.0.1.0.weight',\n",
       "              tensor([[[-9.7982e-02, -1.2761e-02, -6.6099e-02,  1.1663e-01, -1.4064e-02],\n",
       "                       [-1.0251e-01, -9.8539e-02,  6.1466e-02, -6.2549e-02, -2.1574e-02],\n",
       "                       [ 5.7186e-02,  5.7956e-02, -1.0764e-01,  1.3726e-01,  3.5745e-02],\n",
       "                       ...,\n",
       "                       [-3.5507e-02, -9.2969e-02, -8.2163e-02,  1.8373e-01, -9.4310e-03],\n",
       "                       [-6.0465e-02, -1.8567e-02, -3.0952e-02,  1.6370e-01,  3.6034e-02],\n",
       "                       [ 3.0720e-02,  2.2004e-02,  3.6270e-03, -1.3350e-01,  1.2168e-01]],\n",
       "              \n",
       "                      [[ 1.3370e-02,  4.3619e-03,  7.7166e-02, -8.6199e-02, -9.9938e-02],\n",
       "                       [-1.4915e-02, -2.9636e-02, -1.7970e-01, -8.7397e-02, -2.9516e-02],\n",
       "                       [-9.9077e-02, -1.4389e-01,  1.3561e-01, -3.4435e-02, -4.0424e-02],\n",
       "                       ...,\n",
       "                       [ 5.3762e-02, -2.9169e-02,  8.3221e-02,  3.9154e-02,  7.6082e-02],\n",
       "                       [ 3.1914e-02,  1.0319e-01, -5.5373e-02, -6.3963e-02, -1.2396e-03],\n",
       "                       [-4.0058e-02, -4.1074e-02, -7.4671e-02,  4.1508e-02, -5.5732e-02]],\n",
       "              \n",
       "                      [[-7.8395e-02, -3.6643e-02,  2.1610e-02,  1.0661e-01, -4.0530e-02],\n",
       "                       [-2.0141e-02, -4.3800e-04,  5.9087e-02,  1.5981e-02,  6.0337e-02],\n",
       "                       [ 3.3762e-02, -2.0943e-02, -6.4002e-02,  1.2842e-02, -4.2015e-02],\n",
       "                       ...,\n",
       "                       [ 1.1113e-01, -4.2215e-02,  5.2007e-02,  1.4984e-02, -9.5229e-02],\n",
       "                       [-1.5339e-01,  1.8578e-02,  1.1406e-01,  2.6761e-02,  2.8678e-02],\n",
       "                       [-8.0011e-02, -5.3326e-02,  4.0838e-03,  2.2574e-02,  2.3392e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-6.9709e-03,  7.2196e-02, -1.6725e-02,  9.0950e-02,  1.3865e-01],\n",
       "                       [ 1.5826e-01,  8.4815e-03,  1.3853e-01, -7.0594e-03,  5.1524e-03],\n",
       "                       [-5.7565e-02, -3.9104e-02,  8.2913e-02, -2.1487e-02,  5.7015e-02],\n",
       "                       ...,\n",
       "                       [ 1.7257e-01,  5.1367e-02, -1.3975e-01,  1.0109e-01, -3.2802e-02],\n",
       "                       [-7.4708e-02, -5.9357e-02,  6.4704e-02, -2.3270e-02, -4.4137e-03],\n",
       "                       [-1.2323e-02,  5.4410e-02,  3.8502e-02, -2.7522e-02,  8.8798e-02]],\n",
       "              \n",
       "                      [[ 7.8709e-02,  3.9630e-02, -7.9865e-03,  5.0950e-02,  1.2268e-01],\n",
       "                       [-2.9876e-02,  6.3758e-04,  7.0092e-02, -8.2118e-02, -9.1391e-02],\n",
       "                       [ 7.6682e-02, -1.8632e-02,  4.7409e-02,  9.4682e-02,  9.3635e-02],\n",
       "                       ...,\n",
       "                       [ 8.5360e-02, -5.9873e-02,  1.0453e-01, -2.7172e-02, -3.1872e-03],\n",
       "                       [-7.2148e-03,  1.0446e-02,  5.0150e-02, -2.7209e-02,  1.9987e-03],\n",
       "                       [-1.0219e-01, -6.8400e-02,  2.4034e-02, -1.2183e-03,  7.0378e-03]],\n",
       "              \n",
       "                      [[ 7.5180e-03,  7.1001e-02, -1.2814e-01,  2.0146e-02, -6.5666e-02],\n",
       "                       [-1.1598e-01,  1.3663e-01,  1.8703e-01, -7.9319e-02, -2.5803e-02],\n",
       "                       [ 2.4860e-02,  2.9315e-03,  8.8203e-02, -8.3283e-03, -4.9884e-02],\n",
       "                       ...,\n",
       "                       [-5.8444e-05, -1.6208e-02, -4.2016e-02, -2.3293e-04, -5.8134e-02],\n",
       "                       [-3.1801e-02,  7.1128e-02,  4.9274e-02, -6.8835e-03,  6.1572e-02],\n",
       "                       [ 3.1043e-02, -3.2092e-02, -1.2546e-01,  6.0253e-03,  1.1994e-01]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.1.1.weight',\n",
       "              tensor([0.9727, 0.9840, 0.9796, 0.9941, 0.9532, 0.9603, 0.9452, 0.9722, 0.9417,\n",
       "                      0.9682, 0.9613, 0.9770, 0.9584, 0.9599, 0.9627, 0.9902, 1.0144, 0.9612,\n",
       "                      0.9503, 0.9543, 0.9639, 0.9526, 0.9711, 0.9664, 0.9383, 0.9562, 0.9569,\n",
       "                      0.9619, 0.9755, 0.9605, 0.9621, 1.0033, 0.9588, 0.9698, 0.9776, 0.9520,\n",
       "                      0.9810, 0.9803, 0.9994, 0.9801, 0.9548, 0.9874, 0.9612, 0.9967, 0.9625,\n",
       "                      0.9882, 0.9556, 0.9615, 0.9689, 0.9437, 1.0050, 0.9610, 0.9465, 0.9830,\n",
       "                      0.9372, 0.9765, 0.9470, 0.9552, 0.9649, 0.9725, 0.9534, 0.9733, 0.9731,\n",
       "                      0.9774], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.1.1.bias',\n",
       "              tensor([-0.0153,  0.0058,  0.0003, -0.0060,  0.0036, -0.0165, -0.0073,  0.0012,\n",
       "                      -0.0087, -0.0165, -0.0252,  0.0165, -0.0342,  0.0058,  0.0005, -0.0091,\n",
       "                       0.0293, -0.0177, -0.0143, -0.0212, -0.0146, -0.0334,  0.0051, -0.0251,\n",
       "                      -0.0109, -0.0313, -0.0217, -0.0116, -0.0025, -0.0087, -0.0085,  0.0123,\n",
       "                      -0.0101,  0.0026, -0.0030,  0.0107,  0.0129, -0.0006, -0.0061, -0.0005,\n",
       "                      -0.0163,  0.0128, -0.0111,  0.0302,  0.0068,  0.0010, -0.0077, -0.0036,\n",
       "                      -0.0173, -0.0139, -0.0076, -0.0533, -0.0227,  0.0029, -0.0203, -0.0022,\n",
       "                      -0.0113, -0.0313, -0.0190,  0.0043, -0.0230, -0.0135,  0.0009,  0.0093],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.1.1.running_mean',\n",
       "              tensor([ 1.2463,  0.2691,  0.2006,  0.6099, -0.7010,  0.2026, -0.2258, -0.0429,\n",
       "                      -0.0074,  0.5334, -0.4643, -0.2287,  0.0568, -0.5103, -0.3855,  0.0943,\n",
       "                      -0.5141,  0.0113, -0.5586, -0.1022,  0.2446,  0.2875, -0.5562,  0.6388,\n",
       "                       0.1918,  0.2068,  0.2429, -0.6888, -0.0700,  0.5268,  0.2255,  0.4996,\n",
       "                      -0.3366, -1.1653, -0.0834, -0.5605,  0.3329, -0.0566,  0.1109,  0.3425,\n",
       "                      -0.1902, -0.0698, -0.2286, -0.8737, -0.0582, -0.0644, -1.3233,  0.0579,\n",
       "                       0.5339,  0.2005,  0.1695,  0.4966,  0.4083, -0.6585, -0.4888,  0.0511,\n",
       "                      -0.1164,  0.6424,  0.5446, -0.3016, -0.2471,  0.7757,  0.4093, -0.6232],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.1.1.running_var',\n",
       "              tensor([0.7758, 0.5843, 0.5248, 0.4503, 0.6307, 0.4795, 0.3695, 0.4656, 0.4163,\n",
       "                      0.6106, 0.7637, 0.4951, 0.4428, 1.0930, 0.5325, 0.5584, 0.5000, 0.5542,\n",
       "                      0.4828, 0.6982, 0.6061, 0.5412, 0.6219, 0.4847, 0.7456, 0.5069, 0.4489,\n",
       "                      0.4655, 0.4122, 0.4522, 0.6073, 0.4349, 0.6295, 0.4845, 1.1838, 0.6203,\n",
       "                      0.5063, 0.4700, 0.4704, 0.3182, 0.5585, 0.4173, 0.4882, 0.8518, 0.3987,\n",
       "                      0.6489, 0.5742, 0.4507, 0.7601, 0.4160, 0.5150, 0.7346, 0.6092, 0.6886,\n",
       "                      1.1726, 0.4357, 0.6276, 0.7141, 0.6504, 0.4412, 0.5721, 0.4725, 0.6901,\n",
       "                      0.3921], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.12.convpath.0.2.0.weight',\n",
       "              tensor([[[ 4.2645e-02],\n",
       "                       [-4.4919e-02],\n",
       "                       [ 9.1611e-02],\n",
       "                       ...,\n",
       "                       [ 1.8184e-01],\n",
       "                       [ 4.4987e-02],\n",
       "                       [-7.1846e-02]],\n",
       "              \n",
       "                      [[-5.2676e-02],\n",
       "                       [-3.0656e-02],\n",
       "                       [-9.9997e-02],\n",
       "                       ...,\n",
       "                       [-2.5832e-03],\n",
       "                       [ 2.9083e-01],\n",
       "                       [-9.7800e-02]],\n",
       "              \n",
       "                      [[ 5.0634e-02],\n",
       "                       [ 4.2759e-02],\n",
       "                       [ 1.7114e-01],\n",
       "                       ...,\n",
       "                       [-2.1405e-04],\n",
       "                       [ 1.3658e-01],\n",
       "                       [ 8.1322e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.6691e-01],\n",
       "                       [ 2.2944e-01],\n",
       "                       [ 9.7645e-04],\n",
       "                       ...,\n",
       "                       [ 6.8186e-02],\n",
       "                       [-1.1157e-01],\n",
       "                       [ 5.7341e-02]],\n",
       "              \n",
       "                      [[ 3.2393e-02],\n",
       "                       [-6.8236e-02],\n",
       "                       [ 1.1008e-01],\n",
       "                       ...,\n",
       "                       [ 3.1608e-02],\n",
       "                       [-1.3980e-01],\n",
       "                       [ 8.9334e-02]],\n",
       "              \n",
       "                      [[-2.2162e-02],\n",
       "                       [-1.0166e-02],\n",
       "                       [ 2.3773e-01],\n",
       "                       ...,\n",
       "                       [-4.0543e-02],\n",
       "                       [-1.6363e-01],\n",
       "                       [ 1.0111e-01]]], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.2.1.weight',\n",
       "              tensor([ 4.3333e-03, -3.2985e-02,  3.9914e-03, -2.6680e-04,  1.3390e-02,\n",
       "                       5.7171e-03,  2.5363e-02,  1.4338e-02, -2.0090e-02, -2.2176e-03,\n",
       "                       9.1880e-03, -3.7147e-02,  1.0612e-02, -1.9335e-03, -5.7457e-03,\n",
       "                       1.7238e-02,  2.5920e-02,  7.0679e-03,  1.3227e-02,  2.9495e-02,\n",
       "                      -7.9638e-03,  1.7731e-02,  4.5621e-03,  1.3678e-02,  5.9185e-03,\n",
       "                       1.7896e-02,  9.2414e-03,  1.3525e-02,  1.6675e-02, -2.6282e-02,\n",
       "                       3.5259e-05,  1.6538e-02, -1.3696e-02,  1.9330e-02,  2.7159e-02,\n",
       "                       2.2065e-02,  1.1225e-02,  1.0586e-02, -2.6503e-02, -4.3072e-02,\n",
       "                       2.3337e-03, -3.3425e-02, -3.1829e-02,  2.3749e-03, -7.8579e-03,\n",
       "                      -1.0979e-02,  5.4345e-03,  6.3433e-03, -5.2358e-02,  1.4357e-02,\n",
       "                       1.2711e-02,  1.3936e-03,  1.0062e-02, -1.7712e-02, -8.6028e-03,\n",
       "                      -2.2248e-02, -7.1339e-03, -7.2612e-03,  2.3742e-03,  1.2199e-02,\n",
       "                       4.7175e-03, -9.7278e-03,  7.1659e-03,  1.6170e-03,  6.4444e-03,\n",
       "                       1.0993e-02,  7.1212e-03, -2.1645e-02,  2.4415e-03,  1.7752e-02,\n",
       "                       4.2838e-03,  1.2279e-02,  7.4552e-03, -2.1457e-02,  7.0103e-03,\n",
       "                       1.2902e-02,  2.3184e-02,  9.0124e-03, -1.0797e-03,  1.6717e-02,\n",
       "                       7.3032e-03, -1.2958e-02,  8.5208e-03, -1.1383e-02, -5.2576e-03,\n",
       "                       5.8323e-03, -3.4887e-03,  3.4044e-02, -1.6613e-02, -2.3611e-03,\n",
       "                      -1.4635e-02, -2.7882e-02, -1.0064e-02,  1.1715e-02,  1.7560e-02,\n",
       "                       2.7311e-03, -2.3777e-02, -2.2234e-02, -5.5099e-03,  1.1357e-02,\n",
       "                       2.5698e-02, -3.9072e-03,  2.1077e-02, -3.5788e-02, -1.9684e-02,\n",
       "                       1.4666e-02, -8.2681e-03,  2.3861e-02,  2.6581e-02, -1.3678e-02,\n",
       "                      -1.5686e-02, -1.1667e-02,  3.5243e-03,  1.1915e-02,  3.7788e-02,\n",
       "                       1.4163e-02,  9.0875e-03,  1.8285e-02,  1.9371e-02, -1.9560e-02,\n",
       "                       2.2672e-02,  5.7491e-03, -2.3855e-02,  1.8731e-02, -6.7731e-04,\n",
       "                      -3.1417e-02,  1.0569e-02, -2.8762e-03,  9.5676e-03,  1.5725e-02,\n",
       "                       5.6691e-03, -1.2855e-03,  1.9320e-02,  1.3017e-02, -2.3978e-02,\n",
       "                       2.2088e-02, -3.0879e-02,  1.8831e-02,  2.7621e-03,  1.7204e-02,\n",
       "                       7.7387e-03, -2.0760e-03,  2.5390e-02,  7.3766e-03,  1.0156e-02,\n",
       "                      -1.2003e-02,  1.5718e-02,  3.8513e-03, -1.8115e-02, -2.7875e-02,\n",
       "                      -7.2305e-03, -2.0790e-02,  7.2825e-03, -2.8709e-02, -3.7876e-02,\n",
       "                      -6.8566e-03,  9.1621e-03,  1.5685e-02, -1.7024e-02, -1.2376e-03,\n",
       "                      -2.0125e-02, -8.5298e-03, -2.8956e-03,  2.0038e-02, -1.8752e-02,\n",
       "                      -1.1455e-02,  6.8390e-03,  5.1941e-03, -8.6517e-03,  1.8406e-02,\n",
       "                      -1.0333e-02,  5.1810e-03,  1.0007e-02,  2.0577e-02, -2.2655e-02,\n",
       "                       3.7010e-03, -5.8759e-03,  8.3018e-03, -8.6059e-03,  1.1485e-02,\n",
       "                      -5.3462e-04,  1.8886e-02,  1.2490e-03,  7.4949e-03, -2.2191e-03,\n",
       "                       6.7708e-03, -1.6585e-02,  1.2357e-02, -1.1070e-02, -1.4082e-02,\n",
       "                       7.6563e-04, -9.5342e-03, -4.0074e-02, -4.3340e-02, -2.0792e-02,\n",
       "                      -1.1328e-02,  3.4753e-02,  5.3701e-03, -2.5156e-02, -1.3349e-02,\n",
       "                      -5.8134e-03, -3.2724e-02, -2.4255e-02,  1.5011e-02,  1.6584e-02,\n",
       "                       1.1896e-02,  3.8396e-03,  1.0835e-02,  3.9661e-03, -1.9407e-02,\n",
       "                      -7.8115e-03, -3.0624e-02,  4.0959e-02,  2.6369e-02, -1.7248e-02,\n",
       "                      -2.3680e-04, -1.4952e-02,  1.7921e-02, -2.8126e-02, -3.4492e-02,\n",
       "                       1.4971e-02, -2.0886e-02, -5.4711e-03,  1.1128e-02, -2.2040e-02,\n",
       "                      -8.8091e-03,  3.3865e-03, -3.1624e-03, -2.1064e-02, -2.5997e-02,\n",
       "                      -6.1313e-03,  5.7078e-03,  2.3235e-02,  3.4079e-03, -8.3955e-03,\n",
       "                      -1.7391e-02,  9.7061e-04,  2.1430e-02, -1.3030e-02, -3.8849e-02,\n",
       "                      -2.2701e-03,  2.1835e-02,  1.6006e-02,  5.3944e-03,  2.2795e-02,\n",
       "                       8.8596e-03, -9.8455e-03, -1.0179e-02, -2.1849e-02,  2.8151e-02,\n",
       "                       2.9802e-02,  1.9166e-02, -2.7278e-02, -5.1191e-03, -8.8329e-03,\n",
       "                       6.1739e-03], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.2.1.bias',\n",
       "              tensor([-2.5600e-04,  1.7020e-02,  1.0045e-02,  1.4077e-02,  2.1968e-03,\n",
       "                       7.5821e-03,  7.3552e-03, -6.8334e-04,  7.3275e-03,  1.4333e-02,\n",
       "                       1.5833e-02, -5.8730e-03,  8.1243e-03, -4.2887e-03,  9.5703e-03,\n",
       "                       2.4902e-04,  2.4685e-02, -9.6970e-04,  9.9541e-03, -3.2593e-03,\n",
       "                      -3.8560e-03,  4.8604e-04,  4.7689e-03,  6.7267e-03,  5.6186e-03,\n",
       "                      -1.6607e-02,  5.4133e-03,  6.2940e-03,  2.9117e-03, -1.7983e-03,\n",
       "                       1.7642e-03,  6.9711e-03, -1.2844e-03,  2.0768e-02,  5.8349e-03,\n",
       "                       1.6876e-02, -4.8159e-03,  1.8574e-02,  6.5640e-03,  1.2572e-02,\n",
       "                       7.8595e-04,  1.9110e-02, -9.6012e-03, -1.6159e-03,  7.9766e-03,\n",
       "                      -1.2446e-02,  1.4124e-02, -9.4082e-04, -1.2313e-02,  7.6576e-03,\n",
       "                       8.6440e-03,  4.1945e-03,  8.4791e-03,  1.3316e-02,  2.9959e-03,\n",
       "                       1.8845e-02,  9.5597e-03,  1.3199e-03,  1.2198e-02, -2.2303e-03,\n",
       "                       1.1571e-03,  1.5151e-03,  9.3999e-03,  9.4843e-03, -4.6687e-03,\n",
       "                       3.7606e-03, -1.0555e-02,  1.6097e-02, -5.9984e-04, -1.4805e-02,\n",
       "                       7.0054e-03,  3.3655e-03,  4.3141e-05, -7.8689e-03,  1.3777e-02,\n",
       "                       8.5932e-03,  2.4855e-03,  1.0963e-03,  3.4996e-03,  1.4961e-02,\n",
       "                       5.9398e-03, -6.7026e-03,  1.0933e-02,  5.1164e-03, -2.6523e-03,\n",
       "                       1.6488e-02,  1.1068e-03,  1.0784e-02,  1.5853e-02,  2.2014e-03,\n",
       "                       1.2374e-03,  9.3275e-03,  1.0455e-02,  9.5208e-04,  9.8636e-03,\n",
       "                      -1.4447e-02,  1.0779e-02,  6.5399e-03,  2.0659e-02,  3.8402e-03,\n",
       "                       1.8976e-02,  1.5091e-02,  5.1299e-03,  7.7587e-03, -2.0852e-03,\n",
       "                      -7.5260e-04, -4.1723e-03,  8.7620e-03,  9.1412e-03,  4.5257e-03,\n",
       "                      -1.3500e-02, -8.3322e-03,  5.3216e-03,  2.0198e-02,  1.4477e-02,\n",
       "                       5.0377e-03,  1.1875e-02,  3.9472e-03,  6.6442e-03, -1.4596e-02,\n",
       "                       3.3788e-04,  9.5697e-03, -8.3387e-04, -2.2317e-03,  2.4434e-04,\n",
       "                       1.1601e-02,  9.2506e-03,  5.2181e-03,  5.9043e-03,  1.3239e-02,\n",
       "                       7.2757e-03,  7.3823e-03,  1.3766e-02,  4.6326e-03,  1.6891e-02,\n",
       "                      -1.0387e-02,  8.0736e-03,  3.3363e-03,  6.1905e-03,  9.3296e-04,\n",
       "                       1.2954e-02, -8.0869e-03,  1.7141e-02,  3.9806e-03, -7.8536e-03,\n",
       "                       1.5639e-02,  4.1875e-03,  2.0371e-03,  1.2778e-02,  8.8516e-03,\n",
       "                       1.4130e-02,  1.6991e-02,  5.4017e-03,  1.2235e-02,  1.3049e-02,\n",
       "                       5.2551e-03, -1.4156e-03,  3.4166e-03, -3.7861e-04, -1.1388e-02,\n",
       "                       4.2257e-03, -4.9475e-03, -2.5110e-03,  1.0504e-02,  1.3990e-02,\n",
       "                      -2.6560e-03, -1.2329e-02,  1.0394e-02,  7.3265e-03,  2.1756e-02,\n",
       "                       1.8259e-03,  1.0314e-03,  5.3184e-03,  1.4547e-02, -1.3551e-02,\n",
       "                       1.0348e-02,  1.5567e-03,  1.5888e-02,  8.0573e-04,  4.9805e-03,\n",
       "                      -6.0100e-03,  1.3268e-02, -5.1664e-03, -8.5644e-03,  1.1752e-02,\n",
       "                       7.6632e-03,  1.5471e-02,  1.0756e-02,  4.7474e-03,  6.8514e-03,\n",
       "                       5.8507e-03,  3.1228e-03,  9.7273e-03,  1.4821e-04,  1.7491e-03,\n",
       "                       7.2844e-03,  1.6729e-02,  3.4953e-03,  7.5682e-03,  1.4828e-02,\n",
       "                      -9.7120e-04,  2.5077e-02,  1.7338e-02,  1.9577e-02,  1.4727e-02,\n",
       "                      -1.4192e-03,  7.4099e-03, -9.1286e-03,  6.5704e-03,  1.2738e-02,\n",
       "                       8.5957e-03,  1.0890e-02,  1.2723e-02,  1.5806e-03,  1.0670e-02,\n",
       "                       1.1850e-03,  5.3435e-03,  2.1925e-02,  5.9399e-03,  2.2693e-03,\n",
       "                      -5.3717e-03,  9.6136e-04,  2.1991e-03,  1.5042e-02,  2.2005e-03,\n",
       "                       3.8303e-03, -7.5251e-03, -5.3439e-04, -1.1964e-02,  1.4300e-02,\n",
       "                       5.6032e-03, -3.6194e-03,  5.8316e-03,  1.2587e-02,  1.0643e-03,\n",
       "                       8.0725e-03,  3.8096e-03,  5.2157e-03,  9.9200e-03,  1.0016e-02,\n",
       "                      -3.7368e-03,  3.2172e-03, -1.8096e-03,  1.4063e-02, -7.9539e-04,\n",
       "                       1.2141e-02,  4.6286e-03,  3.8485e-03, -1.0175e-02, -8.1536e-03,\n",
       "                       1.7679e-02,  2.4662e-02,  2.0427e-02,  1.7683e-02,  5.7350e-03,\n",
       "                       3.6259e-03], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.2.1.running_mean',\n",
       "              tensor([ 1.4753e-01, -3.0601e-01,  5.1817e-01,  4.1692e-01, -4.3183e-01,\n",
       "                      -2.1904e-01, -2.0195e-01, -1.0384e-01, -6.5060e-01, -4.7379e-01,\n",
       "                       3.0915e-01, -2.8250e-01,  1.3103e-02, -3.4402e-03, -4.5476e-01,\n",
       "                       1.6426e-01, -4.3117e-01,  2.3470e-01,  1.2453e-01,  3.6012e-01,\n",
       "                      -1.4442e-01,  2.0722e-01,  1.7161e-01, -1.7708e-01, -4.3544e-01,\n",
       "                       2.2440e-01,  4.2157e-01,  5.0408e-01,  6.6446e-01,  2.3939e-01,\n",
       "                      -2.4536e-01, -6.4491e-01,  1.4516e-01, -2.6177e-01, -1.2848e-01,\n",
       "                       2.8047e-01, -4.7213e-01, -9.6812e-01, -1.9556e-03, -6.3206e-02,\n",
       "                      -3.8405e-01,  4.8359e-01,  8.2157e-01,  4.5880e-01,  4.5355e-01,\n",
       "                       4.2089e-01,  1.7443e-01,  2.1376e-01,  1.6487e-01, -4.9049e-01,\n",
       "                      -4.9801e-02, -1.4256e-01, -4.4200e-01,  1.3034e+00, -1.2064e+00,\n",
       "                       3.4899e-01,  8.4597e-01,  1.8325e-02, -9.6387e-01,  7.0111e-01,\n",
       "                       1.5948e-01,  2.0721e-01, -2.2218e-01, -1.7130e-01, -6.9824e-01,\n",
       "                       5.5967e-01,  5.5855e-02, -1.8150e-01, -9.3013e-01,  4.4247e-01,\n",
       "                      -1.1931e-01,  1.4947e-01, -2.2282e-01, -3.4601e-01, -1.3687e-01,\n",
       "                       5.2105e-02, -1.7660e-01, -6.7380e-01, -3.3463e-01, -8.6035e-02,\n",
       "                      -8.7581e-01,  3.2253e-01,  6.0354e-01,  6.4281e-01, -5.8594e-01,\n",
       "                      -5.3835e-01,  5.0381e-01,  6.1174e-01, -9.1578e-02,  4.5787e-02,\n",
       "                       7.8894e-02, -9.1025e-02, -6.4429e-01, -4.3106e-01, -5.7191e-01,\n",
       "                      -8.9322e-02, -5.4603e-01, -4.1528e-01,  2.1133e-01,  5.2052e-02,\n",
       "                      -5.5254e-01, -5.7469e-01,  1.6737e-01, -2.3617e-01, -2.6254e-01,\n",
       "                      -2.5764e-01, -4.3746e-01, -2.9873e-01, -6.1210e-01,  4.8055e-01,\n",
       "                       7.1081e-02, -7.8498e-01,  6.4950e-01, -4.2057e-01,  7.0114e-01,\n",
       "                      -9.7119e-02, -4.1169e-01, -9.8688e-02, -7.0832e-01,  3.3856e-01,\n",
       "                      -3.6173e-01, -3.0683e-01, -1.9966e-01,  8.7885e-01, -2.1811e-01,\n",
       "                       5.9722e-02, -3.0662e-01, -4.1434e-01, -6.2363e-01, -1.1739e-01,\n",
       "                      -4.0327e-02,  1.1750e-03, -8.5319e-01, -2.4438e-01,  7.5235e-01,\n",
       "                      -3.8232e-01,  1.3725e-01,  6.2136e-01,  6.7773e-01,  7.9686e-01,\n",
       "                      -8.3322e-02, -1.3326e-01,  2.4364e-01, -4.5360e-01,  8.0759e-01,\n",
       "                      -1.2880e-01,  1.7840e-01,  1.4535e-01,  7.0434e-02,  3.1018e-01,\n",
       "                       3.5097e-01, -6.4020e-01, -2.7085e-01,  6.3063e-01,  1.3747e-01,\n",
       "                      -2.2307e-01,  3.2277e-01,  3.8238e-01,  4.0447e-01,  6.1100e-02,\n",
       "                      -8.0286e-01,  1.0218e-01,  1.7010e-01, -5.4063e-03,  7.2750e-01,\n",
       "                      -4.8741e-01, -7.0680e-04,  4.0081e-01,  1.7672e-02,  8.6178e-01,\n",
       "                      -3.6781e-01,  3.9942e-01, -1.1741e-01,  7.9297e-01, -5.2318e-01,\n",
       "                      -4.5091e-01,  1.5177e-01,  1.5965e-01,  6.4706e-02,  2.3996e-01,\n",
       "                       1.7680e-01, -1.5895e-01,  2.6762e-01,  4.7472e-01,  3.6022e-01,\n",
       "                      -7.2934e-01,  7.0720e-01, -6.1017e-01,  3.5189e-01, -9.7853e-03,\n",
       "                      -1.9449e-01,  8.0933e-01, -1.0425e-01,  3.6561e-01,  6.2799e-01,\n",
       "                       4.4417e-01, -1.0560e-01, -2.8244e-01,  1.2358e-01,  1.9057e-01,\n",
       "                      -3.2314e-01,  2.2405e-01,  3.5805e-01, -6.9201e-01, -1.2915e-01,\n",
       "                       3.6469e-01, -3.0913e-02,  1.6540e-01,  1.2815e-01,  9.2675e-02,\n",
       "                       6.8621e-02,  1.2617e-01, -3.3290e-01,  4.9898e-01,  3.1051e-02,\n",
       "                       3.3834e-01, -5.5665e-01,  3.8894e-01,  6.5896e-01,  2.3898e-01,\n",
       "                       1.7422e-02,  3.5232e-01, -1.4835e-01,  3.9643e-01,  5.5990e-02,\n",
       "                      -8.2668e-01, -5.3417e-01, -5.6419e-02, -4.0678e-01, -3.7904e-01,\n",
       "                      -4.4497e-01, -4.3355e-02,  4.0113e-01, -3.3066e-01, -3.6132e-01,\n",
       "                       2.4055e-01, -4.7341e-01,  2.8538e-01, -8.2936e-01,  1.6485e-01,\n",
       "                      -5.5315e-01,  1.9013e-01, -6.6564e-01,  4.4754e-01, -4.4832e-01,\n",
       "                       2.9771e-02, -3.3644e-01, -5.9301e-01,  5.8840e-02,  3.8288e-02,\n",
       "                       5.1611e-02, -2.7410e-01, -8.6876e-02,  2.9932e-01,  2.2284e-01,\n",
       "                       2.3446e-01], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.2.1.running_var',\n",
       "              tensor([0.3350, 0.4503, 0.3777, 0.2177, 0.3207, 0.1474, 0.4416, 0.1513, 0.2863,\n",
       "                      0.2286, 0.2043, 0.3801, 0.1718, 0.2988, 0.5335, 0.5760, 0.4489, 0.3237,\n",
       "                      0.2729, 0.5978, 0.2859, 0.3018, 0.4265, 0.2910, 0.2641, 0.2614, 0.3065,\n",
       "                      0.5153, 0.4380, 0.4443, 0.2279, 0.2849, 0.1423, 0.5226, 0.4146, 0.4074,\n",
       "                      0.2059, 0.3746, 0.3234, 0.4652, 0.3472, 0.3741, 0.3484, 0.4082, 0.3783,\n",
       "                      0.5932, 0.3533, 0.2218, 0.6305, 0.3294, 0.2853, 0.2677, 0.2416, 0.5568,\n",
       "                      0.3251, 0.3260, 0.3530, 0.6326, 0.5305, 0.3249, 0.1226, 0.2612, 0.2000,\n",
       "                      0.2177, 0.4144, 0.1071, 0.1756, 0.4027, 0.3514, 0.3843, 0.4361, 0.3753,\n",
       "                      0.1187, 0.5673, 0.5123, 0.1927, 0.5193, 0.4015, 0.3666, 0.1315, 0.3815,\n",
       "                      0.3982, 0.3193, 0.4592, 0.2200, 0.3698, 0.1644, 0.3850, 0.6212, 0.1188,\n",
       "                      0.4956, 0.5812, 0.5067, 0.3136, 0.5115, 0.1096, 0.5300, 0.2123, 0.0905,\n",
       "                      0.2473, 0.4239, 0.2464, 0.4142, 0.4949, 0.2562, 0.3198, 0.3961, 0.3760,\n",
       "                      0.4912, 0.3838, 0.2860, 0.5370, 0.2939, 0.3092, 0.4675, 0.4980, 0.4219,\n",
       "                      0.5931, 0.6321, 0.3104, 0.1622, 0.2184, 0.4998, 0.4400, 0.1929, 0.4879,\n",
       "                      0.2311, 0.1799, 0.2539, 0.4469, 0.0249, 0.1327, 0.4234, 0.1463, 0.4570,\n",
       "                      0.2362, 0.3333, 0.2238, 0.3357, 0.4647, 0.2632, 0.2340, 0.4119, 0.1367,\n",
       "                      0.2742, 0.3951, 0.3601, 0.5575, 0.2958, 0.5227, 0.3917, 0.3341, 0.2593,\n",
       "                      0.7426, 0.3549, 0.2147, 0.2287, 0.2589, 0.7083, 0.0556, 0.4847, 0.1636,\n",
       "                      0.1447, 0.4965, 0.4337, 0.3081, 0.4970, 0.3441, 0.3585, 0.4207, 0.1982,\n",
       "                      0.1102, 0.2390, 0.4796, 0.3769, 0.4840, 0.2099, 0.2077, 0.3524, 0.1851,\n",
       "                      0.2189, 0.3197, 0.3173, 0.3261, 0.1426, 0.3154, 0.2969, 0.2029, 0.6535,\n",
       "                      0.3368, 0.1074, 0.3799, 0.2907, 0.4698, 0.4837, 0.2754, 0.5035, 0.3669,\n",
       "                      0.4373, 0.4542, 0.2091, 0.6810, 0.3802, 0.3311, 0.3434, 0.3487, 0.1582,\n",
       "                      0.0636, 0.0855, 0.5924, 0.0801, 0.3918, 0.3443, 0.4168, 0.3292, 0.1314,\n",
       "                      0.6064, 0.3128, 0.3684, 0.5052, 0.3849, 0.4695, 0.0811, 0.3297, 0.4834,\n",
       "                      0.3965, 0.2263, 0.2799, 0.3948, 0.5244, 0.2479, 0.1348, 0.4891, 0.1633,\n",
       "                      0.2855, 0.6305, 0.3246, 0.2866, 0.6562, 0.3896, 0.3554, 0.3373, 0.3958,\n",
       "                      0.3256, 0.2976, 0.3648, 0.4963, 0.3051, 0.2849, 0.3910, 0.3885, 0.5122,\n",
       "                      0.2935, 0.1862, 0.2973, 0.2718], dtype=torch.float64)),\n",
       "             ('6.12.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.13.convs.0.0.weight',\n",
       "              tensor([[[-0.0171],\n",
       "                       [ 0.0466],\n",
       "                       [ 0.0559],\n",
       "                       ...,\n",
       "                       [-0.0358],\n",
       "                       [-0.0417],\n",
       "                       [-0.0885]],\n",
       "              \n",
       "                      [[-0.0490],\n",
       "                       [-0.0320],\n",
       "                       [-0.0085],\n",
       "                       ...,\n",
       "                       [-0.0381],\n",
       "                       [-0.0539],\n",
       "                       [ 0.0024]],\n",
       "              \n",
       "                      [[ 0.0459],\n",
       "                       [ 0.0733],\n",
       "                       [-0.0337],\n",
       "                       ...,\n",
       "                       [ 0.0959],\n",
       "                       [ 0.0054],\n",
       "                       [-0.0658]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0207],\n",
       "                       [ 0.0258],\n",
       "                       [ 0.0256],\n",
       "                       ...,\n",
       "                       [-0.0267],\n",
       "                       [ 0.1061],\n",
       "                       [ 0.0363]],\n",
       "              \n",
       "                      [[ 0.0286],\n",
       "                       [-0.1582],\n",
       "                       [ 0.0615],\n",
       "                       ...,\n",
       "                       [ 0.1192],\n",
       "                       [ 0.0957],\n",
       "                       [ 0.1393]],\n",
       "              \n",
       "                      [[-0.0808],\n",
       "                       [-0.0834],\n",
       "                       [ 0.0938],\n",
       "                       ...,\n",
       "                       [ 0.1318],\n",
       "                       [-0.0147],\n",
       "                       [-0.0764]]], dtype=torch.float64)),\n",
       "             ('6.13.convs.0.1.weight',\n",
       "              tensor([0.9778, 0.9821, 0.9600, 0.9657, 0.9603, 0.9639, 0.9758, 0.9548, 0.9760,\n",
       "                      0.9659, 0.9573, 0.9684, 0.9999, 0.9296, 0.9633, 0.9526, 0.9379, 0.9738,\n",
       "                      0.9416, 0.9574, 0.9881, 0.9777, 0.9599, 0.9635, 0.9565, 0.9750, 0.9682,\n",
       "                      0.9410, 0.9330, 0.9437, 0.9698, 0.9792, 0.9644, 0.9665, 0.9439, 1.0003,\n",
       "                      0.9691, 0.9729, 0.9612, 0.9771, 0.9661, 0.9811, 0.9842, 0.9632, 0.9750,\n",
       "                      0.9571, 0.9783, 0.9752, 0.9870, 0.9574, 0.9505, 0.9511, 0.9727, 0.9432,\n",
       "                      0.9730, 0.9982, 0.9549, 0.9979, 1.0022, 0.9893, 0.9596, 0.9346, 0.9622,\n",
       "                      0.9766], dtype=torch.float64)),\n",
       "             ('6.13.convs.0.1.bias',\n",
       "              tensor([ 0.0017,  0.0037, -0.0169, -0.0129, -0.0200,  0.0030,  0.0041, -0.0009,\n",
       "                       0.0016,  0.0157,  0.0027, -0.0061,  0.0372,  0.0020,  0.0021,  0.0108,\n",
       "                      -0.0081,  0.0119, -0.0060,  0.0144,  0.0098, -0.0071,  0.0046,  0.0078,\n",
       "                      -0.0094,  0.0070, -0.0050,  0.0135, -0.0263,  0.0029,  0.0089,  0.0019,\n",
       "                      -0.0067, -0.0186,  0.0013,  0.0226,  0.0009,  0.0122, -0.0149,  0.0019,\n",
       "                       0.0058, -0.0046,  0.0151, -0.0163,  0.0019, -0.0048,  0.0099,  0.0123,\n",
       "                       0.0095, -0.0013, -0.0208, -0.0251, -0.0023, -0.0028,  0.0127,  0.0119,\n",
       "                       0.0157,  0.0219,  0.0140, -0.0046, -0.0129,  0.0052, -0.0041,  0.0150],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convs.0.1.running_mean',\n",
       "              tensor([-0.5705,  0.1955,  1.6724,  0.8388,  1.2055, -0.0280, -0.4704,  0.6609,\n",
       "                      -0.2674, -0.5305, -0.1330,  0.4741, -0.4546, -0.9844, -0.3226, -0.0108,\n",
       "                      -1.2653,  0.5629, -0.6295, -0.3457, -0.1934,  1.4640, -1.0251,  1.1369,\n",
       "                       0.5671,  0.1600,  0.2716, -0.5820, -0.3679, -0.2190, -0.5219, -0.7149,\n",
       "                       0.1950, -0.0680, -0.2078, -0.2351,  1.7980, -0.1021,  1.3794,  0.0544,\n",
       "                       0.3415,  0.3088,  0.4475,  0.6645,  0.0172, -0.6267, -0.1309,  0.3605,\n",
       "                       0.1949,  0.5779,  0.6670,  0.8631,  0.5621,  1.3369, -0.2124, -0.8789,\n",
       "                      -1.3022,  0.4782, -0.7564, -0.8544,  1.3024, -1.1875,  0.4247, -0.0363],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convs.0.1.running_var',\n",
       "              tensor([0.0818, 0.1604, 1.6647, 0.5731, 0.6027, 0.1323, 0.2977, 0.4069, 0.1752,\n",
       "                      0.2945, 0.3839, 0.1466, 0.1137, 1.0702, 0.2503, 0.5533, 0.1713, 0.3160,\n",
       "                      0.5696, 0.2020, 0.2139, 0.3312, 0.1362, 1.3043, 0.2385, 0.3023, 0.1823,\n",
       "                      0.7287, 0.3828, 0.0757, 0.1310, 0.2247, 0.3231, 0.0993, 0.4513, 0.0856,\n",
       "                      0.3543, 0.1920, 0.5381, 0.1433, 0.2449, 0.1507, 0.1008, 0.1254, 0.7459,\n",
       "                      0.4307, 0.1503, 0.1286, 0.1770, 0.4843, 0.7279, 0.5958, 0.6142, 0.0990,\n",
       "                      0.1254, 0.1339, 0.7094, 0.1357, 0.2193, 0.1044, 1.1201, 0.8450, 0.4090,\n",
       "                      0.1854], dtype=torch.float64)),\n",
       "             ('6.13.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.13.convs.1.0.weight',\n",
       "              tensor([[[-1.4548e-01, -6.0081e-02, -2.7059e-02, -5.8420e-02,  2.5364e-02],\n",
       "                       [ 2.4933e-02, -4.2873e-02, -2.8073e-02, -6.9013e-02, -2.7364e-02],\n",
       "                       [-2.0948e-02,  6.9798e-03,  5.8242e-02, -1.1626e-01,  1.7592e-02],\n",
       "                       ...,\n",
       "                       [ 5.0084e-02, -5.4315e-02, -3.6414e-02, -1.2853e-02, -3.6543e-02],\n",
       "                       [ 5.2874e-02,  4.9857e-02,  6.9492e-02, -9.5053e-02, -2.7161e-02],\n",
       "                       [-1.1644e-01,  7.5752e-02,  3.1112e-02, -2.8855e-02, -3.9235e-02]],\n",
       "              \n",
       "                      [[-1.5654e-01,  7.3430e-03, -2.7421e-02,  7.1822e-02, -4.6880e-02],\n",
       "                       [-8.4769e-02, -2.9939e-02,  7.7032e-03,  3.3473e-02,  1.1162e-01],\n",
       "                       [-3.8761e-02, -9.5768e-02,  1.2726e-02, -6.8003e-02,  6.0147e-02],\n",
       "                       ...,\n",
       "                       [-8.0171e-02, -1.6173e-01, -6.2211e-02, -1.6270e-01,  7.1253e-02],\n",
       "                       [-2.1825e-02,  4.6477e-02, -2.1266e-02, -5.8885e-02, -9.6070e-03],\n",
       "                       [-8.2920e-03,  4.0409e-02,  4.4635e-02,  4.7182e-02, -1.3776e-01]],\n",
       "              \n",
       "                      [[-5.0762e-02,  3.9749e-02,  5.7687e-02, -7.9778e-02, -3.2109e-02],\n",
       "                       [-8.0852e-02, -7.0447e-02,  5.1158e-02, -4.8903e-03,  6.0413e-02],\n",
       "                       [ 1.6301e-02, -1.1975e-01, -2.5601e-02, -3.5559e-02,  3.0498e-04],\n",
       "                       ...,\n",
       "                       [ 1.2384e-01,  2.9540e-02, -4.9960e-02, -8.3949e-02, -9.0407e-02],\n",
       "                       [-8.0676e-02, -1.7478e-01,  4.2582e-02, -1.2974e-01, -5.7886e-02],\n",
       "                       [-1.0883e-01,  6.2665e-04,  7.7072e-02,  1.6236e-02,  6.3000e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 6.4901e-02, -7.1595e-03,  9.8509e-02, -3.6420e-03, -5.6746e-02],\n",
       "                       [ 1.3131e-01, -4.7154e-02, -9.7348e-02,  4.0171e-02, -1.2041e-01],\n",
       "                       [ 5.6126e-02, -3.8203e-02,  1.3718e-01,  3.8906e-02,  7.1897e-02],\n",
       "                       ...,\n",
       "                       [ 1.7149e-02,  7.3543e-03,  3.8296e-02, -7.9906e-02,  1.7509e-02],\n",
       "                       [ 1.1866e-01, -1.4766e-01, -1.2177e-03, -1.7202e-01, -1.1195e-01],\n",
       "                       [-8.4962e-02, -1.2995e-02,  9.3062e-03, -1.6297e-01, -3.8770e-02]],\n",
       "              \n",
       "                      [[-7.1619e-02, -2.0431e-02,  8.3252e-02, -6.2487e-02,  1.8180e-01],\n",
       "                       [-7.8980e-02, -7.6899e-03,  4.5549e-02, -2.9508e-02,  8.4784e-02],\n",
       "                       [-1.5468e-01, -1.3886e-01,  1.3574e-02,  5.2715e-02,  2.7708e-05],\n",
       "                       ...,\n",
       "                       [-1.3815e-01, -4.8067e-03, -1.5901e-02, -8.3183e-02,  6.4381e-04],\n",
       "                       [ 3.1024e-02, -8.5193e-02, -1.8651e-01,  2.4245e-02, -2.1807e-01],\n",
       "                       [-3.1928e-03, -1.5661e-01,  6.4474e-02,  1.0194e-01, -6.7360e-02]],\n",
       "              \n",
       "                      [[-1.6357e-01, -4.4661e-02, -6.1795e-02, -2.6217e-03,  3.1399e-02],\n",
       "                       [-9.2542e-02,  9.8082e-02, -6.0010e-02, -8.8338e-04,  9.7368e-02],\n",
       "                       [ 8.3721e-02, -4.6371e-02, -2.2987e-02,  1.2923e-01,  4.2175e-02],\n",
       "                       ...,\n",
       "                       [-9.6165e-02, -7.7653e-03,  4.7100e-02,  5.1517e-02,  8.0729e-02],\n",
       "                       [-6.2907e-02, -7.5381e-02, -3.0818e-02, -1.3653e-01, -1.0445e-01],\n",
       "                       [ 4.0789e-02, -3.4180e-02,  1.0727e-01,  8.4954e-03, -5.6275e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convs.1.1.weight',\n",
       "              tensor([1.0010, 0.9663, 0.9698, 0.9487, 0.9567, 0.9623, 0.9531, 0.9555, 1.0001,\n",
       "                      0.9614, 0.9682, 0.9626, 0.9687, 0.9748, 0.9658, 0.9486, 0.9752, 0.9647,\n",
       "                      0.9664, 0.9792, 0.9473, 0.9789, 0.9607, 0.9629, 0.9802, 0.9722, 0.9204,\n",
       "                      0.9789, 0.9597, 0.9574, 0.9555, 0.9855, 0.9867, 0.9601, 0.9418, 0.9706,\n",
       "                      0.9722, 0.9618, 0.9627, 0.9632, 0.9581, 0.9444, 0.9952, 0.9689, 0.9705,\n",
       "                      0.9611, 0.9497, 0.9741, 0.9600, 0.9498, 0.9465, 0.9610, 0.9757, 0.9530,\n",
       "                      0.9395, 0.9721, 0.9714, 0.9642, 0.9593, 0.9576, 0.9628, 0.9479, 0.9767,\n",
       "                      0.9489], dtype=torch.float64)),\n",
       "             ('6.13.convs.1.1.bias',\n",
       "              tensor([ 2.2191e-02, -1.9797e-02, -5.4914e-04,  6.8388e-03, -1.9183e-02,\n",
       "                       6.5534e-03,  3.3478e-04,  1.4414e-03,  3.4087e-02, -7.5099e-03,\n",
       "                       1.4579e-02, -1.7031e-02, -3.5580e-03,  1.1472e-02,  1.6541e-02,\n",
       "                      -1.4898e-03,  4.9320e-04,  4.0031e-07, -4.0037e-03, -2.7737e-03,\n",
       "                      -5.5625e-04,  1.0401e-03, -9.9758e-03, -4.4800e-03,  1.1606e-03,\n",
       "                      -1.2184e-02, -1.1498e-02, -4.0597e-03, -1.0666e-02,  3.0479e-03,\n",
       "                       1.6056e-02,  1.1323e-02,  1.9979e-02,  9.4837e-03, -1.3558e-02,\n",
       "                       1.0922e-02, -4.2005e-03,  8.2197e-03, -4.7835e-03, -1.7147e-02,\n",
       "                      -1.3034e-02,  1.3582e-02,  9.4440e-03,  4.0566e-03, -1.8755e-03,\n",
       "                      -4.8153e-03,  2.9140e-03,  1.2538e-02, -1.2239e-02,  4.8748e-04,\n",
       "                      -8.2226e-03,  7.3608e-04, -6.7241e-03, -2.4716e-02, -1.5144e-02,\n",
       "                      -2.8047e-03, -8.1725e-03,  2.3615e-02, -1.1297e-02, -7.4358e-03,\n",
       "                      -7.1439e-03, -3.8513e-03,  1.4019e-04, -1.6053e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convs.1.1.running_mean',\n",
       "              tensor([-4.3767e-01, -3.5169e-01, -4.8482e-01, -7.9885e-01,  2.0882e-01,\n",
       "                      -4.9010e-01,  5.3561e-01, -3.3310e-02, -7.4366e-01,  2.5952e-01,\n",
       "                      -2.7686e-01,  2.8710e-01,  3.3390e-01, -6.2427e-01,  9.5532e-02,\n",
       "                       5.8640e-02,  7.5632e-03, -7.6850e-01, -5.2135e-01, -1.9176e-04,\n",
       "                      -9.2832e-01, -7.3453e-02,  8.8578e-01,  5.2217e-01, -5.3165e-01,\n",
       "                       2.7525e-01, -7.3558e-01,  3.2225e-01,  3.1069e-01, -3.3549e-01,\n",
       "                       2.9882e-02,  2.6587e-01, -7.0607e-01, -1.2120e-01, -1.0605e-01,\n",
       "                      -1.8391e-01, -2.1154e-01, -8.2011e-01, -3.0112e-02,  3.0164e-01,\n",
       "                       1.3161e-01, -9.5813e-01, -3.3909e-02, -6.9102e-01,  4.5450e-01,\n",
       "                      -3.1132e-01,  2.5933e-01, -2.2675e-01, -1.7857e-02,  6.1876e-02,\n",
       "                      -7.1365e-01, -5.5025e-01, -4.6579e-01,  1.0815e-01, -4.2908e-01,\n",
       "                       2.9207e-01,  3.3943e-01, -8.4226e-01,  3.5619e-02,  1.6953e-02,\n",
       "                       2.0708e-01, -8.7690e-01,  9.4395e-02,  1.0529e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convs.1.1.running_var',\n",
       "              tensor([0.5844, 0.9954, 0.5082, 0.9178, 0.6175, 0.6581, 0.4834, 1.1521, 0.5605,\n",
       "                      0.5491, 0.5730, 0.5612, 0.7454, 0.7830, 0.6046, 0.5962, 0.6327, 0.6858,\n",
       "                      0.6639, 0.3449, 0.6112, 0.4824, 0.7322, 0.6266, 0.7572, 0.3791, 0.6467,\n",
       "                      0.4990, 0.8153, 1.2824, 0.5141, 0.5516, 0.6154, 0.5150, 0.6305, 0.7988,\n",
       "                      0.5225, 0.7691, 0.4227, 0.5030, 0.3966, 0.9883, 0.5631, 0.9327, 0.6956,\n",
       "                      0.5729, 0.5655, 0.7164, 0.8374, 0.5203, 0.8330, 0.5797, 0.4854, 0.9130,\n",
       "                      0.6093, 0.5595, 0.7818, 0.7221, 0.5959, 0.9039, 0.5992, 0.6503, 0.4518,\n",
       "                      1.0118], dtype=torch.float64)),\n",
       "             ('6.13.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.13.convs.2.0.weight',\n",
       "              tensor([[[ 0.0519],\n",
       "                       [-0.0516],\n",
       "                       [-0.1350],\n",
       "                       ...,\n",
       "                       [-0.0462],\n",
       "                       [-0.1625],\n",
       "                       [ 0.0618]],\n",
       "              \n",
       "                      [[ 0.0452],\n",
       "                       [ 0.1068],\n",
       "                       [-0.2067],\n",
       "                       ...,\n",
       "                       [ 0.0367],\n",
       "                       [-0.0881],\n",
       "                       [-0.0796]],\n",
       "              \n",
       "                      [[-0.0415],\n",
       "                       [-0.1307],\n",
       "                       [ 0.0260],\n",
       "                       ...,\n",
       "                       [-0.0423],\n",
       "                       [ 0.0027],\n",
       "                       [ 0.0026]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0579],\n",
       "                       [ 0.0510],\n",
       "                       [-0.0494],\n",
       "                       ...,\n",
       "                       [ 0.0419],\n",
       "                       [-0.0481],\n",
       "                       [ 0.1872]],\n",
       "              \n",
       "                      [[ 0.1596],\n",
       "                       [ 0.0068],\n",
       "                       [ 0.0626],\n",
       "                       ...,\n",
       "                       [-0.0255],\n",
       "                       [-0.0219],\n",
       "                       [ 0.0025]],\n",
       "              \n",
       "                      [[ 0.0219],\n",
       "                       [ 0.2924],\n",
       "                       [-0.2022],\n",
       "                       ...,\n",
       "                       [-0.0019],\n",
       "                       [-0.2145],\n",
       "                       [-0.0057]]], dtype=torch.float64)),\n",
       "             ('6.13.convs.2.1.weight',\n",
       "              tensor([ 9.0264e-04, -1.8442e-03,  7.8081e-03, -2.7761e-03, -2.3762e-03,\n",
       "                      -8.1073e-03, -9.2309e-03,  2.8186e-02,  3.0679e-05,  9.4049e-03,\n",
       "                      -3.0244e-02, -2.4950e-02, -1.3176e-02, -1.0886e-02,  1.5435e-02,\n",
       "                       2.3951e-02, -1.7138e-02, -1.2674e-03, -1.2846e-02, -4.8328e-04,\n",
       "                      -2.0524e-02,  1.9178e-02, -1.6388e-03,  1.7316e-03, -3.2421e-02,\n",
       "                       8.7399e-03, -3.2143e-02, -3.4827e-03, -2.7582e-02,  1.6249e-02,\n",
       "                      -2.0744e-02, -2.0761e-02, -2.8662e-03, -8.5422e-03, -5.9387e-03,\n",
       "                       1.6644e-02, -9.6083e-03,  1.5628e-02,  3.1499e-05, -3.2163e-03,\n",
       "                      -5.6035e-03,  1.2028e-02,  1.2773e-02, -1.2157e-02, -1.5288e-03,\n",
       "                      -3.0308e-03, -3.1764e-02, -1.2567e-02,  5.2686e-03,  5.2975e-03,\n",
       "                      -1.6833e-02,  3.8504e-03,  3.8320e-03,  1.9051e-03,  1.4378e-02,\n",
       "                       5.9967e-02,  2.4584e-02, -2.5146e-03, -1.7227e-03,  5.1612e-03,\n",
       "                      -8.1995e-03, -4.4886e-03, -3.2472e-02,  1.5959e-02, -3.2776e-02,\n",
       "                      -1.1816e-02, -6.9172e-03,  1.5806e-02,  2.2582e-02,  1.6673e-02,\n",
       "                       4.1314e-03,  4.6527e-03, -4.7516e-03,  9.5212e-03,  2.8346e-02,\n",
       "                       5.4278e-03,  4.9834e-03, -1.4716e-02,  2.2329e-02, -9.3704e-03,\n",
       "                       7.0517e-03,  1.0359e-02, -1.0477e-02, -3.1556e-03,  9.0022e-03,\n",
       "                       6.4094e-03, -7.8552e-03,  2.1836e-02,  4.8672e-05,  7.7626e-03,\n",
       "                      -2.5395e-03,  7.4278e-03,  1.3625e-02, -1.7499e-02,  2.1558e-02,\n",
       "                      -1.3903e-02, -7.9741e-03, -1.7599e-02, -7.7283e-04,  1.6247e-02,\n",
       "                       1.6919e-02, -1.2140e-02,  1.5336e-03, -1.3440e-02, -7.5494e-03,\n",
       "                      -2.3736e-02,  1.9984e-02,  8.0849e-03, -2.5506e-02,  2.3528e-03,\n",
       "                       2.7488e-03, -6.5428e-03,  2.6358e-02, -2.2948e-02,  1.0978e-02,\n",
       "                       1.5734e-02, -2.4465e-02,  1.1182e-02, -3.5343e-02, -1.3823e-02,\n",
       "                       1.2170e-02,  1.1022e-02, -3.0964e-03,  2.3041e-03,  2.1905e-02,\n",
       "                      -3.2901e-02,  1.0712e-02, -1.5463e-02,  1.3127e-02, -2.6933e-03,\n",
       "                      -2.0616e-03, -1.6855e-02,  1.6730e-02,  1.6052e-02, -8.3106e-03,\n",
       "                       1.1990e-02,  2.8264e-03,  5.3277e-03, -1.7021e-02, -8.6031e-03,\n",
       "                       2.9925e-02,  2.5197e-02,  1.8990e-02,  1.5761e-02,  1.0350e-02,\n",
       "                       1.3884e-02, -1.0856e-02,  1.0129e-02, -1.4048e-02, -9.6497e-03,\n",
       "                      -1.1583e-02, -3.8121e-03, -1.8518e-02,  2.0526e-02,  5.1410e-04,\n",
       "                       1.4138e-02, -2.2857e-02,  2.1986e-03,  1.1884e-02,  1.4280e-02,\n",
       "                      -2.9263e-03,  7.9252e-03,  2.9437e-02, -1.5536e-03, -2.7173e-02,\n",
       "                       1.6297e-02, -3.9052e-02, -1.6970e-02,  9.1741e-03, -3.7511e-02,\n",
       "                       1.2486e-04,  5.7046e-03, -6.8798e-04, -6.2910e-03, -5.5737e-03,\n",
       "                      -5.6677e-03,  1.9926e-02,  3.1230e-02,  2.1947e-03,  2.4191e-02,\n",
       "                       9.4773e-03, -4.3795e-03, -8.4010e-03, -1.6261e-02,  1.1966e-02,\n",
       "                       7.0355e-03,  1.3800e-03, -5.4656e-03,  1.7027e-02, -4.1955e-04,\n",
       "                      -2.9646e-03,  2.9417e-02, -8.1331e-03,  1.9180e-02, -3.2995e-02,\n",
       "                      -3.5414e-03,  1.7536e-02,  4.7590e-03,  6.3905e-04,  2.0163e-02,\n",
       "                      -3.0102e-04, -2.3761e-02,  1.1434e-03, -3.2357e-02, -1.8739e-02,\n",
       "                      -1.3880e-02,  2.3332e-03,  9.9259e-03,  1.8760e-02, -1.9919e-02,\n",
       "                       2.1322e-02, -6.3412e-04, -4.3835e-02, -1.5551e-02,  1.5436e-02,\n",
       "                       9.7790e-03, -1.4621e-03, -6.9060e-04, -2.4824e-02, -9.8609e-03,\n",
       "                      -1.8598e-02,  1.6646e-02,  1.0271e-02,  9.2319e-03,  9.4591e-03,\n",
       "                      -2.9256e-03,  1.5250e-02, -9.6402e-03,  1.7530e-02,  2.1543e-02,\n",
       "                       4.0701e-03, -5.1803e-03, -1.5343e-04, -2.2187e-02,  3.4696e-03,\n",
       "                       1.0980e-02,  6.4323e-03, -7.4039e-03,  7.9961e-03,  1.4056e-02,\n",
       "                       1.5447e-03,  4.7254e-03,  1.4236e-03,  9.7185e-04, -9.4150e-04,\n",
       "                       4.7475e-04, -7.1570e-03,  2.3596e-02, -4.5919e-03, -4.2937e-02,\n",
       "                       3.7873e-02, -3.0164e-02,  2.3760e-03, -7.3786e-03,  5.2193e-04,\n",
       "                       3.3035e-02], dtype=torch.float64)),\n",
       "             ('6.13.convs.2.1.bias',\n",
       "              tensor([ 8.1188e-06,  9.3859e-03,  9.2961e-03,  1.4093e-02,  3.5178e-03,\n",
       "                       9.6883e-03,  7.1956e-03, -7.1808e-04,  1.4511e-02,  1.5965e-02,\n",
       "                       1.5775e-02, -6.2965e-03,  5.5444e-03, -5.1574e-03,  8.0633e-03,\n",
       "                       2.3873e-03,  2.4227e-02, -1.1772e-03,  9.9406e-03, -3.3031e-03,\n",
       "                      -4.7985e-03,  5.2502e-04,  5.1964e-03,  6.5902e-03,  5.0445e-03,\n",
       "                      -1.7085e-02,  3.8389e-03,  7.7876e-03,  1.4593e-02, -7.1374e-03,\n",
       "                       9.1926e-04,  7.3146e-03, -3.2220e-03,  2.0801e-02,  3.6378e-03,\n",
       "                       1.5466e-02, -2.5558e-03,  1.7172e-02,  1.1054e-02,  1.1730e-02,\n",
       "                       2.0702e-03,  1.7164e-02, -1.2344e-02, -1.8373e-03,  6.9630e-03,\n",
       "                      -1.2725e-02,  1.4439e-02,  6.2896e-03, -1.2343e-02,  1.8317e-03,\n",
       "                       8.3281e-03,  4.1248e-03,  7.4451e-03,  1.7264e-02,  3.7784e-03,\n",
       "                       1.9088e-02,  8.8985e-03,  1.3304e-03,  1.2174e-02, -2.9547e-03,\n",
       "                      -7.5268e-04,  5.1524e-04,  9.4787e-03,  8.5604e-03, -5.8265e-03,\n",
       "                       2.8080e-03, -1.0708e-02,  1.4742e-02, -2.0457e-03, -1.4956e-02,\n",
       "                       7.2167e-03,  3.1540e-03, -7.0523e-04, -8.0911e-03,  1.3436e-02,\n",
       "                       6.0556e-03,  2.2118e-04, -1.1355e-03,  2.8094e-03,  1.4773e-02,\n",
       "                       5.2919e-03, -8.2789e-03,  1.0413e-02,  4.1866e-03, -3.4977e-03,\n",
       "                       1.6590e-02, -2.9025e-04,  1.3983e-02,  1.4462e-02,  3.9924e-04,\n",
       "                       2.7518e-04,  1.0580e-02,  1.0004e-02,  2.8441e-03,  1.1647e-02,\n",
       "                      -8.7508e-03,  1.2464e-02, -1.5488e-03,  2.0702e-02,  6.4013e-03,\n",
       "                       1.8810e-02,  1.5998e-02,  3.6197e-03,  1.1261e-02, -5.3379e-04,\n",
       "                       5.4579e-04, -6.2880e-03,  1.1352e-02,  8.2945e-03,  2.7038e-03,\n",
       "                      -1.3244e-02, -9.2793e-03,  4.5037e-03,  1.9861e-02,  1.4106e-02,\n",
       "                       5.9143e-03,  9.8287e-03,  2.6533e-03,  6.5537e-03, -1.3839e-02,\n",
       "                      -1.7607e-04,  9.6864e-03,  1.1683e-03, -4.9378e-04,  1.1176e-02,\n",
       "                       9.9491e-03,  6.9958e-03,  5.2945e-03,  4.9082e-03,  1.2865e-02,\n",
       "                       6.7311e-03,  5.8107e-03,  1.3728e-02,  5.4030e-03,  8.8502e-03,\n",
       "                      -1.2701e-02,  1.4475e-02,  3.7615e-03,  6.0663e-03, -2.8962e-03,\n",
       "                       1.3033e-02, -1.2167e-02,  1.6747e-02,  2.1833e-03, -4.9723e-03,\n",
       "                       1.6532e-02,  5.4126e-03, -8.0455e-04,  1.2399e-02,  8.4627e-03,\n",
       "                       1.1890e-02,  1.4772e-02,  6.2747e-03,  1.2290e-02,  1.0989e-02,\n",
       "                       4.7254e-03, -1.6241e-03,  6.4660e-03,  8.0668e-04, -1.2979e-02,\n",
       "                       2.4385e-03,  4.7222e-04, -2.2378e-03,  7.5218e-03,  1.2945e-02,\n",
       "                      -3.2596e-03, -1.3042e-02,  9.7880e-03,  7.3170e-03,  2.1177e-02,\n",
       "                       1.6999e-03,  1.4970e-03,  5.4934e-03,  1.4688e-02, -1.3014e-02,\n",
       "                       1.0316e-02,  1.0022e-03,  1.5179e-02,  1.3242e-03,  5.8099e-03,\n",
       "                      -5.9191e-03,  1.1417e-02, -7.0672e-03, -8.8494e-03,  1.2337e-02,\n",
       "                       8.0209e-03,  1.4096e-02,  9.3819e-03,  6.4982e-03,  8.1123e-03,\n",
       "                       5.9088e-03,  4.9292e-03,  6.0037e-03,  1.1428e-03,  1.6777e-03,\n",
       "                       9.8802e-03,  1.1496e-02,  2.6247e-03,  5.1550e-03,  1.4937e-02,\n",
       "                      -7.0068e-04,  2.2734e-02,  1.8110e-02,  2.0024e-02,  1.8069e-02,\n",
       "                      -1.7547e-03,  9.1308e-03, -1.1559e-02,  6.6428e-03,  1.2718e-02,\n",
       "                       9.3185e-03,  1.0902e-02,  1.1870e-02,  6.6168e-03,  8.5487e-03,\n",
       "                       1.9172e-03,  4.8528e-03,  1.6108e-02,  4.3948e-03,  4.4651e-03,\n",
       "                       8.3401e-03, -3.7677e-04,  2.5471e-03,  1.5156e-02,  7.8935e-04,\n",
       "                       7.2086e-03, -6.9722e-03, -1.5534e-03,  2.0729e-02,  1.6517e-02,\n",
       "                       3.2275e-03, -4.2153e-03,  4.9803e-03,  1.2740e-02, -3.3138e-04,\n",
       "                       7.5377e-03,  2.5846e-03,  6.6910e-03,  7.0040e-03,  7.5547e-03,\n",
       "                      -3.4200e-03, -2.2858e-04, -2.1586e-03,  1.2933e-02,  1.1062e-03,\n",
       "                       9.3007e-03,  3.5708e-03,  3.5857e-03, -1.2534e-02, -1.0333e-02,\n",
       "                       2.0282e-02,  2.4897e-02,  1.8509e-02,  1.7617e-02,  2.8039e-03,\n",
       "                       4.0916e-03], dtype=torch.float64)),\n",
       "             ('6.13.convs.2.1.running_mean',\n",
       "              tensor([-7.5019e-02,  3.4987e-01,  5.9603e-02,  8.1202e-02, -1.1371e-01,\n",
       "                      -7.7833e-01,  9.6499e-03, -2.9537e-01,  1.8077e-01, -3.9717e-01,\n",
       "                      -3.3094e-01, -7.1698e-01,  2.3992e-01,  5.0273e-01, -5.2787e-01,\n",
       "                      -6.5982e-01,  9.3607e-01, -8.7359e-02,  9.0010e-01,  9.3877e-02,\n",
       "                      -1.6932e-01,  9.0360e-02, -9.9249e-02, -6.9108e-03,  8.3004e-01,\n",
       "                       6.0121e-02, -1.3261e+00, -1.8313e-02, -4.5757e-02,  6.3813e-01,\n",
       "                       4.9511e-01,  8.0187e-03,  8.1358e-02,  4.8489e-01, -1.3992e-01,\n",
       "                      -1.6722e-01,  7.6294e-02, -7.6344e-01, -7.3700e-02, -1.1355e-01,\n",
       "                      -1.2237e-01, -1.0308e-01,  5.9181e-02, -2.6961e-01,  2.2003e-01,\n",
       "                       2.6055e-01, -3.6410e-01, -2.1450e-01,  2.2604e-01, -8.8875e-01,\n",
       "                       5.7539e-02, -5.1677e-01, -2.5665e-01, -1.2461e-01,  4.6009e-01,\n",
       "                       3.9679e-01,  6.3269e-03,  5.4402e-01, -2.0966e-01,  1.3705e-01,\n",
       "                       3.2988e-01,  1.1380e-01,  1.1383e-01, -1.4972e-01,  8.5433e-01,\n",
       "                      -1.4535e-01,  7.6311e-01,  4.3342e-01, -1.4459e-01, -3.4254e-01,\n",
       "                       3.7322e-01,  1.1451e-01,  1.8938e-02, -3.2956e-01,  5.5660e-01,\n",
       "                       3.1419e-01,  5.7530e-01,  2.8784e-01,  2.6796e-01, -2.4315e-01,\n",
       "                       1.6871e-01,  5.2095e-01, -6.4603e-02,  1.7638e-01, -2.3244e-02,\n",
       "                      -1.4593e-01, -2.1309e-01,  4.0366e-02,  2.4277e-01,  2.6452e-02,\n",
       "                       5.0399e-01,  3.4196e-01, -2.4411e-01, -2.0873e-01, -5.7462e-01,\n",
       "                      -4.7988e-01,  6.9530e-02, -1.7714e-02,  7.2791e-02, -3.0984e-01,\n",
       "                      -1.7332e-01,  3.1703e-01,  1.1177e-01,  1.2807e-01, -6.9931e-02,\n",
       "                       5.6725e-02, -3.4908e-01,  6.5505e-02,  4.4137e-02,  2.5664e-02,\n",
       "                      -2.5894e-01, -8.1149e-01, -6.4786e-02,  5.8094e-01,  7.8395e-01,\n",
       "                      -1.9563e-01,  6.9253e-01, -2.9486e-01,  5.1291e-01, -1.7648e-01,\n",
       "                       3.8404e-01, -1.0654e-01,  7.5491e-01,  6.1168e-01, -8.2250e-02,\n",
       "                       7.5600e-01,  3.6907e-02, -7.2429e-01,  5.5753e-02,  3.1528e-01,\n",
       "                       2.7916e-02,  5.2273e-01,  1.6702e-01, -1.6596e-01, -5.4292e-01,\n",
       "                       3.7348e-02, -2.7012e-01, -2.1488e-01, -2.6215e-01,  1.0019e-01,\n",
       "                      -8.9256e-02,  5.9688e-01,  2.9512e-02,  5.7577e-01,  1.9496e-01,\n",
       "                      -5.4371e-01,  1.7891e-01,  6.8517e-01, -3.1385e-03, -1.7543e-01,\n",
       "                       1.1274e+00, -5.4757e-01, -9.9244e-02, -9.0421e-01, -1.2888e-01,\n",
       "                      -4.9647e-02, -3.8015e-01, -4.3676e-02, -1.0141e+00,  5.3824e-01,\n",
       "                       1.0095e-01, -1.7301e-01, -4.7507e-01,  8.7340e-02, -1.1037e-01,\n",
       "                      -8.2543e-02,  5.7178e-01,  7.4243e-01,  6.5475e-02, -5.4299e-01,\n",
       "                      -3.8479e-01, -8.5238e-02, -3.1859e-01,  1.0898e-01,  5.4049e-01,\n",
       "                       1.7061e-01, -5.6904e-01,  8.1368e-01,  4.2633e-01,  1.9510e-01,\n",
       "                       3.2089e-01, -4.7030e-02,  7.4617e-01,  6.3243e-02, -5.7487e-01,\n",
       "                       8.0976e-01,  1.1849e-01, -6.2483e-02, -2.1943e-01,  1.2972e-01,\n",
       "                       3.4769e-01, -5.3095e-01,  3.8545e-01, -2.5792e-01, -1.4042e-01,\n",
       "                      -1.0570e-01,  5.8450e-01,  3.7729e-01, -2.4488e-02,  1.3505e-01,\n",
       "                      -1.2183e-01,  2.8761e-01,  9.3975e-02,  2.1007e-01,  6.3286e-01,\n",
       "                      -3.8089e-01, -1.1797e-01,  1.0107e-01,  4.0529e-01,  3.0759e-01,\n",
       "                      -3.4575e-01, -2.7904e-01,  3.3144e-01, -4.7041e-01,  5.5349e-01,\n",
       "                       6.7930e-02, -6.5247e-01,  1.8468e-01,  2.3026e-01,  4.0175e-01,\n",
       "                       1.2029e-01, -2.3509e-02, -1.5128e-01,  3.0389e-01, -1.0787e+00,\n",
       "                       2.6493e-02, -9.9319e-02,  1.3627e-01,  3.4217e-01, -6.0922e-02,\n",
       "                       1.4853e-01, -2.6796e-01,  4.9524e-01,  9.0733e-03,  1.1409e+00,\n",
       "                      -7.1447e-01,  5.6601e-01,  8.3615e-02,  1.0717e-01,  2.1248e-01,\n",
       "                       3.2406e-01, -7.4458e-04,  3.4014e-01, -3.7291e-01, -1.6408e-01,\n",
       "                       1.9066e-01, -9.5002e-02,  3.4987e-01,  3.5461e-01, -2.6118e-01,\n",
       "                       6.2780e-01, -2.4201e-01,  2.3080e-02, -3.1261e-01, -5.9843e-01,\n",
       "                       1.7681e-01], dtype=torch.float64)),\n",
       "             ('6.13.convs.2.1.running_var',\n",
       "              tensor([0.1536, 0.2526, 0.1511, 0.2511, 0.2982, 0.3210, 0.2114, 0.5696, 0.0901,\n",
       "                      0.2710, 0.4634, 0.4321, 0.1473, 0.3153, 0.4919, 0.6123, 0.4843, 0.3401,\n",
       "                      0.4215, 0.1164, 0.2652, 0.3813, 0.2031, 0.1666, 0.4511, 0.2075, 0.5621,\n",
       "                      0.2148, 0.3406, 0.5812, 0.4709, 0.4462, 0.0663, 0.3420, 0.2454, 0.4558,\n",
       "                      0.2551, 0.2538, 0.1319, 0.3669, 0.2590, 0.5202, 0.1347, 0.5678, 0.1658,\n",
       "                      0.5348, 0.3214, 0.4045, 0.3782, 0.5084, 0.2031, 0.1789, 0.3317, 0.0860,\n",
       "                      0.4606, 0.4749, 0.2358, 0.2683, 0.3019, 0.3028, 0.3255, 0.3277, 0.4021,\n",
       "                      0.3263, 0.3896, 0.3078, 0.3474, 0.4168, 0.2530, 0.3054, 0.2655, 0.2228,\n",
       "                      0.1088, 0.2799, 0.3252, 0.1581, 0.3246, 0.2236, 0.7597, 0.1997, 0.2203,\n",
       "                      0.3031, 0.2264, 0.3281, 0.2517, 0.2378, 0.3133, 0.4601, 0.1710, 0.0975,\n",
       "                      0.3552, 0.3794, 0.3567, 0.2366, 0.5293, 0.3795, 0.3077, 0.3444, 0.0891,\n",
       "                      0.1874, 0.4629, 0.2626, 0.1731, 0.2658, 0.3726, 0.1938, 0.3924, 0.2572,\n",
       "                      0.3402, 0.1147, 0.1044, 0.4150, 0.7442, 0.6369, 0.3626, 0.3018, 0.1828,\n",
       "                      0.4511, 0.3111, 0.5339, 0.2339, 0.2904, 0.3212, 0.3015, 0.3399, 0.5196,\n",
       "                      0.3016, 0.4960, 0.1627, 0.3944, 0.1657, 0.3784, 0.3674, 0.3704, 0.3215,\n",
       "                      0.2961, 0.1313, 0.2123, 0.4623, 0.0674, 0.3962, 0.3077, 0.2827, 0.2510,\n",
       "                      0.2552, 0.3658, 0.1488, 0.8561, 0.0708, 0.1752, 0.5940, 0.2354, 0.4294,\n",
       "                      0.5432, 0.1488, 0.2960, 0.4411, 0.0382, 0.2632, 0.1905, 0.0710, 0.3291,\n",
       "                      0.7065, 0.1959, 0.5945, 0.3937, 0.5396, 0.5225, 0.2965, 0.6626, 0.2037,\n",
       "                      0.1978, 0.1210, 0.0971, 0.2508, 0.4386, 0.4017, 0.4591, 0.2582, 0.3537,\n",
       "                      0.3709, 0.0706, 0.3354, 0.2644, 0.2031, 0.2498, 0.2811, 0.1916, 0.3416,\n",
       "                      0.1263, 0.2080, 0.4597, 0.4795, 0.5773, 0.2210, 0.2660, 0.2898, 0.2305,\n",
       "                      0.3363, 0.4138, 0.0894, 0.5179, 0.2106, 0.3454, 0.3467, 0.5171, 0.0867,\n",
       "                      0.1828, 0.2965, 0.4883, 0.2400, 0.3124, 0.2895, 0.3011, 0.2705, 0.2590,\n",
       "                      0.4832, 0.0652, 0.3223, 0.3409, 0.3071, 0.2273, 0.2194, 0.4172, 0.6200,\n",
       "                      0.2172, 0.1388, 0.3155, 0.4567, 0.3574, 0.3897, 0.2648, 0.2852, 0.2987,\n",
       "                      0.4094, 0.6144, 0.3524, 0.2888, 0.3500, 0.2851, 0.3374, 0.0615, 0.3102,\n",
       "                      0.2253, 0.1165, 0.1647, 0.1981, 0.4118, 0.0795, 0.4155, 0.2973, 0.3202,\n",
       "                      0.1046, 0.2627, 0.2383, 0.3887], dtype=torch.float64)),\n",
       "             ('6.13.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.13.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0171],\n",
       "                       [ 0.0466],\n",
       "                       [ 0.0559],\n",
       "                       ...,\n",
       "                       [-0.0358],\n",
       "                       [-0.0417],\n",
       "                       [-0.0885]],\n",
       "              \n",
       "                      [[-0.0490],\n",
       "                       [-0.0320],\n",
       "                       [-0.0085],\n",
       "                       ...,\n",
       "                       [-0.0381],\n",
       "                       [-0.0539],\n",
       "                       [ 0.0024]],\n",
       "              \n",
       "                      [[ 0.0459],\n",
       "                       [ 0.0733],\n",
       "                       [-0.0337],\n",
       "                       ...,\n",
       "                       [ 0.0959],\n",
       "                       [ 0.0054],\n",
       "                       [-0.0658]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0207],\n",
       "                       [ 0.0258],\n",
       "                       [ 0.0256],\n",
       "                       ...,\n",
       "                       [-0.0267],\n",
       "                       [ 0.1061],\n",
       "                       [ 0.0363]],\n",
       "              \n",
       "                      [[ 0.0286],\n",
       "                       [-0.1582],\n",
       "                       [ 0.0615],\n",
       "                       ...,\n",
       "                       [ 0.1192],\n",
       "                       [ 0.0957],\n",
       "                       [ 0.1393]],\n",
       "              \n",
       "                      [[-0.0808],\n",
       "                       [-0.0834],\n",
       "                       [ 0.0938],\n",
       "                       ...,\n",
       "                       [ 0.1318],\n",
       "                       [-0.0147],\n",
       "                       [-0.0764]]], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.0.1.weight',\n",
       "              tensor([0.9778, 0.9821, 0.9600, 0.9657, 0.9603, 0.9639, 0.9758, 0.9548, 0.9760,\n",
       "                      0.9659, 0.9573, 0.9684, 0.9999, 0.9296, 0.9633, 0.9526, 0.9379, 0.9738,\n",
       "                      0.9416, 0.9574, 0.9881, 0.9777, 0.9599, 0.9635, 0.9565, 0.9750, 0.9682,\n",
       "                      0.9410, 0.9330, 0.9437, 0.9698, 0.9792, 0.9644, 0.9665, 0.9439, 1.0003,\n",
       "                      0.9691, 0.9729, 0.9612, 0.9771, 0.9661, 0.9811, 0.9842, 0.9632, 0.9750,\n",
       "                      0.9571, 0.9783, 0.9752, 0.9870, 0.9574, 0.9505, 0.9511, 0.9727, 0.9432,\n",
       "                      0.9730, 0.9982, 0.9549, 0.9979, 1.0022, 0.9893, 0.9596, 0.9346, 0.9622,\n",
       "                      0.9766], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0017,  0.0037, -0.0169, -0.0129, -0.0200,  0.0030,  0.0041, -0.0009,\n",
       "                       0.0016,  0.0157,  0.0027, -0.0061,  0.0372,  0.0020,  0.0021,  0.0108,\n",
       "                      -0.0081,  0.0119, -0.0060,  0.0144,  0.0098, -0.0071,  0.0046,  0.0078,\n",
       "                      -0.0094,  0.0070, -0.0050,  0.0135, -0.0263,  0.0029,  0.0089,  0.0019,\n",
       "                      -0.0067, -0.0186,  0.0013,  0.0226,  0.0009,  0.0122, -0.0149,  0.0019,\n",
       "                       0.0058, -0.0046,  0.0151, -0.0163,  0.0019, -0.0048,  0.0099,  0.0123,\n",
       "                       0.0095, -0.0013, -0.0208, -0.0251, -0.0023, -0.0028,  0.0127,  0.0119,\n",
       "                       0.0157,  0.0219,  0.0140, -0.0046, -0.0129,  0.0052, -0.0041,  0.0150],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.5705,  0.1955,  1.6724,  0.8388,  1.2055, -0.0280, -0.4704,  0.6609,\n",
       "                      -0.2674, -0.5305, -0.1330,  0.4741, -0.4546, -0.9844, -0.3226, -0.0108,\n",
       "                      -1.2653,  0.5629, -0.6295, -0.3457, -0.1934,  1.4640, -1.0251,  1.1369,\n",
       "                       0.5671,  0.1600,  0.2716, -0.5820, -0.3679, -0.2190, -0.5219, -0.7149,\n",
       "                       0.1950, -0.0680, -0.2078, -0.2351,  1.7980, -0.1021,  1.3794,  0.0544,\n",
       "                       0.3415,  0.3088,  0.4475,  0.6645,  0.0172, -0.6267, -0.1309,  0.3605,\n",
       "                       0.1949,  0.5779,  0.6670,  0.8631,  0.5621,  1.3369, -0.2124, -0.8789,\n",
       "                      -1.3022,  0.4782, -0.7564, -0.8544,  1.3024, -1.1875,  0.4247, -0.0363],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.0.1.running_var',\n",
       "              tensor([0.0818, 0.1604, 1.6647, 0.5731, 0.6027, 0.1323, 0.2977, 0.4069, 0.1752,\n",
       "                      0.2945, 0.3839, 0.1466, 0.1137, 1.0702, 0.2503, 0.5533, 0.1713, 0.3160,\n",
       "                      0.5696, 0.2020, 0.2139, 0.3312, 0.1362, 1.3043, 0.2385, 0.3023, 0.1823,\n",
       "                      0.7287, 0.3828, 0.0757, 0.1310, 0.2247, 0.3231, 0.0993, 0.4513, 0.0856,\n",
       "                      0.3543, 0.1920, 0.5381, 0.1433, 0.2449, 0.1507, 0.1008, 0.1254, 0.7459,\n",
       "                      0.4307, 0.1503, 0.1286, 0.1770, 0.4843, 0.7279, 0.5958, 0.6142, 0.0990,\n",
       "                      0.1254, 0.1339, 0.7094, 0.1357, 0.2193, 0.1044, 1.1201, 0.8450, 0.4090,\n",
       "                      0.1854], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.13.convpath.0.1.0.weight',\n",
       "              tensor([[[-1.4548e-01, -6.0081e-02, -2.7059e-02, -5.8420e-02,  2.5364e-02],\n",
       "                       [ 2.4933e-02, -4.2873e-02, -2.8073e-02, -6.9013e-02, -2.7364e-02],\n",
       "                       [-2.0948e-02,  6.9798e-03,  5.8242e-02, -1.1626e-01,  1.7592e-02],\n",
       "                       ...,\n",
       "                       [ 5.0084e-02, -5.4315e-02, -3.6414e-02, -1.2853e-02, -3.6543e-02],\n",
       "                       [ 5.2874e-02,  4.9857e-02,  6.9492e-02, -9.5053e-02, -2.7161e-02],\n",
       "                       [-1.1644e-01,  7.5752e-02,  3.1112e-02, -2.8855e-02, -3.9235e-02]],\n",
       "              \n",
       "                      [[-1.5654e-01,  7.3430e-03, -2.7421e-02,  7.1822e-02, -4.6880e-02],\n",
       "                       [-8.4769e-02, -2.9939e-02,  7.7032e-03,  3.3473e-02,  1.1162e-01],\n",
       "                       [-3.8761e-02, -9.5768e-02,  1.2726e-02, -6.8003e-02,  6.0147e-02],\n",
       "                       ...,\n",
       "                       [-8.0171e-02, -1.6173e-01, -6.2211e-02, -1.6270e-01,  7.1253e-02],\n",
       "                       [-2.1825e-02,  4.6477e-02, -2.1266e-02, -5.8885e-02, -9.6070e-03],\n",
       "                       [-8.2920e-03,  4.0409e-02,  4.4635e-02,  4.7182e-02, -1.3776e-01]],\n",
       "              \n",
       "                      [[-5.0762e-02,  3.9749e-02,  5.7687e-02, -7.9778e-02, -3.2109e-02],\n",
       "                       [-8.0852e-02, -7.0447e-02,  5.1158e-02, -4.8903e-03,  6.0413e-02],\n",
       "                       [ 1.6301e-02, -1.1975e-01, -2.5601e-02, -3.5559e-02,  3.0498e-04],\n",
       "                       ...,\n",
       "                       [ 1.2384e-01,  2.9540e-02, -4.9960e-02, -8.3949e-02, -9.0407e-02],\n",
       "                       [-8.0676e-02, -1.7478e-01,  4.2582e-02, -1.2974e-01, -5.7886e-02],\n",
       "                       [-1.0883e-01,  6.2665e-04,  7.7072e-02,  1.6236e-02,  6.3000e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 6.4901e-02, -7.1595e-03,  9.8509e-02, -3.6420e-03, -5.6746e-02],\n",
       "                       [ 1.3131e-01, -4.7154e-02, -9.7348e-02,  4.0171e-02, -1.2041e-01],\n",
       "                       [ 5.6126e-02, -3.8203e-02,  1.3718e-01,  3.8906e-02,  7.1897e-02],\n",
       "                       ...,\n",
       "                       [ 1.7149e-02,  7.3543e-03,  3.8296e-02, -7.9906e-02,  1.7509e-02],\n",
       "                       [ 1.1866e-01, -1.4766e-01, -1.2177e-03, -1.7202e-01, -1.1195e-01],\n",
       "                       [-8.4962e-02, -1.2995e-02,  9.3062e-03, -1.6297e-01, -3.8770e-02]],\n",
       "              \n",
       "                      [[-7.1619e-02, -2.0431e-02,  8.3252e-02, -6.2487e-02,  1.8180e-01],\n",
       "                       [-7.8980e-02, -7.6899e-03,  4.5549e-02, -2.9508e-02,  8.4784e-02],\n",
       "                       [-1.5468e-01, -1.3886e-01,  1.3574e-02,  5.2715e-02,  2.7708e-05],\n",
       "                       ...,\n",
       "                       [-1.3815e-01, -4.8067e-03, -1.5901e-02, -8.3183e-02,  6.4381e-04],\n",
       "                       [ 3.1024e-02, -8.5193e-02, -1.8651e-01,  2.4245e-02, -2.1807e-01],\n",
       "                       [-3.1928e-03, -1.5661e-01,  6.4474e-02,  1.0194e-01, -6.7360e-02]],\n",
       "              \n",
       "                      [[-1.6357e-01, -4.4661e-02, -6.1795e-02, -2.6217e-03,  3.1399e-02],\n",
       "                       [-9.2542e-02,  9.8082e-02, -6.0010e-02, -8.8338e-04,  9.7368e-02],\n",
       "                       [ 8.3721e-02, -4.6371e-02, -2.2987e-02,  1.2923e-01,  4.2175e-02],\n",
       "                       ...,\n",
       "                       [-9.6165e-02, -7.7653e-03,  4.7100e-02,  5.1517e-02,  8.0729e-02],\n",
       "                       [-6.2907e-02, -7.5381e-02, -3.0818e-02, -1.3653e-01, -1.0445e-01],\n",
       "                       [ 4.0789e-02, -3.4180e-02,  1.0727e-01,  8.4954e-03, -5.6275e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.1.1.weight',\n",
       "              tensor([1.0010, 0.9663, 0.9698, 0.9487, 0.9567, 0.9623, 0.9531, 0.9555, 1.0001,\n",
       "                      0.9614, 0.9682, 0.9626, 0.9687, 0.9748, 0.9658, 0.9486, 0.9752, 0.9647,\n",
       "                      0.9664, 0.9792, 0.9473, 0.9789, 0.9607, 0.9629, 0.9802, 0.9722, 0.9204,\n",
       "                      0.9789, 0.9597, 0.9574, 0.9555, 0.9855, 0.9867, 0.9601, 0.9418, 0.9706,\n",
       "                      0.9722, 0.9618, 0.9627, 0.9632, 0.9581, 0.9444, 0.9952, 0.9689, 0.9705,\n",
       "                      0.9611, 0.9497, 0.9741, 0.9600, 0.9498, 0.9465, 0.9610, 0.9757, 0.9530,\n",
       "                      0.9395, 0.9721, 0.9714, 0.9642, 0.9593, 0.9576, 0.9628, 0.9479, 0.9767,\n",
       "                      0.9489], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.1.1.bias',\n",
       "              tensor([ 2.2191e-02, -1.9797e-02, -5.4914e-04,  6.8388e-03, -1.9183e-02,\n",
       "                       6.5534e-03,  3.3478e-04,  1.4414e-03,  3.4087e-02, -7.5099e-03,\n",
       "                       1.4579e-02, -1.7031e-02, -3.5580e-03,  1.1472e-02,  1.6541e-02,\n",
       "                      -1.4898e-03,  4.9320e-04,  4.0031e-07, -4.0037e-03, -2.7737e-03,\n",
       "                      -5.5625e-04,  1.0401e-03, -9.9758e-03, -4.4800e-03,  1.1606e-03,\n",
       "                      -1.2184e-02, -1.1498e-02, -4.0597e-03, -1.0666e-02,  3.0479e-03,\n",
       "                       1.6056e-02,  1.1323e-02,  1.9979e-02,  9.4837e-03, -1.3558e-02,\n",
       "                       1.0922e-02, -4.2005e-03,  8.2197e-03, -4.7835e-03, -1.7147e-02,\n",
       "                      -1.3034e-02,  1.3582e-02,  9.4440e-03,  4.0566e-03, -1.8755e-03,\n",
       "                      -4.8153e-03,  2.9140e-03,  1.2538e-02, -1.2239e-02,  4.8748e-04,\n",
       "                      -8.2226e-03,  7.3608e-04, -6.7241e-03, -2.4716e-02, -1.5144e-02,\n",
       "                      -2.8047e-03, -8.1725e-03,  2.3615e-02, -1.1297e-02, -7.4358e-03,\n",
       "                      -7.1439e-03, -3.8513e-03,  1.4019e-04, -1.6053e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.1.1.running_mean',\n",
       "              tensor([-4.3767e-01, -3.5169e-01, -4.8482e-01, -7.9885e-01,  2.0882e-01,\n",
       "                      -4.9010e-01,  5.3561e-01, -3.3310e-02, -7.4366e-01,  2.5952e-01,\n",
       "                      -2.7686e-01,  2.8710e-01,  3.3390e-01, -6.2427e-01,  9.5532e-02,\n",
       "                       5.8640e-02,  7.5632e-03, -7.6850e-01, -5.2135e-01, -1.9176e-04,\n",
       "                      -9.2832e-01, -7.3453e-02,  8.8578e-01,  5.2217e-01, -5.3165e-01,\n",
       "                       2.7525e-01, -7.3558e-01,  3.2225e-01,  3.1069e-01, -3.3549e-01,\n",
       "                       2.9882e-02,  2.6587e-01, -7.0607e-01, -1.2120e-01, -1.0605e-01,\n",
       "                      -1.8391e-01, -2.1154e-01, -8.2011e-01, -3.0112e-02,  3.0164e-01,\n",
       "                       1.3161e-01, -9.5813e-01, -3.3909e-02, -6.9102e-01,  4.5450e-01,\n",
       "                      -3.1132e-01,  2.5933e-01, -2.2675e-01, -1.7857e-02,  6.1876e-02,\n",
       "                      -7.1365e-01, -5.5025e-01, -4.6579e-01,  1.0815e-01, -4.2908e-01,\n",
       "                       2.9207e-01,  3.3943e-01, -8.4226e-01,  3.5619e-02,  1.6953e-02,\n",
       "                       2.0708e-01, -8.7690e-01,  9.4395e-02,  1.0529e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.1.1.running_var',\n",
       "              tensor([0.5844, 0.9954, 0.5082, 0.9178, 0.6175, 0.6581, 0.4834, 1.1521, 0.5605,\n",
       "                      0.5491, 0.5730, 0.5612, 0.7454, 0.7830, 0.6046, 0.5962, 0.6327, 0.6858,\n",
       "                      0.6639, 0.3449, 0.6112, 0.4824, 0.7322, 0.6266, 0.7572, 0.3791, 0.6467,\n",
       "                      0.4990, 0.8153, 1.2824, 0.5141, 0.5516, 0.6154, 0.5150, 0.6305, 0.7988,\n",
       "                      0.5225, 0.7691, 0.4227, 0.5030, 0.3966, 0.9883, 0.5631, 0.9327, 0.6956,\n",
       "                      0.5729, 0.5655, 0.7164, 0.8374, 0.5203, 0.8330, 0.5797, 0.4854, 0.9130,\n",
       "                      0.6093, 0.5595, 0.7818, 0.7221, 0.5959, 0.9039, 0.5992, 0.6503, 0.4518,\n",
       "                      1.0118], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.13.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0519],\n",
       "                       [-0.0516],\n",
       "                       [-0.1350],\n",
       "                       ...,\n",
       "                       [-0.0462],\n",
       "                       [-0.1625],\n",
       "                       [ 0.0618]],\n",
       "              \n",
       "                      [[ 0.0452],\n",
       "                       [ 0.1068],\n",
       "                       [-0.2067],\n",
       "                       ...,\n",
       "                       [ 0.0367],\n",
       "                       [-0.0881],\n",
       "                       [-0.0796]],\n",
       "              \n",
       "                      [[-0.0415],\n",
       "                       [-0.1307],\n",
       "                       [ 0.0260],\n",
       "                       ...,\n",
       "                       [-0.0423],\n",
       "                       [ 0.0027],\n",
       "                       [ 0.0026]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0579],\n",
       "                       [ 0.0510],\n",
       "                       [-0.0494],\n",
       "                       ...,\n",
       "                       [ 0.0419],\n",
       "                       [-0.0481],\n",
       "                       [ 0.1872]],\n",
       "              \n",
       "                      [[ 0.1596],\n",
       "                       [ 0.0068],\n",
       "                       [ 0.0626],\n",
       "                       ...,\n",
       "                       [-0.0255],\n",
       "                       [-0.0219],\n",
       "                       [ 0.0025]],\n",
       "              \n",
       "                      [[ 0.0219],\n",
       "                       [ 0.2924],\n",
       "                       [-0.2022],\n",
       "                       ...,\n",
       "                       [-0.0019],\n",
       "                       [-0.2145],\n",
       "                       [-0.0057]]], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.2.1.weight',\n",
       "              tensor([ 9.0264e-04, -1.8442e-03,  7.8081e-03, -2.7761e-03, -2.3762e-03,\n",
       "                      -8.1073e-03, -9.2309e-03,  2.8186e-02,  3.0679e-05,  9.4049e-03,\n",
       "                      -3.0244e-02, -2.4950e-02, -1.3176e-02, -1.0886e-02,  1.5435e-02,\n",
       "                       2.3951e-02, -1.7138e-02, -1.2674e-03, -1.2846e-02, -4.8328e-04,\n",
       "                      -2.0524e-02,  1.9178e-02, -1.6388e-03,  1.7316e-03, -3.2421e-02,\n",
       "                       8.7399e-03, -3.2143e-02, -3.4827e-03, -2.7582e-02,  1.6249e-02,\n",
       "                      -2.0744e-02, -2.0761e-02, -2.8662e-03, -8.5422e-03, -5.9387e-03,\n",
       "                       1.6644e-02, -9.6083e-03,  1.5628e-02,  3.1499e-05, -3.2163e-03,\n",
       "                      -5.6035e-03,  1.2028e-02,  1.2773e-02, -1.2157e-02, -1.5288e-03,\n",
       "                      -3.0308e-03, -3.1764e-02, -1.2567e-02,  5.2686e-03,  5.2975e-03,\n",
       "                      -1.6833e-02,  3.8504e-03,  3.8320e-03,  1.9051e-03,  1.4378e-02,\n",
       "                       5.9967e-02,  2.4584e-02, -2.5146e-03, -1.7227e-03,  5.1612e-03,\n",
       "                      -8.1995e-03, -4.4886e-03, -3.2472e-02,  1.5959e-02, -3.2776e-02,\n",
       "                      -1.1816e-02, -6.9172e-03,  1.5806e-02,  2.2582e-02,  1.6673e-02,\n",
       "                       4.1314e-03,  4.6527e-03, -4.7516e-03,  9.5212e-03,  2.8346e-02,\n",
       "                       5.4278e-03,  4.9834e-03, -1.4716e-02,  2.2329e-02, -9.3704e-03,\n",
       "                       7.0517e-03,  1.0359e-02, -1.0477e-02, -3.1556e-03,  9.0022e-03,\n",
       "                       6.4094e-03, -7.8552e-03,  2.1836e-02,  4.8672e-05,  7.7626e-03,\n",
       "                      -2.5395e-03,  7.4278e-03,  1.3625e-02, -1.7499e-02,  2.1558e-02,\n",
       "                      -1.3903e-02, -7.9741e-03, -1.7599e-02, -7.7283e-04,  1.6247e-02,\n",
       "                       1.6919e-02, -1.2140e-02,  1.5336e-03, -1.3440e-02, -7.5494e-03,\n",
       "                      -2.3736e-02,  1.9984e-02,  8.0849e-03, -2.5506e-02,  2.3528e-03,\n",
       "                       2.7488e-03, -6.5428e-03,  2.6358e-02, -2.2948e-02,  1.0978e-02,\n",
       "                       1.5734e-02, -2.4465e-02,  1.1182e-02, -3.5343e-02, -1.3823e-02,\n",
       "                       1.2170e-02,  1.1022e-02, -3.0964e-03,  2.3041e-03,  2.1905e-02,\n",
       "                      -3.2901e-02,  1.0712e-02, -1.5463e-02,  1.3127e-02, -2.6933e-03,\n",
       "                      -2.0616e-03, -1.6855e-02,  1.6730e-02,  1.6052e-02, -8.3106e-03,\n",
       "                       1.1990e-02,  2.8264e-03,  5.3277e-03, -1.7021e-02, -8.6031e-03,\n",
       "                       2.9925e-02,  2.5197e-02,  1.8990e-02,  1.5761e-02,  1.0350e-02,\n",
       "                       1.3884e-02, -1.0856e-02,  1.0129e-02, -1.4048e-02, -9.6497e-03,\n",
       "                      -1.1583e-02, -3.8121e-03, -1.8518e-02,  2.0526e-02,  5.1410e-04,\n",
       "                       1.4138e-02, -2.2857e-02,  2.1986e-03,  1.1884e-02,  1.4280e-02,\n",
       "                      -2.9263e-03,  7.9252e-03,  2.9437e-02, -1.5536e-03, -2.7173e-02,\n",
       "                       1.6297e-02, -3.9052e-02, -1.6970e-02,  9.1741e-03, -3.7511e-02,\n",
       "                       1.2486e-04,  5.7046e-03, -6.8798e-04, -6.2910e-03, -5.5737e-03,\n",
       "                      -5.6677e-03,  1.9926e-02,  3.1230e-02,  2.1947e-03,  2.4191e-02,\n",
       "                       9.4773e-03, -4.3795e-03, -8.4010e-03, -1.6261e-02,  1.1966e-02,\n",
       "                       7.0355e-03,  1.3800e-03, -5.4656e-03,  1.7027e-02, -4.1955e-04,\n",
       "                      -2.9646e-03,  2.9417e-02, -8.1331e-03,  1.9180e-02, -3.2995e-02,\n",
       "                      -3.5414e-03,  1.7536e-02,  4.7590e-03,  6.3905e-04,  2.0163e-02,\n",
       "                      -3.0102e-04, -2.3761e-02,  1.1434e-03, -3.2357e-02, -1.8739e-02,\n",
       "                      -1.3880e-02,  2.3332e-03,  9.9259e-03,  1.8760e-02, -1.9919e-02,\n",
       "                       2.1322e-02, -6.3412e-04, -4.3835e-02, -1.5551e-02,  1.5436e-02,\n",
       "                       9.7790e-03, -1.4621e-03, -6.9060e-04, -2.4824e-02, -9.8609e-03,\n",
       "                      -1.8598e-02,  1.6646e-02,  1.0271e-02,  9.2319e-03,  9.4591e-03,\n",
       "                      -2.9256e-03,  1.5250e-02, -9.6402e-03,  1.7530e-02,  2.1543e-02,\n",
       "                       4.0701e-03, -5.1803e-03, -1.5343e-04, -2.2187e-02,  3.4696e-03,\n",
       "                       1.0980e-02,  6.4323e-03, -7.4039e-03,  7.9961e-03,  1.4056e-02,\n",
       "                       1.5447e-03,  4.7254e-03,  1.4236e-03,  9.7185e-04, -9.4150e-04,\n",
       "                       4.7475e-04, -7.1570e-03,  2.3596e-02, -4.5919e-03, -4.2937e-02,\n",
       "                       3.7873e-02, -3.0164e-02,  2.3760e-03, -7.3786e-03,  5.2193e-04,\n",
       "                       3.3035e-02], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.2.1.bias',\n",
       "              tensor([ 8.1188e-06,  9.3859e-03,  9.2961e-03,  1.4093e-02,  3.5178e-03,\n",
       "                       9.6883e-03,  7.1956e-03, -7.1808e-04,  1.4511e-02,  1.5965e-02,\n",
       "                       1.5775e-02, -6.2965e-03,  5.5444e-03, -5.1574e-03,  8.0633e-03,\n",
       "                       2.3873e-03,  2.4227e-02, -1.1772e-03,  9.9406e-03, -3.3031e-03,\n",
       "                      -4.7985e-03,  5.2502e-04,  5.1964e-03,  6.5902e-03,  5.0445e-03,\n",
       "                      -1.7085e-02,  3.8389e-03,  7.7876e-03,  1.4593e-02, -7.1374e-03,\n",
       "                       9.1926e-04,  7.3146e-03, -3.2220e-03,  2.0801e-02,  3.6378e-03,\n",
       "                       1.5466e-02, -2.5558e-03,  1.7172e-02,  1.1054e-02,  1.1730e-02,\n",
       "                       2.0702e-03,  1.7164e-02, -1.2344e-02, -1.8373e-03,  6.9630e-03,\n",
       "                      -1.2725e-02,  1.4439e-02,  6.2896e-03, -1.2343e-02,  1.8317e-03,\n",
       "                       8.3281e-03,  4.1248e-03,  7.4451e-03,  1.7264e-02,  3.7784e-03,\n",
       "                       1.9088e-02,  8.8985e-03,  1.3304e-03,  1.2174e-02, -2.9547e-03,\n",
       "                      -7.5268e-04,  5.1524e-04,  9.4787e-03,  8.5604e-03, -5.8265e-03,\n",
       "                       2.8080e-03, -1.0708e-02,  1.4742e-02, -2.0457e-03, -1.4956e-02,\n",
       "                       7.2167e-03,  3.1540e-03, -7.0523e-04, -8.0911e-03,  1.3436e-02,\n",
       "                       6.0556e-03,  2.2118e-04, -1.1355e-03,  2.8094e-03,  1.4773e-02,\n",
       "                       5.2919e-03, -8.2789e-03,  1.0413e-02,  4.1866e-03, -3.4977e-03,\n",
       "                       1.6590e-02, -2.9025e-04,  1.3983e-02,  1.4462e-02,  3.9924e-04,\n",
       "                       2.7518e-04,  1.0580e-02,  1.0004e-02,  2.8441e-03,  1.1647e-02,\n",
       "                      -8.7508e-03,  1.2464e-02, -1.5488e-03,  2.0702e-02,  6.4013e-03,\n",
       "                       1.8810e-02,  1.5998e-02,  3.6197e-03,  1.1261e-02, -5.3379e-04,\n",
       "                       5.4579e-04, -6.2880e-03,  1.1352e-02,  8.2945e-03,  2.7038e-03,\n",
       "                      -1.3244e-02, -9.2793e-03,  4.5037e-03,  1.9861e-02,  1.4106e-02,\n",
       "                       5.9143e-03,  9.8287e-03,  2.6533e-03,  6.5537e-03, -1.3839e-02,\n",
       "                      -1.7607e-04,  9.6864e-03,  1.1683e-03, -4.9378e-04,  1.1176e-02,\n",
       "                       9.9491e-03,  6.9958e-03,  5.2945e-03,  4.9082e-03,  1.2865e-02,\n",
       "                       6.7311e-03,  5.8107e-03,  1.3728e-02,  5.4030e-03,  8.8502e-03,\n",
       "                      -1.2701e-02,  1.4475e-02,  3.7615e-03,  6.0663e-03, -2.8962e-03,\n",
       "                       1.3033e-02, -1.2167e-02,  1.6747e-02,  2.1833e-03, -4.9723e-03,\n",
       "                       1.6532e-02,  5.4126e-03, -8.0455e-04,  1.2399e-02,  8.4627e-03,\n",
       "                       1.1890e-02,  1.4772e-02,  6.2747e-03,  1.2290e-02,  1.0989e-02,\n",
       "                       4.7254e-03, -1.6241e-03,  6.4660e-03,  8.0668e-04, -1.2979e-02,\n",
       "                       2.4385e-03,  4.7222e-04, -2.2378e-03,  7.5218e-03,  1.2945e-02,\n",
       "                      -3.2596e-03, -1.3042e-02,  9.7880e-03,  7.3170e-03,  2.1177e-02,\n",
       "                       1.6999e-03,  1.4970e-03,  5.4934e-03,  1.4688e-02, -1.3014e-02,\n",
       "                       1.0316e-02,  1.0022e-03,  1.5179e-02,  1.3242e-03,  5.8099e-03,\n",
       "                      -5.9191e-03,  1.1417e-02, -7.0672e-03, -8.8494e-03,  1.2337e-02,\n",
       "                       8.0209e-03,  1.4096e-02,  9.3819e-03,  6.4982e-03,  8.1123e-03,\n",
       "                       5.9088e-03,  4.9292e-03,  6.0037e-03,  1.1428e-03,  1.6777e-03,\n",
       "                       9.8802e-03,  1.1496e-02,  2.6247e-03,  5.1550e-03,  1.4937e-02,\n",
       "                      -7.0068e-04,  2.2734e-02,  1.8110e-02,  2.0024e-02,  1.8069e-02,\n",
       "                      -1.7547e-03,  9.1308e-03, -1.1559e-02,  6.6428e-03,  1.2718e-02,\n",
       "                       9.3185e-03,  1.0902e-02,  1.1870e-02,  6.6168e-03,  8.5487e-03,\n",
       "                       1.9172e-03,  4.8528e-03,  1.6108e-02,  4.3948e-03,  4.4651e-03,\n",
       "                       8.3401e-03, -3.7677e-04,  2.5471e-03,  1.5156e-02,  7.8935e-04,\n",
       "                       7.2086e-03, -6.9722e-03, -1.5534e-03,  2.0729e-02,  1.6517e-02,\n",
       "                       3.2275e-03, -4.2153e-03,  4.9803e-03,  1.2740e-02, -3.3138e-04,\n",
       "                       7.5377e-03,  2.5846e-03,  6.6910e-03,  7.0040e-03,  7.5547e-03,\n",
       "                      -3.4200e-03, -2.2858e-04, -2.1586e-03,  1.2933e-02,  1.1062e-03,\n",
       "                       9.3007e-03,  3.5708e-03,  3.5857e-03, -1.2534e-02, -1.0333e-02,\n",
       "                       2.0282e-02,  2.4897e-02,  1.8509e-02,  1.7617e-02,  2.8039e-03,\n",
       "                       4.0916e-03], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.2.1.running_mean',\n",
       "              tensor([-7.5019e-02,  3.4987e-01,  5.9603e-02,  8.1202e-02, -1.1371e-01,\n",
       "                      -7.7833e-01,  9.6499e-03, -2.9537e-01,  1.8077e-01, -3.9717e-01,\n",
       "                      -3.3094e-01, -7.1698e-01,  2.3992e-01,  5.0273e-01, -5.2787e-01,\n",
       "                      -6.5982e-01,  9.3607e-01, -8.7359e-02,  9.0010e-01,  9.3877e-02,\n",
       "                      -1.6932e-01,  9.0360e-02, -9.9249e-02, -6.9108e-03,  8.3004e-01,\n",
       "                       6.0121e-02, -1.3261e+00, -1.8313e-02, -4.5757e-02,  6.3813e-01,\n",
       "                       4.9511e-01,  8.0187e-03,  8.1358e-02,  4.8489e-01, -1.3992e-01,\n",
       "                      -1.6722e-01,  7.6294e-02, -7.6344e-01, -7.3700e-02, -1.1355e-01,\n",
       "                      -1.2237e-01, -1.0308e-01,  5.9181e-02, -2.6961e-01,  2.2003e-01,\n",
       "                       2.6055e-01, -3.6410e-01, -2.1450e-01,  2.2604e-01, -8.8875e-01,\n",
       "                       5.7539e-02, -5.1677e-01, -2.5665e-01, -1.2461e-01,  4.6009e-01,\n",
       "                       3.9679e-01,  6.3269e-03,  5.4402e-01, -2.0966e-01,  1.3705e-01,\n",
       "                       3.2988e-01,  1.1380e-01,  1.1383e-01, -1.4972e-01,  8.5433e-01,\n",
       "                      -1.4535e-01,  7.6311e-01,  4.3342e-01, -1.4459e-01, -3.4254e-01,\n",
       "                       3.7322e-01,  1.1451e-01,  1.8938e-02, -3.2956e-01,  5.5660e-01,\n",
       "                       3.1419e-01,  5.7530e-01,  2.8784e-01,  2.6796e-01, -2.4315e-01,\n",
       "                       1.6871e-01,  5.2095e-01, -6.4603e-02,  1.7638e-01, -2.3244e-02,\n",
       "                      -1.4593e-01, -2.1309e-01,  4.0366e-02,  2.4277e-01,  2.6452e-02,\n",
       "                       5.0399e-01,  3.4196e-01, -2.4411e-01, -2.0873e-01, -5.7462e-01,\n",
       "                      -4.7988e-01,  6.9530e-02, -1.7714e-02,  7.2791e-02, -3.0984e-01,\n",
       "                      -1.7332e-01,  3.1703e-01,  1.1177e-01,  1.2807e-01, -6.9931e-02,\n",
       "                       5.6725e-02, -3.4908e-01,  6.5505e-02,  4.4137e-02,  2.5664e-02,\n",
       "                      -2.5894e-01, -8.1149e-01, -6.4786e-02,  5.8094e-01,  7.8395e-01,\n",
       "                      -1.9563e-01,  6.9253e-01, -2.9486e-01,  5.1291e-01, -1.7648e-01,\n",
       "                       3.8404e-01, -1.0654e-01,  7.5491e-01,  6.1168e-01, -8.2250e-02,\n",
       "                       7.5600e-01,  3.6907e-02, -7.2429e-01,  5.5753e-02,  3.1528e-01,\n",
       "                       2.7916e-02,  5.2273e-01,  1.6702e-01, -1.6596e-01, -5.4292e-01,\n",
       "                       3.7348e-02, -2.7012e-01, -2.1488e-01, -2.6215e-01,  1.0019e-01,\n",
       "                      -8.9256e-02,  5.9688e-01,  2.9512e-02,  5.7577e-01,  1.9496e-01,\n",
       "                      -5.4371e-01,  1.7891e-01,  6.8517e-01, -3.1385e-03, -1.7543e-01,\n",
       "                       1.1274e+00, -5.4757e-01, -9.9244e-02, -9.0421e-01, -1.2888e-01,\n",
       "                      -4.9647e-02, -3.8015e-01, -4.3676e-02, -1.0141e+00,  5.3824e-01,\n",
       "                       1.0095e-01, -1.7301e-01, -4.7507e-01,  8.7340e-02, -1.1037e-01,\n",
       "                      -8.2543e-02,  5.7178e-01,  7.4243e-01,  6.5475e-02, -5.4299e-01,\n",
       "                      -3.8479e-01, -8.5238e-02, -3.1859e-01,  1.0898e-01,  5.4049e-01,\n",
       "                       1.7061e-01, -5.6904e-01,  8.1368e-01,  4.2633e-01,  1.9510e-01,\n",
       "                       3.2089e-01, -4.7030e-02,  7.4617e-01,  6.3243e-02, -5.7487e-01,\n",
       "                       8.0976e-01,  1.1849e-01, -6.2483e-02, -2.1943e-01,  1.2972e-01,\n",
       "                       3.4769e-01, -5.3095e-01,  3.8545e-01, -2.5792e-01, -1.4042e-01,\n",
       "                      -1.0570e-01,  5.8450e-01,  3.7729e-01, -2.4488e-02,  1.3505e-01,\n",
       "                      -1.2183e-01,  2.8761e-01,  9.3975e-02,  2.1007e-01,  6.3286e-01,\n",
       "                      -3.8089e-01, -1.1797e-01,  1.0107e-01,  4.0529e-01,  3.0759e-01,\n",
       "                      -3.4575e-01, -2.7904e-01,  3.3144e-01, -4.7041e-01,  5.5349e-01,\n",
       "                       6.7930e-02, -6.5247e-01,  1.8468e-01,  2.3026e-01,  4.0175e-01,\n",
       "                       1.2029e-01, -2.3509e-02, -1.5128e-01,  3.0389e-01, -1.0787e+00,\n",
       "                       2.6493e-02, -9.9319e-02,  1.3627e-01,  3.4217e-01, -6.0922e-02,\n",
       "                       1.4853e-01, -2.6796e-01,  4.9524e-01,  9.0733e-03,  1.1409e+00,\n",
       "                      -7.1447e-01,  5.6601e-01,  8.3615e-02,  1.0717e-01,  2.1248e-01,\n",
       "                       3.2406e-01, -7.4458e-04,  3.4014e-01, -3.7291e-01, -1.6408e-01,\n",
       "                       1.9066e-01, -9.5002e-02,  3.4987e-01,  3.5461e-01, -2.6118e-01,\n",
       "                       6.2780e-01, -2.4201e-01,  2.3080e-02, -3.1261e-01, -5.9843e-01,\n",
       "                       1.7681e-01], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.2.1.running_var',\n",
       "              tensor([0.1536, 0.2526, 0.1511, 0.2511, 0.2982, 0.3210, 0.2114, 0.5696, 0.0901,\n",
       "                      0.2710, 0.4634, 0.4321, 0.1473, 0.3153, 0.4919, 0.6123, 0.4843, 0.3401,\n",
       "                      0.4215, 0.1164, 0.2652, 0.3813, 0.2031, 0.1666, 0.4511, 0.2075, 0.5621,\n",
       "                      0.2148, 0.3406, 0.5812, 0.4709, 0.4462, 0.0663, 0.3420, 0.2454, 0.4558,\n",
       "                      0.2551, 0.2538, 0.1319, 0.3669, 0.2590, 0.5202, 0.1347, 0.5678, 0.1658,\n",
       "                      0.5348, 0.3214, 0.4045, 0.3782, 0.5084, 0.2031, 0.1789, 0.3317, 0.0860,\n",
       "                      0.4606, 0.4749, 0.2358, 0.2683, 0.3019, 0.3028, 0.3255, 0.3277, 0.4021,\n",
       "                      0.3263, 0.3896, 0.3078, 0.3474, 0.4168, 0.2530, 0.3054, 0.2655, 0.2228,\n",
       "                      0.1088, 0.2799, 0.3252, 0.1581, 0.3246, 0.2236, 0.7597, 0.1997, 0.2203,\n",
       "                      0.3031, 0.2264, 0.3281, 0.2517, 0.2378, 0.3133, 0.4601, 0.1710, 0.0975,\n",
       "                      0.3552, 0.3794, 0.3567, 0.2366, 0.5293, 0.3795, 0.3077, 0.3444, 0.0891,\n",
       "                      0.1874, 0.4629, 0.2626, 0.1731, 0.2658, 0.3726, 0.1938, 0.3924, 0.2572,\n",
       "                      0.3402, 0.1147, 0.1044, 0.4150, 0.7442, 0.6369, 0.3626, 0.3018, 0.1828,\n",
       "                      0.4511, 0.3111, 0.5339, 0.2339, 0.2904, 0.3212, 0.3015, 0.3399, 0.5196,\n",
       "                      0.3016, 0.4960, 0.1627, 0.3944, 0.1657, 0.3784, 0.3674, 0.3704, 0.3215,\n",
       "                      0.2961, 0.1313, 0.2123, 0.4623, 0.0674, 0.3962, 0.3077, 0.2827, 0.2510,\n",
       "                      0.2552, 0.3658, 0.1488, 0.8561, 0.0708, 0.1752, 0.5940, 0.2354, 0.4294,\n",
       "                      0.5432, 0.1488, 0.2960, 0.4411, 0.0382, 0.2632, 0.1905, 0.0710, 0.3291,\n",
       "                      0.7065, 0.1959, 0.5945, 0.3937, 0.5396, 0.5225, 0.2965, 0.6626, 0.2037,\n",
       "                      0.1978, 0.1210, 0.0971, 0.2508, 0.4386, 0.4017, 0.4591, 0.2582, 0.3537,\n",
       "                      0.3709, 0.0706, 0.3354, 0.2644, 0.2031, 0.2498, 0.2811, 0.1916, 0.3416,\n",
       "                      0.1263, 0.2080, 0.4597, 0.4795, 0.5773, 0.2210, 0.2660, 0.2898, 0.2305,\n",
       "                      0.3363, 0.4138, 0.0894, 0.5179, 0.2106, 0.3454, 0.3467, 0.5171, 0.0867,\n",
       "                      0.1828, 0.2965, 0.4883, 0.2400, 0.3124, 0.2895, 0.3011, 0.2705, 0.2590,\n",
       "                      0.4832, 0.0652, 0.3223, 0.3409, 0.3071, 0.2273, 0.2194, 0.4172, 0.6200,\n",
       "                      0.2172, 0.1388, 0.3155, 0.4567, 0.3574, 0.3897, 0.2648, 0.2852, 0.2987,\n",
       "                      0.4094, 0.6144, 0.3524, 0.2888, 0.3500, 0.2851, 0.3374, 0.0615, 0.3102,\n",
       "                      0.2253, 0.1165, 0.1647, 0.1981, 0.4118, 0.0795, 0.4155, 0.2973, 0.3202,\n",
       "                      0.1046, 0.2627, 0.2383, 0.3887], dtype=torch.float64)),\n",
       "             ('6.13.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.14.convs.0.0.weight',\n",
       "              tensor([[[ 7.6561e-02],\n",
       "                       [-1.5895e-02],\n",
       "                       [ 4.6714e-03],\n",
       "                       ...,\n",
       "                       [ 7.2812e-02],\n",
       "                       [-4.8927e-02],\n",
       "                       [ 3.2493e-02]],\n",
       "              \n",
       "                      [[ 4.4624e-02],\n",
       "                       [ 5.0613e-02],\n",
       "                       [ 4.2176e-02],\n",
       "                       ...,\n",
       "                       [-1.4014e-01],\n",
       "                       [-6.9230e-03],\n",
       "                       [-5.6085e-02]],\n",
       "              \n",
       "                      [[ 1.2783e-01],\n",
       "                       [ 8.1154e-03],\n",
       "                       [ 3.1433e-02],\n",
       "                       ...,\n",
       "                       [-1.7322e-01],\n",
       "                       [ 1.1900e-01],\n",
       "                       [-6.8969e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.6158e-02],\n",
       "                       [-1.1034e-02],\n",
       "                       [-3.3664e-02],\n",
       "                       ...,\n",
       "                       [-1.9662e-02],\n",
       "                       [ 4.7206e-02],\n",
       "                       [ 3.1625e-03]],\n",
       "              \n",
       "                      [[-5.6436e-02],\n",
       "                       [-8.1698e-02],\n",
       "                       [ 7.1369e-02],\n",
       "                       ...,\n",
       "                       [-1.7726e-01],\n",
       "                       [-9.1429e-02],\n",
       "                       [ 3.2624e-02]],\n",
       "              \n",
       "                      [[-6.5344e-02],\n",
       "                       [ 1.0106e-02],\n",
       "                       [-1.5147e-02],\n",
       "                       ...,\n",
       "                       [ 1.0679e-04],\n",
       "                       [ 5.1660e-02],\n",
       "                       [ 8.7525e-03]]], dtype=torch.float64)),\n",
       "             ('6.14.convs.0.1.weight',\n",
       "              tensor([0.9525, 0.9719, 0.9757, 0.9917, 0.9495, 0.9690, 0.9585, 0.9789, 0.9811,\n",
       "                      0.9651, 0.9550, 0.9889, 0.9799, 0.9561, 0.9831, 0.9410, 0.9689, 0.9640,\n",
       "                      0.9759, 0.9656, 0.9825, 0.9566, 0.9243, 0.9800, 0.9463, 0.9699, 0.9652,\n",
       "                      0.9994, 0.9620, 0.9709, 0.9481, 0.9862, 0.9583, 0.9638, 0.9481, 0.9662,\n",
       "                      0.9901, 0.9453, 0.9737, 0.9776, 0.9759, 0.9536, 0.9683, 0.9756, 0.9553,\n",
       "                      0.9489, 0.9587, 0.9524, 0.9730, 0.9627, 0.9534, 0.9626, 0.9703, 0.9718,\n",
       "                      0.9527, 0.9480, 0.9544, 0.9452, 0.9480, 0.9887, 0.9504, 0.9842, 0.9855,\n",
       "                      0.9604], dtype=torch.float64)),\n",
       "             ('6.14.convs.0.1.bias',\n",
       "              tensor([-1.4633e-02,  3.6452e-03,  2.0481e-02, -1.3261e-03, -2.3015e-02,\n",
       "                       2.3452e-02,  7.9624e-03,  2.9815e-02,  1.2440e-02,  5.1935e-03,\n",
       "                      -4.2705e-03,  1.5624e-02,  1.1480e-02, -1.2509e-02,  1.7098e-02,\n",
       "                      -1.4460e-03, -9.4927e-03, -8.7487e-04, -1.0514e-02,  9.4479e-03,\n",
       "                       1.7121e-02, -1.1738e-02, -8.5928e-03,  2.8503e-02,  1.0380e-02,\n",
       "                      -5.1002e-03,  1.3708e-02,  1.9667e-02, -1.7578e-02,  2.0791e-02,\n",
       "                      -2.2950e-02,  2.1195e-02, -1.1251e-02, -1.2482e-03, -5.9303e-03,\n",
       "                       6.1032e-04,  2.0373e-02,  8.4859e-03,  1.6992e-03, -2.0250e-02,\n",
       "                       2.9656e-02,  4.4756e-03,  5.3999e-03, -5.7733e-03, -9.2714e-03,\n",
       "                      -3.1791e-03,  9.3408e-03, -1.1724e-02,  6.2458e-03,  1.8660e-02,\n",
       "                       3.5461e-03,  1.0799e-02,  7.1723e-03,  3.1934e-03, -5.3938e-04,\n",
       "                       1.2567e-02,  8.5068e-04, -2.5023e-02,  9.1758e-03,  1.7066e-02,\n",
       "                      -3.0497e-02,  1.2168e-02,  1.9033e-02, -2.2422e-05],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.14.convs.0.1.running_mean',\n",
       "              tensor([ 0.2129,  0.2392, -1.1709, -0.6569,  0.6296,  0.4536,  0.7904, -0.3640,\n",
       "                      -0.4672,  0.1389, -0.8530, -0.1185, -0.3664, -1.0939, -0.2134, -1.0852,\n",
       "                       0.5117, -0.8136,  1.6629,  0.2476,  1.2363,  0.6140, -0.6228, -0.2199,\n",
       "                      -0.3268,  0.9550, -0.1406, -0.4663,  0.1587,  0.0172,  1.3006, -0.3817,\n",
       "                      -0.4664,  0.7236,  0.5750, -0.4993, -0.0993, -0.8862, -0.1513,  0.3100,\n",
       "                      -1.2171, -0.6683,  0.8378,  0.4937, -0.3231,  0.1375, -0.4551, -0.1724,\n",
       "                       0.4359, -0.8960, -1.3968, -1.1370, -0.2018,  0.9186,  0.7014, -0.6626,\n",
       "                      -0.4704, -0.6797, -0.0240, -0.3629,  0.6358,  0.0805, -0.3016,  0.0126],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.14.convs.0.1.running_var',\n",
       "              tensor([0.3306, 0.1077, 0.4177, 0.1389, 0.1597, 0.5041, 1.3595, 0.2186, 0.3781,\n",
       "                      0.3793, 0.1629, 0.1123, 0.2050, 0.1850, 0.3898, 0.5976, 0.4065, 0.1767,\n",
       "                      1.5156, 0.1501, 0.6881, 0.3413, 1.1223, 0.1513, 0.3041, 0.3005, 0.2007,\n",
       "                      0.1332, 0.3814, 0.2054, 0.7908, 0.1311, 0.1745, 0.1647, 1.3914, 0.1646,\n",
       "                      0.1488, 0.6938, 0.1662, 0.2469, 0.6444, 0.3518, 0.4422, 0.9674, 0.2048,\n",
       "                      0.3099, 0.1459, 0.1890, 0.2512, 0.5993, 1.0015, 0.2166, 0.2218, 0.8162,\n",
       "                      0.1848, 0.2734, 0.5868, 0.1937, 0.2838, 0.1613, 0.2925, 0.1126, 0.1627,\n",
       "                      0.6123], dtype=torch.float64)),\n",
       "             ('6.14.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.14.convs.1.0.weight',\n",
       "              tensor([[[ 0.0965,  0.0027,  0.0158, -0.0907,  0.1548],\n",
       "                       [-0.1032, -0.1144,  0.1827, -0.0500,  0.0275],\n",
       "                       [ 0.0792, -0.0748,  0.0143,  0.1289, -0.0517],\n",
       "                       ...,\n",
       "                       [ 0.0877,  0.1365,  0.0455,  0.0590,  0.0972],\n",
       "                       [-0.0907,  0.0410,  0.0856, -0.0269,  0.0983],\n",
       "                       [-0.0064, -0.1133, -0.0145,  0.0535, -0.0013]],\n",
       "              \n",
       "                      [[-0.1529,  0.1502, -0.1088, -0.0776,  0.0183],\n",
       "                       [ 0.0415, -0.0496, -0.1053,  0.0872,  0.0415],\n",
       "                       [ 0.1552,  0.1142, -0.1063,  0.0355, -0.0559],\n",
       "                       ...,\n",
       "                       [ 0.0871, -0.0404,  0.0049,  0.0624,  0.1225],\n",
       "                       [-0.0818, -0.0193,  0.0717,  0.0115,  0.0944],\n",
       "                       [ 0.0333, -0.0930,  0.0634,  0.0037,  0.0116]],\n",
       "              \n",
       "                      [[ 0.0925,  0.1481, -0.0174, -0.0291, -0.0894],\n",
       "                       [-0.0645, -0.0116,  0.0274, -0.1454, -0.0338],\n",
       "                       [ 0.0035,  0.0285, -0.0951,  0.0514,  0.0578],\n",
       "                       ...,\n",
       "                       [ 0.0320, -0.0762,  0.0013, -0.0643, -0.0345],\n",
       "                       [ 0.0373,  0.0079,  0.0203,  0.0493,  0.1449],\n",
       "                       [-0.0203, -0.0421,  0.1473,  0.0083, -0.1305]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0161, -0.0244, -0.1655, -0.0218,  0.1213],\n",
       "                       [-0.2903,  0.0705, -0.0137,  0.0375,  0.0728],\n",
       "                       [ 0.0028, -0.0110,  0.0097, -0.0485,  0.0141],\n",
       "                       ...,\n",
       "                       [-0.0646,  0.0741, -0.0873,  0.0861,  0.1458],\n",
       "                       [ 0.1155, -0.0252, -0.0417,  0.1304,  0.1073],\n",
       "                       [-0.0664,  0.0150, -0.0763,  0.0077,  0.0668]],\n",
       "              \n",
       "                      [[ 0.0353,  0.0042,  0.0699,  0.0042,  0.0006],\n",
       "                       [ 0.1006, -0.0051,  0.0168, -0.0949,  0.1144],\n",
       "                       [ 0.1709, -0.1775, -0.0006,  0.0008,  0.1779],\n",
       "                       ...,\n",
       "                       [-0.0090, -0.0200,  0.0384, -0.0250,  0.1623],\n",
       "                       [ 0.1357, -0.0239,  0.1576, -0.0031, -0.1411],\n",
       "                       [-0.1240, -0.0836, -0.0531, -0.0615, -0.0977]],\n",
       "              \n",
       "                      [[-0.0844, -0.1113, -0.0198, -0.0386, -0.1010],\n",
       "                       [-0.1122,  0.0376, -0.0720,  0.0822, -0.1421],\n",
       "                       [ 0.0275, -0.0589, -0.0085,  0.1507, -0.0030],\n",
       "                       ...,\n",
       "                       [-0.0825,  0.0495,  0.0048, -0.0400,  0.0203],\n",
       "                       [ 0.0429,  0.0005, -0.0535,  0.0248, -0.0261],\n",
       "                       [ 0.0547, -0.0310, -0.1147,  0.0737,  0.0346]]], dtype=torch.float64)),\n",
       "             ('6.14.convs.1.1.weight',\n",
       "              tensor([0.9698, 0.9703, 0.9649, 0.9486, 0.9362, 0.9595, 0.9669, 0.9414, 0.9611,\n",
       "                      0.9591, 0.9633, 0.9446, 0.9731, 0.9700, 0.9653, 0.9492, 0.9558, 0.9626,\n",
       "                      0.9676, 0.9507, 0.9657, 0.9799, 0.9484, 0.9752, 0.9727, 0.9715, 0.9593,\n",
       "                      0.9408, 0.9555, 0.9812, 0.9544, 0.9627, 0.9817, 0.9610, 0.9597, 0.9737,\n",
       "                      0.9680, 0.9588, 0.9682, 0.9636, 0.9483, 0.9568, 0.9483, 0.9734, 0.9330,\n",
       "                      0.9484, 0.9605, 0.9615, 0.9313, 0.9628, 0.9450, 0.9455, 0.9838, 0.9681,\n",
       "                      0.9748, 0.9480, 0.9543, 0.9572, 0.9508, 0.9481, 0.9556, 0.9635, 0.9715,\n",
       "                      0.9456], dtype=torch.float64)),\n",
       "             ('6.14.convs.1.1.bias',\n",
       "              tensor([-6.7622e-03, -6.6768e-03,  1.4336e-02, -2.0384e-03, -1.9962e-03,\n",
       "                      -1.9036e-02, -4.1224e-04,  4.3166e-03,  1.1551e-02,  1.2141e-02,\n",
       "                       1.3844e-02, -1.1620e-02, -2.3727e-03,  1.0230e-02, -1.4533e-02,\n",
       "                      -6.0496e-03,  2.7096e-03,  2.5620e-04,  2.4661e-03, -1.7885e-03,\n",
       "                      -6.3180e-03, -2.3844e-03,  6.6566e-03, -1.2616e-02,  1.7306e-03,\n",
       "                      -2.3083e-03,  1.5006e-02, -8.1094e-03, -1.4035e-02, -6.7148e-04,\n",
       "                      -1.0172e-02, -1.9230e-03, -1.5971e-03, -3.3683e-03, -1.2528e-02,\n",
       "                       2.6604e-02,  6.1867e-03, -1.7183e-02,  9.1226e-03,  2.6066e-03,\n",
       "                      -4.0264e-02, -2.2759e-02, -9.1506e-03,  1.8505e-02, -2.4043e-03,\n",
       "                      -8.5184e-03, -8.6515e-03,  1.6169e-02, -2.6693e-02, -6.8134e-05,\n",
       "                       3.5488e-03, -4.8545e-03, -7.9838e-03,  2.5749e-03,  4.9354e-03,\n",
       "                       2.1841e-03,  3.3992e-03, -4.5390e-03, -1.2006e-02,  8.6400e-03,\n",
       "                      -9.1348e-04, -4.6363e-04, -5.5802e-03, -2.2655e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.14.convs.1.1.running_mean',\n",
       "              tensor([ 2.1063e-01, -2.1963e-01,  2.9270e-01, -6.6521e-01, -6.5460e-01,\n",
       "                      -1.7141e-01, -3.9080e-01, -3.6882e-01,  1.6433e-01, -5.3185e-01,\n",
       "                      -3.2825e-01, -5.7722e-01,  9.5513e-02, -8.1703e-02, -8.0854e-01,\n",
       "                      -9.2183e-01, -1.0972e-01,  1.0362e+00, -8.0875e-01,  4.9838e-01,\n",
       "                      -3.1681e-01,  2.8013e-01,  1.7551e-01,  3.7642e-01, -7.6371e-01,\n",
       "                      -6.6375e-02,  1.9549e-01,  3.7953e-01, -1.0003e-01,  5.0503e-01,\n",
       "                       5.6529e-01,  4.9146e-01,  7.4374e-01, -3.5891e-01, -4.1658e-01,\n",
       "                      -2.9461e-01, -3.1656e-01,  5.1993e-01,  4.5903e-01,  9.1721e-01,\n",
       "                       7.4038e-01,  3.5792e-01,  1.7909e-01, -7.2803e-01, -6.5921e-01,\n",
       "                      -4.2045e-02,  5.5385e-01, -9.6556e-01,  1.9092e-01,  2.0352e-02,\n",
       "                       2.8835e-01, -2.1176e-01, -7.5625e-01,  4.1450e-01,  6.4818e-01,\n",
       "                      -2.6404e-01,  9.9570e-02,  2.7974e-01, -6.7690e-01, -3.7404e-02,\n",
       "                       1.9910e-01, -5.8474e-01,  9.5688e-04, -4.9329e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.14.convs.1.1.running_var',\n",
       "              tensor([0.4177, 0.4526, 0.3627, 0.5962, 0.6910, 0.3260, 0.4654, 0.4809, 0.5906,\n",
       "                      0.9024, 0.3876, 0.5065, 0.4418, 0.6332, 0.4221, 0.3128, 0.6325, 0.4747,\n",
       "                      0.3829, 0.5612, 0.4202, 0.3599, 0.4299, 0.3656, 0.4964, 0.8745, 0.4172,\n",
       "                      0.5539, 0.3451, 0.4637, 0.6000, 0.5498, 0.6517, 0.3863, 0.6199, 0.5757,\n",
       "                      0.4259, 1.6924, 0.3543, 0.4730, 0.6826, 0.5410, 0.6369, 0.4739, 0.3790,\n",
       "                      0.4693, 0.4901, 0.3365, 0.6446, 0.5219, 0.4454, 0.5427, 0.4177, 0.4721,\n",
       "                      0.4679, 0.6169, 0.6664, 0.3397, 0.5956, 0.3822, 1.1353, 0.6155, 0.2851,\n",
       "                      0.4379], dtype=torch.float64)),\n",
       "             ('6.14.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.14.convs.2.0.weight',\n",
       "              tensor([[[-0.1885],\n",
       "                       [ 0.0270],\n",
       "                       [ 0.2305],\n",
       "                       ...,\n",
       "                       [-0.1859],\n",
       "                       [-0.0906],\n",
       "                       [ 0.0640]],\n",
       "              \n",
       "                      [[-0.0146],\n",
       "                       [-0.1211],\n",
       "                       [ 0.0129],\n",
       "                       ...,\n",
       "                       [-0.0304],\n",
       "                       [ 0.0527],\n",
       "                       [-0.0866]],\n",
       "              \n",
       "                      [[-0.0934],\n",
       "                       [ 0.0120],\n",
       "                       [ 0.1071],\n",
       "                       ...,\n",
       "                       [-0.0665],\n",
       "                       [ 0.0911],\n",
       "                       [ 0.0802]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0100],\n",
       "                       [-0.2365],\n",
       "                       [-0.0050],\n",
       "                       ...,\n",
       "                       [-0.0709],\n",
       "                       [ 0.2043],\n",
       "                       [-0.0051]],\n",
       "              \n",
       "                      [[-0.1404],\n",
       "                       [-0.1385],\n",
       "                       [ 0.1909],\n",
       "                       ...,\n",
       "                       [ 0.1743],\n",
       "                       [-0.1109],\n",
       "                       [-0.1718]],\n",
       "              \n",
       "                      [[ 0.2084],\n",
       "                       [-0.1079],\n",
       "                       [-0.0063],\n",
       "                       ...,\n",
       "                       [ 0.0191],\n",
       "                       [ 0.1082],\n",
       "                       [-0.0130]]], dtype=torch.float64)),\n",
       "             ('6.14.convs.2.1.weight',\n",
       "              tensor([ 1.5736e-02, -7.2876e-03, -3.4539e-03,  7.4461e-03, -7.2907e-03,\n",
       "                       2.1321e-02,  1.5802e-02, -1.6684e-03,  2.2476e-02,  7.5699e-03,\n",
       "                      -1.2772e-02, -2.3367e-02,  2.1775e-02, -3.0274e-03,  2.0812e-03,\n",
       "                      -3.9827e-02,  1.0222e-02,  1.7974e-02, -2.8318e-02,  5.3611e-03,\n",
       "                      -1.4073e-02,  4.9689e-04,  1.3865e-02,  3.4198e-03, -1.9289e-02,\n",
       "                       4.3788e-03,  1.5074e-02, -8.6650e-04, -7.5729e-03,  4.1597e-03,\n",
       "                       1.8546e-02,  2.6312e-02,  8.4122e-03, -1.2805e-02,  2.3715e-03,\n",
       "                       2.2518e-02,  1.6254e-02,  1.8126e-03, -9.4583e-03,  2.7529e-02,\n",
       "                       2.1536e-02, -2.7798e-03,  6.9601e-03,  2.6775e-02, -1.0081e-02,\n",
       "                      -9.4782e-03,  2.9958e-02,  1.2145e-02, -1.7918e-02,  1.4826e-03,\n",
       "                       3.8331e-02, -1.7387e-02, -2.7409e-03,  9.5228e-03, -7.2281e-03,\n",
       "                       2.1282e-02, -6.6992e-03, -2.1436e-02,  1.6560e-02, -9.9812e-03,\n",
       "                      -6.4283e-03, -1.7930e-02,  8.5809e-06,  3.0234e-03,  3.3746e-02,\n",
       "                      -3.1131e-02, -1.2737e-02,  1.6249e-02, -1.7992e-02, -6.7936e-04,\n",
       "                       5.2887e-03,  1.7849e-02, -5.3674e-03,  2.5484e-02, -1.9273e-02,\n",
       "                       6.9146e-03,  5.3136e-03,  3.6484e-03,  2.0866e-02, -9.0841e-03,\n",
       "                      -7.9872e-03,  2.5644e-02,  3.5399e-02, -1.2316e-02,  1.7186e-02,\n",
       "                      -3.0739e-03,  2.9126e-02,  3.1144e-03,  7.7750e-03,  1.1417e-02,\n",
       "                      -1.1424e-02,  8.1994e-03, -6.1575e-05, -1.0525e-02,  4.2314e-03,\n",
       "                      -4.0809e-03,  1.0297e-02, -1.2589e-03,  1.9965e-02,  2.1586e-02,\n",
       "                      -2.9409e-03, -7.9447e-03,  1.6797e-02, -1.2828e-02, -1.6365e-02,\n",
       "                      -2.4021e-02, -3.3813e-02, -1.0140e-02, -1.3431e-02, -6.6214e-04,\n",
       "                       8.8033e-03, -2.2674e-03,  6.8517e-03, -2.1693e-02, -9.7868e-03,\n",
       "                       1.4110e-02,  1.3607e-02,  2.0425e-02, -2.1966e-02,  1.1143e-02,\n",
       "                       1.4850e-02,  1.1744e-02,  3.7157e-03,  2.5422e-02,  5.4570e-03,\n",
       "                      -2.3700e-03, -1.8784e-02, -1.7062e-02, -1.2266e-02,  1.4217e-02,\n",
       "                       6.8295e-03,  6.8180e-03, -1.3141e-02,  9.4746e-03, -9.8198e-03,\n",
       "                       9.8451e-03,  7.6225e-03, -7.9840e-04,  6.0248e-03, -1.2513e-02,\n",
       "                      -4.5429e-03,  1.9239e-03, -2.4311e-02,  5.9705e-03,  2.2080e-02,\n",
       "                       2.4998e-02,  1.4509e-02, -9.4550e-03,  3.1931e-02,  1.7518e-02,\n",
       "                       2.3306e-03, -3.3995e-02,  1.5254e-02,  2.3105e-02, -1.6452e-02,\n",
       "                       1.1688e-02, -1.0264e-02,  1.1572e-02, -2.1778e-02, -1.6071e-04,\n",
       "                      -1.4199e-02, -6.9624e-03, -1.3369e-02,  1.0611e-02, -3.2145e-02,\n",
       "                      -4.6487e-03,  1.1036e-02,  3.0410e-03,  4.7614e-03, -1.4272e-02,\n",
       "                      -3.7738e-02,  2.9097e-03,  2.1413e-02, -2.5720e-03, -9.5727e-03,\n",
       "                      -1.5675e-02, -2.1848e-02,  3.1626e-03,  3.4785e-02, -1.8398e-02,\n",
       "                      -3.2209e-02, -7.6526e-03, -2.0189e-02,  2.0382e-02, -1.6469e-02,\n",
       "                      -2.0120e-02, -6.0278e-04, -1.6347e-02, -1.2308e-02, -1.3368e-02,\n",
       "                       3.0702e-03,  6.7696e-03,  1.3789e-02,  7.5802e-03,  4.4226e-03,\n",
       "                       1.7069e-02,  5.1781e-03, -7.5791e-03, -2.8421e-02,  2.6106e-02,\n",
       "                      -2.1857e-02, -3.6030e-02, -4.0933e-03,  1.5411e-02,  3.3685e-02,\n",
       "                       1.0099e-02,  1.0357e-02, -6.4655e-03, -1.5033e-02, -3.0701e-03,\n",
       "                       4.3711e-03, -2.1394e-02,  1.1476e-02, -1.3979e-03,  1.2544e-02,\n",
       "                       1.3505e-03, -2.9370e-02, -6.9009e-03,  2.7346e-02,  1.4169e-03,\n",
       "                      -4.2313e-04,  3.2365e-03,  2.7603e-02, -1.4010e-02,  2.6882e-02,\n",
       "                      -3.7576e-03, -5.2766e-03, -9.5697e-03, -5.0745e-03, -1.4550e-02,\n",
       "                      -2.6532e-02, -2.4705e-02,  4.0987e-03,  3.1217e-02, -1.4942e-02,\n",
       "                      -7.1709e-03, -2.2050e-02, -4.2713e-03,  9.8033e-03, -1.9234e-02,\n",
       "                      -7.4559e-03, -1.4143e-02, -3.5966e-03, -9.9090e-03, -7.8588e-03,\n",
       "                       1.7008e-03, -2.7607e-03,  2.8645e-02,  4.9021e-03, -2.2649e-02,\n",
       "                      -1.9762e-03,  2.4631e-03, -2.3914e-02,  5.2466e-03,  1.7005e-02,\n",
       "                       1.8338e-02], dtype=torch.float64)),\n",
       "             ('6.14.convs.2.1.bias',\n",
       "              tensor([ 5.8337e-04,  8.7161e-03,  9.7822e-03,  1.4136e-02,  3.7749e-03,\n",
       "                       9.4440e-03,  6.9385e-03, -2.0490e-03,  1.3700e-02,  1.5831e-02,\n",
       "                       1.2665e-02, -6.8320e-03,  3.3390e-03, -5.0369e-03,  8.7464e-03,\n",
       "                       3.8034e-03,  2.5515e-02,  6.2206e-04,  9.5942e-03, -3.3557e-03,\n",
       "                      -6.7202e-03,  1.6262e-04,  5.0797e-03,  5.9981e-03,  7.7227e-03,\n",
       "                      -1.7456e-02,  1.3811e-03,  1.1715e-02,  9.7634e-03, -9.4234e-03,\n",
       "                      -2.5349e-03,  7.7975e-03, -1.6893e-03,  2.1533e-02,  3.4766e-03,\n",
       "                       1.5701e-02, -2.4168e-03,  1.5000e-02,  1.1390e-02,  1.1915e-02,\n",
       "                       1.8040e-03,  1.2340e-02, -1.0227e-02, -1.4714e-03,  6.8795e-03,\n",
       "                      -1.4375e-02,  1.4249e-02,  3.1333e-03, -1.3396e-02,  1.6570e-03,\n",
       "                       9.8685e-03,  3.8613e-03,  7.1221e-03,  1.7412e-02,  2.9498e-03,\n",
       "                       1.5352e-02,  9.4217e-03,  1.1719e-03,  1.2148e-02, -1.8754e-03,\n",
       "                       4.1562e-03, -2.5491e-03,  5.6550e-03,  8.8902e-03, -5.8815e-03,\n",
       "                       4.8627e-03, -1.0043e-02,  1.4669e-02,  1.3239e-02, -1.5225e-02,\n",
       "                       7.4269e-03,  3.0531e-03, -5.4918e-04, -8.1785e-03,  1.4100e-02,\n",
       "                       5.6879e-03, -1.5054e-04, -2.8871e-03,  2.1115e-03,  1.9573e-02,\n",
       "                       4.9192e-03, -9.7291e-03,  8.5289e-03,  4.1062e-03, -5.3416e-03,\n",
       "                       1.6770e-02,  8.9935e-04,  1.1899e-02,  1.4619e-02,  1.0834e-04,\n",
       "                       5.2395e-04,  1.0381e-02,  9.7955e-03, -8.5737e-05,  9.6237e-03,\n",
       "                      -8.5457e-03,  1.1372e-02,  4.9466e-03,  2.0507e-02,  8.5325e-03,\n",
       "                       2.2761e-02,  1.4413e-02,  4.6015e-03,  8.8327e-03,  1.6484e-03,\n",
       "                       2.6931e-03, -8.0282e-03,  8.6644e-03,  7.8472e-03,  4.6853e-03,\n",
       "                      -1.2644e-02, -9.6816e-03,  2.9948e-03,  2.0802e-02,  1.5601e-02,\n",
       "                       5.9147e-03,  5.1458e-03,  3.9814e-03,  5.4950e-03, -1.2381e-02,\n",
       "                       5.6668e-04,  1.1955e-02,  4.0694e-03,  5.7698e-04,  2.1172e-02,\n",
       "                       9.4442e-03,  6.8089e-03,  3.9312e-03,  8.8342e-03,  1.2765e-02,\n",
       "                       6.5112e-03,  5.3796e-03,  1.3433e-02,  5.1025e-03,  7.8809e-03,\n",
       "                      -1.4009e-02,  1.4142e-02,  3.3423e-03,  6.3470e-03, -1.4682e-03,\n",
       "                       1.3080e-02,  5.4408e-03,  1.6634e-02,  2.3801e-03, -7.3193e-03,\n",
       "                       1.2420e-02,  5.1028e-03, -1.0865e-04,  1.2648e-02,  8.4206e-03,\n",
       "                       7.8787e-03,  1.0547e-02,  5.6378e-03,  1.1991e-02,  1.2066e-02,\n",
       "                       3.8934e-03, -4.7506e-04,  9.3844e-03, -1.1138e-03, -1.0792e-02,\n",
       "                       5.2280e-03,  1.6871e-03, -3.5828e-03,  6.0369e-03,  1.2640e-02,\n",
       "                      -3.7089e-03, -1.3168e-02,  6.5984e-03,  6.6375e-03,  2.0516e-02,\n",
       "                       1.1960e-03, -1.4555e-04,  5.8167e-03,  1.4624e-02, -1.3613e-02,\n",
       "                       1.1293e-02,  3.2295e-03,  1.8230e-02,  1.6713e-03,  8.2045e-03,\n",
       "                      -3.3450e-04,  1.1495e-02, -6.2043e-03, -9.0849e-03,  1.2302e-02,\n",
       "                       8.0910e-03,  1.3837e-02,  1.0073e-02,  8.9927e-03,  8.0492e-03,\n",
       "                       6.4389e-03,  7.2144e-03,  6.1394e-03,  4.4872e-03, -1.7703e-03,\n",
       "                       1.0190e-02,  7.4669e-03,  2.2370e-03,  5.1278e-03,  1.1924e-02,\n",
       "                      -1.2104e-03,  2.3817e-02,  1.8197e-02,  1.8632e-02,  1.3702e-02,\n",
       "                      -1.2401e-03,  8.7114e-03, -1.0098e-02,  5.9039e-03,  1.3382e-02,\n",
       "                       4.3429e-03,  1.0475e-02,  3.8276e-03,  7.8336e-03,  7.9269e-03,\n",
       "                       3.9322e-03,  6.3476e-03,  1.6844e-02,  4.5460e-03,  4.3071e-03,\n",
       "                       1.5390e-02,  1.3315e-03,  2.0788e-03,  1.4203e-02,  2.2957e-03,\n",
       "                       6.7605e-03, -8.9227e-03, -2.0635e-03,  2.8109e-02,  1.7326e-02,\n",
       "                       2.8677e-03, -3.4123e-03,  9.7750e-03,  1.1292e-02,  2.0729e-03,\n",
       "                       9.3608e-03,  2.9421e-03,  1.3558e-02,  5.4997e-03,  7.3573e-03,\n",
       "                       2.0913e-03, -1.1360e-04, -2.1136e-03,  1.1646e-02,  2.4487e-03,\n",
       "                       7.4126e-03,  5.5638e-03,  4.9860e-03, -1.3606e-02, -1.1076e-02,\n",
       "                       2.1211e-02,  2.3833e-02,  1.8569e-02,  1.7618e-02,  2.3303e-03,\n",
       "                       3.9070e-03], dtype=torch.float64)),\n",
       "             ('6.14.convs.2.1.running_mean',\n",
       "              tensor([ 5.0026e-01,  9.3141e-02, -2.1251e-01,  7.3323e-01, -1.8499e-01,\n",
       "                      -4.0980e-01,  1.2514e-01, -1.4934e-01,  1.9726e-01,  1.0485e-01,\n",
       "                       2.5828e-01, -7.3974e-02, -2.1603e-01, -1.3170e-01, -3.0867e-01,\n",
       "                       4.3427e-01,  2.8073e-01,  1.5739e-01,  4.8902e-01, -2.1588e-01,\n",
       "                       8.9053e-02, -5.7797e-01,  7.6504e-01, -3.5310e-02,  6.9145e-01,\n",
       "                       4.4874e-01,  1.3136e-01,  7.8434e-02,  5.1857e-01, -1.8248e-01,\n",
       "                       3.4175e-01,  2.8422e-01,  1.8412e-02, -1.6209e-01, -4.4365e-01,\n",
       "                       8.4120e-02, -3.8192e-01, -1.6505e-01, -4.2522e-02,  1.7304e-01,\n",
       "                      -7.4047e-01, -1.6742e-01, -1.1923e-01, -5.9140e-01, -1.1016e+00,\n",
       "                       4.9109e-01,  5.0325e-01, -1.2081e-02,  2.4890e-01,  7.0643e-02,\n",
       "                       2.4532e-01, -8.6393e-02,  9.8280e-02, -2.6729e-01, -2.1211e-01,\n",
       "                       3.5975e-01,  8.5683e-02,  4.3402e-01,  2.8010e-01, -2.9853e-01,\n",
       "                       6.1529e-02, -9.9139e-02,  1.0229e-01,  3.1469e-01, -5.2147e-01,\n",
       "                      -6.9906e-03, -1.9800e-01,  7.6698e-02,  6.1234e-02, -1.2762e+00,\n",
       "                      -1.9253e-01, -4.1760e-01, -1.3152e-01, -4.3664e-01,  7.6436e-01,\n",
       "                       3.4946e-01, -4.4820e-01,  4.7770e-01,  2.0864e-02,  4.7338e-02,\n",
       "                       2.9022e-01, -2.2126e-01, -4.7634e-01,  1.5849e-01,  1.0436e-01,\n",
       "                      -8.9968e-02,  4.5607e-02,  2.8470e-01, -1.7707e-01, -1.2997e-01,\n",
       "                      -1.0082e+00,  2.5810e-01,  2.5660e-01,  2.5079e-01, -2.5922e-01,\n",
       "                      -1.2112e-01, -4.0944e-01, -1.3710e-01,  1.6557e-01, -4.5737e-01,\n",
       "                      -6.8667e-01, -4.4445e-01,  1.4642e-01,  2.1788e-01, -1.4625e-01,\n",
       "                      -3.7751e-01, -4.6903e-01,  5.5947e-02,  3.8867e-01, -1.6644e-01,\n",
       "                       1.4560e-01, -2.4786e-01,  1.0550e-01,  3.7704e-01, -4.2315e-01,\n",
       "                      -5.7592e-01, -7.8602e-01, -2.8560e-01,  8.0650e-01, -4.8573e-01,\n",
       "                       1.6206e-01, -2.9149e-01, -6.0742e-02,  4.8892e-01, -3.8435e-02,\n",
       "                       3.1146e-01, -3.5359e-01,  1.6058e-01,  3.4355e-01, -4.3201e-02,\n",
       "                       4.3305e-01,  3.2971e-01,  9.0624e-01,  3.6702e-01, -3.1481e-01,\n",
       "                       3.0116e-01, -8.4463e-03, -5.2434e-02, -3.1924e-01, -1.8818e-01,\n",
       "                      -1.3858e-02, -1.0314e-02, -9.2277e-01, -8.2794e-02, -7.0564e-02,\n",
       "                      -4.8139e-01,  2.4116e-01, -4.7562e-01,  1.7412e-01,  5.9401e-01,\n",
       "                       2.7586e-01, -2.6760e-02, -4.4510e-01, -4.8671e-01, -2.7432e-01,\n",
       "                      -2.1863e-01,  1.5691e-01, -2.3646e-01, -9.0933e-02, -3.8486e-01,\n",
       "                      -3.2732e-01,  4.2269e-01,  3.9178e-01,  5.2351e-02,  7.1855e-03,\n",
       "                       4.2797e-01, -1.2154e+00, -3.6851e-01, -5.9731e-02,  1.2184e-01,\n",
       "                       4.3613e-01,  5.0065e-01,  9.4921e-01, -7.7080e-01, -1.0948e-01,\n",
       "                      -3.6581e-01,  8.3944e-01,  3.3255e-01, -3.9562e-01, -5.1363e-01,\n",
       "                      -7.6535e-01, -2.2918e-01, -7.8139e-02,  1.6849e-01,  6.7955e-01,\n",
       "                       9.9292e-01,  4.4483e-01, -2.8233e-01,  3.2044e-01,  2.5445e-01,\n",
       "                      -2.1611e-01, -5.3334e-02,  8.7077e-01,  1.1670e-01,  2.2550e-01,\n",
       "                       9.0622e-02,  4.5673e-01,  1.8207e-01,  4.9145e-01,  2.3715e-01,\n",
       "                       4.5510e-01, -4.6668e-02,  1.5837e-01, -3.9190e-01,  1.7196e-01,\n",
       "                       8.7218e-01,  8.0817e-02, -2.9992e-01, -6.6255e-01,  5.9850e-02,\n",
       "                      -3.1378e-02, -7.1788e-01,  4.2144e-01,  4.7466e-01, -2.2126e-01,\n",
       "                       7.9035e-02,  1.4773e-02, -2.4681e-01, -2.1436e-02,  1.0557e-01,\n",
       "                       3.3052e-01, -2.9865e-01,  4.3637e-01, -4.8127e-01, -5.3196e-01,\n",
       "                      -1.0230e-01, -2.1043e-01,  4.1143e-02, -9.9736e-02, -2.4837e-01,\n",
       "                      -2.5516e-01,  2.7657e-01, -1.2699e-01,  1.7097e-01,  4.5303e-02,\n",
       "                      -7.3056e-01,  1.2212e-01, -5.1471e-02,  3.1733e-01, -2.7648e-02,\n",
       "                       1.9847e-01, -2.8087e-01,  1.3055e-01, -3.4334e-01, -7.2076e-04,\n",
       "                       2.7705e-01,  1.5380e-02,  5.0412e-01,  8.5264e-01,  1.5978e-01,\n",
       "                       2.0322e-01,  9.0154e-02,  3.0661e-01, -2.7637e-01,  1.2074e-03,\n",
       "                       2.6530e-01], dtype=torch.float64)),\n",
       "             ('6.14.convs.2.1.running_var',\n",
       "              tensor([0.3715, 0.2850, 0.3478, 0.6129, 0.3449, 0.3169, 0.2080, 0.2719, 0.3345,\n",
       "                      0.3922, 0.2698, 0.4366, 0.1643, 0.2938, 0.4986, 0.4152, 0.4012, 0.3607,\n",
       "                      0.3374, 0.3843, 0.5034, 0.3836, 0.2638, 0.2955, 0.4505, 0.1834, 0.6964,\n",
       "                      0.0738, 0.1925, 0.4188, 0.3754, 0.2805, 0.2274, 0.3307, 0.0808, 0.3544,\n",
       "                      0.1543, 0.1195, 0.2069, 0.5901, 0.3454, 0.3223, 0.1130, 0.3981, 0.4202,\n",
       "                      0.3063, 0.3851, 0.3600, 0.6541, 0.2812, 0.3708, 0.3684, 0.2055, 0.2753,\n",
       "                      0.5789, 0.4541, 0.2016, 0.6917, 0.3962, 0.3877, 0.2105, 0.3840, 0.2467,\n",
       "                      0.0974, 0.3916, 0.4618, 0.3229, 0.3511, 0.2895, 0.5606, 0.3120, 0.2043,\n",
       "                      0.1807, 0.2994, 0.6415, 0.0809, 0.3251, 0.2179, 0.4529, 0.1188, 0.1767,\n",
       "                      0.5147, 0.4899, 0.4587, 0.3688, 0.2789, 0.2846, 0.3584, 0.5212, 0.1543,\n",
       "                      0.5261, 0.0725, 0.1197, 0.5237, 0.1523, 0.1955, 0.5306, 0.0943, 0.2411,\n",
       "                      0.3187, 0.3282, 0.3035, 0.3690, 0.1920, 0.1522, 0.3096, 0.5753, 0.3035,\n",
       "                      0.3711, 0.0669, 0.2502, 0.1947, 0.2682, 0.2303, 0.4490, 0.6046, 0.3999,\n",
       "                      0.2405, 0.5596, 0.5948, 0.3013, 0.3441, 0.2598, 0.3294, 0.1480, 0.4248,\n",
       "                      0.3442, 0.2619, 0.2029, 0.3976, 0.1121, 0.2037, 0.3916, 0.3200, 0.3491,\n",
       "                      0.1539, 0.2194, 0.1420, 0.1775, 0.2977, 0.2182, 0.2346, 0.3621, 0.1361,\n",
       "                      0.1920, 0.3043, 0.1175, 0.3965, 0.1517, 0.4139, 0.2431, 0.2734, 0.3780,\n",
       "                      0.4685, 0.4891, 0.5140, 0.3274, 0.2088, 0.2440, 0.1464, 0.3099, 0.1424,\n",
       "                      0.3065, 0.1068, 0.4195, 0.2866, 0.3903, 0.1936, 0.3266, 0.4546, 0.3739,\n",
       "                      0.0965, 0.4264, 0.2683, 0.3809, 0.5158, 0.3613, 0.1242, 0.4777, 0.2961,\n",
       "                      0.5248, 0.1413, 0.3295, 0.2300, 0.5278, 0.4805, 0.3406, 0.2826, 0.3727,\n",
       "                      0.2331, 0.2419, 0.3833, 0.4922, 0.3249, 0.3030, 0.2729, 0.3098, 0.3590,\n",
       "                      0.4502, 0.5565, 0.4356, 0.3420, 0.1291, 0.4557, 0.3998, 0.3618, 0.2300,\n",
       "                      0.0615, 0.3368, 0.4447, 0.0690, 0.4648, 0.3062, 0.2253, 0.1868, 0.1201,\n",
       "                      0.5601, 0.2608, 0.3905, 0.2948, 0.1460, 0.0878, 0.3208, 0.3119, 0.4130,\n",
       "                      0.2110, 0.2469, 0.1339, 0.2769, 0.7031, 0.5923, 0.4617, 0.1750, 0.2574,\n",
       "                      0.1978, 0.3139, 0.2984, 0.1729, 0.4170, 0.2989, 0.1676, 0.1521, 0.3499,\n",
       "                      0.2030, 0.3443, 0.1467, 0.1355, 0.3351, 0.3515, 0.4910, 0.2412, 0.4063,\n",
       "                      0.4572, 0.3446, 0.2855, 0.3754], dtype=torch.float64)),\n",
       "             ('6.14.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.14.convpath.0.0.0.weight',\n",
       "              tensor([[[ 7.6561e-02],\n",
       "                       [-1.5895e-02],\n",
       "                       [ 4.6714e-03],\n",
       "                       ...,\n",
       "                       [ 7.2812e-02],\n",
       "                       [-4.8927e-02],\n",
       "                       [ 3.2493e-02]],\n",
       "              \n",
       "                      [[ 4.4624e-02],\n",
       "                       [ 5.0613e-02],\n",
       "                       [ 4.2176e-02],\n",
       "                       ...,\n",
       "                       [-1.4014e-01],\n",
       "                       [-6.9230e-03],\n",
       "                       [-5.6085e-02]],\n",
       "              \n",
       "                      [[ 1.2783e-01],\n",
       "                       [ 8.1154e-03],\n",
       "                       [ 3.1433e-02],\n",
       "                       ...,\n",
       "                       [-1.7322e-01],\n",
       "                       [ 1.1900e-01],\n",
       "                       [-6.8969e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.6158e-02],\n",
       "                       [-1.1034e-02],\n",
       "                       [-3.3664e-02],\n",
       "                       ...,\n",
       "                       [-1.9662e-02],\n",
       "                       [ 4.7206e-02],\n",
       "                       [ 3.1625e-03]],\n",
       "              \n",
       "                      [[-5.6436e-02],\n",
       "                       [-8.1698e-02],\n",
       "                       [ 7.1369e-02],\n",
       "                       ...,\n",
       "                       [-1.7726e-01],\n",
       "                       [-9.1429e-02],\n",
       "                       [ 3.2624e-02]],\n",
       "              \n",
       "                      [[-6.5344e-02],\n",
       "                       [ 1.0106e-02],\n",
       "                       [-1.5147e-02],\n",
       "                       ...,\n",
       "                       [ 1.0679e-04],\n",
       "                       [ 5.1660e-02],\n",
       "                       [ 8.7525e-03]]], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.0.1.weight',\n",
       "              tensor([0.9525, 0.9719, 0.9757, 0.9917, 0.9495, 0.9690, 0.9585, 0.9789, 0.9811,\n",
       "                      0.9651, 0.9550, 0.9889, 0.9799, 0.9561, 0.9831, 0.9410, 0.9689, 0.9640,\n",
       "                      0.9759, 0.9656, 0.9825, 0.9566, 0.9243, 0.9800, 0.9463, 0.9699, 0.9652,\n",
       "                      0.9994, 0.9620, 0.9709, 0.9481, 0.9862, 0.9583, 0.9638, 0.9481, 0.9662,\n",
       "                      0.9901, 0.9453, 0.9737, 0.9776, 0.9759, 0.9536, 0.9683, 0.9756, 0.9553,\n",
       "                      0.9489, 0.9587, 0.9524, 0.9730, 0.9627, 0.9534, 0.9626, 0.9703, 0.9718,\n",
       "                      0.9527, 0.9480, 0.9544, 0.9452, 0.9480, 0.9887, 0.9504, 0.9842, 0.9855,\n",
       "                      0.9604], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.0.1.bias',\n",
       "              tensor([-1.4633e-02,  3.6452e-03,  2.0481e-02, -1.3261e-03, -2.3015e-02,\n",
       "                       2.3452e-02,  7.9624e-03,  2.9815e-02,  1.2440e-02,  5.1935e-03,\n",
       "                      -4.2705e-03,  1.5624e-02,  1.1480e-02, -1.2509e-02,  1.7098e-02,\n",
       "                      -1.4460e-03, -9.4927e-03, -8.7487e-04, -1.0514e-02,  9.4479e-03,\n",
       "                       1.7121e-02, -1.1738e-02, -8.5928e-03,  2.8503e-02,  1.0380e-02,\n",
       "                      -5.1002e-03,  1.3708e-02,  1.9667e-02, -1.7578e-02,  2.0791e-02,\n",
       "                      -2.2950e-02,  2.1195e-02, -1.1251e-02, -1.2482e-03, -5.9303e-03,\n",
       "                       6.1032e-04,  2.0373e-02,  8.4859e-03,  1.6992e-03, -2.0250e-02,\n",
       "                       2.9656e-02,  4.4756e-03,  5.3999e-03, -5.7733e-03, -9.2714e-03,\n",
       "                      -3.1791e-03,  9.3408e-03, -1.1724e-02,  6.2458e-03,  1.8660e-02,\n",
       "                       3.5461e-03,  1.0799e-02,  7.1723e-03,  3.1934e-03, -5.3938e-04,\n",
       "                       1.2567e-02,  8.5068e-04, -2.5023e-02,  9.1758e-03,  1.7066e-02,\n",
       "                      -3.0497e-02,  1.2168e-02,  1.9033e-02, -2.2422e-05],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.2129,  0.2392, -1.1709, -0.6569,  0.6296,  0.4536,  0.7904, -0.3640,\n",
       "                      -0.4672,  0.1389, -0.8530, -0.1185, -0.3664, -1.0939, -0.2134, -1.0852,\n",
       "                       0.5117, -0.8136,  1.6629,  0.2476,  1.2363,  0.6140, -0.6228, -0.2199,\n",
       "                      -0.3268,  0.9550, -0.1406, -0.4663,  0.1587,  0.0172,  1.3006, -0.3817,\n",
       "                      -0.4664,  0.7236,  0.5750, -0.4993, -0.0993, -0.8862, -0.1513,  0.3100,\n",
       "                      -1.2171, -0.6683,  0.8378,  0.4937, -0.3231,  0.1375, -0.4551, -0.1724,\n",
       "                       0.4359, -0.8960, -1.3968, -1.1370, -0.2018,  0.9186,  0.7014, -0.6626,\n",
       "                      -0.4704, -0.6797, -0.0240, -0.3629,  0.6358,  0.0805, -0.3016,  0.0126],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.0.1.running_var',\n",
       "              tensor([0.3306, 0.1077, 0.4177, 0.1389, 0.1597, 0.5041, 1.3595, 0.2186, 0.3781,\n",
       "                      0.3793, 0.1629, 0.1123, 0.2050, 0.1850, 0.3898, 0.5976, 0.4065, 0.1767,\n",
       "                      1.5156, 0.1501, 0.6881, 0.3413, 1.1223, 0.1513, 0.3041, 0.3005, 0.2007,\n",
       "                      0.1332, 0.3814, 0.2054, 0.7908, 0.1311, 0.1745, 0.1647, 1.3914, 0.1646,\n",
       "                      0.1488, 0.6938, 0.1662, 0.2469, 0.6444, 0.3518, 0.4422, 0.9674, 0.2048,\n",
       "                      0.3099, 0.1459, 0.1890, 0.2512, 0.5993, 1.0015, 0.2166, 0.2218, 0.8162,\n",
       "                      0.1848, 0.2734, 0.5868, 0.1937, 0.2838, 0.1613, 0.2925, 0.1126, 0.1627,\n",
       "                      0.6123], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.14.convpath.0.1.0.weight',\n",
       "              tensor([[[ 0.0965,  0.0027,  0.0158, -0.0907,  0.1548],\n",
       "                       [-0.1032, -0.1144,  0.1827, -0.0500,  0.0275],\n",
       "                       [ 0.0792, -0.0748,  0.0143,  0.1289, -0.0517],\n",
       "                       ...,\n",
       "                       [ 0.0877,  0.1365,  0.0455,  0.0590,  0.0972],\n",
       "                       [-0.0907,  0.0410,  0.0856, -0.0269,  0.0983],\n",
       "                       [-0.0064, -0.1133, -0.0145,  0.0535, -0.0013]],\n",
       "              \n",
       "                      [[-0.1529,  0.1502, -0.1088, -0.0776,  0.0183],\n",
       "                       [ 0.0415, -0.0496, -0.1053,  0.0872,  0.0415],\n",
       "                       [ 0.1552,  0.1142, -0.1063,  0.0355, -0.0559],\n",
       "                       ...,\n",
       "                       [ 0.0871, -0.0404,  0.0049,  0.0624,  0.1225],\n",
       "                       [-0.0818, -0.0193,  0.0717,  0.0115,  0.0944],\n",
       "                       [ 0.0333, -0.0930,  0.0634,  0.0037,  0.0116]],\n",
       "              \n",
       "                      [[ 0.0925,  0.1481, -0.0174, -0.0291, -0.0894],\n",
       "                       [-0.0645, -0.0116,  0.0274, -0.1454, -0.0338],\n",
       "                       [ 0.0035,  0.0285, -0.0951,  0.0514,  0.0578],\n",
       "                       ...,\n",
       "                       [ 0.0320, -0.0762,  0.0013, -0.0643, -0.0345],\n",
       "                       [ 0.0373,  0.0079,  0.0203,  0.0493,  0.1449],\n",
       "                       [-0.0203, -0.0421,  0.1473,  0.0083, -0.1305]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0161, -0.0244, -0.1655, -0.0218,  0.1213],\n",
       "                       [-0.2903,  0.0705, -0.0137,  0.0375,  0.0728],\n",
       "                       [ 0.0028, -0.0110,  0.0097, -0.0485,  0.0141],\n",
       "                       ...,\n",
       "                       [-0.0646,  0.0741, -0.0873,  0.0861,  0.1458],\n",
       "                       [ 0.1155, -0.0252, -0.0417,  0.1304,  0.1073],\n",
       "                       [-0.0664,  0.0150, -0.0763,  0.0077,  0.0668]],\n",
       "              \n",
       "                      [[ 0.0353,  0.0042,  0.0699,  0.0042,  0.0006],\n",
       "                       [ 0.1006, -0.0051,  0.0168, -0.0949,  0.1144],\n",
       "                       [ 0.1709, -0.1775, -0.0006,  0.0008,  0.1779],\n",
       "                       ...,\n",
       "                       [-0.0090, -0.0200,  0.0384, -0.0250,  0.1623],\n",
       "                       [ 0.1357, -0.0239,  0.1576, -0.0031, -0.1411],\n",
       "                       [-0.1240, -0.0836, -0.0531, -0.0615, -0.0977]],\n",
       "              \n",
       "                      [[-0.0844, -0.1113, -0.0198, -0.0386, -0.1010],\n",
       "                       [-0.1122,  0.0376, -0.0720,  0.0822, -0.1421],\n",
       "                       [ 0.0275, -0.0589, -0.0085,  0.1507, -0.0030],\n",
       "                       ...,\n",
       "                       [-0.0825,  0.0495,  0.0048, -0.0400,  0.0203],\n",
       "                       [ 0.0429,  0.0005, -0.0535,  0.0248, -0.0261],\n",
       "                       [ 0.0547, -0.0310, -0.1147,  0.0737,  0.0346]]], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.1.1.weight',\n",
       "              tensor([0.9698, 0.9703, 0.9649, 0.9486, 0.9362, 0.9595, 0.9669, 0.9414, 0.9611,\n",
       "                      0.9591, 0.9633, 0.9446, 0.9731, 0.9700, 0.9653, 0.9492, 0.9558, 0.9626,\n",
       "                      0.9676, 0.9507, 0.9657, 0.9799, 0.9484, 0.9752, 0.9727, 0.9715, 0.9593,\n",
       "                      0.9408, 0.9555, 0.9812, 0.9544, 0.9627, 0.9817, 0.9610, 0.9597, 0.9737,\n",
       "                      0.9680, 0.9588, 0.9682, 0.9636, 0.9483, 0.9568, 0.9483, 0.9734, 0.9330,\n",
       "                      0.9484, 0.9605, 0.9615, 0.9313, 0.9628, 0.9450, 0.9455, 0.9838, 0.9681,\n",
       "                      0.9748, 0.9480, 0.9543, 0.9572, 0.9508, 0.9481, 0.9556, 0.9635, 0.9715,\n",
       "                      0.9456], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.1.1.bias',\n",
       "              tensor([-6.7622e-03, -6.6768e-03,  1.4336e-02, -2.0384e-03, -1.9962e-03,\n",
       "                      -1.9036e-02, -4.1224e-04,  4.3166e-03,  1.1551e-02,  1.2141e-02,\n",
       "                       1.3844e-02, -1.1620e-02, -2.3727e-03,  1.0230e-02, -1.4533e-02,\n",
       "                      -6.0496e-03,  2.7096e-03,  2.5620e-04,  2.4661e-03, -1.7885e-03,\n",
       "                      -6.3180e-03, -2.3844e-03,  6.6566e-03, -1.2616e-02,  1.7306e-03,\n",
       "                      -2.3083e-03,  1.5006e-02, -8.1094e-03, -1.4035e-02, -6.7148e-04,\n",
       "                      -1.0172e-02, -1.9230e-03, -1.5971e-03, -3.3683e-03, -1.2528e-02,\n",
       "                       2.6604e-02,  6.1867e-03, -1.7183e-02,  9.1226e-03,  2.6066e-03,\n",
       "                      -4.0264e-02, -2.2759e-02, -9.1506e-03,  1.8505e-02, -2.4043e-03,\n",
       "                      -8.5184e-03, -8.6515e-03,  1.6169e-02, -2.6693e-02, -6.8134e-05,\n",
       "                       3.5488e-03, -4.8545e-03, -7.9838e-03,  2.5749e-03,  4.9354e-03,\n",
       "                       2.1841e-03,  3.3992e-03, -4.5390e-03, -1.2006e-02,  8.6400e-03,\n",
       "                      -9.1348e-04, -4.6363e-04, -5.5802e-03, -2.2655e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.1.1.running_mean',\n",
       "              tensor([ 2.1063e-01, -2.1963e-01,  2.9270e-01, -6.6521e-01, -6.5460e-01,\n",
       "                      -1.7141e-01, -3.9080e-01, -3.6882e-01,  1.6433e-01, -5.3185e-01,\n",
       "                      -3.2825e-01, -5.7722e-01,  9.5513e-02, -8.1703e-02, -8.0854e-01,\n",
       "                      -9.2183e-01, -1.0972e-01,  1.0362e+00, -8.0875e-01,  4.9838e-01,\n",
       "                      -3.1681e-01,  2.8013e-01,  1.7551e-01,  3.7642e-01, -7.6371e-01,\n",
       "                      -6.6375e-02,  1.9549e-01,  3.7953e-01, -1.0003e-01,  5.0503e-01,\n",
       "                       5.6529e-01,  4.9146e-01,  7.4374e-01, -3.5891e-01, -4.1658e-01,\n",
       "                      -2.9461e-01, -3.1656e-01,  5.1993e-01,  4.5903e-01,  9.1721e-01,\n",
       "                       7.4038e-01,  3.5792e-01,  1.7909e-01, -7.2803e-01, -6.5921e-01,\n",
       "                      -4.2045e-02,  5.5385e-01, -9.6556e-01,  1.9092e-01,  2.0352e-02,\n",
       "                       2.8835e-01, -2.1176e-01, -7.5625e-01,  4.1450e-01,  6.4818e-01,\n",
       "                      -2.6404e-01,  9.9570e-02,  2.7974e-01, -6.7690e-01, -3.7404e-02,\n",
       "                       1.9910e-01, -5.8474e-01,  9.5688e-04, -4.9329e-01],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.1.1.running_var',\n",
       "              tensor([0.4177, 0.4526, 0.3627, 0.5962, 0.6910, 0.3260, 0.4654, 0.4809, 0.5906,\n",
       "                      0.9024, 0.3876, 0.5065, 0.4418, 0.6332, 0.4221, 0.3128, 0.6325, 0.4747,\n",
       "                      0.3829, 0.5612, 0.4202, 0.3599, 0.4299, 0.3656, 0.4964, 0.8745, 0.4172,\n",
       "                      0.5539, 0.3451, 0.4637, 0.6000, 0.5498, 0.6517, 0.3863, 0.6199, 0.5757,\n",
       "                      0.4259, 1.6924, 0.3543, 0.4730, 0.6826, 0.5410, 0.6369, 0.4739, 0.3790,\n",
       "                      0.4693, 0.4901, 0.3365, 0.6446, 0.5219, 0.4454, 0.5427, 0.4177, 0.4721,\n",
       "                      0.4679, 0.6169, 0.6664, 0.3397, 0.5956, 0.3822, 1.1353, 0.6155, 0.2851,\n",
       "                      0.4379], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.14.convpath.0.2.0.weight',\n",
       "              tensor([[[-0.1885],\n",
       "                       [ 0.0270],\n",
       "                       [ 0.2305],\n",
       "                       ...,\n",
       "                       [-0.1859],\n",
       "                       [-0.0906],\n",
       "                       [ 0.0640]],\n",
       "              \n",
       "                      [[-0.0146],\n",
       "                       [-0.1211],\n",
       "                       [ 0.0129],\n",
       "                       ...,\n",
       "                       [-0.0304],\n",
       "                       [ 0.0527],\n",
       "                       [-0.0866]],\n",
       "              \n",
       "                      [[-0.0934],\n",
       "                       [ 0.0120],\n",
       "                       [ 0.1071],\n",
       "                       ...,\n",
       "                       [-0.0665],\n",
       "                       [ 0.0911],\n",
       "                       [ 0.0802]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0100],\n",
       "                       [-0.2365],\n",
       "                       [-0.0050],\n",
       "                       ...,\n",
       "                       [-0.0709],\n",
       "                       [ 0.2043],\n",
       "                       [-0.0051]],\n",
       "              \n",
       "                      [[-0.1404],\n",
       "                       [-0.1385],\n",
       "                       [ 0.1909],\n",
       "                       ...,\n",
       "                       [ 0.1743],\n",
       "                       [-0.1109],\n",
       "                       [-0.1718]],\n",
       "              \n",
       "                      [[ 0.2084],\n",
       "                       [-0.1079],\n",
       "                       [-0.0063],\n",
       "                       ...,\n",
       "                       [ 0.0191],\n",
       "                       [ 0.1082],\n",
       "                       [-0.0130]]], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.2.1.weight',\n",
       "              tensor([ 1.5736e-02, -7.2876e-03, -3.4539e-03,  7.4461e-03, -7.2907e-03,\n",
       "                       2.1321e-02,  1.5802e-02, -1.6684e-03,  2.2476e-02,  7.5699e-03,\n",
       "                      -1.2772e-02, -2.3367e-02,  2.1775e-02, -3.0274e-03,  2.0812e-03,\n",
       "                      -3.9827e-02,  1.0222e-02,  1.7974e-02, -2.8318e-02,  5.3611e-03,\n",
       "                      -1.4073e-02,  4.9689e-04,  1.3865e-02,  3.4198e-03, -1.9289e-02,\n",
       "                       4.3788e-03,  1.5074e-02, -8.6650e-04, -7.5729e-03,  4.1597e-03,\n",
       "                       1.8546e-02,  2.6312e-02,  8.4122e-03, -1.2805e-02,  2.3715e-03,\n",
       "                       2.2518e-02,  1.6254e-02,  1.8126e-03, -9.4583e-03,  2.7529e-02,\n",
       "                       2.1536e-02, -2.7798e-03,  6.9601e-03,  2.6775e-02, -1.0081e-02,\n",
       "                      -9.4782e-03,  2.9958e-02,  1.2145e-02, -1.7918e-02,  1.4826e-03,\n",
       "                       3.8331e-02, -1.7387e-02, -2.7409e-03,  9.5228e-03, -7.2281e-03,\n",
       "                       2.1282e-02, -6.6992e-03, -2.1436e-02,  1.6560e-02, -9.9812e-03,\n",
       "                      -6.4283e-03, -1.7930e-02,  8.5809e-06,  3.0234e-03,  3.3746e-02,\n",
       "                      -3.1131e-02, -1.2737e-02,  1.6249e-02, -1.7992e-02, -6.7936e-04,\n",
       "                       5.2887e-03,  1.7849e-02, -5.3674e-03,  2.5484e-02, -1.9273e-02,\n",
       "                       6.9146e-03,  5.3136e-03,  3.6484e-03,  2.0866e-02, -9.0841e-03,\n",
       "                      -7.9872e-03,  2.5644e-02,  3.5399e-02, -1.2316e-02,  1.7186e-02,\n",
       "                      -3.0739e-03,  2.9126e-02,  3.1144e-03,  7.7750e-03,  1.1417e-02,\n",
       "                      -1.1424e-02,  8.1994e-03, -6.1575e-05, -1.0525e-02,  4.2314e-03,\n",
       "                      -4.0809e-03,  1.0297e-02, -1.2589e-03,  1.9965e-02,  2.1586e-02,\n",
       "                      -2.9409e-03, -7.9447e-03,  1.6797e-02, -1.2828e-02, -1.6365e-02,\n",
       "                      -2.4021e-02, -3.3813e-02, -1.0140e-02, -1.3431e-02, -6.6214e-04,\n",
       "                       8.8033e-03, -2.2674e-03,  6.8517e-03, -2.1693e-02, -9.7868e-03,\n",
       "                       1.4110e-02,  1.3607e-02,  2.0425e-02, -2.1966e-02,  1.1143e-02,\n",
       "                       1.4850e-02,  1.1744e-02,  3.7157e-03,  2.5422e-02,  5.4570e-03,\n",
       "                      -2.3700e-03, -1.8784e-02, -1.7062e-02, -1.2266e-02,  1.4217e-02,\n",
       "                       6.8295e-03,  6.8180e-03, -1.3141e-02,  9.4746e-03, -9.8198e-03,\n",
       "                       9.8451e-03,  7.6225e-03, -7.9840e-04,  6.0248e-03, -1.2513e-02,\n",
       "                      -4.5429e-03,  1.9239e-03, -2.4311e-02,  5.9705e-03,  2.2080e-02,\n",
       "                       2.4998e-02,  1.4509e-02, -9.4550e-03,  3.1931e-02,  1.7518e-02,\n",
       "                       2.3306e-03, -3.3995e-02,  1.5254e-02,  2.3105e-02, -1.6452e-02,\n",
       "                       1.1688e-02, -1.0264e-02,  1.1572e-02, -2.1778e-02, -1.6071e-04,\n",
       "                      -1.4199e-02, -6.9624e-03, -1.3369e-02,  1.0611e-02, -3.2145e-02,\n",
       "                      -4.6487e-03,  1.1036e-02,  3.0410e-03,  4.7614e-03, -1.4272e-02,\n",
       "                      -3.7738e-02,  2.9097e-03,  2.1413e-02, -2.5720e-03, -9.5727e-03,\n",
       "                      -1.5675e-02, -2.1848e-02,  3.1626e-03,  3.4785e-02, -1.8398e-02,\n",
       "                      -3.2209e-02, -7.6526e-03, -2.0189e-02,  2.0382e-02, -1.6469e-02,\n",
       "                      -2.0120e-02, -6.0278e-04, -1.6347e-02, -1.2308e-02, -1.3368e-02,\n",
       "                       3.0702e-03,  6.7696e-03,  1.3789e-02,  7.5802e-03,  4.4226e-03,\n",
       "                       1.7069e-02,  5.1781e-03, -7.5791e-03, -2.8421e-02,  2.6106e-02,\n",
       "                      -2.1857e-02, -3.6030e-02, -4.0933e-03,  1.5411e-02,  3.3685e-02,\n",
       "                       1.0099e-02,  1.0357e-02, -6.4655e-03, -1.5033e-02, -3.0701e-03,\n",
       "                       4.3711e-03, -2.1394e-02,  1.1476e-02, -1.3979e-03,  1.2544e-02,\n",
       "                       1.3505e-03, -2.9370e-02, -6.9009e-03,  2.7346e-02,  1.4169e-03,\n",
       "                      -4.2313e-04,  3.2365e-03,  2.7603e-02, -1.4010e-02,  2.6882e-02,\n",
       "                      -3.7576e-03, -5.2766e-03, -9.5697e-03, -5.0745e-03, -1.4550e-02,\n",
       "                      -2.6532e-02, -2.4705e-02,  4.0987e-03,  3.1217e-02, -1.4942e-02,\n",
       "                      -7.1709e-03, -2.2050e-02, -4.2713e-03,  9.8033e-03, -1.9234e-02,\n",
       "                      -7.4559e-03, -1.4143e-02, -3.5966e-03, -9.9090e-03, -7.8588e-03,\n",
       "                       1.7008e-03, -2.7607e-03,  2.8645e-02,  4.9021e-03, -2.2649e-02,\n",
       "                      -1.9762e-03,  2.4631e-03, -2.3914e-02,  5.2466e-03,  1.7005e-02,\n",
       "                       1.8338e-02], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.2.1.bias',\n",
       "              tensor([ 5.8337e-04,  8.7161e-03,  9.7822e-03,  1.4136e-02,  3.7749e-03,\n",
       "                       9.4440e-03,  6.9385e-03, -2.0490e-03,  1.3700e-02,  1.5831e-02,\n",
       "                       1.2665e-02, -6.8320e-03,  3.3390e-03, -5.0369e-03,  8.7464e-03,\n",
       "                       3.8034e-03,  2.5515e-02,  6.2206e-04,  9.5942e-03, -3.3557e-03,\n",
       "                      -6.7202e-03,  1.6262e-04,  5.0797e-03,  5.9981e-03,  7.7227e-03,\n",
       "                      -1.7456e-02,  1.3811e-03,  1.1715e-02,  9.7634e-03, -9.4234e-03,\n",
       "                      -2.5349e-03,  7.7975e-03, -1.6893e-03,  2.1533e-02,  3.4766e-03,\n",
       "                       1.5701e-02, -2.4168e-03,  1.5000e-02,  1.1390e-02,  1.1915e-02,\n",
       "                       1.8040e-03,  1.2340e-02, -1.0227e-02, -1.4714e-03,  6.8795e-03,\n",
       "                      -1.4375e-02,  1.4249e-02,  3.1333e-03, -1.3396e-02,  1.6570e-03,\n",
       "                       9.8685e-03,  3.8613e-03,  7.1221e-03,  1.7412e-02,  2.9498e-03,\n",
       "                       1.5352e-02,  9.4217e-03,  1.1719e-03,  1.2148e-02, -1.8754e-03,\n",
       "                       4.1562e-03, -2.5491e-03,  5.6550e-03,  8.8902e-03, -5.8815e-03,\n",
       "                       4.8627e-03, -1.0043e-02,  1.4669e-02,  1.3239e-02, -1.5225e-02,\n",
       "                       7.4269e-03,  3.0531e-03, -5.4918e-04, -8.1785e-03,  1.4100e-02,\n",
       "                       5.6879e-03, -1.5054e-04, -2.8871e-03,  2.1115e-03,  1.9573e-02,\n",
       "                       4.9192e-03, -9.7291e-03,  8.5289e-03,  4.1062e-03, -5.3416e-03,\n",
       "                       1.6770e-02,  8.9935e-04,  1.1899e-02,  1.4619e-02,  1.0834e-04,\n",
       "                       5.2395e-04,  1.0381e-02,  9.7955e-03, -8.5737e-05,  9.6237e-03,\n",
       "                      -8.5457e-03,  1.1372e-02,  4.9466e-03,  2.0507e-02,  8.5325e-03,\n",
       "                       2.2761e-02,  1.4413e-02,  4.6015e-03,  8.8327e-03,  1.6484e-03,\n",
       "                       2.6931e-03, -8.0282e-03,  8.6644e-03,  7.8472e-03,  4.6853e-03,\n",
       "                      -1.2644e-02, -9.6816e-03,  2.9948e-03,  2.0802e-02,  1.5601e-02,\n",
       "                       5.9147e-03,  5.1458e-03,  3.9814e-03,  5.4950e-03, -1.2381e-02,\n",
       "                       5.6668e-04,  1.1955e-02,  4.0694e-03,  5.7698e-04,  2.1172e-02,\n",
       "                       9.4442e-03,  6.8089e-03,  3.9312e-03,  8.8342e-03,  1.2765e-02,\n",
       "                       6.5112e-03,  5.3796e-03,  1.3433e-02,  5.1025e-03,  7.8809e-03,\n",
       "                      -1.4009e-02,  1.4142e-02,  3.3423e-03,  6.3470e-03, -1.4682e-03,\n",
       "                       1.3080e-02,  5.4408e-03,  1.6634e-02,  2.3801e-03, -7.3193e-03,\n",
       "                       1.2420e-02,  5.1028e-03, -1.0865e-04,  1.2648e-02,  8.4206e-03,\n",
       "                       7.8787e-03,  1.0547e-02,  5.6378e-03,  1.1991e-02,  1.2066e-02,\n",
       "                       3.8934e-03, -4.7506e-04,  9.3844e-03, -1.1138e-03, -1.0792e-02,\n",
       "                       5.2280e-03,  1.6871e-03, -3.5828e-03,  6.0369e-03,  1.2640e-02,\n",
       "                      -3.7089e-03, -1.3168e-02,  6.5984e-03,  6.6375e-03,  2.0516e-02,\n",
       "                       1.1960e-03, -1.4555e-04,  5.8167e-03,  1.4624e-02, -1.3613e-02,\n",
       "                       1.1293e-02,  3.2295e-03,  1.8230e-02,  1.6713e-03,  8.2045e-03,\n",
       "                      -3.3450e-04,  1.1495e-02, -6.2043e-03, -9.0849e-03,  1.2302e-02,\n",
       "                       8.0910e-03,  1.3837e-02,  1.0073e-02,  8.9927e-03,  8.0492e-03,\n",
       "                       6.4389e-03,  7.2144e-03,  6.1394e-03,  4.4872e-03, -1.7703e-03,\n",
       "                       1.0190e-02,  7.4669e-03,  2.2370e-03,  5.1278e-03,  1.1924e-02,\n",
       "                      -1.2104e-03,  2.3817e-02,  1.8197e-02,  1.8632e-02,  1.3702e-02,\n",
       "                      -1.2401e-03,  8.7114e-03, -1.0098e-02,  5.9039e-03,  1.3382e-02,\n",
       "                       4.3429e-03,  1.0475e-02,  3.8276e-03,  7.8336e-03,  7.9269e-03,\n",
       "                       3.9322e-03,  6.3476e-03,  1.6844e-02,  4.5460e-03,  4.3071e-03,\n",
       "                       1.5390e-02,  1.3315e-03,  2.0788e-03,  1.4203e-02,  2.2957e-03,\n",
       "                       6.7605e-03, -8.9227e-03, -2.0635e-03,  2.8109e-02,  1.7326e-02,\n",
       "                       2.8677e-03, -3.4123e-03,  9.7750e-03,  1.1292e-02,  2.0729e-03,\n",
       "                       9.3608e-03,  2.9421e-03,  1.3558e-02,  5.4997e-03,  7.3573e-03,\n",
       "                       2.0913e-03, -1.1360e-04, -2.1136e-03,  1.1646e-02,  2.4487e-03,\n",
       "                       7.4126e-03,  5.5638e-03,  4.9860e-03, -1.3606e-02, -1.1076e-02,\n",
       "                       2.1211e-02,  2.3833e-02,  1.8569e-02,  1.7618e-02,  2.3303e-03,\n",
       "                       3.9070e-03], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.2.1.running_mean',\n",
       "              tensor([ 5.0026e-01,  9.3141e-02, -2.1251e-01,  7.3323e-01, -1.8499e-01,\n",
       "                      -4.0980e-01,  1.2514e-01, -1.4934e-01,  1.9726e-01,  1.0485e-01,\n",
       "                       2.5828e-01, -7.3974e-02, -2.1603e-01, -1.3170e-01, -3.0867e-01,\n",
       "                       4.3427e-01,  2.8073e-01,  1.5739e-01,  4.8902e-01, -2.1588e-01,\n",
       "                       8.9053e-02, -5.7797e-01,  7.6504e-01, -3.5310e-02,  6.9145e-01,\n",
       "                       4.4874e-01,  1.3136e-01,  7.8434e-02,  5.1857e-01, -1.8248e-01,\n",
       "                       3.4175e-01,  2.8422e-01,  1.8412e-02, -1.6209e-01, -4.4365e-01,\n",
       "                       8.4120e-02, -3.8192e-01, -1.6505e-01, -4.2522e-02,  1.7304e-01,\n",
       "                      -7.4047e-01, -1.6742e-01, -1.1923e-01, -5.9140e-01, -1.1016e+00,\n",
       "                       4.9109e-01,  5.0325e-01, -1.2081e-02,  2.4890e-01,  7.0643e-02,\n",
       "                       2.4532e-01, -8.6393e-02,  9.8280e-02, -2.6729e-01, -2.1211e-01,\n",
       "                       3.5975e-01,  8.5683e-02,  4.3402e-01,  2.8010e-01, -2.9853e-01,\n",
       "                       6.1529e-02, -9.9139e-02,  1.0229e-01,  3.1469e-01, -5.2147e-01,\n",
       "                      -6.9906e-03, -1.9800e-01,  7.6698e-02,  6.1234e-02, -1.2762e+00,\n",
       "                      -1.9253e-01, -4.1760e-01, -1.3152e-01, -4.3664e-01,  7.6436e-01,\n",
       "                       3.4946e-01, -4.4820e-01,  4.7770e-01,  2.0864e-02,  4.7338e-02,\n",
       "                       2.9022e-01, -2.2126e-01, -4.7634e-01,  1.5849e-01,  1.0436e-01,\n",
       "                      -8.9968e-02,  4.5607e-02,  2.8470e-01, -1.7707e-01, -1.2997e-01,\n",
       "                      -1.0082e+00,  2.5810e-01,  2.5660e-01,  2.5079e-01, -2.5922e-01,\n",
       "                      -1.2112e-01, -4.0944e-01, -1.3710e-01,  1.6557e-01, -4.5737e-01,\n",
       "                      -6.8667e-01, -4.4445e-01,  1.4642e-01,  2.1788e-01, -1.4625e-01,\n",
       "                      -3.7751e-01, -4.6903e-01,  5.5947e-02,  3.8867e-01, -1.6644e-01,\n",
       "                       1.4560e-01, -2.4786e-01,  1.0550e-01,  3.7704e-01, -4.2315e-01,\n",
       "                      -5.7592e-01, -7.8602e-01, -2.8560e-01,  8.0650e-01, -4.8573e-01,\n",
       "                       1.6206e-01, -2.9149e-01, -6.0742e-02,  4.8892e-01, -3.8435e-02,\n",
       "                       3.1146e-01, -3.5359e-01,  1.6058e-01,  3.4355e-01, -4.3201e-02,\n",
       "                       4.3305e-01,  3.2971e-01,  9.0624e-01,  3.6702e-01, -3.1481e-01,\n",
       "                       3.0116e-01, -8.4463e-03, -5.2434e-02, -3.1924e-01, -1.8818e-01,\n",
       "                      -1.3858e-02, -1.0314e-02, -9.2277e-01, -8.2794e-02, -7.0564e-02,\n",
       "                      -4.8139e-01,  2.4116e-01, -4.7562e-01,  1.7412e-01,  5.9401e-01,\n",
       "                       2.7586e-01, -2.6760e-02, -4.4510e-01, -4.8671e-01, -2.7432e-01,\n",
       "                      -2.1863e-01,  1.5691e-01, -2.3646e-01, -9.0933e-02, -3.8486e-01,\n",
       "                      -3.2732e-01,  4.2269e-01,  3.9178e-01,  5.2351e-02,  7.1855e-03,\n",
       "                       4.2797e-01, -1.2154e+00, -3.6851e-01, -5.9731e-02,  1.2184e-01,\n",
       "                       4.3613e-01,  5.0065e-01,  9.4921e-01, -7.7080e-01, -1.0948e-01,\n",
       "                      -3.6581e-01,  8.3944e-01,  3.3255e-01, -3.9562e-01, -5.1363e-01,\n",
       "                      -7.6535e-01, -2.2918e-01, -7.8139e-02,  1.6849e-01,  6.7955e-01,\n",
       "                       9.9292e-01,  4.4483e-01, -2.8233e-01,  3.2044e-01,  2.5445e-01,\n",
       "                      -2.1611e-01, -5.3334e-02,  8.7077e-01,  1.1670e-01,  2.2550e-01,\n",
       "                       9.0622e-02,  4.5673e-01,  1.8207e-01,  4.9145e-01,  2.3715e-01,\n",
       "                       4.5510e-01, -4.6668e-02,  1.5837e-01, -3.9190e-01,  1.7196e-01,\n",
       "                       8.7218e-01,  8.0817e-02, -2.9992e-01, -6.6255e-01,  5.9850e-02,\n",
       "                      -3.1378e-02, -7.1788e-01,  4.2144e-01,  4.7466e-01, -2.2126e-01,\n",
       "                       7.9035e-02,  1.4773e-02, -2.4681e-01, -2.1436e-02,  1.0557e-01,\n",
       "                       3.3052e-01, -2.9865e-01,  4.3637e-01, -4.8127e-01, -5.3196e-01,\n",
       "                      -1.0230e-01, -2.1043e-01,  4.1143e-02, -9.9736e-02, -2.4837e-01,\n",
       "                      -2.5516e-01,  2.7657e-01, -1.2699e-01,  1.7097e-01,  4.5303e-02,\n",
       "                      -7.3056e-01,  1.2212e-01, -5.1471e-02,  3.1733e-01, -2.7648e-02,\n",
       "                       1.9847e-01, -2.8087e-01,  1.3055e-01, -3.4334e-01, -7.2076e-04,\n",
       "                       2.7705e-01,  1.5380e-02,  5.0412e-01,  8.5264e-01,  1.5978e-01,\n",
       "                       2.0322e-01,  9.0154e-02,  3.0661e-01, -2.7637e-01,  1.2074e-03,\n",
       "                       2.6530e-01], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.2.1.running_var',\n",
       "              tensor([0.3715, 0.2850, 0.3478, 0.6129, 0.3449, 0.3169, 0.2080, 0.2719, 0.3345,\n",
       "                      0.3922, 0.2698, 0.4366, 0.1643, 0.2938, 0.4986, 0.4152, 0.4012, 0.3607,\n",
       "                      0.3374, 0.3843, 0.5034, 0.3836, 0.2638, 0.2955, 0.4505, 0.1834, 0.6964,\n",
       "                      0.0738, 0.1925, 0.4188, 0.3754, 0.2805, 0.2274, 0.3307, 0.0808, 0.3544,\n",
       "                      0.1543, 0.1195, 0.2069, 0.5901, 0.3454, 0.3223, 0.1130, 0.3981, 0.4202,\n",
       "                      0.3063, 0.3851, 0.3600, 0.6541, 0.2812, 0.3708, 0.3684, 0.2055, 0.2753,\n",
       "                      0.5789, 0.4541, 0.2016, 0.6917, 0.3962, 0.3877, 0.2105, 0.3840, 0.2467,\n",
       "                      0.0974, 0.3916, 0.4618, 0.3229, 0.3511, 0.2895, 0.5606, 0.3120, 0.2043,\n",
       "                      0.1807, 0.2994, 0.6415, 0.0809, 0.3251, 0.2179, 0.4529, 0.1188, 0.1767,\n",
       "                      0.5147, 0.4899, 0.4587, 0.3688, 0.2789, 0.2846, 0.3584, 0.5212, 0.1543,\n",
       "                      0.5261, 0.0725, 0.1197, 0.5237, 0.1523, 0.1955, 0.5306, 0.0943, 0.2411,\n",
       "                      0.3187, 0.3282, 0.3035, 0.3690, 0.1920, 0.1522, 0.3096, 0.5753, 0.3035,\n",
       "                      0.3711, 0.0669, 0.2502, 0.1947, 0.2682, 0.2303, 0.4490, 0.6046, 0.3999,\n",
       "                      0.2405, 0.5596, 0.5948, 0.3013, 0.3441, 0.2598, 0.3294, 0.1480, 0.4248,\n",
       "                      0.3442, 0.2619, 0.2029, 0.3976, 0.1121, 0.2037, 0.3916, 0.3200, 0.3491,\n",
       "                      0.1539, 0.2194, 0.1420, 0.1775, 0.2977, 0.2182, 0.2346, 0.3621, 0.1361,\n",
       "                      0.1920, 0.3043, 0.1175, 0.3965, 0.1517, 0.4139, 0.2431, 0.2734, 0.3780,\n",
       "                      0.4685, 0.4891, 0.5140, 0.3274, 0.2088, 0.2440, 0.1464, 0.3099, 0.1424,\n",
       "                      0.3065, 0.1068, 0.4195, 0.2866, 0.3903, 0.1936, 0.3266, 0.4546, 0.3739,\n",
       "                      0.0965, 0.4264, 0.2683, 0.3809, 0.5158, 0.3613, 0.1242, 0.4777, 0.2961,\n",
       "                      0.5248, 0.1413, 0.3295, 0.2300, 0.5278, 0.4805, 0.3406, 0.2826, 0.3727,\n",
       "                      0.2331, 0.2419, 0.3833, 0.4922, 0.3249, 0.3030, 0.2729, 0.3098, 0.3590,\n",
       "                      0.4502, 0.5565, 0.4356, 0.3420, 0.1291, 0.4557, 0.3998, 0.3618, 0.2300,\n",
       "                      0.0615, 0.3368, 0.4447, 0.0690, 0.4648, 0.3062, 0.2253, 0.1868, 0.1201,\n",
       "                      0.5601, 0.2608, 0.3905, 0.2948, 0.1460, 0.0878, 0.3208, 0.3119, 0.4130,\n",
       "                      0.2110, 0.2469, 0.1339, 0.2769, 0.7031, 0.5923, 0.4617, 0.1750, 0.2574,\n",
       "                      0.1978, 0.3139, 0.2984, 0.1729, 0.4170, 0.2989, 0.1676, 0.1521, 0.3499,\n",
       "                      0.2030, 0.3443, 0.1467, 0.1355, 0.3351, 0.3515, 0.4910, 0.2412, 0.4063,\n",
       "                      0.4572, 0.3446, 0.2855, 0.3754], dtype=torch.float64)),\n",
       "             ('6.14.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.15.convs.0.0.weight',\n",
       "              tensor([[[-0.0541],\n",
       "                       [-0.0288],\n",
       "                       [ 0.0700],\n",
       "                       ...,\n",
       "                       [-0.1937],\n",
       "                       [-0.0201],\n",
       "                       [-0.0638]],\n",
       "              \n",
       "                      [[-0.0419],\n",
       "                       [ 0.0127],\n",
       "                       [ 0.1278],\n",
       "                       ...,\n",
       "                       [-0.0330],\n",
       "                       [ 0.0121],\n",
       "                       [-0.1421]],\n",
       "              \n",
       "                      [[ 0.0452],\n",
       "                       [ 0.0520],\n",
       "                       [-0.0199],\n",
       "                       ...,\n",
       "                       [-0.0458],\n",
       "                       [-0.0698],\n",
       "                       [-0.1104]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0225],\n",
       "                       [-0.1383],\n",
       "                       [-0.1002],\n",
       "                       ...,\n",
       "                       [-0.1351],\n",
       "                       [-0.0041],\n",
       "                       [ 0.0609]],\n",
       "              \n",
       "                      [[ 0.0742],\n",
       "                       [ 0.0229],\n",
       "                       [ 0.0301],\n",
       "                       ...,\n",
       "                       [-0.0782],\n",
       "                       [ 0.0675],\n",
       "                       [-0.0669]],\n",
       "              \n",
       "                      [[ 0.0992],\n",
       "                       [ 0.0533],\n",
       "                       [ 0.1041],\n",
       "                       ...,\n",
       "                       [ 0.0658],\n",
       "                       [ 0.0627],\n",
       "                       [ 0.0502]]], dtype=torch.float64)),\n",
       "             ('6.15.convs.0.1.weight',\n",
       "              tensor([0.9463, 0.9705, 0.9827, 0.9735, 0.9734, 0.9728, 0.9625, 0.9430, 0.9935,\n",
       "                      0.9951, 0.9725, 0.9666, 0.9745, 0.9771, 0.9533, 0.9805, 0.9636, 0.9474,\n",
       "                      0.9691, 0.9935, 0.9748, 0.9666, 1.0127, 0.9508, 0.9485, 0.9879, 0.9835,\n",
       "                      0.9156, 0.9648, 0.9741, 0.9820, 0.9494, 0.9557, 1.0001, 0.9531, 0.9736,\n",
       "                      0.9869, 0.9828, 0.9850, 0.9783, 0.9518, 0.9873, 0.9819, 0.9675, 0.9766,\n",
       "                      0.9632, 0.9973, 0.9751, 0.9473, 0.9826, 0.9513, 0.9514, 0.9841, 0.9834,\n",
       "                      0.9695, 0.9585, 0.9733, 0.9740, 0.9532, 0.9602, 0.9690, 0.9257, 0.9629,\n",
       "                      0.9733], dtype=torch.float64)),\n",
       "             ('6.15.convs.0.1.bias',\n",
       "              tensor([-2.1911e-02,  2.2383e-02,  5.1651e-03,  4.6313e-03,  6.6057e-03,\n",
       "                      -2.0082e-02, -1.1793e-02, -1.8412e-03,  1.6916e-02, -2.5712e-03,\n",
       "                       6.5386e-03,  1.1808e-02, -2.4849e-03, -6.6839e-03, -3.4937e-03,\n",
       "                       1.8632e-02,  6.6344e-03, -3.6308e-03, -1.3727e-03,  6.9857e-03,\n",
       "                       7.5670e-04, -3.2121e-03,  3.2562e-02, -2.6373e-03, -1.4681e-02,\n",
       "                       1.4497e-02, -5.8505e-03, -1.8250e-02,  4.7206e-03, -8.6974e-05,\n",
       "                      -1.2655e-02, -2.7792e-02, -1.1447e-02,  1.8565e-02, -1.0512e-02,\n",
       "                       1.0934e-02,  1.2045e-03,  1.5368e-02,  1.3512e-02,  2.0219e-02,\n",
       "                      -1.3205e-02, -9.7965e-03,  2.5704e-02,  1.3520e-02, -4.9599e-03,\n",
       "                       5.2376e-03,  2.1400e-02, -2.1097e-03, -6.7256e-03,  1.2010e-02,\n",
       "                      -1.4655e-02, -7.3916e-03,  1.4205e-02,  1.0389e-02, -6.4587e-03,\n",
       "                       5.1018e-03, -6.5240e-03, -1.3284e-02, -7.4626e-03, -1.3694e-02,\n",
       "                      -9.1392e-04, -2.2744e-02,  3.3859e-03,  2.5712e-05],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convs.0.1.running_mean',\n",
       "              tensor([-0.3664, -0.6768, -0.8207, -0.3930, -0.3286,  0.9531, -1.3503, -0.2966,\n",
       "                      -0.1421,  0.4222,  0.1947,  0.4024, -0.3859,  0.9844, -0.4524, -0.2657,\n",
       "                       0.4571, -0.4074,  0.0493,  0.2227, -0.5151, -0.2222, -1.1664, -0.5592,\n",
       "                      -1.1289, -0.5731,  0.2532, -1.3125, -0.6064, -0.1724, -0.5534,  0.3572,\n",
       "                       0.0241,  0.4629, -0.3359, -0.1692,  0.5204, -0.4762,  0.1248,  0.1715,\n",
       "                      -0.4837, -0.1730, -0.5014, -0.2952, -0.4773,  0.9244,  0.2181, -0.2514,\n",
       "                      -0.7051, -0.5596,  0.6210, -1.0957, -0.1398, -0.7159,  0.4442,  0.0800,\n",
       "                      -0.7100,  0.2565,  0.3326,  0.3973,  0.2485, -0.1736,  0.8007,  0.5940],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convs.0.1.running_var',\n",
       "              tensor([0.6134, 0.4527, 0.1750, 0.2008, 0.1813, 0.3022, 0.3942, 0.4855, 0.1967,\n",
       "                      0.1443, 0.1512, 0.1315, 0.2069, 0.7281, 0.3426, 0.3440, 0.5554, 0.5919,\n",
       "                      0.1539, 0.1948, 0.1116, 0.4094, 0.2235, 0.4364, 0.8588, 0.4760, 0.4412,\n",
       "                      0.7581, 0.1895, 0.1007, 0.1305, 0.1993, 0.1518, 0.1238, 0.4263, 0.1462,\n",
       "                      0.2099, 0.2160, 0.2551, 0.5796, 0.6776, 0.2586, 0.1278, 0.4879, 0.1715,\n",
       "                      1.1504, 0.2099, 0.2651, 0.4664, 0.1136, 0.1952, 0.4565, 0.1458, 0.3117,\n",
       "                      0.1826, 0.2265, 0.3653, 0.2073, 0.3343, 0.3065, 0.5733, 0.2401, 0.1906,\n",
       "                      0.1774], dtype=torch.float64)),\n",
       "             ('6.15.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.15.convs.1.0.weight',\n",
       "              tensor([[[ 0.0365, -0.0088, -0.1596,  0.0008, -0.0102],\n",
       "                       [-0.0652, -0.1257, -0.1465,  0.0406,  0.0022],\n",
       "                       [ 0.0661, -0.1009, -0.0582,  0.1363, -0.0557],\n",
       "                       ...,\n",
       "                       [ 0.0702, -0.0138,  0.1363,  0.0524, -0.0036],\n",
       "                       [ 0.0407, -0.0791, -0.0375, -0.1090,  0.0930],\n",
       "                       [ 0.0861,  0.0422,  0.0104,  0.1234, -0.0203]],\n",
       "              \n",
       "                      [[-0.0119,  0.0614,  0.0369, -0.0738,  0.0594],\n",
       "                       [ 0.0173, -0.1537,  0.0102, -0.0114, -0.0138],\n",
       "                       [ 0.0485, -0.0777,  0.0055, -0.1281, -0.0553],\n",
       "                       ...,\n",
       "                       [ 0.0245, -0.0312, -0.0310, -0.0294, -0.1041],\n",
       "                       [ 0.0184,  0.0267, -0.1629, -0.0523, -0.1395],\n",
       "                       [ 0.0182,  0.0307,  0.1425,  0.0949,  0.0388]],\n",
       "              \n",
       "                      [[-0.0205,  0.1368, -0.2226, -0.0908, -0.0523],\n",
       "                       [-0.0882,  0.0452, -0.0129, -0.1099, -0.1264],\n",
       "                       [-0.0164, -0.1916,  0.0304,  0.1287, -0.0046],\n",
       "                       ...,\n",
       "                       [ 0.0938,  0.0962,  0.0884,  0.0203, -0.0352],\n",
       "                       [-0.0056,  0.0036,  0.0159, -0.0188,  0.0613],\n",
       "                       [ 0.0737,  0.0036,  0.0486, -0.0992,  0.0282]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0712,  0.0641,  0.0567, -0.0712,  0.0029],\n",
       "                       [-0.1085, -0.0066,  0.0666, -0.0095, -0.0585],\n",
       "                       [ 0.0104, -0.0419, -0.0818, -0.0713, -0.0852],\n",
       "                       ...,\n",
       "                       [ 0.0641,  0.0020,  0.0349,  0.0906, -0.0563],\n",
       "                       [ 0.1625, -0.1216,  0.0388, -0.0475, -0.0682],\n",
       "                       [-0.0170, -0.0096, -0.0879,  0.1046,  0.0212]],\n",
       "              \n",
       "                      [[-0.0677, -0.0203,  0.0128, -0.0203, -0.0028],\n",
       "                       [ 0.0286, -0.0496, -0.0099,  0.0382, -0.0120],\n",
       "                       [-0.0052, -0.1719,  0.0473, -0.0082,  0.1848],\n",
       "                       ...,\n",
       "                       [ 0.0184, -0.0383, -0.0863, -0.0073, -0.0374],\n",
       "                       [-0.2072, -0.2095,  0.0337, -0.0184,  0.0535],\n",
       "                       [ 0.0658,  0.1133,  0.0735, -0.0796, -0.0046]],\n",
       "              \n",
       "                      [[-0.0344,  0.0512,  0.0384, -0.0591,  0.1539],\n",
       "                       [ 0.0795,  0.0118,  0.0088,  0.0292,  0.0554],\n",
       "                       [ 0.0160, -0.0637, -0.0667,  0.0548,  0.0072],\n",
       "                       ...,\n",
       "                       [ 0.0268,  0.0009,  0.1383,  0.1455, -0.0215],\n",
       "                       [ 0.0083,  0.0437,  0.0833,  0.1238,  0.1306],\n",
       "                       [ 0.0299,  0.0419, -0.1319, -0.0439, -0.1120]]], dtype=torch.float64)),\n",
       "             ('6.15.convs.1.1.weight',\n",
       "              tensor([0.9293, 0.9985, 0.9525, 0.9769, 0.9566, 0.9610, 0.9652, 0.9372, 0.9724,\n",
       "                      0.9845, 0.9571, 1.0179, 0.9806, 0.9775, 0.9529, 0.9436, 0.9670, 0.9697,\n",
       "                      0.9621, 0.9779, 0.9677, 0.9781, 0.9603, 0.8998, 0.9333, 0.9519, 0.9178,\n",
       "                      0.9528, 0.9570, 0.9582, 0.9627, 0.9513, 0.9925, 0.9657, 0.9548, 0.9501,\n",
       "                      0.9575, 0.9530, 0.9602, 0.9973, 0.9731, 0.9719, 0.9949, 0.9624, 0.9561,\n",
       "                      0.9645, 0.9727, 0.9714, 0.9595, 0.9599, 0.9526, 0.9489, 0.9593, 0.9786,\n",
       "                      0.9750, 0.9718, 0.9794, 0.9654, 0.9524, 0.9885, 1.0028, 1.0046, 0.9717,\n",
       "                      0.9736], dtype=torch.float64)),\n",
       "             ('6.15.convs.1.1.bias',\n",
       "              tensor([-0.0056, -0.0137, -0.0162, -0.0156,  0.0018, -0.0066, -0.0092, -0.0143,\n",
       "                       0.0084,  0.0077,  0.0018, -0.0311, -0.0056, -0.0167, -0.0356, -0.0016,\n",
       "                      -0.0016,  0.0144, -0.0267,  0.0193, -0.0125, -0.0004, -0.0091, -0.0364,\n",
       "                      -0.0158, -0.0052, -0.0180, -0.0223, -0.0190, -0.0251,  0.0003, -0.0091,\n",
       "                      -0.0283, -0.0065, -0.0084,  0.0037, -0.0008, -0.0073, -0.0030,  0.0245,\n",
       "                      -0.0058,  0.0051,  0.0126,  0.0042, -0.0203, -0.0140, -0.0095, -0.0211,\n",
       "                      -0.0095, -0.0175,  0.0018, -0.0202,  0.0109, -0.0067,  0.0025,  0.0030,\n",
       "                       0.0012,  0.0073, -0.0057, -0.0082, -0.0007,  0.0230, -0.0018, -0.0029],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convs.1.1.running_mean',\n",
       "              tensor([-0.3485, -0.2754, -0.3150,  0.7041, -0.3306, -0.2593, -0.2418, -0.2294,\n",
       "                      -0.2694,  0.1487, -0.5379, -0.1990,  0.6688,  0.5622,  0.2482, -0.8124,\n",
       "                       0.1933, -0.8719,  0.3852, -0.1066, -0.7692, -0.1053,  0.1267, -0.6182,\n",
       "                      -0.4634, -0.6459, -0.5931, -0.9057, -0.2623, -0.0419, -0.7965, -1.1764,\n",
       "                       0.6690, -0.5609, -1.1999,  0.7370,  0.4391,  0.3725, -0.6687, -0.6831,\n",
       "                      -0.4745,  0.2714, -0.6251, -0.5994,  0.7184,  0.8468, -0.9091,  0.1424,\n",
       "                      -0.2948, -0.5900, -0.1343,  0.7723, -0.1976,  0.7360,  0.1816, -0.0813,\n",
       "                      -0.5161,  0.0181, -0.5071,  0.6816, -0.4056, -0.2278,  0.6237,  0.3408],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convs.1.1.running_var',\n",
       "              tensor([0.5408, 0.4678, 0.3464, 0.4533, 0.5386, 0.4097, 0.3803, 1.0948, 0.6647,\n",
       "                      0.3112, 0.4504, 0.5255, 0.6277, 0.5079, 0.3101, 0.6061, 0.4881, 0.5388,\n",
       "                      0.7805, 0.5783, 0.5154, 0.3350, 0.4275, 0.5500, 0.5687, 0.6771, 0.5446,\n",
       "                      0.3741, 1.0552, 0.7730, 0.7270, 0.3843, 0.4254, 0.5863, 0.7281, 0.5104,\n",
       "                      0.4715, 0.6462, 0.5404, 0.3935, 0.5149, 0.4131, 0.3629, 0.5706, 0.5875,\n",
       "                      0.6909, 0.3766, 0.6369, 0.4133, 0.4357, 0.7915, 0.6372, 0.5983, 0.3493,\n",
       "                      0.5035, 0.3689, 0.4628, 0.5193, 0.5091, 0.5171, 0.5984, 0.4025, 0.5612,\n",
       "                      0.4365], dtype=torch.float64)),\n",
       "             ('6.15.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.15.convs.2.0.weight',\n",
       "              tensor([[[-0.0897],\n",
       "                       [-0.1421],\n",
       "                       [ 0.1287],\n",
       "                       ...,\n",
       "                       [-0.0959],\n",
       "                       [-0.1251],\n",
       "                       [-0.0776]],\n",
       "              \n",
       "                      [[-0.1253],\n",
       "                       [-0.3135],\n",
       "                       [-0.2487],\n",
       "                       ...,\n",
       "                       [ 0.1479],\n",
       "                       [ 0.0657],\n",
       "                       [ 0.0065]],\n",
       "              \n",
       "                      [[ 0.0369],\n",
       "                       [ 0.0230],\n",
       "                       [-0.0845],\n",
       "                       ...,\n",
       "                       [-0.0645],\n",
       "                       [-0.0878],\n",
       "                       [ 0.0084]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0673],\n",
       "                       [-0.2753],\n",
       "                       [-0.0797],\n",
       "                       ...,\n",
       "                       [-0.0663],\n",
       "                       [-0.1305],\n",
       "                       [ 0.0428]],\n",
       "              \n",
       "                      [[-0.0404],\n",
       "                       [ 0.0839],\n",
       "                       [-0.1159],\n",
       "                       ...,\n",
       "                       [-0.1294],\n",
       "                       [-0.1473],\n",
       "                       [-0.0257]],\n",
       "              \n",
       "                      [[ 0.1763],\n",
       "                       [-0.0708],\n",
       "                       [-0.0577],\n",
       "                       ...,\n",
       "                       [-0.1063],\n",
       "                       [-0.0006],\n",
       "                       [ 0.3006]]], dtype=torch.float64)),\n",
       "             ('6.15.convs.2.1.weight',\n",
       "              tensor([-0.0249,  0.0140, -0.0065,  0.0115,  0.0256, -0.0141, -0.0022, -0.0149,\n",
       "                       0.0270, -0.0325, -0.0224, -0.0188,  0.0037,  0.0032,  0.0046,  0.0106,\n",
       "                      -0.0319, -0.0150, -0.0239,  0.0130,  0.0007,  0.0354,  0.0016,  0.0135,\n",
       "                       0.0155,  0.0138, -0.0055,  0.0217,  0.0025,  0.0058, -0.0119,  0.0448,\n",
       "                       0.0142, -0.0015, -0.0243, -0.0055,  0.0140, -0.0039,  0.0188,  0.0153,\n",
       "                      -0.0169, -0.0318,  0.0164,  0.0158,  0.0029,  0.0058, -0.0263, -0.0170,\n",
       "                      -0.0227, -0.0005, -0.0022, -0.0131, -0.0243,  0.0169, -0.0191, -0.0075,\n",
       "                       0.0222,  0.0351,  0.0319, -0.0058,  0.0219,  0.0063,  0.0038,  0.0167,\n",
       "                      -0.0055, -0.0154, -0.0192,  0.0062,  0.0056, -0.0003,  0.0114,  0.0125,\n",
       "                       0.0135, -0.0228,  0.0080,  0.0320,  0.0063, -0.0154,  0.0096, -0.0113,\n",
       "                      -0.0092,  0.0029, -0.0295,  0.0043, -0.0276,  0.0096, -0.0223, -0.0308,\n",
       "                       0.0180, -0.0039, -0.0104,  0.0199, -0.0047, -0.0178,  0.0176, -0.0034,\n",
       "                      -0.0215,  0.0181, -0.0151,  0.0345, -0.0041,  0.0359,  0.0157, -0.0140,\n",
       "                       0.0125, -0.0121,  0.0002, -0.0089, -0.0094, -0.0208,  0.0080,  0.0037,\n",
       "                       0.0210,  0.0128, -0.0087, -0.0102,  0.0242,  0.0065,  0.0032, -0.0386,\n",
       "                      -0.0088, -0.0065,  0.0151, -0.0222, -0.0017, -0.0064,  0.0110, -0.0112,\n",
       "                       0.0063, -0.0271,  0.0086, -0.0020, -0.0129, -0.0010,  0.0140,  0.0120,\n",
       "                      -0.0174, -0.0088,  0.0145, -0.0205,  0.0046,  0.0001,  0.0071, -0.0042,\n",
       "                       0.0022,  0.0201,  0.0144,  0.0388, -0.0506,  0.0305,  0.0003, -0.0058,\n",
       "                      -0.0096, -0.0240,  0.0118,  0.0150, -0.0150, -0.0209, -0.0054, -0.0235,\n",
       "                      -0.0026,  0.0057,  0.0150,  0.0018,  0.0173,  0.0070, -0.0243, -0.0077,\n",
       "                      -0.0044, -0.0329,  0.0102,  0.0091,  0.0278, -0.0221, -0.0059,  0.0115,\n",
       "                       0.0090,  0.0031,  0.0034,  0.0159,  0.0082, -0.0019, -0.0132,  0.0138,\n",
       "                      -0.0231,  0.0018,  0.0130,  0.0088,  0.0016,  0.0075,  0.0292,  0.0051,\n",
       "                       0.0375, -0.0377, -0.0221,  0.0290, -0.0299, -0.0303,  0.0174,  0.0158,\n",
       "                      -0.0089,  0.0134,  0.0216, -0.0089, -0.0136,  0.0288, -0.0084, -0.0134,\n",
       "                      -0.0028, -0.0287, -0.0182,  0.0088, -0.0187, -0.0222, -0.0147,  0.0103,\n",
       "                      -0.0262,  0.0051,  0.0047, -0.0100, -0.0178, -0.0211,  0.0063,  0.0312,\n",
       "                       0.0265, -0.0155, -0.0080,  0.0046,  0.0303, -0.0058, -0.0230, -0.0090,\n",
       "                       0.0345,  0.0335, -0.0023,  0.0038,  0.0067, -0.0219, -0.0071,  0.0081,\n",
       "                      -0.0322,  0.0172, -0.0079,  0.0036,  0.0051, -0.0186, -0.0153, -0.0081,\n",
       "                       0.0013,  0.0095, -0.0081, -0.0126,  0.0202,  0.0238,  0.0236,  0.0189],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convs.2.1.bias',\n",
       "              tensor([ 0.0008,  0.0093,  0.0093,  0.0141,  0.0030,  0.0087,  0.0060, -0.0031,\n",
       "                       0.0111,  0.0154,  0.0130, -0.0087,  0.0039, -0.0056,  0.0086,  0.0043,\n",
       "                       0.0255,  0.0006,  0.0120, -0.0029, -0.0110,  0.0014,  0.0086,  0.0058,\n",
       "                       0.0107, -0.0204,  0.0076,  0.0134,  0.0099, -0.0081, -0.0047,  0.0090,\n",
       "                      -0.0024,  0.0217,  0.0040,  0.0110, -0.0025,  0.0108,  0.0110,  0.0079,\n",
       "                       0.0024,  0.0121, -0.0141, -0.0031,  0.0070, -0.0152,  0.0169,  0.0016,\n",
       "                      -0.0139,  0.0004,  0.0121,  0.0038,  0.0048,  0.0183,  0.0018,  0.0130,\n",
       "                       0.0099,  0.0011,  0.0123, -0.0034,  0.0053, -0.0003,  0.0049,  0.0088,\n",
       "                      -0.0063,  0.0026, -0.0102,  0.0128,  0.0141, -0.0152,  0.0071, -0.0017,\n",
       "                      -0.0012, -0.0073,  0.0138,  0.0077, -0.0007,  0.0005,  0.0022,  0.0168,\n",
       "                       0.0048, -0.0086,  0.0113,  0.0034, -0.0030,  0.0167,  0.0007,  0.0127,\n",
       "                       0.0152, -0.0005,  0.0003,  0.0118,  0.0100, -0.0040,  0.0113, -0.0075,\n",
       "                       0.0116,  0.0063,  0.0205,  0.0099,  0.0230,  0.0145,  0.0037,  0.0075,\n",
       "                       0.0034,  0.0008, -0.0077,  0.0055,  0.0072,  0.0048, -0.0095, -0.0098,\n",
       "                       0.0025,  0.0235,  0.0156,  0.0061,  0.0052,  0.0052,  0.0055, -0.0040,\n",
       "                      -0.0002,  0.0121,  0.0052,  0.0037,  0.0215,  0.0091,  0.0066,  0.0043,\n",
       "                       0.0096,  0.0139,  0.0064,  0.0051,  0.0123,  0.0036,  0.0061, -0.0160,\n",
       "                       0.0132,  0.0035,  0.0059,  0.0033,  0.0136,  0.0075,  0.0166,  0.0022,\n",
       "                      -0.0055,  0.0105,  0.0042, -0.0026,  0.0128,  0.0069,  0.0078,  0.0112,\n",
       "                       0.0030,  0.0120,  0.0126,  0.0034,  0.0002,  0.0094, -0.0004, -0.0057,\n",
       "                       0.0051,  0.0118, -0.0029,  0.0061,  0.0117, -0.0042, -0.0164,  0.0060,\n",
       "                       0.0069,  0.0194, -0.0007, -0.0008,  0.0088,  0.0136, -0.0118,  0.0118,\n",
       "                       0.0005,  0.0184,  0.0054,  0.0087,  0.0005,  0.0110, -0.0035, -0.0095,\n",
       "                       0.0112,  0.0067,  0.0138,  0.0103,  0.0086,  0.0080,  0.0071,  0.0049,\n",
       "                       0.0052,  0.0049, -0.0004,  0.0111,  0.0096,  0.0021,  0.0058,  0.0216,\n",
       "                      -0.0007,  0.0236,  0.0181,  0.0164,  0.0169,  0.0032,  0.0085, -0.0135,\n",
       "                       0.0038,  0.0130,  0.0044,  0.0116,  0.0020,  0.0079,  0.0085,  0.0052,\n",
       "                       0.0073,  0.0164,  0.0027,  0.0030,  0.0157,  0.0002,  0.0046,  0.0144,\n",
       "                       0.0050,  0.0062, -0.0065, -0.0032,  0.0289,  0.0196,  0.0004,  0.0019,\n",
       "                       0.0091,  0.0115,  0.0016,  0.0093,  0.0019,  0.0123,  0.0051,  0.0098,\n",
       "                       0.0006, -0.0034, -0.0023,  0.0133,  0.0060,  0.0075,  0.0052,  0.0024,\n",
       "                      -0.0118, -0.0090,  0.0211,  0.0241,  0.0167,  0.0176,  0.0009,  0.0020],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convs.2.1.running_mean',\n",
       "              tensor([ 1.0479e-01,  1.8677e-01, -3.5391e-01, -1.7504e-01, -6.7980e-01,\n",
       "                      -1.6289e-02,  2.5559e-01, -1.1582e-01, -1.2931e-02, -2.2876e-01,\n",
       "                       1.8573e-01, -1.0069e-01, -1.8811e-01,  8.6703e-04, -4.0426e-01,\n",
       "                      -1.3337e-01,  2.9601e-01, -5.1322e-01,  2.3288e-01, -1.9224e-01,\n",
       "                      -1.5222e-01, -6.3568e-02, -1.1412e-01, -4.3768e-01,  2.6221e-01,\n",
       "                      -1.7339e-01,  2.1424e-01,  3.5728e-01,  4.0704e-01,  1.9737e-01,\n",
       "                      -2.4685e-01,  8.9206e-02, -1.5409e-01, -1.6658e-01, -4.5586e-01,\n",
       "                      -1.2754e-01, -1.8894e-01,  1.5415e-01, -2.8832e-01,  8.3452e-02,\n",
       "                       2.9798e-01, -4.9729e-01, -2.2228e-01,  1.9003e-01,  2.1117e-03,\n",
       "                       6.8536e-01, -2.2233e-01, -2.2881e-01, -1.2354e-01, -2.3497e-01,\n",
       "                       5.9885e-02, -3.7618e-01,  2.6879e-01, -3.5419e-01,  2.7170e-01,\n",
       "                      -3.4546e-01, -9.3643e-01, -3.1858e-01,  1.9661e-01, -7.5543e-01,\n",
       "                      -5.0649e-01, -1.0024e-01, -1.2122e-02, -2.4440e-01, -3.8876e-01,\n",
       "                      -1.6764e-03, -6.4166e-01, -3.8463e-01,  3.6953e-01,  3.0495e-01,\n",
       "                       3.5121e-01, -1.4471e-01, -1.0449e-02, -6.8700e-01, -2.8979e-01,\n",
       "                      -4.8481e-01, -3.1703e-01,  5.2793e-01,  7.9635e-01, -2.1931e-01,\n",
       "                       3.9055e-01, -1.4431e-01,  9.5028e-01, -3.1821e-01, -2.5749e-01,\n",
       "                      -5.8180e-01,  5.4855e-01, -9.3870e-01,  3.8442e-01, -2.9656e-01,\n",
       "                      -6.9393e-01,  6.4734e-01, -3.1124e-01, -1.2238e-01, -3.8310e-01,\n",
       "                      -2.5708e-01,  1.7398e-01,  3.0630e-02, -7.3252e-01,  1.5129e-01,\n",
       "                       5.0478e-01, -8.0460e-02,  2.2963e-01,  7.1013e-02,  5.1687e-01,\n",
       "                      -2.7485e-01,  2.6014e-02, -4.2407e-01, -1.3121e-01, -2.7005e-01,\n",
       "                      -2.9262e-01,  7.4822e-02, -9.6785e-01,  4.5174e-01, -9.1099e-02,\n",
       "                       7.0045e-01, -4.8365e-01, -1.9028e-01, -1.7435e-01,  6.0641e-01,\n",
       "                      -1.3054e-01,  7.0349e-01,  6.2479e-02, -4.5685e-01,  3.0731e-01,\n",
       "                      -2.2747e-01,  1.1041e-01, -3.2144e-03, -1.8292e-01,  6.9356e-01,\n",
       "                       2.0157e-01,  8.7339e-02, -4.4246e-01, -2.3561e-01, -4.6846e-01,\n",
       "                      -1.0735e-01, -2.7825e-01,  1.1165e-02,  2.7746e-01, -7.2893e-01,\n",
       "                      -1.7397e-02,  4.8868e-01,  6.2146e-02,  1.4681e-01,  8.7959e-03,\n",
       "                      -7.0782e-01, -2.0533e-01,  4.4275e-01, -3.5407e-01,  1.3771e-01,\n",
       "                       1.9552e-01,  1.1500e-02, -3.2183e-01,  7.1869e-01,  2.0491e-02,\n",
       "                      -3.1756e-01,  6.3591e-01,  1.0389e-01,  8.8295e-02, -2.1867e-01,\n",
       "                      -5.8845e-01, -1.4317e-01, -6.5038e-02,  2.9326e-02, -5.1279e-01,\n",
       "                       5.4331e-01,  5.1955e-01, -2.2634e-02, -4.6085e-02,  2.0497e-01,\n",
       "                       2.2110e-01, -1.2189e-01,  2.1803e-01,  3.4218e-02, -2.7513e-01,\n",
       "                       1.5140e-01,  4.1626e-02,  1.1159e-01,  3.2007e-01, -5.2300e-01,\n",
       "                       2.4906e-01, -5.9964e-01,  3.9300e-01,  5.1744e-01,  5.7434e-01,\n",
       "                      -1.7518e-01, -2.8018e-01, -3.4586e-01,  2.0095e-02,  2.0409e-02,\n",
       "                       2.3337e-01, -1.8359e-01,  1.7274e-01, -7.7483e-01, -7.7451e-02,\n",
       "                       3.2532e-01, -8.2276e-01, -6.1814e-02, -4.9117e-02, -6.3873e-01,\n",
       "                      -2.1534e-01,  3.2278e-02, -4.7700e-01,  3.8683e-01, -6.6096e-02,\n",
       "                       1.9187e-01,  2.9021e-01,  1.0910e-02, -7.2273e-02,  5.3995e-01,\n",
       "                      -1.1949e-01, -7.4782e-01,  3.5793e-02,  4.3922e-01, -5.0333e-01,\n",
       "                      -2.0267e-01,  9.5468e-02, -4.5315e-03, -5.3939e-01, -3.2830e-01,\n",
       "                      -8.3010e-01, -4.8634e-01,  1.8608e-02,  1.7785e-01, -4.8933e-01,\n",
       "                       2.8294e-01, -9.9302e-02,  1.1578e-01, -5.2607e-01, -7.7552e-01,\n",
       "                       1.6543e-01, -1.7001e-01, -4.1742e-01,  4.8436e-01, -2.3778e-01,\n",
       "                       3.1478e-01,  2.0144e-01,  2.1662e-01, -9.1818e-01, -6.9275e-02,\n",
       "                       2.2825e-01, -1.1320e-01,  2.6199e-01, -1.6639e-02, -3.1166e-02,\n",
       "                      -1.4135e-01, -2.1073e-01, -4.1948e-01,  2.0640e-01, -4.4599e-01,\n",
       "                       9.0185e-01,  5.9018e-01, -2.7295e-01, -1.9527e-01, -4.0795e-01,\n",
       "                       1.8765e-01], dtype=torch.float64)),\n",
       "             ('6.15.convs.2.1.running_var',\n",
       "              tensor([0.3135, 0.3781, 0.1736, 0.3603, 0.4590, 0.5072, 0.1257, 0.4336, 0.2330,\n",
       "                      0.4114, 0.2835, 0.4340, 0.0949, 0.1575, 0.3950, 0.2456, 0.2902, 0.3000,\n",
       "                      0.2790, 0.4455, 0.1980, 0.5252, 0.3532, 0.3930, 0.4254, 0.2121, 0.3774,\n",
       "                      0.3274, 0.2840, 0.3836, 0.7551, 0.3911, 0.1550, 0.3059, 0.5672, 0.3948,\n",
       "                      0.3652, 0.2074, 0.4422, 0.3415, 0.2113, 0.3504, 0.3131, 0.4447, 0.3633,\n",
       "                      0.3820, 0.4223, 0.3368, 0.5318, 0.4337, 0.1178, 0.3670, 0.3754, 0.4140,\n",
       "                      0.3801, 0.3197, 0.5504, 0.4567, 0.4693, 0.2123, 0.3096, 0.2895, 0.2178,\n",
       "                      0.3126, 0.3632, 0.2206, 0.4002, 0.1966, 0.1738, 0.4091, 0.2828, 0.3404,\n",
       "                      0.2327, 0.6510, 0.2811, 0.2819, 0.2291, 0.4534, 0.4709, 0.1609, 0.3142,\n",
       "                      0.2755, 0.3894, 0.5698, 0.3086, 0.3690, 0.6925, 0.4212, 0.3391, 0.2701,\n",
       "                      0.5574, 0.2751, 0.2864, 0.4911, 0.2465, 0.2322, 0.5320, 0.2430, 0.4115,\n",
       "                      0.2584, 0.2798, 0.4306, 0.3511, 0.2572, 0.3124, 0.2414, 0.3444, 0.6826,\n",
       "                      0.4306, 0.3720, 0.2076, 0.3348, 0.6123, 0.3995, 0.2375, 0.4530, 0.3811,\n",
       "                      0.1410, 0.1294, 0.3727, 0.1302, 0.3509, 0.3208, 0.3497, 0.0804, 0.2702,\n",
       "                      0.2695, 0.5138, 0.1046, 0.4247, 0.1918, 0.3231, 0.5364, 0.1916, 0.1685,\n",
       "                      0.1591, 0.1758, 0.3813, 0.4704, 0.4362, 0.1025, 0.2494, 0.4240, 0.1669,\n",
       "                      0.1152, 0.3842, 0.2001, 0.4396, 0.3914, 0.3538, 0.2552, 0.3404, 0.5096,\n",
       "                      0.7207, 0.4262, 0.2094, 0.2314, 0.2303, 0.3435, 0.3477, 0.1860, 0.1319,\n",
       "                      0.3631, 0.4989, 0.6070, 0.3542, 0.3878, 0.0841, 0.4020, 0.5578, 0.2265,\n",
       "                      0.1435, 0.4680, 0.3120, 0.4217, 0.3852, 0.2484, 0.1407, 0.3949, 0.5614,\n",
       "                      0.2795, 0.2495, 0.5103, 0.3847, 0.3899, 0.2983, 0.3305, 0.2930, 0.1935,\n",
       "                      0.3251, 0.5286, 0.3981, 0.3502, 0.2924, 0.3298, 0.3093, 0.2672, 0.3031,\n",
       "                      0.3339, 0.4020, 0.3489, 0.3213, 0.3566, 0.3139, 0.6308, 0.6544, 0.1406,\n",
       "                      0.1098, 0.1602, 0.3394, 0.1359, 0.3483, 0.2814, 0.2717, 0.2663, 0.2063,\n",
       "                      0.3771, 0.0309, 0.1363, 0.4361, 0.3120, 0.3508, 0.1236, 0.3520, 0.6128,\n",
       "                      0.4074, 0.1826, 0.1285, 0.5723, 0.3298, 0.1600, 0.2964, 0.4572, 0.3846,\n",
       "                      0.2573, 0.2025, 0.3171, 0.1765, 0.5909, 0.2828, 0.4280, 0.1850, 0.7586,\n",
       "                      0.1593, 0.1209, 0.3152, 0.2796, 0.4446, 0.1909, 0.3149, 0.4554, 0.6545,\n",
       "                      0.4658, 0.2942, 0.3452, 0.3046], dtype=torch.float64)),\n",
       "             ('6.15.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.15.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0541],\n",
       "                       [-0.0288],\n",
       "                       [ 0.0700],\n",
       "                       ...,\n",
       "                       [-0.1937],\n",
       "                       [-0.0201],\n",
       "                       [-0.0638]],\n",
       "              \n",
       "                      [[-0.0419],\n",
       "                       [ 0.0127],\n",
       "                       [ 0.1278],\n",
       "                       ...,\n",
       "                       [-0.0330],\n",
       "                       [ 0.0121],\n",
       "                       [-0.1421]],\n",
       "              \n",
       "                      [[ 0.0452],\n",
       "                       [ 0.0520],\n",
       "                       [-0.0199],\n",
       "                       ...,\n",
       "                       [-0.0458],\n",
       "                       [-0.0698],\n",
       "                       [-0.1104]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0225],\n",
       "                       [-0.1383],\n",
       "                       [-0.1002],\n",
       "                       ...,\n",
       "                       [-0.1351],\n",
       "                       [-0.0041],\n",
       "                       [ 0.0609]],\n",
       "              \n",
       "                      [[ 0.0742],\n",
       "                       [ 0.0229],\n",
       "                       [ 0.0301],\n",
       "                       ...,\n",
       "                       [-0.0782],\n",
       "                       [ 0.0675],\n",
       "                       [-0.0669]],\n",
       "              \n",
       "                      [[ 0.0992],\n",
       "                       [ 0.0533],\n",
       "                       [ 0.1041],\n",
       "                       ...,\n",
       "                       [ 0.0658],\n",
       "                       [ 0.0627],\n",
       "                       [ 0.0502]]], dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.0.1.weight',\n",
       "              tensor([0.9463, 0.9705, 0.9827, 0.9735, 0.9734, 0.9728, 0.9625, 0.9430, 0.9935,\n",
       "                      0.9951, 0.9725, 0.9666, 0.9745, 0.9771, 0.9533, 0.9805, 0.9636, 0.9474,\n",
       "                      0.9691, 0.9935, 0.9748, 0.9666, 1.0127, 0.9508, 0.9485, 0.9879, 0.9835,\n",
       "                      0.9156, 0.9648, 0.9741, 0.9820, 0.9494, 0.9557, 1.0001, 0.9531, 0.9736,\n",
       "                      0.9869, 0.9828, 0.9850, 0.9783, 0.9518, 0.9873, 0.9819, 0.9675, 0.9766,\n",
       "                      0.9632, 0.9973, 0.9751, 0.9473, 0.9826, 0.9513, 0.9514, 0.9841, 0.9834,\n",
       "                      0.9695, 0.9585, 0.9733, 0.9740, 0.9532, 0.9602, 0.9690, 0.9257, 0.9629,\n",
       "                      0.9733], dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.0.1.bias',\n",
       "              tensor([-2.1911e-02,  2.2383e-02,  5.1651e-03,  4.6313e-03,  6.6057e-03,\n",
       "                      -2.0082e-02, -1.1793e-02, -1.8412e-03,  1.6916e-02, -2.5712e-03,\n",
       "                       6.5386e-03,  1.1808e-02, -2.4849e-03, -6.6839e-03, -3.4937e-03,\n",
       "                       1.8632e-02,  6.6344e-03, -3.6308e-03, -1.3727e-03,  6.9857e-03,\n",
       "                       7.5670e-04, -3.2121e-03,  3.2562e-02, -2.6373e-03, -1.4681e-02,\n",
       "                       1.4497e-02, -5.8505e-03, -1.8250e-02,  4.7206e-03, -8.6974e-05,\n",
       "                      -1.2655e-02, -2.7792e-02, -1.1447e-02,  1.8565e-02, -1.0512e-02,\n",
       "                       1.0934e-02,  1.2045e-03,  1.5368e-02,  1.3512e-02,  2.0219e-02,\n",
       "                      -1.3205e-02, -9.7965e-03,  2.5704e-02,  1.3520e-02, -4.9599e-03,\n",
       "                       5.2376e-03,  2.1400e-02, -2.1097e-03, -6.7256e-03,  1.2010e-02,\n",
       "                      -1.4655e-02, -7.3916e-03,  1.4205e-02,  1.0389e-02, -6.4587e-03,\n",
       "                       5.1018e-03, -6.5240e-03, -1.3284e-02, -7.4626e-03, -1.3694e-02,\n",
       "                      -9.1392e-04, -2.2744e-02,  3.3859e-03,  2.5712e-05],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.3664, -0.6768, -0.8207, -0.3930, -0.3286,  0.9531, -1.3503, -0.2966,\n",
       "                      -0.1421,  0.4222,  0.1947,  0.4024, -0.3859,  0.9844, -0.4524, -0.2657,\n",
       "                       0.4571, -0.4074,  0.0493,  0.2227, -0.5151, -0.2222, -1.1664, -0.5592,\n",
       "                      -1.1289, -0.5731,  0.2532, -1.3125, -0.6064, -0.1724, -0.5534,  0.3572,\n",
       "                       0.0241,  0.4629, -0.3359, -0.1692,  0.5204, -0.4762,  0.1248,  0.1715,\n",
       "                      -0.4837, -0.1730, -0.5014, -0.2952, -0.4773,  0.9244,  0.2181, -0.2514,\n",
       "                      -0.7051, -0.5596,  0.6210, -1.0957, -0.1398, -0.7159,  0.4442,  0.0800,\n",
       "                      -0.7100,  0.2565,  0.3326,  0.3973,  0.2485, -0.1736,  0.8007,  0.5940],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.0.1.running_var',\n",
       "              tensor([0.6134, 0.4527, 0.1750, 0.2008, 0.1813, 0.3022, 0.3942, 0.4855, 0.1967,\n",
       "                      0.1443, 0.1512, 0.1315, 0.2069, 0.7281, 0.3426, 0.3440, 0.5554, 0.5919,\n",
       "                      0.1539, 0.1948, 0.1116, 0.4094, 0.2235, 0.4364, 0.8588, 0.4760, 0.4412,\n",
       "                      0.7581, 0.1895, 0.1007, 0.1305, 0.1993, 0.1518, 0.1238, 0.4263, 0.1462,\n",
       "                      0.2099, 0.2160, 0.2551, 0.5796, 0.6776, 0.2586, 0.1278, 0.4879, 0.1715,\n",
       "                      1.1504, 0.2099, 0.2651, 0.4664, 0.1136, 0.1952, 0.4565, 0.1458, 0.3117,\n",
       "                      0.1826, 0.2265, 0.3653, 0.2073, 0.3343, 0.3065, 0.5733, 0.2401, 0.1906,\n",
       "                      0.1774], dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.15.convpath.0.1.0.weight',\n",
       "              tensor([[[ 0.0365, -0.0088, -0.1596,  0.0008, -0.0102],\n",
       "                       [-0.0652, -0.1257, -0.1465,  0.0406,  0.0022],\n",
       "                       [ 0.0661, -0.1009, -0.0582,  0.1363, -0.0557],\n",
       "                       ...,\n",
       "                       [ 0.0702, -0.0138,  0.1363,  0.0524, -0.0036],\n",
       "                       [ 0.0407, -0.0791, -0.0375, -0.1090,  0.0930],\n",
       "                       [ 0.0861,  0.0422,  0.0104,  0.1234, -0.0203]],\n",
       "              \n",
       "                      [[-0.0119,  0.0614,  0.0369, -0.0738,  0.0594],\n",
       "                       [ 0.0173, -0.1537,  0.0102, -0.0114, -0.0138],\n",
       "                       [ 0.0485, -0.0777,  0.0055, -0.1281, -0.0553],\n",
       "                       ...,\n",
       "                       [ 0.0245, -0.0312, -0.0310, -0.0294, -0.1041],\n",
       "                       [ 0.0184,  0.0267, -0.1629, -0.0523, -0.1395],\n",
       "                       [ 0.0182,  0.0307,  0.1425,  0.0949,  0.0388]],\n",
       "              \n",
       "                      [[-0.0205,  0.1368, -0.2226, -0.0908, -0.0523],\n",
       "                       [-0.0882,  0.0452, -0.0129, -0.1099, -0.1264],\n",
       "                       [-0.0164, -0.1916,  0.0304,  0.1287, -0.0046],\n",
       "                       ...,\n",
       "                       [ 0.0938,  0.0962,  0.0884,  0.0203, -0.0352],\n",
       "                       [-0.0056,  0.0036,  0.0159, -0.0188,  0.0613],\n",
       "                       [ 0.0737,  0.0036,  0.0486, -0.0992,  0.0282]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0712,  0.0641,  0.0567, -0.0712,  0.0029],\n",
       "                       [-0.1085, -0.0066,  0.0666, -0.0095, -0.0585],\n",
       "                       [ 0.0104, -0.0419, -0.0818, -0.0713, -0.0852],\n",
       "                       ...,\n",
       "                       [ 0.0641,  0.0020,  0.0349,  0.0906, -0.0563],\n",
       "                       [ 0.1625, -0.1216,  0.0388, -0.0475, -0.0682],\n",
       "                       [-0.0170, -0.0096, -0.0879,  0.1046,  0.0212]],\n",
       "              \n",
       "                      [[-0.0677, -0.0203,  0.0128, -0.0203, -0.0028],\n",
       "                       [ 0.0286, -0.0496, -0.0099,  0.0382, -0.0120],\n",
       "                       [-0.0052, -0.1719,  0.0473, -0.0082,  0.1848],\n",
       "                       ...,\n",
       "                       [ 0.0184, -0.0383, -0.0863, -0.0073, -0.0374],\n",
       "                       [-0.2072, -0.2095,  0.0337, -0.0184,  0.0535],\n",
       "                       [ 0.0658,  0.1133,  0.0735, -0.0796, -0.0046]],\n",
       "              \n",
       "                      [[-0.0344,  0.0512,  0.0384, -0.0591,  0.1539],\n",
       "                       [ 0.0795,  0.0118,  0.0088,  0.0292,  0.0554],\n",
       "                       [ 0.0160, -0.0637, -0.0667,  0.0548,  0.0072],\n",
       "                       ...,\n",
       "                       [ 0.0268,  0.0009,  0.1383,  0.1455, -0.0215],\n",
       "                       [ 0.0083,  0.0437,  0.0833,  0.1238,  0.1306],\n",
       "                       [ 0.0299,  0.0419, -0.1319, -0.0439, -0.1120]]], dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.1.1.weight',\n",
       "              tensor([0.9293, 0.9985, 0.9525, 0.9769, 0.9566, 0.9610, 0.9652, 0.9372, 0.9724,\n",
       "                      0.9845, 0.9571, 1.0179, 0.9806, 0.9775, 0.9529, 0.9436, 0.9670, 0.9697,\n",
       "                      0.9621, 0.9779, 0.9677, 0.9781, 0.9603, 0.8998, 0.9333, 0.9519, 0.9178,\n",
       "                      0.9528, 0.9570, 0.9582, 0.9627, 0.9513, 0.9925, 0.9657, 0.9548, 0.9501,\n",
       "                      0.9575, 0.9530, 0.9602, 0.9973, 0.9731, 0.9719, 0.9949, 0.9624, 0.9561,\n",
       "                      0.9645, 0.9727, 0.9714, 0.9595, 0.9599, 0.9526, 0.9489, 0.9593, 0.9786,\n",
       "                      0.9750, 0.9718, 0.9794, 0.9654, 0.9524, 0.9885, 1.0028, 1.0046, 0.9717,\n",
       "                      0.9736], dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.1.1.bias',\n",
       "              tensor([-0.0056, -0.0137, -0.0162, -0.0156,  0.0018, -0.0066, -0.0092, -0.0143,\n",
       "                       0.0084,  0.0077,  0.0018, -0.0311, -0.0056, -0.0167, -0.0356, -0.0016,\n",
       "                      -0.0016,  0.0144, -0.0267,  0.0193, -0.0125, -0.0004, -0.0091, -0.0364,\n",
       "                      -0.0158, -0.0052, -0.0180, -0.0223, -0.0190, -0.0251,  0.0003, -0.0091,\n",
       "                      -0.0283, -0.0065, -0.0084,  0.0037, -0.0008, -0.0073, -0.0030,  0.0245,\n",
       "                      -0.0058,  0.0051,  0.0126,  0.0042, -0.0203, -0.0140, -0.0095, -0.0211,\n",
       "                      -0.0095, -0.0175,  0.0018, -0.0202,  0.0109, -0.0067,  0.0025,  0.0030,\n",
       "                       0.0012,  0.0073, -0.0057, -0.0082, -0.0007,  0.0230, -0.0018, -0.0029],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.1.1.running_mean',\n",
       "              tensor([-0.3485, -0.2754, -0.3150,  0.7041, -0.3306, -0.2593, -0.2418, -0.2294,\n",
       "                      -0.2694,  0.1487, -0.5379, -0.1990,  0.6688,  0.5622,  0.2482, -0.8124,\n",
       "                       0.1933, -0.8719,  0.3852, -0.1066, -0.7692, -0.1053,  0.1267, -0.6182,\n",
       "                      -0.4634, -0.6459, -0.5931, -0.9057, -0.2623, -0.0419, -0.7965, -1.1764,\n",
       "                       0.6690, -0.5609, -1.1999,  0.7370,  0.4391,  0.3725, -0.6687, -0.6831,\n",
       "                      -0.4745,  0.2714, -0.6251, -0.5994,  0.7184,  0.8468, -0.9091,  0.1424,\n",
       "                      -0.2948, -0.5900, -0.1343,  0.7723, -0.1976,  0.7360,  0.1816, -0.0813,\n",
       "                      -0.5161,  0.0181, -0.5071,  0.6816, -0.4056, -0.2278,  0.6237,  0.3408],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.1.1.running_var',\n",
       "              tensor([0.5408, 0.4678, 0.3464, 0.4533, 0.5386, 0.4097, 0.3803, 1.0948, 0.6647,\n",
       "                      0.3112, 0.4504, 0.5255, 0.6277, 0.5079, 0.3101, 0.6061, 0.4881, 0.5388,\n",
       "                      0.7805, 0.5783, 0.5154, 0.3350, 0.4275, 0.5500, 0.5687, 0.6771, 0.5446,\n",
       "                      0.3741, 1.0552, 0.7730, 0.7270, 0.3843, 0.4254, 0.5863, 0.7281, 0.5104,\n",
       "                      0.4715, 0.6462, 0.5404, 0.3935, 0.5149, 0.4131, 0.3629, 0.5706, 0.5875,\n",
       "                      0.6909, 0.3766, 0.6369, 0.4133, 0.4357, 0.7915, 0.6372, 0.5983, 0.3493,\n",
       "                      0.5035, 0.3689, 0.4628, 0.5193, 0.5091, 0.5171, 0.5984, 0.4025, 0.5612,\n",
       "                      0.4365], dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.15.convpath.0.2.0.weight',\n",
       "              tensor([[[-0.0897],\n",
       "                       [-0.1421],\n",
       "                       [ 0.1287],\n",
       "                       ...,\n",
       "                       [-0.0959],\n",
       "                       [-0.1251],\n",
       "                       [-0.0776]],\n",
       "              \n",
       "                      [[-0.1253],\n",
       "                       [-0.3135],\n",
       "                       [-0.2487],\n",
       "                       ...,\n",
       "                       [ 0.1479],\n",
       "                       [ 0.0657],\n",
       "                       [ 0.0065]],\n",
       "              \n",
       "                      [[ 0.0369],\n",
       "                       [ 0.0230],\n",
       "                       [-0.0845],\n",
       "                       ...,\n",
       "                       [-0.0645],\n",
       "                       [-0.0878],\n",
       "                       [ 0.0084]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0673],\n",
       "                       [-0.2753],\n",
       "                       [-0.0797],\n",
       "                       ...,\n",
       "                       [-0.0663],\n",
       "                       [-0.1305],\n",
       "                       [ 0.0428]],\n",
       "              \n",
       "                      [[-0.0404],\n",
       "                       [ 0.0839],\n",
       "                       [-0.1159],\n",
       "                       ...,\n",
       "                       [-0.1294],\n",
       "                       [-0.1473],\n",
       "                       [-0.0257]],\n",
       "              \n",
       "                      [[ 0.1763],\n",
       "                       [-0.0708],\n",
       "                       [-0.0577],\n",
       "                       ...,\n",
       "                       [-0.1063],\n",
       "                       [-0.0006],\n",
       "                       [ 0.3006]]], dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.2.1.weight',\n",
       "              tensor([-0.0249,  0.0140, -0.0065,  0.0115,  0.0256, -0.0141, -0.0022, -0.0149,\n",
       "                       0.0270, -0.0325, -0.0224, -0.0188,  0.0037,  0.0032,  0.0046,  0.0106,\n",
       "                      -0.0319, -0.0150, -0.0239,  0.0130,  0.0007,  0.0354,  0.0016,  0.0135,\n",
       "                       0.0155,  0.0138, -0.0055,  0.0217,  0.0025,  0.0058, -0.0119,  0.0448,\n",
       "                       0.0142, -0.0015, -0.0243, -0.0055,  0.0140, -0.0039,  0.0188,  0.0153,\n",
       "                      -0.0169, -0.0318,  0.0164,  0.0158,  0.0029,  0.0058, -0.0263, -0.0170,\n",
       "                      -0.0227, -0.0005, -0.0022, -0.0131, -0.0243,  0.0169, -0.0191, -0.0075,\n",
       "                       0.0222,  0.0351,  0.0319, -0.0058,  0.0219,  0.0063,  0.0038,  0.0167,\n",
       "                      -0.0055, -0.0154, -0.0192,  0.0062,  0.0056, -0.0003,  0.0114,  0.0125,\n",
       "                       0.0135, -0.0228,  0.0080,  0.0320,  0.0063, -0.0154,  0.0096, -0.0113,\n",
       "                      -0.0092,  0.0029, -0.0295,  0.0043, -0.0276,  0.0096, -0.0223, -0.0308,\n",
       "                       0.0180, -0.0039, -0.0104,  0.0199, -0.0047, -0.0178,  0.0176, -0.0034,\n",
       "                      -0.0215,  0.0181, -0.0151,  0.0345, -0.0041,  0.0359,  0.0157, -0.0140,\n",
       "                       0.0125, -0.0121,  0.0002, -0.0089, -0.0094, -0.0208,  0.0080,  0.0037,\n",
       "                       0.0210,  0.0128, -0.0087, -0.0102,  0.0242,  0.0065,  0.0032, -0.0386,\n",
       "                      -0.0088, -0.0065,  0.0151, -0.0222, -0.0017, -0.0064,  0.0110, -0.0112,\n",
       "                       0.0063, -0.0271,  0.0086, -0.0020, -0.0129, -0.0010,  0.0140,  0.0120,\n",
       "                      -0.0174, -0.0088,  0.0145, -0.0205,  0.0046,  0.0001,  0.0071, -0.0042,\n",
       "                       0.0022,  0.0201,  0.0144,  0.0388, -0.0506,  0.0305,  0.0003, -0.0058,\n",
       "                      -0.0096, -0.0240,  0.0118,  0.0150, -0.0150, -0.0209, -0.0054, -0.0235,\n",
       "                      -0.0026,  0.0057,  0.0150,  0.0018,  0.0173,  0.0070, -0.0243, -0.0077,\n",
       "                      -0.0044, -0.0329,  0.0102,  0.0091,  0.0278, -0.0221, -0.0059,  0.0115,\n",
       "                       0.0090,  0.0031,  0.0034,  0.0159,  0.0082, -0.0019, -0.0132,  0.0138,\n",
       "                      -0.0231,  0.0018,  0.0130,  0.0088,  0.0016,  0.0075,  0.0292,  0.0051,\n",
       "                       0.0375, -0.0377, -0.0221,  0.0290, -0.0299, -0.0303,  0.0174,  0.0158,\n",
       "                      -0.0089,  0.0134,  0.0216, -0.0089, -0.0136,  0.0288, -0.0084, -0.0134,\n",
       "                      -0.0028, -0.0287, -0.0182,  0.0088, -0.0187, -0.0222, -0.0147,  0.0103,\n",
       "                      -0.0262,  0.0051,  0.0047, -0.0100, -0.0178, -0.0211,  0.0063,  0.0312,\n",
       "                       0.0265, -0.0155, -0.0080,  0.0046,  0.0303, -0.0058, -0.0230, -0.0090,\n",
       "                       0.0345,  0.0335, -0.0023,  0.0038,  0.0067, -0.0219, -0.0071,  0.0081,\n",
       "                      -0.0322,  0.0172, -0.0079,  0.0036,  0.0051, -0.0186, -0.0153, -0.0081,\n",
       "                       0.0013,  0.0095, -0.0081, -0.0126,  0.0202,  0.0238,  0.0236,  0.0189],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.2.1.bias',\n",
       "              tensor([ 0.0008,  0.0093,  0.0093,  0.0141,  0.0030,  0.0087,  0.0060, -0.0031,\n",
       "                       0.0111,  0.0154,  0.0130, -0.0087,  0.0039, -0.0056,  0.0086,  0.0043,\n",
       "                       0.0255,  0.0006,  0.0120, -0.0029, -0.0110,  0.0014,  0.0086,  0.0058,\n",
       "                       0.0107, -0.0204,  0.0076,  0.0134,  0.0099, -0.0081, -0.0047,  0.0090,\n",
       "                      -0.0024,  0.0217,  0.0040,  0.0110, -0.0025,  0.0108,  0.0110,  0.0079,\n",
       "                       0.0024,  0.0121, -0.0141, -0.0031,  0.0070, -0.0152,  0.0169,  0.0016,\n",
       "                      -0.0139,  0.0004,  0.0121,  0.0038,  0.0048,  0.0183,  0.0018,  0.0130,\n",
       "                       0.0099,  0.0011,  0.0123, -0.0034,  0.0053, -0.0003,  0.0049,  0.0088,\n",
       "                      -0.0063,  0.0026, -0.0102,  0.0128,  0.0141, -0.0152,  0.0071, -0.0017,\n",
       "                      -0.0012, -0.0073,  0.0138,  0.0077, -0.0007,  0.0005,  0.0022,  0.0168,\n",
       "                       0.0048, -0.0086,  0.0113,  0.0034, -0.0030,  0.0167,  0.0007,  0.0127,\n",
       "                       0.0152, -0.0005,  0.0003,  0.0118,  0.0100, -0.0040,  0.0113, -0.0075,\n",
       "                       0.0116,  0.0063,  0.0205,  0.0099,  0.0230,  0.0145,  0.0037,  0.0075,\n",
       "                       0.0034,  0.0008, -0.0077,  0.0055,  0.0072,  0.0048, -0.0095, -0.0098,\n",
       "                       0.0025,  0.0235,  0.0156,  0.0061,  0.0052,  0.0052,  0.0055, -0.0040,\n",
       "                      -0.0002,  0.0121,  0.0052,  0.0037,  0.0215,  0.0091,  0.0066,  0.0043,\n",
       "                       0.0096,  0.0139,  0.0064,  0.0051,  0.0123,  0.0036,  0.0061, -0.0160,\n",
       "                       0.0132,  0.0035,  0.0059,  0.0033,  0.0136,  0.0075,  0.0166,  0.0022,\n",
       "                      -0.0055,  0.0105,  0.0042, -0.0026,  0.0128,  0.0069,  0.0078,  0.0112,\n",
       "                       0.0030,  0.0120,  0.0126,  0.0034,  0.0002,  0.0094, -0.0004, -0.0057,\n",
       "                       0.0051,  0.0118, -0.0029,  0.0061,  0.0117, -0.0042, -0.0164,  0.0060,\n",
       "                       0.0069,  0.0194, -0.0007, -0.0008,  0.0088,  0.0136, -0.0118,  0.0118,\n",
       "                       0.0005,  0.0184,  0.0054,  0.0087,  0.0005,  0.0110, -0.0035, -0.0095,\n",
       "                       0.0112,  0.0067,  0.0138,  0.0103,  0.0086,  0.0080,  0.0071,  0.0049,\n",
       "                       0.0052,  0.0049, -0.0004,  0.0111,  0.0096,  0.0021,  0.0058,  0.0216,\n",
       "                      -0.0007,  0.0236,  0.0181,  0.0164,  0.0169,  0.0032,  0.0085, -0.0135,\n",
       "                       0.0038,  0.0130,  0.0044,  0.0116,  0.0020,  0.0079,  0.0085,  0.0052,\n",
       "                       0.0073,  0.0164,  0.0027,  0.0030,  0.0157,  0.0002,  0.0046,  0.0144,\n",
       "                       0.0050,  0.0062, -0.0065, -0.0032,  0.0289,  0.0196,  0.0004,  0.0019,\n",
       "                       0.0091,  0.0115,  0.0016,  0.0093,  0.0019,  0.0123,  0.0051,  0.0098,\n",
       "                       0.0006, -0.0034, -0.0023,  0.0133,  0.0060,  0.0075,  0.0052,  0.0024,\n",
       "                      -0.0118, -0.0090,  0.0211,  0.0241,  0.0167,  0.0176,  0.0009,  0.0020],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.2.1.running_mean',\n",
       "              tensor([ 1.0479e-01,  1.8677e-01, -3.5391e-01, -1.7504e-01, -6.7980e-01,\n",
       "                      -1.6289e-02,  2.5559e-01, -1.1582e-01, -1.2931e-02, -2.2876e-01,\n",
       "                       1.8573e-01, -1.0069e-01, -1.8811e-01,  8.6703e-04, -4.0426e-01,\n",
       "                      -1.3337e-01,  2.9601e-01, -5.1322e-01,  2.3288e-01, -1.9224e-01,\n",
       "                      -1.5222e-01, -6.3568e-02, -1.1412e-01, -4.3768e-01,  2.6221e-01,\n",
       "                      -1.7339e-01,  2.1424e-01,  3.5728e-01,  4.0704e-01,  1.9737e-01,\n",
       "                      -2.4685e-01,  8.9206e-02, -1.5409e-01, -1.6658e-01, -4.5586e-01,\n",
       "                      -1.2754e-01, -1.8894e-01,  1.5415e-01, -2.8832e-01,  8.3452e-02,\n",
       "                       2.9798e-01, -4.9729e-01, -2.2228e-01,  1.9003e-01,  2.1117e-03,\n",
       "                       6.8536e-01, -2.2233e-01, -2.2881e-01, -1.2354e-01, -2.3497e-01,\n",
       "                       5.9885e-02, -3.7618e-01,  2.6879e-01, -3.5419e-01,  2.7170e-01,\n",
       "                      -3.4546e-01, -9.3643e-01, -3.1858e-01,  1.9661e-01, -7.5543e-01,\n",
       "                      -5.0649e-01, -1.0024e-01, -1.2122e-02, -2.4440e-01, -3.8876e-01,\n",
       "                      -1.6764e-03, -6.4166e-01, -3.8463e-01,  3.6953e-01,  3.0495e-01,\n",
       "                       3.5121e-01, -1.4471e-01, -1.0449e-02, -6.8700e-01, -2.8979e-01,\n",
       "                      -4.8481e-01, -3.1703e-01,  5.2793e-01,  7.9635e-01, -2.1931e-01,\n",
       "                       3.9055e-01, -1.4431e-01,  9.5028e-01, -3.1821e-01, -2.5749e-01,\n",
       "                      -5.8180e-01,  5.4855e-01, -9.3870e-01,  3.8442e-01, -2.9656e-01,\n",
       "                      -6.9393e-01,  6.4734e-01, -3.1124e-01, -1.2238e-01, -3.8310e-01,\n",
       "                      -2.5708e-01,  1.7398e-01,  3.0630e-02, -7.3252e-01,  1.5129e-01,\n",
       "                       5.0478e-01, -8.0460e-02,  2.2963e-01,  7.1013e-02,  5.1687e-01,\n",
       "                      -2.7485e-01,  2.6014e-02, -4.2407e-01, -1.3121e-01, -2.7005e-01,\n",
       "                      -2.9262e-01,  7.4822e-02, -9.6785e-01,  4.5174e-01, -9.1099e-02,\n",
       "                       7.0045e-01, -4.8365e-01, -1.9028e-01, -1.7435e-01,  6.0641e-01,\n",
       "                      -1.3054e-01,  7.0349e-01,  6.2479e-02, -4.5685e-01,  3.0731e-01,\n",
       "                      -2.2747e-01,  1.1041e-01, -3.2144e-03, -1.8292e-01,  6.9356e-01,\n",
       "                       2.0157e-01,  8.7339e-02, -4.4246e-01, -2.3561e-01, -4.6846e-01,\n",
       "                      -1.0735e-01, -2.7825e-01,  1.1165e-02,  2.7746e-01, -7.2893e-01,\n",
       "                      -1.7397e-02,  4.8868e-01,  6.2146e-02,  1.4681e-01,  8.7959e-03,\n",
       "                      -7.0782e-01, -2.0533e-01,  4.4275e-01, -3.5407e-01,  1.3771e-01,\n",
       "                       1.9552e-01,  1.1500e-02, -3.2183e-01,  7.1869e-01,  2.0491e-02,\n",
       "                      -3.1756e-01,  6.3591e-01,  1.0389e-01,  8.8295e-02, -2.1867e-01,\n",
       "                      -5.8845e-01, -1.4317e-01, -6.5038e-02,  2.9326e-02, -5.1279e-01,\n",
       "                       5.4331e-01,  5.1955e-01, -2.2634e-02, -4.6085e-02,  2.0497e-01,\n",
       "                       2.2110e-01, -1.2189e-01,  2.1803e-01,  3.4218e-02, -2.7513e-01,\n",
       "                       1.5140e-01,  4.1626e-02,  1.1159e-01,  3.2007e-01, -5.2300e-01,\n",
       "                       2.4906e-01, -5.9964e-01,  3.9300e-01,  5.1744e-01,  5.7434e-01,\n",
       "                      -1.7518e-01, -2.8018e-01, -3.4586e-01,  2.0095e-02,  2.0409e-02,\n",
       "                       2.3337e-01, -1.8359e-01,  1.7274e-01, -7.7483e-01, -7.7451e-02,\n",
       "                       3.2532e-01, -8.2276e-01, -6.1814e-02, -4.9117e-02, -6.3873e-01,\n",
       "                      -2.1534e-01,  3.2278e-02, -4.7700e-01,  3.8683e-01, -6.6096e-02,\n",
       "                       1.9187e-01,  2.9021e-01,  1.0910e-02, -7.2273e-02,  5.3995e-01,\n",
       "                      -1.1949e-01, -7.4782e-01,  3.5793e-02,  4.3922e-01, -5.0333e-01,\n",
       "                      -2.0267e-01,  9.5468e-02, -4.5315e-03, -5.3939e-01, -3.2830e-01,\n",
       "                      -8.3010e-01, -4.8634e-01,  1.8608e-02,  1.7785e-01, -4.8933e-01,\n",
       "                       2.8294e-01, -9.9302e-02,  1.1578e-01, -5.2607e-01, -7.7552e-01,\n",
       "                       1.6543e-01, -1.7001e-01, -4.1742e-01,  4.8436e-01, -2.3778e-01,\n",
       "                       3.1478e-01,  2.0144e-01,  2.1662e-01, -9.1818e-01, -6.9275e-02,\n",
       "                       2.2825e-01, -1.1320e-01,  2.6199e-01, -1.6639e-02, -3.1166e-02,\n",
       "                      -1.4135e-01, -2.1073e-01, -4.1948e-01,  2.0640e-01, -4.4599e-01,\n",
       "                       9.0185e-01,  5.9018e-01, -2.7295e-01, -1.9527e-01, -4.0795e-01,\n",
       "                       1.8765e-01], dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.2.1.running_var',\n",
       "              tensor([0.3135, 0.3781, 0.1736, 0.3603, 0.4590, 0.5072, 0.1257, 0.4336, 0.2330,\n",
       "                      0.4114, 0.2835, 0.4340, 0.0949, 0.1575, 0.3950, 0.2456, 0.2902, 0.3000,\n",
       "                      0.2790, 0.4455, 0.1980, 0.5252, 0.3532, 0.3930, 0.4254, 0.2121, 0.3774,\n",
       "                      0.3274, 0.2840, 0.3836, 0.7551, 0.3911, 0.1550, 0.3059, 0.5672, 0.3948,\n",
       "                      0.3652, 0.2074, 0.4422, 0.3415, 0.2113, 0.3504, 0.3131, 0.4447, 0.3633,\n",
       "                      0.3820, 0.4223, 0.3368, 0.5318, 0.4337, 0.1178, 0.3670, 0.3754, 0.4140,\n",
       "                      0.3801, 0.3197, 0.5504, 0.4567, 0.4693, 0.2123, 0.3096, 0.2895, 0.2178,\n",
       "                      0.3126, 0.3632, 0.2206, 0.4002, 0.1966, 0.1738, 0.4091, 0.2828, 0.3404,\n",
       "                      0.2327, 0.6510, 0.2811, 0.2819, 0.2291, 0.4534, 0.4709, 0.1609, 0.3142,\n",
       "                      0.2755, 0.3894, 0.5698, 0.3086, 0.3690, 0.6925, 0.4212, 0.3391, 0.2701,\n",
       "                      0.5574, 0.2751, 0.2864, 0.4911, 0.2465, 0.2322, 0.5320, 0.2430, 0.4115,\n",
       "                      0.2584, 0.2798, 0.4306, 0.3511, 0.2572, 0.3124, 0.2414, 0.3444, 0.6826,\n",
       "                      0.4306, 0.3720, 0.2076, 0.3348, 0.6123, 0.3995, 0.2375, 0.4530, 0.3811,\n",
       "                      0.1410, 0.1294, 0.3727, 0.1302, 0.3509, 0.3208, 0.3497, 0.0804, 0.2702,\n",
       "                      0.2695, 0.5138, 0.1046, 0.4247, 0.1918, 0.3231, 0.5364, 0.1916, 0.1685,\n",
       "                      0.1591, 0.1758, 0.3813, 0.4704, 0.4362, 0.1025, 0.2494, 0.4240, 0.1669,\n",
       "                      0.1152, 0.3842, 0.2001, 0.4396, 0.3914, 0.3538, 0.2552, 0.3404, 0.5096,\n",
       "                      0.7207, 0.4262, 0.2094, 0.2314, 0.2303, 0.3435, 0.3477, 0.1860, 0.1319,\n",
       "                      0.3631, 0.4989, 0.6070, 0.3542, 0.3878, 0.0841, 0.4020, 0.5578, 0.2265,\n",
       "                      0.1435, 0.4680, 0.3120, 0.4217, 0.3852, 0.2484, 0.1407, 0.3949, 0.5614,\n",
       "                      0.2795, 0.2495, 0.5103, 0.3847, 0.3899, 0.2983, 0.3305, 0.2930, 0.1935,\n",
       "                      0.3251, 0.5286, 0.3981, 0.3502, 0.2924, 0.3298, 0.3093, 0.2672, 0.3031,\n",
       "                      0.3339, 0.4020, 0.3489, 0.3213, 0.3566, 0.3139, 0.6308, 0.6544, 0.1406,\n",
       "                      0.1098, 0.1602, 0.3394, 0.1359, 0.3483, 0.2814, 0.2717, 0.2663, 0.2063,\n",
       "                      0.3771, 0.0309, 0.1363, 0.4361, 0.3120, 0.3508, 0.1236, 0.3520, 0.6128,\n",
       "                      0.4074, 0.1826, 0.1285, 0.5723, 0.3298, 0.1600, 0.2964, 0.4572, 0.3846,\n",
       "                      0.2573, 0.2025, 0.3171, 0.1765, 0.5909, 0.2828, 0.4280, 0.1850, 0.7586,\n",
       "                      0.1593, 0.1209, 0.3152, 0.2796, 0.4446, 0.1909, 0.3149, 0.4554, 0.6545,\n",
       "                      0.4658, 0.2942, 0.3452, 0.3046], dtype=torch.float64)),\n",
       "             ('6.15.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.16.convs.0.0.weight',\n",
       "              tensor([[[-0.0849],\n",
       "                       [ 0.0370],\n",
       "                       [ 0.0660],\n",
       "                       ...,\n",
       "                       [ 0.0349],\n",
       "                       [ 0.0190],\n",
       "                       [ 0.0572]],\n",
       "              \n",
       "                      [[ 0.1340],\n",
       "                       [-0.0127],\n",
       "                       [-0.1204],\n",
       "                       ...,\n",
       "                       [ 0.0607],\n",
       "                       [ 0.0385],\n",
       "                       [ 0.0542]],\n",
       "              \n",
       "                      [[-0.0033],\n",
       "                       [ 0.0583],\n",
       "                       [ 0.0407],\n",
       "                       ...,\n",
       "                       [-0.0902],\n",
       "                       [-0.1398],\n",
       "                       [-0.0860]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1042],\n",
       "                       [-0.1574],\n",
       "                       [-0.0387],\n",
       "                       ...,\n",
       "                       [ 0.0432],\n",
       "                       [ 0.0390],\n",
       "                       [ 0.0041]],\n",
       "              \n",
       "                      [[ 0.0076],\n",
       "                       [ 0.0651],\n",
       "                       [-0.0265],\n",
       "                       ...,\n",
       "                       [ 0.1583],\n",
       "                       [ 0.1733],\n",
       "                       [ 0.0527]],\n",
       "              \n",
       "                      [[ 0.1249],\n",
       "                       [-0.0949],\n",
       "                       [-0.0671],\n",
       "                       ...,\n",
       "                       [-0.1007],\n",
       "                       [-0.0337],\n",
       "                       [-0.0539]]], dtype=torch.float64)),\n",
       "             ('6.16.convs.0.1.weight',\n",
       "              tensor([1.0204, 0.9983, 0.9722, 0.9709, 0.9496, 0.9767, 0.9625, 0.9766, 0.9750,\n",
       "                      1.0028, 0.9789, 0.9604, 0.9579, 0.9582, 0.9726, 0.9695, 0.9591, 0.9919,\n",
       "                      0.9730, 0.9733, 0.9822, 0.9740, 0.9776, 0.9634, 0.9870, 0.9621, 0.9761,\n",
       "                      0.9525, 0.9793, 0.9947, 0.9793, 0.9809, 1.0071, 0.9582, 0.9795, 0.9642,\n",
       "                      0.9817, 0.9942, 0.9596, 0.9613, 0.9832, 0.9603, 0.9715, 0.9670, 0.9693,\n",
       "                      0.9862, 0.9944, 0.9899, 0.9428, 0.9702, 1.0020, 0.9859, 0.9851, 0.9738,\n",
       "                      0.9715, 0.9766, 0.9613, 0.9507, 0.9693, 0.9697, 0.9631, 0.9612, 0.9928,\n",
       "                      0.9599], dtype=torch.float64)),\n",
       "             ('6.16.convs.0.1.bias',\n",
       "              tensor([ 3.7872e-02,  1.7528e-02,  9.4606e-04,  6.7585e-03, -9.2415e-03,\n",
       "                       7.4245e-03,  3.3601e-03, -5.3582e-03,  8.7345e-03,  1.9513e-02,\n",
       "                      -9.6278e-04, -1.5136e-02, -5.4815e-03, -1.4322e-02,  3.6464e-03,\n",
       "                       8.7829e-03, -4.4805e-03,  2.0636e-02, -3.5340e-03, -8.0657e-03,\n",
       "                       1.6374e-02, -4.2637e-03,  6.8740e-03,  4.2311e-04,  6.6076e-04,\n",
       "                      -4.9033e-03,  1.1023e-02, -1.3583e-02,  1.1037e-02,  6.1770e-03,\n",
       "                       8.7457e-03,  9.7177e-03,  1.3991e-02,  1.2460e-02,  4.3055e-04,\n",
       "                       1.4306e-02,  1.7489e-02, -8.1642e-05,  2.2225e-03,  1.2362e-03,\n",
       "                      -5.1253e-03, -1.2712e-02,  1.0149e-02, -1.7798e-03,  3.5995e-03,\n",
       "                       9.3915e-03,  1.9896e-02,  1.2670e-02, -3.2209e-02, -3.8582e-03,\n",
       "                       3.0761e-02,  9.0579e-03,  2.9330e-02,  1.1309e-02,  3.7868e-03,\n",
       "                      -2.3350e-03,  3.4725e-03, -3.8650e-03,  3.3181e-03, -6.6589e-04,\n",
       "                      -5.7606e-03,  1.2657e-03,  1.0486e-02, -1.4904e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.16.convs.0.1.running_mean',\n",
       "              tensor([ 0.2091, -0.3048, -1.1237,  1.1509,  0.7080, -0.8807, -0.1687, -0.8891,\n",
       "                      -0.9276,  0.6444,  0.3535,  0.6074,  1.7552,  0.6510,  0.1953, -0.8793,\n",
       "                      -0.4890, -0.5889, -0.0730, -0.5934, -0.1562, -0.1691, -0.0669, -0.3359,\n",
       "                      -0.3484,  0.2112,  0.7949,  0.6647,  0.8641,  0.3263, -0.4912,  0.1529,\n",
       "                      -0.0412, -1.2238,  0.2319, -0.7661, -0.0840, -0.1459, -0.0771,  0.6293,\n",
       "                       0.3002,  0.2458, -0.4420,  0.4570, -1.0461,  0.1204, -1.3301, -0.3564,\n",
       "                      -0.0401,  1.1795,  0.2219, -0.0931, -0.0042, -0.3307,  0.3959,  0.6692,\n",
       "                      -0.8969,  0.4309,  0.4061, -1.0083, -0.9263, -0.9333, -0.3082, -0.1359],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.16.convs.0.1.running_var',\n",
       "              tensor([0.1525, 0.1737, 0.1394, 0.2540, 0.4210, 0.1965, 0.2169, 0.2674, 0.1344,\n",
       "                      0.0966, 0.1535, 0.2333, 1.5348, 1.0286, 0.2110, 0.1943, 0.2559, 0.1814,\n",
       "                      0.1055, 0.1294, 0.2185, 0.1433, 0.1353, 0.1014, 0.1175, 0.1602, 0.1496,\n",
       "                      0.1953, 0.1265, 0.2047, 0.1056, 0.3393, 0.1275, 1.1701, 0.1572, 0.1764,\n",
       "                      0.5158, 0.3284, 0.1791, 1.6581, 0.2850, 0.2629, 0.3453, 0.1870, 0.7823,\n",
       "                      0.4712, 0.2041, 0.1751, 0.1437, 0.4975, 0.1308, 0.1125, 0.1751, 0.1249,\n",
       "                      0.9092, 0.1291, 0.3944, 0.4786, 0.3618, 0.1770, 0.2023, 0.3866, 0.1370,\n",
       "                      0.6383], dtype=torch.float64)),\n",
       "             ('6.16.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.16.convs.1.0.weight',\n",
       "              tensor([[[-0.0495, -0.0257,  0.0729, -0.0628,  0.0664],\n",
       "                       [ 0.0872,  0.0761, -0.1176, -0.0915, -0.0315],\n",
       "                       [ 0.0615,  0.0835, -0.0732,  0.0728,  0.0103],\n",
       "                       ...,\n",
       "                       [-0.0311, -0.0073, -0.0252, -0.0855,  0.1494],\n",
       "                       [-0.0005, -0.0151,  0.1097,  0.0150, -0.0251],\n",
       "                       [-0.0480,  0.1253,  0.0874, -0.0400, -0.0724]],\n",
       "              \n",
       "                      [[ 0.0125,  0.0584,  0.2318,  0.0178,  0.1433],\n",
       "                       [ 0.0839, -0.0259, -0.0564,  0.0386, -0.0003],\n",
       "                       [ 0.1535,  0.0124, -0.0149,  0.1117, -0.0777],\n",
       "                       ...,\n",
       "                       [-0.0654, -0.0153, -0.0812,  0.0630, -0.1094],\n",
       "                       [-0.0259,  0.0435,  0.0299,  0.0790, -0.1026],\n",
       "                       [ 0.0499, -0.0335,  0.0372, -0.0486, -0.0005]],\n",
       "              \n",
       "                      [[ 0.0953,  0.0963,  0.0318,  0.0819, -0.0382],\n",
       "                       [-0.1328,  0.0064, -0.0100,  0.0602,  0.0263],\n",
       "                       [-0.1218, -0.0080, -0.0063, -0.0373,  0.0640],\n",
       "                       ...,\n",
       "                       [ 0.0971,  0.0049, -0.0025, -0.0477, -0.0630],\n",
       "                       [-0.0736, -0.2161, -0.0748,  0.0991,  0.0707],\n",
       "                       [ 0.0634, -0.0100,  0.0149,  0.0701, -0.0062]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1141,  0.0655,  0.0645,  0.0988, -0.0535],\n",
       "                       [ 0.0189,  0.0011,  0.0627,  0.0571, -0.0065],\n",
       "                       [-0.0256, -0.0695,  0.0029, -0.0065, -0.0278],\n",
       "                       ...,\n",
       "                       [ 0.0783, -0.0260,  0.0638,  0.0338,  0.0096],\n",
       "                       [ 0.0115,  0.0455,  0.0435,  0.0109, -0.0641],\n",
       "                       [ 0.0210, -0.0198,  0.0508,  0.0690, -0.0831]],\n",
       "              \n",
       "                      [[-0.0371, -0.0980, -0.1335, -0.0326,  0.1524],\n",
       "                       [-0.0761, -0.0580, -0.0129, -0.0514, -0.0040],\n",
       "                       [-0.1499, -0.0150, -0.0092, -0.1002, -0.1156],\n",
       "                       ...,\n",
       "                       [-0.1336, -0.0441,  0.0788,  0.0535,  0.0330],\n",
       "                       [ 0.0216, -0.1529,  0.0017,  0.1496,  0.0180],\n",
       "                       [ 0.0853, -0.0043, -0.0247,  0.0088,  0.0530]],\n",
       "              \n",
       "                      [[ 0.0390, -0.0798,  0.0299,  0.0353,  0.0489],\n",
       "                       [ 0.0220, -0.1562, -0.0673, -0.1119,  0.1118],\n",
       "                       [ 0.0406, -0.0420,  0.0609,  0.1055, -0.0913],\n",
       "                       ...,\n",
       "                       [-0.1312, -0.0054,  0.0705, -0.0770,  0.0593],\n",
       "                       [-0.0046, -0.0738,  0.1191,  0.0335,  0.0504],\n",
       "                       [-0.0950,  0.1289,  0.0746,  0.0174, -0.0401]]], dtype=torch.float64)),\n",
       "             ('6.16.convs.1.1.weight',\n",
       "              tensor([0.9521, 0.9663, 0.9419, 0.9671, 1.0194, 0.9439, 0.9950, 0.9539, 0.9640,\n",
       "                      0.9785, 0.9245, 0.9682, 0.9661, 0.9759, 0.9984, 0.9626, 0.9533, 0.9649,\n",
       "                      0.9754, 0.9531, 0.9816, 0.9421, 1.0038, 0.9764, 0.9616, 0.9579, 0.9554,\n",
       "                      0.9736, 0.9662, 0.9372, 0.9691, 0.9603, 0.9606, 0.9221, 0.9600, 0.9773,\n",
       "                      0.9938, 0.9632, 1.0066, 0.9742, 0.9760, 0.9704, 1.0337, 0.9769, 0.9782,\n",
       "                      0.9478, 0.9541, 0.9743, 0.9941, 0.9371, 0.9572, 0.9273, 1.0007, 0.9460,\n",
       "                      0.9810, 0.9513, 0.9822, 0.9660, 0.9393, 0.9559, 0.9687, 0.9425, 0.9770,\n",
       "                      0.9621], dtype=torch.float64)),\n",
       "             ('6.16.convs.1.1.bias',\n",
       "              tensor([-0.0354,  0.0144, -0.0082, -0.0069,  0.0244, -0.0049,  0.0041, -0.0045,\n",
       "                      -0.0102, -0.0095, -0.0307,  0.0032,  0.0032,  0.0102, -0.0125, -0.0081,\n",
       "                      -0.0010, -0.0095, -0.0050, -0.0092,  0.0172,  0.0005, -0.0234,  0.0026,\n",
       "                      -0.0236, -0.0175,  0.0005, -0.0204,  0.0004, -0.0250,  0.0141, -0.0213,\n",
       "                       0.0062, -0.0177,  0.0106,  0.0018,  0.0005, -0.0092,  0.0218, -0.0095,\n",
       "                       0.0106,  0.0002,  0.0192, -0.0051, -0.0242, -0.0034, -0.0052,  0.0131,\n",
       "                       0.0257, -0.0280, -0.0126, -0.0361,  0.0197, -0.0236,  0.0092, -0.0268,\n",
       "                      -0.0272, -0.0179, -0.0069, -0.0019, -0.0130, -0.0106,  0.0071, -0.0072],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.16.convs.1.1.running_mean',\n",
       "              tensor([ 0.3796, -0.3983, -0.7651, -0.0324,  0.3357,  0.0143,  0.0337, -0.5383,\n",
       "                       0.0723, -0.3463,  0.5091,  0.3380,  0.0919, -0.0493, -0.2716, -0.0137,\n",
       "                      -0.0227,  0.4798, -0.4945,  0.1577, -0.4114, -0.4955, -0.0542, -0.2214,\n",
       "                      -0.1997,  0.4557, -0.4343, -0.0194, -1.2919, -0.1384,  0.5426,  0.7191,\n",
       "                       0.2690, -1.1025, -0.2469, -0.0124,  0.4420, -0.0629, -0.0067,  0.3446,\n",
       "                       0.0428, -0.7081,  0.0539,  0.6643,  0.3667, -0.6925, -0.0742, -0.0649,\n",
       "                       0.0947, -0.4319,  0.2873,  0.3959, -0.1346,  0.0755, -0.7097, -0.0335,\n",
       "                       0.9937, -0.1613,  0.0135, -0.5595,  0.4577, -0.3138, -0.9171, -0.2414],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.16.convs.1.1.running_var',\n",
       "              tensor([0.5643, 0.6416, 0.9706, 0.5738, 0.5148, 0.5681, 0.6402, 0.6911, 0.5865,\n",
       "                      0.4405, 0.6877, 0.5318, 0.6561, 0.7423, 0.5779, 0.4612, 0.6561, 0.5076,\n",
       "                      0.6750, 0.9432, 0.4387, 0.8454, 0.7202, 0.3461, 0.5043, 0.4775, 0.5518,\n",
       "                      0.6444, 0.8404, 0.5568, 0.5134, 0.4892, 0.4832, 0.6589, 1.0680, 0.5413,\n",
       "                      0.4567, 0.7856, 0.4941, 0.6084, 0.5559, 0.5024, 0.6621, 0.5626, 0.3897,\n",
       "                      0.6590, 0.5006, 0.8367, 0.4844, 0.7295, 1.0898, 0.5473, 0.7793, 0.5465,\n",
       "                      0.4796, 0.7566, 0.5572, 0.6338, 0.5360, 0.9785, 0.7664, 1.0578, 0.5516,\n",
       "                      0.6342], dtype=torch.float64)),\n",
       "             ('6.16.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.16.convs.2.0.weight',\n",
       "              tensor([[[ 0.0930],\n",
       "                       [ 0.0412],\n",
       "                       [-0.0414],\n",
       "                       ...,\n",
       "                       [ 0.0876],\n",
       "                       [-0.0330],\n",
       "                       [-0.0239]],\n",
       "              \n",
       "                      [[ 0.0033],\n",
       "                       [ 0.1032],\n",
       "                       [ 0.0673],\n",
       "                       ...,\n",
       "                       [-0.0214],\n",
       "                       [ 0.0200],\n",
       "                       [-0.0275]],\n",
       "              \n",
       "                      [[ 0.0295],\n",
       "                       [-0.0573],\n",
       "                       [ 0.1216],\n",
       "                       ...,\n",
       "                       [ 0.0039],\n",
       "                       [ 0.0025],\n",
       "                       [-0.3180]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1113],\n",
       "                       [-0.4144],\n",
       "                       [-0.0549],\n",
       "                       ...,\n",
       "                       [ 0.2064],\n",
       "                       [ 0.2598],\n",
       "                       [ 0.0462]],\n",
       "              \n",
       "                      [[ 0.0325],\n",
       "                       [-0.0147],\n",
       "                       [ 0.0393],\n",
       "                       ...,\n",
       "                       [-0.0517],\n",
       "                       [ 0.0677],\n",
       "                       [-0.0752]],\n",
       "              \n",
       "                      [[ 0.0882],\n",
       "                       [ 0.0162],\n",
       "                       [ 0.1092],\n",
       "                       ...,\n",
       "                       [ 0.1672],\n",
       "                       [ 0.0101],\n",
       "                       [ 0.0132]]], dtype=torch.float64)),\n",
       "             ('6.16.convs.2.1.weight',\n",
       "              tensor([-4.2887e-03,  5.3547e-03,  2.8098e-02, -4.1148e-02,  8.9659e-03,\n",
       "                       1.4052e-02,  1.7672e-02, -1.5002e-02,  2.2406e-02,  1.4576e-02,\n",
       "                       1.8012e-02,  1.5807e-02,  8.0291e-03,  2.1013e-02, -3.6874e-02,\n",
       "                       3.1353e-02, -2.3360e-02,  1.6778e-02, -1.3213e-02,  2.6153e-02,\n",
       "                       1.6228e-02,  4.0400e-02, -2.8806e-03,  9.2256e-03, -1.0633e-02,\n",
       "                      -1.7746e-02, -3.0937e-04, -2.2479e-02, -9.0966e-03,  1.6908e-02,\n",
       "                       1.0458e-02,  3.0138e-02,  1.4046e-03,  4.1998e-02, -8.7236e-03,\n",
       "                      -3.0711e-02,  5.2909e-03, -1.8230e-03,  3.3795e-02, -2.7628e-02,\n",
       "                      -3.0381e-02, -8.2002e-03, -8.7711e-03,  2.1332e-02,  2.7518e-03,\n",
       "                       2.8232e-03,  1.2952e-02, -1.8517e-02, -1.1196e-04,  3.3431e-03,\n",
       "                       3.9941e-03,  2.9208e-02,  1.6043e-02,  1.7105e-02, -3.2334e-03,\n",
       "                       1.2888e-03, -1.2872e-02,  4.3753e-02,  3.0307e-02,  2.2347e-03,\n",
       "                       1.3201e-02,  1.2301e-02, -4.7794e-03, -6.8303e-03, -1.6982e-02,\n",
       "                      -7.4266e-03, -2.1852e-02,  2.3630e-02, -1.6068e-02, -6.8652e-03,\n",
       "                      -1.6146e-02, -2.3270e-02,  3.4155e-03,  7.5641e-03, -4.4102e-02,\n",
       "                       7.8778e-03, -3.1041e-02, -8.7155e-03, -3.3446e-02, -1.2616e-02,\n",
       "                      -1.3742e-02,  1.7855e-03,  9.3243e-03,  2.0487e-02, -8.5238e-03,\n",
       "                       4.2211e-02, -4.9792e-03,  1.0958e-02,  1.9776e-02,  3.1619e-04,\n",
       "                      -5.9298e-03, -1.3137e-02,  2.5259e-02, -2.8567e-02, -4.5968e-03,\n",
       "                       1.3717e-02,  1.4659e-02,  1.9317e-02,  4.4472e-03,  1.0376e-02,\n",
       "                       8.2648e-03, -3.5143e-02, -2.3706e-02, -1.9286e-03, -1.1590e-02,\n",
       "                      -2.5200e-02, -9.1530e-03, -9.3763e-03, -3.7565e-02,  2.7193e-03,\n",
       "                      -2.4676e-02, -1.6890e-02, -2.7430e-02,  9.2596e-03, -2.7572e-02,\n",
       "                       1.5723e-02, -6.4210e-03,  1.3429e-02,  1.3513e-02, -7.3940e-03,\n",
       "                      -7.8988e-03, -1.3452e-02, -1.7926e-02, -3.2606e-02, -1.9435e-02,\n",
       "                       4.6131e-04, -1.0693e-02, -1.7958e-02, -2.9680e-02,  1.3550e-02,\n",
       "                      -6.2280e-03,  7.3637e-03, -2.6189e-02,  9.6368e-03, -4.1867e-03,\n",
       "                       2.0588e-03, -3.4247e-02,  1.5086e-02,  2.2798e-02,  5.0421e-06,\n",
       "                       2.2978e-02,  1.0273e-02,  2.1271e-02, -5.8057e-03, -5.8482e-03,\n",
       "                       1.0571e-02,  1.5283e-02,  2.4695e-02, -1.4543e-02,  1.6483e-02,\n",
       "                       3.1754e-03, -7.9288e-03,  1.1269e-02, -2.2481e-02, -1.2273e-02,\n",
       "                      -4.5980e-03, -1.9678e-02, -1.4204e-02, -1.3493e-02, -2.5066e-02,\n",
       "                       4.3385e-03, -6.1403e-03,  1.4905e-02, -7.7507e-04,  2.5668e-02,\n",
       "                       9.5060e-03, -1.1172e-02, -1.9561e-02,  2.6481e-02, -4.9491e-02,\n",
       "                       7.9912e-03, -7.5990e-03,  6.6821e-03,  1.3816e-02,  2.3499e-02,\n",
       "                      -2.6853e-03,  1.5853e-02,  3.8100e-02, -1.3817e-02,  1.1213e-02,\n",
       "                      -1.1415e-02,  1.6445e-02, -9.3296e-03,  1.3714e-02,  6.2017e-03,\n",
       "                      -1.7782e-02,  3.5762e-02, -2.9937e-02, -2.7340e-03, -1.9184e-02,\n",
       "                       5.8794e-05,  1.2618e-02, -6.5432e-03, -2.5166e-02, -2.2505e-02,\n",
       "                       1.5141e-02,  2.1169e-02, -1.0039e-02, -4.4835e-03,  2.2034e-02,\n",
       "                       1.0826e-03,  9.1657e-03,  8.5009e-03, -1.1663e-02, -8.6444e-03,\n",
       "                       1.0814e-02,  2.4179e-03, -1.3879e-02,  6.6626e-03, -3.1775e-02,\n",
       "                      -1.1022e-03,  1.3412e-02,  1.0795e-02,  1.0487e-02,  8.4371e-03,\n",
       "                       1.0807e-02, -7.4968e-03, -1.3240e-02, -1.0706e-02, -2.7411e-02,\n",
       "                      -1.4444e-02, -2.9956e-02,  1.0542e-02, -4.6799e-03,  9.1211e-03,\n",
       "                      -1.8913e-02, -2.4750e-03,  4.2870e-03, -1.7951e-02, -1.7830e-02,\n",
       "                      -1.9307e-02,  3.8218e-03, -8.0723e-03,  1.3052e-02,  1.8856e-02,\n",
       "                       2.1231e-02,  1.7566e-03,  8.4203e-03, -2.1740e-03,  7.3546e-03,\n",
       "                       4.1479e-02,  8.6095e-03, -3.2123e-02,  6.4610e-03, -3.0998e-02,\n",
       "                       3.0812e-02, -1.4489e-02,  2.4966e-02,  1.9497e-03, -3.1294e-02,\n",
       "                      -1.2307e-02, -6.4975e-03, -3.1969e-03,  1.2752e-02, -6.7522e-03,\n",
       "                      -6.9401e-03], dtype=torch.float64)),\n",
       "             ('6.16.convs.2.1.bias',\n",
       "              tensor([ 1.3239e-04,  5.9952e-03,  9.3251e-03,  1.4057e-02, -4.1340e-04,\n",
       "                       5.8669e-03,  5.9947e-03, -3.6517e-03,  1.1120e-02,  1.6620e-02,\n",
       "                       1.4444e-02, -7.4460e-03,  3.9039e-03, -7.1543e-03,  8.7027e-03,\n",
       "                       4.4965e-03,  2.6014e-02,  9.9015e-04,  1.2080e-02, -2.5601e-04,\n",
       "                      -1.0805e-02,  2.4438e-03,  8.3434e-03,  6.9587e-03,  9.6617e-03,\n",
       "                      -2.1555e-02,  6.7647e-03,  1.2255e-02,  1.2894e-02, -4.9601e-03,\n",
       "                      -3.4266e-03,  1.0724e-02,  4.4924e-03,  2.1441e-02,  8.8721e-03,\n",
       "                       1.1025e-02, -6.1305e-03,  1.0371e-02,  2.1027e-02,  6.2433e-03,\n",
       "                       2.8081e-03,  7.2477e-03, -6.6896e-03, -4.0474e-03,  7.3500e-03,\n",
       "                      -1.6637e-02,  1.6194e-02,  1.0437e-02, -1.3652e-02, -4.1064e-04,\n",
       "                       1.1147e-02,  2.7983e-03,  3.6667e-03,  2.0729e-02,  3.1084e-04,\n",
       "                       1.3225e-02,  1.0156e-02,  2.6511e-03,  1.2527e-02, -4.0934e-03,\n",
       "                      -4.0890e-04,  1.0625e-03,  8.7474e-03,  9.1291e-03, -7.7499e-03,\n",
       "                       1.9510e-04, -7.9020e-03,  1.2744e-02,  1.5976e-02, -1.4377e-02,\n",
       "                       7.3737e-03, -2.4469e-03, -7.3329e-04, -7.4612e-03,  1.3656e-02,\n",
       "                       8.3042e-03,  2.3329e-04,  9.6921e-03,  2.4927e-04,  1.7013e-02,\n",
       "                       4.6550e-03, -7.8937e-03,  1.3986e-02,  3.6012e-03, -5.0575e-03,\n",
       "                       1.7210e-02, -8.2577e-04,  1.0912e-02,  1.3911e-02, -1.0697e-03,\n",
       "                       7.5105e-04,  1.1527e-02,  1.0212e-02,  1.4002e-02,  8.1182e-03,\n",
       "                      -6.0427e-03,  1.4571e-02,  5.6991e-03,  1.9976e-02,  9.0048e-03,\n",
       "                       2.3133e-02,  1.6251e-02,  6.4168e-03,  1.2667e-02,  6.1930e-03,\n",
       "                       3.4247e-03, -7.1713e-03,  1.1359e-02,  7.3542e-03,  6.2848e-03,\n",
       "                       1.1315e-03, -9.3433e-03,  1.5573e-03,  2.1615e-02,  1.5572e-02,\n",
       "                       5.5938e-03,  5.6072e-03,  4.2924e-03,  4.6647e-03, -5.7760e-03,\n",
       "                      -2.4097e-04,  1.1999e-02,  4.8271e-03,  4.6796e-03,  2.1520e-02,\n",
       "                       8.2732e-03,  6.0123e-03,  5.5142e-03,  8.7275e-03,  1.5135e-02,\n",
       "                       6.5944e-03,  5.8353e-03,  1.4577e-02,  2.2841e-03,  5.9913e-03,\n",
       "                      -1.6714e-02,  1.5067e-02,  3.3433e-03,  5.1037e-03,  8.2408e-03,\n",
       "                       1.3740e-02,  7.8210e-03,  1.5095e-02,  3.5819e-03, -8.0414e-03,\n",
       "                       9.6777e-03,  8.8312e-03, -2.1516e-03,  5.8577e-03,  4.2446e-03,\n",
       "                       7.9761e-03,  1.0870e-02,  5.4885e-03,  1.1858e-02,  1.4177e-02,\n",
       "                       3.3224e-03, -3.9424e-04,  5.9704e-03, -1.0368e-03, -7.0068e-04,\n",
       "                       4.7409e-03,  9.2333e-03, -2.8326e-03,  6.1248e-03,  1.0726e-02,\n",
       "                      -4.6764e-03, -1.4223e-02,  5.3103e-03,  6.3637e-03,  1.7889e-02,\n",
       "                       4.1875e-03, -1.0991e-03,  9.7235e-03,  1.4793e-02, -1.3577e-02,\n",
       "                       1.2898e-02,  1.8470e-03,  1.8432e-02,  2.6971e-03,  6.9354e-03,\n",
       "                       3.2598e-04,  1.0614e-02, -3.0122e-03, -8.6167e-03,  1.0016e-02,\n",
       "                       7.2768e-03,  1.3332e-02,  1.0278e-02,  8.3826e-03,  8.0632e-03,\n",
       "                       6.1904e-03,  5.0412e-03,  6.2193e-03,  1.2392e-03, -1.3277e-03,\n",
       "                       1.0656e-02,  1.0794e-02,  1.8575e-03,  6.0470e-03,  1.5418e-02,\n",
       "                      -2.1556e-03,  2.2473e-02,  1.6429e-02,  1.6354e-02,  1.7115e-02,\n",
       "                       1.5950e-03,  8.7438e-03, -1.2510e-02,  4.0747e-03,  9.9341e-03,\n",
       "                       9.7133e-03,  1.1614e-02, -7.8708e-04,  7.6011e-03,  6.0641e-03,\n",
       "                       7.1787e-03,  2.5677e-03,  1.6120e-02,  2.7974e-03,  1.7038e-03,\n",
       "                       1.2634e-02,  3.3191e-03,  3.7477e-03,  1.3246e-02,  8.3140e-03,\n",
       "                       6.1698e-03, -8.1395e-03, -1.6029e-03,  2.8262e-02,  1.9504e-02,\n",
       "                       4.4171e-03,  5.8607e-04,  6.3725e-03,  1.2017e-02,  7.5251e-04,\n",
       "                       1.0322e-02,  1.3695e-05,  1.4474e-02,  4.4732e-03,  1.3578e-02,\n",
       "                      -9.4972e-04,  7.3473e-03, -3.1719e-03,  1.3425e-02,  7.1577e-03,\n",
       "                       8.9096e-03,  4.7802e-03,  2.0985e-03, -1.1745e-02, -9.2216e-03,\n",
       "                       1.8780e-02,  2.2160e-02,  1.4048e-02,  1.7082e-02,  3.3521e-03,\n",
       "                       1.1426e-03], dtype=torch.float64)),\n",
       "             ('6.16.convs.2.1.running_mean',\n",
       "              tensor([ 6.1306e-01, -6.2078e-03, -1.8435e-01,  6.5953e-02,  1.9692e-02,\n",
       "                       6.8546e-01,  4.8946e-01,  4.5521e-01,  1.0915e-01,  2.0139e-01,\n",
       "                      -1.1507e-01, -1.9916e-01,  1.0243e-01,  2.0044e-01,  7.8897e-03,\n",
       "                      -1.1108e+00,  3.9688e-01,  1.3976e-01,  3.9393e-01, -2.2625e-01,\n",
       "                       2.1822e-01, -7.7434e-01,  3.6786e-02, -7.0005e-01,  8.0393e-02,\n",
       "                       2.4291e-01, -2.2736e-01, -1.3886e-01,  3.3794e-01,  5.1980e-01,\n",
       "                      -4.9370e-01, -2.7451e-01, -1.1982e-01,  4.4666e-01,  1.9052e-01,\n",
       "                      -2.3208e-01, -2.6255e-02,  6.3425e-01, -6.0396e-02, -1.0914e-01,\n",
       "                       3.8388e-01, -1.2205e-01,  2.3332e-01,  5.0189e-01,  1.4234e-01,\n",
       "                       5.5909e-02, -1.9562e-01, -4.9734e-01,  1.0565e+00,  6.2301e-01,\n",
       "                       1.2532e-01,  2.3393e-01, -3.9227e-01,  1.1734e-01, -4.2162e-04,\n",
       "                      -8.7809e-01, -2.9131e-01,  1.2416e-01, -9.1970e-02, -4.9564e-02,\n",
       "                      -5.9136e-02, -1.5892e-01,  3.1150e-01,  3.0159e-01,  8.7612e-01,\n",
       "                      -3.6963e-01,  6.2932e-01, -2.7327e-01, -1.5035e-01,  6.2895e-01,\n",
       "                      -8.6141e-01,  2.2655e-01,  6.6538e-02, -3.6014e-01,  4.1273e-01,\n",
       "                       9.6808e-02, -5.0759e-02,  3.4167e-01,  3.7929e-02,  5.1091e-01,\n",
       "                      -2.6523e-01,  3.4326e-01, -2.5974e-02,  3.8641e-01,  1.7151e-01,\n",
       "                      -6.7585e-02, -7.5243e-01, -7.6153e-02,  4.0592e-01,  2.8271e-01,\n",
       "                      -3.0570e-01, -6.0099e-01,  2.9698e-01, -3.2425e-01,  2.1180e-01,\n",
       "                       8.7377e-03, -5.2692e-01, -5.1686e-01,  4.1962e-02,  2.2891e-01,\n",
       "                      -8.2175e-01, -1.0140e+00,  1.9329e-01, -2.7158e-01, -2.8176e-01,\n",
       "                      -8.4360e-02, -7.1051e-01, -8.5633e-01,  5.0236e-01,  1.4016e-01,\n",
       "                       2.2585e-01, -5.8610e-01, -2.1127e-02,  4.5338e-01, -4.3334e-01,\n",
       "                      -4.8692e-02,  2.3909e-01, -9.4583e-01,  3.4418e-01,  3.8721e-01,\n",
       "                      -2.0788e-01,  9.4788e-02,  6.5160e-01, -1.3896e-01, -3.3092e-01,\n",
       "                       5.7804e-01,  1.5541e-01, -4.3961e-02,  4.8244e-01, -3.2292e-01,\n",
       "                       6.1213e-02, -2.8619e-01, -6.0153e-01, -2.5566e-01, -1.8018e-01,\n",
       "                      -2.5891e-01,  4.9818e-02,  3.5354e-01, -3.6644e-02,  2.4181e-01,\n",
       "                      -1.9632e-01,  9.1498e-01,  1.2314e-01,  5.2392e-01, -1.4135e-01,\n",
       "                      -2.3385e-01,  3.5498e-01,  2.6323e-01,  1.3812e-01,  4.2290e-01,\n",
       "                       1.3710e-01,  1.4288e+00,  1.6401e-01,  6.4494e-01, -4.8343e-01,\n",
       "                      -2.2728e-01, -1.3081e-01,  1.9859e-01,  5.1851e-01,  1.7820e-01,\n",
       "                       6.8328e-02, -2.1686e-01, -1.3230e-01,  1.6343e-01, -2.3534e-01,\n",
       "                       8.2609e-01,  6.6073e-01, -6.2572e-01, -8.0333e-01, -1.3264e-01,\n",
       "                       5.9903e-01, -3.0722e-02,  3.3766e-01,  5.1450e-02,  5.1100e-01,\n",
       "                       4.3058e-01, -5.0604e-01, -3.3865e-01, -2.2567e-01, -1.7736e-01,\n",
       "                      -1.4153e-02,  3.4312e-01,  1.0110e+00,  1.6017e-01, -2.2221e-01,\n",
       "                      -1.6938e-01, -5.8114e-01, -5.0691e-01,  3.6252e-01,  3.0749e-02,\n",
       "                      -1.3048e-01, -5.6993e-01, -3.5579e-01, -3.9806e-01, -8.5054e-01,\n",
       "                       9.7509e-03,  8.1117e-02, -4.4937e-01,  6.6542e-01,  4.4782e-01,\n",
       "                      -2.6690e-02,  1.2220e-01,  2.6535e-01, -7.1831e-01,  7.6122e-02,\n",
       "                      -2.0710e-01,  1.3585e-02, -1.8125e-01, -9.8350e-02,  4.3923e-01,\n",
       "                       4.4509e-01, -1.0687e-01,  3.3277e-01,  5.9799e-01,  7.0560e-01,\n",
       "                      -5.7123e-02,  6.0254e-02, -9.3929e-02,  2.2802e-01, -4.0039e-02,\n",
       "                       1.5842e-02, -8.7733e-01,  6.4256e-02, -7.1610e-02, -3.6014e-01,\n",
       "                      -1.9152e-01, -7.4374e-01,  2.2500e-02,  6.1319e-02, -3.0701e-01,\n",
       "                      -2.2476e-01,  5.4270e-02,  4.3336e-01, -4.5984e-01,  4.4515e-02,\n",
       "                       3.7807e-01,  1.5538e-01,  6.2516e-01,  1.8614e-01,  3.7799e-01,\n",
       "                       6.4289e-01,  8.5381e-01,  3.7553e-01, -3.1792e-01,  5.8097e-01,\n",
       "                      -8.7172e-02, -3.8625e-02, -5.6988e-02,  3.7833e-02,  2.4193e-01,\n",
       "                      -2.4288e-01,  4.2301e-01, -2.2027e-01, -3.0302e-01,  1.0070e-01,\n",
       "                       9.8010e-01], dtype=torch.float64)),\n",
       "             ('6.16.convs.2.1.running_var',\n",
       "              tensor([0.3133, 0.1922, 0.3422, 0.4176, 0.3093, 0.2284, 0.3108, 0.5188, 0.2302,\n",
       "                      0.4271, 0.2768, 0.3147, 0.0466, 0.4343, 0.4955, 0.4783, 0.2291, 0.4844,\n",
       "                      0.1740, 0.5771, 0.2095, 0.3850, 0.1939, 0.3683, 0.3818, 0.2451, 0.1651,\n",
       "                      0.3108, 0.1634, 0.3742, 0.4722, 0.7049, 0.0644, 0.4734, 0.2857, 0.3992,\n",
       "                      0.3182, 0.2040, 0.3829, 0.2944, 0.6267, 0.3199, 0.3212, 0.5727, 0.2603,\n",
       "                      0.1812, 0.7401, 0.2705, 0.3074, 0.3129, 0.1301, 0.4902, 0.2484, 0.2459,\n",
       "                      0.2344, 0.4069, 0.6537, 0.4933, 0.5320, 0.1483, 0.2342, 0.1491, 0.1204,\n",
       "                      0.3233, 0.6566, 0.4202, 0.4079, 0.3538, 0.2616, 0.4105, 0.7248, 0.3265,\n",
       "                      0.0663, 0.4411, 0.5530, 0.0937, 0.4070, 0.3388, 0.4188, 0.3898, 0.5769,\n",
       "                      0.1645, 0.3725, 0.4534, 0.1581, 0.5219, 0.2435, 0.4300, 0.5928, 0.3090,\n",
       "                      0.2796, 0.3137, 0.3389, 0.3986, 0.3343, 0.2211, 0.4333, 0.5383, 0.1850,\n",
       "                      0.1930, 0.4125, 0.5704, 0.3220, 0.2697, 0.4498, 0.5880, 0.4425, 0.4711,\n",
       "                      0.5014, 0.1203, 0.3135, 0.3679, 0.3669, 0.2458, 0.5322, 0.5680, 0.1994,\n",
       "                      0.2871, 0.2653, 0.4116, 0.2745, 0.4457, 0.5028, 0.4277, 0.2836, 0.4855,\n",
       "                      0.1778, 0.2352, 0.4457, 0.4371, 0.0583, 0.3205, 0.6673, 0.1172, 0.2534,\n",
       "                      0.0734, 0.4079, 0.3415, 0.5969, 0.1359, 0.3046, 0.3069, 0.3308, 0.2062,\n",
       "                      0.2927, 0.5014, 0.1463, 0.5133, 0.1067, 0.7088, 0.2917, 0.3569, 0.3563,\n",
       "                      0.4550, 0.4520, 0.1508, 0.3734, 0.1910, 0.4831, 0.3506, 0.2492, 0.1979,\n",
       "                      0.5237, 0.1145, 0.5266, 0.4935, 0.4422, 0.2838, 0.3637, 0.4010, 0.1738,\n",
       "                      0.0760, 0.1718, 0.2479, 0.5964, 0.2508, 0.4666, 0.3105, 0.2718, 0.3246,\n",
       "                      0.2973, 0.2534, 0.4928, 0.4504, 0.2600, 0.4325, 0.3286, 0.2124, 0.2420,\n",
       "                      0.6731, 0.2501, 0.2855, 0.3022, 0.5669, 0.3630, 0.4219, 0.4059, 0.2435,\n",
       "                      0.2839, 0.4457, 0.1439, 0.3331, 0.3270, 0.3455, 0.1955, 0.6198, 0.0509,\n",
       "                      0.0718, 0.0685, 0.4660, 0.0890, 0.3144, 0.3449, 0.3180, 0.1373, 0.1355,\n",
       "                      0.3570, 0.1986, 0.3384, 0.5744, 0.2798, 0.3902, 0.1597, 0.1455, 0.3579,\n",
       "                      0.6040, 0.2347, 0.1471, 0.6010, 0.3557, 0.2532, 0.2359, 0.3658, 0.5241,\n",
       "                      0.3923, 0.4290, 0.1312, 0.3150, 0.1041, 0.3859, 0.4342, 0.2519, 0.3787,\n",
       "                      0.2352, 0.4382, 0.4002, 0.4378, 0.4208, 0.0396, 0.5058, 0.2718, 0.4559,\n",
       "                      0.0972, 0.4081, 0.1595, 0.3917], dtype=torch.float64)),\n",
       "             ('6.16.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.16.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0849],\n",
       "                       [ 0.0370],\n",
       "                       [ 0.0660],\n",
       "                       ...,\n",
       "                       [ 0.0349],\n",
       "                       [ 0.0190],\n",
       "                       [ 0.0572]],\n",
       "              \n",
       "                      [[ 0.1340],\n",
       "                       [-0.0127],\n",
       "                       [-0.1204],\n",
       "                       ...,\n",
       "                       [ 0.0607],\n",
       "                       [ 0.0385],\n",
       "                       [ 0.0542]],\n",
       "              \n",
       "                      [[-0.0033],\n",
       "                       [ 0.0583],\n",
       "                       [ 0.0407],\n",
       "                       ...,\n",
       "                       [-0.0902],\n",
       "                       [-0.1398],\n",
       "                       [-0.0860]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1042],\n",
       "                       [-0.1574],\n",
       "                       [-0.0387],\n",
       "                       ...,\n",
       "                       [ 0.0432],\n",
       "                       [ 0.0390],\n",
       "                       [ 0.0041]],\n",
       "              \n",
       "                      [[ 0.0076],\n",
       "                       [ 0.0651],\n",
       "                       [-0.0265],\n",
       "                       ...,\n",
       "                       [ 0.1583],\n",
       "                       [ 0.1733],\n",
       "                       [ 0.0527]],\n",
       "              \n",
       "                      [[ 0.1249],\n",
       "                       [-0.0949],\n",
       "                       [-0.0671],\n",
       "                       ...,\n",
       "                       [-0.1007],\n",
       "                       [-0.0337],\n",
       "                       [-0.0539]]], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.0.1.weight',\n",
       "              tensor([1.0204, 0.9983, 0.9722, 0.9709, 0.9496, 0.9767, 0.9625, 0.9766, 0.9750,\n",
       "                      1.0028, 0.9789, 0.9604, 0.9579, 0.9582, 0.9726, 0.9695, 0.9591, 0.9919,\n",
       "                      0.9730, 0.9733, 0.9822, 0.9740, 0.9776, 0.9634, 0.9870, 0.9621, 0.9761,\n",
       "                      0.9525, 0.9793, 0.9947, 0.9793, 0.9809, 1.0071, 0.9582, 0.9795, 0.9642,\n",
       "                      0.9817, 0.9942, 0.9596, 0.9613, 0.9832, 0.9603, 0.9715, 0.9670, 0.9693,\n",
       "                      0.9862, 0.9944, 0.9899, 0.9428, 0.9702, 1.0020, 0.9859, 0.9851, 0.9738,\n",
       "                      0.9715, 0.9766, 0.9613, 0.9507, 0.9693, 0.9697, 0.9631, 0.9612, 0.9928,\n",
       "                      0.9599], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.0.1.bias',\n",
       "              tensor([ 3.7872e-02,  1.7528e-02,  9.4606e-04,  6.7585e-03, -9.2415e-03,\n",
       "                       7.4245e-03,  3.3601e-03, -5.3582e-03,  8.7345e-03,  1.9513e-02,\n",
       "                      -9.6278e-04, -1.5136e-02, -5.4815e-03, -1.4322e-02,  3.6464e-03,\n",
       "                       8.7829e-03, -4.4805e-03,  2.0636e-02, -3.5340e-03, -8.0657e-03,\n",
       "                       1.6374e-02, -4.2637e-03,  6.8740e-03,  4.2311e-04,  6.6076e-04,\n",
       "                      -4.9033e-03,  1.1023e-02, -1.3583e-02,  1.1037e-02,  6.1770e-03,\n",
       "                       8.7457e-03,  9.7177e-03,  1.3991e-02,  1.2460e-02,  4.3055e-04,\n",
       "                       1.4306e-02,  1.7489e-02, -8.1642e-05,  2.2225e-03,  1.2362e-03,\n",
       "                      -5.1253e-03, -1.2712e-02,  1.0149e-02, -1.7798e-03,  3.5995e-03,\n",
       "                       9.3915e-03,  1.9896e-02,  1.2670e-02, -3.2209e-02, -3.8582e-03,\n",
       "                       3.0761e-02,  9.0579e-03,  2.9330e-02,  1.1309e-02,  3.7868e-03,\n",
       "                      -2.3350e-03,  3.4725e-03, -3.8650e-03,  3.3181e-03, -6.6589e-04,\n",
       "                      -5.7606e-03,  1.2657e-03,  1.0486e-02, -1.4904e-02],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.2091, -0.3048, -1.1237,  1.1509,  0.7080, -0.8807, -0.1687, -0.8891,\n",
       "                      -0.9276,  0.6444,  0.3535,  0.6074,  1.7552,  0.6510,  0.1953, -0.8793,\n",
       "                      -0.4890, -0.5889, -0.0730, -0.5934, -0.1562, -0.1691, -0.0669, -0.3359,\n",
       "                      -0.3484,  0.2112,  0.7949,  0.6647,  0.8641,  0.3263, -0.4912,  0.1529,\n",
       "                      -0.0412, -1.2238,  0.2319, -0.7661, -0.0840, -0.1459, -0.0771,  0.6293,\n",
       "                       0.3002,  0.2458, -0.4420,  0.4570, -1.0461,  0.1204, -1.3301, -0.3564,\n",
       "                      -0.0401,  1.1795,  0.2219, -0.0931, -0.0042, -0.3307,  0.3959,  0.6692,\n",
       "                      -0.8969,  0.4309,  0.4061, -1.0083, -0.9263, -0.9333, -0.3082, -0.1359],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.0.1.running_var',\n",
       "              tensor([0.1525, 0.1737, 0.1394, 0.2540, 0.4210, 0.1965, 0.2169, 0.2674, 0.1344,\n",
       "                      0.0966, 0.1535, 0.2333, 1.5348, 1.0286, 0.2110, 0.1943, 0.2559, 0.1814,\n",
       "                      0.1055, 0.1294, 0.2185, 0.1433, 0.1353, 0.1014, 0.1175, 0.1602, 0.1496,\n",
       "                      0.1953, 0.1265, 0.2047, 0.1056, 0.3393, 0.1275, 1.1701, 0.1572, 0.1764,\n",
       "                      0.5158, 0.3284, 0.1791, 1.6581, 0.2850, 0.2629, 0.3453, 0.1870, 0.7823,\n",
       "                      0.4712, 0.2041, 0.1751, 0.1437, 0.4975, 0.1308, 0.1125, 0.1751, 0.1249,\n",
       "                      0.9092, 0.1291, 0.3944, 0.4786, 0.3618, 0.1770, 0.2023, 0.3866, 0.1370,\n",
       "                      0.6383], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.16.convpath.0.1.0.weight',\n",
       "              tensor([[[-0.0495, -0.0257,  0.0729, -0.0628,  0.0664],\n",
       "                       [ 0.0872,  0.0761, -0.1176, -0.0915, -0.0315],\n",
       "                       [ 0.0615,  0.0835, -0.0732,  0.0728,  0.0103],\n",
       "                       ...,\n",
       "                       [-0.0311, -0.0073, -0.0252, -0.0855,  0.1494],\n",
       "                       [-0.0005, -0.0151,  0.1097,  0.0150, -0.0251],\n",
       "                       [-0.0480,  0.1253,  0.0874, -0.0400, -0.0724]],\n",
       "              \n",
       "                      [[ 0.0125,  0.0584,  0.2318,  0.0178,  0.1433],\n",
       "                       [ 0.0839, -0.0259, -0.0564,  0.0386, -0.0003],\n",
       "                       [ 0.1535,  0.0124, -0.0149,  0.1117, -0.0777],\n",
       "                       ...,\n",
       "                       [-0.0654, -0.0153, -0.0812,  0.0630, -0.1094],\n",
       "                       [-0.0259,  0.0435,  0.0299,  0.0790, -0.1026],\n",
       "                       [ 0.0499, -0.0335,  0.0372, -0.0486, -0.0005]],\n",
       "              \n",
       "                      [[ 0.0953,  0.0963,  0.0318,  0.0819, -0.0382],\n",
       "                       [-0.1328,  0.0064, -0.0100,  0.0602,  0.0263],\n",
       "                       [-0.1218, -0.0080, -0.0063, -0.0373,  0.0640],\n",
       "                       ...,\n",
       "                       [ 0.0971,  0.0049, -0.0025, -0.0477, -0.0630],\n",
       "                       [-0.0736, -0.2161, -0.0748,  0.0991,  0.0707],\n",
       "                       [ 0.0634, -0.0100,  0.0149,  0.0701, -0.0062]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1141,  0.0655,  0.0645,  0.0988, -0.0535],\n",
       "                       [ 0.0189,  0.0011,  0.0627,  0.0571, -0.0065],\n",
       "                       [-0.0256, -0.0695,  0.0029, -0.0065, -0.0278],\n",
       "                       ...,\n",
       "                       [ 0.0783, -0.0260,  0.0638,  0.0338,  0.0096],\n",
       "                       [ 0.0115,  0.0455,  0.0435,  0.0109, -0.0641],\n",
       "                       [ 0.0210, -0.0198,  0.0508,  0.0690, -0.0831]],\n",
       "              \n",
       "                      [[-0.0371, -0.0980, -0.1335, -0.0326,  0.1524],\n",
       "                       [-0.0761, -0.0580, -0.0129, -0.0514, -0.0040],\n",
       "                       [-0.1499, -0.0150, -0.0092, -0.1002, -0.1156],\n",
       "                       ...,\n",
       "                       [-0.1336, -0.0441,  0.0788,  0.0535,  0.0330],\n",
       "                       [ 0.0216, -0.1529,  0.0017,  0.1496,  0.0180],\n",
       "                       [ 0.0853, -0.0043, -0.0247,  0.0088,  0.0530]],\n",
       "              \n",
       "                      [[ 0.0390, -0.0798,  0.0299,  0.0353,  0.0489],\n",
       "                       [ 0.0220, -0.1562, -0.0673, -0.1119,  0.1118],\n",
       "                       [ 0.0406, -0.0420,  0.0609,  0.1055, -0.0913],\n",
       "                       ...,\n",
       "                       [-0.1312, -0.0054,  0.0705, -0.0770,  0.0593],\n",
       "                       [-0.0046, -0.0738,  0.1191,  0.0335,  0.0504],\n",
       "                       [-0.0950,  0.1289,  0.0746,  0.0174, -0.0401]]], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.1.1.weight',\n",
       "              tensor([0.9521, 0.9663, 0.9419, 0.9671, 1.0194, 0.9439, 0.9950, 0.9539, 0.9640,\n",
       "                      0.9785, 0.9245, 0.9682, 0.9661, 0.9759, 0.9984, 0.9626, 0.9533, 0.9649,\n",
       "                      0.9754, 0.9531, 0.9816, 0.9421, 1.0038, 0.9764, 0.9616, 0.9579, 0.9554,\n",
       "                      0.9736, 0.9662, 0.9372, 0.9691, 0.9603, 0.9606, 0.9221, 0.9600, 0.9773,\n",
       "                      0.9938, 0.9632, 1.0066, 0.9742, 0.9760, 0.9704, 1.0337, 0.9769, 0.9782,\n",
       "                      0.9478, 0.9541, 0.9743, 0.9941, 0.9371, 0.9572, 0.9273, 1.0007, 0.9460,\n",
       "                      0.9810, 0.9513, 0.9822, 0.9660, 0.9393, 0.9559, 0.9687, 0.9425, 0.9770,\n",
       "                      0.9621], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.1.1.bias',\n",
       "              tensor([-0.0354,  0.0144, -0.0082, -0.0069,  0.0244, -0.0049,  0.0041, -0.0045,\n",
       "                      -0.0102, -0.0095, -0.0307,  0.0032,  0.0032,  0.0102, -0.0125, -0.0081,\n",
       "                      -0.0010, -0.0095, -0.0050, -0.0092,  0.0172,  0.0005, -0.0234,  0.0026,\n",
       "                      -0.0236, -0.0175,  0.0005, -0.0204,  0.0004, -0.0250,  0.0141, -0.0213,\n",
       "                       0.0062, -0.0177,  0.0106,  0.0018,  0.0005, -0.0092,  0.0218, -0.0095,\n",
       "                       0.0106,  0.0002,  0.0192, -0.0051, -0.0242, -0.0034, -0.0052,  0.0131,\n",
       "                       0.0257, -0.0280, -0.0126, -0.0361,  0.0197, -0.0236,  0.0092, -0.0268,\n",
       "                      -0.0272, -0.0179, -0.0069, -0.0019, -0.0130, -0.0106,  0.0071, -0.0072],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.3796, -0.3983, -0.7651, -0.0324,  0.3357,  0.0143,  0.0337, -0.5383,\n",
       "                       0.0723, -0.3463,  0.5091,  0.3380,  0.0919, -0.0493, -0.2716, -0.0137,\n",
       "                      -0.0227,  0.4798, -0.4945,  0.1577, -0.4114, -0.4955, -0.0542, -0.2214,\n",
       "                      -0.1997,  0.4557, -0.4343, -0.0194, -1.2919, -0.1384,  0.5426,  0.7191,\n",
       "                       0.2690, -1.1025, -0.2469, -0.0124,  0.4420, -0.0629, -0.0067,  0.3446,\n",
       "                       0.0428, -0.7081,  0.0539,  0.6643,  0.3667, -0.6925, -0.0742, -0.0649,\n",
       "                       0.0947, -0.4319,  0.2873,  0.3959, -0.1346,  0.0755, -0.7097, -0.0335,\n",
       "                       0.9937, -0.1613,  0.0135, -0.5595,  0.4577, -0.3138, -0.9171, -0.2414],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.1.1.running_var',\n",
       "              tensor([0.5643, 0.6416, 0.9706, 0.5738, 0.5148, 0.5681, 0.6402, 0.6911, 0.5865,\n",
       "                      0.4405, 0.6877, 0.5318, 0.6561, 0.7423, 0.5779, 0.4612, 0.6561, 0.5076,\n",
       "                      0.6750, 0.9432, 0.4387, 0.8454, 0.7202, 0.3461, 0.5043, 0.4775, 0.5518,\n",
       "                      0.6444, 0.8404, 0.5568, 0.5134, 0.4892, 0.4832, 0.6589, 1.0680, 0.5413,\n",
       "                      0.4567, 0.7856, 0.4941, 0.6084, 0.5559, 0.5024, 0.6621, 0.5626, 0.3897,\n",
       "                      0.6590, 0.5006, 0.8367, 0.4844, 0.7295, 1.0898, 0.5473, 0.7793, 0.5465,\n",
       "                      0.4796, 0.7566, 0.5572, 0.6338, 0.5360, 0.9785, 0.7664, 1.0578, 0.5516,\n",
       "                      0.6342], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.16.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0930],\n",
       "                       [ 0.0412],\n",
       "                       [-0.0414],\n",
       "                       ...,\n",
       "                       [ 0.0876],\n",
       "                       [-0.0330],\n",
       "                       [-0.0239]],\n",
       "              \n",
       "                      [[ 0.0033],\n",
       "                       [ 0.1032],\n",
       "                       [ 0.0673],\n",
       "                       ...,\n",
       "                       [-0.0214],\n",
       "                       [ 0.0200],\n",
       "                       [-0.0275]],\n",
       "              \n",
       "                      [[ 0.0295],\n",
       "                       [-0.0573],\n",
       "                       [ 0.1216],\n",
       "                       ...,\n",
       "                       [ 0.0039],\n",
       "                       [ 0.0025],\n",
       "                       [-0.3180]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1113],\n",
       "                       [-0.4144],\n",
       "                       [-0.0549],\n",
       "                       ...,\n",
       "                       [ 0.2064],\n",
       "                       [ 0.2598],\n",
       "                       [ 0.0462]],\n",
       "              \n",
       "                      [[ 0.0325],\n",
       "                       [-0.0147],\n",
       "                       [ 0.0393],\n",
       "                       ...,\n",
       "                       [-0.0517],\n",
       "                       [ 0.0677],\n",
       "                       [-0.0752]],\n",
       "              \n",
       "                      [[ 0.0882],\n",
       "                       [ 0.0162],\n",
       "                       [ 0.1092],\n",
       "                       ...,\n",
       "                       [ 0.1672],\n",
       "                       [ 0.0101],\n",
       "                       [ 0.0132]]], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.2.1.weight',\n",
       "              tensor([-4.2887e-03,  5.3547e-03,  2.8098e-02, -4.1148e-02,  8.9659e-03,\n",
       "                       1.4052e-02,  1.7672e-02, -1.5002e-02,  2.2406e-02,  1.4576e-02,\n",
       "                       1.8012e-02,  1.5807e-02,  8.0291e-03,  2.1013e-02, -3.6874e-02,\n",
       "                       3.1353e-02, -2.3360e-02,  1.6778e-02, -1.3213e-02,  2.6153e-02,\n",
       "                       1.6228e-02,  4.0400e-02, -2.8806e-03,  9.2256e-03, -1.0633e-02,\n",
       "                      -1.7746e-02, -3.0937e-04, -2.2479e-02, -9.0966e-03,  1.6908e-02,\n",
       "                       1.0458e-02,  3.0138e-02,  1.4046e-03,  4.1998e-02, -8.7236e-03,\n",
       "                      -3.0711e-02,  5.2909e-03, -1.8230e-03,  3.3795e-02, -2.7628e-02,\n",
       "                      -3.0381e-02, -8.2002e-03, -8.7711e-03,  2.1332e-02,  2.7518e-03,\n",
       "                       2.8232e-03,  1.2952e-02, -1.8517e-02, -1.1196e-04,  3.3431e-03,\n",
       "                       3.9941e-03,  2.9208e-02,  1.6043e-02,  1.7105e-02, -3.2334e-03,\n",
       "                       1.2888e-03, -1.2872e-02,  4.3753e-02,  3.0307e-02,  2.2347e-03,\n",
       "                       1.3201e-02,  1.2301e-02, -4.7794e-03, -6.8303e-03, -1.6982e-02,\n",
       "                      -7.4266e-03, -2.1852e-02,  2.3630e-02, -1.6068e-02, -6.8652e-03,\n",
       "                      -1.6146e-02, -2.3270e-02,  3.4155e-03,  7.5641e-03, -4.4102e-02,\n",
       "                       7.8778e-03, -3.1041e-02, -8.7155e-03, -3.3446e-02, -1.2616e-02,\n",
       "                      -1.3742e-02,  1.7855e-03,  9.3243e-03,  2.0487e-02, -8.5238e-03,\n",
       "                       4.2211e-02, -4.9792e-03,  1.0958e-02,  1.9776e-02,  3.1619e-04,\n",
       "                      -5.9298e-03, -1.3137e-02,  2.5259e-02, -2.8567e-02, -4.5968e-03,\n",
       "                       1.3717e-02,  1.4659e-02,  1.9317e-02,  4.4472e-03,  1.0376e-02,\n",
       "                       8.2648e-03, -3.5143e-02, -2.3706e-02, -1.9286e-03, -1.1590e-02,\n",
       "                      -2.5200e-02, -9.1530e-03, -9.3763e-03, -3.7565e-02,  2.7193e-03,\n",
       "                      -2.4676e-02, -1.6890e-02, -2.7430e-02,  9.2596e-03, -2.7572e-02,\n",
       "                       1.5723e-02, -6.4210e-03,  1.3429e-02,  1.3513e-02, -7.3940e-03,\n",
       "                      -7.8988e-03, -1.3452e-02, -1.7926e-02, -3.2606e-02, -1.9435e-02,\n",
       "                       4.6131e-04, -1.0693e-02, -1.7958e-02, -2.9680e-02,  1.3550e-02,\n",
       "                      -6.2280e-03,  7.3637e-03, -2.6189e-02,  9.6368e-03, -4.1867e-03,\n",
       "                       2.0588e-03, -3.4247e-02,  1.5086e-02,  2.2798e-02,  5.0421e-06,\n",
       "                       2.2978e-02,  1.0273e-02,  2.1271e-02, -5.8057e-03, -5.8482e-03,\n",
       "                       1.0571e-02,  1.5283e-02,  2.4695e-02, -1.4543e-02,  1.6483e-02,\n",
       "                       3.1754e-03, -7.9288e-03,  1.1269e-02, -2.2481e-02, -1.2273e-02,\n",
       "                      -4.5980e-03, -1.9678e-02, -1.4204e-02, -1.3493e-02, -2.5066e-02,\n",
       "                       4.3385e-03, -6.1403e-03,  1.4905e-02, -7.7507e-04,  2.5668e-02,\n",
       "                       9.5060e-03, -1.1172e-02, -1.9561e-02,  2.6481e-02, -4.9491e-02,\n",
       "                       7.9912e-03, -7.5990e-03,  6.6821e-03,  1.3816e-02,  2.3499e-02,\n",
       "                      -2.6853e-03,  1.5853e-02,  3.8100e-02, -1.3817e-02,  1.1213e-02,\n",
       "                      -1.1415e-02,  1.6445e-02, -9.3296e-03,  1.3714e-02,  6.2017e-03,\n",
       "                      -1.7782e-02,  3.5762e-02, -2.9937e-02, -2.7340e-03, -1.9184e-02,\n",
       "                       5.8794e-05,  1.2618e-02, -6.5432e-03, -2.5166e-02, -2.2505e-02,\n",
       "                       1.5141e-02,  2.1169e-02, -1.0039e-02, -4.4835e-03,  2.2034e-02,\n",
       "                       1.0826e-03,  9.1657e-03,  8.5009e-03, -1.1663e-02, -8.6444e-03,\n",
       "                       1.0814e-02,  2.4179e-03, -1.3879e-02,  6.6626e-03, -3.1775e-02,\n",
       "                      -1.1022e-03,  1.3412e-02,  1.0795e-02,  1.0487e-02,  8.4371e-03,\n",
       "                       1.0807e-02, -7.4968e-03, -1.3240e-02, -1.0706e-02, -2.7411e-02,\n",
       "                      -1.4444e-02, -2.9956e-02,  1.0542e-02, -4.6799e-03,  9.1211e-03,\n",
       "                      -1.8913e-02, -2.4750e-03,  4.2870e-03, -1.7951e-02, -1.7830e-02,\n",
       "                      -1.9307e-02,  3.8218e-03, -8.0723e-03,  1.3052e-02,  1.8856e-02,\n",
       "                       2.1231e-02,  1.7566e-03,  8.4203e-03, -2.1740e-03,  7.3546e-03,\n",
       "                       4.1479e-02,  8.6095e-03, -3.2123e-02,  6.4610e-03, -3.0998e-02,\n",
       "                       3.0812e-02, -1.4489e-02,  2.4966e-02,  1.9497e-03, -3.1294e-02,\n",
       "                      -1.2307e-02, -6.4975e-03, -3.1969e-03,  1.2752e-02, -6.7522e-03,\n",
       "                      -6.9401e-03], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.2.1.bias',\n",
       "              tensor([ 1.3239e-04,  5.9952e-03,  9.3251e-03,  1.4057e-02, -4.1340e-04,\n",
       "                       5.8669e-03,  5.9947e-03, -3.6517e-03,  1.1120e-02,  1.6620e-02,\n",
       "                       1.4444e-02, -7.4460e-03,  3.9039e-03, -7.1543e-03,  8.7027e-03,\n",
       "                       4.4965e-03,  2.6014e-02,  9.9015e-04,  1.2080e-02, -2.5601e-04,\n",
       "                      -1.0805e-02,  2.4438e-03,  8.3434e-03,  6.9587e-03,  9.6617e-03,\n",
       "                      -2.1555e-02,  6.7647e-03,  1.2255e-02,  1.2894e-02, -4.9601e-03,\n",
       "                      -3.4266e-03,  1.0724e-02,  4.4924e-03,  2.1441e-02,  8.8721e-03,\n",
       "                       1.1025e-02, -6.1305e-03,  1.0371e-02,  2.1027e-02,  6.2433e-03,\n",
       "                       2.8081e-03,  7.2477e-03, -6.6896e-03, -4.0474e-03,  7.3500e-03,\n",
       "                      -1.6637e-02,  1.6194e-02,  1.0437e-02, -1.3652e-02, -4.1064e-04,\n",
       "                       1.1147e-02,  2.7983e-03,  3.6667e-03,  2.0729e-02,  3.1084e-04,\n",
       "                       1.3225e-02,  1.0156e-02,  2.6511e-03,  1.2527e-02, -4.0934e-03,\n",
       "                      -4.0890e-04,  1.0625e-03,  8.7474e-03,  9.1291e-03, -7.7499e-03,\n",
       "                       1.9510e-04, -7.9020e-03,  1.2744e-02,  1.5976e-02, -1.4377e-02,\n",
       "                       7.3737e-03, -2.4469e-03, -7.3329e-04, -7.4612e-03,  1.3656e-02,\n",
       "                       8.3042e-03,  2.3329e-04,  9.6921e-03,  2.4927e-04,  1.7013e-02,\n",
       "                       4.6550e-03, -7.8937e-03,  1.3986e-02,  3.6012e-03, -5.0575e-03,\n",
       "                       1.7210e-02, -8.2577e-04,  1.0912e-02,  1.3911e-02, -1.0697e-03,\n",
       "                       7.5105e-04,  1.1527e-02,  1.0212e-02,  1.4002e-02,  8.1182e-03,\n",
       "                      -6.0427e-03,  1.4571e-02,  5.6991e-03,  1.9976e-02,  9.0048e-03,\n",
       "                       2.3133e-02,  1.6251e-02,  6.4168e-03,  1.2667e-02,  6.1930e-03,\n",
       "                       3.4247e-03, -7.1713e-03,  1.1359e-02,  7.3542e-03,  6.2848e-03,\n",
       "                       1.1315e-03, -9.3433e-03,  1.5573e-03,  2.1615e-02,  1.5572e-02,\n",
       "                       5.5938e-03,  5.6072e-03,  4.2924e-03,  4.6647e-03, -5.7760e-03,\n",
       "                      -2.4097e-04,  1.1999e-02,  4.8271e-03,  4.6796e-03,  2.1520e-02,\n",
       "                       8.2732e-03,  6.0123e-03,  5.5142e-03,  8.7275e-03,  1.5135e-02,\n",
       "                       6.5944e-03,  5.8353e-03,  1.4577e-02,  2.2841e-03,  5.9913e-03,\n",
       "                      -1.6714e-02,  1.5067e-02,  3.3433e-03,  5.1037e-03,  8.2408e-03,\n",
       "                       1.3740e-02,  7.8210e-03,  1.5095e-02,  3.5819e-03, -8.0414e-03,\n",
       "                       9.6777e-03,  8.8312e-03, -2.1516e-03,  5.8577e-03,  4.2446e-03,\n",
       "                       7.9761e-03,  1.0870e-02,  5.4885e-03,  1.1858e-02,  1.4177e-02,\n",
       "                       3.3224e-03, -3.9424e-04,  5.9704e-03, -1.0368e-03, -7.0068e-04,\n",
       "                       4.7409e-03,  9.2333e-03, -2.8326e-03,  6.1248e-03,  1.0726e-02,\n",
       "                      -4.6764e-03, -1.4223e-02,  5.3103e-03,  6.3637e-03,  1.7889e-02,\n",
       "                       4.1875e-03, -1.0991e-03,  9.7235e-03,  1.4793e-02, -1.3577e-02,\n",
       "                       1.2898e-02,  1.8470e-03,  1.8432e-02,  2.6971e-03,  6.9354e-03,\n",
       "                       3.2598e-04,  1.0614e-02, -3.0122e-03, -8.6167e-03,  1.0016e-02,\n",
       "                       7.2768e-03,  1.3332e-02,  1.0278e-02,  8.3826e-03,  8.0632e-03,\n",
       "                       6.1904e-03,  5.0412e-03,  6.2193e-03,  1.2392e-03, -1.3277e-03,\n",
       "                       1.0656e-02,  1.0794e-02,  1.8575e-03,  6.0470e-03,  1.5418e-02,\n",
       "                      -2.1556e-03,  2.2473e-02,  1.6429e-02,  1.6354e-02,  1.7115e-02,\n",
       "                       1.5950e-03,  8.7438e-03, -1.2510e-02,  4.0747e-03,  9.9341e-03,\n",
       "                       9.7133e-03,  1.1614e-02, -7.8708e-04,  7.6011e-03,  6.0641e-03,\n",
       "                       7.1787e-03,  2.5677e-03,  1.6120e-02,  2.7974e-03,  1.7038e-03,\n",
       "                       1.2634e-02,  3.3191e-03,  3.7477e-03,  1.3246e-02,  8.3140e-03,\n",
       "                       6.1698e-03, -8.1395e-03, -1.6029e-03,  2.8262e-02,  1.9504e-02,\n",
       "                       4.4171e-03,  5.8607e-04,  6.3725e-03,  1.2017e-02,  7.5251e-04,\n",
       "                       1.0322e-02,  1.3695e-05,  1.4474e-02,  4.4732e-03,  1.3578e-02,\n",
       "                      -9.4972e-04,  7.3473e-03, -3.1719e-03,  1.3425e-02,  7.1577e-03,\n",
       "                       8.9096e-03,  4.7802e-03,  2.0985e-03, -1.1745e-02, -9.2216e-03,\n",
       "                       1.8780e-02,  2.2160e-02,  1.4048e-02,  1.7082e-02,  3.3521e-03,\n",
       "                       1.1426e-03], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.2.1.running_mean',\n",
       "              tensor([ 6.1306e-01, -6.2078e-03, -1.8435e-01,  6.5953e-02,  1.9692e-02,\n",
       "                       6.8546e-01,  4.8946e-01,  4.5521e-01,  1.0915e-01,  2.0139e-01,\n",
       "                      -1.1507e-01, -1.9916e-01,  1.0243e-01,  2.0044e-01,  7.8897e-03,\n",
       "                      -1.1108e+00,  3.9688e-01,  1.3976e-01,  3.9393e-01, -2.2625e-01,\n",
       "                       2.1822e-01, -7.7434e-01,  3.6786e-02, -7.0005e-01,  8.0393e-02,\n",
       "                       2.4291e-01, -2.2736e-01, -1.3886e-01,  3.3794e-01,  5.1980e-01,\n",
       "                      -4.9370e-01, -2.7451e-01, -1.1982e-01,  4.4666e-01,  1.9052e-01,\n",
       "                      -2.3208e-01, -2.6255e-02,  6.3425e-01, -6.0396e-02, -1.0914e-01,\n",
       "                       3.8388e-01, -1.2205e-01,  2.3332e-01,  5.0189e-01,  1.4234e-01,\n",
       "                       5.5909e-02, -1.9562e-01, -4.9734e-01,  1.0565e+00,  6.2301e-01,\n",
       "                       1.2532e-01,  2.3393e-01, -3.9227e-01,  1.1734e-01, -4.2162e-04,\n",
       "                      -8.7809e-01, -2.9131e-01,  1.2416e-01, -9.1970e-02, -4.9564e-02,\n",
       "                      -5.9136e-02, -1.5892e-01,  3.1150e-01,  3.0159e-01,  8.7612e-01,\n",
       "                      -3.6963e-01,  6.2932e-01, -2.7327e-01, -1.5035e-01,  6.2895e-01,\n",
       "                      -8.6141e-01,  2.2655e-01,  6.6538e-02, -3.6014e-01,  4.1273e-01,\n",
       "                       9.6808e-02, -5.0759e-02,  3.4167e-01,  3.7929e-02,  5.1091e-01,\n",
       "                      -2.6523e-01,  3.4326e-01, -2.5974e-02,  3.8641e-01,  1.7151e-01,\n",
       "                      -6.7585e-02, -7.5243e-01, -7.6153e-02,  4.0592e-01,  2.8271e-01,\n",
       "                      -3.0570e-01, -6.0099e-01,  2.9698e-01, -3.2425e-01,  2.1180e-01,\n",
       "                       8.7377e-03, -5.2692e-01, -5.1686e-01,  4.1962e-02,  2.2891e-01,\n",
       "                      -8.2175e-01, -1.0140e+00,  1.9329e-01, -2.7158e-01, -2.8176e-01,\n",
       "                      -8.4360e-02, -7.1051e-01, -8.5633e-01,  5.0236e-01,  1.4016e-01,\n",
       "                       2.2585e-01, -5.8610e-01, -2.1127e-02,  4.5338e-01, -4.3334e-01,\n",
       "                      -4.8692e-02,  2.3909e-01, -9.4583e-01,  3.4418e-01,  3.8721e-01,\n",
       "                      -2.0788e-01,  9.4788e-02,  6.5160e-01, -1.3896e-01, -3.3092e-01,\n",
       "                       5.7804e-01,  1.5541e-01, -4.3961e-02,  4.8244e-01, -3.2292e-01,\n",
       "                       6.1213e-02, -2.8619e-01, -6.0153e-01, -2.5566e-01, -1.8018e-01,\n",
       "                      -2.5891e-01,  4.9818e-02,  3.5354e-01, -3.6644e-02,  2.4181e-01,\n",
       "                      -1.9632e-01,  9.1498e-01,  1.2314e-01,  5.2392e-01, -1.4135e-01,\n",
       "                      -2.3385e-01,  3.5498e-01,  2.6323e-01,  1.3812e-01,  4.2290e-01,\n",
       "                       1.3710e-01,  1.4288e+00,  1.6401e-01,  6.4494e-01, -4.8343e-01,\n",
       "                      -2.2728e-01, -1.3081e-01,  1.9859e-01,  5.1851e-01,  1.7820e-01,\n",
       "                       6.8328e-02, -2.1686e-01, -1.3230e-01,  1.6343e-01, -2.3534e-01,\n",
       "                       8.2609e-01,  6.6073e-01, -6.2572e-01, -8.0333e-01, -1.3264e-01,\n",
       "                       5.9903e-01, -3.0722e-02,  3.3766e-01,  5.1450e-02,  5.1100e-01,\n",
       "                       4.3058e-01, -5.0604e-01, -3.3865e-01, -2.2567e-01, -1.7736e-01,\n",
       "                      -1.4153e-02,  3.4312e-01,  1.0110e+00,  1.6017e-01, -2.2221e-01,\n",
       "                      -1.6938e-01, -5.8114e-01, -5.0691e-01,  3.6252e-01,  3.0749e-02,\n",
       "                      -1.3048e-01, -5.6993e-01, -3.5579e-01, -3.9806e-01, -8.5054e-01,\n",
       "                       9.7509e-03,  8.1117e-02, -4.4937e-01,  6.6542e-01,  4.4782e-01,\n",
       "                      -2.6690e-02,  1.2220e-01,  2.6535e-01, -7.1831e-01,  7.6122e-02,\n",
       "                      -2.0710e-01,  1.3585e-02, -1.8125e-01, -9.8350e-02,  4.3923e-01,\n",
       "                       4.4509e-01, -1.0687e-01,  3.3277e-01,  5.9799e-01,  7.0560e-01,\n",
       "                      -5.7123e-02,  6.0254e-02, -9.3929e-02,  2.2802e-01, -4.0039e-02,\n",
       "                       1.5842e-02, -8.7733e-01,  6.4256e-02, -7.1610e-02, -3.6014e-01,\n",
       "                      -1.9152e-01, -7.4374e-01,  2.2500e-02,  6.1319e-02, -3.0701e-01,\n",
       "                      -2.2476e-01,  5.4270e-02,  4.3336e-01, -4.5984e-01,  4.4515e-02,\n",
       "                       3.7807e-01,  1.5538e-01,  6.2516e-01,  1.8614e-01,  3.7799e-01,\n",
       "                       6.4289e-01,  8.5381e-01,  3.7553e-01, -3.1792e-01,  5.8097e-01,\n",
       "                      -8.7172e-02, -3.8625e-02, -5.6988e-02,  3.7833e-02,  2.4193e-01,\n",
       "                      -2.4288e-01,  4.2301e-01, -2.2027e-01, -3.0302e-01,  1.0070e-01,\n",
       "                       9.8010e-01], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.2.1.running_var',\n",
       "              tensor([0.3133, 0.1922, 0.3422, 0.4176, 0.3093, 0.2284, 0.3108, 0.5188, 0.2302,\n",
       "                      0.4271, 0.2768, 0.3147, 0.0466, 0.4343, 0.4955, 0.4783, 0.2291, 0.4844,\n",
       "                      0.1740, 0.5771, 0.2095, 0.3850, 0.1939, 0.3683, 0.3818, 0.2451, 0.1651,\n",
       "                      0.3108, 0.1634, 0.3742, 0.4722, 0.7049, 0.0644, 0.4734, 0.2857, 0.3992,\n",
       "                      0.3182, 0.2040, 0.3829, 0.2944, 0.6267, 0.3199, 0.3212, 0.5727, 0.2603,\n",
       "                      0.1812, 0.7401, 0.2705, 0.3074, 0.3129, 0.1301, 0.4902, 0.2484, 0.2459,\n",
       "                      0.2344, 0.4069, 0.6537, 0.4933, 0.5320, 0.1483, 0.2342, 0.1491, 0.1204,\n",
       "                      0.3233, 0.6566, 0.4202, 0.4079, 0.3538, 0.2616, 0.4105, 0.7248, 0.3265,\n",
       "                      0.0663, 0.4411, 0.5530, 0.0937, 0.4070, 0.3388, 0.4188, 0.3898, 0.5769,\n",
       "                      0.1645, 0.3725, 0.4534, 0.1581, 0.5219, 0.2435, 0.4300, 0.5928, 0.3090,\n",
       "                      0.2796, 0.3137, 0.3389, 0.3986, 0.3343, 0.2211, 0.4333, 0.5383, 0.1850,\n",
       "                      0.1930, 0.4125, 0.5704, 0.3220, 0.2697, 0.4498, 0.5880, 0.4425, 0.4711,\n",
       "                      0.5014, 0.1203, 0.3135, 0.3679, 0.3669, 0.2458, 0.5322, 0.5680, 0.1994,\n",
       "                      0.2871, 0.2653, 0.4116, 0.2745, 0.4457, 0.5028, 0.4277, 0.2836, 0.4855,\n",
       "                      0.1778, 0.2352, 0.4457, 0.4371, 0.0583, 0.3205, 0.6673, 0.1172, 0.2534,\n",
       "                      0.0734, 0.4079, 0.3415, 0.5969, 0.1359, 0.3046, 0.3069, 0.3308, 0.2062,\n",
       "                      0.2927, 0.5014, 0.1463, 0.5133, 0.1067, 0.7088, 0.2917, 0.3569, 0.3563,\n",
       "                      0.4550, 0.4520, 0.1508, 0.3734, 0.1910, 0.4831, 0.3506, 0.2492, 0.1979,\n",
       "                      0.5237, 0.1145, 0.5266, 0.4935, 0.4422, 0.2838, 0.3637, 0.4010, 0.1738,\n",
       "                      0.0760, 0.1718, 0.2479, 0.5964, 0.2508, 0.4666, 0.3105, 0.2718, 0.3246,\n",
       "                      0.2973, 0.2534, 0.4928, 0.4504, 0.2600, 0.4325, 0.3286, 0.2124, 0.2420,\n",
       "                      0.6731, 0.2501, 0.2855, 0.3022, 0.5669, 0.3630, 0.4219, 0.4059, 0.2435,\n",
       "                      0.2839, 0.4457, 0.1439, 0.3331, 0.3270, 0.3455, 0.1955, 0.6198, 0.0509,\n",
       "                      0.0718, 0.0685, 0.4660, 0.0890, 0.3144, 0.3449, 0.3180, 0.1373, 0.1355,\n",
       "                      0.3570, 0.1986, 0.3384, 0.5744, 0.2798, 0.3902, 0.1597, 0.1455, 0.3579,\n",
       "                      0.6040, 0.2347, 0.1471, 0.6010, 0.3557, 0.2532, 0.2359, 0.3658, 0.5241,\n",
       "                      0.3923, 0.4290, 0.1312, 0.3150, 0.1041, 0.3859, 0.4342, 0.2519, 0.3787,\n",
       "                      0.2352, 0.4382, 0.4002, 0.4378, 0.4208, 0.0396, 0.5058, 0.2718, 0.4559,\n",
       "                      0.0972, 0.4081, 0.1595, 0.3917], dtype=torch.float64)),\n",
       "             ('6.16.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.17.convs.0.0.weight',\n",
       "              tensor([[[ 0.1011],\n",
       "                       [ 0.1910],\n",
       "                       [-0.0038],\n",
       "                       ...,\n",
       "                       [-0.1547],\n",
       "                       [ 0.0677],\n",
       "                       [-0.0680]],\n",
       "              \n",
       "                      [[-0.0171],\n",
       "                       [-0.0157],\n",
       "                       [-0.1286],\n",
       "                       ...,\n",
       "                       [-0.0976],\n",
       "                       [-0.0246],\n",
       "                       [-0.1203]],\n",
       "              \n",
       "                      [[-0.0841],\n",
       "                       [ 0.0101],\n",
       "                       [-0.0634],\n",
       "                       ...,\n",
       "                       [-0.0668],\n",
       "                       [-0.1459],\n",
       "                       [ 0.0700]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0079],\n",
       "                       [-0.0362],\n",
       "                       [-0.0751],\n",
       "                       ...,\n",
       "                       [ 0.1131],\n",
       "                       [ 0.0727],\n",
       "                       [ 0.0293]],\n",
       "              \n",
       "                      [[ 0.0453],\n",
       "                       [-0.0168],\n",
       "                       [ 0.1205],\n",
       "                       ...,\n",
       "                       [ 0.0348],\n",
       "                       [ 0.0182],\n",
       "                       [ 0.0405]],\n",
       "              \n",
       "                      [[-0.0843],\n",
       "                       [-0.0257],\n",
       "                       [-0.0705],\n",
       "                       ...,\n",
       "                       [-0.0185],\n",
       "                       [-0.0186],\n",
       "                       [ 0.0884]]], dtype=torch.float64)),\n",
       "             ('6.17.convs.0.1.weight',\n",
       "              tensor([0.9546, 0.9901, 0.9658, 1.0060, 0.9663, 0.9994, 0.9632, 0.9947, 0.9562,\n",
       "                      0.9514, 0.9837, 0.9780, 0.9789, 0.9608, 0.9545, 0.9662, 0.9640, 0.9949,\n",
       "                      0.9597, 0.9776, 0.9839, 0.9756, 0.9557, 0.9577, 0.9561, 0.9956, 0.9636,\n",
       "                      0.9498, 0.9728, 0.9772, 0.9605, 0.9446, 0.9576, 0.9761, 0.9658, 0.9944,\n",
       "                      0.9678, 0.9601, 0.9873, 0.9531, 0.9494, 0.9700, 0.9756, 0.9400, 0.9635,\n",
       "                      0.9587, 0.9886, 0.9748, 0.9529, 0.9753, 0.9938, 0.9957, 0.9687, 0.9733,\n",
       "                      0.9631, 0.9728, 0.9541, 0.9469, 0.9842, 0.9612, 0.9629, 0.9861, 0.9751,\n",
       "                      0.9540], dtype=torch.float64)),\n",
       "             ('6.17.convs.0.1.bias',\n",
       "              tensor([-0.0119,  0.0167,  0.0088,  0.0083, -0.0066,  0.0169,  0.0153,  0.0202,\n",
       "                      -0.0178, -0.0057, -0.0153, -0.0096, -0.0063, -0.0047, -0.0076, -0.0140,\n",
       "                      -0.0260,  0.0103, -0.0008,  0.0121,  0.0059,  0.0247, -0.0302, -0.0155,\n",
       "                       0.0100,  0.0182, -0.0056, -0.0007,  0.0111, -0.0046, -0.0095,  0.0017,\n",
       "                      -0.0116,  0.0141, -0.0087,  0.0118, -0.0053,  0.0011,  0.0161,  0.0005,\n",
       "                       0.0074, -0.0099, -0.0048, -0.0056,  0.0019,  0.0019,  0.0142, -0.0085,\n",
       "                       0.0110,  0.0326,  0.0053, -0.0033,  0.0119,  0.0063, -0.0008,  0.0123,\n",
       "                      -0.0266, -0.0235,  0.0039, -0.0100,  0.0134,  0.0103,  0.0019, -0.0110],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convs.0.1.running_mean',\n",
       "              tensor([ 0.0431,  0.3416,  1.1659, -0.4379,  0.9825, -0.2735, -0.5742, -0.0839,\n",
       "                      -0.3975, -0.4308, -0.6213, -0.0291, -0.5786, -0.0193,  0.0833,  0.5728,\n",
       "                       0.9937,  0.2995, -0.6744, -0.9051, -0.9441, -0.6111, -1.3306,  0.1646,\n",
       "                      -0.2059,  0.2093,  0.1936, -0.9058,  0.0300, -0.9388,  0.2495, -0.7662,\n",
       "                       0.2187,  0.1358,  0.6306,  0.8113, -0.0563,  0.2728,  0.1240, -0.1015,\n",
       "                       0.7224,  0.8565,  0.2912, -1.0717, -0.0315, -1.0396,  1.1022, -0.4631,\n",
       "                      -0.0057, -0.4879, -1.1238,  0.4833, -0.2824,  0.8825,  0.5286,  0.2315,\n",
       "                       0.2808,  0.3639, -0.7991, -0.0864, -0.4335, -0.7895,  0.2155,  0.2494],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convs.0.1.running_var',\n",
       "              tensor([0.2662, 0.1606, 0.9427, 0.0978, 0.5794, 0.1695, 0.1603, 0.0982, 0.2000,\n",
       "                      0.2465, 0.1052, 0.1230, 0.1076, 0.1245, 0.2364, 0.1655, 0.1708, 0.1950,\n",
       "                      0.2093, 0.5119, 0.1396, 0.0962, 0.3256, 0.2245, 0.1506, 0.1173, 0.4474,\n",
       "                      0.3014, 0.2194, 0.6246, 0.2335, 1.0946, 0.3558, 0.1441, 0.1674, 0.1553,\n",
       "                      0.1965, 0.2472, 0.2358, 0.2846, 0.1663, 0.1888, 0.1784, 0.8368, 0.8129,\n",
       "                      0.8493, 0.1019, 0.1602, 0.2671, 0.2183, 0.1491, 0.1671, 0.4543, 0.1669,\n",
       "                      0.2251, 0.1110, 0.8243, 0.6660, 0.1390, 0.1291, 0.3830, 0.1056, 0.2283,\n",
       "                      0.1395], dtype=torch.float64)),\n",
       "             ('6.17.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.17.convs.1.0.weight',\n",
       "              tensor([[[-2.7650e-03, -8.7907e-02, -8.0904e-02, -8.8151e-02, -1.7358e-01],\n",
       "                       [ 3.8751e-02,  4.9101e-02,  1.7389e-02,  5.8484e-02,  1.2000e-02],\n",
       "                       [ 3.6215e-02, -8.3917e-02,  5.0440e-03, -5.5940e-02, -8.0683e-02],\n",
       "                       ...,\n",
       "                       [-8.1097e-02,  3.3157e-02,  9.5237e-02,  5.3807e-02,  5.8816e-02],\n",
       "                       [ 3.3692e-02, -4.0109e-02, -1.3064e-02,  7.8080e-02,  6.4626e-03],\n",
       "                       [ 1.3472e-01, -3.6794e-02, -3.2681e-02, -1.5583e-01,  4.1795e-02]],\n",
       "              \n",
       "                      [[ 9.0043e-02, -7.6573e-02, -2.1841e-02,  4.0454e-02, -4.0627e-02],\n",
       "                       [ 3.3711e-02,  1.2113e-01,  6.4196e-02, -4.7071e-03,  4.9153e-02],\n",
       "                       [ 4.9101e-02,  1.2570e-02,  2.0064e-02,  5.2496e-03, -5.9189e-02],\n",
       "                       ...,\n",
       "                       [ 6.4913e-02, -2.8510e-02, -2.2203e-02,  6.4161e-02, -5.8795e-02],\n",
       "                       [-5.3323e-02, -4.5986e-02,  1.5897e-01,  8.1368e-02,  6.4010e-02],\n",
       "                       [ 2.4161e-02, -6.6179e-02,  7.9401e-02, -7.1610e-02,  1.6790e-02]],\n",
       "              \n",
       "                      [[ 7.4899e-02,  6.3762e-02,  4.4013e-03,  1.8360e-01, -6.2220e-02],\n",
       "                       [-1.0947e-02, -6.7096e-03,  4.6106e-02, -6.3463e-02, -3.3193e-02],\n",
       "                       [-1.7243e-03,  1.0452e-01, -3.1891e-02, -1.4179e-02, -9.9657e-02],\n",
       "                       ...,\n",
       "                       [-2.6831e-02, -1.2870e-01, -7.2081e-02, -3.5437e-02, -5.7481e-02],\n",
       "                       [ 1.1444e-01,  5.0991e-02,  4.5252e-02,  8.1723e-02,  1.4126e-02],\n",
       "                       [-6.1653e-02,  1.5755e-04,  1.5366e-01, -2.0145e-02,  1.3626e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 5.0871e-02, -1.5253e-01,  3.7321e-02,  1.5114e-02, -9.8919e-02],\n",
       "                       [-1.8270e-02, -8.8611e-02, -6.2199e-02, -3.5088e-02,  6.9235e-02],\n",
       "                       [ 1.8439e-01, -1.8785e-01,  9.3109e-02,  8.7847e-02,  1.6660e-01],\n",
       "                       ...,\n",
       "                       [ 9.6717e-02,  8.4309e-02,  7.3325e-04,  7.0540e-02,  4.7752e-02],\n",
       "                       [-2.3678e-02, -1.1943e-02,  5.0881e-02,  6.2254e-02, -3.7987e-02],\n",
       "                       [ 1.6986e-02,  2.3752e-02,  4.9315e-02,  6.3301e-02,  6.4597e-02]],\n",
       "              \n",
       "                      [[-2.8797e-02,  1.5723e-01,  5.9449e-02, -2.4509e-02,  3.9729e-02],\n",
       "                       [-2.0425e-02,  2.8752e-03,  1.4395e-01,  6.1944e-02,  5.5884e-02],\n",
       "                       [-7.8054e-02,  4.7143e-02, -1.1606e-01,  5.0965e-03, -3.9009e-02],\n",
       "                       ...,\n",
       "                       [ 7.2926e-03,  1.7506e-01, -1.8480e-03,  7.1178e-02, -1.8200e-02],\n",
       "                       [-1.0687e-01,  1.0052e-01, -6.2718e-02, -3.4395e-02, -9.4569e-02],\n",
       "                       [ 5.6353e-02,  5.1006e-02, -3.9454e-02, -7.6750e-02, -8.2791e-02]],\n",
       "              \n",
       "                      [[-1.2018e-02,  6.7915e-02, -8.0359e-03, -1.8727e-02, -6.7394e-02],\n",
       "                       [-5.7579e-02,  9.2954e-03, -9.1481e-02, -2.4134e-02, -5.3126e-03],\n",
       "                       [ 2.4703e-02, -7.7651e-02, -1.4564e-01, -2.7633e-02,  5.8622e-02],\n",
       "                       ...,\n",
       "                       [ 4.3366e-02,  9.1384e-02, -6.0102e-02, -6.7411e-02,  5.9397e-02],\n",
       "                       [ 6.2592e-02,  5.1124e-02,  7.2105e-02,  1.7691e-01, -1.6832e-01],\n",
       "                       [-2.4049e-03,  4.1401e-02,  7.8244e-02, -9.5568e-02,  2.4983e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convs.1.1.weight',\n",
       "              tensor([0.9490, 0.9780, 0.9574, 0.9939, 0.9676, 0.9685, 0.9727, 0.9774, 0.9398,\n",
       "                      0.9683, 0.9597, 0.9828, 0.9244, 0.9300, 0.9817, 0.9983, 0.9407, 0.9416,\n",
       "                      0.9459, 0.9723, 0.9887, 0.9688, 0.9466, 0.9652, 0.9725, 0.9727, 0.9774,\n",
       "                      0.9574, 0.9645, 0.9305, 0.9633, 0.9482, 0.9567, 0.9594, 0.9607, 0.9601,\n",
       "                      0.9735, 0.9529, 0.9600, 0.9547, 0.9749, 0.9565, 0.9697, 0.9553, 0.9678,\n",
       "                      0.9492, 1.0010, 0.9589, 0.9757, 0.9713, 0.9897, 0.9772, 0.9593, 1.0072,\n",
       "                      0.9574, 0.9697, 0.9534, 0.9765, 0.9794, 0.9620, 0.9813, 0.9826, 0.9359,\n",
       "                      0.9683], dtype=torch.float64)),\n",
       "             ('6.17.convs.1.1.bias',\n",
       "              tensor([-0.0059,  0.0153, -0.0273,  0.0134,  0.0020,  0.0073, -0.0014, -0.0193,\n",
       "                      -0.0195, -0.0210, -0.0007, -0.0241, -0.0092, -0.0293,  0.0136, -0.0335,\n",
       "                      -0.0134, -0.0135, -0.0083, -0.0078,  0.0016, -0.0152, -0.0043, -0.0290,\n",
       "                      -0.0024,  0.0032, -0.0137,  0.0006, -0.0026, -0.0082, -0.0061, -0.0051,\n",
       "                      -0.0238, -0.0061, -0.0049, -0.0108,  0.0136, -0.0154, -0.0134, -0.0098,\n",
       "                       0.0134, -0.0236,  0.0085, -0.0122,  0.0093, -0.0199,  0.0123, -0.0056,\n",
       "                      -0.0313,  0.0074, -0.0245, -0.0017,  0.0080,  0.0105, -0.0094,  0.0024,\n",
       "                      -0.0106, -0.0018, -0.0098, -0.0083,  0.0004, -0.0059, -0.0045,  0.0082],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convs.1.1.running_mean',\n",
       "              tensor([ 0.1076,  0.0531,  0.3838, -0.4194,  0.2765,  1.0686,  0.4875,  0.9236,\n",
       "                       0.1217,  0.7606, -0.9840,  0.9500, -0.4870, -0.3049,  0.5356,  1.5241,\n",
       "                      -0.0368, -0.8052, -0.0407, -0.0346, -0.6509,  0.1868, -0.5836,  0.5512,\n",
       "                       0.3642, -0.4180,  0.5873,  0.3476,  0.5529, -0.1865,  0.2539, -0.6929,\n",
       "                      -0.4648,  0.5983, -0.1700, -0.2726, -0.1861,  0.2151,  0.2371, -0.2833,\n",
       "                      -0.0923,  0.2916, -0.4289, -1.1124, -0.8487,  0.0323, -0.3319,  0.6912,\n",
       "                       0.9337,  0.3910,  0.8991,  0.0033,  1.0178,  0.3381, -1.1239,  0.2089,\n",
       "                       0.6657, -0.8024,  1.2301, -0.1110, -0.1906, -0.4709,  0.1098, -0.1694],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convs.1.1.running_var',\n",
       "              tensor([0.5253, 0.6203, 0.6087, 0.3960, 0.2999, 0.4142, 0.5388, 0.5990, 0.6290,\n",
       "                      0.5431, 0.7907, 0.4143, 0.4195, 0.4786, 0.3714, 0.5621, 0.4939, 0.4016,\n",
       "                      0.5699, 0.5559, 0.5137, 0.5611, 0.5967, 0.7345, 0.4974, 0.4699, 0.6522,\n",
       "                      0.4545, 0.4128, 0.5330, 0.5432, 0.6835, 0.4363, 0.8313, 0.4695, 0.8678,\n",
       "                      0.4816, 0.3829, 0.7665, 0.5329, 0.4250, 1.1877, 0.4461, 0.5738, 0.5738,\n",
       "                      0.4175, 0.4046, 0.4687, 0.3871, 0.5521, 0.6238, 0.4324, 0.5601, 0.4125,\n",
       "                      0.5125, 0.6241, 0.5805, 0.5618, 0.3811, 0.5905, 0.6000, 0.4785, 0.5265,\n",
       "                      0.3171], dtype=torch.float64)),\n",
       "             ('6.17.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.17.convs.2.0.weight',\n",
       "              tensor([[[-0.0794],\n",
       "                       [-0.1554],\n",
       "                       [ 0.1495],\n",
       "                       ...,\n",
       "                       [ 0.1434],\n",
       "                       [-0.0471],\n",
       "                       [-0.1191]],\n",
       "              \n",
       "                      [[ 0.0439],\n",
       "                       [ 0.0580],\n",
       "                       [-0.0277],\n",
       "                       ...,\n",
       "                       [-0.1035],\n",
       "                       [-0.0186],\n",
       "                       [-0.1371]],\n",
       "              \n",
       "                      [[ 0.0437],\n",
       "                       [-0.0252],\n",
       "                       [ 0.0775],\n",
       "                       ...,\n",
       "                       [ 0.1078],\n",
       "                       [ 0.2906],\n",
       "                       [-0.0108]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0177],\n",
       "                       [-0.1471],\n",
       "                       [ 0.0080],\n",
       "                       ...,\n",
       "                       [-0.0669],\n",
       "                       [ 0.0281],\n",
       "                       [-0.3486]],\n",
       "              \n",
       "                      [[-0.1739],\n",
       "                       [ 0.2456],\n",
       "                       [-0.1407],\n",
       "                       ...,\n",
       "                       [ 0.0558],\n",
       "                       [-0.1788],\n",
       "                       [ 0.0984]],\n",
       "              \n",
       "                      [[-0.1239],\n",
       "                       [-0.1243],\n",
       "                       [ 0.0225],\n",
       "                       ...,\n",
       "                       [-0.0854],\n",
       "                       [-0.1869],\n",
       "                       [ 0.0199]]], dtype=torch.float64)),\n",
       "             ('6.17.convs.2.1.weight',\n",
       "              tensor([ 0.0045,  0.0041, -0.0233,  0.0119,  0.0216, -0.0186,  0.0135, -0.0435,\n",
       "                       0.0137,  0.0382, -0.0151,  0.0052, -0.0125, -0.0150, -0.0153,  0.0216,\n",
       "                      -0.0262,  0.0083,  0.0091, -0.0370, -0.0102, -0.0245,  0.0087, -0.0046,\n",
       "                       0.0291,  0.0240,  0.0230, -0.0279,  0.0274,  0.0013,  0.0226,  0.0087,\n",
       "                       0.0147, -0.0231, -0.0045,  0.0025, -0.0028, -0.0222, -0.0135,  0.0266,\n",
       "                       0.0113,  0.0007,  0.0258, -0.0053,  0.0051, -0.0173, -0.0004, -0.0130,\n",
       "                      -0.0150, -0.0130, -0.0232,  0.0059, -0.0045,  0.0100, -0.0163,  0.0428,\n",
       "                       0.0133, -0.0004, -0.0009,  0.0105,  0.0072, -0.0039, -0.0133,  0.0011,\n",
       "                      -0.0349, -0.0419,  0.0073,  0.0144,  0.0186,  0.0272, -0.0201, -0.0132,\n",
       "                      -0.0191, -0.0073, -0.0010, -0.0238, -0.0139, -0.0123, -0.0195, -0.0244,\n",
       "                      -0.0068,  0.0110, -0.0179,  0.0168,  0.0218, -0.0199,  0.0165, -0.0164,\n",
       "                       0.0058, -0.0064, -0.0163,  0.0019,  0.0396, -0.0007, -0.0215,  0.0076,\n",
       "                      -0.0004,  0.0111, -0.0291, -0.0323,  0.0423, -0.0094,  0.0344,  0.0076,\n",
       "                      -0.0301,  0.0032,  0.0256,  0.0029, -0.0495, -0.0139,  0.0022,  0.0087,\n",
       "                       0.0089, -0.0109,  0.0030,  0.0174,  0.0048,  0.0168, -0.0151, -0.0104,\n",
       "                      -0.0007, -0.0208,  0.0175, -0.0113, -0.0355,  0.0031,  0.0363, -0.0085,\n",
       "                      -0.0009,  0.0151,  0.0120, -0.0446,  0.0325,  0.0078, -0.0035,  0.0156,\n",
       "                       0.0295, -0.0103,  0.0229,  0.0157, -0.0066,  0.0062, -0.0012,  0.0025,\n",
       "                      -0.0159,  0.0192, -0.0056, -0.0278, -0.0042,  0.0019, -0.0159,  0.0007,\n",
       "                      -0.0339,  0.0181, -0.0011, -0.0128, -0.0080,  0.0027, -0.0100, -0.0229,\n",
       "                       0.0100,  0.0020,  0.0079,  0.0152,  0.0299,  0.0030,  0.0277,  0.0017,\n",
       "                      -0.0342, -0.0192,  0.0107, -0.0099,  0.0032,  0.0070,  0.0262,  0.0313,\n",
       "                       0.0048, -0.0215, -0.0190,  0.0052,  0.0057, -0.0039,  0.0073,  0.0062,\n",
       "                      -0.0301, -0.0257, -0.0250, -0.0010, -0.0320,  0.0150, -0.0213, -0.0154,\n",
       "                       0.0179,  0.0004,  0.0121, -0.0026,  0.0176,  0.0256, -0.0055,  0.0062,\n",
       "                       0.0135, -0.0113, -0.0226,  0.0230,  0.0061,  0.0081,  0.0147,  0.0050,\n",
       "                       0.0138, -0.0072,  0.0056, -0.0111, -0.0146, -0.0244, -0.0157,  0.0225,\n",
       "                      -0.0080, -0.0289, -0.0022, -0.0338,  0.0064, -0.0354,  0.0154,  0.0002,\n",
       "                      -0.0001,  0.0075,  0.0323, -0.0307, -0.0070,  0.0077,  0.0133,  0.0108,\n",
       "                       0.0132,  0.0105, -0.0028,  0.0381,  0.0076,  0.0011, -0.0230, -0.0130,\n",
       "                      -0.0158, -0.0173,  0.0144,  0.0095, -0.0140, -0.0332,  0.0263, -0.0204,\n",
       "                      -0.0078, -0.0084,  0.0388,  0.0386,  0.0169,  0.0194, -0.0512, -0.0069],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convs.2.1.bias',\n",
       "              tensor([-4.5486e-05,  6.0256e-03,  9.3203e-03,  1.4539e-02,  1.3087e-03,\n",
       "                       5.6782e-03,  6.0570e-03, -7.3542e-04,  5.3249e-04,  1.6577e-02,\n",
       "                       1.6396e-02, -7.3291e-03,  2.5514e-03, -5.6310e-03,  5.6751e-03,\n",
       "                       4.0660e-03,  2.7858e-02,  5.8710e-04,  1.1688e-02, -4.9836e-03,\n",
       "                      -1.0568e-02,  1.6861e-03,  8.4686e-03,  4.6090e-03,  9.6537e-03,\n",
       "                      -1.7670e-02,  6.8723e-03,  5.2994e-03,  1.3304e-02, -5.5060e-03,\n",
       "                      -1.8059e-03,  1.1647e-02,  3.5535e-03,  1.7987e-02,  1.0142e-02,\n",
       "                       1.3516e-02,  2.3112e-04,  1.1144e-02,  9.6727e-03,  6.7899e-03,\n",
       "                       3.8965e-03,  2.2842e-03, -7.8735e-03, -4.6794e-03,  7.4168e-03,\n",
       "                      -1.7873e-02,  1.2272e-02,  5.5425e-03, -1.3350e-02, -1.4436e-05,\n",
       "                       1.1693e-02,  3.4187e-03,  5.9580e-03,  1.9528e-02, -4.5441e-04,\n",
       "                       1.1899e-02,  1.0841e-02,  5.4668e-03,  6.3329e-03, -5.1205e-03,\n",
       "                      -5.9168e-04,  1.8611e-03,  9.1517e-03,  8.8308e-03, -1.0028e-02,\n",
       "                      -1.5754e-04, -4.1114e-03,  1.5066e-02,  1.7317e-02, -1.6164e-02,\n",
       "                       7.3855e-03, -3.8283e-03, -1.0748e-03, -7.6576e-03,  1.3662e-02,\n",
       "                       7.4842e-03,  1.6951e-03,  1.8237e-02, -3.9403e-04,  1.3537e-02,\n",
       "                       4.5510e-03, -7.9282e-03,  2.0848e-02,  3.6059e-03, -7.7019e-03,\n",
       "                       1.8586e-02, -1.7934e-03,  8.4113e-03,  1.2737e-02, -4.3181e-04,\n",
       "                       1.4576e-03,  1.2780e-02,  1.0248e-02, -6.6179e-03,  6.4495e-03,\n",
       "                      -4.8571e-03,  1.5484e-02,  5.4774e-03,  2.0043e-02,  8.2383e-03,\n",
       "                       2.3438e-02,  1.5568e-02,  6.3293e-03,  1.3777e-02,  1.1332e-02,\n",
       "                       2.2643e-03, -9.1796e-03,  1.0896e-02,  6.0323e-03,  6.4556e-03,\n",
       "                      -2.8244e-04, -6.4253e-03,  2.2538e-03,  2.2485e-02,  1.7934e-02,\n",
       "                       5.1690e-03,  5.2958e-03,  3.3799e-03,  2.8632e-03, -3.2200e-03,\n",
       "                       3.1456e-03,  1.0977e-02,  3.3900e-03,  4.1344e-03,  1.9959e-02,\n",
       "                       8.3535e-03,  5.1631e-03,  4.9004e-03,  3.8810e-03,  1.4662e-02,\n",
       "                       8.1672e-03,  7.7800e-03,  1.3100e-02,  1.4073e-03,  6.0063e-03,\n",
       "                      -1.8018e-02,  1.3580e-02,  3.9374e-03,  5.4135e-03,  8.2910e-03,\n",
       "                       1.5792e-02,  1.1208e-02,  1.1902e-02,  1.8086e-03, -8.0435e-03,\n",
       "                       9.0699e-03,  6.0981e-03, -3.1861e-03,  4.7604e-03,  2.9878e-03,\n",
       "                       7.9735e-03,  9.9461e-03,  6.9924e-03,  1.1382e-02,  1.4283e-02,\n",
       "                       3.0344e-03, -6.7065e-04,  4.5958e-03,  4.1192e-03, -1.5040e-03,\n",
       "                       5.6651e-03,  8.7652e-03, -1.8505e-03,  6.6854e-03,  1.1015e-02,\n",
       "                      -5.3422e-03, -9.5780e-03,  5.3796e-03,  5.8183e-03,  1.1702e-02,\n",
       "                       1.1239e-02, -2.5882e-03,  1.0441e-02,  1.5723e-02, -1.3589e-02,\n",
       "                       1.2948e-02, -1.0222e-04,  1.8138e-02,  2.3002e-03,  2.1699e-03,\n",
       "                      -7.3694e-04,  9.1046e-03, -1.9512e-03, -7.9285e-03,  9.8535e-03,\n",
       "                       7.0501e-03,  1.0547e-02,  8.7334e-03,  8.2931e-03,  3.7524e-03,\n",
       "                       6.6465e-03,  6.2764e-03,  6.8081e-03,  9.5316e-03,  5.7852e-03,\n",
       "                       9.4402e-03,  1.0103e-02,  4.6320e-04,  5.7802e-03,  1.2478e-02,\n",
       "                      -5.4578e-04,  2.2199e-02,  1.4904e-02,  1.6152e-02,  1.7721e-02,\n",
       "                       4.9351e-03,  8.8235e-03, -1.0745e-02,  3.7662e-03,  7.8666e-03,\n",
       "                       8.1069e-03,  9.6116e-03, -3.1557e-03,  9.1075e-03,  6.4481e-03,\n",
       "                       7.6962e-03,  1.7362e-03,  1.5496e-02,  2.2152e-03,  1.3356e-03,\n",
       "                       1.5570e-02,  8.1333e-03,  5.5015e-03,  1.3156e-02,  8.4536e-03,\n",
       "                       4.8096e-03, -4.3397e-03, -3.1354e-03,  2.4866e-02,  1.8989e-02,\n",
       "                       4.7648e-03, -2.2109e-04,  8.2660e-03,  6.3731e-03, -7.4253e-04,\n",
       "                       8.6815e-03, -2.2512e-03,  1.4911e-02,  4.3540e-03,  1.4208e-02,\n",
       "                       1.3251e-04,  2.7282e-03, -6.1565e-03,  1.2093e-02,  1.4628e-03,\n",
       "                       1.0310e-02,  6.6734e-03,  4.5486e-04, -1.6654e-02, -9.6438e-03,\n",
       "                       1.8525e-02,  2.3138e-02,  1.1708e-02,  1.7715e-02,  4.1041e-03,\n",
       "                       2.3974e-03], dtype=torch.float64)),\n",
       "             ('6.17.convs.2.1.running_mean',\n",
       "              tensor([ 3.7024e-01,  2.0199e-01, -5.8932e-01, -2.9456e-01, -1.5762e-02,\n",
       "                      -5.4308e-01,  2.4270e-01,  6.8195e-01,  1.6808e-01,  1.8157e-01,\n",
       "                      -3.1067e-02, -9.1627e-02,  3.3589e-01,  4.3754e-01,  4.4139e-01,\n",
       "                      -4.1747e-01, -6.2627e-01, -3.7111e-01, -3.3084e-03,  4.4530e-01,\n",
       "                       1.8779e-01,  3.8325e-01,  5.7041e-01, -2.0387e-01, -4.7382e-01,\n",
       "                      -4.3674e-03,  6.2565e-01,  4.0120e-01,  4.0990e-01, -1.0849e-01,\n",
       "                      -1.3312e-01,  3.0331e-01,  2.9492e-01,  9.3740e-01, -1.1587e-01,\n",
       "                      -3.0130e-01,  3.9192e-01,  3.5150e-01,  2.3179e-01,  4.3525e-02,\n",
       "                      -2.9420e-02, -1.8285e-01, -3.0051e-01, -3.1498e-01,  5.9791e-01,\n",
       "                       1.9901e-01,  4.5652e-01, -2.9374e-01,  2.0447e-01,  3.7247e-01,\n",
       "                       3.6691e-01, -5.0435e-03, -6.8386e-02, -6.0224e-01, -6.4418e-02,\n",
       "                       6.7236e-01, -4.6991e-01,  5.7562e-02, -4.7838e-01, -2.9798e-02,\n",
       "                       5.0790e-01, -1.7083e-01,  1.2350e-01, -2.8500e-01,  3.9261e-01,\n",
       "                       1.4347e-01, -6.2737e-04, -3.0265e-02,  2.3465e-01,  5.5923e-01,\n",
       "                      -5.0849e-01,  2.7459e-02,  1.4260e-01,  1.4072e-01,  4.1721e-01,\n",
       "                       5.4835e-02,  6.4167e-01,  3.9489e-01, -5.6341e-01, -4.1856e-01,\n",
       "                       5.1450e-01, -1.0079e-01,  7.9869e-02, -3.7211e-01,  1.3429e-01,\n",
       "                      -6.5351e-01, -2.6659e-01, -5.0698e-01,  2.3678e-01, -2.6831e-01,\n",
       "                      -3.9020e-01, -2.2874e-02,  8.1380e-02,  1.4259e-01,  8.5290e-01,\n",
       "                       5.9297e-01, -5.8248e-01,  6.3449e-01, -8.1682e-01, -7.3134e-02,\n",
       "                      -5.8580e-01,  2.9379e-01,  1.1317e-01,  1.6616e-01, -3.8099e-01,\n",
       "                       3.2084e-01,  1.3036e-01,  4.1928e-01,  5.3826e-01,  7.2245e-01,\n",
       "                       3.9075e-02,  8.0109e-01,  1.2795e-02,  3.6939e-01,  2.6068e-01,\n",
       "                      -5.8114e-01,  3.8999e-01, -1.6727e-01,  2.0008e-01, -2.2343e-01,\n",
       "                       1.2692e-01, -4.4147e-01,  2.9411e-01, -7.3177e-01,  4.8792e-01,\n",
       "                       9.3940e-01,  1.3152e-01, -9.1903e-02,  7.7173e-02, -6.1913e-01,\n",
       "                       2.6078e-01,  5.7101e-01,  1.2481e-01, -1.6686e-02, -4.2232e-02,\n",
       "                       1.3614e-01, -4.2237e-01,  8.9904e-02,  3.6924e-01,  1.7907e-01,\n",
       "                      -2.4065e-01,  3.2218e-01, -3.4991e-01,  2.2324e-01,  2.2254e-01,\n",
       "                       5.1009e-01, -2.6143e-01, -8.9272e-01, -2.4157e-02, -4.4340e-01,\n",
       "                      -1.0770e-01,  1.8312e-01, -3.8298e-01, -8.0961e-02, -7.4842e-02,\n",
       "                      -1.9189e-01, -5.0744e-01, -1.4356e-01, -1.1591e-01, -4.2615e-01,\n",
       "                      -2.3919e-01, -2.5695e-01, -1.2306e-01, -2.6789e-01, -6.3123e-01,\n",
       "                       1.3136e-04, -9.0787e-01, -3.6040e-01,  3.2891e-01, -2.7260e-01,\n",
       "                      -7.6605e-02, -4.5037e-01, -2.3511e-01, -4.7999e-01, -1.3458e-02,\n",
       "                       3.7782e-01,  6.3541e-02,  2.3703e-02,  4.6335e-01,  7.8672e-02,\n",
       "                      -4.3246e-01,  7.9925e-01, -5.4128e-01,  5.2813e-01, -3.3250e-01,\n",
       "                       4.3922e-01, -1.1671e-01,  1.8851e-01,  2.4798e-01,  5.2746e-01,\n",
       "                       1.6409e-02,  7.2987e-01, -3.0908e-01,  4.6262e-02,  9.6338e-01,\n",
       "                       8.1525e-01,  1.5216e-01, -2.1230e-01,  2.7901e-01,  1.9349e-01,\n",
       "                      -2.9105e-01,  5.3078e-01,  1.5774e-01, -2.0463e-01,  2.1300e-01,\n",
       "                       5.6954e-01,  4.3563e-01,  1.1149e-01,  2.7809e-01, -1.7339e-01,\n",
       "                      -2.7596e-01, -1.0872e+00, -9.6208e-02, -1.6955e-01, -5.7735e-01,\n",
       "                       3.3802e-01,  3.4071e-01,  1.5794e-02, -6.2159e-02,  5.0687e-01,\n",
       "                       3.1973e-01,  2.7486e-02,  9.7964e-02, -1.7091e-02, -9.1394e-01,\n",
       "                      -5.5152e-02, -1.1772e-01,  1.1513e-01, -2.2522e-01, -2.2518e-01,\n",
       "                       8.7394e-02, -3.6991e-01, -7.9692e-01, -2.0979e-01, -5.6866e-02,\n",
       "                      -1.2670e-01, -1.0352e-01, -3.9386e-01, -1.9357e-01,  4.3411e-01,\n",
       "                      -4.9134e-01, -7.3731e-02,  3.5982e-01, -1.7892e-01,  2.2660e-01,\n",
       "                       5.9985e-01, -8.4993e-02, -1.5441e-01,  2.1440e-01,  4.4953e-01,\n",
       "                       1.5204e-01, -8.1264e-01, -7.8709e-02, -6.6976e-01,  2.3725e-01,\n",
       "                      -4.3351e-01], dtype=torch.float64)),\n",
       "             ('6.17.convs.2.1.running_var',\n",
       "              tensor([0.4834, 0.2445, 0.4250, 0.4389, 0.2160, 0.4665, 0.4324, 0.6194, 0.3131,\n",
       "                      0.5174, 0.3143, 0.2008, 0.2788, 0.5726, 0.2613, 0.5530, 0.3823, 0.3396,\n",
       "                      0.3076, 0.5625, 0.1679, 0.5683, 0.3463, 0.3091, 0.4258, 0.2476, 0.3051,\n",
       "                      0.4082, 0.4261, 0.1978, 0.7196, 0.2739, 0.2767, 0.4441, 0.3076, 0.3342,\n",
       "                      0.0811, 0.2860, 0.2839, 0.4172, 0.3195, 0.1690, 0.1475, 0.4127, 0.3228,\n",
       "                      0.5583, 0.2369, 0.1649, 0.3827, 0.2620, 0.5234, 0.4196, 0.3438, 0.2099,\n",
       "                      0.4946, 0.4881, 0.5881, 0.3282, 0.6560, 0.1514, 0.1317, 0.1007, 0.1751,\n",
       "                      0.1825, 0.2969, 0.3156, 0.3539, 0.3036, 0.2313, 0.6777, 0.3586, 0.3528,\n",
       "                      0.1945, 0.4021, 0.4117, 0.3253, 0.4511, 0.3565, 0.4871, 0.3781, 0.3168,\n",
       "                      0.4729, 0.2951, 0.4289, 0.5328, 0.6612, 0.3624, 0.4502, 0.2456, 0.2601,\n",
       "                      0.5935, 0.1553, 0.4542, 0.2070, 0.3745, 0.4115, 0.3708, 0.1990, 0.4252,\n",
       "                      0.3363, 0.5051, 0.3461, 0.4251, 0.1150, 0.4776, 0.0926, 0.4658, 0.6165,\n",
       "                      0.3205, 0.3335, 0.1285, 0.5038, 0.4889, 0.5185, 0.3024, 0.4351, 0.5167,\n",
       "                      0.4952, 0.3016, 0.3540, 0.1233, 0.3830, 0.3595, 0.4158, 0.3526, 0.3903,\n",
       "                      0.3123, 0.2241, 0.0856, 0.4551, 0.3894, 0.3268, 0.3814, 0.0969, 0.3195,\n",
       "                      0.3051, 0.2632, 0.3055, 0.3501, 0.3030, 0.2753, 0.2809, 0.2193, 0.0746,\n",
       "                      0.1382, 0.8117, 0.0877, 0.5908, 0.0776, 0.2687, 0.6965, 0.2212, 0.4589,\n",
       "                      0.4283, 0.1816, 0.3318, 0.4388, 0.0761, 0.2122, 0.2887, 0.3384, 0.3440,\n",
       "                      0.2722, 0.2363, 0.5354, 0.4137, 0.3240, 0.1577, 0.4402, 0.4709, 0.0716,\n",
       "                      0.2064, 0.2588, 0.1717, 0.3567, 0.4416, 0.1605, 0.3168, 0.2784, 0.1911,\n",
       "                      0.4119, 0.1748, 0.4294, 0.3043, 0.2657, 0.5145, 0.4997, 0.1051, 0.5464,\n",
       "                      0.3533, 0.4112, 0.3274, 0.3064, 0.5507, 0.3906, 0.3060, 0.5791, 0.3679,\n",
       "                      0.2572, 0.3905, 0.1842, 0.2337, 0.5736, 0.6057, 0.2915, 0.3813, 0.3652,\n",
       "                      0.0254, 0.2391, 0.3461, 0.0871, 0.3246, 0.2150, 0.5893, 0.3394, 0.4176,\n",
       "                      0.4271, 0.3352, 0.0980, 0.5630, 0.2918, 0.2940, 0.2407, 0.2996, 0.6469,\n",
       "                      0.3469, 0.4700, 0.3163, 0.5411, 0.4300, 0.2391, 0.4199, 0.6520, 0.2476,\n",
       "                      0.1674, 0.3415, 0.1240, 0.0780, 0.4357, 0.1243, 0.2961, 0.2322, 0.7925,\n",
       "                      0.1487, 0.2004, 0.3188, 0.5123, 0.4813, 0.2167, 0.4056, 0.5035, 0.5278,\n",
       "                      0.3785, 0.3716, 0.3405, 0.3593], dtype=torch.float64)),\n",
       "             ('6.17.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.17.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.1011],\n",
       "                       [ 0.1910],\n",
       "                       [-0.0038],\n",
       "                       ...,\n",
       "                       [-0.1547],\n",
       "                       [ 0.0677],\n",
       "                       [-0.0680]],\n",
       "              \n",
       "                      [[-0.0171],\n",
       "                       [-0.0157],\n",
       "                       [-0.1286],\n",
       "                       ...,\n",
       "                       [-0.0976],\n",
       "                       [-0.0246],\n",
       "                       [-0.1203]],\n",
       "              \n",
       "                      [[-0.0841],\n",
       "                       [ 0.0101],\n",
       "                       [-0.0634],\n",
       "                       ...,\n",
       "                       [-0.0668],\n",
       "                       [-0.1459],\n",
       "                       [ 0.0700]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0079],\n",
       "                       [-0.0362],\n",
       "                       [-0.0751],\n",
       "                       ...,\n",
       "                       [ 0.1131],\n",
       "                       [ 0.0727],\n",
       "                       [ 0.0293]],\n",
       "              \n",
       "                      [[ 0.0453],\n",
       "                       [-0.0168],\n",
       "                       [ 0.1205],\n",
       "                       ...,\n",
       "                       [ 0.0348],\n",
       "                       [ 0.0182],\n",
       "                       [ 0.0405]],\n",
       "              \n",
       "                      [[-0.0843],\n",
       "                       [-0.0257],\n",
       "                       [-0.0705],\n",
       "                       ...,\n",
       "                       [-0.0185],\n",
       "                       [-0.0186],\n",
       "                       [ 0.0884]]], dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.0.1.weight',\n",
       "              tensor([0.9546, 0.9901, 0.9658, 1.0060, 0.9663, 0.9994, 0.9632, 0.9947, 0.9562,\n",
       "                      0.9514, 0.9837, 0.9780, 0.9789, 0.9608, 0.9545, 0.9662, 0.9640, 0.9949,\n",
       "                      0.9597, 0.9776, 0.9839, 0.9756, 0.9557, 0.9577, 0.9561, 0.9956, 0.9636,\n",
       "                      0.9498, 0.9728, 0.9772, 0.9605, 0.9446, 0.9576, 0.9761, 0.9658, 0.9944,\n",
       "                      0.9678, 0.9601, 0.9873, 0.9531, 0.9494, 0.9700, 0.9756, 0.9400, 0.9635,\n",
       "                      0.9587, 0.9886, 0.9748, 0.9529, 0.9753, 0.9938, 0.9957, 0.9687, 0.9733,\n",
       "                      0.9631, 0.9728, 0.9541, 0.9469, 0.9842, 0.9612, 0.9629, 0.9861, 0.9751,\n",
       "                      0.9540], dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.0.1.bias',\n",
       "              tensor([-0.0119,  0.0167,  0.0088,  0.0083, -0.0066,  0.0169,  0.0153,  0.0202,\n",
       "                      -0.0178, -0.0057, -0.0153, -0.0096, -0.0063, -0.0047, -0.0076, -0.0140,\n",
       "                      -0.0260,  0.0103, -0.0008,  0.0121,  0.0059,  0.0247, -0.0302, -0.0155,\n",
       "                       0.0100,  0.0182, -0.0056, -0.0007,  0.0111, -0.0046, -0.0095,  0.0017,\n",
       "                      -0.0116,  0.0141, -0.0087,  0.0118, -0.0053,  0.0011,  0.0161,  0.0005,\n",
       "                       0.0074, -0.0099, -0.0048, -0.0056,  0.0019,  0.0019,  0.0142, -0.0085,\n",
       "                       0.0110,  0.0326,  0.0053, -0.0033,  0.0119,  0.0063, -0.0008,  0.0123,\n",
       "                      -0.0266, -0.0235,  0.0039, -0.0100,  0.0134,  0.0103,  0.0019, -0.0110],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.0431,  0.3416,  1.1659, -0.4379,  0.9825, -0.2735, -0.5742, -0.0839,\n",
       "                      -0.3975, -0.4308, -0.6213, -0.0291, -0.5786, -0.0193,  0.0833,  0.5728,\n",
       "                       0.9937,  0.2995, -0.6744, -0.9051, -0.9441, -0.6111, -1.3306,  0.1646,\n",
       "                      -0.2059,  0.2093,  0.1936, -0.9058,  0.0300, -0.9388,  0.2495, -0.7662,\n",
       "                       0.2187,  0.1358,  0.6306,  0.8113, -0.0563,  0.2728,  0.1240, -0.1015,\n",
       "                       0.7224,  0.8565,  0.2912, -1.0717, -0.0315, -1.0396,  1.1022, -0.4631,\n",
       "                      -0.0057, -0.4879, -1.1238,  0.4833, -0.2824,  0.8825,  0.5286,  0.2315,\n",
       "                       0.2808,  0.3639, -0.7991, -0.0864, -0.4335, -0.7895,  0.2155,  0.2494],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.0.1.running_var',\n",
       "              tensor([0.2662, 0.1606, 0.9427, 0.0978, 0.5794, 0.1695, 0.1603, 0.0982, 0.2000,\n",
       "                      0.2465, 0.1052, 0.1230, 0.1076, 0.1245, 0.2364, 0.1655, 0.1708, 0.1950,\n",
       "                      0.2093, 0.5119, 0.1396, 0.0962, 0.3256, 0.2245, 0.1506, 0.1173, 0.4474,\n",
       "                      0.3014, 0.2194, 0.6246, 0.2335, 1.0946, 0.3558, 0.1441, 0.1674, 0.1553,\n",
       "                      0.1965, 0.2472, 0.2358, 0.2846, 0.1663, 0.1888, 0.1784, 0.8368, 0.8129,\n",
       "                      0.8493, 0.1019, 0.1602, 0.2671, 0.2183, 0.1491, 0.1671, 0.4543, 0.1669,\n",
       "                      0.2251, 0.1110, 0.8243, 0.6660, 0.1390, 0.1291, 0.3830, 0.1056, 0.2283,\n",
       "                      0.1395], dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.17.convpath.0.1.0.weight',\n",
       "              tensor([[[-2.7650e-03, -8.7907e-02, -8.0904e-02, -8.8151e-02, -1.7358e-01],\n",
       "                       [ 3.8751e-02,  4.9101e-02,  1.7389e-02,  5.8484e-02,  1.2000e-02],\n",
       "                       [ 3.6215e-02, -8.3917e-02,  5.0440e-03, -5.5940e-02, -8.0683e-02],\n",
       "                       ...,\n",
       "                       [-8.1097e-02,  3.3157e-02,  9.5237e-02,  5.3807e-02,  5.8816e-02],\n",
       "                       [ 3.3692e-02, -4.0109e-02, -1.3064e-02,  7.8080e-02,  6.4626e-03],\n",
       "                       [ 1.3472e-01, -3.6794e-02, -3.2681e-02, -1.5583e-01,  4.1795e-02]],\n",
       "              \n",
       "                      [[ 9.0043e-02, -7.6573e-02, -2.1841e-02,  4.0454e-02, -4.0627e-02],\n",
       "                       [ 3.3711e-02,  1.2113e-01,  6.4196e-02, -4.7071e-03,  4.9153e-02],\n",
       "                       [ 4.9101e-02,  1.2570e-02,  2.0064e-02,  5.2496e-03, -5.9189e-02],\n",
       "                       ...,\n",
       "                       [ 6.4913e-02, -2.8510e-02, -2.2203e-02,  6.4161e-02, -5.8795e-02],\n",
       "                       [-5.3323e-02, -4.5986e-02,  1.5897e-01,  8.1368e-02,  6.4010e-02],\n",
       "                       [ 2.4161e-02, -6.6179e-02,  7.9401e-02, -7.1610e-02,  1.6790e-02]],\n",
       "              \n",
       "                      [[ 7.4899e-02,  6.3762e-02,  4.4013e-03,  1.8360e-01, -6.2220e-02],\n",
       "                       [-1.0947e-02, -6.7096e-03,  4.6106e-02, -6.3463e-02, -3.3193e-02],\n",
       "                       [-1.7243e-03,  1.0452e-01, -3.1891e-02, -1.4179e-02, -9.9657e-02],\n",
       "                       ...,\n",
       "                       [-2.6831e-02, -1.2870e-01, -7.2081e-02, -3.5437e-02, -5.7481e-02],\n",
       "                       [ 1.1444e-01,  5.0991e-02,  4.5252e-02,  8.1723e-02,  1.4126e-02],\n",
       "                       [-6.1653e-02,  1.5755e-04,  1.5366e-01, -2.0145e-02,  1.3626e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 5.0871e-02, -1.5253e-01,  3.7321e-02,  1.5114e-02, -9.8919e-02],\n",
       "                       [-1.8270e-02, -8.8611e-02, -6.2199e-02, -3.5088e-02,  6.9235e-02],\n",
       "                       [ 1.8439e-01, -1.8785e-01,  9.3109e-02,  8.7847e-02,  1.6660e-01],\n",
       "                       ...,\n",
       "                       [ 9.6717e-02,  8.4309e-02,  7.3325e-04,  7.0540e-02,  4.7752e-02],\n",
       "                       [-2.3678e-02, -1.1943e-02,  5.0881e-02,  6.2254e-02, -3.7987e-02],\n",
       "                       [ 1.6986e-02,  2.3752e-02,  4.9315e-02,  6.3301e-02,  6.4597e-02]],\n",
       "              \n",
       "                      [[-2.8797e-02,  1.5723e-01,  5.9449e-02, -2.4509e-02,  3.9729e-02],\n",
       "                       [-2.0425e-02,  2.8752e-03,  1.4395e-01,  6.1944e-02,  5.5884e-02],\n",
       "                       [-7.8054e-02,  4.7143e-02, -1.1606e-01,  5.0965e-03, -3.9009e-02],\n",
       "                       ...,\n",
       "                       [ 7.2926e-03,  1.7506e-01, -1.8480e-03,  7.1178e-02, -1.8200e-02],\n",
       "                       [-1.0687e-01,  1.0052e-01, -6.2718e-02, -3.4395e-02, -9.4569e-02],\n",
       "                       [ 5.6353e-02,  5.1006e-02, -3.9454e-02, -7.6750e-02, -8.2791e-02]],\n",
       "              \n",
       "                      [[-1.2018e-02,  6.7915e-02, -8.0359e-03, -1.8727e-02, -6.7394e-02],\n",
       "                       [-5.7579e-02,  9.2954e-03, -9.1481e-02, -2.4134e-02, -5.3126e-03],\n",
       "                       [ 2.4703e-02, -7.7651e-02, -1.4564e-01, -2.7633e-02,  5.8622e-02],\n",
       "                       ...,\n",
       "                       [ 4.3366e-02,  9.1384e-02, -6.0102e-02, -6.7411e-02,  5.9397e-02],\n",
       "                       [ 6.2592e-02,  5.1124e-02,  7.2105e-02,  1.7691e-01, -1.6832e-01],\n",
       "                       [-2.4049e-03,  4.1401e-02,  7.8244e-02, -9.5568e-02,  2.4983e-02]]],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.1.1.weight',\n",
       "              tensor([0.9490, 0.9780, 0.9574, 0.9939, 0.9676, 0.9685, 0.9727, 0.9774, 0.9398,\n",
       "                      0.9683, 0.9597, 0.9828, 0.9244, 0.9300, 0.9817, 0.9983, 0.9407, 0.9416,\n",
       "                      0.9459, 0.9723, 0.9887, 0.9688, 0.9466, 0.9652, 0.9725, 0.9727, 0.9774,\n",
       "                      0.9574, 0.9645, 0.9305, 0.9633, 0.9482, 0.9567, 0.9594, 0.9607, 0.9601,\n",
       "                      0.9735, 0.9529, 0.9600, 0.9547, 0.9749, 0.9565, 0.9697, 0.9553, 0.9678,\n",
       "                      0.9492, 1.0010, 0.9589, 0.9757, 0.9713, 0.9897, 0.9772, 0.9593, 1.0072,\n",
       "                      0.9574, 0.9697, 0.9534, 0.9765, 0.9794, 0.9620, 0.9813, 0.9826, 0.9359,\n",
       "                      0.9683], dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.1.1.bias',\n",
       "              tensor([-0.0059,  0.0153, -0.0273,  0.0134,  0.0020,  0.0073, -0.0014, -0.0193,\n",
       "                      -0.0195, -0.0210, -0.0007, -0.0241, -0.0092, -0.0293,  0.0136, -0.0335,\n",
       "                      -0.0134, -0.0135, -0.0083, -0.0078,  0.0016, -0.0152, -0.0043, -0.0290,\n",
       "                      -0.0024,  0.0032, -0.0137,  0.0006, -0.0026, -0.0082, -0.0061, -0.0051,\n",
       "                      -0.0238, -0.0061, -0.0049, -0.0108,  0.0136, -0.0154, -0.0134, -0.0098,\n",
       "                       0.0134, -0.0236,  0.0085, -0.0122,  0.0093, -0.0199,  0.0123, -0.0056,\n",
       "                      -0.0313,  0.0074, -0.0245, -0.0017,  0.0080,  0.0105, -0.0094,  0.0024,\n",
       "                      -0.0106, -0.0018, -0.0098, -0.0083,  0.0004, -0.0059, -0.0045,  0.0082],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.1.1.running_mean',\n",
       "              tensor([ 0.1076,  0.0531,  0.3838, -0.4194,  0.2765,  1.0686,  0.4875,  0.9236,\n",
       "                       0.1217,  0.7606, -0.9840,  0.9500, -0.4870, -0.3049,  0.5356,  1.5241,\n",
       "                      -0.0368, -0.8052, -0.0407, -0.0346, -0.6509,  0.1868, -0.5836,  0.5512,\n",
       "                       0.3642, -0.4180,  0.5873,  0.3476,  0.5529, -0.1865,  0.2539, -0.6929,\n",
       "                      -0.4648,  0.5983, -0.1700, -0.2726, -0.1861,  0.2151,  0.2371, -0.2833,\n",
       "                      -0.0923,  0.2916, -0.4289, -1.1124, -0.8487,  0.0323, -0.3319,  0.6912,\n",
       "                       0.9337,  0.3910,  0.8991,  0.0033,  1.0178,  0.3381, -1.1239,  0.2089,\n",
       "                       0.6657, -0.8024,  1.2301, -0.1110, -0.1906, -0.4709,  0.1098, -0.1694],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.1.1.running_var',\n",
       "              tensor([0.5253, 0.6203, 0.6087, 0.3960, 0.2999, 0.4142, 0.5388, 0.5990, 0.6290,\n",
       "                      0.5431, 0.7907, 0.4143, 0.4195, 0.4786, 0.3714, 0.5621, 0.4939, 0.4016,\n",
       "                      0.5699, 0.5559, 0.5137, 0.5611, 0.5967, 0.7345, 0.4974, 0.4699, 0.6522,\n",
       "                      0.4545, 0.4128, 0.5330, 0.5432, 0.6835, 0.4363, 0.8313, 0.4695, 0.8678,\n",
       "                      0.4816, 0.3829, 0.7665, 0.5329, 0.4250, 1.1877, 0.4461, 0.5738, 0.5738,\n",
       "                      0.4175, 0.4046, 0.4687, 0.3871, 0.5521, 0.6238, 0.4324, 0.5601, 0.4125,\n",
       "                      0.5125, 0.6241, 0.5805, 0.5618, 0.3811, 0.5905, 0.6000, 0.4785, 0.5265,\n",
       "                      0.3171], dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.17.convpath.0.2.0.weight',\n",
       "              tensor([[[-0.0794],\n",
       "                       [-0.1554],\n",
       "                       [ 0.1495],\n",
       "                       ...,\n",
       "                       [ 0.1434],\n",
       "                       [-0.0471],\n",
       "                       [-0.1191]],\n",
       "              \n",
       "                      [[ 0.0439],\n",
       "                       [ 0.0580],\n",
       "                       [-0.0277],\n",
       "                       ...,\n",
       "                       [-0.1035],\n",
       "                       [-0.0186],\n",
       "                       [-0.1371]],\n",
       "              \n",
       "                      [[ 0.0437],\n",
       "                       [-0.0252],\n",
       "                       [ 0.0775],\n",
       "                       ...,\n",
       "                       [ 0.1078],\n",
       "                       [ 0.2906],\n",
       "                       [-0.0108]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0177],\n",
       "                       [-0.1471],\n",
       "                       [ 0.0080],\n",
       "                       ...,\n",
       "                       [-0.0669],\n",
       "                       [ 0.0281],\n",
       "                       [-0.3486]],\n",
       "              \n",
       "                      [[-0.1739],\n",
       "                       [ 0.2456],\n",
       "                       [-0.1407],\n",
       "                       ...,\n",
       "                       [ 0.0558],\n",
       "                       [-0.1788],\n",
       "                       [ 0.0984]],\n",
       "              \n",
       "                      [[-0.1239],\n",
       "                       [-0.1243],\n",
       "                       [ 0.0225],\n",
       "                       ...,\n",
       "                       [-0.0854],\n",
       "                       [-0.1869],\n",
       "                       [ 0.0199]]], dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.2.1.weight',\n",
       "              tensor([ 0.0045,  0.0041, -0.0233,  0.0119,  0.0216, -0.0186,  0.0135, -0.0435,\n",
       "                       0.0137,  0.0382, -0.0151,  0.0052, -0.0125, -0.0150, -0.0153,  0.0216,\n",
       "                      -0.0262,  0.0083,  0.0091, -0.0370, -0.0102, -0.0245,  0.0087, -0.0046,\n",
       "                       0.0291,  0.0240,  0.0230, -0.0279,  0.0274,  0.0013,  0.0226,  0.0087,\n",
       "                       0.0147, -0.0231, -0.0045,  0.0025, -0.0028, -0.0222, -0.0135,  0.0266,\n",
       "                       0.0113,  0.0007,  0.0258, -0.0053,  0.0051, -0.0173, -0.0004, -0.0130,\n",
       "                      -0.0150, -0.0130, -0.0232,  0.0059, -0.0045,  0.0100, -0.0163,  0.0428,\n",
       "                       0.0133, -0.0004, -0.0009,  0.0105,  0.0072, -0.0039, -0.0133,  0.0011,\n",
       "                      -0.0349, -0.0419,  0.0073,  0.0144,  0.0186,  0.0272, -0.0201, -0.0132,\n",
       "                      -0.0191, -0.0073, -0.0010, -0.0238, -0.0139, -0.0123, -0.0195, -0.0244,\n",
       "                      -0.0068,  0.0110, -0.0179,  0.0168,  0.0218, -0.0199,  0.0165, -0.0164,\n",
       "                       0.0058, -0.0064, -0.0163,  0.0019,  0.0396, -0.0007, -0.0215,  0.0076,\n",
       "                      -0.0004,  0.0111, -0.0291, -0.0323,  0.0423, -0.0094,  0.0344,  0.0076,\n",
       "                      -0.0301,  0.0032,  0.0256,  0.0029, -0.0495, -0.0139,  0.0022,  0.0087,\n",
       "                       0.0089, -0.0109,  0.0030,  0.0174,  0.0048,  0.0168, -0.0151, -0.0104,\n",
       "                      -0.0007, -0.0208,  0.0175, -0.0113, -0.0355,  0.0031,  0.0363, -0.0085,\n",
       "                      -0.0009,  0.0151,  0.0120, -0.0446,  0.0325,  0.0078, -0.0035,  0.0156,\n",
       "                       0.0295, -0.0103,  0.0229,  0.0157, -0.0066,  0.0062, -0.0012,  0.0025,\n",
       "                      -0.0159,  0.0192, -0.0056, -0.0278, -0.0042,  0.0019, -0.0159,  0.0007,\n",
       "                      -0.0339,  0.0181, -0.0011, -0.0128, -0.0080,  0.0027, -0.0100, -0.0229,\n",
       "                       0.0100,  0.0020,  0.0079,  0.0152,  0.0299,  0.0030,  0.0277,  0.0017,\n",
       "                      -0.0342, -0.0192,  0.0107, -0.0099,  0.0032,  0.0070,  0.0262,  0.0313,\n",
       "                       0.0048, -0.0215, -0.0190,  0.0052,  0.0057, -0.0039,  0.0073,  0.0062,\n",
       "                      -0.0301, -0.0257, -0.0250, -0.0010, -0.0320,  0.0150, -0.0213, -0.0154,\n",
       "                       0.0179,  0.0004,  0.0121, -0.0026,  0.0176,  0.0256, -0.0055,  0.0062,\n",
       "                       0.0135, -0.0113, -0.0226,  0.0230,  0.0061,  0.0081,  0.0147,  0.0050,\n",
       "                       0.0138, -0.0072,  0.0056, -0.0111, -0.0146, -0.0244, -0.0157,  0.0225,\n",
       "                      -0.0080, -0.0289, -0.0022, -0.0338,  0.0064, -0.0354,  0.0154,  0.0002,\n",
       "                      -0.0001,  0.0075,  0.0323, -0.0307, -0.0070,  0.0077,  0.0133,  0.0108,\n",
       "                       0.0132,  0.0105, -0.0028,  0.0381,  0.0076,  0.0011, -0.0230, -0.0130,\n",
       "                      -0.0158, -0.0173,  0.0144,  0.0095, -0.0140, -0.0332,  0.0263, -0.0204,\n",
       "                      -0.0078, -0.0084,  0.0388,  0.0386,  0.0169,  0.0194, -0.0512, -0.0069],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.2.1.bias',\n",
       "              tensor([-4.5486e-05,  6.0256e-03,  9.3203e-03,  1.4539e-02,  1.3087e-03,\n",
       "                       5.6782e-03,  6.0570e-03, -7.3542e-04,  5.3249e-04,  1.6577e-02,\n",
       "                       1.6396e-02, -7.3291e-03,  2.5514e-03, -5.6310e-03,  5.6751e-03,\n",
       "                       4.0660e-03,  2.7858e-02,  5.8710e-04,  1.1688e-02, -4.9836e-03,\n",
       "                      -1.0568e-02,  1.6861e-03,  8.4686e-03,  4.6090e-03,  9.6537e-03,\n",
       "                      -1.7670e-02,  6.8723e-03,  5.2994e-03,  1.3304e-02, -5.5060e-03,\n",
       "                      -1.8059e-03,  1.1647e-02,  3.5535e-03,  1.7987e-02,  1.0142e-02,\n",
       "                       1.3516e-02,  2.3112e-04,  1.1144e-02,  9.6727e-03,  6.7899e-03,\n",
       "                       3.8965e-03,  2.2842e-03, -7.8735e-03, -4.6794e-03,  7.4168e-03,\n",
       "                      -1.7873e-02,  1.2272e-02,  5.5425e-03, -1.3350e-02, -1.4436e-05,\n",
       "                       1.1693e-02,  3.4187e-03,  5.9580e-03,  1.9528e-02, -4.5441e-04,\n",
       "                       1.1899e-02,  1.0841e-02,  5.4668e-03,  6.3329e-03, -5.1205e-03,\n",
       "                      -5.9168e-04,  1.8611e-03,  9.1517e-03,  8.8308e-03, -1.0028e-02,\n",
       "                      -1.5754e-04, -4.1114e-03,  1.5066e-02,  1.7317e-02, -1.6164e-02,\n",
       "                       7.3855e-03, -3.8283e-03, -1.0748e-03, -7.6576e-03,  1.3662e-02,\n",
       "                       7.4842e-03,  1.6951e-03,  1.8237e-02, -3.9403e-04,  1.3537e-02,\n",
       "                       4.5510e-03, -7.9282e-03,  2.0848e-02,  3.6059e-03, -7.7019e-03,\n",
       "                       1.8586e-02, -1.7934e-03,  8.4113e-03,  1.2737e-02, -4.3181e-04,\n",
       "                       1.4576e-03,  1.2780e-02,  1.0248e-02, -6.6179e-03,  6.4495e-03,\n",
       "                      -4.8571e-03,  1.5484e-02,  5.4774e-03,  2.0043e-02,  8.2383e-03,\n",
       "                       2.3438e-02,  1.5568e-02,  6.3293e-03,  1.3777e-02,  1.1332e-02,\n",
       "                       2.2643e-03, -9.1796e-03,  1.0896e-02,  6.0323e-03,  6.4556e-03,\n",
       "                      -2.8244e-04, -6.4253e-03,  2.2538e-03,  2.2485e-02,  1.7934e-02,\n",
       "                       5.1690e-03,  5.2958e-03,  3.3799e-03,  2.8632e-03, -3.2200e-03,\n",
       "                       3.1456e-03,  1.0977e-02,  3.3900e-03,  4.1344e-03,  1.9959e-02,\n",
       "                       8.3535e-03,  5.1631e-03,  4.9004e-03,  3.8810e-03,  1.4662e-02,\n",
       "                       8.1672e-03,  7.7800e-03,  1.3100e-02,  1.4073e-03,  6.0063e-03,\n",
       "                      -1.8018e-02,  1.3580e-02,  3.9374e-03,  5.4135e-03,  8.2910e-03,\n",
       "                       1.5792e-02,  1.1208e-02,  1.1902e-02,  1.8086e-03, -8.0435e-03,\n",
       "                       9.0699e-03,  6.0981e-03, -3.1861e-03,  4.7604e-03,  2.9878e-03,\n",
       "                       7.9735e-03,  9.9461e-03,  6.9924e-03,  1.1382e-02,  1.4283e-02,\n",
       "                       3.0344e-03, -6.7065e-04,  4.5958e-03,  4.1192e-03, -1.5040e-03,\n",
       "                       5.6651e-03,  8.7652e-03, -1.8505e-03,  6.6854e-03,  1.1015e-02,\n",
       "                      -5.3422e-03, -9.5780e-03,  5.3796e-03,  5.8183e-03,  1.1702e-02,\n",
       "                       1.1239e-02, -2.5882e-03,  1.0441e-02,  1.5723e-02, -1.3589e-02,\n",
       "                       1.2948e-02, -1.0222e-04,  1.8138e-02,  2.3002e-03,  2.1699e-03,\n",
       "                      -7.3694e-04,  9.1046e-03, -1.9512e-03, -7.9285e-03,  9.8535e-03,\n",
       "                       7.0501e-03,  1.0547e-02,  8.7334e-03,  8.2931e-03,  3.7524e-03,\n",
       "                       6.6465e-03,  6.2764e-03,  6.8081e-03,  9.5316e-03,  5.7852e-03,\n",
       "                       9.4402e-03,  1.0103e-02,  4.6320e-04,  5.7802e-03,  1.2478e-02,\n",
       "                      -5.4578e-04,  2.2199e-02,  1.4904e-02,  1.6152e-02,  1.7721e-02,\n",
       "                       4.9351e-03,  8.8235e-03, -1.0745e-02,  3.7662e-03,  7.8666e-03,\n",
       "                       8.1069e-03,  9.6116e-03, -3.1557e-03,  9.1075e-03,  6.4481e-03,\n",
       "                       7.6962e-03,  1.7362e-03,  1.5496e-02,  2.2152e-03,  1.3356e-03,\n",
       "                       1.5570e-02,  8.1333e-03,  5.5015e-03,  1.3156e-02,  8.4536e-03,\n",
       "                       4.8096e-03, -4.3397e-03, -3.1354e-03,  2.4866e-02,  1.8989e-02,\n",
       "                       4.7648e-03, -2.2109e-04,  8.2660e-03,  6.3731e-03, -7.4253e-04,\n",
       "                       8.6815e-03, -2.2512e-03,  1.4911e-02,  4.3540e-03,  1.4208e-02,\n",
       "                       1.3251e-04,  2.7282e-03, -6.1565e-03,  1.2093e-02,  1.4628e-03,\n",
       "                       1.0310e-02,  6.6734e-03,  4.5486e-04, -1.6654e-02, -9.6438e-03,\n",
       "                       1.8525e-02,  2.3138e-02,  1.1708e-02,  1.7715e-02,  4.1041e-03,\n",
       "                       2.3974e-03], dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.2.1.running_mean',\n",
       "              tensor([ 3.7024e-01,  2.0199e-01, -5.8932e-01, -2.9456e-01, -1.5762e-02,\n",
       "                      -5.4308e-01,  2.4270e-01,  6.8195e-01,  1.6808e-01,  1.8157e-01,\n",
       "                      -3.1067e-02, -9.1627e-02,  3.3589e-01,  4.3754e-01,  4.4139e-01,\n",
       "                      -4.1747e-01, -6.2627e-01, -3.7111e-01, -3.3084e-03,  4.4530e-01,\n",
       "                       1.8779e-01,  3.8325e-01,  5.7041e-01, -2.0387e-01, -4.7382e-01,\n",
       "                      -4.3674e-03,  6.2565e-01,  4.0120e-01,  4.0990e-01, -1.0849e-01,\n",
       "                      -1.3312e-01,  3.0331e-01,  2.9492e-01,  9.3740e-01, -1.1587e-01,\n",
       "                      -3.0130e-01,  3.9192e-01,  3.5150e-01,  2.3179e-01,  4.3525e-02,\n",
       "                      -2.9420e-02, -1.8285e-01, -3.0051e-01, -3.1498e-01,  5.9791e-01,\n",
       "                       1.9901e-01,  4.5652e-01, -2.9374e-01,  2.0447e-01,  3.7247e-01,\n",
       "                       3.6691e-01, -5.0435e-03, -6.8386e-02, -6.0224e-01, -6.4418e-02,\n",
       "                       6.7236e-01, -4.6991e-01,  5.7562e-02, -4.7838e-01, -2.9798e-02,\n",
       "                       5.0790e-01, -1.7083e-01,  1.2350e-01, -2.8500e-01,  3.9261e-01,\n",
       "                       1.4347e-01, -6.2737e-04, -3.0265e-02,  2.3465e-01,  5.5923e-01,\n",
       "                      -5.0849e-01,  2.7459e-02,  1.4260e-01,  1.4072e-01,  4.1721e-01,\n",
       "                       5.4835e-02,  6.4167e-01,  3.9489e-01, -5.6341e-01, -4.1856e-01,\n",
       "                       5.1450e-01, -1.0079e-01,  7.9869e-02, -3.7211e-01,  1.3429e-01,\n",
       "                      -6.5351e-01, -2.6659e-01, -5.0698e-01,  2.3678e-01, -2.6831e-01,\n",
       "                      -3.9020e-01, -2.2874e-02,  8.1380e-02,  1.4259e-01,  8.5290e-01,\n",
       "                       5.9297e-01, -5.8248e-01,  6.3449e-01, -8.1682e-01, -7.3134e-02,\n",
       "                      -5.8580e-01,  2.9379e-01,  1.1317e-01,  1.6616e-01, -3.8099e-01,\n",
       "                       3.2084e-01,  1.3036e-01,  4.1928e-01,  5.3826e-01,  7.2245e-01,\n",
       "                       3.9075e-02,  8.0109e-01,  1.2795e-02,  3.6939e-01,  2.6068e-01,\n",
       "                      -5.8114e-01,  3.8999e-01, -1.6727e-01,  2.0008e-01, -2.2343e-01,\n",
       "                       1.2692e-01, -4.4147e-01,  2.9411e-01, -7.3177e-01,  4.8792e-01,\n",
       "                       9.3940e-01,  1.3152e-01, -9.1903e-02,  7.7173e-02, -6.1913e-01,\n",
       "                       2.6078e-01,  5.7101e-01,  1.2481e-01, -1.6686e-02, -4.2232e-02,\n",
       "                       1.3614e-01, -4.2237e-01,  8.9904e-02,  3.6924e-01,  1.7907e-01,\n",
       "                      -2.4065e-01,  3.2218e-01, -3.4991e-01,  2.2324e-01,  2.2254e-01,\n",
       "                       5.1009e-01, -2.6143e-01, -8.9272e-01, -2.4157e-02, -4.4340e-01,\n",
       "                      -1.0770e-01,  1.8312e-01, -3.8298e-01, -8.0961e-02, -7.4842e-02,\n",
       "                      -1.9189e-01, -5.0744e-01, -1.4356e-01, -1.1591e-01, -4.2615e-01,\n",
       "                      -2.3919e-01, -2.5695e-01, -1.2306e-01, -2.6789e-01, -6.3123e-01,\n",
       "                       1.3136e-04, -9.0787e-01, -3.6040e-01,  3.2891e-01, -2.7260e-01,\n",
       "                      -7.6605e-02, -4.5037e-01, -2.3511e-01, -4.7999e-01, -1.3458e-02,\n",
       "                       3.7782e-01,  6.3541e-02,  2.3703e-02,  4.6335e-01,  7.8672e-02,\n",
       "                      -4.3246e-01,  7.9925e-01, -5.4128e-01,  5.2813e-01, -3.3250e-01,\n",
       "                       4.3922e-01, -1.1671e-01,  1.8851e-01,  2.4798e-01,  5.2746e-01,\n",
       "                       1.6409e-02,  7.2987e-01, -3.0908e-01,  4.6262e-02,  9.6338e-01,\n",
       "                       8.1525e-01,  1.5216e-01, -2.1230e-01,  2.7901e-01,  1.9349e-01,\n",
       "                      -2.9105e-01,  5.3078e-01,  1.5774e-01, -2.0463e-01,  2.1300e-01,\n",
       "                       5.6954e-01,  4.3563e-01,  1.1149e-01,  2.7809e-01, -1.7339e-01,\n",
       "                      -2.7596e-01, -1.0872e+00, -9.6208e-02, -1.6955e-01, -5.7735e-01,\n",
       "                       3.3802e-01,  3.4071e-01,  1.5794e-02, -6.2159e-02,  5.0687e-01,\n",
       "                       3.1973e-01,  2.7486e-02,  9.7964e-02, -1.7091e-02, -9.1394e-01,\n",
       "                      -5.5152e-02, -1.1772e-01,  1.1513e-01, -2.2522e-01, -2.2518e-01,\n",
       "                       8.7394e-02, -3.6991e-01, -7.9692e-01, -2.0979e-01, -5.6866e-02,\n",
       "                      -1.2670e-01, -1.0352e-01, -3.9386e-01, -1.9357e-01,  4.3411e-01,\n",
       "                      -4.9134e-01, -7.3731e-02,  3.5982e-01, -1.7892e-01,  2.2660e-01,\n",
       "                       5.9985e-01, -8.4993e-02, -1.5441e-01,  2.1440e-01,  4.4953e-01,\n",
       "                       1.5204e-01, -8.1264e-01, -7.8709e-02, -6.6976e-01,  2.3725e-01,\n",
       "                      -4.3351e-01], dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.2.1.running_var',\n",
       "              tensor([0.4834, 0.2445, 0.4250, 0.4389, 0.2160, 0.4665, 0.4324, 0.6194, 0.3131,\n",
       "                      0.5174, 0.3143, 0.2008, 0.2788, 0.5726, 0.2613, 0.5530, 0.3823, 0.3396,\n",
       "                      0.3076, 0.5625, 0.1679, 0.5683, 0.3463, 0.3091, 0.4258, 0.2476, 0.3051,\n",
       "                      0.4082, 0.4261, 0.1978, 0.7196, 0.2739, 0.2767, 0.4441, 0.3076, 0.3342,\n",
       "                      0.0811, 0.2860, 0.2839, 0.4172, 0.3195, 0.1690, 0.1475, 0.4127, 0.3228,\n",
       "                      0.5583, 0.2369, 0.1649, 0.3827, 0.2620, 0.5234, 0.4196, 0.3438, 0.2099,\n",
       "                      0.4946, 0.4881, 0.5881, 0.3282, 0.6560, 0.1514, 0.1317, 0.1007, 0.1751,\n",
       "                      0.1825, 0.2969, 0.3156, 0.3539, 0.3036, 0.2313, 0.6777, 0.3586, 0.3528,\n",
       "                      0.1945, 0.4021, 0.4117, 0.3253, 0.4511, 0.3565, 0.4871, 0.3781, 0.3168,\n",
       "                      0.4729, 0.2951, 0.4289, 0.5328, 0.6612, 0.3624, 0.4502, 0.2456, 0.2601,\n",
       "                      0.5935, 0.1553, 0.4542, 0.2070, 0.3745, 0.4115, 0.3708, 0.1990, 0.4252,\n",
       "                      0.3363, 0.5051, 0.3461, 0.4251, 0.1150, 0.4776, 0.0926, 0.4658, 0.6165,\n",
       "                      0.3205, 0.3335, 0.1285, 0.5038, 0.4889, 0.5185, 0.3024, 0.4351, 0.5167,\n",
       "                      0.4952, 0.3016, 0.3540, 0.1233, 0.3830, 0.3595, 0.4158, 0.3526, 0.3903,\n",
       "                      0.3123, 0.2241, 0.0856, 0.4551, 0.3894, 0.3268, 0.3814, 0.0969, 0.3195,\n",
       "                      0.3051, 0.2632, 0.3055, 0.3501, 0.3030, 0.2753, 0.2809, 0.2193, 0.0746,\n",
       "                      0.1382, 0.8117, 0.0877, 0.5908, 0.0776, 0.2687, 0.6965, 0.2212, 0.4589,\n",
       "                      0.4283, 0.1816, 0.3318, 0.4388, 0.0761, 0.2122, 0.2887, 0.3384, 0.3440,\n",
       "                      0.2722, 0.2363, 0.5354, 0.4137, 0.3240, 0.1577, 0.4402, 0.4709, 0.0716,\n",
       "                      0.2064, 0.2588, 0.1717, 0.3567, 0.4416, 0.1605, 0.3168, 0.2784, 0.1911,\n",
       "                      0.4119, 0.1748, 0.4294, 0.3043, 0.2657, 0.5145, 0.4997, 0.1051, 0.5464,\n",
       "                      0.3533, 0.4112, 0.3274, 0.3064, 0.5507, 0.3906, 0.3060, 0.5791, 0.3679,\n",
       "                      0.2572, 0.3905, 0.1842, 0.2337, 0.5736, 0.6057, 0.2915, 0.3813, 0.3652,\n",
       "                      0.0254, 0.2391, 0.3461, 0.0871, 0.3246, 0.2150, 0.5893, 0.3394, 0.4176,\n",
       "                      0.4271, 0.3352, 0.0980, 0.5630, 0.2918, 0.2940, 0.2407, 0.2996, 0.6469,\n",
       "                      0.3469, 0.4700, 0.3163, 0.5411, 0.4300, 0.2391, 0.4199, 0.6520, 0.2476,\n",
       "                      0.1674, 0.3415, 0.1240, 0.0780, 0.4357, 0.1243, 0.2961, 0.2322, 0.7925,\n",
       "                      0.1487, 0.2004, 0.3188, 0.5123, 0.4813, 0.2167, 0.4056, 0.5035, 0.5278,\n",
       "                      0.3785, 0.3716, 0.3405, 0.3593], dtype=torch.float64)),\n",
       "             ('6.17.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.18.convs.0.0.weight',\n",
       "              tensor([[[ 0.0326],\n",
       "                       [ 0.0622],\n",
       "                       [ 0.0897],\n",
       "                       ...,\n",
       "                       [-0.0259],\n",
       "                       [-0.0473],\n",
       "                       [ 0.0863]],\n",
       "              \n",
       "                      [[-0.0303],\n",
       "                       [ 0.0579],\n",
       "                       [ 0.1164],\n",
       "                       ...,\n",
       "                       [-0.0343],\n",
       "                       [ 0.1348],\n",
       "                       [-0.0078]],\n",
       "              \n",
       "                      [[ 0.0598],\n",
       "                       [-0.0100],\n",
       "                       [-0.0197],\n",
       "                       ...,\n",
       "                       [-0.0651],\n",
       "                       [-0.1132],\n",
       "                       [ 0.1284]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0994],\n",
       "                       [ 0.0243],\n",
       "                       [ 0.1443],\n",
       "                       ...,\n",
       "                       [ 0.0282],\n",
       "                       [-0.0606],\n",
       "                       [-0.1937]],\n",
       "              \n",
       "                      [[-0.1157],\n",
       "                       [-0.0695],\n",
       "                       [-0.1269],\n",
       "                       ...,\n",
       "                       [-0.0351],\n",
       "                       [-0.0380],\n",
       "                       [-0.1206]],\n",
       "              \n",
       "                      [[ 0.0463],\n",
       "                       [-0.1051],\n",
       "                       [-0.0652],\n",
       "                       ...,\n",
       "                       [ 0.0918],\n",
       "                       [ 0.0303],\n",
       "                       [-0.0258]]], dtype=torch.float64)),\n",
       "             ('6.18.convs.0.1.weight',\n",
       "              tensor([0.9693, 0.9608, 0.9642, 0.9795, 0.9707, 0.9424, 0.9496, 0.9757, 0.9618,\n",
       "                      0.9657, 0.9909, 0.9712, 0.9703, 1.0110, 0.9739, 0.9758, 1.0145, 1.0055,\n",
       "                      0.9801, 0.9795, 0.9615, 0.9495, 0.9829, 0.9818, 0.9797, 0.9531, 0.9648,\n",
       "                      0.9743, 0.9750, 0.9641, 0.9683, 0.9765, 0.9545, 0.9727, 0.9750, 0.9799,\n",
       "                      0.9506, 0.9660, 1.0045, 0.9571, 0.9782, 0.9508, 0.9647, 0.9892, 0.9497,\n",
       "                      0.9494, 0.9932, 0.9814, 0.9639, 0.9801, 0.9612, 0.9717, 0.9696, 0.9683,\n",
       "                      0.9565, 0.9687, 0.9876, 0.9492, 0.9585, 0.9565, 0.9756, 0.9652, 0.9740,\n",
       "                      0.9550], dtype=torch.float64)),\n",
       "             ('6.18.convs.0.1.bias',\n",
       "              tensor([ 1.4644e-03, -9.3553e-03, -7.7696e-03,  1.2056e-02, -1.9368e-02,\n",
       "                       7.0443e-03, -1.3395e-02, -1.1643e-02, -9.5395e-03, -1.2194e-02,\n",
       "                       1.9161e-02,  5.6341e-04, -1.1159e-02,  2.4839e-02, -8.1317e-03,\n",
       "                      -1.6184e-03,  1.6074e-02, -8.2810e-03, -8.4647e-03,  7.7671e-03,\n",
       "                       2.2326e-04, -2.0229e-05,  9.8568e-03,  1.6711e-02,  2.7004e-02,\n",
       "                       1.4573e-02, -8.6591e-03, -2.2268e-02, -7.2342e-03, -8.6033e-03,\n",
       "                      -2.5289e-03, -6.3978e-03, -5.2394e-03,  2.8941e-03,  1.4332e-02,\n",
       "                       1.8374e-02,  1.1981e-03, -4.3097e-04,  3.2194e-02, -1.2187e-02,\n",
       "                       2.1108e-02, -8.5860e-03,  4.1466e-03,  1.5354e-02, -6.8866e-03,\n",
       "                       1.4691e-02,  1.4348e-02,  2.2744e-04, -1.6536e-02,  9.2811e-03,\n",
       "                      -4.6270e-03,  4.7947e-03,  6.3936e-03, -1.7480e-02, -1.0078e-02,\n",
       "                       1.9818e-02,  1.7869e-02,  3.7228e-03, -9.5491e-03, -9.0658e-03,\n",
       "                       1.5320e-02, -2.9019e-03,  1.6277e-03, -6.0902e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convs.0.1.running_mean',\n",
       "              tensor([ 0.7911,  1.0856, -0.1271,  0.4413,  1.3026, -0.8317, -0.7399, -1.2779,\n",
       "                       0.0735,  1.1619,  0.6248, -0.2560, -0.3489,  0.1403,  0.2621, -0.7375,\n",
       "                       0.0212, -0.5844,  0.2094,  0.1336, -0.1608, -1.3917,  0.0524,  0.1382,\n",
       "                      -0.8523,  0.3752, -0.5548,  0.7559,  1.2574, -0.0529,  0.7082, -0.5641,\n",
       "                      -1.4012, -0.4222, -1.2143,  0.2030, -0.1999, -1.3190, -0.2920,  0.1989,\n",
       "                      -0.1171,  0.1261,  0.4280, -1.1588,  0.6451, -0.6450, -0.5804,  0.1390,\n",
       "                      -0.3991, -0.2114, -0.0702, -0.0440,  0.2758, -0.0428, -0.8534, -1.0308,\n",
       "                       0.0107,  0.4808,  0.2333,  0.2953,  0.2533,  0.1044,  1.3181,  0.2374],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convs.0.1.running_var',\n",
       "              tensor([0.1505, 0.9159, 0.3126, 0.2280, 0.2127, 0.4216, 0.1253, 0.1659, 0.1205,\n",
       "                      1.0745, 0.1182, 0.2970, 0.1873, 0.1414, 0.2570, 0.2836, 0.0983, 0.1541,\n",
       "                      0.1687, 0.1334, 0.1676, 0.5300, 0.2283, 0.2158, 0.1906, 0.1985, 0.2586,\n",
       "                      0.4634, 0.1213, 0.1751, 0.3176, 0.3535, 0.2251, 0.1867, 0.4454, 0.1679,\n",
       "                      0.1419, 0.1268, 0.1468, 0.1245, 0.1410, 0.2251, 0.1988, 0.1568, 0.2570,\n",
       "                      0.7680, 0.2041, 0.1606, 0.1948, 0.1312, 0.1316, 0.1588, 0.2987, 0.2048,\n",
       "                      0.2823, 0.1957, 0.1769, 0.1863, 0.1024, 0.1098, 0.1037, 0.2023, 0.1028,\n",
       "                      0.1515], dtype=torch.float64)),\n",
       "             ('6.18.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.18.convs.1.0.weight',\n",
       "              tensor([[[-0.0699, -0.0065,  0.0287,  0.0297,  0.0957],\n",
       "                       [ 0.0765, -0.1905,  0.1309,  0.1234, -0.0747],\n",
       "                       [-0.0673, -0.0923, -0.1309, -0.0678, -0.0278],\n",
       "                       ...,\n",
       "                       [-0.0820,  0.0623, -0.0270,  0.0348,  0.0489],\n",
       "                       [-0.1027,  0.0825,  0.0055,  0.0275,  0.0665],\n",
       "                       [ 0.1255, -0.1047, -0.0907, -0.0772, -0.0879]],\n",
       "              \n",
       "                      [[ 0.0024,  0.0277,  0.0817, -0.0020,  0.0155],\n",
       "                       [-0.0345,  0.0154, -0.0585,  0.0028,  0.1844],\n",
       "                       [ 0.0749, -0.0277,  0.0359,  0.0443, -0.0576],\n",
       "                       ...,\n",
       "                       [ 0.0352,  0.0201, -0.0416, -0.1004,  0.0328],\n",
       "                       [-0.0307, -0.0453, -0.0767, -0.0677, -0.0190],\n",
       "                       [ 0.0831,  0.0273,  0.0701,  0.0060, -0.1484]],\n",
       "              \n",
       "                      [[ 0.1036,  0.0110, -0.0590, -0.0081, -0.0507],\n",
       "                       [ 0.0192,  0.1049, -0.0535, -0.0701,  0.1101],\n",
       "                       [ 0.0387,  0.0267,  0.1388, -0.0512, -0.0071],\n",
       "                       ...,\n",
       "                       [-0.0349, -0.1413, -0.0051,  0.0827,  0.0311],\n",
       "                       [-0.1081,  0.0131, -0.0557,  0.0370, -0.1276],\n",
       "                       [-0.1572,  0.0660,  0.0661,  0.0362, -0.0224]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0082,  0.0575, -0.0559,  0.0069, -0.0443],\n",
       "                       [ 0.0223,  0.1566, -0.0250, -0.0507, -0.0568],\n",
       "                       [ 0.0224, -0.0563, -0.0884,  0.1039,  0.0485],\n",
       "                       ...,\n",
       "                       [ 0.0514, -0.0394,  0.0670,  0.0471, -0.0902],\n",
       "                       [-0.1240, -0.0415,  0.1104, -0.0603, -0.0023],\n",
       "                       [-0.1577, -0.0558, -0.1134, -0.0116, -0.0240]],\n",
       "              \n",
       "                      [[ 0.0725,  0.0531, -0.0406, -0.0116,  0.0553],\n",
       "                       [ 0.0502, -0.0395,  0.0592,  0.0314,  0.1352],\n",
       "                       [-0.0075, -0.0009,  0.1412,  0.2115,  0.0184],\n",
       "                       ...,\n",
       "                       [ 0.0462,  0.0162, -0.1095, -0.0886,  0.1991],\n",
       "                       [-0.0826, -0.0101, -0.0229,  0.0448,  0.1285],\n",
       "                       [ 0.0721,  0.0141,  0.0232,  0.0370,  0.0098]],\n",
       "              \n",
       "                      [[-0.1181, -0.0504, -0.0034,  0.0041,  0.0623],\n",
       "                       [-0.1397, -0.0815,  0.0469, -0.0488, -0.1109],\n",
       "                       [ 0.0548,  0.0719, -0.1314, -0.1144, -0.0111],\n",
       "                       ...,\n",
       "                       [ 0.0296, -0.0649,  0.0560,  0.1466, -0.0326],\n",
       "                       [-0.0958,  0.0471,  0.0475,  0.0230, -0.0047],\n",
       "                       [ 0.0281, -0.0935,  0.0127, -0.0664,  0.0094]]], dtype=torch.float64)),\n",
       "             ('6.18.convs.1.1.weight',\n",
       "              tensor([0.9610, 0.9796, 0.9399, 0.9772, 0.9852, 0.9276, 0.9653, 0.9428, 0.9817,\n",
       "                      0.9708, 0.9792, 0.9787, 0.9495, 0.9730, 0.9661, 0.9821, 0.9755, 0.9922,\n",
       "                      0.9722, 0.9525, 0.9702, 0.9589, 0.9802, 0.9466, 0.9428, 0.9781, 0.9721,\n",
       "                      0.9552, 0.9784, 0.9666, 0.9656, 0.9536, 0.9580, 0.9861, 0.9820, 0.9272,\n",
       "                      0.9512, 0.9577, 0.9557, 0.9499, 0.9775, 0.9682, 0.9534, 0.9523, 0.9661,\n",
       "                      0.9558, 0.9686, 0.9579, 0.9607, 0.9707, 0.9890, 0.9573, 0.9552, 0.9642,\n",
       "                      0.9554, 0.9669, 0.9755, 0.9673, 0.9896, 0.9975, 0.9615, 0.9542, 0.9897,\n",
       "                      0.9682], dtype=torch.float64)),\n",
       "             ('6.18.convs.1.1.bias',\n",
       "              tensor([-0.0083,  0.0096, -0.0079, -0.0098,  0.0079, -0.0072, -0.0049, -0.0050,\n",
       "                       0.0128,  0.0003, -0.0059,  0.0048,  0.0007, -0.0159, -0.0177,  0.0013,\n",
       "                      -0.0036, -0.0074,  0.0013, -0.0037, -0.0008, -0.0225, -0.0277, -0.0147,\n",
       "                      -0.0052,  0.0068, -0.0047, -0.0051,  0.0010,  0.0037, -0.0112, -0.0296,\n",
       "                      -0.0108, -0.0085, -0.0104, -0.0267, -0.0272, -0.0071, -0.0062, -0.0133,\n",
       "                       0.0093, -0.0065,  0.0006, -0.0245, -0.0201,  0.0038,  0.0084, -0.0220,\n",
       "                       0.0094,  0.0113,  0.0176, -0.0176, -0.0246,  0.0101, -0.0076, -0.0283,\n",
       "                      -0.0062, -0.0346,  0.0031,  0.0148,  0.0105, -0.0175, -0.0025, -0.0077],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convs.1.1.running_mean',\n",
       "              tensor([-0.2456,  0.3734, -0.3205, -0.4581, -0.0111, -0.2860,  0.5471,  0.0383,\n",
       "                       0.2086,  0.3688,  0.0716, -1.3562, -0.2441, -0.5892, -0.0978, -0.3246,\n",
       "                      -0.0569,  0.6194, -0.3676,  0.0369, -0.5219, -0.1303, -0.4742, -0.6607,\n",
       "                      -0.5371, -0.4513, -0.6930, -0.6633,  0.6716, -0.4953, -0.2153, -0.4817,\n",
       "                      -0.8008, -0.4875,  0.2456, -0.1912,  0.2986,  0.3066,  0.2862, -0.1004,\n",
       "                      -0.4656, -0.0087, -0.6817, -0.5223,  0.5085, -0.4211, -1.0567,  0.3645,\n",
       "                      -0.7002,  0.0866,  0.1141,  0.3119,  0.9414,  1.3299, -0.1979, -0.3982,\n",
       "                       0.5804,  0.2144, -0.5156,  0.3599, -0.9109, -0.1137, -0.2019, -0.5339],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convs.1.1.running_var',\n",
       "              tensor([0.5257, 0.6336, 0.4815, 0.7168, 0.8632, 0.7030, 0.3303, 0.4625, 0.4001,\n",
       "                      0.4910, 0.4410, 0.8068, 0.7808, 0.4280, 0.5905, 0.6657, 0.6357, 0.4209,\n",
       "                      0.5663, 0.4526, 0.4523, 0.4809, 0.3738, 0.4723, 0.6604, 0.4958, 0.6646,\n",
       "                      0.5248, 0.6344, 0.5742, 0.4544, 0.5549, 0.6469, 0.4479, 0.4748, 0.5404,\n",
       "                      0.6669, 0.6506, 0.3404, 0.4634, 0.6312, 0.6308, 0.7208, 0.6500, 0.4138,\n",
       "                      0.6190, 0.5990, 0.6618, 0.5618, 0.5002, 0.5534, 0.4077, 0.4548, 0.7171,\n",
       "                      0.6190, 0.5977, 0.7583, 0.8713, 0.5393, 0.5285, 0.5386, 0.5539, 0.5991,\n",
       "                      0.5065], dtype=torch.float64)),\n",
       "             ('6.18.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.18.convs.2.0.weight',\n",
       "              tensor([[[-0.0606],\n",
       "                       [-0.0881],\n",
       "                       [ 0.1923],\n",
       "                       ...,\n",
       "                       [ 0.0470],\n",
       "                       [ 0.0801],\n",
       "                       [ 0.0749]],\n",
       "              \n",
       "                      [[ 0.0503],\n",
       "                       [-0.0712],\n",
       "                       [ 0.0044],\n",
       "                       ...,\n",
       "                       [ 0.0589],\n",
       "                       [-0.0123],\n",
       "                       [-0.0054]],\n",
       "              \n",
       "                      [[-0.1691],\n",
       "                       [-0.0244],\n",
       "                       [-0.0830],\n",
       "                       ...,\n",
       "                       [-0.1529],\n",
       "                       [ 0.0536],\n",
       "                       [-0.1610]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.2000],\n",
       "                       [-0.0557],\n",
       "                       [-0.1459],\n",
       "                       ...,\n",
       "                       [ 0.0996],\n",
       "                       [ 0.1150],\n",
       "                       [ 0.0637]],\n",
       "              \n",
       "                      [[-0.1319],\n",
       "                       [ 0.0597],\n",
       "                       [-0.0909],\n",
       "                       ...,\n",
       "                       [ 0.0110],\n",
       "                       [-0.2066],\n",
       "                       [-0.1393]],\n",
       "              \n",
       "                      [[ 0.0124],\n",
       "                       [-0.0879],\n",
       "                       [-0.0872],\n",
       "                       ...,\n",
       "                       [ 0.1538],\n",
       "                       [ 0.1130],\n",
       "                       [-0.0020]]], dtype=torch.float64)),\n",
       "             ('6.18.convs.2.1.weight',\n",
       "              tensor([ 1.9600e-02,  1.2067e-02,  1.7449e-02,  3.0706e-03,  5.4469e-03,\n",
       "                      -8.3460e-03, -5.6302e-03, -1.6789e-02,  8.8008e-03, -7.9497e-03,\n",
       "                      -1.0700e-02,  5.5923e-03,  5.7849e-03,  8.3630e-03,  5.8248e-03,\n",
       "                       1.3987e-02, -5.2145e-02, -1.1648e-02,  6.8550e-03,  9.1247e-03,\n",
       "                      -1.2569e-02,  9.2128e-04,  2.4236e-02,  1.2678e-02,  1.3325e-02,\n",
       "                       1.8923e-02, -2.2389e-02,  6.4395e-03, -1.1526e-02,  2.3172e-02,\n",
       "                      -9.6461e-03,  3.0464e-02,  1.7222e-02, -1.8433e-02, -6.9785e-02,\n",
       "                       1.6874e-02,  1.7926e-02,  4.8753e-03,  1.7527e-03, -1.1408e-03,\n",
       "                      -1.1214e-02,  2.8707e-02, -5.8988e-03,  7.0184e-03,  6.1359e-03,\n",
       "                       2.9272e-02, -2.9838e-02, -5.2065e-03, -3.5785e-02, -2.0929e-02,\n",
       "                      -3.0276e-02, -1.2769e-02, -2.1736e-02, -1.5033e-03,  1.2660e-02,\n",
       "                       1.0708e-02, -1.4412e-02,  8.9157e-04, -5.7865e-03,  5.8098e-03,\n",
       "                       3.6804e-03,  1.4412e-02,  1.5876e-03, -4.7275e-02, -2.5694e-02,\n",
       "                      -1.0761e-02, -5.0806e-03, -3.4255e-02,  9.4502e-03, -2.0274e-02,\n",
       "                       8.4346e-03,  7.2065e-03, -7.8735e-03, -1.9829e-02,  9.2813e-03,\n",
       "                       1.0792e-02, -2.7873e-02, -2.4430e-02, -1.9158e-02, -1.2250e-02,\n",
       "                       1.4809e-02,  2.2369e-02,  5.0336e-03, -8.5300e-03, -3.0914e-02,\n",
       "                      -1.9050e-03,  1.6162e-02,  1.3694e-02, -7.0497e-03, -2.9154e-02,\n",
       "                       3.1416e-02,  1.2979e-02, -1.2714e-02,  8.5382e-03,  1.8068e-03,\n",
       "                      -1.9883e-02, -1.8492e-02,  5.3051e-03,  2.5011e-02,  1.6844e-02,\n",
       "                       2.9109e-04,  1.8003e-02, -7.7917e-03,  4.0893e-02,  1.1443e-02,\n",
       "                       2.2266e-02, -3.1417e-03,  1.2431e-02, -7.0870e-04,  6.6558e-03,\n",
       "                       9.8892e-03,  1.3473e-02, -9.8680e-03,  9.2901e-03,  2.2994e-02,\n",
       "                      -2.0649e-02, -6.9128e-03,  3.0918e-02,  5.5584e-03,  3.1578e-02,\n",
       "                      -1.2305e-02, -1.8649e-02,  1.4175e-02,  4.2901e-03,  9.4881e-03,\n",
       "                       5.1201e-02, -8.8319e-03,  5.7289e-03,  9.9962e-04,  8.0820e-03,\n",
       "                      -5.2919e-03,  9.1284e-03, -2.6513e-02,  1.9012e-03, -1.2204e-02,\n",
       "                      -1.2970e-02, -6.1749e-03, -1.0992e-02, -1.8732e-02, -2.2937e-02,\n",
       "                       1.3254e-02,  4.8321e-03,  2.4983e-02, -5.8679e-04,  1.7433e-02,\n",
       "                       2.0568e-02, -2.8096e-03, -8.8333e-03, -1.1907e-02,  2.9226e-03,\n",
       "                      -9.4637e-03, -1.2581e-02, -4.3402e-03,  8.8420e-03, -1.9088e-03,\n",
       "                      -1.3332e-02,  8.2638e-03,  3.7064e-03, -1.5463e-02,  9.1711e-04,\n",
       "                      -3.7246e-03,  1.4282e-02,  3.9456e-03,  2.1891e-02, -2.5818e-02,\n",
       "                       5.5600e-03, -5.9263e-03, -1.9170e-02, -1.2410e-02,  2.7370e-02,\n",
       "                      -7.9121e-03, -4.9170e-03, -8.5817e-03, -8.0854e-03,  1.7443e-02,\n",
       "                      -3.9178e-02,  9.8698e-03, -1.2641e-02, -1.6787e-02,  7.4793e-03,\n",
       "                      -2.9841e-02,  2.5893e-02, -2.2694e-02,  1.1599e-02,  8.6739e-03,\n",
       "                       1.8298e-02,  3.7548e-03, -1.4132e-02,  1.1466e-02, -1.3387e-02,\n",
       "                      -7.1240e-03, -4.8281e-02, -1.1828e-03, -2.2117e-02,  3.6535e-02,\n",
       "                      -1.1665e-02,  1.3719e-02,  2.7388e-02,  1.1115e-02,  1.5647e-02,\n",
       "                      -1.2775e-02, -2.8299e-02,  3.1611e-02, -1.0292e-02, -3.7667e-03,\n",
       "                       8.0773e-03,  2.2250e-02, -2.3351e-02,  1.9374e-02, -8.7631e-03,\n",
       "                       2.9280e-03,  8.4645e-03, -1.0909e-02,  1.0227e-02,  9.9291e-03,\n",
       "                      -1.2464e-02,  1.0244e-02,  1.1889e-02, -7.5968e-03,  2.0103e-02,\n",
       "                       7.5045e-05, -1.3698e-02, -4.7202e-04,  2.7508e-03, -2.3327e-02,\n",
       "                       1.1899e-02,  4.9536e-03, -1.3317e-03,  2.8445e-02,  9.0946e-04,\n",
       "                      -1.1273e-02, -7.9019e-03,  1.5172e-02, -1.6721e-02, -4.3719e-03,\n",
       "                       4.0167e-02, -4.9451e-03, -4.9652e-02,  2.6526e-03,  1.9213e-02,\n",
       "                      -1.4157e-02,  1.5956e-02,  1.3411e-02, -4.6567e-03, -2.0045e-03,\n",
       "                      -1.0787e-02,  1.5407e-02, -1.8295e-02, -5.5819e-03, -1.9157e-02,\n",
       "                      -2.0630e-02, -2.4605e-02,  1.3807e-02, -2.6926e-02,  7.4194e-03,\n",
       "                       1.0944e-02], dtype=torch.float64)),\n",
       "             ('6.18.convs.2.1.bias',\n",
       "              tensor([ 0.0042,  0.0061,  0.0042,  0.0152, -0.0022,  0.0079,  0.0044,  0.0012,\n",
       "                       0.0024,  0.0071,  0.0163, -0.0078,  0.0055, -0.0058,  0.0023,  0.0058,\n",
       "                       0.0274,  0.0042,  0.0115, -0.0032, -0.0079,  0.0016,  0.0076,  0.0049,\n",
       "                       0.0177, -0.0193,  0.0057,  0.0111,  0.0110, -0.0054, -0.0049,  0.0132,\n",
       "                       0.0089,  0.0155,  0.0101,  0.0138, -0.0045,  0.0092,  0.0149,  0.0005,\n",
       "                       0.0092,  0.0026, -0.0089, -0.0060,  0.0077, -0.0166,  0.0113,  0.0036,\n",
       "                      -0.0128,  0.0002,  0.0113,  0.0042,  0.0055,  0.0207,  0.0006,  0.0126,\n",
       "                       0.0102,  0.0052,  0.0052, -0.0034,  0.0015,  0.0006,  0.0134,  0.0081,\n",
       "                      -0.0112,  0.0023, -0.0058,  0.0142,  0.0187, -0.0149,  0.0085,  0.0024,\n",
       "                      -0.0007, -0.0079,  0.0131,  0.0038,  0.0039,  0.0182,  0.0011,  0.0097,\n",
       "                       0.0032, -0.0087,  0.0189,  0.0027, -0.0082,  0.0214, -0.0020,  0.0122,\n",
       "                       0.0124,  0.0002,  0.0017,  0.0132,  0.0098, -0.0075,  0.0046, -0.0064,\n",
       "                       0.0148,  0.0043,  0.0197,  0.0066,  0.0245,  0.0170,  0.0013,  0.0146,\n",
       "                       0.0066,  0.0017,  0.0049,  0.0108,  0.0057,  0.0079,  0.0033, -0.0050,\n",
       "                       0.0058,  0.0225,  0.0179,  0.0026,  0.0047,  0.0027,  0.0008, -0.0030,\n",
       "                      -0.0002,  0.0125,  0.0034,  0.0016,  0.0180,  0.0081,  0.0108,  0.0046,\n",
       "                       0.0029,  0.0134,  0.0072,  0.0065,  0.0088,  0.0019,  0.0059, -0.0133,\n",
       "                       0.0102,  0.0049,  0.0081,  0.0076,  0.0157,  0.0134,  0.0093,  0.0018,\n",
       "                      -0.0081,  0.0087,  0.0055,  0.0066,  0.0055,  0.0013,  0.0102,  0.0084,\n",
       "                       0.0044,  0.0108,  0.0140,  0.0030, -0.0019,  0.0045,  0.0042,  0.0008,\n",
       "                       0.0052,  0.0081, -0.0002,  0.0065,  0.0107, -0.0053, -0.0110,  0.0047,\n",
       "                       0.0105,  0.0114,  0.0147, -0.0022,  0.0125,  0.0150, -0.0156,  0.0129,\n",
       "                      -0.0026,  0.0130, -0.0024,  0.0036, -0.0003,  0.0110, -0.0039, -0.0065,\n",
       "                       0.0089,  0.0078,  0.0110,  0.0087,  0.0011,  0.0071,  0.0034,  0.0096,\n",
       "                       0.0050,  0.0076,  0.0124,  0.0099,  0.0092, -0.0012,  0.0056,  0.0104,\n",
       "                      -0.0004,  0.0210,  0.0141,  0.0169,  0.0148,  0.0054,  0.0074, -0.0062,\n",
       "                       0.0040,  0.0070,  0.0066,  0.0100, -0.0041,  0.0133,  0.0066,  0.0058,\n",
       "                       0.0010,  0.0162,  0.0007, -0.0013,  0.0180,  0.0101,  0.0028,  0.0134,\n",
       "                       0.0119,  0.0051, -0.0071, -0.0041,  0.0254,  0.0183,  0.0028, -0.0007,\n",
       "                       0.0064,  0.0058, -0.0020,  0.0064, -0.0035,  0.0153,  0.0021,  0.0149,\n",
       "                      -0.0031,  0.0025, -0.0076,  0.0132,  0.0007,  0.0024,  0.0070,  0.0023,\n",
       "                      -0.0211, -0.0112,  0.0185,  0.0165,  0.0095,  0.0175,  0.0033,  0.0019],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convs.2.1.running_mean',\n",
       "              tensor([ 7.7297e-01, -1.0550e-01,  1.0763e-01, -8.0681e-02, -9.9735e-04,\n",
       "                      -5.5130e-01, -1.6592e-02,  4.4639e-01, -9.7016e-02,  7.2733e-01,\n",
       "                      -2.3602e-01,  2.8331e-01,  2.1040e-02,  1.0536e-01, -4.3713e-01,\n",
       "                      -2.6298e-02, -1.9619e-01,  4.0163e-01, -5.6093e-01, -6.9598e-01,\n",
       "                      -7.6822e-02, -2.1407e-01,  1.9279e-01,  2.5199e-01, -3.2156e-01,\n",
       "                      -2.6858e-01,  7.4786e-02, -1.7502e-01, -4.1488e-01,  5.4379e-01,\n",
       "                       1.3537e+00, -6.4823e-01,  2.1594e-01,  2.3014e-01,  6.8409e-01,\n",
       "                      -8.3925e-01, -6.7568e-02, -3.7324e-01,  1.0105e-01,  2.3012e-01,\n",
       "                       2.2100e-01, -1.4756e-01,  1.4439e-01,  1.9787e-01, -7.0692e-01,\n",
       "                       6.3368e-03, -8.6856e-01, -3.2146e-01,  9.9722e-02,  5.7602e-01,\n",
       "                      -2.4114e-02, -5.5874e-01,  2.5370e-01,  2.3945e-01,  3.3417e-01,\n",
       "                       5.6123e-01,  4.1261e-01,  4.2150e-01, -7.7494e-02,  1.9512e-01,\n",
       "                       5.8126e-01,  1.2466e-01,  2.5612e-01, -1.8675e-01, -1.2655e-01,\n",
       "                      -6.2670e-02,  9.1066e-04, -2.4185e-01,  2.5471e-01, -8.5520e-02,\n",
       "                       9.6745e-01,  5.2680e-01,  3.3554e-01,  6.5724e-01, -1.2188e+00,\n",
       "                      -4.0781e-01,  5.0810e-01, -1.3068e-01, -7.6112e-01, -8.2694e-02,\n",
       "                      -6.8665e-01,  8.7213e-01, -4.6975e-02,  5.0169e-02, -3.0235e-01,\n",
       "                      -2.1147e-01, -3.2663e-01,  7.5809e-01, -4.5827e-01,  5.9889e-01,\n",
       "                      -8.6986e-02, -1.3586e-01,  4.1223e-01, -4.1404e-01, -2.1901e-01,\n",
       "                      -5.6238e-01,  2.8949e-02, -7.9281e-03, -6.4932e-01, -1.4727e-01,\n",
       "                       2.7748e-03, -3.5938e-01, -6.4176e-01, -8.0207e-01,  3.4256e-01,\n",
       "                       2.6874e-01,  8.5718e-02,  2.8744e-01,  2.1488e-01,  2.3778e-01,\n",
       "                       2.4563e-01, -1.2899e-02,  2.1048e-01, -6.7537e-01,  5.3172e-01,\n",
       "                       4.1443e-01,  5.7816e-01, -6.9320e-01,  3.6026e-01, -8.7836e-02,\n",
       "                      -2.5065e-01, -6.7196e-01,  3.5993e-01,  2.1463e-01,  1.3988e-01,\n",
       "                      -5.8351e-01, -8.5797e-02,  5.1361e-01, -1.8977e-02, -5.0259e-01,\n",
       "                      -4.4895e-02, -2.2994e-01, -1.1669e-01, -2.6686e-01, -3.1314e-01,\n",
       "                       3.3971e-02, -7.3420e-03,  1.2434e-01, -1.6070e-01, -2.2562e-01,\n",
       "                      -5.2357e-01,  6.4218e-02,  7.5142e-01,  2.4942e-01,  3.3641e-01,\n",
       "                       3.8522e-01,  9.3835e-02, -5.6183e-01,  2.3336e-02,  2.6558e-01,\n",
       "                      -2.6176e-01,  4.8150e-01, -2.3535e-01, -1.3355e-01,  4.3214e-01,\n",
       "                       2.5568e-01,  3.6074e-01, -4.4321e-02,  4.5100e-01, -8.1580e-03,\n",
       "                       4.0667e-01,  2.5507e-01, -1.8878e-01, -4.5634e-01, -1.9376e-03,\n",
       "                       9.7773e-02,  2.1771e-01,  2.2567e-01, -1.2761e-01, -2.6499e-01,\n",
       "                       8.0108e-02, -1.2826e-01, -9.4114e-02,  1.5773e-01, -3.6830e-01,\n",
       "                      -5.2824e-01, -2.8120e-01, -3.6948e-01,  3.3065e-01, -7.7955e-01,\n",
       "                      -1.0149e-01,  2.3654e-01,  4.3488e-01,  2.7248e-01,  2.8639e-01,\n",
       "                      -1.1094e-01, -1.0786e-01, -2.1823e-03,  9.2183e-01,  3.8103e-01,\n",
       "                      -2.2365e-01,  2.5584e-01, -4.3678e-01, -1.0737e-01,  6.7606e-01,\n",
       "                       5.4486e-03, -1.6769e-01, -3.6260e-01,  1.3729e-01, -1.3350e-01,\n",
       "                      -3.2611e-01, -5.8568e-01,  4.0421e-01,  4.4531e-01, -9.5040e-02,\n",
       "                       4.4474e-01,  3.6696e-01,  1.9211e-01,  3.7226e-01,  1.6134e-01,\n",
       "                       1.6496e-01,  6.3573e-02,  2.5671e-01,  2.2514e-01,  6.9041e-02,\n",
       "                      -1.1368e-01,  2.3480e-01, -1.1725e-01,  2.5873e-02, -2.5599e-01,\n",
       "                      -3.7109e-01,  4.5825e-01, -1.2619e-01,  9.3730e-01,  2.0248e-01,\n",
       "                      -7.6791e-02,  3.0305e-01,  5.9686e-02,  5.7985e-01, -3.8884e-01,\n",
       "                      -6.5739e-02, -7.1770e-01, -3.0932e-01, -4.2560e-01,  1.6907e-01,\n",
       "                      -7.4240e-02,  1.8930e-01,  6.1338e-01, -1.4488e-01,  3.2112e-01,\n",
       "                      -4.2869e-01,  9.2409e-02,  4.0495e-01, -1.3100e-02,  1.2595e-01,\n",
       "                       1.3171e-01,  5.4219e-01,  6.6487e-02, -3.5884e-01, -2.3615e-01,\n",
       "                       2.6037e-01, -1.7370e-01, -3.6932e-01,  3.9731e-01, -4.1626e-01,\n",
       "                       4.2828e-01], dtype=torch.float64)),\n",
       "             ('6.18.convs.2.1.running_var',\n",
       "              tensor([0.5027, 0.2789, 0.2474, 0.3024, 0.4673, 0.1978, 0.1944, 0.3229, 0.1606,\n",
       "                      0.4020, 0.2890, 0.2050, 0.0731, 0.1802, 0.5074, 0.3439, 0.4591, 0.3183,\n",
       "                      0.1334, 0.6073, 0.1882, 0.2437, 0.4098, 0.2736, 0.3000, 0.3634, 0.3360,\n",
       "                      0.1636, 0.2182, 0.2939, 0.6119, 0.5169, 0.2103, 0.3892, 0.5651, 0.5459,\n",
       "                      0.1788, 0.2224, 0.1095, 0.3436, 0.6027, 0.2180, 0.1874, 0.4948, 0.2203,\n",
       "                      0.4113, 0.4821, 0.1087, 0.4726, 0.3603, 0.3598, 0.4120, 0.5232, 0.0719,\n",
       "                      0.6229, 0.3412, 0.4377, 0.2467, 0.3156, 0.1675, 0.1592, 0.2451, 0.1242,\n",
       "                      0.4417, 0.4087, 0.3856, 0.2379, 0.5252, 0.2825, 0.5343, 0.5386, 0.2684,\n",
       "                      0.1666, 0.5099, 0.4004, 0.2264, 0.4568, 0.3038, 0.5604, 0.1957, 0.4106,\n",
       "                      0.6138, 0.3222, 0.3476, 0.5642, 0.2987, 0.3263, 0.4100, 0.2053, 0.1932,\n",
       "                      0.6016, 0.5876, 0.2311, 0.1737, 0.2841, 0.3007, 0.5892, 0.1242, 0.3034,\n",
       "                      0.4184, 0.5513, 0.5158, 0.2246, 0.6594, 0.4737, 0.3662, 0.2929, 0.3533,\n",
       "                      0.2992, 0.1654, 0.1407, 0.2628, 0.3091, 0.3792, 0.4222, 0.5051, 0.3909,\n",
       "                      0.5063, 0.2592, 0.5521, 0.4681, 0.4270, 0.3317, 0.1596, 0.2421, 0.3292,\n",
       "                      0.1958, 0.2536, 0.2545, 0.2768, 0.3246, 0.2735, 0.3756, 0.0863, 0.2476,\n",
       "                      0.1280, 0.0569, 0.3442, 0.3355, 0.4602, 0.4584, 0.0830, 0.3024, 0.1507,\n",
       "                      0.3132, 0.4159, 0.0791, 0.4559, 0.0806, 0.3913, 0.3916, 0.2991, 0.2003,\n",
       "                      0.4046, 0.2692, 0.1813, 0.2487, 0.1460, 0.4957, 0.1389, 0.1198, 0.2473,\n",
       "                      0.2776, 0.3304, 0.4821, 0.3365, 0.6486, 0.3036, 0.3833, 0.4677, 0.0951,\n",
       "                      0.0989, 0.2398, 0.2202, 0.7901, 0.5209, 0.3599, 0.2472, 0.3224, 0.2672,\n",
       "                      0.8757, 0.4342, 0.4727, 0.3744, 0.1521, 0.4479, 0.2096, 0.3283, 0.4618,\n",
       "                      0.1377, 0.2535, 0.5651, 0.2063, 0.6375, 0.4324, 0.3621, 0.3044, 0.3737,\n",
       "                      0.2715, 0.2355, 0.2862, 0.5097, 0.5200, 0.4040, 0.2693, 0.2242, 0.3296,\n",
       "                      0.2772, 0.2923, 0.3419, 0.0776, 0.3295, 0.2575, 0.2453, 0.1361, 0.4140,\n",
       "                      0.2965, 0.2613, 0.2432, 0.4271, 0.1075, 0.5608, 0.1242, 0.3460, 0.6001,\n",
       "                      0.2329, 0.2246, 0.2389, 0.8850, 0.5230, 0.1118, 0.3299, 0.2798, 0.4547,\n",
       "                      0.2506, 0.3151, 0.1293, 0.3373, 0.2370, 0.3779, 0.4788, 0.2138, 0.5492,\n",
       "                      0.3443, 0.0747, 0.2048, 0.3871, 0.4093, 0.1205, 0.7260, 0.5135, 0.3473,\n",
       "                      0.2989, 0.2890, 0.2596, 0.3594], dtype=torch.float64)),\n",
       "             ('6.18.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.18.convpath.0.0.0.weight',\n",
       "              tensor([[[ 0.0326],\n",
       "                       [ 0.0622],\n",
       "                       [ 0.0897],\n",
       "                       ...,\n",
       "                       [-0.0259],\n",
       "                       [-0.0473],\n",
       "                       [ 0.0863]],\n",
       "              \n",
       "                      [[-0.0303],\n",
       "                       [ 0.0579],\n",
       "                       [ 0.1164],\n",
       "                       ...,\n",
       "                       [-0.0343],\n",
       "                       [ 0.1348],\n",
       "                       [-0.0078]],\n",
       "              \n",
       "                      [[ 0.0598],\n",
       "                       [-0.0100],\n",
       "                       [-0.0197],\n",
       "                       ...,\n",
       "                       [-0.0651],\n",
       "                       [-0.1132],\n",
       "                       [ 0.1284]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0994],\n",
       "                       [ 0.0243],\n",
       "                       [ 0.1443],\n",
       "                       ...,\n",
       "                       [ 0.0282],\n",
       "                       [-0.0606],\n",
       "                       [-0.1937]],\n",
       "              \n",
       "                      [[-0.1157],\n",
       "                       [-0.0695],\n",
       "                       [-0.1269],\n",
       "                       ...,\n",
       "                       [-0.0351],\n",
       "                       [-0.0380],\n",
       "                       [-0.1206]],\n",
       "              \n",
       "                      [[ 0.0463],\n",
       "                       [-0.1051],\n",
       "                       [-0.0652],\n",
       "                       ...,\n",
       "                       [ 0.0918],\n",
       "                       [ 0.0303],\n",
       "                       [-0.0258]]], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.0.1.weight',\n",
       "              tensor([0.9693, 0.9608, 0.9642, 0.9795, 0.9707, 0.9424, 0.9496, 0.9757, 0.9618,\n",
       "                      0.9657, 0.9909, 0.9712, 0.9703, 1.0110, 0.9739, 0.9758, 1.0145, 1.0055,\n",
       "                      0.9801, 0.9795, 0.9615, 0.9495, 0.9829, 0.9818, 0.9797, 0.9531, 0.9648,\n",
       "                      0.9743, 0.9750, 0.9641, 0.9683, 0.9765, 0.9545, 0.9727, 0.9750, 0.9799,\n",
       "                      0.9506, 0.9660, 1.0045, 0.9571, 0.9782, 0.9508, 0.9647, 0.9892, 0.9497,\n",
       "                      0.9494, 0.9932, 0.9814, 0.9639, 0.9801, 0.9612, 0.9717, 0.9696, 0.9683,\n",
       "                      0.9565, 0.9687, 0.9876, 0.9492, 0.9585, 0.9565, 0.9756, 0.9652, 0.9740,\n",
       "                      0.9550], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.0.1.bias',\n",
       "              tensor([ 1.4644e-03, -9.3553e-03, -7.7696e-03,  1.2056e-02, -1.9368e-02,\n",
       "                       7.0443e-03, -1.3395e-02, -1.1643e-02, -9.5395e-03, -1.2194e-02,\n",
       "                       1.9161e-02,  5.6341e-04, -1.1159e-02,  2.4839e-02, -8.1317e-03,\n",
       "                      -1.6184e-03,  1.6074e-02, -8.2810e-03, -8.4647e-03,  7.7671e-03,\n",
       "                       2.2326e-04, -2.0229e-05,  9.8568e-03,  1.6711e-02,  2.7004e-02,\n",
       "                       1.4573e-02, -8.6591e-03, -2.2268e-02, -7.2342e-03, -8.6033e-03,\n",
       "                      -2.5289e-03, -6.3978e-03, -5.2394e-03,  2.8941e-03,  1.4332e-02,\n",
       "                       1.8374e-02,  1.1981e-03, -4.3097e-04,  3.2194e-02, -1.2187e-02,\n",
       "                       2.1108e-02, -8.5860e-03,  4.1466e-03,  1.5354e-02, -6.8866e-03,\n",
       "                       1.4691e-02,  1.4348e-02,  2.2744e-04, -1.6536e-02,  9.2811e-03,\n",
       "                      -4.6270e-03,  4.7947e-03,  6.3936e-03, -1.7480e-02, -1.0078e-02,\n",
       "                       1.9818e-02,  1.7869e-02,  3.7228e-03, -9.5491e-03, -9.0658e-03,\n",
       "                       1.5320e-02, -2.9019e-03,  1.6277e-03, -6.0902e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.0.1.running_mean',\n",
       "              tensor([ 0.7911,  1.0856, -0.1271,  0.4413,  1.3026, -0.8317, -0.7399, -1.2779,\n",
       "                       0.0735,  1.1619,  0.6248, -0.2560, -0.3489,  0.1403,  0.2621, -0.7375,\n",
       "                       0.0212, -0.5844,  0.2094,  0.1336, -0.1608, -1.3917,  0.0524,  0.1382,\n",
       "                      -0.8523,  0.3752, -0.5548,  0.7559,  1.2574, -0.0529,  0.7082, -0.5641,\n",
       "                      -1.4012, -0.4222, -1.2143,  0.2030, -0.1999, -1.3190, -0.2920,  0.1989,\n",
       "                      -0.1171,  0.1261,  0.4280, -1.1588,  0.6451, -0.6450, -0.5804,  0.1390,\n",
       "                      -0.3991, -0.2114, -0.0702, -0.0440,  0.2758, -0.0428, -0.8534, -1.0308,\n",
       "                       0.0107,  0.4808,  0.2333,  0.2953,  0.2533,  0.1044,  1.3181,  0.2374],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.0.1.running_var',\n",
       "              tensor([0.1505, 0.9159, 0.3126, 0.2280, 0.2127, 0.4216, 0.1253, 0.1659, 0.1205,\n",
       "                      1.0745, 0.1182, 0.2970, 0.1873, 0.1414, 0.2570, 0.2836, 0.0983, 0.1541,\n",
       "                      0.1687, 0.1334, 0.1676, 0.5300, 0.2283, 0.2158, 0.1906, 0.1985, 0.2586,\n",
       "                      0.4634, 0.1213, 0.1751, 0.3176, 0.3535, 0.2251, 0.1867, 0.4454, 0.1679,\n",
       "                      0.1419, 0.1268, 0.1468, 0.1245, 0.1410, 0.2251, 0.1988, 0.1568, 0.2570,\n",
       "                      0.7680, 0.2041, 0.1606, 0.1948, 0.1312, 0.1316, 0.1588, 0.2987, 0.2048,\n",
       "                      0.2823, 0.1957, 0.1769, 0.1863, 0.1024, 0.1098, 0.1037, 0.2023, 0.1028,\n",
       "                      0.1515], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.18.convpath.0.1.0.weight',\n",
       "              tensor([[[-0.0699, -0.0065,  0.0287,  0.0297,  0.0957],\n",
       "                       [ 0.0765, -0.1905,  0.1309,  0.1234, -0.0747],\n",
       "                       [-0.0673, -0.0923, -0.1309, -0.0678, -0.0278],\n",
       "                       ...,\n",
       "                       [-0.0820,  0.0623, -0.0270,  0.0348,  0.0489],\n",
       "                       [-0.1027,  0.0825,  0.0055,  0.0275,  0.0665],\n",
       "                       [ 0.1255, -0.1047, -0.0907, -0.0772, -0.0879]],\n",
       "              \n",
       "                      [[ 0.0024,  0.0277,  0.0817, -0.0020,  0.0155],\n",
       "                       [-0.0345,  0.0154, -0.0585,  0.0028,  0.1844],\n",
       "                       [ 0.0749, -0.0277,  0.0359,  0.0443, -0.0576],\n",
       "                       ...,\n",
       "                       [ 0.0352,  0.0201, -0.0416, -0.1004,  0.0328],\n",
       "                       [-0.0307, -0.0453, -0.0767, -0.0677, -0.0190],\n",
       "                       [ 0.0831,  0.0273,  0.0701,  0.0060, -0.1484]],\n",
       "              \n",
       "                      [[ 0.1036,  0.0110, -0.0590, -0.0081, -0.0507],\n",
       "                       [ 0.0192,  0.1049, -0.0535, -0.0701,  0.1101],\n",
       "                       [ 0.0387,  0.0267,  0.1388, -0.0512, -0.0071],\n",
       "                       ...,\n",
       "                       [-0.0349, -0.1413, -0.0051,  0.0827,  0.0311],\n",
       "                       [-0.1081,  0.0131, -0.0557,  0.0370, -0.1276],\n",
       "                       [-0.1572,  0.0660,  0.0661,  0.0362, -0.0224]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0082,  0.0575, -0.0559,  0.0069, -0.0443],\n",
       "                       [ 0.0223,  0.1566, -0.0250, -0.0507, -0.0568],\n",
       "                       [ 0.0224, -0.0563, -0.0884,  0.1039,  0.0485],\n",
       "                       ...,\n",
       "                       [ 0.0514, -0.0394,  0.0670,  0.0471, -0.0902],\n",
       "                       [-0.1240, -0.0415,  0.1104, -0.0603, -0.0023],\n",
       "                       [-0.1577, -0.0558, -0.1134, -0.0116, -0.0240]],\n",
       "              \n",
       "                      [[ 0.0725,  0.0531, -0.0406, -0.0116,  0.0553],\n",
       "                       [ 0.0502, -0.0395,  0.0592,  0.0314,  0.1352],\n",
       "                       [-0.0075, -0.0009,  0.1412,  0.2115,  0.0184],\n",
       "                       ...,\n",
       "                       [ 0.0462,  0.0162, -0.1095, -0.0886,  0.1991],\n",
       "                       [-0.0826, -0.0101, -0.0229,  0.0448,  0.1285],\n",
       "                       [ 0.0721,  0.0141,  0.0232,  0.0370,  0.0098]],\n",
       "              \n",
       "                      [[-0.1181, -0.0504, -0.0034,  0.0041,  0.0623],\n",
       "                       [-0.1397, -0.0815,  0.0469, -0.0488, -0.1109],\n",
       "                       [ 0.0548,  0.0719, -0.1314, -0.1144, -0.0111],\n",
       "                       ...,\n",
       "                       [ 0.0296, -0.0649,  0.0560,  0.1466, -0.0326],\n",
       "                       [-0.0958,  0.0471,  0.0475,  0.0230, -0.0047],\n",
       "                       [ 0.0281, -0.0935,  0.0127, -0.0664,  0.0094]]], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.1.1.weight',\n",
       "              tensor([0.9610, 0.9796, 0.9399, 0.9772, 0.9852, 0.9276, 0.9653, 0.9428, 0.9817,\n",
       "                      0.9708, 0.9792, 0.9787, 0.9495, 0.9730, 0.9661, 0.9821, 0.9755, 0.9922,\n",
       "                      0.9722, 0.9525, 0.9702, 0.9589, 0.9802, 0.9466, 0.9428, 0.9781, 0.9721,\n",
       "                      0.9552, 0.9784, 0.9666, 0.9656, 0.9536, 0.9580, 0.9861, 0.9820, 0.9272,\n",
       "                      0.9512, 0.9577, 0.9557, 0.9499, 0.9775, 0.9682, 0.9534, 0.9523, 0.9661,\n",
       "                      0.9558, 0.9686, 0.9579, 0.9607, 0.9707, 0.9890, 0.9573, 0.9552, 0.9642,\n",
       "                      0.9554, 0.9669, 0.9755, 0.9673, 0.9896, 0.9975, 0.9615, 0.9542, 0.9897,\n",
       "                      0.9682], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.1.1.bias',\n",
       "              tensor([-0.0083,  0.0096, -0.0079, -0.0098,  0.0079, -0.0072, -0.0049, -0.0050,\n",
       "                       0.0128,  0.0003, -0.0059,  0.0048,  0.0007, -0.0159, -0.0177,  0.0013,\n",
       "                      -0.0036, -0.0074,  0.0013, -0.0037, -0.0008, -0.0225, -0.0277, -0.0147,\n",
       "                      -0.0052,  0.0068, -0.0047, -0.0051,  0.0010,  0.0037, -0.0112, -0.0296,\n",
       "                      -0.0108, -0.0085, -0.0104, -0.0267, -0.0272, -0.0071, -0.0062, -0.0133,\n",
       "                       0.0093, -0.0065,  0.0006, -0.0245, -0.0201,  0.0038,  0.0084, -0.0220,\n",
       "                       0.0094,  0.0113,  0.0176, -0.0176, -0.0246,  0.0101, -0.0076, -0.0283,\n",
       "                      -0.0062, -0.0346,  0.0031,  0.0148,  0.0105, -0.0175, -0.0025, -0.0077],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.1.1.running_mean',\n",
       "              tensor([-0.2456,  0.3734, -0.3205, -0.4581, -0.0111, -0.2860,  0.5471,  0.0383,\n",
       "                       0.2086,  0.3688,  0.0716, -1.3562, -0.2441, -0.5892, -0.0978, -0.3246,\n",
       "                      -0.0569,  0.6194, -0.3676,  0.0369, -0.5219, -0.1303, -0.4742, -0.6607,\n",
       "                      -0.5371, -0.4513, -0.6930, -0.6633,  0.6716, -0.4953, -0.2153, -0.4817,\n",
       "                      -0.8008, -0.4875,  0.2456, -0.1912,  0.2986,  0.3066,  0.2862, -0.1004,\n",
       "                      -0.4656, -0.0087, -0.6817, -0.5223,  0.5085, -0.4211, -1.0567,  0.3645,\n",
       "                      -0.7002,  0.0866,  0.1141,  0.3119,  0.9414,  1.3299, -0.1979, -0.3982,\n",
       "                       0.5804,  0.2144, -0.5156,  0.3599, -0.9109, -0.1137, -0.2019, -0.5339],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.1.1.running_var',\n",
       "              tensor([0.5257, 0.6336, 0.4815, 0.7168, 0.8632, 0.7030, 0.3303, 0.4625, 0.4001,\n",
       "                      0.4910, 0.4410, 0.8068, 0.7808, 0.4280, 0.5905, 0.6657, 0.6357, 0.4209,\n",
       "                      0.5663, 0.4526, 0.4523, 0.4809, 0.3738, 0.4723, 0.6604, 0.4958, 0.6646,\n",
       "                      0.5248, 0.6344, 0.5742, 0.4544, 0.5549, 0.6469, 0.4479, 0.4748, 0.5404,\n",
       "                      0.6669, 0.6506, 0.3404, 0.4634, 0.6312, 0.6308, 0.7208, 0.6500, 0.4138,\n",
       "                      0.6190, 0.5990, 0.6618, 0.5618, 0.5002, 0.5534, 0.4077, 0.4548, 0.7171,\n",
       "                      0.6190, 0.5977, 0.7583, 0.8713, 0.5393, 0.5285, 0.5386, 0.5539, 0.5991,\n",
       "                      0.5065], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.18.convpath.0.2.0.weight',\n",
       "              tensor([[[-0.0606],\n",
       "                       [-0.0881],\n",
       "                       [ 0.1923],\n",
       "                       ...,\n",
       "                       [ 0.0470],\n",
       "                       [ 0.0801],\n",
       "                       [ 0.0749]],\n",
       "              \n",
       "                      [[ 0.0503],\n",
       "                       [-0.0712],\n",
       "                       [ 0.0044],\n",
       "                       ...,\n",
       "                       [ 0.0589],\n",
       "                       [-0.0123],\n",
       "                       [-0.0054]],\n",
       "              \n",
       "                      [[-0.1691],\n",
       "                       [-0.0244],\n",
       "                       [-0.0830],\n",
       "                       ...,\n",
       "                       [-0.1529],\n",
       "                       [ 0.0536],\n",
       "                       [-0.1610]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.2000],\n",
       "                       [-0.0557],\n",
       "                       [-0.1459],\n",
       "                       ...,\n",
       "                       [ 0.0996],\n",
       "                       [ 0.1150],\n",
       "                       [ 0.0637]],\n",
       "              \n",
       "                      [[-0.1319],\n",
       "                       [ 0.0597],\n",
       "                       [-0.0909],\n",
       "                       ...,\n",
       "                       [ 0.0110],\n",
       "                       [-0.2066],\n",
       "                       [-0.1393]],\n",
       "              \n",
       "                      [[ 0.0124],\n",
       "                       [-0.0879],\n",
       "                       [-0.0872],\n",
       "                       ...,\n",
       "                       [ 0.1538],\n",
       "                       [ 0.1130],\n",
       "                       [-0.0020]]], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.2.1.weight',\n",
       "              tensor([ 1.9600e-02,  1.2067e-02,  1.7449e-02,  3.0706e-03,  5.4469e-03,\n",
       "                      -8.3460e-03, -5.6302e-03, -1.6789e-02,  8.8008e-03, -7.9497e-03,\n",
       "                      -1.0700e-02,  5.5923e-03,  5.7849e-03,  8.3630e-03,  5.8248e-03,\n",
       "                       1.3987e-02, -5.2145e-02, -1.1648e-02,  6.8550e-03,  9.1247e-03,\n",
       "                      -1.2569e-02,  9.2128e-04,  2.4236e-02,  1.2678e-02,  1.3325e-02,\n",
       "                       1.8923e-02, -2.2389e-02,  6.4395e-03, -1.1526e-02,  2.3172e-02,\n",
       "                      -9.6461e-03,  3.0464e-02,  1.7222e-02, -1.8433e-02, -6.9785e-02,\n",
       "                       1.6874e-02,  1.7926e-02,  4.8753e-03,  1.7527e-03, -1.1408e-03,\n",
       "                      -1.1214e-02,  2.8707e-02, -5.8988e-03,  7.0184e-03,  6.1359e-03,\n",
       "                       2.9272e-02, -2.9838e-02, -5.2065e-03, -3.5785e-02, -2.0929e-02,\n",
       "                      -3.0276e-02, -1.2769e-02, -2.1736e-02, -1.5033e-03,  1.2660e-02,\n",
       "                       1.0708e-02, -1.4412e-02,  8.9157e-04, -5.7865e-03,  5.8098e-03,\n",
       "                       3.6804e-03,  1.4412e-02,  1.5876e-03, -4.7275e-02, -2.5694e-02,\n",
       "                      -1.0761e-02, -5.0806e-03, -3.4255e-02,  9.4502e-03, -2.0274e-02,\n",
       "                       8.4346e-03,  7.2065e-03, -7.8735e-03, -1.9829e-02,  9.2813e-03,\n",
       "                       1.0792e-02, -2.7873e-02, -2.4430e-02, -1.9158e-02, -1.2250e-02,\n",
       "                       1.4809e-02,  2.2369e-02,  5.0336e-03, -8.5300e-03, -3.0914e-02,\n",
       "                      -1.9050e-03,  1.6162e-02,  1.3694e-02, -7.0497e-03, -2.9154e-02,\n",
       "                       3.1416e-02,  1.2979e-02, -1.2714e-02,  8.5382e-03,  1.8068e-03,\n",
       "                      -1.9883e-02, -1.8492e-02,  5.3051e-03,  2.5011e-02,  1.6844e-02,\n",
       "                       2.9109e-04,  1.8003e-02, -7.7917e-03,  4.0893e-02,  1.1443e-02,\n",
       "                       2.2266e-02, -3.1417e-03,  1.2431e-02, -7.0870e-04,  6.6558e-03,\n",
       "                       9.8892e-03,  1.3473e-02, -9.8680e-03,  9.2901e-03,  2.2994e-02,\n",
       "                      -2.0649e-02, -6.9128e-03,  3.0918e-02,  5.5584e-03,  3.1578e-02,\n",
       "                      -1.2305e-02, -1.8649e-02,  1.4175e-02,  4.2901e-03,  9.4881e-03,\n",
       "                       5.1201e-02, -8.8319e-03,  5.7289e-03,  9.9962e-04,  8.0820e-03,\n",
       "                      -5.2919e-03,  9.1284e-03, -2.6513e-02,  1.9012e-03, -1.2204e-02,\n",
       "                      -1.2970e-02, -6.1749e-03, -1.0992e-02, -1.8732e-02, -2.2937e-02,\n",
       "                       1.3254e-02,  4.8321e-03,  2.4983e-02, -5.8679e-04,  1.7433e-02,\n",
       "                       2.0568e-02, -2.8096e-03, -8.8333e-03, -1.1907e-02,  2.9226e-03,\n",
       "                      -9.4637e-03, -1.2581e-02, -4.3402e-03,  8.8420e-03, -1.9088e-03,\n",
       "                      -1.3332e-02,  8.2638e-03,  3.7064e-03, -1.5463e-02,  9.1711e-04,\n",
       "                      -3.7246e-03,  1.4282e-02,  3.9456e-03,  2.1891e-02, -2.5818e-02,\n",
       "                       5.5600e-03, -5.9263e-03, -1.9170e-02, -1.2410e-02,  2.7370e-02,\n",
       "                      -7.9121e-03, -4.9170e-03, -8.5817e-03, -8.0854e-03,  1.7443e-02,\n",
       "                      -3.9178e-02,  9.8698e-03, -1.2641e-02, -1.6787e-02,  7.4793e-03,\n",
       "                      -2.9841e-02,  2.5893e-02, -2.2694e-02,  1.1599e-02,  8.6739e-03,\n",
       "                       1.8298e-02,  3.7548e-03, -1.4132e-02,  1.1466e-02, -1.3387e-02,\n",
       "                      -7.1240e-03, -4.8281e-02, -1.1828e-03, -2.2117e-02,  3.6535e-02,\n",
       "                      -1.1665e-02,  1.3719e-02,  2.7388e-02,  1.1115e-02,  1.5647e-02,\n",
       "                      -1.2775e-02, -2.8299e-02,  3.1611e-02, -1.0292e-02, -3.7667e-03,\n",
       "                       8.0773e-03,  2.2250e-02, -2.3351e-02,  1.9374e-02, -8.7631e-03,\n",
       "                       2.9280e-03,  8.4645e-03, -1.0909e-02,  1.0227e-02,  9.9291e-03,\n",
       "                      -1.2464e-02,  1.0244e-02,  1.1889e-02, -7.5968e-03,  2.0103e-02,\n",
       "                       7.5045e-05, -1.3698e-02, -4.7202e-04,  2.7508e-03, -2.3327e-02,\n",
       "                       1.1899e-02,  4.9536e-03, -1.3317e-03,  2.8445e-02,  9.0946e-04,\n",
       "                      -1.1273e-02, -7.9019e-03,  1.5172e-02, -1.6721e-02, -4.3719e-03,\n",
       "                       4.0167e-02, -4.9451e-03, -4.9652e-02,  2.6526e-03,  1.9213e-02,\n",
       "                      -1.4157e-02,  1.5956e-02,  1.3411e-02, -4.6567e-03, -2.0045e-03,\n",
       "                      -1.0787e-02,  1.5407e-02, -1.8295e-02, -5.5819e-03, -1.9157e-02,\n",
       "                      -2.0630e-02, -2.4605e-02,  1.3807e-02, -2.6926e-02,  7.4194e-03,\n",
       "                       1.0944e-02], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.2.1.bias',\n",
       "              tensor([ 0.0042,  0.0061,  0.0042,  0.0152, -0.0022,  0.0079,  0.0044,  0.0012,\n",
       "                       0.0024,  0.0071,  0.0163, -0.0078,  0.0055, -0.0058,  0.0023,  0.0058,\n",
       "                       0.0274,  0.0042,  0.0115, -0.0032, -0.0079,  0.0016,  0.0076,  0.0049,\n",
       "                       0.0177, -0.0193,  0.0057,  0.0111,  0.0110, -0.0054, -0.0049,  0.0132,\n",
       "                       0.0089,  0.0155,  0.0101,  0.0138, -0.0045,  0.0092,  0.0149,  0.0005,\n",
       "                       0.0092,  0.0026, -0.0089, -0.0060,  0.0077, -0.0166,  0.0113,  0.0036,\n",
       "                      -0.0128,  0.0002,  0.0113,  0.0042,  0.0055,  0.0207,  0.0006,  0.0126,\n",
       "                       0.0102,  0.0052,  0.0052, -0.0034,  0.0015,  0.0006,  0.0134,  0.0081,\n",
       "                      -0.0112,  0.0023, -0.0058,  0.0142,  0.0187, -0.0149,  0.0085,  0.0024,\n",
       "                      -0.0007, -0.0079,  0.0131,  0.0038,  0.0039,  0.0182,  0.0011,  0.0097,\n",
       "                       0.0032, -0.0087,  0.0189,  0.0027, -0.0082,  0.0214, -0.0020,  0.0122,\n",
       "                       0.0124,  0.0002,  0.0017,  0.0132,  0.0098, -0.0075,  0.0046, -0.0064,\n",
       "                       0.0148,  0.0043,  0.0197,  0.0066,  0.0245,  0.0170,  0.0013,  0.0146,\n",
       "                       0.0066,  0.0017,  0.0049,  0.0108,  0.0057,  0.0079,  0.0033, -0.0050,\n",
       "                       0.0058,  0.0225,  0.0179,  0.0026,  0.0047,  0.0027,  0.0008, -0.0030,\n",
       "                      -0.0002,  0.0125,  0.0034,  0.0016,  0.0180,  0.0081,  0.0108,  0.0046,\n",
       "                       0.0029,  0.0134,  0.0072,  0.0065,  0.0088,  0.0019,  0.0059, -0.0133,\n",
       "                       0.0102,  0.0049,  0.0081,  0.0076,  0.0157,  0.0134,  0.0093,  0.0018,\n",
       "                      -0.0081,  0.0087,  0.0055,  0.0066,  0.0055,  0.0013,  0.0102,  0.0084,\n",
       "                       0.0044,  0.0108,  0.0140,  0.0030, -0.0019,  0.0045,  0.0042,  0.0008,\n",
       "                       0.0052,  0.0081, -0.0002,  0.0065,  0.0107, -0.0053, -0.0110,  0.0047,\n",
       "                       0.0105,  0.0114,  0.0147, -0.0022,  0.0125,  0.0150, -0.0156,  0.0129,\n",
       "                      -0.0026,  0.0130, -0.0024,  0.0036, -0.0003,  0.0110, -0.0039, -0.0065,\n",
       "                       0.0089,  0.0078,  0.0110,  0.0087,  0.0011,  0.0071,  0.0034,  0.0096,\n",
       "                       0.0050,  0.0076,  0.0124,  0.0099,  0.0092, -0.0012,  0.0056,  0.0104,\n",
       "                      -0.0004,  0.0210,  0.0141,  0.0169,  0.0148,  0.0054,  0.0074, -0.0062,\n",
       "                       0.0040,  0.0070,  0.0066,  0.0100, -0.0041,  0.0133,  0.0066,  0.0058,\n",
       "                       0.0010,  0.0162,  0.0007, -0.0013,  0.0180,  0.0101,  0.0028,  0.0134,\n",
       "                       0.0119,  0.0051, -0.0071, -0.0041,  0.0254,  0.0183,  0.0028, -0.0007,\n",
       "                       0.0064,  0.0058, -0.0020,  0.0064, -0.0035,  0.0153,  0.0021,  0.0149,\n",
       "                      -0.0031,  0.0025, -0.0076,  0.0132,  0.0007,  0.0024,  0.0070,  0.0023,\n",
       "                      -0.0211, -0.0112,  0.0185,  0.0165,  0.0095,  0.0175,  0.0033,  0.0019],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.2.1.running_mean',\n",
       "              tensor([ 7.7297e-01, -1.0550e-01,  1.0763e-01, -8.0681e-02, -9.9735e-04,\n",
       "                      -5.5130e-01, -1.6592e-02,  4.4639e-01, -9.7016e-02,  7.2733e-01,\n",
       "                      -2.3602e-01,  2.8331e-01,  2.1040e-02,  1.0536e-01, -4.3713e-01,\n",
       "                      -2.6298e-02, -1.9619e-01,  4.0163e-01, -5.6093e-01, -6.9598e-01,\n",
       "                      -7.6822e-02, -2.1407e-01,  1.9279e-01,  2.5199e-01, -3.2156e-01,\n",
       "                      -2.6858e-01,  7.4786e-02, -1.7502e-01, -4.1488e-01,  5.4379e-01,\n",
       "                       1.3537e+00, -6.4823e-01,  2.1594e-01,  2.3014e-01,  6.8409e-01,\n",
       "                      -8.3925e-01, -6.7568e-02, -3.7324e-01,  1.0105e-01,  2.3012e-01,\n",
       "                       2.2100e-01, -1.4756e-01,  1.4439e-01,  1.9787e-01, -7.0692e-01,\n",
       "                       6.3368e-03, -8.6856e-01, -3.2146e-01,  9.9722e-02,  5.7602e-01,\n",
       "                      -2.4114e-02, -5.5874e-01,  2.5370e-01,  2.3945e-01,  3.3417e-01,\n",
       "                       5.6123e-01,  4.1261e-01,  4.2150e-01, -7.7494e-02,  1.9512e-01,\n",
       "                       5.8126e-01,  1.2466e-01,  2.5612e-01, -1.8675e-01, -1.2655e-01,\n",
       "                      -6.2670e-02,  9.1066e-04, -2.4185e-01,  2.5471e-01, -8.5520e-02,\n",
       "                       9.6745e-01,  5.2680e-01,  3.3554e-01,  6.5724e-01, -1.2188e+00,\n",
       "                      -4.0781e-01,  5.0810e-01, -1.3068e-01, -7.6112e-01, -8.2694e-02,\n",
       "                      -6.8665e-01,  8.7213e-01, -4.6975e-02,  5.0169e-02, -3.0235e-01,\n",
       "                      -2.1147e-01, -3.2663e-01,  7.5809e-01, -4.5827e-01,  5.9889e-01,\n",
       "                      -8.6986e-02, -1.3586e-01,  4.1223e-01, -4.1404e-01, -2.1901e-01,\n",
       "                      -5.6238e-01,  2.8949e-02, -7.9281e-03, -6.4932e-01, -1.4727e-01,\n",
       "                       2.7748e-03, -3.5938e-01, -6.4176e-01, -8.0207e-01,  3.4256e-01,\n",
       "                       2.6874e-01,  8.5718e-02,  2.8744e-01,  2.1488e-01,  2.3778e-01,\n",
       "                       2.4563e-01, -1.2899e-02,  2.1048e-01, -6.7537e-01,  5.3172e-01,\n",
       "                       4.1443e-01,  5.7816e-01, -6.9320e-01,  3.6026e-01, -8.7836e-02,\n",
       "                      -2.5065e-01, -6.7196e-01,  3.5993e-01,  2.1463e-01,  1.3988e-01,\n",
       "                      -5.8351e-01, -8.5797e-02,  5.1361e-01, -1.8977e-02, -5.0259e-01,\n",
       "                      -4.4895e-02, -2.2994e-01, -1.1669e-01, -2.6686e-01, -3.1314e-01,\n",
       "                       3.3971e-02, -7.3420e-03,  1.2434e-01, -1.6070e-01, -2.2562e-01,\n",
       "                      -5.2357e-01,  6.4218e-02,  7.5142e-01,  2.4942e-01,  3.3641e-01,\n",
       "                       3.8522e-01,  9.3835e-02, -5.6183e-01,  2.3336e-02,  2.6558e-01,\n",
       "                      -2.6176e-01,  4.8150e-01, -2.3535e-01, -1.3355e-01,  4.3214e-01,\n",
       "                       2.5568e-01,  3.6074e-01, -4.4321e-02,  4.5100e-01, -8.1580e-03,\n",
       "                       4.0667e-01,  2.5507e-01, -1.8878e-01, -4.5634e-01, -1.9376e-03,\n",
       "                       9.7773e-02,  2.1771e-01,  2.2567e-01, -1.2761e-01, -2.6499e-01,\n",
       "                       8.0108e-02, -1.2826e-01, -9.4114e-02,  1.5773e-01, -3.6830e-01,\n",
       "                      -5.2824e-01, -2.8120e-01, -3.6948e-01,  3.3065e-01, -7.7955e-01,\n",
       "                      -1.0149e-01,  2.3654e-01,  4.3488e-01,  2.7248e-01,  2.8639e-01,\n",
       "                      -1.1094e-01, -1.0786e-01, -2.1823e-03,  9.2183e-01,  3.8103e-01,\n",
       "                      -2.2365e-01,  2.5584e-01, -4.3678e-01, -1.0737e-01,  6.7606e-01,\n",
       "                       5.4486e-03, -1.6769e-01, -3.6260e-01,  1.3729e-01, -1.3350e-01,\n",
       "                      -3.2611e-01, -5.8568e-01,  4.0421e-01,  4.4531e-01, -9.5040e-02,\n",
       "                       4.4474e-01,  3.6696e-01,  1.9211e-01,  3.7226e-01,  1.6134e-01,\n",
       "                       1.6496e-01,  6.3573e-02,  2.5671e-01,  2.2514e-01,  6.9041e-02,\n",
       "                      -1.1368e-01,  2.3480e-01, -1.1725e-01,  2.5873e-02, -2.5599e-01,\n",
       "                      -3.7109e-01,  4.5825e-01, -1.2619e-01,  9.3730e-01,  2.0248e-01,\n",
       "                      -7.6791e-02,  3.0305e-01,  5.9686e-02,  5.7985e-01, -3.8884e-01,\n",
       "                      -6.5739e-02, -7.1770e-01, -3.0932e-01, -4.2560e-01,  1.6907e-01,\n",
       "                      -7.4240e-02,  1.8930e-01,  6.1338e-01, -1.4488e-01,  3.2112e-01,\n",
       "                      -4.2869e-01,  9.2409e-02,  4.0495e-01, -1.3100e-02,  1.2595e-01,\n",
       "                       1.3171e-01,  5.4219e-01,  6.6487e-02, -3.5884e-01, -2.3615e-01,\n",
       "                       2.6037e-01, -1.7370e-01, -3.6932e-01,  3.9731e-01, -4.1626e-01,\n",
       "                       4.2828e-01], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.2.1.running_var',\n",
       "              tensor([0.5027, 0.2789, 0.2474, 0.3024, 0.4673, 0.1978, 0.1944, 0.3229, 0.1606,\n",
       "                      0.4020, 0.2890, 0.2050, 0.0731, 0.1802, 0.5074, 0.3439, 0.4591, 0.3183,\n",
       "                      0.1334, 0.6073, 0.1882, 0.2437, 0.4098, 0.2736, 0.3000, 0.3634, 0.3360,\n",
       "                      0.1636, 0.2182, 0.2939, 0.6119, 0.5169, 0.2103, 0.3892, 0.5651, 0.5459,\n",
       "                      0.1788, 0.2224, 0.1095, 0.3436, 0.6027, 0.2180, 0.1874, 0.4948, 0.2203,\n",
       "                      0.4113, 0.4821, 0.1087, 0.4726, 0.3603, 0.3598, 0.4120, 0.5232, 0.0719,\n",
       "                      0.6229, 0.3412, 0.4377, 0.2467, 0.3156, 0.1675, 0.1592, 0.2451, 0.1242,\n",
       "                      0.4417, 0.4087, 0.3856, 0.2379, 0.5252, 0.2825, 0.5343, 0.5386, 0.2684,\n",
       "                      0.1666, 0.5099, 0.4004, 0.2264, 0.4568, 0.3038, 0.5604, 0.1957, 0.4106,\n",
       "                      0.6138, 0.3222, 0.3476, 0.5642, 0.2987, 0.3263, 0.4100, 0.2053, 0.1932,\n",
       "                      0.6016, 0.5876, 0.2311, 0.1737, 0.2841, 0.3007, 0.5892, 0.1242, 0.3034,\n",
       "                      0.4184, 0.5513, 0.5158, 0.2246, 0.6594, 0.4737, 0.3662, 0.2929, 0.3533,\n",
       "                      0.2992, 0.1654, 0.1407, 0.2628, 0.3091, 0.3792, 0.4222, 0.5051, 0.3909,\n",
       "                      0.5063, 0.2592, 0.5521, 0.4681, 0.4270, 0.3317, 0.1596, 0.2421, 0.3292,\n",
       "                      0.1958, 0.2536, 0.2545, 0.2768, 0.3246, 0.2735, 0.3756, 0.0863, 0.2476,\n",
       "                      0.1280, 0.0569, 0.3442, 0.3355, 0.4602, 0.4584, 0.0830, 0.3024, 0.1507,\n",
       "                      0.3132, 0.4159, 0.0791, 0.4559, 0.0806, 0.3913, 0.3916, 0.2991, 0.2003,\n",
       "                      0.4046, 0.2692, 0.1813, 0.2487, 0.1460, 0.4957, 0.1389, 0.1198, 0.2473,\n",
       "                      0.2776, 0.3304, 0.4821, 0.3365, 0.6486, 0.3036, 0.3833, 0.4677, 0.0951,\n",
       "                      0.0989, 0.2398, 0.2202, 0.7901, 0.5209, 0.3599, 0.2472, 0.3224, 0.2672,\n",
       "                      0.8757, 0.4342, 0.4727, 0.3744, 0.1521, 0.4479, 0.2096, 0.3283, 0.4618,\n",
       "                      0.1377, 0.2535, 0.5651, 0.2063, 0.6375, 0.4324, 0.3621, 0.3044, 0.3737,\n",
       "                      0.2715, 0.2355, 0.2862, 0.5097, 0.5200, 0.4040, 0.2693, 0.2242, 0.3296,\n",
       "                      0.2772, 0.2923, 0.3419, 0.0776, 0.3295, 0.2575, 0.2453, 0.1361, 0.4140,\n",
       "                      0.2965, 0.2613, 0.2432, 0.4271, 0.1075, 0.5608, 0.1242, 0.3460, 0.6001,\n",
       "                      0.2329, 0.2246, 0.2389, 0.8850, 0.5230, 0.1118, 0.3299, 0.2798, 0.4547,\n",
       "                      0.2506, 0.3151, 0.1293, 0.3373, 0.2370, 0.3779, 0.4788, 0.2138, 0.5492,\n",
       "                      0.3443, 0.0747, 0.2048, 0.3871, 0.4093, 0.1205, 0.7260, 0.5135, 0.3473,\n",
       "                      0.2989, 0.2890, 0.2596, 0.3594], dtype=torch.float64)),\n",
       "             ('6.18.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.19.convs.0.0.weight',\n",
       "              tensor([[[-0.0309],\n",
       "                       [ 0.0352],\n",
       "                       [-0.0062],\n",
       "                       ...,\n",
       "                       [ 0.0164],\n",
       "                       [-0.1095],\n",
       "                       [ 0.1249]],\n",
       "              \n",
       "                      [[ 0.0469],\n",
       "                       [-0.0528],\n",
       "                       [-0.0574],\n",
       "                       ...,\n",
       "                       [-0.0871],\n",
       "                       [ 0.0535],\n",
       "                       [-0.0431]],\n",
       "              \n",
       "                      [[-0.0536],\n",
       "                       [ 0.1097],\n",
       "                       [ 0.0267],\n",
       "                       ...,\n",
       "                       [ 0.1238],\n",
       "                       [-0.1016],\n",
       "                       [-0.0073]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1524],\n",
       "                       [-0.1054],\n",
       "                       [ 0.0396],\n",
       "                       ...,\n",
       "                       [-0.0170],\n",
       "                       [-0.0055],\n",
       "                       [-0.0294]],\n",
       "              \n",
       "                      [[-0.0636],\n",
       "                       [ 0.0465],\n",
       "                       [-0.1090],\n",
       "                       ...,\n",
       "                       [-0.0072],\n",
       "                       [ 0.0397],\n",
       "                       [-0.0325]],\n",
       "              \n",
       "                      [[ 0.1725],\n",
       "                       [ 0.1143],\n",
       "                       [ 0.0235],\n",
       "                       ...,\n",
       "                       [-0.0319],\n",
       "                       [ 0.0712],\n",
       "                       [ 0.0875]]], dtype=torch.float64)),\n",
       "             ('6.19.convs.0.1.weight',\n",
       "              tensor([0.9465, 0.9673, 0.9610, 0.9982, 0.9627, 0.9206, 0.9613, 0.9774, 0.9680,\n",
       "                      0.9548, 0.9687, 0.9728, 0.9534, 0.9651, 0.9637, 0.9550, 0.9873, 0.9821,\n",
       "                      0.9950, 0.9775, 0.9508, 0.9539, 0.9569, 0.9602, 0.9906, 0.9584, 0.9734,\n",
       "                      0.9563, 0.9670, 0.9598, 0.9677, 0.9615, 0.9995, 0.9924, 0.9926, 0.9774,\n",
       "                      0.9630, 0.9691, 0.9840, 0.9736, 0.9810, 0.9847, 0.9664, 0.9729, 0.9663,\n",
       "                      0.9759, 0.9888, 0.9898, 0.9786, 0.9691, 0.9576, 0.9848, 0.9614, 0.9877,\n",
       "                      0.9785, 1.0056, 0.9587, 0.9637, 0.9717, 0.9649, 0.9715, 0.9830, 0.9343,\n",
       "                      0.9689], dtype=torch.float64)),\n",
       "             ('6.19.convs.0.1.bias',\n",
       "              tensor([ 0.0004,  0.0010,  0.0090,  0.0118, -0.0161, -0.0230,  0.0081,  0.0007,\n",
       "                      -0.0011, -0.0010, -0.0007,  0.0052, -0.0120, -0.0151,  0.0100, -0.0061,\n",
       "                       0.0027, -0.0112,  0.0109, -0.0109, -0.0046, -0.0194, -0.0048, -0.0098,\n",
       "                       0.0251,  0.0005, -0.0126,  0.0074,  0.0064, -0.0065,  0.0087, -0.0048,\n",
       "                       0.0267,  0.0263,  0.0099,  0.0038,  0.0168,  0.0078,  0.0081,  0.0054,\n",
       "                       0.0019,  0.0193, -0.0142,  0.0120, -0.0155,  0.0095,  0.0080,  0.0065,\n",
       "                       0.0028, -0.0186, -0.0022,  0.0122, -0.0067, -0.0053, -0.0004,  0.0218,\n",
       "                       0.0016,  0.0023,  0.0117, -0.0185,  0.0077,  0.0066,  0.0057, -0.0242],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.19.convs.0.1.running_mean',\n",
       "              tensor([-0.0352,  0.1269,  1.0086, -0.5691,  0.4288,  0.1688,  0.6714,  0.3483,\n",
       "                       1.6770, -0.5643,  0.3108,  0.5974,  0.1055,  0.6841,  0.4968,  1.0746,\n",
       "                       0.4248, -0.1263,  0.0488,  1.3591,  0.1826,  0.4513, -0.2599, -0.1598,\n",
       "                      -0.3771,  0.4301,  0.3143, -0.1347,  1.0426,  0.4396, -0.5129,  0.8051,\n",
       "                      -0.5000, -0.0382, -0.4156,  0.1962, -0.5401, -0.5085,  0.0811,  0.8767,\n",
       "                       0.5280,  0.4389, -0.1381,  0.2047,  0.2205,  0.3668, -0.7498, -0.9375,\n",
       "                       0.2150,  0.7657, -0.0034,  0.6661, -0.1777,  0.1903, -1.2948,  0.3198,\n",
       "                       0.3274, -0.1673, -0.3854,  0.8866,  0.0911, -0.0436, -1.5243, -0.7568],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.19.convs.0.1.running_var',\n",
       "              tensor([0.6753, 0.6099, 0.1485, 0.1127, 0.4499, 0.1259, 0.3177, 0.1275, 0.3582,\n",
       "                      0.1177, 0.1491, 0.1335, 0.1072, 0.1845, 0.3260, 0.5314, 0.1514, 0.1063,\n",
       "                      0.1642, 0.6159, 0.2689, 0.0986, 0.2813, 0.1059, 0.2782, 0.4126, 0.2184,\n",
       "                      0.3942, 0.3670, 0.6785, 0.2573, 0.6176, 0.1335, 0.2136, 0.1746, 0.1991,\n",
       "                      0.2718, 0.2110, 0.0934, 0.3661, 0.3891, 0.1652, 0.1269, 0.1293, 0.1617,\n",
       "                      0.5399, 0.2253, 0.1296, 0.4586, 0.1804, 0.7872, 0.2141, 0.2740, 0.1984,\n",
       "                      0.1814, 0.1486, 0.2788, 0.1341, 0.1227, 0.2549, 0.4101, 0.1312, 0.5740,\n",
       "                      0.1581], dtype=torch.float64)),\n",
       "             ('6.19.convs.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.19.convs.1.0.weight',\n",
       "              tensor([[[ 0.1165, -0.1736,  0.0306, -0.0704, -0.0433],\n",
       "                       [ 0.0334, -0.0367, -0.0195,  0.0504, -0.1455],\n",
       "                       [ 0.1327,  0.0585, -0.0744,  0.0926,  0.0495],\n",
       "                       ...,\n",
       "                       [-0.0434,  0.1077, -0.0595,  0.0033,  0.0543],\n",
       "                       [-0.0087,  0.1416, -0.0783,  0.0033, -0.0156],\n",
       "                       [ 0.0259,  0.0772, -0.0559,  0.0033, -0.0133]],\n",
       "              \n",
       "                      [[-0.0969, -0.1059, -0.1564, -0.0751, -0.1244],\n",
       "                       [-0.1024, -0.0131, -0.1156,  0.0490, -0.0207],\n",
       "                       [ 0.0746,  0.0309, -0.0064,  0.0696, -0.0899],\n",
       "                       ...,\n",
       "                       [ 0.0702, -0.0677,  0.0464, -0.0528,  0.0621],\n",
       "                       [-0.1095,  0.0752,  0.0498, -0.0710, -0.0553],\n",
       "                       [ 0.0399,  0.1017, -0.1137,  0.1110, -0.0143]],\n",
       "              \n",
       "                      [[ 0.0486,  0.1574, -0.0219, -0.0175,  0.0295],\n",
       "                       [-0.0751, -0.2239,  0.0829,  0.0138,  0.0032],\n",
       "                       [ 0.0452, -0.0014, -0.0441, -0.1438, -0.0019],\n",
       "                       ...,\n",
       "                       [-0.0967, -0.0573,  0.0150, -0.1774,  0.0102],\n",
       "                       [-0.1442,  0.1391,  0.0036,  0.0125, -0.0165],\n",
       "                       [ 0.0196, -0.0220,  0.0362,  0.0105,  0.0080]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0459, -0.0270,  0.0123, -0.0173, -0.0490],\n",
       "                       [-0.0014, -0.0581, -0.0340,  0.0084, -0.1285],\n",
       "                       [ 0.0311,  0.0581,  0.0909,  0.0502, -0.0235],\n",
       "                       ...,\n",
       "                       [-0.0576, -0.0291, -0.1795, -0.0349,  0.1208],\n",
       "                       [-0.0633, -0.0917,  0.0608,  0.0222,  0.1170],\n",
       "                       [ 0.0178, -0.0665, -0.0138,  0.1873,  0.0839]],\n",
       "              \n",
       "                      [[-0.0355, -0.0649,  0.0332, -0.0104, -0.0937],\n",
       "                       [ 0.0547,  0.0169,  0.0314,  0.0078, -0.0403],\n",
       "                       [ 0.0762, -0.0570, -0.0565, -0.0390,  0.0486],\n",
       "                       ...,\n",
       "                       [-0.0129,  0.0333, -0.0114, -0.0347, -0.0766],\n",
       "                       [-0.0408,  0.0754, -0.0126,  0.0182, -0.0775],\n",
       "                       [-0.0025,  0.0352,  0.1216,  0.1075, -0.1832]],\n",
       "              \n",
       "                      [[ 0.0954,  0.0212, -0.0932,  0.0348, -0.1242],\n",
       "                       [-0.0298, -0.0097, -0.0489,  0.1128, -0.0180],\n",
       "                       [ 0.0729,  0.0294, -0.0500, -0.0591,  0.0400],\n",
       "                       ...,\n",
       "                       [-0.1481,  0.0661,  0.0523, -0.0160,  0.0190],\n",
       "                       [ 0.0876,  0.0092,  0.0145, -0.0134, -0.1215],\n",
       "                       [ 0.0388,  0.1000,  0.1322, -0.0559,  0.1115]]], dtype=torch.float64)),\n",
       "             ('6.19.convs.1.1.weight',\n",
       "              tensor([0.9854, 0.9772, 0.9586, 0.9698, 0.9546, 0.9785, 0.9591, 0.9452, 0.9358,\n",
       "                      0.9381, 0.9514, 0.9844, 0.9680, 0.9707, 0.9283, 0.9679, 0.9576, 0.9826,\n",
       "                      0.9592, 0.9798, 0.9548, 0.9960, 0.9639, 0.9595, 0.9699, 0.9628, 0.9560,\n",
       "                      0.9582, 0.9932, 1.0024, 0.9836, 0.9702, 0.9626, 0.9779, 0.9211, 0.9636,\n",
       "                      0.9846, 0.9447, 0.9561, 0.9486, 0.9418, 0.9346, 0.9613, 0.9692, 1.0056,\n",
       "                      0.9570, 0.9559, 0.9564, 0.9965, 0.9589, 0.9799, 0.9652, 0.9894, 0.9469,\n",
       "                      0.9864, 0.9511, 0.9373, 0.9645, 0.9467, 0.9789, 0.9695, 0.9466, 0.9587,\n",
       "                      0.9868], dtype=torch.float64)),\n",
       "             ('6.19.convs.1.1.bias',\n",
       "              tensor([ 0.0189,  0.0067,  0.0051,  0.0044, -0.0194,  0.0132, -0.0118, -0.0287,\n",
       "                       0.0040,  0.0007, -0.0265, -0.0091, -0.0233,  0.0129, -0.0266,  0.0060,\n",
       "                      -0.0025,  0.0012, -0.0061, -0.0023, -0.0109, -0.0014,  0.0093,  0.0049,\n",
       "                       0.0071, -0.0071, -0.0114,  0.0026,  0.0002,  0.0190, -0.0305, -0.0072,\n",
       "                       0.0082, -0.0015, -0.0130,  0.0010,  0.0272, -0.0126, -0.0106, -0.0003,\n",
       "                      -0.0254, -0.0387, -0.0120,  0.0103, -0.0037, -0.0085,  0.0028,  0.0035,\n",
       "                       0.0182, -0.0046,  0.0323,  0.0015,  0.0018, -0.0021,  0.0128, -0.0015,\n",
       "                      -0.0285, -0.0041, -0.0327,  0.0104, -0.0117, -0.0086, -0.0268,  0.0189],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.19.convs.1.1.running_mean',\n",
       "              tensor([-0.5928,  0.4752, -0.6233,  0.0427,  0.3794,  0.6618,  0.1289, -0.1337,\n",
       "                      -0.7683, -0.7071,  0.7596, -0.4342,  0.4187, -0.3059,  0.1674,  0.4107,\n",
       "                       0.4373, -0.1382,  0.1947, -0.5036,  0.3961,  0.3380, -0.1310, -0.2714,\n",
       "                      -0.4456, -0.8531, -0.3238, -0.4221,  0.5841,  0.6657, -0.3842,  0.5015,\n",
       "                      -0.5533,  1.1292, -0.6113,  0.5296, -0.1887,  0.7650, -0.2793, -1.5744,\n",
       "                      -0.5374, -0.0544,  0.1547, -0.3493,  0.2678,  0.5066, -0.3600, -0.5852,\n",
       "                      -0.1266,  0.0696, -0.8083,  0.3702, -0.2838, -0.8286,  0.3888, -0.6621,\n",
       "                      -0.4211, -0.0509, -0.2778, -0.2576,  0.3087,  0.1847, -0.5284, -0.0500],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.19.convs.1.1.running_var',\n",
       "              tensor([1.0307, 0.5464, 0.4976, 0.5659, 0.7815, 0.3228, 0.8903, 0.7220, 0.6383,\n",
       "                      0.6007, 0.5564, 0.4324, 0.6375, 0.4143, 0.6234, 0.5191, 0.7773, 0.5040,\n",
       "                      0.7775, 0.7485, 0.6540, 0.6999, 0.7966, 0.7159, 0.8776, 0.5601, 0.6416,\n",
       "                      0.6073, 0.5239, 0.7212, 1.3477, 1.1656, 1.2305, 0.6658, 0.8735, 0.6730,\n",
       "                      0.3857, 0.5948, 0.8603, 0.9221, 0.7339, 0.5856, 0.4816, 0.4837, 0.6153,\n",
       "                      0.7093, 0.8636, 0.9905, 0.5833, 0.6152, 0.6400, 0.9273, 0.5936, 0.6099,\n",
       "                      0.6584, 0.5396, 0.6721, 0.9188, 0.5512, 0.9061, 0.4455, 0.6003, 0.6007,\n",
       "                      0.5200], dtype=torch.float64)),\n",
       "             ('6.19.convs.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.19.convs.2.0.weight',\n",
       "              tensor([[[ 0.0797],\n",
       "                       [-0.0102],\n",
       "                       [ 0.0596],\n",
       "                       ...,\n",
       "                       [ 0.2428],\n",
       "                       [ 0.1211],\n",
       "                       [ 0.0528]],\n",
       "              \n",
       "                      [[-0.0220],\n",
       "                       [ 0.1337],\n",
       "                       [-0.1664],\n",
       "                       ...,\n",
       "                       [ 0.0216],\n",
       "                       [ 0.1583],\n",
       "                       [ 0.0961]],\n",
       "              \n",
       "                      [[ 0.1662],\n",
       "                       [-0.0966],\n",
       "                       [ 0.0320],\n",
       "                       ...,\n",
       "                       [ 0.1126],\n",
       "                       [ 0.1122],\n",
       "                       [ 0.1576]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0625],\n",
       "                       [ 0.2303],\n",
       "                       [ 0.0232],\n",
       "                       ...,\n",
       "                       [ 0.1938],\n",
       "                       [-0.0746],\n",
       "                       [-0.2493]],\n",
       "              \n",
       "                      [[ 0.1689],\n",
       "                       [-0.0716],\n",
       "                       [ 0.0050],\n",
       "                       ...,\n",
       "                       [ 0.0837],\n",
       "                       [-0.1406],\n",
       "                       [-0.0357]],\n",
       "              \n",
       "                      [[ 0.1402],\n",
       "                       [ 0.0852],\n",
       "                       [-0.0055],\n",
       "                       ...,\n",
       "                       [-0.1540],\n",
       "                       [ 0.2255],\n",
       "                       [-0.0104]]], dtype=torch.float64)),\n",
       "             ('6.19.convs.2.1.weight',\n",
       "              tensor([ 2.5642e-02,  8.4580e-03, -4.8173e-03, -4.9446e-04,  1.3209e-02,\n",
       "                      -2.9487e-02,  2.0291e-02,  2.4041e-03,  2.3538e-04, -3.7390e-03,\n",
       "                      -1.0076e-02,  1.8152e-02,  9.8603e-03, -1.7469e-02,  1.2249e-02,\n",
       "                      -3.9430e-02,  3.6992e-02, -1.0561e-02,  1.3577e-02,  2.3682e-02,\n",
       "                      -1.7785e-02,  1.1457e-02,  3.7826e-03, -2.4202e-02,  2.8240e-03,\n",
       "                      -3.7078e-02, -3.4709e-03, -1.6482e-04, -2.7158e-02,  8.4474e-03,\n",
       "                       4.2631e-03, -3.0330e-02, -2.9785e-03, -1.5166e-02, -4.0212e-02,\n",
       "                      -2.7101e-02,  1.9115e-03, -9.6038e-03, -6.8617e-03,  6.7111e-04,\n",
       "                      -6.8956e-03, -1.8139e-02, -9.8092e-04,  1.3832e-02, -5.0147e-03,\n",
       "                      -2.9889e-03,  1.8575e-02,  5.7270e-03,  1.9845e-02, -1.4142e-02,\n",
       "                      -7.2997e-03,  1.5792e-02, -2.7999e-03, -1.1880e-02,  2.8977e-02,\n",
       "                      -3.8239e-02, -1.8930e-02, -1.6091e-02, -1.1582e-02,  1.1376e-02,\n",
       "                       6.2557e-03, -4.3417e-03, -1.2699e-02, -3.3392e-05,  3.2460e-02,\n",
       "                       9.4697e-03,  2.8259e-02,  2.4293e-03,  3.7619e-02,  3.6423e-02,\n",
       "                       1.7905e-02,  2.5833e-03,  1.8416e-02, -1.5838e-02,  3.7919e-03,\n",
       "                      -6.8733e-03,  7.6757e-03, -2.7425e-02, -6.8777e-03, -1.9252e-02,\n",
       "                       2.0784e-02, -1.5466e-02,  1.1911e-02, -1.4919e-02,  1.5543e-02,\n",
       "                       3.7667e-03, -3.2947e-02, -1.7854e-02, -3.4302e-03, -1.1307e-03,\n",
       "                       3.0725e-02, -1.9104e-02,  3.3421e-03, -2.1570e-03,  7.6046e-03,\n",
       "                       2.1950e-02,  5.0224e-03, -2.4202e-02, -1.7812e-02,  1.4054e-02,\n",
       "                       1.4697e-02,  1.0055e-02,  3.6937e-02, -1.3041e-02, -1.0499e-02,\n",
       "                       2.1797e-02, -2.2166e-02,  2.2993e-02,  3.9294e-02, -1.8800e-02,\n",
       "                       1.3852e-02,  3.7469e-02,  2.5107e-02, -4.4953e-03,  4.8752e-03,\n",
       "                       5.3893e-02, -1.4162e-02,  1.9378e-02, -9.1012e-03, -4.9546e-03,\n",
       "                       5.8681e-03,  1.3361e-02, -4.6484e-03,  9.6366e-03,  1.7023e-02,\n",
       "                       1.4821e-02, -1.5190e-02,  1.8107e-02,  9.8599e-03,  1.2751e-02,\n",
       "                      -1.3604e-02, -2.4777e-02, -1.2270e-02, -2.8400e-02,  2.3828e-02,\n",
       "                      -2.2001e-02, -1.6476e-02, -8.7873e-04, -2.2996e-02, -1.3663e-02,\n",
       "                       8.9200e-03,  7.1816e-03,  2.5577e-02,  1.0948e-02, -2.4022e-02,\n",
       "                      -5.4403e-03,  3.3081e-02,  1.8847e-02,  1.9761e-02,  3.4166e-02,\n",
       "                      -1.1408e-02, -2.9594e-02,  3.5449e-02, -2.4427e-02,  2.2056e-02,\n",
       "                       5.0418e-03, -1.4556e-02,  6.1573e-03, -5.4429e-03,  2.3332e-02,\n",
       "                      -2.4918e-02,  1.6788e-04,  3.3074e-03,  1.3567e-02,  3.2918e-02,\n",
       "                       1.2756e-02, -3.8438e-03,  6.0706e-03,  8.5753e-04,  2.4783e-02,\n",
       "                       1.7048e-02,  1.3910e-02, -2.6020e-02,  2.6514e-02,  3.5533e-03,\n",
       "                      -1.1540e-02, -6.3640e-03, -1.0191e-03, -6.3798e-04, -1.3322e-02,\n",
       "                       2.5359e-02,  1.3001e-02, -1.0785e-03,  1.2665e-02, -1.7876e-02,\n",
       "                       4.0294e-02, -8.1248e-03,  1.7187e-02,  3.9423e-03,  9.3750e-03,\n",
       "                       8.6104e-04, -3.5274e-03, -7.4409e-03,  4.9900e-03,  1.4811e-02,\n",
       "                      -4.0469e-02, -1.0745e-02, -6.5732e-03,  9.6444e-03, -6.4943e-03,\n",
       "                      -3.4300e-03, -7.9677e-03, -1.8368e-02,  1.3603e-02,  2.8427e-02,\n",
       "                       9.3733e-03,  2.0542e-02,  1.4194e-02, -1.1689e-02,  1.4431e-02,\n",
       "                      -7.5627e-03, -2.1449e-03,  4.1732e-03,  4.3689e-02,  1.5029e-02,\n",
       "                       4.4983e-03, -3.0290e-02, -6.8898e-03, -1.1102e-03, -1.5572e-03,\n",
       "                       1.1373e-02, -7.2241e-04, -3.6555e-03, -1.9394e-02,  2.4366e-02,\n",
       "                       3.1652e-03, -8.9972e-03,  2.5415e-02,  7.2177e-03,  1.7781e-02,\n",
       "                       4.3796e-04, -1.3753e-02,  2.1411e-02, -6.5026e-03, -3.0598e-02,\n",
       "                      -1.3901e-02,  1.9894e-02,  1.6247e-02,  1.4317e-02, -9.8724e-04,\n",
       "                      -1.5569e-02,  1.5917e-02, -1.1595e-02,  6.6037e-03,  1.4463e-02,\n",
       "                      -5.3876e-04, -1.8056e-03,  4.6114e-03, -1.8690e-02, -1.2095e-03,\n",
       "                      -1.7851e-02, -6.0589e-03,  1.1632e-02, -1.1150e-02,  1.4940e-02,\n",
       "                      -1.7556e-02], dtype=torch.float64)),\n",
       "             ('6.19.convs.2.1.bias',\n",
       "              tensor([ 5.5795e-03,  6.8452e-03,  1.3027e-02,  1.3996e-02, -1.5968e-03,\n",
       "                       7.1464e-03,  4.0992e-03,  3.7857e-03,  7.6059e-03,  3.2851e-03,\n",
       "                       1.4242e-02, -6.4224e-03,  4.2620e-03,  9.4007e-04,  5.9677e-04,\n",
       "                       5.3216e-03,  2.5768e-02,  1.3462e-03,  1.0280e-02, -3.3940e-03,\n",
       "                      -7.9514e-03,  1.3612e-03,  7.9924e-03,  4.8551e-03,  1.5408e-02,\n",
       "                      -1.4372e-02,  5.6363e-03,  7.3427e-03,  1.0387e-02, -6.6261e-03,\n",
       "                      -4.4624e-03,  1.8424e-02,  5.1608e-03,  1.4987e-02,  1.2605e-02,\n",
       "                       1.4338e-02,  1.1324e-02,  6.6319e-03,  1.5994e-02,  4.6495e-04,\n",
       "                       8.7336e-03,  9.9964e-03, -2.4465e-03, -6.0165e-03,  8.5780e-03,\n",
       "                      -1.6520e-02,  1.3089e-02,  3.9584e-03, -1.1820e-02,  3.2972e-03,\n",
       "                       9.8129e-03,  2.5974e-03,  7.5514e-03,  2.0750e-02,  4.0634e-04,\n",
       "                       1.4957e-02,  1.0559e-02,  5.1121e-03,  5.1806e-03, -2.9122e-03,\n",
       "                       8.0817e-04,  3.6802e-04,  1.4792e-02,  5.3082e-03, -1.1777e-02,\n",
       "                       4.5985e-04, -7.8810e-05,  1.0087e-02,  1.7604e-02, -1.3171e-02,\n",
       "                       8.0979e-03, -1.7241e-03, -9.4438e-04, -8.3990e-03,  1.1979e-02,\n",
       "                       7.6170e-03,  4.7734e-03,  1.8051e-02,  3.0206e-04,  9.0756e-03,\n",
       "                       3.3894e-03, -1.0864e-02,  1.8498e-02,  4.3812e-03, -7.3263e-03,\n",
       "                       2.1294e-02,  2.2070e-04,  1.0547e-02,  1.2104e-02, -3.1122e-03,\n",
       "                       3.0811e-03,  1.2447e-02,  8.4645e-03, -2.9774e-03,  3.8647e-03,\n",
       "                      -7.0275e-03,  1.1523e-02,  2.6896e-03,  1.9267e-02,  6.4599e-03,\n",
       "                       2.4632e-02,  1.3974e-02,  5.1281e-03,  1.0933e-02,  4.2280e-03,\n",
       "                      -5.4675e-03,  4.7855e-03,  1.1219e-02,  4.1039e-03,  4.6562e-03,\n",
       "                      -9.1134e-04, -5.5956e-03,  5.5832e-03,  2.0898e-02,  1.5679e-02,\n",
       "                      -1.3077e-03,  4.2575e-03,  7.3684e-04, -1.3083e-03, -4.2507e-03,\n",
       "                       5.5670e-05,  1.2555e-02,  6.3002e-03,  6.6684e-04,  1.6028e-02,\n",
       "                       4.0528e-03,  9.2572e-03,  3.9450e-03,  5.5439e-03,  1.3665e-02,\n",
       "                       6.2590e-03,  3.5932e-03,  9.4597e-03,  3.6877e-04,  4.5255e-03,\n",
       "                      -1.4191e-02,  8.4326e-03,  4.0407e-03,  7.4254e-03,  1.1482e-02,\n",
       "                       2.6038e-02,  1.5751e-02,  5.9726e-03,  1.9073e-03, -5.9728e-03,\n",
       "                       6.4643e-03,  3.7168e-03,  4.2105e-03,  1.1550e-03, -5.6850e-05,\n",
       "                       1.0249e-02,  6.8243e-03,  2.3168e-03,  1.0297e-02,  1.3657e-02,\n",
       "                       2.2880e-03, -5.2862e-03,  4.4627e-03,  6.7281e-03,  9.7064e-04,\n",
       "                       6.5972e-03,  9.0131e-03, -1.4831e-03,  5.8038e-03,  1.0834e-02,\n",
       "                      -5.5050e-03, -1.0966e-02,  5.5163e-03,  1.1194e-02,  1.1666e-02,\n",
       "                       1.3355e-02,  2.3986e-03,  1.3743e-02,  1.4511e-02, -1.4481e-02,\n",
       "                       1.6554e-03, -3.8071e-03,  1.4000e-02, -3.6034e-03,  3.6123e-03,\n",
       "                       3.5138e-03,  1.3401e-02, -2.8651e-03, -7.4266e-03,  8.4105e-03,\n",
       "                       6.2168e-03,  1.0858e-02,  5.8692e-03,  1.3663e-02,  5.5727e-03,\n",
       "                       3.5659e-03,  8.1475e-03,  4.6109e-03,  8.9707e-03,  9.1123e-03,\n",
       "                       8.1295e-03,  1.1478e-02, -1.1042e-03,  3.3490e-03,  7.2678e-03,\n",
       "                      -3.5186e-03,  2.1046e-02,  1.7184e-02,  1.5737e-02,  1.5109e-02,\n",
       "                       7.4730e-03,  1.4879e-02, -8.9731e-03,  3.2758e-03,  6.5919e-03,\n",
       "                       2.8882e-03,  1.0140e-02, -4.5578e-03,  1.2943e-02,  8.4944e-03,\n",
       "                       3.3985e-03,  3.1783e-03,  1.8979e-02,  1.3290e-03, -1.2039e-03,\n",
       "                       1.8321e-02,  7.8887e-03,  1.0324e-03,  1.3165e-02,  1.1563e-02,\n",
       "                       5.0112e-03, -6.9181e-03, -5.3101e-03,  2.6231e-02,  1.8432e-02,\n",
       "                       9.1612e-04, -1.7465e-03,  1.3066e-02,  1.2667e-02, -5.3628e-03,\n",
       "                       3.7116e-03, -4.1852e-03,  8.9871e-03,  2.8716e-03,  1.5833e-02,\n",
       "                      -5.2716e-03,  9.9374e-04, -8.9385e-03,  1.2544e-02,  2.3159e-04,\n",
       "                       3.1393e-03,  5.2788e-03, -1.2344e-04, -2.6189e-02, -1.1535e-02,\n",
       "                       1.8015e-02,  1.7858e-02,  8.8621e-03,  1.8253e-02,  3.3046e-03,\n",
       "                       8.0231e-04], dtype=torch.float64)),\n",
       "             ('6.19.convs.2.1.running_mean',\n",
       "              tensor([ 4.6563e-01, -3.4816e-01,  4.7304e-01,  6.3204e-01,  9.7278e-03,\n",
       "                      -2.3532e-01, -9.3138e-02, -1.7648e-01, -2.0710e-01, -3.3035e-01,\n",
       "                      -7.0218e-01, -6.9077e-02,  2.9301e-02,  1.1658e-01, -3.3423e-01,\n",
       "                      -3.4745e-02,  4.7870e-01, -3.3121e-02,  2.1530e-01, -3.3713e-01,\n",
       "                       4.3058e-01,  1.4090e-01, -1.0053e-01,  7.5492e-02,  8.6351e-02,\n",
       "                       6.1790e-01,  1.8424e-01,  1.1125e-01, -5.5139e-02,  2.7138e-01,\n",
       "                       1.8303e-01, -4.4575e-01, -3.4503e-01, -6.8247e-04,  5.2191e-02,\n",
       "                      -1.5672e-01,  6.8534e-02,  4.5404e-01,  4.7735e-01, -2.4491e-01,\n",
       "                       2.6441e-01,  8.4410e-02, -2.7534e-01, -7.4926e-02, -5.1675e-01,\n",
       "                      -8.8760e-03, -2.3826e-03,  2.6709e-01, -3.5656e-01, -1.3981e-02,\n",
       "                       4.9776e-02,  1.7527e-01,  3.6491e-02,  7.1266e-01,  6.4192e-01,\n",
       "                       8.7452e-02, -3.3114e-01,  3.7922e-02, -2.8434e-01,  5.2543e-01,\n",
       "                      -4.8034e-02,  5.7596e-01,  1.2587e-01, -1.7413e-01, -6.3395e-01,\n",
       "                       3.8107e-01,  4.6375e-01, -2.6954e-01,  1.4986e-01, -2.7817e-01,\n",
       "                       3.4784e-01,  8.9721e-01, -4.9930e-02, -1.0327e+00, -2.3148e-01,\n",
       "                       4.2404e-02, -6.7433e-01,  3.5453e-01, -3.8668e-01, -2.9126e-01,\n",
       "                       3.8084e-01, -4.3838e-01, -1.2300e-01,  4.8746e-01,  2.8548e-01,\n",
       "                      -5.3066e-02,  4.5110e-01,  3.8671e-01,  4.0836e-01, -2.3824e-01,\n",
       "                       6.9267e-02,  2.3549e-03, -3.8494e-01, -8.0819e-02, -1.4605e-01,\n",
       "                      -1.5555e-01, -4.2562e-01, -7.5378e-01, -1.5044e-01, -5.7594e-01,\n",
       "                      -1.0600e+00,  1.4572e-01,  5.6451e-01,  7.1868e-02, -6.1224e-01,\n",
       "                      -1.1158e-01,  1.3358e-01,  6.8077e-01,  4.1712e-01,  2.9568e-01,\n",
       "                       5.2029e-01, -1.1982e-01,  2.1936e-01,  3.8868e-02, -6.9053e-02,\n",
       "                      -1.8599e-01, -4.0702e-01, -4.7971e-01,  1.4578e-01, -7.2118e-01,\n",
       "                       1.3920e-01, -5.8302e-01, -1.5235e-01,  1.0100e-01, -3.3491e-01,\n",
       "                      -1.3602e-01, -1.1133e-01,  5.8465e-02,  1.2921e-01,  2.0191e-01,\n",
       "                      -5.6975e-04, -2.7403e-01, -4.2124e-01,  5.0644e-01, -2.2896e-01,\n",
       "                       6.4109e-01, -1.8716e-01,  4.4038e-02, -7.7396e-02, -8.6320e-02,\n",
       "                       2.7824e-01, -2.5178e-01,  4.1393e-01, -6.3122e-02,  2.6609e-02,\n",
       "                       5.0872e-01,  4.7795e-01, -4.7177e-02,  1.1216e-01,  4.0698e-01,\n",
       "                       2.7063e-01,  1.5148e-01,  2.0920e-02,  5.7333e-01, -7.2754e-01,\n",
       "                      -1.0667e-02, -2.8255e-01,  2.6180e-02,  5.8384e-01, -2.6073e-01,\n",
       "                      -5.6122e-01,  7.5266e-02, -2.9557e-01, -2.4874e-01, -6.1147e-01,\n",
       "                      -1.7894e-01,  1.2616e-02, -1.3509e-01,  2.9992e-03, -5.8052e-01,\n",
       "                       4.7149e-02,  4.8902e-01, -1.1700e-01, -2.7034e-01,  3.2961e-01,\n",
       "                      -3.5747e-01,  3.7908e-02,  2.7772e-02, -1.2957e-01,  6.6487e-02,\n",
       "                      -1.6610e-01, -9.8769e-02,  3.5037e-02,  2.2840e-01,  2.4427e-01,\n",
       "                      -1.0658e-01,  6.9748e-01,  7.1381e-02,  8.5652e-02,  5.8543e-01,\n",
       "                      -3.3029e-01,  1.7319e-01,  4.5155e-01,  1.8966e-01,  9.9249e-02,\n",
       "                       2.5932e-01, -5.4634e-01,  3.6261e-01,  2.4419e-01, -3.6525e-01,\n",
       "                      -2.3492e-01, -9.7841e-02,  2.2012e-01, -7.3702e-01, -5.4523e-01,\n",
       "                       5.9148e-02,  1.1227e-01, -1.5223e-02,  5.0568e-03,  2.6028e-01,\n",
       "                      -1.4641e-01,  4.4206e-01,  4.6827e-02, -4.7252e-01, -2.4931e-01,\n",
       "                      -1.7327e-01, -5.3082e-01, -5.1788e-01,  4.8424e-02,  1.1789e-01,\n",
       "                       1.2217e-01,  4.4098e-02, -3.1413e-01,  7.2869e-01, -9.1709e-01,\n",
       "                      -1.2146e-01, -1.4294e-01, -2.3664e-02, -2.5959e-01, -5.9141e-02,\n",
       "                      -1.9730e-01,  4.2915e-03,  4.2853e-01, -6.5367e-01, -6.0749e-01,\n",
       "                       2.5845e-01,  3.1770e-01,  1.7928e-01,  8.5676e-02, -4.1451e-01,\n",
       "                      -2.5173e-01,  4.2405e-01,  5.2295e-01, -4.0515e-01, -8.7854e-02,\n",
       "                       1.2757e-01, -1.4580e-01,  1.4460e-01,  5.1708e-02, -8.3048e-03,\n",
       "                      -6.2309e-01, -1.7422e-01, -5.0098e-01,  6.4917e-01, -4.7236e-01,\n",
       "                       3.5787e-02], dtype=torch.float64)),\n",
       "             ('6.19.convs.2.1.running_var',\n",
       "              tensor([0.5134, 0.4325, 0.1983, 0.6342, 0.3373, 0.3455, 0.3954, 0.3193, 0.2742,\n",
       "                      0.4187, 0.3627, 0.3761, 0.1793, 0.4352, 0.1900, 0.5649, 0.5326, 0.3870,\n",
       "                      0.2241, 0.4234, 0.4342, 0.6256, 0.5527, 0.4402, 0.3814, 0.4537, 0.3875,\n",
       "                      0.1738, 0.4370, 0.2759, 0.2520, 0.6207, 0.1247, 0.2877, 0.2704, 0.5901,\n",
       "                      0.1621, 0.3926, 0.2081, 0.3508, 0.3355, 0.1718, 0.0503, 0.4076, 0.2696,\n",
       "                      0.3421, 0.3347, 0.3705, 0.3099, 0.3521, 0.2363, 0.2508, 0.3277, 0.4268,\n",
       "                      0.5970, 0.5193, 0.2602, 0.4151, 0.2855, 0.2324, 0.2513, 0.2916, 0.2816,\n",
       "                      0.1003, 0.4265, 0.3067, 0.3697, 0.2170, 0.2707, 0.2727, 0.3060, 0.2662,\n",
       "                      0.3292, 0.5290, 0.2870, 0.1694, 0.3984, 0.3518, 0.4821, 0.1801, 0.5990,\n",
       "                      0.2890, 0.3063, 0.5041, 0.3122, 0.4221, 0.3611, 0.3865, 0.2048, 0.1861,\n",
       "                      0.6148, 0.4104, 0.3192, 0.1180, 0.1598, 0.3434, 0.2847, 0.3921, 0.2627,\n",
       "                      0.2892, 0.5259, 0.2490, 0.2245, 0.2558, 0.2766, 0.2692, 0.4599, 0.3815,\n",
       "                      0.6175, 0.2056, 0.2523, 0.4830, 0.6354, 0.1646, 0.3105, 0.3987, 0.3158,\n",
       "                      0.4761, 0.2604, 0.7351, 0.0376, 0.3755, 0.5876, 0.2159, 0.2582, 0.3784,\n",
       "                      0.3223, 0.2443, 0.1142, 0.7720, 0.1374, 0.4067, 0.5944, 0.3025, 0.3142,\n",
       "                      0.3831, 0.3412, 0.1294, 0.5424, 0.3390, 0.3865, 0.3155, 0.3182, 0.1661,\n",
       "                      0.3778, 0.2916, 0.2514, 0.5505, 0.1573, 0.4250, 0.3575, 0.1896, 0.2617,\n",
       "                      0.5433, 0.4804, 0.1807, 0.4113, 0.3352, 0.3466, 0.3594, 0.5993, 0.1370,\n",
       "                      0.0650, 0.2164, 0.4894, 0.4464, 0.4413, 0.1607, 0.2144, 0.3155, 0.2865,\n",
       "                      0.3933, 0.4302, 0.2372, 0.3917, 0.4778, 0.2297, 0.2884, 0.1655, 0.3402,\n",
       "                      0.6513, 0.2633, 0.3002, 0.4044, 0.3371, 0.4165, 0.3335, 0.2477, 0.1975,\n",
       "                      0.3340, 0.1174, 0.1793, 0.1944, 0.2828, 0.2714, 0.3109, 0.4287, 0.1807,\n",
       "                      0.3260, 0.4032, 0.1769, 0.2604, 0.2938, 0.3250, 0.3376, 0.3443, 0.2208,\n",
       "                      0.1547, 0.2426, 0.4781, 0.1359, 0.2274, 0.1359, 0.8513, 0.2469, 0.1483,\n",
       "                      0.3002, 0.2571, 0.1664, 0.4263, 0.2461, 0.1977, 0.1077, 0.3126, 0.5675,\n",
       "                      0.2108, 0.1386, 0.4669, 0.5812, 0.4779, 0.2133, 0.1663, 0.4578, 0.2748,\n",
       "                      0.3831, 0.2817, 0.4702, 0.3001, 0.3737, 0.3382, 0.1635, 0.1979, 0.4303,\n",
       "                      0.2696, 0.2337, 0.1974, 0.1061, 0.4901, 0.2056, 0.2740, 0.7442, 0.3983,\n",
       "                      0.1774, 0.3929, 0.2224, 0.2557], dtype=torch.float64)),\n",
       "             ('6.19.convs.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.19.convpath.0.0.0.weight',\n",
       "              tensor([[[-0.0309],\n",
       "                       [ 0.0352],\n",
       "                       [-0.0062],\n",
       "                       ...,\n",
       "                       [ 0.0164],\n",
       "                       [-0.1095],\n",
       "                       [ 0.1249]],\n",
       "              \n",
       "                      [[ 0.0469],\n",
       "                       [-0.0528],\n",
       "                       [-0.0574],\n",
       "                       ...,\n",
       "                       [-0.0871],\n",
       "                       [ 0.0535],\n",
       "                       [-0.0431]],\n",
       "              \n",
       "                      [[-0.0536],\n",
       "                       [ 0.1097],\n",
       "                       [ 0.0267],\n",
       "                       ...,\n",
       "                       [ 0.1238],\n",
       "                       [-0.1016],\n",
       "                       [-0.0073]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1524],\n",
       "                       [-0.1054],\n",
       "                       [ 0.0396],\n",
       "                       ...,\n",
       "                       [-0.0170],\n",
       "                       [-0.0055],\n",
       "                       [-0.0294]],\n",
       "              \n",
       "                      [[-0.0636],\n",
       "                       [ 0.0465],\n",
       "                       [-0.1090],\n",
       "                       ...,\n",
       "                       [-0.0072],\n",
       "                       [ 0.0397],\n",
       "                       [-0.0325]],\n",
       "              \n",
       "                      [[ 0.1725],\n",
       "                       [ 0.1143],\n",
       "                       [ 0.0235],\n",
       "                       ...,\n",
       "                       [-0.0319],\n",
       "                       [ 0.0712],\n",
       "                       [ 0.0875]]], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.0.1.weight',\n",
       "              tensor([0.9465, 0.9673, 0.9610, 0.9982, 0.9627, 0.9206, 0.9613, 0.9774, 0.9680,\n",
       "                      0.9548, 0.9687, 0.9728, 0.9534, 0.9651, 0.9637, 0.9550, 0.9873, 0.9821,\n",
       "                      0.9950, 0.9775, 0.9508, 0.9539, 0.9569, 0.9602, 0.9906, 0.9584, 0.9734,\n",
       "                      0.9563, 0.9670, 0.9598, 0.9677, 0.9615, 0.9995, 0.9924, 0.9926, 0.9774,\n",
       "                      0.9630, 0.9691, 0.9840, 0.9736, 0.9810, 0.9847, 0.9664, 0.9729, 0.9663,\n",
       "                      0.9759, 0.9888, 0.9898, 0.9786, 0.9691, 0.9576, 0.9848, 0.9614, 0.9877,\n",
       "                      0.9785, 1.0056, 0.9587, 0.9637, 0.9717, 0.9649, 0.9715, 0.9830, 0.9343,\n",
       "                      0.9689], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.0.1.bias',\n",
       "              tensor([ 0.0004,  0.0010,  0.0090,  0.0118, -0.0161, -0.0230,  0.0081,  0.0007,\n",
       "                      -0.0011, -0.0010, -0.0007,  0.0052, -0.0120, -0.0151,  0.0100, -0.0061,\n",
       "                       0.0027, -0.0112,  0.0109, -0.0109, -0.0046, -0.0194, -0.0048, -0.0098,\n",
       "                       0.0251,  0.0005, -0.0126,  0.0074,  0.0064, -0.0065,  0.0087, -0.0048,\n",
       "                       0.0267,  0.0263,  0.0099,  0.0038,  0.0168,  0.0078,  0.0081,  0.0054,\n",
       "                       0.0019,  0.0193, -0.0142,  0.0120, -0.0155,  0.0095,  0.0080,  0.0065,\n",
       "                       0.0028, -0.0186, -0.0022,  0.0122, -0.0067, -0.0053, -0.0004,  0.0218,\n",
       "                       0.0016,  0.0023,  0.0117, -0.0185,  0.0077,  0.0066,  0.0057, -0.0242],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.0.1.running_mean',\n",
       "              tensor([-0.0352,  0.1269,  1.0086, -0.5691,  0.4288,  0.1688,  0.6714,  0.3483,\n",
       "                       1.6770, -0.5643,  0.3108,  0.5974,  0.1055,  0.6841,  0.4968,  1.0746,\n",
       "                       0.4248, -0.1263,  0.0488,  1.3591,  0.1826,  0.4513, -0.2599, -0.1598,\n",
       "                      -0.3771,  0.4301,  0.3143, -0.1347,  1.0426,  0.4396, -0.5129,  0.8051,\n",
       "                      -0.5000, -0.0382, -0.4156,  0.1962, -0.5401, -0.5085,  0.0811,  0.8767,\n",
       "                       0.5280,  0.4389, -0.1381,  0.2047,  0.2205,  0.3668, -0.7498, -0.9375,\n",
       "                       0.2150,  0.7657, -0.0034,  0.6661, -0.1777,  0.1903, -1.2948,  0.3198,\n",
       "                       0.3274, -0.1673, -0.3854,  0.8866,  0.0911, -0.0436, -1.5243, -0.7568],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.0.1.running_var',\n",
       "              tensor([0.6753, 0.6099, 0.1485, 0.1127, 0.4499, 0.1259, 0.3177, 0.1275, 0.3582,\n",
       "                      0.1177, 0.1491, 0.1335, 0.1072, 0.1845, 0.3260, 0.5314, 0.1514, 0.1063,\n",
       "                      0.1642, 0.6159, 0.2689, 0.0986, 0.2813, 0.1059, 0.2782, 0.4126, 0.2184,\n",
       "                      0.3942, 0.3670, 0.6785, 0.2573, 0.6176, 0.1335, 0.2136, 0.1746, 0.1991,\n",
       "                      0.2718, 0.2110, 0.0934, 0.3661, 0.3891, 0.1652, 0.1269, 0.1293, 0.1617,\n",
       "                      0.5399, 0.2253, 0.1296, 0.4586, 0.1804, 0.7872, 0.2141, 0.2740, 0.1984,\n",
       "                      0.1814, 0.1486, 0.2788, 0.1341, 0.1227, 0.2549, 0.4101, 0.1312, 0.5740,\n",
       "                      0.1581], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.19.convpath.0.1.0.weight',\n",
       "              tensor([[[ 0.1165, -0.1736,  0.0306, -0.0704, -0.0433],\n",
       "                       [ 0.0334, -0.0367, -0.0195,  0.0504, -0.1455],\n",
       "                       [ 0.1327,  0.0585, -0.0744,  0.0926,  0.0495],\n",
       "                       ...,\n",
       "                       [-0.0434,  0.1077, -0.0595,  0.0033,  0.0543],\n",
       "                       [-0.0087,  0.1416, -0.0783,  0.0033, -0.0156],\n",
       "                       [ 0.0259,  0.0772, -0.0559,  0.0033, -0.0133]],\n",
       "              \n",
       "                      [[-0.0969, -0.1059, -0.1564, -0.0751, -0.1244],\n",
       "                       [-0.1024, -0.0131, -0.1156,  0.0490, -0.0207],\n",
       "                       [ 0.0746,  0.0309, -0.0064,  0.0696, -0.0899],\n",
       "                       ...,\n",
       "                       [ 0.0702, -0.0677,  0.0464, -0.0528,  0.0621],\n",
       "                       [-0.1095,  0.0752,  0.0498, -0.0710, -0.0553],\n",
       "                       [ 0.0399,  0.1017, -0.1137,  0.1110, -0.0143]],\n",
       "              \n",
       "                      [[ 0.0486,  0.1574, -0.0219, -0.0175,  0.0295],\n",
       "                       [-0.0751, -0.2239,  0.0829,  0.0138,  0.0032],\n",
       "                       [ 0.0452, -0.0014, -0.0441, -0.1438, -0.0019],\n",
       "                       ...,\n",
       "                       [-0.0967, -0.0573,  0.0150, -0.1774,  0.0102],\n",
       "                       [-0.1442,  0.1391,  0.0036,  0.0125, -0.0165],\n",
       "                       [ 0.0196, -0.0220,  0.0362,  0.0105,  0.0080]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0459, -0.0270,  0.0123, -0.0173, -0.0490],\n",
       "                       [-0.0014, -0.0581, -0.0340,  0.0084, -0.1285],\n",
       "                       [ 0.0311,  0.0581,  0.0909,  0.0502, -0.0235],\n",
       "                       ...,\n",
       "                       [-0.0576, -0.0291, -0.1795, -0.0349,  0.1208],\n",
       "                       [-0.0633, -0.0917,  0.0608,  0.0222,  0.1170],\n",
       "                       [ 0.0178, -0.0665, -0.0138,  0.1873,  0.0839]],\n",
       "              \n",
       "                      [[-0.0355, -0.0649,  0.0332, -0.0104, -0.0937],\n",
       "                       [ 0.0547,  0.0169,  0.0314,  0.0078, -0.0403],\n",
       "                       [ 0.0762, -0.0570, -0.0565, -0.0390,  0.0486],\n",
       "                       ...,\n",
       "                       [-0.0129,  0.0333, -0.0114, -0.0347, -0.0766],\n",
       "                       [-0.0408,  0.0754, -0.0126,  0.0182, -0.0775],\n",
       "                       [-0.0025,  0.0352,  0.1216,  0.1075, -0.1832]],\n",
       "              \n",
       "                      [[ 0.0954,  0.0212, -0.0932,  0.0348, -0.1242],\n",
       "                       [-0.0298, -0.0097, -0.0489,  0.1128, -0.0180],\n",
       "                       [ 0.0729,  0.0294, -0.0500, -0.0591,  0.0400],\n",
       "                       ...,\n",
       "                       [-0.1481,  0.0661,  0.0523, -0.0160,  0.0190],\n",
       "                       [ 0.0876,  0.0092,  0.0145, -0.0134, -0.1215],\n",
       "                       [ 0.0388,  0.1000,  0.1322, -0.0559,  0.1115]]], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.1.1.weight',\n",
       "              tensor([0.9854, 0.9772, 0.9586, 0.9698, 0.9546, 0.9785, 0.9591, 0.9452, 0.9358,\n",
       "                      0.9381, 0.9514, 0.9844, 0.9680, 0.9707, 0.9283, 0.9679, 0.9576, 0.9826,\n",
       "                      0.9592, 0.9798, 0.9548, 0.9960, 0.9639, 0.9595, 0.9699, 0.9628, 0.9560,\n",
       "                      0.9582, 0.9932, 1.0024, 0.9836, 0.9702, 0.9626, 0.9779, 0.9211, 0.9636,\n",
       "                      0.9846, 0.9447, 0.9561, 0.9486, 0.9418, 0.9346, 0.9613, 0.9692, 1.0056,\n",
       "                      0.9570, 0.9559, 0.9564, 0.9965, 0.9589, 0.9799, 0.9652, 0.9894, 0.9469,\n",
       "                      0.9864, 0.9511, 0.9373, 0.9645, 0.9467, 0.9789, 0.9695, 0.9466, 0.9587,\n",
       "                      0.9868], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.1.1.bias',\n",
       "              tensor([ 0.0189,  0.0067,  0.0051,  0.0044, -0.0194,  0.0132, -0.0118, -0.0287,\n",
       "                       0.0040,  0.0007, -0.0265, -0.0091, -0.0233,  0.0129, -0.0266,  0.0060,\n",
       "                      -0.0025,  0.0012, -0.0061, -0.0023, -0.0109, -0.0014,  0.0093,  0.0049,\n",
       "                       0.0071, -0.0071, -0.0114,  0.0026,  0.0002,  0.0190, -0.0305, -0.0072,\n",
       "                       0.0082, -0.0015, -0.0130,  0.0010,  0.0272, -0.0126, -0.0106, -0.0003,\n",
       "                      -0.0254, -0.0387, -0.0120,  0.0103, -0.0037, -0.0085,  0.0028,  0.0035,\n",
       "                       0.0182, -0.0046,  0.0323,  0.0015,  0.0018, -0.0021,  0.0128, -0.0015,\n",
       "                      -0.0285, -0.0041, -0.0327,  0.0104, -0.0117, -0.0086, -0.0268,  0.0189],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.1.1.running_mean',\n",
       "              tensor([-0.5928,  0.4752, -0.6233,  0.0427,  0.3794,  0.6618,  0.1289, -0.1337,\n",
       "                      -0.7683, -0.7071,  0.7596, -0.4342,  0.4187, -0.3059,  0.1674,  0.4107,\n",
       "                       0.4373, -0.1382,  0.1947, -0.5036,  0.3961,  0.3380, -0.1310, -0.2714,\n",
       "                      -0.4456, -0.8531, -0.3238, -0.4221,  0.5841,  0.6657, -0.3842,  0.5015,\n",
       "                      -0.5533,  1.1292, -0.6113,  0.5296, -0.1887,  0.7650, -0.2793, -1.5744,\n",
       "                      -0.5374, -0.0544,  0.1547, -0.3493,  0.2678,  0.5066, -0.3600, -0.5852,\n",
       "                      -0.1266,  0.0696, -0.8083,  0.3702, -0.2838, -0.8286,  0.3888, -0.6621,\n",
       "                      -0.4211, -0.0509, -0.2778, -0.2576,  0.3087,  0.1847, -0.5284, -0.0500],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.1.1.running_var',\n",
       "              tensor([1.0307, 0.5464, 0.4976, 0.5659, 0.7815, 0.3228, 0.8903, 0.7220, 0.6383,\n",
       "                      0.6007, 0.5564, 0.4324, 0.6375, 0.4143, 0.6234, 0.5191, 0.7773, 0.5040,\n",
       "                      0.7775, 0.7485, 0.6540, 0.6999, 0.7966, 0.7159, 0.8776, 0.5601, 0.6416,\n",
       "                      0.6073, 0.5239, 0.7212, 1.3477, 1.1656, 1.2305, 0.6658, 0.8735, 0.6730,\n",
       "                      0.3857, 0.5948, 0.8603, 0.9221, 0.7339, 0.5856, 0.4816, 0.4837, 0.6153,\n",
       "                      0.7093, 0.8636, 0.9905, 0.5833, 0.6152, 0.6400, 0.9273, 0.5936, 0.6099,\n",
       "                      0.6584, 0.5396, 0.6721, 0.9188, 0.5512, 0.9061, 0.4455, 0.6003, 0.6007,\n",
       "                      0.5200], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.19.convpath.0.2.0.weight',\n",
       "              tensor([[[ 0.0797],\n",
       "                       [-0.0102],\n",
       "                       [ 0.0596],\n",
       "                       ...,\n",
       "                       [ 0.2428],\n",
       "                       [ 0.1211],\n",
       "                       [ 0.0528]],\n",
       "              \n",
       "                      [[-0.0220],\n",
       "                       [ 0.1337],\n",
       "                       [-0.1664],\n",
       "                       ...,\n",
       "                       [ 0.0216],\n",
       "                       [ 0.1583],\n",
       "                       [ 0.0961]],\n",
       "              \n",
       "                      [[ 0.1662],\n",
       "                       [-0.0966],\n",
       "                       [ 0.0320],\n",
       "                       ...,\n",
       "                       [ 0.1126],\n",
       "                       [ 0.1122],\n",
       "                       [ 0.1576]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0625],\n",
       "                       [ 0.2303],\n",
       "                       [ 0.0232],\n",
       "                       ...,\n",
       "                       [ 0.1938],\n",
       "                       [-0.0746],\n",
       "                       [-0.2493]],\n",
       "              \n",
       "                      [[ 0.1689],\n",
       "                       [-0.0716],\n",
       "                       [ 0.0050],\n",
       "                       ...,\n",
       "                       [ 0.0837],\n",
       "                       [-0.1406],\n",
       "                       [-0.0357]],\n",
       "              \n",
       "                      [[ 0.1402],\n",
       "                       [ 0.0852],\n",
       "                       [-0.0055],\n",
       "                       ...,\n",
       "                       [-0.1540],\n",
       "                       [ 0.2255],\n",
       "                       [-0.0104]]], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.2.1.weight',\n",
       "              tensor([ 2.5642e-02,  8.4580e-03, -4.8173e-03, -4.9446e-04,  1.3209e-02,\n",
       "                      -2.9487e-02,  2.0291e-02,  2.4041e-03,  2.3538e-04, -3.7390e-03,\n",
       "                      -1.0076e-02,  1.8152e-02,  9.8603e-03, -1.7469e-02,  1.2249e-02,\n",
       "                      -3.9430e-02,  3.6992e-02, -1.0561e-02,  1.3577e-02,  2.3682e-02,\n",
       "                      -1.7785e-02,  1.1457e-02,  3.7826e-03, -2.4202e-02,  2.8240e-03,\n",
       "                      -3.7078e-02, -3.4709e-03, -1.6482e-04, -2.7158e-02,  8.4474e-03,\n",
       "                       4.2631e-03, -3.0330e-02, -2.9785e-03, -1.5166e-02, -4.0212e-02,\n",
       "                      -2.7101e-02,  1.9115e-03, -9.6038e-03, -6.8617e-03,  6.7111e-04,\n",
       "                      -6.8956e-03, -1.8139e-02, -9.8092e-04,  1.3832e-02, -5.0147e-03,\n",
       "                      -2.9889e-03,  1.8575e-02,  5.7270e-03,  1.9845e-02, -1.4142e-02,\n",
       "                      -7.2997e-03,  1.5792e-02, -2.7999e-03, -1.1880e-02,  2.8977e-02,\n",
       "                      -3.8239e-02, -1.8930e-02, -1.6091e-02, -1.1582e-02,  1.1376e-02,\n",
       "                       6.2557e-03, -4.3417e-03, -1.2699e-02, -3.3392e-05,  3.2460e-02,\n",
       "                       9.4697e-03,  2.8259e-02,  2.4293e-03,  3.7619e-02,  3.6423e-02,\n",
       "                       1.7905e-02,  2.5833e-03,  1.8416e-02, -1.5838e-02,  3.7919e-03,\n",
       "                      -6.8733e-03,  7.6757e-03, -2.7425e-02, -6.8777e-03, -1.9252e-02,\n",
       "                       2.0784e-02, -1.5466e-02,  1.1911e-02, -1.4919e-02,  1.5543e-02,\n",
       "                       3.7667e-03, -3.2947e-02, -1.7854e-02, -3.4302e-03, -1.1307e-03,\n",
       "                       3.0725e-02, -1.9104e-02,  3.3421e-03, -2.1570e-03,  7.6046e-03,\n",
       "                       2.1950e-02,  5.0224e-03, -2.4202e-02, -1.7812e-02,  1.4054e-02,\n",
       "                       1.4697e-02,  1.0055e-02,  3.6937e-02, -1.3041e-02, -1.0499e-02,\n",
       "                       2.1797e-02, -2.2166e-02,  2.2993e-02,  3.9294e-02, -1.8800e-02,\n",
       "                       1.3852e-02,  3.7469e-02,  2.5107e-02, -4.4953e-03,  4.8752e-03,\n",
       "                       5.3893e-02, -1.4162e-02,  1.9378e-02, -9.1012e-03, -4.9546e-03,\n",
       "                       5.8681e-03,  1.3361e-02, -4.6484e-03,  9.6366e-03,  1.7023e-02,\n",
       "                       1.4821e-02, -1.5190e-02,  1.8107e-02,  9.8599e-03,  1.2751e-02,\n",
       "                      -1.3604e-02, -2.4777e-02, -1.2270e-02, -2.8400e-02,  2.3828e-02,\n",
       "                      -2.2001e-02, -1.6476e-02, -8.7873e-04, -2.2996e-02, -1.3663e-02,\n",
       "                       8.9200e-03,  7.1816e-03,  2.5577e-02,  1.0948e-02, -2.4022e-02,\n",
       "                      -5.4403e-03,  3.3081e-02,  1.8847e-02,  1.9761e-02,  3.4166e-02,\n",
       "                      -1.1408e-02, -2.9594e-02,  3.5449e-02, -2.4427e-02,  2.2056e-02,\n",
       "                       5.0418e-03, -1.4556e-02,  6.1573e-03, -5.4429e-03,  2.3332e-02,\n",
       "                      -2.4918e-02,  1.6788e-04,  3.3074e-03,  1.3567e-02,  3.2918e-02,\n",
       "                       1.2756e-02, -3.8438e-03,  6.0706e-03,  8.5753e-04,  2.4783e-02,\n",
       "                       1.7048e-02,  1.3910e-02, -2.6020e-02,  2.6514e-02,  3.5533e-03,\n",
       "                      -1.1540e-02, -6.3640e-03, -1.0191e-03, -6.3798e-04, -1.3322e-02,\n",
       "                       2.5359e-02,  1.3001e-02, -1.0785e-03,  1.2665e-02, -1.7876e-02,\n",
       "                       4.0294e-02, -8.1248e-03,  1.7187e-02,  3.9423e-03,  9.3750e-03,\n",
       "                       8.6104e-04, -3.5274e-03, -7.4409e-03,  4.9900e-03,  1.4811e-02,\n",
       "                      -4.0469e-02, -1.0745e-02, -6.5732e-03,  9.6444e-03, -6.4943e-03,\n",
       "                      -3.4300e-03, -7.9677e-03, -1.8368e-02,  1.3603e-02,  2.8427e-02,\n",
       "                       9.3733e-03,  2.0542e-02,  1.4194e-02, -1.1689e-02,  1.4431e-02,\n",
       "                      -7.5627e-03, -2.1449e-03,  4.1732e-03,  4.3689e-02,  1.5029e-02,\n",
       "                       4.4983e-03, -3.0290e-02, -6.8898e-03, -1.1102e-03, -1.5572e-03,\n",
       "                       1.1373e-02, -7.2241e-04, -3.6555e-03, -1.9394e-02,  2.4366e-02,\n",
       "                       3.1652e-03, -8.9972e-03,  2.5415e-02,  7.2177e-03,  1.7781e-02,\n",
       "                       4.3796e-04, -1.3753e-02,  2.1411e-02, -6.5026e-03, -3.0598e-02,\n",
       "                      -1.3901e-02,  1.9894e-02,  1.6247e-02,  1.4317e-02, -9.8724e-04,\n",
       "                      -1.5569e-02,  1.5917e-02, -1.1595e-02,  6.6037e-03,  1.4463e-02,\n",
       "                      -5.3876e-04, -1.8056e-03,  4.6114e-03, -1.8690e-02, -1.2095e-03,\n",
       "                      -1.7851e-02, -6.0589e-03,  1.1632e-02, -1.1150e-02,  1.4940e-02,\n",
       "                      -1.7556e-02], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.2.1.bias',\n",
       "              tensor([ 5.5795e-03,  6.8452e-03,  1.3027e-02,  1.3996e-02, -1.5968e-03,\n",
       "                       7.1464e-03,  4.0992e-03,  3.7857e-03,  7.6059e-03,  3.2851e-03,\n",
       "                       1.4242e-02, -6.4224e-03,  4.2620e-03,  9.4007e-04,  5.9677e-04,\n",
       "                       5.3216e-03,  2.5768e-02,  1.3462e-03,  1.0280e-02, -3.3940e-03,\n",
       "                      -7.9514e-03,  1.3612e-03,  7.9924e-03,  4.8551e-03,  1.5408e-02,\n",
       "                      -1.4372e-02,  5.6363e-03,  7.3427e-03,  1.0387e-02, -6.6261e-03,\n",
       "                      -4.4624e-03,  1.8424e-02,  5.1608e-03,  1.4987e-02,  1.2605e-02,\n",
       "                       1.4338e-02,  1.1324e-02,  6.6319e-03,  1.5994e-02,  4.6495e-04,\n",
       "                       8.7336e-03,  9.9964e-03, -2.4465e-03, -6.0165e-03,  8.5780e-03,\n",
       "                      -1.6520e-02,  1.3089e-02,  3.9584e-03, -1.1820e-02,  3.2972e-03,\n",
       "                       9.8129e-03,  2.5974e-03,  7.5514e-03,  2.0750e-02,  4.0634e-04,\n",
       "                       1.4957e-02,  1.0559e-02,  5.1121e-03,  5.1806e-03, -2.9122e-03,\n",
       "                       8.0817e-04,  3.6802e-04,  1.4792e-02,  5.3082e-03, -1.1777e-02,\n",
       "                       4.5985e-04, -7.8810e-05,  1.0087e-02,  1.7604e-02, -1.3171e-02,\n",
       "                       8.0979e-03, -1.7241e-03, -9.4438e-04, -8.3990e-03,  1.1979e-02,\n",
       "                       7.6170e-03,  4.7734e-03,  1.8051e-02,  3.0206e-04,  9.0756e-03,\n",
       "                       3.3894e-03, -1.0864e-02,  1.8498e-02,  4.3812e-03, -7.3263e-03,\n",
       "                       2.1294e-02,  2.2070e-04,  1.0547e-02,  1.2104e-02, -3.1122e-03,\n",
       "                       3.0811e-03,  1.2447e-02,  8.4645e-03, -2.9774e-03,  3.8647e-03,\n",
       "                      -7.0275e-03,  1.1523e-02,  2.6896e-03,  1.9267e-02,  6.4599e-03,\n",
       "                       2.4632e-02,  1.3974e-02,  5.1281e-03,  1.0933e-02,  4.2280e-03,\n",
       "                      -5.4675e-03,  4.7855e-03,  1.1219e-02,  4.1039e-03,  4.6562e-03,\n",
       "                      -9.1134e-04, -5.5956e-03,  5.5832e-03,  2.0898e-02,  1.5679e-02,\n",
       "                      -1.3077e-03,  4.2575e-03,  7.3684e-04, -1.3083e-03, -4.2507e-03,\n",
       "                       5.5670e-05,  1.2555e-02,  6.3002e-03,  6.6684e-04,  1.6028e-02,\n",
       "                       4.0528e-03,  9.2572e-03,  3.9450e-03,  5.5439e-03,  1.3665e-02,\n",
       "                       6.2590e-03,  3.5932e-03,  9.4597e-03,  3.6877e-04,  4.5255e-03,\n",
       "                      -1.4191e-02,  8.4326e-03,  4.0407e-03,  7.4254e-03,  1.1482e-02,\n",
       "                       2.6038e-02,  1.5751e-02,  5.9726e-03,  1.9073e-03, -5.9728e-03,\n",
       "                       6.4643e-03,  3.7168e-03,  4.2105e-03,  1.1550e-03, -5.6850e-05,\n",
       "                       1.0249e-02,  6.8243e-03,  2.3168e-03,  1.0297e-02,  1.3657e-02,\n",
       "                       2.2880e-03, -5.2862e-03,  4.4627e-03,  6.7281e-03,  9.7064e-04,\n",
       "                       6.5972e-03,  9.0131e-03, -1.4831e-03,  5.8038e-03,  1.0834e-02,\n",
       "                      -5.5050e-03, -1.0966e-02,  5.5163e-03,  1.1194e-02,  1.1666e-02,\n",
       "                       1.3355e-02,  2.3986e-03,  1.3743e-02,  1.4511e-02, -1.4481e-02,\n",
       "                       1.6554e-03, -3.8071e-03,  1.4000e-02, -3.6034e-03,  3.6123e-03,\n",
       "                       3.5138e-03,  1.3401e-02, -2.8651e-03, -7.4266e-03,  8.4105e-03,\n",
       "                       6.2168e-03,  1.0858e-02,  5.8692e-03,  1.3663e-02,  5.5727e-03,\n",
       "                       3.5659e-03,  8.1475e-03,  4.6109e-03,  8.9707e-03,  9.1123e-03,\n",
       "                       8.1295e-03,  1.1478e-02, -1.1042e-03,  3.3490e-03,  7.2678e-03,\n",
       "                      -3.5186e-03,  2.1046e-02,  1.7184e-02,  1.5737e-02,  1.5109e-02,\n",
       "                       7.4730e-03,  1.4879e-02, -8.9731e-03,  3.2758e-03,  6.5919e-03,\n",
       "                       2.8882e-03,  1.0140e-02, -4.5578e-03,  1.2943e-02,  8.4944e-03,\n",
       "                       3.3985e-03,  3.1783e-03,  1.8979e-02,  1.3290e-03, -1.2039e-03,\n",
       "                       1.8321e-02,  7.8887e-03,  1.0324e-03,  1.3165e-02,  1.1563e-02,\n",
       "                       5.0112e-03, -6.9181e-03, -5.3101e-03,  2.6231e-02,  1.8432e-02,\n",
       "                       9.1612e-04, -1.7465e-03,  1.3066e-02,  1.2667e-02, -5.3628e-03,\n",
       "                       3.7116e-03, -4.1852e-03,  8.9871e-03,  2.8716e-03,  1.5833e-02,\n",
       "                      -5.2716e-03,  9.9374e-04, -8.9385e-03,  1.2544e-02,  2.3159e-04,\n",
       "                       3.1393e-03,  5.2788e-03, -1.2344e-04, -2.6189e-02, -1.1535e-02,\n",
       "                       1.8015e-02,  1.7858e-02,  8.8621e-03,  1.8253e-02,  3.3046e-03,\n",
       "                       8.0231e-04], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.2.1.running_mean',\n",
       "              tensor([ 4.6563e-01, -3.4816e-01,  4.7304e-01,  6.3204e-01,  9.7278e-03,\n",
       "                      -2.3532e-01, -9.3138e-02, -1.7648e-01, -2.0710e-01, -3.3035e-01,\n",
       "                      -7.0218e-01, -6.9077e-02,  2.9301e-02,  1.1658e-01, -3.3423e-01,\n",
       "                      -3.4745e-02,  4.7870e-01, -3.3121e-02,  2.1530e-01, -3.3713e-01,\n",
       "                       4.3058e-01,  1.4090e-01, -1.0053e-01,  7.5492e-02,  8.6351e-02,\n",
       "                       6.1790e-01,  1.8424e-01,  1.1125e-01, -5.5139e-02,  2.7138e-01,\n",
       "                       1.8303e-01, -4.4575e-01, -3.4503e-01, -6.8247e-04,  5.2191e-02,\n",
       "                      -1.5672e-01,  6.8534e-02,  4.5404e-01,  4.7735e-01, -2.4491e-01,\n",
       "                       2.6441e-01,  8.4410e-02, -2.7534e-01, -7.4926e-02, -5.1675e-01,\n",
       "                      -8.8760e-03, -2.3826e-03,  2.6709e-01, -3.5656e-01, -1.3981e-02,\n",
       "                       4.9776e-02,  1.7527e-01,  3.6491e-02,  7.1266e-01,  6.4192e-01,\n",
       "                       8.7452e-02, -3.3114e-01,  3.7922e-02, -2.8434e-01,  5.2543e-01,\n",
       "                      -4.8034e-02,  5.7596e-01,  1.2587e-01, -1.7413e-01, -6.3395e-01,\n",
       "                       3.8107e-01,  4.6375e-01, -2.6954e-01,  1.4986e-01, -2.7817e-01,\n",
       "                       3.4784e-01,  8.9721e-01, -4.9930e-02, -1.0327e+00, -2.3148e-01,\n",
       "                       4.2404e-02, -6.7433e-01,  3.5453e-01, -3.8668e-01, -2.9126e-01,\n",
       "                       3.8084e-01, -4.3838e-01, -1.2300e-01,  4.8746e-01,  2.8548e-01,\n",
       "                      -5.3066e-02,  4.5110e-01,  3.8671e-01,  4.0836e-01, -2.3824e-01,\n",
       "                       6.9267e-02,  2.3549e-03, -3.8494e-01, -8.0819e-02, -1.4605e-01,\n",
       "                      -1.5555e-01, -4.2562e-01, -7.5378e-01, -1.5044e-01, -5.7594e-01,\n",
       "                      -1.0600e+00,  1.4572e-01,  5.6451e-01,  7.1868e-02, -6.1224e-01,\n",
       "                      -1.1158e-01,  1.3358e-01,  6.8077e-01,  4.1712e-01,  2.9568e-01,\n",
       "                       5.2029e-01, -1.1982e-01,  2.1936e-01,  3.8868e-02, -6.9053e-02,\n",
       "                      -1.8599e-01, -4.0702e-01, -4.7971e-01,  1.4578e-01, -7.2118e-01,\n",
       "                       1.3920e-01, -5.8302e-01, -1.5235e-01,  1.0100e-01, -3.3491e-01,\n",
       "                      -1.3602e-01, -1.1133e-01,  5.8465e-02,  1.2921e-01,  2.0191e-01,\n",
       "                      -5.6975e-04, -2.7403e-01, -4.2124e-01,  5.0644e-01, -2.2896e-01,\n",
       "                       6.4109e-01, -1.8716e-01,  4.4038e-02, -7.7396e-02, -8.6320e-02,\n",
       "                       2.7824e-01, -2.5178e-01,  4.1393e-01, -6.3122e-02,  2.6609e-02,\n",
       "                       5.0872e-01,  4.7795e-01, -4.7177e-02,  1.1216e-01,  4.0698e-01,\n",
       "                       2.7063e-01,  1.5148e-01,  2.0920e-02,  5.7333e-01, -7.2754e-01,\n",
       "                      -1.0667e-02, -2.8255e-01,  2.6180e-02,  5.8384e-01, -2.6073e-01,\n",
       "                      -5.6122e-01,  7.5266e-02, -2.9557e-01, -2.4874e-01, -6.1147e-01,\n",
       "                      -1.7894e-01,  1.2616e-02, -1.3509e-01,  2.9992e-03, -5.8052e-01,\n",
       "                       4.7149e-02,  4.8902e-01, -1.1700e-01, -2.7034e-01,  3.2961e-01,\n",
       "                      -3.5747e-01,  3.7908e-02,  2.7772e-02, -1.2957e-01,  6.6487e-02,\n",
       "                      -1.6610e-01, -9.8769e-02,  3.5037e-02,  2.2840e-01,  2.4427e-01,\n",
       "                      -1.0658e-01,  6.9748e-01,  7.1381e-02,  8.5652e-02,  5.8543e-01,\n",
       "                      -3.3029e-01,  1.7319e-01,  4.5155e-01,  1.8966e-01,  9.9249e-02,\n",
       "                       2.5932e-01, -5.4634e-01,  3.6261e-01,  2.4419e-01, -3.6525e-01,\n",
       "                      -2.3492e-01, -9.7841e-02,  2.2012e-01, -7.3702e-01, -5.4523e-01,\n",
       "                       5.9148e-02,  1.1227e-01, -1.5223e-02,  5.0568e-03,  2.6028e-01,\n",
       "                      -1.4641e-01,  4.4206e-01,  4.6827e-02, -4.7252e-01, -2.4931e-01,\n",
       "                      -1.7327e-01, -5.3082e-01, -5.1788e-01,  4.8424e-02,  1.1789e-01,\n",
       "                       1.2217e-01,  4.4098e-02, -3.1413e-01,  7.2869e-01, -9.1709e-01,\n",
       "                      -1.2146e-01, -1.4294e-01, -2.3664e-02, -2.5959e-01, -5.9141e-02,\n",
       "                      -1.9730e-01,  4.2915e-03,  4.2853e-01, -6.5367e-01, -6.0749e-01,\n",
       "                       2.5845e-01,  3.1770e-01,  1.7928e-01,  8.5676e-02, -4.1451e-01,\n",
       "                      -2.5173e-01,  4.2405e-01,  5.2295e-01, -4.0515e-01, -8.7854e-02,\n",
       "                       1.2757e-01, -1.4580e-01,  1.4460e-01,  5.1708e-02, -8.3048e-03,\n",
       "                      -6.2309e-01, -1.7422e-01, -5.0098e-01,  6.4917e-01, -4.7236e-01,\n",
       "                       3.5787e-02], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.2.1.running_var',\n",
       "              tensor([0.5134, 0.4325, 0.1983, 0.6342, 0.3373, 0.3455, 0.3954, 0.3193, 0.2742,\n",
       "                      0.4187, 0.3627, 0.3761, 0.1793, 0.4352, 0.1900, 0.5649, 0.5326, 0.3870,\n",
       "                      0.2241, 0.4234, 0.4342, 0.6256, 0.5527, 0.4402, 0.3814, 0.4537, 0.3875,\n",
       "                      0.1738, 0.4370, 0.2759, 0.2520, 0.6207, 0.1247, 0.2877, 0.2704, 0.5901,\n",
       "                      0.1621, 0.3926, 0.2081, 0.3508, 0.3355, 0.1718, 0.0503, 0.4076, 0.2696,\n",
       "                      0.3421, 0.3347, 0.3705, 0.3099, 0.3521, 0.2363, 0.2508, 0.3277, 0.4268,\n",
       "                      0.5970, 0.5193, 0.2602, 0.4151, 0.2855, 0.2324, 0.2513, 0.2916, 0.2816,\n",
       "                      0.1003, 0.4265, 0.3067, 0.3697, 0.2170, 0.2707, 0.2727, 0.3060, 0.2662,\n",
       "                      0.3292, 0.5290, 0.2870, 0.1694, 0.3984, 0.3518, 0.4821, 0.1801, 0.5990,\n",
       "                      0.2890, 0.3063, 0.5041, 0.3122, 0.4221, 0.3611, 0.3865, 0.2048, 0.1861,\n",
       "                      0.6148, 0.4104, 0.3192, 0.1180, 0.1598, 0.3434, 0.2847, 0.3921, 0.2627,\n",
       "                      0.2892, 0.5259, 0.2490, 0.2245, 0.2558, 0.2766, 0.2692, 0.4599, 0.3815,\n",
       "                      0.6175, 0.2056, 0.2523, 0.4830, 0.6354, 0.1646, 0.3105, 0.3987, 0.3158,\n",
       "                      0.4761, 0.2604, 0.7351, 0.0376, 0.3755, 0.5876, 0.2159, 0.2582, 0.3784,\n",
       "                      0.3223, 0.2443, 0.1142, 0.7720, 0.1374, 0.4067, 0.5944, 0.3025, 0.3142,\n",
       "                      0.3831, 0.3412, 0.1294, 0.5424, 0.3390, 0.3865, 0.3155, 0.3182, 0.1661,\n",
       "                      0.3778, 0.2916, 0.2514, 0.5505, 0.1573, 0.4250, 0.3575, 0.1896, 0.2617,\n",
       "                      0.5433, 0.4804, 0.1807, 0.4113, 0.3352, 0.3466, 0.3594, 0.5993, 0.1370,\n",
       "                      0.0650, 0.2164, 0.4894, 0.4464, 0.4413, 0.1607, 0.2144, 0.3155, 0.2865,\n",
       "                      0.3933, 0.4302, 0.2372, 0.3917, 0.4778, 0.2297, 0.2884, 0.1655, 0.3402,\n",
       "                      0.6513, 0.2633, 0.3002, 0.4044, 0.3371, 0.4165, 0.3335, 0.2477, 0.1975,\n",
       "                      0.3340, 0.1174, 0.1793, 0.1944, 0.2828, 0.2714, 0.3109, 0.4287, 0.1807,\n",
       "                      0.3260, 0.4032, 0.1769, 0.2604, 0.2938, 0.3250, 0.3376, 0.3443, 0.2208,\n",
       "                      0.1547, 0.2426, 0.4781, 0.1359, 0.2274, 0.1359, 0.8513, 0.2469, 0.1483,\n",
       "                      0.3002, 0.2571, 0.1664, 0.4263, 0.2461, 0.1977, 0.1077, 0.3126, 0.5675,\n",
       "                      0.2108, 0.1386, 0.4669, 0.5812, 0.4779, 0.2133, 0.1663, 0.4578, 0.2748,\n",
       "                      0.3831, 0.2817, 0.4702, 0.3001, 0.3737, 0.3382, 0.1635, 0.1979, 0.4303,\n",
       "                      0.2696, 0.2337, 0.1974, 0.1061, 0.4901, 0.2056, 0.2740, 0.7442, 0.3983,\n",
       "                      0.1774, 0.3929, 0.2224, 0.2557], dtype=torch.float64)),\n",
       "             ('6.19.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n",
       "             ('6.20.convs.0.0.weight',\n",
       "              tensor([[[ 0.0476],\n",
       "                       [-0.1550],\n",
       "                       [-0.0317],\n",
       "                       ...,\n",
       "                       [ 0.0603],\n",
       "                       [-0.0032],\n",
       "                       [-0.0984]],\n",
       "              \n",
       "                      [[ 0.0939],\n",
       "                       [ 0.1092],\n",
       "                       [-0.0196],\n",
       "                       ...,\n",
       "                       [ 0.0424],\n",
       "                       [-0.1157],\n",
       "                       [-0.1963]],\n",
       "              \n",
       "                      [[ 0.0488],\n",
       "                       [-0.0706],\n",
       "                       [-0.0224],\n",
       "                       ...,\n",
       "                       [ 0.1880],\n",
       "                       [-0.0177],\n",
       "                       [-0.0785]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1139],\n",
       "                       [ 0.1142],\n",
       "                       [ 0.1631],\n",
       "                       ...,\n",
       "                       [ 0.0237],\n",
       "                       [ 0.2427],\n",
       "                       [-0.1150]],\n",
       "              \n",
       "                      [[-0.0670],\n",
       "                       [ 0.0406],\n",
       "                       [ 0.0810],\n",
       "                       ...,\n",
       "                       [-0.1754],\n",
       "                       [ 0.1236],\n",
       "                       [-0.0116]],\n",
       "              \n",
       "                      [[ 0.0310],\n",
       "                       [ 0.0100],\n",
       "                       [-0.0825],\n",
       "                       ...,\n",
       "                       [ 0.1177],\n",
       "                       [-0.1649],\n",
       "                       [-0.0401]]], dtype=torch.float64)),\n",
       "             ('6.20.convs.0.1.weight',\n",
       "              tensor([0.9570, 0.9978, 0.9605, 0.9748, 0.9624, 0.9680, 0.9777, 1.0064, 0.9957,\n",
       "                      0.9876, 0.9837, 0.9638, 0.9765, 0.9961, 0.9803, 0.9636, 0.9598, 0.9840,\n",
       "                      0.9679, 0.9654, 0.9605, 0.9555, 0.9283, 0.9562, 0.9723, 0.9920, 1.0031,\n",
       "                      0.9803, 0.9767, 0.9936, 0.9425, 0.9738, 0.9616, 0.9673, 0.9766, 0.9669,\n",
       "                      0.9680, 0.9921, 0.9731, 0.9785, 0.9768, 0.9868, 0.9708, 0.9637, 0.9941,\n",
       "                      0.9679, 0.9683, 0.9392, 0.9766, 1.0021, 0.9599, 0.9582, 0.9636, 0.9854,\n",
       "                      0.9425, 0.9609, 0.9563, 0.9970, 1.0296, 0.9722, 0.9843, 0.9647, 0.9802,\n",
       "                      0.9795], dtype=torch.float64)),\n",
       "             ('6.20.convs.0.1.bias',\n",
       "              tensor([-7.8793e-03,  1.6539e-02, -5.0831e-03,  1.4974e-02,  9.4530e-03,\n",
       "                      -1.2007e-02,  4.7464e-03,  3.7740e-02,  2.1361e-02,  7.6922e-03,\n",
       "                      -1.0669e-04, -1.5153e-03, -7.1853e-03,  4.2779e-03,  1.5775e-02,\n",
       "                      -1.6825e-02,  7.2471e-03,  2.2324e-02,  4.1969e-05, -6.6903e-03,\n",
       "                      -2.0347e-02, -5.1689e-03, -2.5578e-02,  5.5452e-03,  1.0847e-02,\n",
       "                       5.3774e-03,  4.6737e-03,  5.9176e-03, -1.0246e-02,  1.7053e-02,\n",
       "                      -1.7449e-02,  3.0628e-03,  8.3087e-03,  5.8184e-04,  9.3430e-03,\n",
       "                      -5.9269e-04, -1.1075e-02,  1.9195e-02, -1.5395e-03, -2.2225e-02,\n",
       "                       1.9571e-02,  3.0154e-03, -5.0114e-03, -1.2864e-02, -1.5554e-03,\n",
       "                       4.3612e-03,  6.6128e-03, -1.6994e-02,  4.2922e-03,  3.0310e-02,\n",
       "                       3.5876e-04,  7.4116e-03, -2.8969e-03,  1.1802e-02,  5.8864e-03,\n",
       "                       1.2041e-02,  4.1173e-03,  2.7668e-03,  2.5435e-02,  9.8150e-04,\n",
       "                       6.3370e-03,  1.2606e-02,  1.5518e-02,  4.0411e-03],\n",
       "                     dtype=torch.float64)),\n",
       "             ('6.20.convs.0.1.running_mean',\n",
       "              tensor([ 0.9154,  0.2985, -0.2129, -1.0236, -0.3104,  0.7648,  0.0363,  0.0602,\n",
       "                       0.1009, -0.7696, -0.9205, -0.4375,  0.2287, -0.5051, -0.9573, -0.1271,\n",
       "                      -0.9918, -0.1454, -0.3502,  0.6269,  0.8969, -1.5624, -0.2593, -0.8964,\n",
       "                      -0.3351, -0.0227, -0.9133, -0.7113, -0.3329, -0.0708,  0.4311,  0.9299,\n",
       "                       0.5119, -0.3825,  0.9115,  0.0998, -0.6060,  0.0886,  1.2144, -0.2897,\n",
       "                      -0.2851, -0.3652,  0.3223, -0.1026, -0.3235, -0.2754, -0.3874, -0.0245,\n",
       "                      -0.3118, -0.2191,  0.6866, -0.3534, -0.9942,  0.3365, -1.4729, -1.0423,\n",
       "                      -1.5268, -0.7534,  0.2379, -0.7365,  0.6082,  0.6973,  0.0664,  0.4735],\n",
       "                     dtype=torch.float64)),\n",
       "             ...])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(xresnet1d_model_weights_path, map_location=torch.device('cpu'))['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613d40852992bbbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:03:16.171119Z",
     "start_time": "2024-05-05T10:03:16.148787Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 1000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg, label = valid_dataset[7]\n",
    "ecg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b884df856a0194a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:04:18.910536Z",
     "start_time": "2024-05-04T11:04:18.905398Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c5c50d67ffa1660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:04:25.952444Z",
     "start_time": "2024-05-04T11:04:25.896342Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3253, -4.9247, -5.4436,  5.2726, -5.4596]], dtype=torch.float64,\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xresnet1d_model(ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11cd0a4c25e804f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:52:04.837719Z",
     "start_time": "2024-05-04T10:52:04.818736Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0900,  0.0730,  0.0500,  ...,  0.0750,  0.0730,  0.0900],\n",
       "          [-0.0350, -0.0520, -0.0780,  ..., -0.1060, -0.1050, -0.1040],\n",
       "          [-0.1250, -0.1250, -0.1270,  ..., -0.1810, -0.1790, -0.1940],\n",
       "          ...,\n",
       "          [-0.1500, -0.1500, -0.1500,  ..., -0.2750, -0.2820, -0.2770],\n",
       "          [ 0.1400,  0.1390,  0.1350,  ...,  0.1920,  0.2540,  0.3120],\n",
       "          [ 0.0100,  0.0090,  0.0050,  ..., -0.2940, -0.2970, -0.2930]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([0., 0., 1., 0., 1.]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42169fd9559e83a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:05:18.905446Z",
     "start_time": "2024-05-04T11:04:39.439766Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:39<00:00, 54.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.8897126969416126, 0.9216867469879518, 0.8665430954587581, 0.8873957367933272, 0.9031510658016683]\n",
      "accuracy: 0.8936978683966637\n",
      "roc_score : 0.945232846766223\n",
      "class wise AUC : [0.9417918559062147, 0.9382669823171321, 0.932451379466305, 0.958210265166821, 0.9554437509746423]\n",
      "F1 score (Max): 0.8080090213529213\n",
      "class wise precision, recall, f1 score : (0.8080090213529213, 0.945232846766223, [0.8080090213529213, 0.8041618410750325, 0.8005559699915934, 0.7979259734294084, 0.791585762440762, 0.7877588781528645, 0.7830403633295228, 0.7758309809935896, 0.7668490152751574, 0.7584454037942777], [0.8434701188731478, 0.8495703189555446, 0.8566565809379728, 0.8647435897435898, 0.8716169023921774, 0.8788485495639794, 0.8908849881148291, 0.8964660667416573, 0.9036714975845411, 0.9055489964580874], [0.775409329626197, 0.7633611368551128, 0.7513515600864997, 0.7406935434043868, 0.7250154464009887, 0.7137781896818042, 0.6984862527031201, 0.6838121717639789, 0.6660101946246525, 0.6524559777571826], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0]]),\n",
       " array([[-3.9445402 , -5.17392056, -3.26830999,  3.12357277, -5.25319514],\n",
       "        [-1.64896047, -4.99737425, -4.78981792,  3.16528685, -3.44972022],\n",
       "        [-2.92633657, -3.56020432, -4.75886424,  2.19726658, -3.45016258],\n",
       "        ...,\n",
       "        [-3.35843216, -2.15863849, -2.3312406 ,  1.33540295, -4.82410338],\n",
       "        [ 0.89151499, -4.07900148, -2.52005066, -0.22301925, -2.77432349],\n",
       "        [-2.88676383, -5.28226944,  0.1416349 , -2.12537415, -1.57720985]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(xresnet1d_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c281602e5abcd0ef",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d70a49075504e06f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:16:16.585190Z",
     "start_time": "2024-05-04T11:15:15.688894Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2146/2146 [01:00<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9012115563839702, 0.9221808014911463, 0.8802423112767941, 0.8970177073625349, 0.8918918918918919]\n",
      "accuracy: 0.8985088536812675\n",
      "roc_score : 0.9487086238429022\n",
      "class wise AUC : [0.9476852106773366, 0.9358697725430357, 0.9454268714542687, 0.9638844562842611, 0.9506768082556092]\n",
      "F1 score (Max): 0.8211694718834347\n",
      "class wise precision, recall, f1 score : (0.8211694718834347, 0.9487086238429022, [0.8211694718834347, 0.8180125045103792, 0.8157698383023614, 0.8081038861629387, 0.8047648564685581, 0.7985846057967387, 0.7900616418647007, 0.7844893277050097, 0.7772188207858182, 0.769764825544673], [0.8548122643056238, 0.8620804253904951, 0.870801687763713, 0.874593391542544, 0.8806047966631908, 0.8853283898305084, 0.8916938110749185, 0.8953734363502575, 0.9022435897435898, 0.910077519379845], [0.7900745573159367, 0.7782308170239204, 0.7672802112457284, 0.751009630319975, 0.7409521590556074, 0.7273221497359428, 0.7092264678471575, 0.6980428704566636, 0.6826265921093506, 0.6669384902143523], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0]]),\n",
       " array([[-3.1677591 , -3.90180522, -1.81254499,  1.32187091, -4.69090351],\n",
       "        [-5.44434877, -6.47968096, -6.28095825,  5.6266861 , -5.46598626],\n",
       "        [-1.24765092, -1.26739126, -1.03284439, -4.13920664,  2.75576176],\n",
       "        ...,\n",
       "        [-4.77860175, -5.69768495, -1.22651957, -3.50874596,  1.9376714 ],\n",
       "        [-5.44661797, -6.4738648 , -4.4702851 ,  5.25229792, -6.22884795],\n",
       "        [-4.89926612, -5.28330157, -5.26760933,  4.08361618, -4.03348173]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(xresnet1d_model, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26435c-b232-4297-b794-eb976694dac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ea2ba-a82d-4aba-a925-11932dc4f757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea4ca049-4cba-4b40-ba11-44d63fb4febd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2146/2146 [01:01<00:00, 34.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9086672879776329, 0.924044734389562, 0.8951537744641193, 0.8937558247903076, 0.8970177073625349]\n",
      "accuracy: 0.9037278657968313\n",
      "roc_score : 0.9487086238429022\n",
      "class wise AUC : [0.9476852106773366, 0.9358697725430357, 0.9454268714542687, 0.9638844562842611, 0.9506768082556092]\n",
      "F1 score (Max): 0.8351283062259676\n",
      "class wise precision, recall, f1 score : (0.8351283062259676, 0.9487086238429022, [0.4122521456052086, 0.8039341400928796, 0.8315700341856296, 0.8351283062259676, 0.8259049677528372, 0.8156711827034051, 0.7883597000969818, 0.7473742372870205, 0.6619919062367985, nan], [0.259645852749301, 0.6992932587760174, 0.7766246890547264, 0.8153809971777987, 0.8412373615792008, 0.8711775637776651, 0.892467248908297, 0.9225526641883519, 0.9547470005216483, nan], [1.0, 0.9454022988505748, 0.8948819509164336, 0.8558558558558558, 0.81112146629388, 0.7668142280211245, 0.7060034172103137, 0.6281065548306927, 0.5066402609506058, 0.0], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0]]),\n",
       " array([[0.04039719, 0.01980523, 0.14033082, 0.78949281, 0.00909491],\n",
       "        [0.00430207, 0.00153195, 0.00186811, 0.99641243, 0.00421037],\n",
       "        [0.22310704, 0.21970415, 0.26253303, 0.01568553, 0.94023793],\n",
       "        ...,\n",
       "        [0.00833765, 0.00334251, 0.22679116, 0.0290644 , 0.8740961 ],\n",
       "        [0.00429236, 0.00154087, 0.01131457, 0.99479179, 0.00196784],\n",
       "        [0.00739693, 0.00505001, 0.00512947, 0.98343266, 0.01740428]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(xresnet1d_model, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e86e13f8ee02db",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa045cef629e4f4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df9d78f530c6af91",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# ResNET1d_wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec815f0e4f18ea4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:05:27.154646Z",
     "start_time": "2024-05-05T10:05:27.096772Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet1d(\n",
       "  (0): Conv1d(12, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "  (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Sequential(\n",
       "    (0): BasicBlock1d(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock1d(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock1d(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): AdaptiveConcatPool1d(\n",
       "      (ap): AdaptiveAvgPool1d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool1d(output_size=1)\n",
       "    )\n",
       "    (1): fastai.layers.Flatten(full=False)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=5, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.nn.resnet1d import resnet1d_wang\n",
    "import torch\n",
    "\n",
    "resnet1d_wang_model = resnet1d_wang(input_channels=12, num_classes=5)\n",
    "resnet1d_wang_weights = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\resnet1d_wang\\resnet1d_wang_fold1_16epoch_best_score.pth'\n",
    "# xresnet1d_model.load_state_dict(torch.load(xresnet1d_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "\n",
    "resnet1d_wang_model.load_state_dict(torch.load(resnet1d_wang_weights, map_location=torch.device('cpu'))['model'])\n",
    "resnet1d_wang_model.double()\n",
    "resnet1d_wang_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5652ef693016177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:05:35.313314Z",
     "start_time": "2024-05-05T10:05:35.204815Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4778, -3.9272, -4.5273,  3.4386, -4.4794]], dtype=torch.float64,\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet1d_wang_model(ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26d5e2441f0b6d6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:06:41.431864Z",
     "start_time": "2024-05-05T10:06:00.546513Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:40<00:00, 52.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9119555143651529, 0.9272474513438369, 0.8897126969416126, 0.8934198331788693, 0.9040778498609824]\n",
      "accuracy: 0.9052826691380907\n",
      "roc_score : 0.9519354108684759\n",
      "class wise AUC : [0.9458144093785179, 0.9414536831255838, 0.9578312980551786, 0.961587959523282, 0.9529897042598171]\n",
      "F1 score (Max): 0.8293092983071139\n",
      "class wise precision, recall, f1 score : (0.8293092983071139, 0.9519354108684759, [0.8293092983071139, 0.824009395552638, 0.8203824261197298, 0.8157066766948554, 0.8115561542500916, 0.805619734018517, 0.7997239338129407, 0.790707686015716, 0.7808625554212011, 0.7714658458705445], [0.8625895182291666, 0.8708686264740076, 0.8767641129032258, 0.8845097029022841, 0.8942021369767035, 0.9047040834682496, 0.9086996336996337, 0.9137591446257738, 0.9166666666666667, 0.9258268964151316], [0.7985016991041086, 0.7819354340438677, 0.7708140253320975, 0.7568350324374421, 0.7428946555452579, 0.7260966944701884, 0.7140871177015755, 0.6968643805993203, 0.6801050355267222, 0.6612218103181958], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0]]),\n",
       " array([[-2.66339326, -5.29602226, -2.89385369,  2.33851818, -4.72413427],\n",
       "        [-0.23080978, -4.66203341, -3.30822062,  0.85252593, -3.50124264],\n",
       "        [-1.55635372, -3.22963769, -3.15087489,  1.13181596, -3.40798393],\n",
       "        ...,\n",
       "        [-2.55091923, -1.6129529 , -1.08714386,  0.12585486, -4.37837511],\n",
       "        [ 3.88926931, -2.08258841, -2.98448787, -1.36419389, -3.06046174],\n",
       "        [-2.05338135, -4.74342537,  1.05190746, -1.97983718, -2.72900002]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(resnet1d_wang_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cadd95b1fb8fbebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T10:07:21.619464Z",
     "start_time": "2024-05-05T10:06:41.432870Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2146/2146 [00:40<00:00, 53.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9114631873252563, 0.9161230195712954, 0.8946877912395154, 0.8951537744641193, 0.8928238583410997]\n",
      "accuracy: 0.9020503261882572\n",
      "roc_score : 0.955242851223654\n",
      "class wise AUC : [0.9547748839087422, 0.9418562141369827, 0.9603593007702597, 0.9645016506873101, 0.9547222066149755]\n",
      "F1 score (Max): 0.8306149669907514\n",
      "class wise precision, recall, f1 score : (0.8306149669907514, 0.955242851223654, [0.8306149669907514, 0.8262283200747632, 0.8213426707617111, 0.8141857850536365, 0.8078183707730434, 0.8003694205160029, 0.7923585677203713, 0.7871001325562982, 0.7801469606959226, 0.7711295453543118], [0.8579295154185022, 0.8646401985111662, 0.8728313963281118, 0.8782216494845361, 0.8873375482964523, 0.8939475574712643, 0.9013266998341625, 0.9110481586402266, 0.9160393746381007, 0.9231763068972371], [0.8049860205032618, 0.7910841876359118, 0.7755902454178315, 0.7588536812674743, 0.7413793103448276, 0.7245262503883194, 0.7068965517241379, 0.6928393911152532, 0.6793647095371234, 0.6620844982913948], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0]]),\n",
       " array([[-3.14832513, -3.26460991,  0.2536856 , -0.02308407, -3.61274702],\n",
       "        [-4.19766302, -5.41535718, -4.84862716,  4.5559457 , -4.57813923],\n",
       "        [-0.94796921, -2.48907457, -0.80158036, -2.77964796,  0.9146152 ],\n",
       "        ...,\n",
       "        [-4.12834013, -4.75765843, -0.12445068, -3.615529  ,  1.38919457],\n",
       "        [-4.86035748, -6.23637954, -4.32480366,  4.19391938, -4.51776387],\n",
       "        [-4.62028469, -5.38658484, -5.11096646,  4.1857975 , -4.0493642 ]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(resnet1d_wang_model, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d283b60ac339a6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b03ef03e7d067cbb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:21<00:00, 98.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9133456904541242, 0.9304911955514366, 0.896663577386469, 0.8906394810009268, 0.9082483781278962]\n",
      "accuracy: 0.9078776645041705\n",
      "roc_score : 0.9519354108684759\n",
      "class wise AUC : [0.9458144093785179, 0.9414536831255838, 0.9578312980551786, 0.961587959523282, 0.9529897042598171]\n",
      "F1 score (Max): 0.8390414594282605\n",
      "class wise precision, recall, f1 score : (0.8390414594282605, 0.9519354108684759, [0.41113238109262257, 0.7934017120716688, 0.8330273814507657, 0.8390414594282605, 0.8352409399496095, 0.8205759259958391, 0.7983611142836237, 0.7479615999138117, 0.6185842308793499, nan], [0.258758109360519, 0.6786299042323138, 0.7694238492431262, 0.8154205607476636, 0.8484017175572519, 0.8772062531517902, 0.910454629118351, 0.9400380710659898, 0.9629948364888123, nan], [1.0, 0.9548965091133768, 0.9080939141180105, 0.8640716713005869, 0.8224822366388632, 0.7708140253320975, 0.7108433734939759, 0.6210611677479148, 0.45563021316033364, 0.0], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0]]),\n",
       " array([[0.06516831, 0.0049865 , 0.05245823, 0.91201725, 0.00880026],\n",
       "        [0.44255236, 0.00935882, 0.03529025, 0.70109675, 0.02927689],\n",
       "        [0.17417049, 0.03806551, 0.04105682, 0.75617387, 0.03204688],\n",
       "        ...,\n",
       "        [0.07236475, 0.16617905, 0.25215649, 0.53142225, 0.01239028],\n",
       "        [0.97994994, 0.11080069, 0.0481316 , 0.20355953, 0.04476795],\n",
       "        [0.11371116, 0.00863358, 0.74114102, 0.1213362 , 0.06128366]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(resnet1d_wang_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16fdf5-c1c8-4219-b9ec-7fd9a219112d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96b0a7466fc1ecba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Inception1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1f6a3280c064ddc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:47:39.763439Z",
     "start_time": "2024-05-04T15:47:39.628107Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception1d(\n",
       "  (layers): Sequential(\n",
       "    (0): InceptionBackbone(\n",
       "      (im): ModuleList(\n",
       "        (0): InceptionBlock1d(\n",
       "          (bottleneck): Conv1d(12, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (convs): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "            (1): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "            (2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "          )\n",
       "          (conv_bottle): Sequential(\n",
       "            (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "            (1): Conv1d(12, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (bn_relu): Sequential(\n",
       "            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x InceptionBlock1d(\n",
       "          (bottleneck): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (convs): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "            (1): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "            (2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "          )\n",
       "          (conv_bottle): Sequential(\n",
       "            (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "            (1): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (bn_relu): Sequential(\n",
       "            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (sk): ModuleList(\n",
       "        (0): Shortcut1d(\n",
       "          (act_fn): ReLU(inplace=True)\n",
       "          (conv): Conv1d(12, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): Shortcut1d(\n",
       "          (act_fn): ReLU(inplace=True)\n",
       "          (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): AdaptiveConcatPool1d(\n",
       "        (ap): AdaptiveAvgPool1d(output_size=1)\n",
       "        (mp): AdaptiveMaxPool1d(output_size=1)\n",
       "      )\n",
       "      (1): fastai.layers.Flatten(full=False)\n",
       "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=256, out_features=5, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.nn.inception1d import inception1d\n",
    "\n",
    "inception1d_model = inception1d(input_channels=12, num_classes=5)\n",
    "inception1d_model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\inception1d\\inception1d_fold1_15epoch_best_score.pth'\n",
    "inception1d_model.load_state_dict(torch.load(inception1d_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "inception1d_model.double()\n",
    "inception1d_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b3efc5fe7bab13b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:48:15.479207Z",
     "start_time": "2024-05-04T15:48:15.473927Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0360,  0.0460,  0.0460,  ...,  0.0040, -0.1340, -0.3340],\n",
       "          [-0.1140, -0.1040, -0.1060,  ..., -0.0060, -0.1450, -0.3110],\n",
       "          [-0.1500, -0.1490, -0.1520,  ..., -0.0100, -0.0100,  0.0230],\n",
       "          ...,\n",
       "          [ 0.0210,  0.0230,  0.0170,  ..., -0.0880, -0.1230, -0.1090],\n",
       "          [-0.0250, -0.0230, -0.0320,  ..., -0.0420, -0.0890, -0.1210],\n",
       "          [ 0.0060,  0.0040, -0.0160,  ..., -0.1120, -0.1480, -0.1480]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([0., 0., 0., 1., 0.]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "edf4f9246a21d763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:48:19.575014Z",
     "start_time": "2024-05-04T15:48:19.392933Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4925, -4.6633, -4.5221,  3.2949, -3.5534]], dtype=torch.float64,\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception1d_model(ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12da7cd388b0670c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:49:49.266640Z",
     "start_time": "2024-05-04T15:49:00.379441Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:48<00:00, 44.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9138090824837812, 0.9207599629286376, 0.8887859128822985, 0.8980537534754403, 0.9045412418906394]\n",
      "accuracy: 0.9051899907321594\n",
      "roc_score : 0.9569492358010082\n",
      "class wise AUC : [0.954472118706572, 0.9485739362901409, 0.960292853912257, 0.9650091024822187, 0.9563981676138529]\n",
      "F1 score (Max): 0.8345535231120428\n",
      "class wise precision, recall, f1 score : (0.8345535231120428, 0.9569492358010082, [0.8345535231120428, 0.8306702106588043, 0.8268053498758148, 0.819813458866716, 0.813922657858165, 0.8100104919261963, 0.800939796888839, 0.7931867633953288, 0.7889815056776961, 0.7796063832331508], [0.8703432568732715, 0.8780366881507189, 0.8851963746223565, 0.8921845574387948, 0.8958658346333853, 0.902336860670194, 0.9079089924160346, 0.9142170456646331, 0.925715368580633, 0.9332355816226784], [0.8015909793018227, 0.788152610441767, 0.7756410256410257, 0.7583024405313561, 0.745713623725672, 0.7348239110287303, 0.7165199258572753, 0.7004556688291628, 0.6874420759962928, 0.6694084028421379], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0]]),\n",
       " array([[-2.22023794, -5.01295134, -2.70663503,  1.89465267, -4.14693349],\n",
       "        [ 0.3324141 , -4.08592618, -3.67161655,  1.15772968, -4.0388319 ],\n",
       "        [-1.54339273, -3.06256439, -4.20844905,  2.203993  , -2.77911508],\n",
       "        ...,\n",
       "        [-2.36203804, -1.22312216, -0.88608206, -0.72825251, -3.85984596],\n",
       "        [ 4.51332536, -3.03034121, -3.00525668, -1.98216501, -3.65007412],\n",
       "        [-2.02133119, -5.12259159,  0.94243378, -3.00276813, -2.10483386]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(inception1d_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2d0b1d6812dee72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:51:55.787331Z",
     "start_time": "2024-05-04T15:51:55.777921Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e, l = test_dataset[107]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8e4c565a31a09ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:59:10.111226Z",
     "start_time": "2024-05-04T15:59:09.983949Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.62190692e-03, 7.54639804e-04, 9.48442227e-01, 5.63857648e-04,\n",
       "        4.86173686e-02]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(inception1d_model(e), dim=1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6568a79ef0070ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T16:01:15.432635Z",
     "start_time": "2024-05-04T16:01:15.308680Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2712580cb90>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(e[0,6].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fdeb480032d4c81e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T16:00:49.768552Z",
     "start_time": "2024-05-04T16:00:49.734224Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0350, -0.0520, -0.0780, -0.0730, -0.0770, -0.0800, -0.0800, -0.0780,\n",
       "        -0.0710, -0.0670, -0.0610, -0.0550, -0.0500, -0.0430, -0.0320, -0.0230,\n",
       "        -0.0120,  0.0070,  0.0260,  0.0500,  0.0810,  0.1050,  0.1340,  0.1570,\n",
       "         0.1550,  0.1460,  0.1250,  0.0860,  0.0450,  0.0080, -0.0170, -0.0330,\n",
       "        -0.0450, -0.0530, -0.0590, -0.0600, -0.0600, -0.0600, -0.0600, -0.0580,\n",
       "        -0.0550, -0.0520, -0.0500, -0.0470, -0.0450, -0.0490, -0.0500, -0.0500,\n",
       "        -0.0500, -0.0500, -0.0510, -0.0550, -0.0550, -0.0550, -0.0550, -0.0550,\n",
       "        -0.0590, -0.0600, -0.0600, -0.0600, -0.0600, -0.0590, -0.0550, -0.0550,\n",
       "        -0.0530, -0.0490, -0.0510, -0.0460, -0.0400, -0.0350, -0.0300, -0.0240,\n",
       "        -0.0180,  0.0010,  0.0430,  0.0570,  0.0450,  0.0430,  0.0260, -0.0150,\n",
       "        -0.0390, -0.0610, -0.0580, -0.0670, -0.0810, -0.0870, -0.0480,  0.0730,\n",
       "         0.2420,  0.6750,  0.7510,  0.3080,  0.0960,  0.0180, -0.0190, -0.0290,\n",
       "        -0.0460, -0.0480, -0.0590, -0.0510, -0.0510, -0.0460, -0.0440, -0.0430,\n",
       "        -0.0380, -0.0370, -0.0330, -0.0300, -0.0280, -0.0050,  0.0150,  0.0260,\n",
       "         0.0480,  0.0740,  0.1060,  0.1370,  0.1680,  0.1740,  0.1610,  0.1490,\n",
       "         0.1170,  0.0750,  0.0310, -0.0030, -0.0280, -0.0440, -0.0460, -0.0490,\n",
       "        -0.0520, -0.0550, -0.0550, -0.0550, -0.0550, -0.0550, -0.0520, -0.0490,\n",
       "        -0.0460, -0.0430, -0.0400, -0.0400, -0.0400, -0.0400, -0.0400, -0.0400,\n",
       "        -0.0400, -0.0440, -0.0450, -0.0450, -0.0500, -0.0500, -0.0510, -0.0550,\n",
       "        -0.0550, -0.0550, -0.0550, -0.0550, -0.0520, -0.0490, -0.0460, -0.0430,\n",
       "        -0.0400, -0.0390, -0.0270, -0.0160,  0.0040,  0.0380,  0.0450,  0.0350,\n",
       "         0.0240, -0.0030, -0.0400, -0.0680, -0.0790, -0.0800, -0.0970, -0.0840,\n",
       "        -0.1060, -0.0550,  0.0740,  0.2870,  0.7140,  0.6430,  0.2110,  0.0430,\n",
       "        -0.0350, -0.0550, -0.0730, -0.0840, -0.0790, -0.0820, -0.0770, -0.0760,\n",
       "        -0.0740, -0.0730, -0.0650, -0.0590, -0.0520, -0.0460, -0.0400, -0.0310,\n",
       "        -0.0190, -0.0060,  0.0060,  0.0330,  0.0640,  0.0970,  0.1300,  0.1600,\n",
       "         0.1730,  0.1620,  0.1470,  0.1030,  0.0500,  0.0110, -0.0190, -0.0340,\n",
       "        -0.0450, -0.0540, -0.0550, -0.0550, -0.0600, -0.0600, -0.0610, -0.0650,\n",
       "        -0.0650, -0.0650, -0.0650, -0.0650, -0.0650, -0.0650, -0.0650, -0.0650,\n",
       "        -0.0650, -0.0660, -0.0700, -0.0700, -0.0700, -0.0700, -0.0700, -0.0740,\n",
       "        -0.0750, -0.0750, -0.0750, -0.0750, -0.0740, -0.0700, -0.0700, -0.0700,\n",
       "        -0.0700, -0.0700, -0.0670, -0.0640, -0.0620, -0.0580, -0.0560, -0.0520,\n",
       "        -0.0350, -0.0040,  0.0310,  0.0410,  0.0330,  0.0320,  0.0130, -0.0330,\n",
       "        -0.0660, -0.0830, -0.0710, -0.0740, -0.0640, -0.0610, -0.0610,  0.0440,\n",
       "         0.1860,  0.5770,  0.6820,  0.2750,  0.0710, -0.0080, -0.0480, -0.0590,\n",
       "        -0.0790, -0.0780, -0.0880, -0.0760, -0.0760, -0.0700, -0.0650, -0.0620,\n",
       "        -0.0540, -0.0510, -0.0440, -0.0390, -0.0340, -0.0200, -0.0070,  0.0070,\n",
       "         0.0260,  0.0510,  0.0840,  0.1150,  0.1440,  0.1560,  0.1480,  0.1380,\n",
       "         0.1050,  0.0590,  0.0200, -0.0070, -0.0200, -0.0330, -0.0430, -0.0450,\n",
       "        -0.0450, -0.0480, -0.0510, -0.0490, -0.0460, -0.0430, -0.0410, -0.0370,\n",
       "        -0.0350, -0.0330, -0.0290, -0.0300, -0.0300, -0.0300, -0.0300, -0.0250,\n",
       "        -0.0250, -0.0250, -0.0250, -0.0250, -0.0270, -0.0310, -0.0300, -0.0340,\n",
       "        -0.0350, -0.0350, -0.0400, -0.0400, -0.0400, -0.0400, -0.0400, -0.0380,\n",
       "        -0.0310, -0.0270, -0.0210, -0.0140, -0.0120,  0.0040,  0.0190,  0.0570,\n",
       "         0.0930,  0.0840,  0.0750,  0.0550,  0.0190,  0.0070, -0.0090, -0.0100,\n",
       "        -0.0190, -0.0290, -0.0180, -0.0020,  0.0990,  0.2080,  0.5810,  0.7740,\n",
       "         0.3760,  0.1420,  0.0720,  0.0200,  0.0180, -0.0010,  0.0050, -0.0090,\n",
       "        -0.0100, -0.0140, -0.0100, -0.0050, -0.0040,  0.0030,  0.0040,  0.0100,\n",
       "         0.0200,  0.0290,  0.0410,  0.0530,  0.0750,  0.1010,  0.1240,  0.1520,\n",
       "         0.1810,  0.2050,  0.2250,  0.2350,  0.2120,  0.1700,  0.1270,  0.0840,\n",
       "         0.0470,  0.0210,  0.0090,  0.0040, -0.0010, -0.0070, -0.0130, -0.0150,\n",
       "        -0.0150, -0.0150, -0.0150, -0.0150, -0.0150, -0.0150, -0.0150, -0.0150,\n",
       "        -0.0150, -0.0150, -0.0170, -0.0210, -0.0200, -0.0200, -0.0200, -0.0200,\n",
       "        -0.0250, -0.0250, -0.0260, -0.0300, -0.0300, -0.0300, -0.0300, -0.0300,\n",
       "        -0.0300, -0.0300, -0.0300, -0.0250, -0.0250, -0.0240, -0.0200, -0.0210,\n",
       "        -0.0180, -0.0070,  0.0130,  0.0510,  0.0770,  0.0730,  0.0670,  0.0380,\n",
       "        -0.0080, -0.0320, -0.0530, -0.0480, -0.0610, -0.0550, -0.0650, -0.0600,\n",
       "         0.0730,  0.2290,  0.6570,  0.7750,  0.3230,  0.0970,  0.0190, -0.0190,\n",
       "        -0.0190, -0.0380, -0.0350, -0.0530, -0.0540, -0.0490, -0.0450, -0.0400,\n",
       "        -0.0360, -0.0310, -0.0240, -0.0180, -0.0100, -0.0050,  0.0020,  0.0220,\n",
       "         0.0410,  0.0660,  0.0920,  0.1190,  0.1510,  0.1790,  0.1970,  0.1860,\n",
       "         0.1690,  0.1320,  0.0770,  0.0310, -0.0040, -0.0280, -0.0400, -0.0510,\n",
       "        -0.0560, -0.0550, -0.0590, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,\n",
       "        -0.0600, -0.0600, -0.0630, -0.0650, -0.0650, -0.0690, -0.0700, -0.0700,\n",
       "        -0.0700, -0.0700, -0.0700, -0.0700, -0.0700, -0.0720, -0.0750, -0.0750,\n",
       "        -0.0750, -0.0750, -0.0750, -0.0750, -0.0750, -0.0750, -0.0750, -0.0750,\n",
       "        -0.0730, -0.0630, -0.0520, -0.0430, -0.0210,  0.0090,  0.0210,  0.0140,\n",
       "         0.0010, -0.0180, -0.0630, -0.0950, -0.1120, -0.1050, -0.1090, -0.1040,\n",
       "        -0.1030, -0.1090,  0.0160,  0.1630,  0.5560,  0.7190,  0.2910,  0.0500,\n",
       "        -0.0260, -0.0770, -0.0870, -0.1060, -0.0960, -0.1030, -0.0980, -0.1010,\n",
       "        -0.0970, -0.0920, -0.0900, -0.0850, -0.0820, -0.0780, -0.0710, -0.0620,\n",
       "        -0.0540, -0.0420, -0.0250, -0.0080,  0.0190,  0.0530,  0.0820,  0.1110,\n",
       "         0.1150,  0.1080,  0.0980,  0.0660,  0.0250, -0.0140, -0.0500, -0.0710,\n",
       "        -0.0800, -0.0850, -0.0850, -0.0860, -0.0900, -0.0900, -0.0870, -0.0850,\n",
       "        -0.0850, -0.0810, -0.0800, -0.0800, -0.0800, -0.0800, -0.0800, -0.0800,\n",
       "        -0.0800, -0.0820, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850,\n",
       "        -0.0850, -0.0850, -0.0850, -0.0850, -0.0820, -0.0790, -0.0800, -0.0800,\n",
       "        -0.0800, -0.0800, -0.0740, -0.0650, -0.0600, -0.0490, -0.0230,  0.0030,\n",
       "         0.0300,  0.0330,  0.0170,  0.0050, -0.0360, -0.0670, -0.0820, -0.0840,\n",
       "        -0.0960, -0.1010, -0.0850, -0.0890,  0.0200,  0.1380,  0.4790,  0.7300,\n",
       "         0.3590,  0.0830,  0.0180, -0.0410, -0.0510, -0.0710, -0.0610, -0.0700,\n",
       "        -0.0700, -0.0700, -0.0680, -0.0610, -0.0600, -0.0550, -0.0520, -0.0490,\n",
       "        -0.0400, -0.0300, -0.0200, -0.0080,  0.0120,  0.0340,  0.0580,  0.0880,\n",
       "         0.1070,  0.1380,  0.1650,  0.1600,  0.1510,  0.1170,  0.0700,  0.0260,\n",
       "        -0.0090, -0.0300, -0.0440, -0.0450, -0.0450, -0.0490, -0.0500, -0.0490,\n",
       "        -0.0450, -0.0450, -0.0450, -0.0450, -0.0450, -0.0410, -0.0400, -0.0400,\n",
       "        -0.0360, -0.0350, -0.0360, -0.0400, -0.0400, -0.0420, -0.0460, -0.0450,\n",
       "        -0.0490, -0.0500, -0.0500, -0.0500, -0.0500, -0.0500, -0.0500, -0.0500,\n",
       "        -0.0500, -0.0500, -0.0510, -0.0440, -0.0320, -0.0170,  0.0000,  0.0330,\n",
       "         0.0570,  0.0650,  0.0610,  0.0300, -0.0120, -0.0460, -0.0630, -0.0640,\n",
       "        -0.0680, -0.0650, -0.0450, -0.0640,  0.0330,  0.1460,  0.4510,  0.7680,\n",
       "         0.4510,  0.1360,  0.0550, -0.0120, -0.0170, -0.0390, -0.0400, -0.0560,\n",
       "        -0.0520, -0.0450, -0.0440, -0.0360, -0.0350, -0.0270, -0.0210, -0.0140,\n",
       "        -0.0070, -0.0020,  0.0070,  0.0220,  0.0340,  0.0540,  0.0840,  0.1130,\n",
       "         0.1390,  0.1730,  0.1990,  0.1990,  0.1830,  0.1510,  0.1090,  0.0650,\n",
       "         0.0240,  0.0020, -0.0040, -0.0110, -0.0190, -0.0260, -0.0300, -0.0300,\n",
       "        -0.0290, -0.0360, -0.0410, -0.0350, -0.0330, -0.0280, -0.0250, -0.0210,\n",
       "        -0.0200, -0.0200, -0.0160, -0.0140, -0.0170, -0.0200, -0.0200, -0.0220,\n",
       "        -0.0260, -0.0250, -0.0210, -0.0200, -0.0200, -0.0200, -0.0200, -0.0190,\n",
       "        -0.0110, -0.0030,  0.0040,  0.0140,  0.0190,  0.0600,  0.0970,  0.0940,\n",
       "         0.0850,  0.0530,  0.0070, -0.0180, -0.0380, -0.0420, -0.0390, -0.0410,\n",
       "        -0.0250, -0.0450,  0.0380,  0.1620,  0.4990,  0.8260,  0.4910,  0.1340,\n",
       "         0.0470, -0.0050, -0.0080, -0.0260, -0.0250, -0.0360, -0.0390, -0.0340,\n",
       "        -0.0320, -0.0270, -0.0240, -0.0200, -0.0150, -0.0060,  0.0020,  0.0110,\n",
       "         0.0240,  0.0390,  0.0490,  0.0660,  0.0940,  0.1220,  0.1500,  0.1820,\n",
       "         0.1970,  0.1910,  0.1850,  0.1560,  0.1060,  0.0620,  0.0210, -0.0060,\n",
       "        -0.0140, -0.0210, -0.0270, -0.0340, -0.0390, -0.0350, -0.0350, -0.0340,\n",
       "        -0.0290, -0.0310, -0.0270, -0.0250, -0.0250, -0.0210, -0.0200, -0.0210,\n",
       "        -0.0250, -0.0250, -0.0260, -0.0310, -0.0290, -0.0330, -0.0350, -0.0350,\n",
       "        -0.0390, -0.0410, -0.0390, -0.0360, -0.0330, -0.0310, -0.0270, -0.0260,\n",
       "        -0.0220, -0.0140, -0.0050,  0.0110,  0.0470,  0.0690,  0.0530,  0.0380,\n",
       "        -0.0010, -0.0430, -0.0540, -0.0800, -0.0850, -0.0920, -0.0720, -0.0880,\n",
       "        -0.0400,  0.0900,  0.3080,  0.7380,  0.6290,  0.1800,  0.0440, -0.0270,\n",
       "        -0.0570, -0.0710, -0.0710, -0.0700, -0.0780, -0.0720, -0.0740, -0.0680,\n",
       "        -0.0670, -0.0630, -0.0600, -0.0590, -0.0510, -0.0430, -0.0350, -0.0280,\n",
       "        -0.0180,  0.0040,  0.0290,  0.0550,  0.0850,  0.1140,  0.1420,  0.1550,\n",
       "         0.1480,  0.1160,  0.0630,  0.0150, -0.0230, -0.0490, -0.0640, -0.0800,\n",
       "        -0.0860, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850,\n",
       "        -0.0850, -0.0850, -0.0850, -0.0900, -0.0900, -0.0900, -0.0900, -0.0890,\n",
       "        -0.0930, -0.0950, -0.0950, -0.0950, -0.0950, -0.0940, -0.0900, -0.0900,\n",
       "        -0.0900, -0.0900, -0.0910, -0.0870, -0.0840, -0.0850, -0.0840, -0.0860,\n",
       "        -0.0840, -0.0810, -0.0740, -0.0730, -0.0630, -0.0310, -0.0190, -0.0190,\n",
       "        -0.0240, -0.0280, -0.0610, -0.1030, -0.1260, -0.1240, -0.1150, -0.1180,\n",
       "        -0.0960, -0.1180, -0.0280,  0.0860,  0.3980,  0.7050,  0.3690,  0.0550,\n",
       "        -0.0280, -0.0910, -0.0910, -0.1110, -0.1020, -0.1060, -0.1050, -0.1040],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb71edeb3acefa7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f15415a04d342",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "222339ccd77bf4ea",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# RNN1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4baa946bde015adf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T10:33:49.365070Z",
     "start_time": "2024-05-03T10:33:49.330372Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bn_drop_lin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn1d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RNN1d\n\u001b[1;32m----> 3\u001b[0m rnn1d_model \u001b[38;5;241m=\u001b[39m \u001b[43mRNN1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m rnn1d_model\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[0;32m      5\u001b[0m rnn1d_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\PycharmProjects\\ecg-tool-api\\models\\nn\\rnn1d.py:61\u001b[0m, in \u001b[0;36mRNN1d.__init__\u001b[1;34m(self, input_channels, num_classes, lstm, hidden_dim, num_layers, bidirectional, ps_head, act_head, lin_ftrs_head, bn)\u001b[0m\n\u001b[0;32m     57\u001b[0m actns \u001b[38;5;241m=\u001b[39m [nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m act_head \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mELU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mlen\u001b[39m(lin_ftrs_head) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m [\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ni, no, p, actn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lin_ftrs_head[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], lin_ftrs_head[\u001b[38;5;241m1\u001b[39m:], ps_head, actns):\n\u001b[1;32m---> 61\u001b[0m     layers_head \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mbn_drop_lin\u001b[49m(ni, no, bn, p, actn)\n\u001b[0;32m     62\u001b[0m layers_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mlayers_head)\n\u001b[0;32m     63\u001b[0m layers_tmp\u001b[38;5;241m.\u001b[39mappend(layers_head)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bn_drop_lin' is not defined"
     ]
    }
   ],
   "source": [
    "from models.nn.rnn1d import RNN1d\n",
    "\n",
    "rnn1d_model = RNN1d(input_channels=12, num_classes=5)\n",
    "rnn1d_model.double()\n",
    "rnn1d_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a70f5-d26e-4a57-b5ee-4e5394b8257d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f024b8e-1cdf-45a9-a017-de218c3ce6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5684eb-ceff-4cbd-a84f-bd004b40b7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1db7ec-ab1e-42d0-bdce-09047a98d039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "927c92be-f116-47ec-9728-87a211849eaf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e5bcac4-add4-41c0-ba65-650490aba63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4c0848b-3bec-4d00-8079-d66112f984c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:41<00:00, 51.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.8897126969416126, 0.9216867469879518, 0.8665430954587581, 0.8873957367933272, 0.9031510658016683]\n",
      "accuracy: 0.8936978683966637\n",
      "roc_score : 0.945232846766223\n",
      "class wise AUC : [0.9417918559062147, 0.9382669823171321, 0.932451379466305, 0.958210265166821, 0.9554437509746423]\n",
      "F1 score (Max): 0.8080090213529213\n",
      "class wise precision, recall, f1 score : (0.8080090213529213, 0.945232846766223, [0.8080090213529213, 0.8041618410750325, 0.8005559699915934, 0.7979259734294084, 0.791585762440762, 0.7877588781528645, 0.7830403633295228, 0.7758309809935896, 0.7668490152751574, 0.7584454037942777], [0.8434701188731478, 0.8495703189555446, 0.8566565809379728, 0.8647435897435898, 0.8716169023921774, 0.8788485495639794, 0.8908849881148291, 0.8964660667416573, 0.9036714975845411, 0.9055489964580874], [0.775409329626197, 0.7633611368551128, 0.7513515600864997, 0.7406935434043868, 0.7250154464009887, 0.7137781896818042, 0.6984862527031201, 0.6838121717639789, 0.6660101946246525, 0.6524559777571826], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gt, scores = evaluate_model(xresnet1d_model, test_dataset)\n",
    "# cm, y_pred = calculate_metrics(scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cd8734c-fae9-47a2-bf4c-cd719ef07a56",
   "metadata": {},
   "source": [
    "# y_pred=[]\n",
    "# for sample in  tqdm(scores):\n",
    "#   y_pred.append([1 if i>=0.5 else 0 for i in sample ] )\n",
    "# y_pred = np.array(y_pred)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a7ea2b2-b36e-4d46-b662-2c47820accbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from models.metrics import MR, multilabel_accuracy, zero_one_loss, multilabel_recall, multilabel_precision, multilabel_hamming_loss\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def calculate_metrics(scores):\n",
    "    \n",
    "    y_pred=[]\n",
    "    for sample in  tqdm(scores):\n",
    "      sample = sigmoid(sample)\n",
    "      y_pred.append([1 if i>=0.5 else 0 for i in sample ] )\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    confusion_matrix = multilabel_confusion_matrix(gt, y_pred)\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix)\n",
    "    \n",
    "    match_ratio = MR(gt, y_pred)\n",
    "    print(\"\\nMR: \", match_ratio.round(3))\n",
    "    \n",
    "    mlb_accuracy = multilabel_accuracy(gt, y_pred)\n",
    "    print(\"\\nAccuracy: \", mlb_accuracy.round(3))\n",
    "\n",
    "    zoneloss = zero_one_loss(gt, y_pred)\n",
    "    print(\"\\n0/1Loss: \", zoneloss.round(3))\n",
    "    \n",
    "    mlb_recall = multilabel_recall(gt, y_pred)\n",
    "    print(\"\\nRecall: \", mlb_recall.round(3))\n",
    "    \n",
    "    mlb_precision = multilabel_precision(gt, y_pred)\n",
    "    print(\"\\nPrecision: \", mlb_precision.round(3))\n",
    "    \n",
    "    mlb_hamming_loss = multilabel_hamming_loss(gt, y_pred)\n",
    "    print(\"\\nHamming loss: \", mlb_hamming_loss)\n",
    "\n",
    "    return confusion_matrix, y_pred\n",
    "   \n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85f5fb2071e0d9d1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:00<00:00, 47928.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[[1635   27]\n",
      "  [ 183  313]]\n",
      "\n",
      " [[1870   26]\n",
      "  [ 123  139]]\n",
      "\n",
      " [[1541   67]\n",
      "  [ 207  343]]\n",
      "\n",
      " [[1005  190]\n",
      "  [  62  901]]\n",
      "\n",
      " [[1530  107]\n",
      "  [ 103  418]]]\n",
      "\n",
      "MR:  0.657\n",
      "\n",
      "Accuracy:  0.748\n",
      "\n",
      "0/1Loss:  0.343\n",
      "\n",
      "Recall:  0.775\n",
      "\n",
      "Precision:  0.8\n",
      "\n",
      "Hamming loss:  0.10148285449490269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cm, y_pred = calculate_metrics(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e1153629844478b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1635,   27],\n",
       "       [ 183,  313]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "244877ec-092c-4080-bd8b-75823f7bbc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Определяем названия классов\n",
    "classes = ['CD', 'HYP', 'MI', 'NORM', 'STTC']\n",
    "\n",
    "# Визуализация матриц ошибок в одну строку\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for i, (matrix, class_name) in enumerate(zip(cm, classes)):\n",
    "    axes[i].matshow(matrix, cmap=\"Pastel2_r\")\n",
    "    axes[i].set_title(class_name)\n",
    "    for (j, k), value in np.ndenumerate(matrix):\n",
    "        axes[i].text(k, j, f\"{value}\", ha='center', va='center')\n",
    "    axes[i].set_xlabel(\"Predicted label\")\n",
    "    axes[i].set_ylabel(\"True label\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff19b50b-d2c6-4be0-8e07-5d21aeaae8dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (5, 2, 2) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHYP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNORM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSTTC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 5\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(cm, classes)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_confusion_matrix\u001b[39m(cm, classes):\n\u001b[0;32m      4\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[1;32m----> 5\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_xticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(classes)))\n\u001b[0;32m      7\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_yticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(classes)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\__init__.py:1459\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1459\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1461\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1462\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1463\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5663\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m   5656\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   5657\u001b[0m                       interpolation\u001b[38;5;241m=\u001b[39minterpolation, origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m   5658\u001b[0m                       extent\u001b[38;5;241m=\u001b[39mextent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   5659\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   5660\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5661\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 5663\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5664\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5666\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\image.py:710\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    711\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (5, 2, 2) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, ['CD', 'HYP', 'MI', 'NORM', 'STTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3fa63-0fde-4ab1-bf1a-119746f51ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad6a36b899ecefac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (2), usually from a call to set_ticks, does not match the number of labels (5).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Plot the first confusion matrix (Model 1) at position (0, 0)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel 1\u001b[39m\u001b[38;5;124m\"\u001b[39m, size\u001b[38;5;241m=\u001b[39mtitle_size)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mConfusionMatrixDisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfusion_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolorbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolorbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# # Remove x-axis labels and ticks\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# axes[0, 0].xaxis.set_ticklabels(['', '', '', ''])\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# axes[0, 0].set_xlabel('')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# ConfusionMatrixDisplay(confusion_matrix=cm01, display_labels=display_labels).plot(\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#     include_values=True, cmap=cmap, ax=axes[0, 1], colorbar=colorbar, values_format=values_format)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:181\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[1;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m colorbar:\n\u001b[0;32m    180\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_, ax\u001b[38;5;241m=\u001b[39max)\n\u001b[1;32m--> 181\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicted label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim((n_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m    191\u001b[0m plt\u001b[38;5;241m.\u001b[39msetp(ax\u001b[38;5;241m.\u001b[39mget_xticklabels(), rotation\u001b[38;5;241m=\u001b[39mxticks_rotation)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\artist.py:147\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_autogenerated_signature\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mArtist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\artist.py:1231\u001b[0m, in \u001b[0;36mArtist.set\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[1;32m-> 1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\artist.py:1223\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[38;5;124;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\artist.py:1199\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[1;34m(self, props, errfmt)\u001b[0m\n\u001b[0;32m   1196\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m   1197\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1198\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk))\n\u001b[1;32m-> 1199\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpchanged()\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\axes\\_base.py:74\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     warn_deprecated(\n\u001b[0;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\matplotlib\\axis.py:2018\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[1;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[0;32m   2014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[0;32m   2015\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[0;32m   2016\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[0;32m   2017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2018\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2019\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2020\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2021\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2022\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2023\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[0;32m   2024\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (2), usually from a call to set_ticks, does not match the number of labels (5)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title_size = 16\n",
    "plt.rcParams.update({'font.size':16})\n",
    "display_labels = ['CD', 'HYP', 'MI', 'NORM', 'STTC']  \n",
    "colorbar = False\n",
    "cmap = \"Blues\"  # Try \"Greens\". Change the color of the confusion matrix.\n",
    "## Please see other alternatives at https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "values_format = \".3f\"  # Determine the number of decimal places to be displayed.\n",
    "\n",
    "# Create subplots for given confusion matrices\n",
    "f, axes = plt.subplots(1, 5, figsize=(10, 16))\n",
    "\n",
    "# Plot the first confusion matrix (Model 1) at position (0, 0)\n",
    "axes[0, 0].set_title(\"Model 1\", size=title_size)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm[0], display_labels=display_labels).plot(\n",
    "    include_values=True, cmap=cmap, ax=axes[0, 1], colorbar=colorbar, values_format=values_format)\n",
    "\n",
    "# # Remove x-axis labels and ticks\n",
    "# axes[0, 0].xaxis.set_ticklabels(['', '', '', ''])\n",
    "# axes[0, 0].set_xlabel('')\n",
    "# axes[0, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "\n",
    "# # Plot the second confusion matrix (Model 2) at position (0, 1)\n",
    "# axes[0, 1].set_title(\"Model 2\", size=title_size)\n",
    "# ConfusionMatrixDisplay(confusion_matrix=cm01, display_labels=display_labels).plot(\n",
    "#     include_values=True, cmap=cmap, ax=axes[0, 1], colorbar=colorbar, values_format=values_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3383d597-9d1a-4d0f-893d-0b4eee25f817",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgt\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gt' is not defined"
     ]
    }
   ],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc09de78-3e8f-4eea-9494-9cc51a7350f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\redmi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.92      0.63      0.75       496\\n           1       0.84      0.53      0.65       262\\n           2       0.84      0.62      0.71       550\\n           3       0.83      0.94      0.88       963\\n           4       0.80      0.80      0.80       521\\n\\n   micro avg       0.84      0.76      0.79      2792\\n   macro avg       0.84      0.70      0.76      2792\\nweighted avg       0.84      0.76      0.79      2792\\n samples avg       0.80      0.78      0.78      2792\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(gt, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0fe4a7-26e7-4311-8225-7351f25016d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87743deb-b38e-449d-a8f5-8190fcb3fdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e55c476-a06a-4723-b979-d511986c5fed",
   "metadata": {},
   "source": [
    "# VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e44b2d87-2f0a-4876-8098-049deec529c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECG_CRNN(\n",
       "  (cnn): VGG16(\n",
       "    (vgg_block_1): VGGBlock(\n",
       "      (cba_1): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(12, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (cba_2): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (max_pool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (vgg_block_2): VGGBlock(\n",
       "      (cba_1): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (cba_2): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (max_pool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (vgg_block_3): VGGBlock(\n",
       "      (cba_1): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (cba_2): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (cba_3): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (max_pool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (vgg_block_4): VGGBlock(\n",
       "      (cba_1): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (cba_2): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (cba_3): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (max_pool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (vgg_block_5): VGGBlock(\n",
       "      (cba_1): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (cba_2): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (cba_3): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (max_pool): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (rnn_in_rearrange): Rearrange('batch_size channels seq_len -> seq_len batch_size channels')\n",
       "  (rnn): Identity()\n",
       "  (rnn_out_rearrange): Identity()\n",
       "  (attn_in_rearrange): Rearrange('seq_len batch_size channels -> batch_size channels seq_len')\n",
       "  (attn): SEBlock(\n",
       "    (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "    (fc): Sequential(\n",
       "      (0): SeqLin(\n",
       "        (lin_0): Linear(in_features=384, out_features=48, bias=True)\n",
       "        (act_0): ReLU(inplace=True)\n",
       "        (lin_1): Linear(in_features=48, out_features=384, bias=True)\n",
       "      )\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (attn_out_rearrange): Identity()\n",
       "  (pool): AdaptiveMaxPool1d(output_size=(1,))\n",
       "  (pool_rearrange): Rearrange('batch_size channels pool_size -> batch_size (channels pool_size)')\n",
       "  (clf): MLP(\n",
       "    (lin_0): Linear(in_features=384, out_features=1024, bias=True)\n",
       "    (act_0): Mish()\n",
       "    (dropout_0): Dropout(p=0.2, inplace=False)\n",
       "    (lin_1): Linear(in_features=1024, out_features=5, bias=True)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_ecg.utils.utils_nn import adjust_cnn_filter_lengths\n",
    "from torch_ecg.model_configs import ECG_CRNN_CONFIG\n",
    "from torch_ecg.models.ecg_crnn import ECG_CRNN\n",
    "\n",
    "\n",
    "# xresnet1d_model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\xresnet1d101\\exp0_xresnet1d101xresnet1d101_fold1_19epoch_best_score.pth'\n",
    "# xresnet1d_model.load_state_dict(torch.load(xresnet1d_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "# xresnet1d_model.double()\n",
    "# xresnet1d_model.eval()\n",
    "\n",
    "vgg16_model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\vgg16\\vgg16_fold1_10epoch_best_score.pth'\n",
    "config = adjust_cnn_filter_lengths(ECG_CRNN_CONFIG, fs=100)\n",
    "config.cnn.name=\"vgg16\"\n",
    "classes = ['CD', 'HYP', 'MI', 'NORM', 'STTC']\n",
    "n_leads = 12\n",
    "vgg16_model = ECG_CRNN(classes, n_leads, config)\n",
    "vgg16_model.load_state_dict(torch.load(vgg16_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "vgg16_model.double()\n",
    "vgg16_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42829d-8091-48ad-9c2f-08173a8a3593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ec087-1da8-445a-8004-bf3362b52495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00d1c440-7f73-4159-b2e4-4e153c630c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:34<00:00, 62.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9443929564411492, 0.9416126042632067, 0.9235403151065802, 0.9564411492122336, 0.9341983317886933]\n",
      "accuracy: 0.9400370713623726\n",
      "roc_score : 0.9778205177504251\n",
      "class wise AUC : [0.9753952195178759, 0.9644631526395465, 0.9802702397105383, 0.9911260574303626, 0.9778479194538017]\n",
      "F1 score (Max): 0.9046505804439674\n",
      "class wise precision, recall, f1 score : (0.9046505804439674, 0.9778205177504251, [0.9046505804439674, 0.9038983394952643, 0.9031458501126676, 0.9015237484493674, 0.8957272207129167, 0.8915892787278965, 0.8850983564496786, 0.8792953346269956, 0.8728961897776523, 0.8668126507611201], [0.9299233349305223, 0.9368065605402798, 0.9421554370657619, 0.9476621049201693, 0.9491379310344827, 0.9539440838741887, 0.9573016675088428, 0.9636192432802603, 0.965057948451825, 0.96821215314366], [0.8807151683657708, 0.8732236638863144, 0.8672381835032438, 0.8596694470188445, 0.8480074142724745, 0.8368860055607044, 0.8230228606734632, 0.8085418597466791, 0.7968025949953661, 0.7846385542168675], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gt, scores = evaluate_model(vgg16_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03012d78-18e2-4604-8205-e79dc26f9bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:22<00:00, 96.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9443929564411492, 0.9416126042632067, 0.9235403151065802, 0.9564411492122336, 0.9341983317886933]\n",
      "accuracy: 0.9400370713623726\n",
      "roc_score : 0.9778205177504251\n",
      "class wise AUC : [0.9753952195178759, 0.9644631526395465, 0.9802702397105383, 0.9911260574303626, 0.9778479194538017]\n",
      "F1 score (Max): 0.9046505804439674\n",
      "class wise precision, recall, f1 score : (0.9046505804439674, 0.9778205177504251, [0.9046505804439674, 0.9038983394952643, 0.9031458501126676, 0.9015237484493674, 0.8957272207129167, 0.8915892787278965, 0.8850983564496786, 0.8792953346269956, 0.8728961897776523, 0.8668126507611201], [0.9299233349305223, 0.9368065605402798, 0.9421554370657619, 0.9476621049201693, 0.9491379310344827, 0.9539440838741887, 0.9573016675088428, 0.9636192432802603, 0.965057948451825, 0.96821215314366], [0.8807151683657708, 0.8732236638863144, 0.8672381835032438, 0.8596694470188445, 0.8480074142724745, 0.8368860055607044, 0.8230228606734632, 0.8085418597466791, 0.7968025949953661, 0.7846385542168675], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gt, scores = evaluate_model(vgg16_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db5810da-28aa-4302-a382-282c30589912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:00<00:00, 164736.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[[1631   31]\n",
      "  [  88  408]]\n",
      "\n",
      " [[1868   28]\n",
      "  [  93  169]]\n",
      "\n",
      " [[1573   35]\n",
      "  [ 104  446]]\n",
      "\n",
      " [[1116   79]\n",
      "  [  25  938]]\n",
      "\n",
      " [[1590   47]\n",
      "  [  80  441]]]\n",
      "\n",
      "MR:  0.781\n",
      "\n",
      "Accuracy:  0.857\n",
      "\n",
      "0/1Loss:  0.219\n",
      "\n",
      "Recall:  0.881\n",
      "\n",
      "Precision:  0.899\n",
      "\n",
      "Hamming loss:  0.056533827618164965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cm, y_pred = calculate_metrics(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e3eea9f-7ae6-4515-9807-74ebe4c17153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.93      0.82      0.87       496\n",
      "         HYP       0.86      0.65      0.74       262\n",
      "          MI       0.93      0.81      0.87       550\n",
      "        NORM       0.92      0.97      0.95       963\n",
      "        STTC       0.90      0.85      0.87       521\n",
      "\n",
      "   micro avg       0.92      0.86      0.89      2792\n",
      "   macro avg       0.91      0.82      0.86      2792\n",
      "weighted avg       0.92      0.86      0.88      2792\n",
      " samples avg       0.90      0.88      0.88      2792\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\redmi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gt, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da395985-5929-45f7-af7c-920c569ac536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ba949-4ff5-420e-b096-d7a12643f9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fd062-74b2-481b-8533-47a989eb2f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a79672-522f-437f-9c21-9f8e955c2ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4844a08-7c23-40e4-a3b2-5ff666761c7c",
   "metadata": {},
   "source": [
    "# MobileNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ce69a37-3a9d-4a6a-825d-fef069afa5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECG_CRNN(\n",
       "  (cnn): MobileNetV3(\n",
       "    (stem): MobileNetV3_STEM(\n",
       "      (init_conv): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(12, 24, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (batch_norm): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (block_0): InvertedResidualBlock(\n",
       "      (inv_res_0): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(24, 96, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(96, 96, kernel_size=(3,), stride=(2,), padding=(1,), groups=96)\n",
       "            (batch_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU()\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=96, out_features=12, bias=False)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=12, out_features=96, bias=False)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(96, 48, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block_1): InvertedResidualBlock(\n",
       "      (inv_res_0): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(48, 192, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(192, 192, kernel_size=(3,), stride=(2,), padding=(1,), groups=192)\n",
       "            (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU()\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(192, 96, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inv_res_1): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(96, 384, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "            (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU()\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(384, 96, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block_2): InvertedResidualBlock(\n",
       "      (inv_res_0): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(96, 384, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,), groups=384)\n",
       "            (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=384, out_features=48, bias=False)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=48, out_features=384, bias=False)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(384, 192, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inv_res_1): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(192, 768, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=768, out_features=96, bias=False)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=96, out_features=768, bias=False)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 192, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inv_res_2): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(192, 768, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=768, out_features=96, bias=False)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=96, out_features=768, bias=False)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 192, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inv_res_3): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(192, 768, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=768, out_features=96, bias=False)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=96, out_features=768, bias=False)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 192, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inv_res_4): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(192, 768, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,), groups=768)\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=768, out_features=96, bias=False)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=96, out_features=768, bias=False)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 192, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block_3): InvertedResidualBlock(\n",
       "      (inv_res_0): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(192, 768, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,), groups=768)\n",
       "            (batch_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=768, out_features=96, bias=False)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=96, out_features=768, bias=False)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(768, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inv_res_1): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "            (batch_norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=1536, out_features=192, bias=False)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=192, out_features=1536, bias=False)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inv_res_2): InvertedResidual(\n",
       "        (main_stream): Sequential(\n",
       "          (expansion): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (batch_norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (depthwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "            (batch_norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_Hardswish): Hardswish()\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=1536, out_features=192, bias=False)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=192, out_features=1536, bias=False)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (pointwise_conv): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (exit_flow): Conv_Bn_Activation(\n",
       "      (conv1d): Conv1d(384, 1536, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      (batch_norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation_ReLU): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (rnn_in_rearrange): Rearrange('batch_size channels seq_len -> seq_len batch_size channels')\n",
       "  (rnn): Identity()\n",
       "  (rnn_out_rearrange): Identity()\n",
       "  (attn_in_rearrange): Rearrange('seq_len batch_size channels -> batch_size channels seq_len')\n",
       "  (attn): SEBlock(\n",
       "    (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "    (fc): Sequential(\n",
       "      (0): SeqLin(\n",
       "        (lin_0): Linear(in_features=1536, out_features=192, bias=True)\n",
       "        (act_0): ReLU(inplace=True)\n",
       "        (lin_1): Linear(in_features=192, out_features=1536, bias=True)\n",
       "      )\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (attn_out_rearrange): Identity()\n",
       "  (pool): AdaptiveMaxPool1d(output_size=(1,))\n",
       "  (pool_rearrange): Rearrange('batch_size channels pool_size -> batch_size (channels pool_size)')\n",
       "  (clf): MLP(\n",
       "    (lin_0): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "    (act_0): Mish()\n",
       "    (dropout_0): Dropout(p=0.2, inplace=False)\n",
       "    (lin_1): Linear(in_features=1024, out_features=5, bias=True)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet_model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\mobilenet\\mobilenet_v3_fold1_3epoch_best_score.pth'\n",
    "config = adjust_cnn_filter_lengths(ECG_CRNN_CONFIG, fs=100)\n",
    "config.cnn.name=\"mobilenet_v3\"\n",
    "classes = ['CD', 'HYP', 'MI', 'NORM', 'STTC']\n",
    "n_leads = 12\n",
    "mobilenet = ECG_CRNN(classes, n_leads, config)\n",
    "mobilenet.load_state_dict(torch.load(mobilenet_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "mobilenet.double()\n",
    "mobilenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed89cf24-d23e-4d17-9ad8-d0cdd916545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [05:48<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.8999073215940686, 0.9323447636700649, 0.8586654309545876, 0.8994439295644114, 0.901760889712697]\n",
      "accuracy: 0.8984244670991659\n",
      "roc_score : 0.9495002674831957\n",
      "class wise AUC : [0.9391012577151509, 0.945415418558959, 0.9380269109000452, 0.9669555998731302, 0.9580021503686933]\n",
      "F1 score (Max): 0.8181791569468833\n",
      "class wise precision, recall, f1 score : (0.8181791569468833, 0.9495002674831957, [0.8181791569468833, 0.8152394938260943, 0.8117681358720336, 0.8072227926359807, 0.8028361461598871, 0.7944860354606909, 0.7886988645794696, 0.7842968287658761, 0.7788066548107536, 0.7690326215584468], [0.8542575537243497, 0.862151067323481, 0.8692326980942828, 0.877491057741441, 0.8852266805627931, 0.8883430695698353, 0.8950533550370773, 0.9044117647058824, 0.9147187381223868, 0.9208699902248288], [0.7850247142415818, 0.7731696014828545, 0.7614303367315416, 0.7473741118319431, 0.7344763670064874, 0.7185665739882607, 0.704935125115848, 0.6923463083101637, 0.6780583873957368, 0.6601791782514673], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    }
   ],
   "source": [
    "gt, scores = evaluate_model(mobilenet, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc58a5e-16fa-43ce-b7a2-5f36435afc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acebcf7d-575c-4d82-8b74-c38e2e34cb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16741e-82e3-4d10-8a61-d73fd3775349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e97504-ca84-4f9d-a440-d8d79b2142b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6515e63a-3d6d-420b-b2f1-3d73e8ea0371",
   "metadata": {},
   "source": [
    "# RegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e242792f-2d38-4650-a0ea-ff422b65004b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECG_CRNN(\n",
       "  (cnn): RegNet(\n",
       "    (input_stem): RegNetStem(\n",
       "      (conv_0): Conv_Bn_Activation(\n",
       "        (conv1d): Conv1d(12, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (batch_norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation_ReLU): ReLU()\n",
       "      )\n",
       "      (pool): DownSample(\n",
       "        (down_sample): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (stage_0): AnyStage(\n",
       "      (block_0_0): ResNetBottleNeck(\n",
       "        (shortcut): DownSample(\n",
       "          (down_sample): Conv1d(64, 48, kernel_size=(1,), stride=(2,), bias=False)\n",
       "          (batch_normalization): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(64, 48, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(48, 48, kernel_size=(3,), stride=(2,), padding=(1,), groups=2, bias=False)\n",
       "            (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(48, 48, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=48, out_features=6, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=6, out_features=48, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_0_1): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(48, 48, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(1,), groups=2, bias=False)\n",
       "            (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(48, 48, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=48, out_features=6, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=6, out_features=48, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "    )\n",
       "    (stage_1): AnyStage(\n",
       "      (block_1_0): ResNetBottleNeck(\n",
       "        (shortcut): DownSample(\n",
       "          (down_sample): Conv1d(48, 120, kernel_size=(1,), stride=(2,), bias=False)\n",
       "          (batch_normalization): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(48, 115, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 115, kernel_size=(3,), stride=(2,), padding=(1,), groups=5, bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 120, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=120, out_features=15, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=15, out_features=120, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_1_1): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(120, 115, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 115, kernel_size=(3,), stride=(1,), padding=(1,), groups=5, bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 120, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=120, out_features=15, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=15, out_features=120, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_1_2): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(120, 115, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 115, kernel_size=(3,), stride=(1,), padding=(1,), groups=5, bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 120, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=120, out_features=15, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=15, out_features=120, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_1_3): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(120, 115, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 115, kernel_size=(3,), stride=(1,), padding=(1,), groups=5, bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 120, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=120, out_features=15, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=15, out_features=120, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_1_4): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(120, 115, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 115, kernel_size=(3,), stride=(1,), padding=(1,), groups=5, bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 120, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=120, out_features=15, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=15, out_features=120, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_1_5): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(120, 115, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 115, kernel_size=(3,), stride=(1,), padding=(1,), groups=5, bias=False)\n",
       "            (batch_norm): BatchNorm1d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(115, 120, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=120, out_features=15, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=15, out_features=120, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "    )\n",
       "    (stage_2): AnyStage(\n",
       "      (block_2_0): ResNetBottleNeck(\n",
       "        (shortcut): DownSample(\n",
       "          (down_sample): Conv1d(120, 336, kernel_size=(1,), stride=(2,), bias=False)\n",
       "          (batch_normalization): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(120, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(2,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_1): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_2): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_3): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_4): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_5): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_6): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_7): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_8): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_9): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_10): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_11): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_12): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_13): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_14): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_15): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_2_16): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(3,), stride=(1,), padding=(1,), groups=14, bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 336, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=336, out_features=42, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=42, out_features=336, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "    )\n",
       "    (stage_3): AnyStage(\n",
       "      (block_3_0): ResNetBottleNeck(\n",
       "        (shortcut): DownSample(\n",
       "          (down_sample): Conv1d(336, 888, kernel_size=(1,), stride=(2,), bias=False)\n",
       "          (batch_normalization): BatchNorm1d(888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(336, 888, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(888, 888, kernel_size=(3,), stride=(2,), padding=(1,), groups=37, bias=False)\n",
       "            (batch_norm): BatchNorm1d(888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(888, 888, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=888, out_features=111, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=111, out_features=888, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "      (block_3_1): ResNetBottleNeck(\n",
       "        (shortcut): Identity()\n",
       "        (main_stream): Sequential(\n",
       "          (cba_head): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(888, 888, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_neck): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(888, 888, kernel_size=(3,), stride=(1,), padding=(1,), groups=37, bias=False)\n",
       "            (batch_norm): BatchNorm1d(888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation_ReLU): ReLU(inplace=True)\n",
       "          )\n",
       "          (cba_tail): Conv_Bn_Activation(\n",
       "            (conv1d): Conv1d(888, 888, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (batch_norm): BatchNorm1d(888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (se): SEBlock(\n",
       "            (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): SeqLin(\n",
       "                (lin_0): Linear(in_features=888, out_features=111, bias=True)\n",
       "                (act_0): ReLU(inplace=True)\n",
       "                (lin_1): Linear(in_features=111, out_features=888, bias=True)\n",
       "              )\n",
       "              (1): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_activation): ReLU(inplace=True)\n",
       "        (out_dropout): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (rnn_in_rearrange): Rearrange('batch_size channels seq_len -> seq_len batch_size channels')\n",
       "  (rnn): Identity()\n",
       "  (rnn_out_rearrange): Identity()\n",
       "  (attn_in_rearrange): Rearrange('seq_len batch_size channels -> batch_size channels seq_len')\n",
       "  (attn): SEBlock(\n",
       "    (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "    (fc): Sequential(\n",
       "      (0): SeqLin(\n",
       "        (lin_0): Linear(in_features=888, out_features=111, bias=True)\n",
       "        (act_0): ReLU(inplace=True)\n",
       "        (lin_1): Linear(in_features=111, out_features=888, bias=True)\n",
       "      )\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (attn_out_rearrange): Identity()\n",
       "  (pool): AdaptiveMaxPool1d(output_size=(1,))\n",
       "  (pool_rearrange): Rearrange('batch_size channels pool_size -> batch_size (channels pool_size)')\n",
       "  (clf): MLP(\n",
       "    (lin_0): Linear(in_features=888, out_features=1024, bias=True)\n",
       "    (act_0): Mish()\n",
       "    (dropout_0): Dropout(p=0.2, inplace=False)\n",
       "    (lin_1): Linear(in_features=1024, out_features=5, bias=True)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\regnet\\regnet_27_24_fold1_10epoch_best_score.pth\n",
    "regnet_model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\regnet\\regnet_27_24_fold1_10epoch_best_score.pth'\n",
    "config = adjust_cnn_filter_lengths(ECG_CRNN_CONFIG, fs=100)\n",
    "config.cnn.name=\"regnet_27_24\"\n",
    "classes = ['CD', 'HYP', 'MI', 'NORM', 'STTC']\n",
    "n_leads = 12\n",
    "regnet = ECG_CRNN(classes, n_leads, config)\n",
    "regnet.load_state_dict(torch.load(regnet_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "regnet.double()\n",
    "regnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53cb1722-ce3a-4821-b0f6-efe9d04ac221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [01:36<00:00, 22.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.8758109360518999, 0.9272474513438369, 0.8493975903614458, 0.9161260426320668, 0.9133456904541242]\n",
      "accuracy: 0.8963855421686748\n",
      "roc_score : 0.9392373779179364\n",
      "class wise AUC : [0.9129461686269944, 0.9160707958901021, 0.9332293080054274, 0.9730974943190952, 0.9608431227480633]\n",
      "F1 score (Max): 0.8228014495736116\n",
      "class wise precision, recall, f1 score : (0.8228014495736116, 0.9392373779179364, [0.8228014495736116, 0.8186749577524243, 0.8166158056078442, 0.8111439258339307, 0.802645738012891, 0.8009632117971975, 0.7916247149679855, 0.7837633487569987, 0.7753208601472028, 0.7624940376443793], [0.8578455284552845, 0.8667163684559311, 0.8754196038939243, 0.8812756147540983, 0.8872420426722631, 0.8980591168091168, 0.9030054644808743, 0.9120187793427231, 0.9179219775975279, 0.9239783653846154], [0.790508186592524, 0.775679641643497, 0.7652147049737411, 0.7513515600864997, 0.7327772628977448, 0.7228143342601173, 0.7047034291010195, 0.6871331479765216, 0.6710688909484089, 0.6490577695396972], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gt, scores = evaluate_model(regnet, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "283181e6-726b-4ffc-90b5-04efda6d41ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [01:50<00:00, 19.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.8883225208526413, 0.9291010194624653, 0.8688600556070436, 0.9138090824837812, 0.906858202038925]\n",
      "accuracy: 0.9013901760889713\n",
      "roc_score : 0.9392373779179364\n",
      "class wise AUC : [0.9129461686269944, 0.9160707958901021, 0.9332293080054274, 0.9730974943190952, 0.9608431227480633]\n",
      "F1 score (Max): 0.8397177359483794\n",
      "class wise precision, recall, f1 score : (0.8397177359483794, 0.9392373779179364, [0.41113238109262257, 0.786229692962842, 0.8308098315964298, 0.8397177359483794, 0.8322756725680879, 0.8166158056078442, 0.7905771325832022, 0.7440019013384844, 0.6315029125056157, nan], [0.258758109360519, 0.6729147358665432, 0.768303985171455, 0.8178754067875407, 0.8459403742467491, 0.8754196038939243, 0.9060205580029369, 0.9356687898089172, 0.9645602049530316, nan], [1.0, 0.9454355885078776, 0.9043867778807537, 0.8627587272165587, 0.8190454124189064, 0.7652147049737411, 0.7012279888785913, 0.6175084955205437, 0.469416126042632, 0.0], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gt, scores = evaluate_model(regnet, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48ddf3c4-d3a6-47d0-937a-eb7a76d9574c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.52519921e-03, 3.75845225e-04, 2.86774804e-03, 9.94029427e-01,\n",
       "        5.24788376e-05],\n",
       "       [9.07293666e-02, 2.90881560e-03, 6.01605381e-02, 8.70344206e-01,\n",
       "        2.27302275e-02],\n",
       "       [2.04408104e-02, 2.79763932e-03, 9.21883939e-03, 9.76920905e-01,\n",
       "        3.40483473e-03],\n",
       "       ...,\n",
       "       [7.16723957e-02, 7.48383336e-02, 4.70268201e-02, 8.30500856e-01,\n",
       "        7.76996174e-03],\n",
       "       [7.02959345e-01, 3.41441322e-02, 5.95875369e-01, 7.18140129e-02,\n",
       "        3.58954671e-02],\n",
       "       [6.97037598e-02, 2.25118027e-02, 2.64048073e-01, 2.04948933e-01,\n",
       "        5.28933500e-01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc3eb7-f6d5-4b8b-a774-f44012cebb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96065571-980f-4f09-abbb-1252e4ae858b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b3561939-f743-4cbc-a356-54aa58d64aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fs': 100, 'cnn': {'name': 'regnet_27_24', 'vgg16': {'fs': 100, 'num_convs': [2, 2, 3, 3, 3], 'num_filters': [48, 96, 192, 384, 384], 'groups': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {}, 'block': {'filter_length': 3, 'subsample_length': 1, 'dilation': 1, 'batch_norm': True, 'pool_size': 3, 'pool_stride': 2, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {}}}, 'vgg16_mish': {'fs': 100, 'num_convs': [2, 2, 3, 3, 3], 'num_filters': [48, 96, 192, 384, 384], 'groups': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {}, 'block': {'filter_length': 3, 'subsample_length': 1, 'dilation': 1, 'batch_norm': True, 'pool_size': 3, 'pool_stride': 2, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'mish', 'kw_activation': {}}}, 'vgg16_swish': {'fs': 100, 'num_convs': [2, 2, 3, 3, 3], 'num_filters': [48, 96, 192, 384, 384], 'groups': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {}, 'block': {'filter_length': 3, 'subsample_length': 1, 'dilation': 1, 'batch_norm': True, 'pool_size': 3, 'pool_stride': 2, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'swish', 'kw_activation': {}}}, 'vgg16_leadwise': {'fs': 100, 'num_convs': [2, 2, 3, 3, 3], 'num_filters': [192, 384, 768, 1536, 1536], 'groups': 12, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {}, 'block': {'filter_length': 3, 'subsample_length': 1, 'dilation': 1, 'batch_norm': True, 'pool_size': 3, 'pool_stride': 2, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'swish', 'kw_activation': {}}}, 'resnet_18': {'num_blocks': [2, 2, 2, 2], 'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'building_block': 'basic', 'block': {'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False}}, 'resnet_34': {'num_blocks': [3, 4, 6, 3], 'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'building_block': 'basic', 'block': {'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False}}, 'resnet_50': {'num_blocks': [3, 4, 6, 3], 'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'base_groups': 1, 'base_width': 64, 'building_block': 'bottleneck', 'block': {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False}}, 'resnext_50_32x4d': {'num_blocks': [3, 4, 6, 3], 'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': 3, 'groups': 32, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'base_groups': 1, 'base_width': 4, 'building_block': 'bottleneck', 'block': {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False}}, 'resnet_nature_comm': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [4, 4, 4, 4], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 3, 'conv_stride': 1, 'pool_size': 3, 'pool_stride': 1}, 'building_block': 'basic', 'block': {'increase_channels_method': 'conv', 'subsample_mode': 'max', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False}, 'dropouts': 0.2, 'num_filters': [128, 192, 256, 320]}, 'resnet_nature_comm_se': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [4, 4, 4, 4], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 3, 'conv_stride': 1, 'pool_size': 3, 'pool_stride': 1}, 'building_block': 'basic', 'block': {'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}}, 'dropouts': 0.2, 'num_filters': [128, 192, 256, 320]}, 'resnet_nature_comm_gc': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [4, 4, 4, 4], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 3, 'conv_stride': 1, 'pool_size': 3, 'pool_stride': 1}, 'building_block': 'basic', 'block': {'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'ratio': 4, 'reduction': True, 'pooling_type': 'attn', 'fusion_types': ['mul'], 'name': 'gc', 'pos': -1}}, 'dropouts': 0.2, 'num_filters': [128, 192, 256, 320]}, 'resnet_nature_comm_nl': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [4, 4, 4, 4], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 3, 'conv_stride': 1, 'pool_size': 3, 'pool_stride': 1}, 'building_block': 'basic', 'block': {'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'filter_lengths': {'g': 1, 'phi': 1, 'theta': 1, 'W': 1}, 'subsample_length': 2, 'batch_norm': True, 'name': 'nl', 'pos': -1}}, 'dropouts': 0.2, 'num_filters': [128, 192, 256, 320]}, 'resnet_nature_comm_bottle_neck': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [4, 4, 4, 4], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 3, 'conv_stride': 1, 'pool_size': 3, 'pool_stride': 1}, 'building_block': 'bottleneck', 'block': {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False}, 'dropouts': 0.2, 'num_filters': [128, 192, 256, 320]}, 'resnet_nature_comm_bottle_neck_se': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [4, 4, 4, 4], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 3, 'conv_stride': 1, 'pool_size': 3, 'pool_stride': 1}, 'building_block': 'bottleneck', 'block': {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}}, 'dropouts': 0.2, 'num_filters': [128, 192, 256, 320]}, 'resnet_nature_comm_bottle_neck_gc': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [4, 4, 4, 4], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 3, 'conv_stride': 1, 'pool_size': 3, 'pool_stride': 1}, 'building_block': 'bottleneck', 'block': {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'ratio': 4, 'reduction': True, 'pooling_type': 'attn', 'fusion_types': ['mul'], 'name': 'gc', 'pos': -1}}, 'dropouts': 0.2, 'num_filters': [128, 192, 256, 320]}, 'resnet_nature_comm_bottle_neck_nl': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [4, 4, 4, 4], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 3, 'conv_stride': 1, 'pool_size': 3, 'pool_stride': 1}, 'building_block': 'bottleneck', 'block': {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'filter_lengths': {'g': 1, 'phi': 1, 'theta': 1, 'W': 1}, 'subsample_length': 2, 'batch_norm': True, 'name': 'nl', 'pos': -1}}, 'dropouts': 0.2, 'num_filters': [128, 192, 256, 320]}, 'resnetN': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': [5, 3, 3, 1], 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'building_block': 'basic', 'block': {'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False}}, 'resnetNB': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': [5, 3, 3, 1], 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'building_block': 'bottleneck', 'block': {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False}}, 'resnetNS': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': [5, 3, 3, 1], 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'building_block': 'basic', 'block': {'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'conv_type': 'separable'}}, 'resnetNBS': {'num_blocks': [1, 1, 1, 1], 'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': [5, 3, 3, 1], 'groups': 1, 'increase_channels_method': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'building_block': 'bottleneck', 'block': {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'conv_type': 'separable'}}, 'tresnetF': {'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'stem': {'subsample_mode': 's2d', 'num_filters': 32, 'filter_lengths': 1, 'conv_stride': 1, 'pool_size': 1, 'pool_stride': 1}, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'building_block': ['basic', 'basic', 'bottleneck', 'bottleneck'], 'block': [{'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'separable'}, {'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'separable'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'pos': 2, 'filt_size': 7, 'conv_type': 'separable'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'filt_size': 7, 'conv_type': 'separable'}], 'num_blocks': [1, 1, 1, 1]}, 'tresnetP': {'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'stem': {'subsample_mode': 's2d', 'num_filters': 56, 'filter_lengths': 1, 'conv_stride': 1, 'pool_size': 1, 'pool_stride': 1}, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'building_block': ['basic', 'basic', 'bottleneck', 'bottleneck'], 'block': [{'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'aa'}, {'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'aa'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'pos': 2, 'filt_size': 7, 'conv_type': 'aa'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'filt_size': 7, 'conv_type': 'aa'}], 'num_blocks': [1, 1, 1, 1]}, 'tresnetN': {'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'stem': {'subsample_mode': 's2d', 'num_filters': 56, 'filter_lengths': 1, 'conv_stride': 1, 'pool_size': 1, 'pool_stride': 1}, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'building_block': ['basic', 'basic', 'bottleneck', 'bottleneck'], 'block': [{'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'aa'}, {'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'aa'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'pos': 2, 'filt_size': 7, 'conv_type': 'aa'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'filt_size': 7, 'conv_type': 'aa'}], 'num_blocks': [2, 2, 2, 2]}, 'tresnetS': {'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'stem': {'subsample_mode': 's2d', 'num_filters': 56, 'filter_lengths': 1, 'conv_stride': 1, 'pool_size': 1, 'pool_stride': 1}, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'building_block': ['basic', 'basic', 'bottleneck', 'bottleneck'], 'block': [{'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'aa'}, {'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'aa'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'pos': 2, 'filt_size': 7, 'conv_type': 'aa'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'filt_size': 7, 'conv_type': 'aa'}], 'num_blocks': [3, 4, 6, 3]}, 'tresnetM': {'fs': 100, 'subsample_lengths': [1, 2, 2, 2], 'filter_lengths': 3, 'groups': 1, 'increase_channels_method': 'conv', 'stem': {'subsample_mode': 's2d', 'num_filters': 64, 'filter_lengths': 1, 'conv_stride': 1, 'pool_size': 1, 'pool_stride': 1}, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'building_block': ['basic', 'basic', 'bottleneck', 'bottleneck'], 'block': [{'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'aa'}, {'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'reduction': 4, 'filt_size': 7, 'conv_type': 'aa'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}, 'pos': 2, 'filt_size': 7, 'conv_type': 'aa'}, {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'blur', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'leaky', 'kw_activation': {'inplace': True}, 'bias': False, 'filt_size': 7, 'conv_type': 'aa'}], 'num_blocks': [3, 4, 11, 3]}, 'resnet_leadwise': {'fs': 100, 'building_block': 'basic', 'expansion': 1, 'subsample_lengths': [1, 2, 2, 2], 'num_blocks': [3, 4, 6, 3], 'filter_lengths': [[1, 1, 5], [1, 1, 1, 5], [1, 1, 1, 1, 1, 5], [1, 1, 11]], 'groups': 12, 'stem': {'num_filters': 96, 'filter_lengths': 3, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'block': {'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False}}, 'resnet_stanford': {'fs': 100, 'groups': 1, 'num_blocks': [2, 2, 2, 2], 'subsample_lengths': 2, 'filter_lengths': 3, 'stem': {'num_filters': 72, 'filter_lengths': 3, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'building_block': 'basic', 'block': {'increase_channels_at': 4, 'increase_channels_method': 'conv', 'num_skip': 2, 'subsample_mode': 'conv', 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'dropout': 0.2, 'bias': False}}, 'regnet_16_8': {'fs': 100, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'filter_lengths': 3, 'subsample_lengths': 2, 'tot_blocks': 16, 'group_widths': 8, 'w_a': 27.89, 'w_0': 48, 'w_m': 2.09, 'block': {'expansion': 1, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}}}, 'regnet_27_24': {'fs': 100, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'filter_lengths': 3, 'subsample_lengths': 2, 'tot_blocks': 27, 'group_widths': 24, 'w_a': 20.71, 'w_0': 48, 'w_m': 2.65, 'block': {'expansion': 1, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}}}, 'regnet_23_168': {'fs': 100, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'filter_lengths': 3, 'subsample_lengths': 2, 'tot_blocks': 23, 'group_widths': 168, 'w_a': 69.86, 'w_0': 320, 'w_m': 2.0, 'block': {'expansion': 1, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}}}, 'regnet_S': {'fs': 100, 'stem': {'num_filters': 64, 'filter_lengths': 5, 'conv_stride': 2, 'pool_size': 3, 'pool_stride': 2}, 'num_blocks': [2, 2, 2, 2], 'filter_lengths': [3, 3, 1, 1], 'subsample_lengths': [2, 2, 2, 2], 'num_filters': [32, 64, 128, 256], 'group_widths': [8, 16, 32, 64], 'block': {'expansion': 4, 'increase_channels_method': 'conv', 'subsample_mode': 'conv', 'subsample_at': 1, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': False, 'attn': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal', 'name': 'se', 'pos': -1}}}, 'multi_scopic': {'fs': 100, 'groups': 1, 'scopes': [[[1], [1, 1], [1, 1, 1]], [[2], [2, 4], [8, 8, 8]], [[4], [4, 8], [16, 32, 64]]], 'filter_lengths': [[3, 1, 1], [3, 1, 1], [3, 1, 1]], 'subsample_lengths': [2, 2, 2], 'num_filters': [[96, 192, 384], [96, 192, 384], [96, 192, 384]], 'dropouts': [[0, 0.2, 0], [0, 0.2, 0], [0, 0.2, 0]], 'bias': True, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'block': {'subsample_mode': 'max', 'bias': True, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'batch_norm': False, 'kw_bn': {}}}, 'multi_scopic_leadwise': {'fs': 100, 'groups': 12, 'scopes': [[[1], [1, 1], [1, 1, 1]], [[2], [2, 4], [8, 8, 8]], [[4], [4, 8], [16, 32, 64]]], 'filter_lengths': [[3, 1, 1], [3, 1, 1], [3, 1, 1]], 'subsample_lengths': [2, 2, 2], 'num_filters': [[192, 384, 768], [192, 384, 768], [192, 384, 768]], 'dropouts': [[0, 0.2, 0], [0, 0.2, 0], [0, 0.2, 0]], 'bias': True, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'block': {'subsample_mode': 'max', 'bias': True, 'kernel_initializer': 'he_normal', 'kw_initializer': {}, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'batch_norm': False, 'kw_bn': {}}}, 'mobilenet_v1': {'fs': 100, 'groups': 1, 'batch_norm': True, 'activation': 'relu6', 'depth_multiplier': 1, 'width_multiplier': 1.0, 'bias': True, 'ordering': 'cba', 'init_num_filters': 36, 'init_filter_lengths': 5, 'init_subsample_lengths': 2, 'entry_flow': {'out_channels': [72, 144, 144, 288, 288, 576], 'filter_lengths': 3, 'subsample_lengths': [1, 2, 1, 2, 1, 2], 'groups': 1, 'batch_norm': True, 'activation': 'relu6'}, 'middle_flow': {'out_channels': [576, 576, 576, 576, 576], 'filter_lengths': 3, 'subsample_lengths': 1, 'groups': 1, 'batch_norm': True, 'activation': 'relu6'}, 'exit_flow': {'out_channels': [1152, 1152], 'filter_lengths': 3, 'subsample_lengths': [2, 1], 'groups': 1, 'batch_norm': True, 'activation': 'relu6'}}, 'mobilenet_v2': {'fs': 100, 'groups': 1, 'batch_norm': True, 'activation': 'relu6', 'depth_multiplier': 1, 'width_multiplier': 1.0, 'bias': True, 'ordering': 'cba', 'stem': {'num_filters': 48, 'filter_lengths': 5, 'subsample_lengths': 2}, 'inv_res': {'expansions': [1, 6, 6, 6, 6, 6, 6], 'out_channels': [24, 36, 48, 72, 96, 240, 480], 'n_blocks': [1, 2, 3, 4, 3, 3, 1], 'strides': [1, 2, 2, 2, 1, 2, 1], 'filter_lengths': [3, 3, 3, 3, 3, 3, 3]}, 'exit_flow': {'num_filters': 1536, 'filter_lengths': 5, 'subsample_lengths': 2}}, 'mobilenet_v3': {'fs': 100, 'groups': 1, 'batch_norm': True, 'activation': 'relu', 'depth_multiplier': 1, 'width_multiplier': 1.0, 'bias': True, 'ordering': 'cba', 'stem': {'num_filters': [24], 'filter_lengths': 5, 'subsample_lengths': 2}, 'inv_res': {'n_blocks': [1, 2, 5, 3], 'expansions': [4, 4, 4, 4], 'out_channels': [48, 96, 192, 384], 'strides': [2, 2, 2, 2], 'filter_lengths': [3, 3, 3, 3], 'dilations': [1, 1, 1, 1], 'activations': ['relu', 'relu', 'hardswish', 'hardswish'], 'groups': 1, 'attns': [{'name': 'se', 'pos': 2, 'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}}, None, {'name': 'se', 'pos': 2, 'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}}, {'name': 'se', 'pos': 2, 'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}}]}, 'exit_flow': {'num_filters': 1536, 'filter_lengths': 5, 'subsample_lengths': 2}}, 'xception_vanilla': {'fs': 100, 'groups': 1, 'entry_flow': {'init_num_filters': [32, 64], 'init_filter_lengths': 7, 'init_subsample_lengths': [2, 1], 'num_filters': [128, 256, 728], 'filter_lengths': 3, 'subsample_lengths': 2, 'subsample_kernels': 3}, 'middle_flow': {'num_filters': [728, 728, 728, 728, 728, 728, 728, 728], 'filter_lengths': 3}, 'exit_flow': {'final_num_filters': [1456, 2048], 'final_filter_lengths': 1, 'num_filters': [[728, 1024]], 'filter_lengths': 3, 'subsample_lengths': 2, 'subsample_kernels': 3}}, 'xception_leadwise': {'fs': 100, 'groups': 12, 'entry_flow': {'init_num_filters': [96, 192], 'init_filter_lengths': 7, 'init_subsample_lengths': [2, 1], 'num_filters': [384, 768, 2184], 'filter_lengths': 3, 'subsample_lengths': 2, 'subsample_kernels': 3}, 'middle_flow': {'num_filters': [2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184], 'filter_lengths': 3}, 'exit_flow': {'final_num_filters': [4368, 6144], 'final_filter_lengths': 3, 'num_filters': [[2184, 3072]], 'filter_lengths': 1, 'subsample_lengths': 2, 'subsample_kernels': 3}}, 'densenet_vanilla': {'fs': 100, 'num_layers': [6, 6, 6, 6], 'init_num_filters': 64, 'init_filter_length': 5, 'init_pool_stride': 2, 'init_pool_size': 3, 'init_subsample_mode': 'avg', 'growth_rates': 16, 'filter_lengths': 3, 'subsample_lengths': 2, 'bn_size': 4, 'dropout': 0, 'compression': 0.5, 'groups': 1, 'block': {'building_block': 'basic'}, 'transition': {}}, 'densenet_leadwise': {'fs': 100, 'num_layers': [6, 6, 6, 6], 'init_num_filters': 96, 'init_filter_length': 5, 'init_pool_stride': 2, 'init_pool_size': 3, 'init_subsample_mode': 'avg', 'growth_rates': 12, 'filter_lengths': 3, 'subsample_lengths': 2, 'bn_size': 4, 'dropout': 0, 'compression': 0.5, 'groups': 12, 'block': {'building_block': 'basic'}, 'transition': {}}}, 'rnn': {'name': 'none', 'lstm': {'bias': True, 'dropouts': 0.2, 'bidirectional': True, 'retseq': True, 'hidden_sizes': [192, 192]}, 'linear': {'out_channels': [256, 64], 'bias': True, 'dropouts': 0.2, 'activation': 'mish'}}, 'attn': {'name': 'se', 'se': {'reduction': 8, 'activation': 'relu', 'kw_activation': {'inplace': True}, 'bias': True, 'kernel_initializer': 'he_normal'}, 'gc': {'ratio': 4, 'reduction': True, 'pooling_type': 'attn', 'fusion_types': ['mul']}, 'nl': {'filter_lengths': {'g': 1, 'phi': 1, 'theta': 1, 'W': 1}, 'subsample_length': 2, 'batch_norm': True}, 'transformer': {'hidden_size': 1024, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.1, 'activation': 'relu'}, 'sa': {'num_heads': 8, 'dropout': 0.1, 'bias': True}}, 'global_pool': 'max', 'global_pool_size': 1, 'clf': {'out_channels': [1024], 'activation': 'mish', 'bias': True, 'kernel_initializer': 'he_normal', 'dropouts': 0.2}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "73fe868c-fb02-4944-8407-1f40a41141a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(dot.exe:123448): Pango-WARNING **: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"532pt\" height=\"950pt\"\n",
       " viewBox=\"0.00 0.00 531.98 950.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.784638 0.784638) rotate(0) translate(4 1206.75)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1206.75 674,-1206.75 674,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"8,-8 8,-1160.75 662,-1160.75 662,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"39.25\" y=\"-1145.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-406 16,-1130.5 408,-1130.5 408,-406 16,-406\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.25\" y=\"-1115.1\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">InceptionBackbone</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"416,-16 416,-488.25 654,-488.25 654,-16 416,-16\"/>\n",
       "<text text-anchor=\"middle\" x=\"447.25\" y=\"-472.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"259,-1202.75 131,-1202.75 131,-1168.75 259,-1168.75 259,-1202.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"131,-1168.75 131,-1202.75 192.75,-1202.75 192.75,-1168.75 131,-1168.75\"/>\n",
       "<text text-anchor=\"start\" x=\"136\" y=\"-1188.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"145.38\" y=\"-1176.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"192.75,-1168.75 192.75,-1202.75 259,-1202.75 259,-1168.75 192.75,-1168.75\"/>\n",
       "<text text-anchor=\"start\" x=\"197.75\" y=\"-1182.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12, 1000)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"231,-1100.25 33,-1100.25 33,-1056.25 231,-1056.25 231,-1100.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"33,-1056.25 33,-1100.25 114,-1100.25 114,-1056.25 33,-1056.25\"/>\n",
       "<text text-anchor=\"start\" x=\"37.88\" y=\"-1080.75\" font-family=\"Linux libertine\" font-size=\"10.00\">InceptionBlock1d</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-1068.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-1078.25 114,-1100.25 157,-1100.25 157,-1078.25 114,-1078.25\"/>\n",
       "<text text-anchor=\"start\" x=\"123.12\" y=\"-1085.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-1078.25 157,-1100.25 231,-1100.25 231,-1078.25 157,-1078.25\"/>\n",
       "<text text-anchor=\"start\" x=\"164.38\" y=\"-1085.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-1056.25 114,-1078.25 157,-1078.25 157,-1056.25 114,-1056.25\"/>\n",
       "<text text-anchor=\"start\" x=\"118.62\" y=\"-1063.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-1056.25 157,-1078.25 231,-1078.25 231,-1056.25 157,-1056.25\"/>\n",
       "<text text-anchor=\"start\" x=\"161.75\" y=\"-1063.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M185.7,-1169.18C176.38,-1153.56 161.77,-1129.1 150.14,-1109.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"153.28,-1108.06 145.15,-1101.27 147.27,-1111.65 153.28,-1108.06\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"299.5,-860.25 64.5,-860.25 64.5,-816.25 299.5,-816.25 299.5,-860.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"64.5,-816.25 64.5,-860.25 120.5,-860.25 120.5,-816.25 64.5,-816.25\"/>\n",
       "<text text-anchor=\"start\" x=\"69.25\" y=\"-840.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Shortcut1d</text>\n",
       "<text text-anchor=\"start\" x=\"76\" y=\"-828.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120.5,-838.25 120.5,-860.25 163.5,-860.25 163.5,-838.25 120.5,-838.25\"/>\n",
       "<text text-anchor=\"start\" x=\"129.62\" y=\"-845.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163.5,-838.25 163.5,-860.25 299.5,-860.25 299.5,-838.25 163.5,-838.25\"/>\n",
       "<text text-anchor=\"start\" x=\"168.12\" y=\"-845.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12, 1000), (1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120.5,-816.25 120.5,-838.25 163.5,-838.25 163.5,-816.25 120.5,-816.25\"/>\n",
       "<text text-anchor=\"start\" x=\"125.12\" y=\"-823.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163.5,-816.25 163.5,-838.25 299.5,-838.25 299.5,-816.25 163.5,-816.25\"/>\n",
       "<text text-anchor=\"start\" x=\"199.25\" y=\"-823.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.16,-1168.81C235.83,-1166.46 238.18,-1163.79 240,-1160.75 300.48,-1059.95 285.46,-1004.66 240,-896.25 235.54,-885.61 228.01,-875.95 219.83,-867.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.34,-865.28 212.63,-861.04 217.57,-870.41 222.34,-865.28\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"231,-1020.25 33,-1020.25 33,-976.25 231,-976.25 231,-1020.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"33,-976.25 33,-1020.25 114,-1020.25 114,-976.25 33,-976.25\"/>\n",
       "<text text-anchor=\"start\" x=\"37.88\" y=\"-1000.75\" font-family=\"Linux libertine\" font-size=\"10.00\">InceptionBlock1d</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-988.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-998.25 114,-1020.25 157,-1020.25 157,-998.25 114,-998.25\"/>\n",
       "<text text-anchor=\"start\" x=\"123.12\" y=\"-1005.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-998.25 157,-1020.25 231,-1020.25 231,-998.25 157,-998.25\"/>\n",
       "<text text-anchor=\"start\" x=\"161.75\" y=\"-1005.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-976.25 114,-998.25 157,-998.25 157,-976.25 114,-976.25\"/>\n",
       "<text text-anchor=\"start\" x=\"118.62\" y=\"-983.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-976.25 157,-998.25 231,-998.25 231,-976.25 157,-976.25\"/>\n",
       "<text text-anchor=\"start\" x=\"161.75\" y=\"-983.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M132,-1056.35C132,-1048.74 132,-1039.95 132,-1031.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.5,-1031.72 132,-1021.72 128.5,-1031.72 135.5,-1031.72\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"231,-940.25 33,-940.25 33,-896.25 231,-896.25 231,-940.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"33,-896.25 33,-940.25 114,-940.25 114,-896.25 33,-896.25\"/>\n",
       "<text text-anchor=\"start\" x=\"37.88\" y=\"-920.75\" font-family=\"Linux libertine\" font-size=\"10.00\">InceptionBlock1d</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-908.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-918.25 114,-940.25 157,-940.25 157,-918.25 114,-918.25\"/>\n",
       "<text text-anchor=\"start\" x=\"123.12\" y=\"-925.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-918.25 157,-940.25 231,-940.25 231,-918.25 157,-918.25\"/>\n",
       "<text text-anchor=\"start\" x=\"161.75\" y=\"-925.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-896.25 114,-918.25 157,-918.25 157,-896.25 114,-896.25\"/>\n",
       "<text text-anchor=\"start\" x=\"118.62\" y=\"-903.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-896.25 157,-918.25 231,-918.25 231,-896.25 157,-896.25\"/>\n",
       "<text text-anchor=\"start\" x=\"161.75\" y=\"-903.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M132,-976.35C132,-968.74 132,-959.95 132,-951.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.5,-951.72 132,-941.72 128.5,-951.72 135.5,-951.72\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.4,-896.35C150.61,-888.22 156.69,-878.74 162.38,-869.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.3,-871.79 167.75,-861.48 159.4,-868.01 165.3,-871.79\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"184,-700.25 24,-700.25 24,-656.25 184,-656.25 184,-700.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24,-656.25 24,-700.25 67,-700.25 67,-656.25 24,-656.25\"/>\n",
       "<text text-anchor=\"start\" x=\"34.25\" y=\"-680.75\" font-family=\"Linux libertine\" font-size=\"10.00\">clone</text>\n",
       "<text text-anchor=\"start\" x=\"29\" y=\"-668.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"67,-678.25 67,-700.25 110,-700.25 110,-678.25 67,-678.25\"/>\n",
       "<text text-anchor=\"start\" x=\"76.12\" y=\"-685.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-678.25 110,-700.25 184,-700.25 184,-678.25 110,-678.25\"/>\n",
       "<text text-anchor=\"start\" x=\"114.75\" y=\"-685.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"67,-656.25 67,-678.25 110,-678.25 110,-656.25 67,-656.25\"/>\n",
       "<text text-anchor=\"start\" x=\"71.62\" y=\"-663.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-656.25 110,-678.25 184,-678.25 184,-656.25 110,-656.25\"/>\n",
       "<text text-anchor=\"start\" x=\"114.75\" y=\"-663.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.64,-816.27C158.16,-788.97 134.52,-741.06 119.06,-709.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122.39,-708.59 114.82,-701.17 116.11,-711.69 122.39,-708.59\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"380,-780.25 182,-780.25 182,-736.25 380,-736.25 380,-780.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"182,-736.25 182,-780.25 263,-780.25 263,-736.25 182,-736.25\"/>\n",
       "<text text-anchor=\"start\" x=\"186.88\" y=\"-760.75\" font-family=\"Linux libertine\" font-size=\"10.00\">InceptionBlock1d</text>\n",
       "<text text-anchor=\"start\" x=\"206\" y=\"-748.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"263,-758.25 263,-780.25 306,-780.25 306,-758.25 263,-758.25\"/>\n",
       "<text text-anchor=\"start\" x=\"272.12\" y=\"-765.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"306,-758.25 306,-780.25 380,-780.25 380,-758.25 306,-758.25\"/>\n",
       "<text text-anchor=\"start\" x=\"310.75\" y=\"-765.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"263,-736.25 263,-758.25 306,-758.25 306,-736.25 263,-736.25\"/>\n",
       "<text text-anchor=\"start\" x=\"267.62\" y=\"-743.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"306,-736.25 306,-758.25 380,-758.25 380,-736.25 306,-736.25\"/>\n",
       "<text text-anchor=\"start\" x=\"310.75\" y=\"-743.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.53,-816.35C219.85,-807.43 233.23,-796.89 245.39,-787.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"247.52,-790.08 253.21,-781.15 243.19,-784.59 247.52,-790.08\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"395.5,-540.25 206.5,-540.25 206.5,-496.25 395.5,-496.25 395.5,-540.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"206.5,-496.25 206.5,-540.25 262.5,-540.25 262.5,-496.25 206.5,-496.25\"/>\n",
       "<text text-anchor=\"start\" x=\"211.25\" y=\"-520.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Shortcut1d</text>\n",
       "<text text-anchor=\"start\" x=\"218\" y=\"-508.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"262.5,-518.25 262.5,-540.25 305.5,-540.25 305.5,-518.25 262.5,-518.25\"/>\n",
       "<text text-anchor=\"start\" x=\"271.62\" y=\"-525.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"305.5,-518.25 305.5,-540.25 395.5,-540.25 395.5,-518.25 305.5,-518.25\"/>\n",
       "<text text-anchor=\"start\" x=\"310.38\" y=\"-525.75\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"262.5,-496.25 262.5,-518.25 305.5,-518.25 305.5,-496.25 262.5,-496.25\"/>\n",
       "<text text-anchor=\"start\" x=\"267.12\" y=\"-503.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"305.5,-496.25 305.5,-518.25 395.5,-518.25 395.5,-496.25 305.5,-496.25\"/>\n",
       "<text text-anchor=\"start\" x=\"318.25\" y=\"-503.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.85,-656.28C135.17,-634.32 163.07,-599.82 193,-576.25 207.9,-564.52 225.57,-554.03 242.25,-545.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"243.79,-548.49 251.13,-540.85 240.63,-542.24 243.79,-548.49\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"400,-700.25 202,-700.25 202,-656.25 400,-656.25 400,-700.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"202,-656.25 202,-700.25 283,-700.25 283,-656.25 202,-656.25\"/>\n",
       "<text text-anchor=\"start\" x=\"206.88\" y=\"-680.75\" font-family=\"Linux libertine\" font-size=\"10.00\">InceptionBlock1d</text>\n",
       "<text text-anchor=\"start\" x=\"226\" y=\"-668.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"283,-678.25 283,-700.25 326,-700.25 326,-678.25 283,-678.25\"/>\n",
       "<text text-anchor=\"start\" x=\"292.12\" y=\"-685.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"326,-678.25 326,-700.25 400,-700.25 400,-678.25 326,-678.25\"/>\n",
       "<text text-anchor=\"start\" x=\"330.75\" y=\"-685.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"283,-656.25 283,-678.25 326,-678.25 326,-656.25 283,-656.25\"/>\n",
       "<text text-anchor=\"start\" x=\"287.62\" y=\"-663.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"326,-656.25 326,-678.25 400,-678.25 400,-656.25 326,-656.25\"/>\n",
       "<text text-anchor=\"start\" x=\"330.75\" y=\"-663.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M286.36,-736.35C288.33,-728.65 290.61,-719.75 292.78,-711.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"296.16,-712.23 295.25,-701.68 289.38,-710.49 296.16,-712.23\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"400,-620.25 202,-620.25 202,-576.25 400,-576.25 400,-620.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"202,-576.25 202,-620.25 283,-620.25 283,-576.25 202,-576.25\"/>\n",
       "<text text-anchor=\"start\" x=\"206.88\" y=\"-600.75\" font-family=\"Linux libertine\" font-size=\"10.00\">InceptionBlock1d</text>\n",
       "<text text-anchor=\"start\" x=\"226\" y=\"-588.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"283,-598.25 283,-620.25 326,-620.25 326,-598.25 283,-598.25\"/>\n",
       "<text text-anchor=\"start\" x=\"292.12\" y=\"-605.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"326,-598.25 326,-620.25 400,-620.25 400,-598.25 326,-598.25\"/>\n",
       "<text text-anchor=\"start\" x=\"330.75\" y=\"-605.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"283,-576.25 283,-598.25 326,-598.25 326,-576.25 283,-576.25\"/>\n",
       "<text text-anchor=\"start\" x=\"287.62\" y=\"-583.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"326,-576.25 326,-598.25 400,-598.25 400,-576.25 326,-576.25\"/>\n",
       "<text text-anchor=\"start\" x=\"330.75\" y=\"-583.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301,-656.35C301,-648.74 301,-639.95 301,-631.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"304.5,-631.72 301,-621.72 297.5,-631.72 304.5,-631.72\"/>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301,-576.35C301,-568.74 301,-559.95 301,-551.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"304.5,-551.72 301,-541.72 297.5,-551.72 304.5,-551.72\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"381,-458 221,-458 221,-414 381,-414 381,-458\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"221,-414 221,-458 264,-458 264,-414 221,-414\"/>\n",
       "<text text-anchor=\"start\" x=\"231.25\" y=\"-438.5\" font-family=\"Linux libertine\" font-size=\"10.00\">clone</text>\n",
       "<text text-anchor=\"start\" x=\"226\" y=\"-426.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"264,-436 264,-458 307,-458 307,-436 264,-436\"/>\n",
       "<text text-anchor=\"start\" x=\"273.12\" y=\"-443.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"307,-436 307,-458 381,-458 381,-436 307,-436\"/>\n",
       "<text text-anchor=\"start\" x=\"311.75\" y=\"-443.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"264,-414 264,-436 307,-436 307,-414 264,-414\"/>\n",
       "<text text-anchor=\"start\" x=\"268.62\" y=\"-421.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"307,-414 307,-436 381,-436 381,-414 307,-414\"/>\n",
       "<text text-anchor=\"start\" x=\"311.75\" y=\"-421.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301,-496.58C301,-488.22 301,-478.38 301,-469.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"304.5,-469.39 301,-459.39 297.5,-469.39 304.5,-469.39\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"645.5,-458 424.5,-458 424.5,-414 645.5,-414 645.5,-458\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"424.5,-414 424.5,-458 528.5,-458 528.5,-414 424.5,-414\"/>\n",
       "<text text-anchor=\"start\" x=\"429.25\" y=\"-438.5\" font-family=\"Linux libertine\" font-size=\"10.00\">AdaptiveConcatPool1d</text>\n",
       "<text text-anchor=\"start\" x=\"460\" y=\"-426.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"528.5,-436 528.5,-458 571.5,-458 571.5,-436 528.5,-436\"/>\n",
       "<text text-anchor=\"start\" x=\"537.62\" y=\"-443.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"571.5,-436 571.5,-458 645.5,-458 645.5,-436 571.5,-436\"/>\n",
       "<text text-anchor=\"start\" x=\"576.25\" y=\"-443.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"528.5,-414 528.5,-436 571.5,-436 571.5,-414 528.5,-414\"/>\n",
       "<text text-anchor=\"start\" x=\"533.12\" y=\"-421.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"571.5,-414 571.5,-436 645.5,-436 645.5,-414 571.5,-414\"/>\n",
       "<text text-anchor=\"start\" x=\"584.12\" y=\"-421.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 1) </text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M386.2,-496.29C394.97,-493.74 403.7,-491.05 412,-488.25 434.12,-480.79 457.91,-471.25 478.62,-462.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"479.96,-465.66 487.76,-458.49 477.19,-459.23 479.96,-465.66\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"607,-378 463,-378 463,-334 607,-334 607,-378\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"463,-334 463,-378 506,-378 506,-334 463,-334\"/>\n",
       "<text text-anchor=\"start\" x=\"469.88\" y=\"-358.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Flatten</text>\n",
       "<text text-anchor=\"start\" x=\"468\" y=\"-346.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"506,-356 506,-378 549,-378 549,-356 506,-356\"/>\n",
       "<text text-anchor=\"start\" x=\"515.12\" y=\"-363.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"549,-356 549,-378 607,-378 607,-356 549,-356\"/>\n",
       "<text text-anchor=\"start\" x=\"553.62\" y=\"-363.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"506,-334 506,-356 549,-356 549,-334 506,-334\"/>\n",
       "<text text-anchor=\"start\" x=\"510.62\" y=\"-341.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"549,-334 549,-356 607,-356 607,-334 549,-334\"/>\n",
       "<text text-anchor=\"start\" x=\"559.25\" y=\"-341.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256) </text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535,-414.1C535,-406.49 535,-397.7 535,-389.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.5,-389.47 535,-379.47 531.5,-389.47 538.5,-389.47\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"613.5,-298 456.5,-298 456.5,-254 613.5,-254 613.5,-298\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"456.5,-254 456.5,-298 523.5,-298 523.5,-254 456.5,-254\"/>\n",
       "<text text-anchor=\"start\" x=\"461.5\" y=\"-278.5\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm1d</text>\n",
       "<text text-anchor=\"start\" x=\"473.5\" y=\"-266.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"523.5,-276 523.5,-298 566.5,-298 566.5,-276 523.5,-276\"/>\n",
       "<text text-anchor=\"start\" x=\"532.62\" y=\"-283.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"566.5,-276 566.5,-298 613.5,-298 613.5,-276 566.5,-276\"/>\n",
       "<text text-anchor=\"start\" x=\"571.25\" y=\"-283.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"523.5,-254 523.5,-276 566.5,-276 566.5,-254 523.5,-254\"/>\n",
       "<text text-anchor=\"start\" x=\"528.12\" y=\"-261.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"566.5,-254 566.5,-276 613.5,-276 613.5,-254 566.5,-254\"/>\n",
       "<text text-anchor=\"start\" x=\"571.25\" y=\"-261.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256) </text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535,-334.1C535,-326.49 535,-317.7 535,-309.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.5,-309.47 535,-299.47 531.5,-309.47 538.5,-309.47\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"601.5,-218 468.5,-218 468.5,-174 601.5,-174 601.5,-218\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"468.5,-174 468.5,-218 511.5,-218 511.5,-174 468.5,-174\"/>\n",
       "<text text-anchor=\"start\" x=\"473.12\" y=\"-198.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n",
       "<text text-anchor=\"start\" x=\"473.5\" y=\"-186.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"511.5,-196 511.5,-218 554.5,-218 554.5,-196 511.5,-196\"/>\n",
       "<text text-anchor=\"start\" x=\"520.62\" y=\"-203.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"554.5,-196 554.5,-218 601.5,-218 601.5,-196 554.5,-196\"/>\n",
       "<text text-anchor=\"start\" x=\"559.25\" y=\"-203.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"511.5,-174 511.5,-196 554.5,-196 554.5,-174 511.5,-174\"/>\n",
       "<text text-anchor=\"start\" x=\"516.12\" y=\"-181.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"554.5,-174 554.5,-196 601.5,-196 601.5,-174 554.5,-174\"/>\n",
       "<text text-anchor=\"start\" x=\"559.25\" y=\"-181.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256) </text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535,-254.1C535,-246.49 535,-237.7 535,-229.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.5,-229.47 535,-219.47 531.5,-229.47 538.5,-229.47\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"601.5,-138 468.5,-138 468.5,-94 601.5,-94 601.5,-138\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"468.5,-94 468.5,-138 511.5,-138 511.5,-94 468.5,-94\"/>\n",
       "<text text-anchor=\"start\" x=\"476.88\" y=\"-118.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"473.5\" y=\"-106.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"511.5,-116 511.5,-138 554.5,-138 554.5,-116 511.5,-116\"/>\n",
       "<text text-anchor=\"start\" x=\"520.62\" y=\"-123.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"554.5,-116 554.5,-138 601.5,-138 601.5,-116 554.5,-116\"/>\n",
       "<text text-anchor=\"start\" x=\"559.25\" y=\"-123.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"511.5,-94 511.5,-116 554.5,-116 554.5,-94 511.5,-94\"/>\n",
       "<text text-anchor=\"start\" x=\"516.12\" y=\"-101.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"554.5,-94 554.5,-116 601.5,-116 601.5,-94 554.5,-94\"/>\n",
       "<text text-anchor=\"start\" x=\"564.5\" y=\"-101.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535,-174.1C535,-166.49 535,-157.7 535,-149.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.5,-149.47 535,-139.47 531.5,-149.47 538.5,-149.47\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"585.88,-58 484.12,-58 484.12,-24 585.88,-24 585.88,-58\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"484.12,-24 484.12,-58 551.88,-58 551.88,-24 484.12,-24\"/>\n",
       "<text text-anchor=\"start\" x=\"489.12\" y=\"-43.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"501.5\" y=\"-31.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"551.88,-24 551.88,-58 585.88,-58 585.88,-24 551.88,-24\"/>\n",
       "<text text-anchor=\"start\" x=\"556.88\" y=\"-37.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535,-94.28C535,-86.46 535,-77.45 535,-69.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.5,-69.18 535,-59.18 531.5,-69.18 538.5,-69.18\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x248cfc8e810>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchview import draw_graph\n",
    "# import\n",
    "\n",
    "model_graph = draw_graph(inception1d(input_channels=12, num_classes=5), input_size=( 1, 12, 1000), expand_nested=True)\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "24d93f57-2705-4039-8d92-79deba2da494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(dot.exe:123096): Pango-WARNING **: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"190pt\" height=\"2182pt\"\n",
       " viewBox=\"0.00 0.00 190.11 2182.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.725339 0.725339) rotate(0) translate(4 3004.25)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-3004.25 258.1,-3004.25 258.1,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"8,-1436.75 8,-2958.25 246,-2958.25 246,-1436.75 8,-1436.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"34.38\" y=\"-2942.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">VGG16</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-2685.75 16,-2928 238,-2928 238,-2685.75 16,-2685.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"49.88\" y=\"-2912.6\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">VGGBlock</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"19,-2435.5 19,-2677.75 235,-2677.75 235,-2435.5 19,-2435.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.88\" y=\"-2662.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">VGGBlock</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster_5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-2105.25 16,-2427.5 238,-2427.5 238,-2105.25 16,-2105.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"49.88\" y=\"-2412.1\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">VGGBlock</text>\n",
       "</g>\n",
       "<g id=\"clust5\" class=\"cluster\">\n",
       "<title>cluster_6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-1775 16,-2097.25 238,-2097.25 238,-1775 16,-1775\"/>\n",
       "<text text-anchor=\"middle\" x=\"49.88\" y=\"-2081.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">VGGBlock</text>\n",
       "</g>\n",
       "<g id=\"clust6\" class=\"cluster\">\n",
       "<title>cluster_7</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"19,-1444.75 19,-1767 235,-1767 235,-1444.75 19,-1444.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.88\" y=\"-1751.6\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">VGGBlock</text>\n",
       "</g>\n",
       "<g id=\"clust7\" class=\"cluster\">\n",
       "<title>cluster_8</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"14,-640.25 14,-1124.75 232,-1124.75 232,-640.25 14,-640.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"42.25\" y=\"-1109.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SEBlock</text>\n",
       "</g>\n",
       "<g id=\"clust8\" class=\"cluster\">\n",
       "<title>cluster_9</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"48,-800.25 48,-962.5 198,-962.5 198,-800.25 48,-800.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"79.25\" y=\"-947.1\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<g id=\"clust9\" class=\"cluster\">\n",
       "<title>cluster_10</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"46,-8 46,-400.25 200,-400.25 200,-8 46,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"66\" y=\"-384.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MLP</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"191,-3000.25 63,-3000.25 63,-2966.25 191,-2966.25 191,-3000.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"63,-2966.25 63,-3000.25 124.75,-3000.25 124.75,-2966.25 63,-2966.25\"/>\n",
       "<text text-anchor=\"start\" x=\"68\" y=\"-2985.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"77.38\" y=\"-2973.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"124.75,-2966.25 124.75,-3000.25 191,-3000.25 191,-2966.25 124.75,-2966.25\"/>\n",
       "<text text-anchor=\"start\" x=\"129.75\" y=\"-2979.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12, 1000)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"229.5,-2897.75 24.5,-2897.75 24.5,-2853.75 229.5,-2853.75 229.5,-2897.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-2853.75 24.5,-2897.75 117.5,-2897.75 117.5,-2853.75 24.5,-2853.75\"/>\n",
       "<text text-anchor=\"start\" x=\"29.38\" y=\"-2878.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-2866.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2875.75 117.5,-2897.75 160.5,-2897.75 160.5,-2875.75 117.5,-2875.75\"/>\n",
       "<text text-anchor=\"start\" x=\"126.62\" y=\"-2883.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2875.75 160.5,-2897.75 229.5,-2897.75 229.5,-2875.75 160.5,-2875.75\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2883.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2853.75 117.5,-2875.75 160.5,-2875.75 160.5,-2853.75 117.5,-2853.75\"/>\n",
       "<text text-anchor=\"start\" x=\"122.12\" y=\"-2861.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2853.75 160.5,-2875.75 229.5,-2875.75 229.5,-2853.75 160.5,-2853.75\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2861.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 48, 1000) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2966.68C127,-2951.49 127,-2927.94 127,-2908.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2908.98 127,-2898.98 123.5,-2908.98 130.5,-2908.98\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"229.5,-2817.75 24.5,-2817.75 24.5,-2773.75 229.5,-2773.75 229.5,-2817.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-2773.75 24.5,-2817.75 117.5,-2817.75 117.5,-2773.75 24.5,-2773.75\"/>\n",
       "<text text-anchor=\"start\" x=\"29.38\" y=\"-2798.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-2786.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2795.75 117.5,-2817.75 160.5,-2817.75 160.5,-2795.75 117.5,-2795.75\"/>\n",
       "<text text-anchor=\"start\" x=\"126.62\" y=\"-2803.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2795.75 160.5,-2817.75 229.5,-2817.75 229.5,-2795.75 160.5,-2795.75\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2803.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 48, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2773.75 117.5,-2795.75 160.5,-2795.75 160.5,-2773.75 117.5,-2773.75\"/>\n",
       "<text text-anchor=\"start\" x=\"122.12\" y=\"-2781.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2773.75 160.5,-2795.75 229.5,-2795.75 229.5,-2773.75 160.5,-2773.75\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2781.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 48, 1000) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2853.85C127,-2846.24 127,-2837.45 127,-2829.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2829.22 127,-2819.22 123.5,-2829.22 130.5,-2829.22\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"210.5,-2737.75 43.5,-2737.75 43.5,-2693.75 210.5,-2693.75 210.5,-2737.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"43.5,-2693.75 43.5,-2737.75 98.5,-2737.75 98.5,-2693.75 43.5,-2693.75\"/>\n",
       "<text text-anchor=\"start\" x=\"48.12\" y=\"-2718.25\" font-family=\"Linux libertine\" font-size=\"10.00\">MaxPool1d</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-2706.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.5,-2715.75 98.5,-2737.75 141.5,-2737.75 141.5,-2715.75 98.5,-2715.75\"/>\n",
       "<text text-anchor=\"start\" x=\"107.62\" y=\"-2723.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.5,-2715.75 141.5,-2737.75 210.5,-2737.75 210.5,-2715.75 141.5,-2715.75\"/>\n",
       "<text text-anchor=\"start\" x=\"146.38\" y=\"-2723.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 48, 1000) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.5,-2693.75 98.5,-2715.75 141.5,-2715.75 141.5,-2693.75 98.5,-2693.75\"/>\n",
       "<text text-anchor=\"start\" x=\"103.12\" y=\"-2701.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.5,-2693.75 141.5,-2715.75 210.5,-2715.75 210.5,-2693.75 141.5,-2693.75\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-2701.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 48, 499) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2773.85C127,-2766.24 127,-2757.45 127,-2749.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2749.22 127,-2739.22 123.5,-2749.22 130.5,-2749.22\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"227,-2647.5 27,-2647.5 27,-2603.5 227,-2603.5 227,-2647.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27,-2603.5 27,-2647.5 120,-2647.5 120,-2603.5 27,-2603.5\"/>\n",
       "<text text-anchor=\"start\" x=\"31.88\" y=\"-2628\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-2616\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-2625.5 120,-2647.5 163,-2647.5 163,-2625.5 120,-2625.5\"/>\n",
       "<text text-anchor=\"start\" x=\"129.12\" y=\"-2633\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-2625.5 163,-2647.5 227,-2647.5 227,-2625.5 163,-2625.5\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-2633\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 48, 499) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-2603.5 120,-2625.5 163,-2625.5 163,-2603.5 120,-2603.5\"/>\n",
       "<text text-anchor=\"start\" x=\"124.62\" y=\"-2611\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-2603.5 163,-2625.5 227,-2625.5 227,-2603.5 163,-2603.5\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-2611\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 499) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2693.84C127,-2683.29 127,-2670.26 127,-2658.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2658.78 127,-2648.78 123.5,-2658.78 130.5,-2658.78\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"227,-2567.5 27,-2567.5 27,-2523.5 227,-2523.5 227,-2567.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27,-2523.5 27,-2567.5 120,-2567.5 120,-2523.5 27,-2523.5\"/>\n",
       "<text text-anchor=\"start\" x=\"31.88\" y=\"-2548\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-2536\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-2545.5 120,-2567.5 163,-2567.5 163,-2545.5 120,-2545.5\"/>\n",
       "<text text-anchor=\"start\" x=\"129.12\" y=\"-2553\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-2545.5 163,-2567.5 227,-2567.5 227,-2545.5 163,-2545.5\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-2553\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 499) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-2523.5 120,-2545.5 163,-2545.5 163,-2523.5 120,-2523.5\"/>\n",
       "<text text-anchor=\"start\" x=\"124.62\" y=\"-2531\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-2523.5 163,-2545.5 227,-2545.5 227,-2523.5 163,-2523.5\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-2531\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 499) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2603.6C127,-2595.99 127,-2587.2 127,-2578.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2578.97 127,-2568.97 123.5,-2578.97 130.5,-2578.97\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"208,-2487.5 46,-2487.5 46,-2443.5 208,-2443.5 208,-2487.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"46,-2443.5 46,-2487.5 101,-2487.5 101,-2443.5 46,-2443.5\"/>\n",
       "<text text-anchor=\"start\" x=\"50.62\" y=\"-2468\" font-family=\"Linux libertine\" font-size=\"10.00\">MaxPool1d</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-2456\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"101,-2465.5 101,-2487.5 144,-2487.5 144,-2465.5 101,-2465.5\"/>\n",
       "<text text-anchor=\"start\" x=\"110.12\" y=\"-2473\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144,-2465.5 144,-2487.5 208,-2487.5 208,-2465.5 144,-2465.5\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-2473\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 499) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"101,-2443.5 101,-2465.5 144,-2465.5 144,-2443.5 101,-2443.5\"/>\n",
       "<text text-anchor=\"start\" x=\"105.62\" y=\"-2451\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144,-2443.5 144,-2465.5 208,-2465.5 208,-2443.5 144,-2443.5\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-2451\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 249) </text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2523.6C127,-2515.99 127,-2507.2 127,-2498.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2498.97 127,-2488.97 123.5,-2498.97 130.5,-2498.97\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"229.5,-2397.25 24.5,-2397.25 24.5,-2353.25 229.5,-2353.25 229.5,-2397.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-2353.25 24.5,-2397.25 117.5,-2397.25 117.5,-2353.25 24.5,-2353.25\"/>\n",
       "<text text-anchor=\"start\" x=\"29.38\" y=\"-2377.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-2365.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2375.25 117.5,-2397.25 160.5,-2397.25 160.5,-2375.25 117.5,-2375.25\"/>\n",
       "<text text-anchor=\"start\" x=\"126.62\" y=\"-2382.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2375.25 160.5,-2397.25 229.5,-2397.25 229.5,-2375.25 160.5,-2375.25\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-2382.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 249) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2353.25 117.5,-2375.25 160.5,-2375.25 160.5,-2353.25 117.5,-2353.25\"/>\n",
       "<text text-anchor=\"start\" x=\"122.12\" y=\"-2360.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2353.25 160.5,-2375.25 229.5,-2375.25 229.5,-2353.25 160.5,-2353.25\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2360.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 249) </text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2443.59C127,-2433.04 127,-2420.01 127,-2408.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2408.53 127,-2398.53 123.5,-2408.53 130.5,-2408.53\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"229.5,-2317.25 24.5,-2317.25 24.5,-2273.25 229.5,-2273.25 229.5,-2317.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-2273.25 24.5,-2317.25 117.5,-2317.25 117.5,-2273.25 24.5,-2273.25\"/>\n",
       "<text text-anchor=\"start\" x=\"29.38\" y=\"-2297.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-2285.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2295.25 117.5,-2317.25 160.5,-2317.25 160.5,-2295.25 117.5,-2295.25\"/>\n",
       "<text text-anchor=\"start\" x=\"126.62\" y=\"-2302.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2295.25 160.5,-2317.25 229.5,-2317.25 229.5,-2295.25 160.5,-2295.25\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2302.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 249) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2273.25 117.5,-2295.25 160.5,-2295.25 160.5,-2273.25 117.5,-2273.25\"/>\n",
       "<text text-anchor=\"start\" x=\"122.12\" y=\"-2280.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2273.25 160.5,-2295.25 229.5,-2295.25 229.5,-2273.25 160.5,-2273.25\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2280.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 249) </text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2353.35C127,-2345.74 127,-2336.95 127,-2328.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2328.72 127,-2318.72 123.5,-2328.72 130.5,-2328.72\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"229.5,-2237.25 24.5,-2237.25 24.5,-2193.25 229.5,-2193.25 229.5,-2237.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-2193.25 24.5,-2237.25 117.5,-2237.25 117.5,-2193.25 24.5,-2193.25\"/>\n",
       "<text text-anchor=\"start\" x=\"29.38\" y=\"-2217.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-2205.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2215.25 117.5,-2237.25 160.5,-2237.25 160.5,-2215.25 117.5,-2215.25\"/>\n",
       "<text text-anchor=\"start\" x=\"126.62\" y=\"-2222.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2215.25 160.5,-2237.25 229.5,-2237.25 229.5,-2215.25 160.5,-2215.25\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2222.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 249) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2193.25 117.5,-2215.25 160.5,-2215.25 160.5,-2193.25 117.5,-2193.25\"/>\n",
       "<text text-anchor=\"start\" x=\"122.12\" y=\"-2200.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2193.25 160.5,-2215.25 229.5,-2215.25 229.5,-2193.25 160.5,-2193.25\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2200.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 249) </text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2273.35C127,-2265.74 127,-2256.95 127,-2248.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2248.72 127,-2238.72 123.5,-2248.72 130.5,-2248.72\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"210.5,-2157.25 43.5,-2157.25 43.5,-2113.25 210.5,-2113.25 210.5,-2157.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"43.5,-2113.25 43.5,-2157.25 98.5,-2157.25 98.5,-2113.25 43.5,-2113.25\"/>\n",
       "<text text-anchor=\"start\" x=\"48.12\" y=\"-2137.75\" font-family=\"Linux libertine\" font-size=\"10.00\">MaxPool1d</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-2125.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.5,-2135.25 98.5,-2157.25 141.5,-2157.25 141.5,-2135.25 98.5,-2135.25\"/>\n",
       "<text text-anchor=\"start\" x=\"107.62\" y=\"-2142.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.5,-2135.25 141.5,-2157.25 210.5,-2157.25 210.5,-2135.25 141.5,-2135.25\"/>\n",
       "<text text-anchor=\"start\" x=\"146.38\" y=\"-2142.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 249) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.5,-2113.25 98.5,-2135.25 141.5,-2135.25 141.5,-2113.25 98.5,-2113.25\"/>\n",
       "<text text-anchor=\"start\" x=\"103.12\" y=\"-2120.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.5,-2113.25 141.5,-2135.25 210.5,-2135.25 210.5,-2113.25 141.5,-2113.25\"/>\n",
       "<text text-anchor=\"start\" x=\"146.38\" y=\"-2120.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 124) </text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2193.35C127,-2185.74 127,-2176.95 127,-2168.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2168.72 127,-2158.72 123.5,-2168.72 130.5,-2168.72\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"229.5,-2067 24.5,-2067 24.5,-2023 229.5,-2023 229.5,-2067\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-2023 24.5,-2067 117.5,-2067 117.5,-2023 24.5,-2023\"/>\n",
       "<text text-anchor=\"start\" x=\"29.38\" y=\"-2047.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-2035.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2045 117.5,-2067 160.5,-2067 160.5,-2045 117.5,-2045\"/>\n",
       "<text text-anchor=\"start\" x=\"126.62\" y=\"-2052.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2045 160.5,-2067 229.5,-2067 229.5,-2045 160.5,-2045\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2052.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 124) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-2023 117.5,-2045 160.5,-2045 160.5,-2023 117.5,-2023\"/>\n",
       "<text text-anchor=\"start\" x=\"122.12\" y=\"-2030.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-2023 160.5,-2045 229.5,-2045 229.5,-2023 160.5,-2023\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-2030.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 124) </text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2113.34C127,-2102.79 127,-2089.76 127,-2077.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-2078.28 127,-2068.28 123.5,-2078.28 130.5,-2078.28\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"229.5,-1987 24.5,-1987 24.5,-1943 229.5,-1943 229.5,-1987\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-1943 24.5,-1987 117.5,-1987 117.5,-1943 24.5,-1943\"/>\n",
       "<text text-anchor=\"start\" x=\"29.38\" y=\"-1967.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-1955.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-1965 117.5,-1987 160.5,-1987 160.5,-1965 117.5,-1965\"/>\n",
       "<text text-anchor=\"start\" x=\"126.62\" y=\"-1972.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-1965 160.5,-1987 229.5,-1987 229.5,-1965 160.5,-1965\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-1972.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 124) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-1943 117.5,-1965 160.5,-1965 160.5,-1943 117.5,-1943\"/>\n",
       "<text text-anchor=\"start\" x=\"122.12\" y=\"-1950.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-1943 160.5,-1965 229.5,-1965 229.5,-1943 160.5,-1943\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-1950.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 124) </text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-2023.1C127,-2015.49 127,-2006.7 127,-1998.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1998.47 127,-1988.47 123.5,-1998.47 130.5,-1998.47\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"229.5,-1907 24.5,-1907 24.5,-1863 229.5,-1863 229.5,-1907\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-1863 24.5,-1907 117.5,-1907 117.5,-1863 24.5,-1863\"/>\n",
       "<text text-anchor=\"start\" x=\"29.38\" y=\"-1887.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-1875.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-1885 117.5,-1907 160.5,-1907 160.5,-1885 117.5,-1885\"/>\n",
       "<text text-anchor=\"start\" x=\"126.62\" y=\"-1892.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-1885 160.5,-1907 229.5,-1907 229.5,-1885 160.5,-1885\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-1892.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 124) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117.5,-1863 117.5,-1885 160.5,-1885 160.5,-1863 117.5,-1863\"/>\n",
       "<text text-anchor=\"start\" x=\"122.12\" y=\"-1870.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-1863 160.5,-1885 229.5,-1885 229.5,-1863 160.5,-1863\"/>\n",
       "<text text-anchor=\"start\" x=\"165.38\" y=\"-1870.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 124) </text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1943.1C127,-1935.49 127,-1926.7 127,-1918.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1918.47 127,-1908.47 123.5,-1918.47 130.5,-1918.47\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"210.5,-1827 43.5,-1827 43.5,-1783 210.5,-1783 210.5,-1827\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"43.5,-1783 43.5,-1827 98.5,-1827 98.5,-1783 43.5,-1783\"/>\n",
       "<text text-anchor=\"start\" x=\"48.12\" y=\"-1807.5\" font-family=\"Linux libertine\" font-size=\"10.00\">MaxPool1d</text>\n",
       "<text text-anchor=\"start\" x=\"54.5\" y=\"-1795.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.5,-1805 98.5,-1827 141.5,-1827 141.5,-1805 98.5,-1805\"/>\n",
       "<text text-anchor=\"start\" x=\"107.62\" y=\"-1812.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.5,-1805 141.5,-1827 210.5,-1827 210.5,-1805 141.5,-1805\"/>\n",
       "<text text-anchor=\"start\" x=\"146.38\" y=\"-1812.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 124) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.5,-1783 98.5,-1805 141.5,-1805 141.5,-1783 98.5,-1783\"/>\n",
       "<text text-anchor=\"start\" x=\"103.12\" y=\"-1790.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.5,-1783 141.5,-1805 210.5,-1805 210.5,-1783 141.5,-1783\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-1790.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 61) </text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1863.1C127,-1855.49 127,-1846.7 127,-1838.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1838.47 127,-1828.47 123.5,-1838.47 130.5,-1838.47\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"227,-1736.75 27,-1736.75 27,-1692.75 227,-1692.75 227,-1736.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27,-1692.75 27,-1736.75 120,-1736.75 120,-1692.75 27,-1692.75\"/>\n",
       "<text text-anchor=\"start\" x=\"31.88\" y=\"-1717.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-1705.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-1714.75 120,-1736.75 163,-1736.75 163,-1714.75 120,-1714.75\"/>\n",
       "<text text-anchor=\"start\" x=\"129.12\" y=\"-1722.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-1714.75 163,-1736.75 227,-1736.75 227,-1714.75 163,-1714.75\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-1722.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 61) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-1692.75 120,-1714.75 163,-1714.75 163,-1692.75 120,-1692.75\"/>\n",
       "<text text-anchor=\"start\" x=\"124.62\" y=\"-1700.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-1692.75 163,-1714.75 227,-1714.75 227,-1692.75 163,-1692.75\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-1700.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 61) </text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1783.09C127,-1772.54 127,-1759.51 127,-1747.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1748.03 127,-1738.03 123.5,-1748.03 130.5,-1748.03\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"227,-1656.75 27,-1656.75 27,-1612.75 227,-1612.75 227,-1656.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27,-1612.75 27,-1656.75 120,-1656.75 120,-1612.75 27,-1612.75\"/>\n",
       "<text text-anchor=\"start\" x=\"31.88\" y=\"-1637.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-1625.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-1634.75 120,-1656.75 163,-1656.75 163,-1634.75 120,-1634.75\"/>\n",
       "<text text-anchor=\"start\" x=\"129.12\" y=\"-1642.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-1634.75 163,-1656.75 227,-1656.75 227,-1634.75 163,-1634.75\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-1642.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 61) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-1612.75 120,-1634.75 163,-1634.75 163,-1612.75 120,-1612.75\"/>\n",
       "<text text-anchor=\"start\" x=\"124.62\" y=\"-1620.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-1612.75 163,-1634.75 227,-1634.75 227,-1612.75 163,-1612.75\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-1620.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 61) </text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1692.85C127,-1685.24 127,-1676.45 127,-1668.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1668.22 127,-1658.22 123.5,-1668.22 130.5,-1668.22\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"227,-1576.75 27,-1576.75 27,-1532.75 227,-1532.75 227,-1576.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27,-1532.75 27,-1576.75 120,-1576.75 120,-1532.75 27,-1532.75\"/>\n",
       "<text text-anchor=\"start\" x=\"31.88\" y=\"-1557.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv_Bn_Activation</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-1545.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-1554.75 120,-1576.75 163,-1576.75 163,-1554.75 120,-1554.75\"/>\n",
       "<text text-anchor=\"start\" x=\"129.12\" y=\"-1562.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-1554.75 163,-1576.75 227,-1576.75 227,-1554.75 163,-1554.75\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-1562.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 61) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-1532.75 120,-1554.75 163,-1554.75 163,-1532.75 120,-1532.75\"/>\n",
       "<text text-anchor=\"start\" x=\"124.62\" y=\"-1540.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"163,-1532.75 163,-1554.75 227,-1554.75 227,-1532.75 163,-1532.75\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-1540.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 61) </text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>16&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1612.85C127,-1605.24 127,-1596.45 127,-1588.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1588.22 127,-1578.22 123.5,-1588.22 130.5,-1588.22\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"208,-1496.75 46,-1496.75 46,-1452.75 208,-1452.75 208,-1496.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"46,-1452.75 46,-1496.75 101,-1496.75 101,-1452.75 46,-1452.75\"/>\n",
       "<text text-anchor=\"start\" x=\"50.62\" y=\"-1477.25\" font-family=\"Linux libertine\" font-size=\"10.00\">MaxPool1d</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-1465.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"101,-1474.75 101,-1496.75 144,-1496.75 144,-1474.75 101,-1474.75\"/>\n",
       "<text text-anchor=\"start\" x=\"110.12\" y=\"-1482.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144,-1474.75 144,-1496.75 208,-1496.75 208,-1474.75 144,-1474.75\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-1482.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 61) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"101,-1452.75 101,-1474.75 144,-1474.75 144,-1452.75 101,-1452.75\"/>\n",
       "<text text-anchor=\"start\" x=\"105.62\" y=\"-1460.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144,-1452.75 144,-1474.75 208,-1474.75 208,-1452.75 144,-1452.75\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-1460.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 30) </text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1532.85C127,-1525.24 127,-1516.45 127,-1508.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1508.22 127,-1498.22 123.5,-1508.22 130.5,-1508.22\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"208,-1416.75 46,-1416.75 46,-1372.75 208,-1372.75 208,-1416.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"46,-1372.75 46,-1416.75 101,-1416.75 101,-1372.75 46,-1372.75\"/>\n",
       "<text text-anchor=\"start\" x=\"51\" y=\"-1397.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Rearrange</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-1385.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"101,-1394.75 101,-1416.75 144,-1416.75 144,-1394.75 101,-1394.75\"/>\n",
       "<text text-anchor=\"start\" x=\"110.12\" y=\"-1402.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144,-1394.75 144,-1416.75 208,-1416.75 208,-1394.75 144,-1394.75\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-1402.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 30) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"101,-1372.75 101,-1394.75 144,-1394.75 144,-1372.75 101,-1372.75\"/>\n",
       "<text text-anchor=\"start\" x=\"105.62\" y=\"-1380.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144,-1372.75 144,-1394.75 208,-1394.75 208,-1372.75 144,-1372.75\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-1380.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(30, 1, 384) </text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>18&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1452.85C127,-1445.24 127,-1436.45 127,-1428.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1428.22 127,-1418.22 123.5,-1428.22 130.5,-1428.22\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"202,-1336.75 52,-1336.75 52,-1292.75 202,-1292.75 202,-1336.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52,-1292.75 52,-1336.75 95,-1336.75 95,-1292.75 52,-1292.75\"/>\n",
       "<text text-anchor=\"start\" x=\"57.75\" y=\"-1317.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Identity</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-1305.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95,-1314.75 95,-1336.75 138,-1336.75 138,-1314.75 95,-1314.75\"/>\n",
       "<text text-anchor=\"start\" x=\"104.12\" y=\"-1322.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"138,-1314.75 138,-1336.75 202,-1336.75 202,-1314.75 138,-1314.75\"/>\n",
       "<text text-anchor=\"start\" x=\"143\" y=\"-1322.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(30, 1, 384) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95,-1292.75 95,-1314.75 138,-1314.75 138,-1292.75 95,-1292.75\"/>\n",
       "<text text-anchor=\"start\" x=\"99.62\" y=\"-1300.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"138,-1292.75 138,-1314.75 202,-1314.75 202,-1292.75 138,-1292.75\"/>\n",
       "<text text-anchor=\"start\" x=\"143\" y=\"-1300.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(30, 1, 384) </text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>19&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1372.85C127,-1365.24 127,-1356.45 127,-1348.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1348.22 127,-1338.22 123.5,-1348.22 130.5,-1348.22\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>21</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"202,-1256.75 52,-1256.75 52,-1212.75 202,-1212.75 202,-1256.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52,-1212.75 52,-1256.75 95,-1256.75 95,-1212.75 52,-1212.75\"/>\n",
       "<text text-anchor=\"start\" x=\"57.75\" y=\"-1237.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Identity</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-1225.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95,-1234.75 95,-1256.75 138,-1256.75 138,-1234.75 95,-1234.75\"/>\n",
       "<text text-anchor=\"start\" x=\"104.12\" y=\"-1242.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"138,-1234.75 138,-1256.75 202,-1256.75 202,-1234.75 138,-1234.75\"/>\n",
       "<text text-anchor=\"start\" x=\"143\" y=\"-1242.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(30, 1, 384) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95,-1212.75 95,-1234.75 138,-1234.75 138,-1212.75 95,-1212.75\"/>\n",
       "<text text-anchor=\"start\" x=\"99.62\" y=\"-1220.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"138,-1212.75 138,-1234.75 202,-1234.75 202,-1212.75 138,-1212.75\"/>\n",
       "<text text-anchor=\"start\" x=\"143\" y=\"-1220.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(30, 1, 384) </text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;21 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>20&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1292.85C127,-1285.24 127,-1276.45 127,-1268.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1268.22 127,-1258.22 123.5,-1268.22 130.5,-1268.22\"/>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>22</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"208,-1176.75 46,-1176.75 46,-1132.75 208,-1132.75 208,-1176.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"46,-1132.75 46,-1176.75 101,-1176.75 101,-1132.75 46,-1132.75\"/>\n",
       "<text text-anchor=\"start\" x=\"51\" y=\"-1157.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Rearrange</text>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-1145.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"101,-1154.75 101,-1176.75 144,-1176.75 144,-1154.75 101,-1154.75\"/>\n",
       "<text text-anchor=\"start\" x=\"110.12\" y=\"-1162.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144,-1154.75 144,-1176.75 208,-1176.75 208,-1154.75 144,-1154.75\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-1162.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(30, 1, 384) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"101,-1132.75 101,-1154.75 144,-1154.75 144,-1132.75 101,-1132.75\"/>\n",
       "<text text-anchor=\"start\" x=\"105.62\" y=\"-1140.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144,-1132.75 144,-1154.75 208,-1154.75 208,-1132.75 144,-1132.75\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-1140.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 30) </text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;22 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>21&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127,-1212.85C127,-1205.24 127,-1196.45 127,-1188.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-1188.22 127,-1178.22 123.5,-1188.22 130.5,-1188.22\"/>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>23</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"221,-1094.5 23,-1094.5 23,-1050.5 221,-1050.5 221,-1094.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"23,-1050.5 23,-1094.5 114,-1094.5 114,-1050.5 23,-1050.5\"/>\n",
       "<text text-anchor=\"start\" x=\"28\" y=\"-1075\" font-family=\"Linux libertine\" font-size=\"10.00\">AdaptiveAvgPool1d</text>\n",
       "<text text-anchor=\"start\" x=\"52\" y=\"-1063\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-1072.5 114,-1094.5 157,-1094.5 157,-1072.5 114,-1072.5\"/>\n",
       "<text text-anchor=\"start\" x=\"123.12\" y=\"-1080\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-1072.5 157,-1094.5 221,-1094.5 221,-1072.5 157,-1072.5\"/>\n",
       "<text text-anchor=\"start\" x=\"162\" y=\"-1080\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 30) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-1050.5 114,-1072.5 157,-1072.5 157,-1050.5 114,-1050.5\"/>\n",
       "<text text-anchor=\"start\" x=\"118.62\" y=\"-1058\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-1050.5 157,-1072.5 221,-1072.5 221,-1050.5 157,-1050.5\"/>\n",
       "<text text-anchor=\"start\" x=\"164.62\" y=\"-1058\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 1) </text>\n",
       "</g>\n",
       "<!-- 22&#45;&gt;23 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>22&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.71,-1133.08C125.19,-1124.72 124.58,-1114.88 124,-1105.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127.51,-1105.65 123.39,-1095.89 120.52,-1106.08 127.51,-1105.65\"/>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>28</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"223.5,-692.25 22.5,-692.25 22.5,-648.25 223.5,-648.25 223.5,-692.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"22.5,-648.25 22.5,-692.25 65.5,-692.25 65.5,-648.25 22.5,-648.25\"/>\n",
       "<text text-anchor=\"start\" x=\"36.12\" y=\"-672.75\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n",
       "<text text-anchor=\"start\" x=\"27.5\" y=\"-660.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-670.25 65.5,-692.25 108.5,-692.25 108.5,-670.25 65.5,-670.25\"/>\n",
       "<text text-anchor=\"start\" x=\"74.62\" y=\"-677.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-670.25 108.5,-692.25 223.5,-692.25 223.5,-670.25 108.5,-670.25\"/>\n",
       "<text text-anchor=\"start\" x=\"113.12\" y=\"-677.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 30), (1, 384, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-648.25 65.5,-670.25 108.5,-670.25 108.5,-648.25 65.5,-648.25\"/>\n",
       "<text text-anchor=\"start\" x=\"70.12\" y=\"-655.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-648.25 108.5,-670.25 223.5,-670.25 223.5,-648.25 108.5,-648.25\"/>\n",
       "<text text-anchor=\"start\" x=\"139\" y=\"-655.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 30) </text>\n",
       "</g>\n",
       "<!-- 22&#45;&gt;28 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>22&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M207.85,-1141.2C216.21,-1137.09 223.87,-1131.73 230,-1124.75 268.87,-1080.44 249,-1052.44 249,-993.5 249,-993.5 249,-993.5 249,-829.25 249,-781.13 240.24,-765.68 210,-728.25 200.59,-716.61 188.16,-706.53 175.65,-698.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"177.72,-695.39 167.39,-693.03 173.99,-701.32 177.72,-695.39\"/>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>24</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"195,-1014.5 49,-1014.5 49,-970.5 195,-970.5 195,-1014.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"49,-970.5 49,-1014.5 94,-1014.5 94,-970.5 49,-970.5\"/>\n",
       "<text text-anchor=\"start\" x=\"53.88\" y=\"-995\" font-family=\"Linux libertine\" font-size=\"10.00\">squeeze</text>\n",
       "<text text-anchor=\"start\" x=\"55\" y=\"-983\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"94,-992.5 94,-1014.5 137,-1014.5 137,-992.5 94,-992.5\"/>\n",
       "<text text-anchor=\"start\" x=\"103.12\" y=\"-1000\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"137,-992.5 137,-1014.5 195,-1014.5 195,-992.5 137,-992.5\"/>\n",
       "<text text-anchor=\"start\" x=\"141.62\" y=\"-1000\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"94,-970.5 94,-992.5 137,-992.5 137,-970.5 94,-970.5\"/>\n",
       "<text text-anchor=\"start\" x=\"98.62\" y=\"-978\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"137,-970.5 137,-992.5 195,-992.5 195,-970.5 137,-970.5\"/>\n",
       "<text text-anchor=\"start\" x=\"147.25\" y=\"-978\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384) </text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;24 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>23&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-1050.6C122,-1042.99 122,-1034.2 122,-1025.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-1025.97 122,-1015.97 118.5,-1025.97 125.5,-1025.97\"/>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>25</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"189.5,-932.25 56.5,-932.25 56.5,-888.25 189.5,-888.25 189.5,-932.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"56.5,-888.25 56.5,-932.25 99.5,-932.25 99.5,-888.25 56.5,-888.25\"/>\n",
       "<text text-anchor=\"start\" x=\"63.75\" y=\"-912.75\" font-family=\"Linux libertine\" font-size=\"10.00\">SeqLin</text>\n",
       "<text text-anchor=\"start\" x=\"61.5\" y=\"-900.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-910.25 99.5,-932.25 142.5,-932.25 142.5,-910.25 99.5,-910.25\"/>\n",
       "<text text-anchor=\"start\" x=\"108.62\" y=\"-917.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-910.25 142.5,-932.25 189.5,-932.25 189.5,-910.25 142.5,-910.25\"/>\n",
       "<text text-anchor=\"start\" x=\"147.25\" y=\"-917.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-888.25 99.5,-910.25 142.5,-910.25 142.5,-888.25 99.5,-888.25\"/>\n",
       "<text text-anchor=\"start\" x=\"104.12\" y=\"-895.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-888.25 142.5,-910.25 189.5,-910.25 189.5,-888.25 142.5,-888.25\"/>\n",
       "<text text-anchor=\"start\" x=\"147.25\" y=\"-895.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384) </text>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;25 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>24&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.26,-970.83C122.36,-962.47 122.48,-952.63 122.6,-943.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.1,-943.68 122.72,-933.64 119.1,-943.59 126.1,-943.68\"/>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>26</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"190,-852.25 56,-852.25 56,-808.25 190,-808.25 190,-852.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"56,-808.25 56,-852.25 100,-852.25 100,-808.25 56,-808.25\"/>\n",
       "<text text-anchor=\"start\" x=\"60.75\" y=\"-832.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Sigmoid</text>\n",
       "<text text-anchor=\"start\" x=\"61.5\" y=\"-820.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100,-830.25 100,-852.25 143,-852.25 143,-830.25 100,-830.25\"/>\n",
       "<text text-anchor=\"start\" x=\"109.12\" y=\"-837.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143,-830.25 143,-852.25 190,-852.25 190,-830.25 143,-830.25\"/>\n",
       "<text text-anchor=\"start\" x=\"147.75\" y=\"-837.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100,-808.25 100,-830.25 143,-830.25 143,-808.25 100,-808.25\"/>\n",
       "<text text-anchor=\"start\" x=\"104.62\" y=\"-815.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143,-808.25 143,-830.25 190,-830.25 190,-808.25 143,-808.25\"/>\n",
       "<text text-anchor=\"start\" x=\"147.75\" y=\"-815.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384) </text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;26 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>25&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-888.35C123,-880.74 123,-871.95 123,-863.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-863.72 123,-853.72 119.5,-863.72 126.5,-863.72\"/>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>27</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"201,-772.25 45,-772.25 45,-728.25 201,-728.25 201,-772.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"45,-728.25 45,-772.25 100,-772.25 100,-728.25 45,-728.25\"/>\n",
       "<text text-anchor=\"start\" x=\"49.62\" y=\"-752.75\" font-family=\"Linux libertine\" font-size=\"10.00\">unsqueeze</text>\n",
       "<text text-anchor=\"start\" x=\"56\" y=\"-740.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100,-750.25 100,-772.25 143,-772.25 143,-750.25 100,-750.25\"/>\n",
       "<text text-anchor=\"start\" x=\"109.12\" y=\"-757.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143,-750.25 143,-772.25 201,-772.25 201,-750.25 143,-750.25\"/>\n",
       "<text text-anchor=\"start\" x=\"153.25\" y=\"-757.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100,-728.25 100,-750.25 143,-750.25 143,-728.25 100,-728.25\"/>\n",
       "<text text-anchor=\"start\" x=\"104.62\" y=\"-735.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143,-728.25 143,-750.25 201,-750.25 201,-728.25 143,-728.25\"/>\n",
       "<text text-anchor=\"start\" x=\"147.62\" y=\"-735.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 1) </text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;27 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>26&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-808.35C123,-800.74 123,-791.95 123,-783.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-783.72 123,-773.72 119.5,-783.72 126.5,-783.72\"/>\n",
       "</g>\n",
       "<!-- 27&#45;&gt;28 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>27&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-728.35C123,-720.74 123,-711.95 123,-703.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-703.72 123,-693.72 119.5,-703.72 126.5,-703.72\"/>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>29</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"198,-612.25 48,-612.25 48,-568.25 198,-568.25 198,-612.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48,-568.25 48,-612.25 91,-612.25 91,-568.25 48,-568.25\"/>\n",
       "<text text-anchor=\"start\" x=\"53.75\" y=\"-592.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Identity</text>\n",
       "<text text-anchor=\"start\" x=\"53\" y=\"-580.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91,-590.25 91,-612.25 134,-612.25 134,-590.25 91,-590.25\"/>\n",
       "<text text-anchor=\"start\" x=\"100.12\" y=\"-597.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"134,-590.25 134,-612.25 198,-612.25 198,-590.25 134,-590.25\"/>\n",
       "<text text-anchor=\"start\" x=\"139\" y=\"-597.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 30) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91,-568.25 91,-590.25 134,-590.25 134,-568.25 91,-568.25\"/>\n",
       "<text text-anchor=\"start\" x=\"95.62\" y=\"-575.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"134,-568.25 134,-590.25 198,-590.25 198,-568.25 134,-568.25\"/>\n",
       "<text text-anchor=\"start\" x=\"139\" y=\"-575.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 30) </text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;29 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>28&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-648.35C123,-640.74 123,-631.95 123,-623.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-623.72 123,-613.72 119.5,-623.72 126.5,-623.72\"/>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>30</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"222.5,-532.25 23.5,-532.25 23.5,-488.25 222.5,-488.25 222.5,-532.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"23.5,-488.25 23.5,-532.25 115.5,-532.25 115.5,-488.25 23.5,-488.25\"/>\n",
       "<text text-anchor=\"start\" x=\"28.25\" y=\"-512.75\" font-family=\"Linux libertine\" font-size=\"10.00\">AdaptiveMaxPool1d</text>\n",
       "<text text-anchor=\"start\" x=\"53\" y=\"-500.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"115.5,-510.25 115.5,-532.25 158.5,-532.25 158.5,-510.25 115.5,-510.25\"/>\n",
       "<text text-anchor=\"start\" x=\"124.62\" y=\"-517.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"158.5,-510.25 158.5,-532.25 222.5,-532.25 222.5,-510.25 158.5,-510.25\"/>\n",
       "<text text-anchor=\"start\" x=\"163.5\" y=\"-517.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 30) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"115.5,-488.25 115.5,-510.25 158.5,-510.25 158.5,-488.25 115.5,-488.25\"/>\n",
       "<text text-anchor=\"start\" x=\"120.12\" y=\"-495.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"158.5,-488.25 158.5,-510.25 222.5,-510.25 222.5,-488.25 158.5,-488.25\"/>\n",
       "<text text-anchor=\"start\" x=\"166.12\" y=\"-495.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 1) </text>\n",
       "</g>\n",
       "<!-- 29&#45;&gt;30 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>29&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-568.35C123,-560.74 123,-551.95 123,-543.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-543.72 123,-533.72 119.5,-543.72 126.5,-543.72\"/>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>31</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"201,-452.25 45,-452.25 45,-408.25 201,-408.25 201,-452.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"45,-408.25 45,-452.25 100,-452.25 100,-408.25 45,-408.25\"/>\n",
       "<text text-anchor=\"start\" x=\"50\" y=\"-432.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Rearrange</text>\n",
       "<text text-anchor=\"start\" x=\"56\" y=\"-420.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100,-430.25 100,-452.25 143,-452.25 143,-430.25 100,-430.25\"/>\n",
       "<text text-anchor=\"start\" x=\"109.12\" y=\"-437.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143,-430.25 143,-452.25 201,-452.25 201,-430.25 143,-430.25\"/>\n",
       "<text text-anchor=\"start\" x=\"147.62\" y=\"-437.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100,-408.25 100,-430.25 143,-430.25 143,-408.25 100,-408.25\"/>\n",
       "<text text-anchor=\"start\" x=\"104.62\" y=\"-415.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143,-408.25 143,-430.25 201,-430.25 201,-408.25 143,-408.25\"/>\n",
       "<text text-anchor=\"start\" x=\"153.25\" y=\"-415.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384) </text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;31 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>30&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-488.35C123,-480.74 123,-471.95 123,-463.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-463.72 123,-453.72 119.5,-463.72 126.5,-463.72\"/>\n",
       "</g>\n",
       "<!-- 32 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>32</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"192,-370 54,-370 54,-326 192,-326 192,-370\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"54,-326 54,-370 97,-370 97,-326 54,-326\"/>\n",
       "<text text-anchor=\"start\" x=\"62.38\" y=\"-350.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"59\" y=\"-338.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97,-348 97,-370 140,-370 140,-348 97,-348\"/>\n",
       "<text text-anchor=\"start\" x=\"106.12\" y=\"-355.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-348 140,-370 192,-370 192,-348 140,-348\"/>\n",
       "<text text-anchor=\"start\" x=\"147.25\" y=\"-355.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 384) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97,-326 97,-348 140,-348 140,-326 97,-326\"/>\n",
       "<text text-anchor=\"start\" x=\"101.62\" y=\"-333.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-326 140,-348 192,-348 192,-326 140,-326\"/>\n",
       "<text text-anchor=\"start\" x=\"144.62\" y=\"-333.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1024) </text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;32 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>31&#45;&gt;32</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-408.58C123,-400.22 123,-390.38 123,-381.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-381.39 123,-371.39 119.5,-381.39 126.5,-381.39\"/>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>33</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"192,-290 54,-290 54,-246 192,-246 192,-290\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"54,-246 54,-290 97,-290 97,-246 54,-246\"/>\n",
       "<text text-anchor=\"start\" x=\"65.75\" y=\"-270.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Mish</text>\n",
       "<text text-anchor=\"start\" x=\"59\" y=\"-258.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97,-268 97,-290 140,-290 140,-268 97,-268\"/>\n",
       "<text text-anchor=\"start\" x=\"106.12\" y=\"-275.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-268 140,-290 192,-290 192,-268 140,-268\"/>\n",
       "<text text-anchor=\"start\" x=\"144.62\" y=\"-275.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1024) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97,-246 97,-268 140,-268 140,-246 97,-246\"/>\n",
       "<text text-anchor=\"start\" x=\"101.62\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-246 140,-268 192,-268 192,-246 140,-246\"/>\n",
       "<text text-anchor=\"start\" x=\"144.62\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1024) </text>\n",
       "</g>\n",
       "<!-- 32&#45;&gt;33 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>32&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-326.1C123,-318.49 123,-309.7 123,-301.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-301.47 123,-291.47 119.5,-301.47 126.5,-301.47\"/>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>34</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"192,-210 54,-210 54,-166 192,-166 192,-210\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"54,-166 54,-210 97,-210 97,-166 54,-166\"/>\n",
       "<text text-anchor=\"start\" x=\"58.62\" y=\"-190.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n",
       "<text text-anchor=\"start\" x=\"59\" y=\"-178.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97,-188 97,-210 140,-210 140,-188 97,-188\"/>\n",
       "<text text-anchor=\"start\" x=\"106.12\" y=\"-195.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-188 140,-210 192,-210 192,-188 140,-188\"/>\n",
       "<text text-anchor=\"start\" x=\"144.62\" y=\"-195.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1024) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97,-166 97,-188 140,-188 140,-166 97,-166\"/>\n",
       "<text text-anchor=\"start\" x=\"101.62\" y=\"-173.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-166 140,-188 192,-188 192,-166 140,-166\"/>\n",
       "<text text-anchor=\"start\" x=\"144.62\" y=\"-173.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1024) </text>\n",
       "</g>\n",
       "<!-- 33&#45;&gt;34 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>33&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-246.1C123,-238.49 123,-229.7 123,-221.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-221.47 123,-211.47 119.5,-221.47 126.5,-221.47\"/>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>35</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"192,-130 54,-130 54,-86 192,-86 192,-130\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"54,-86 54,-130 97,-130 97,-86 54,-86\"/>\n",
       "<text text-anchor=\"start\" x=\"62.38\" y=\"-110.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"59\" y=\"-98.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97,-108 97,-130 140,-130 140,-108 97,-108\"/>\n",
       "<text text-anchor=\"start\" x=\"106.12\" y=\"-115.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-108 140,-130 192,-130 192,-108 140,-108\"/>\n",
       "<text text-anchor=\"start\" x=\"144.62\" y=\"-115.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1024) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97,-86 97,-108 140,-108 140,-86 97,-86\"/>\n",
       "<text text-anchor=\"start\" x=\"101.62\" y=\"-93.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-86 140,-108 192,-108 192,-86 140,-86\"/>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-93.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;35 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>34&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-166.1C123,-158.49 123,-149.7 123,-141.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-141.47 123,-131.47 119.5,-141.47 126.5,-141.47\"/>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>36</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"173.88,-50 72.12,-50 72.12,-16 173.88,-16 173.88,-50\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"72.12,-16 72.12,-50 139.88,-50 139.88,-16 72.12,-16\"/>\n",
       "<text text-anchor=\"start\" x=\"77.12\" y=\"-35.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"89.5\" y=\"-23.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"139.88,-16 139.88,-50 173.88,-50 173.88,-16 139.88,-16\"/>\n",
       "<text text-anchor=\"start\" x=\"144.88\" y=\"-29.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5)</text>\n",
       "</g>\n",
       "<!-- 35&#45;&gt;36 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>35&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-86.28C123,-78.46 123,-69.45 123,-61.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-61.18 123,-51.18 119.5,-61.18 126.5,-61.18\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x248cf5733b0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = adjust_cnn_filter_lengths(ECG_CRNN_CONFIG, fs=100)\n",
    "config.cnn.name=\"vgg16\"\n",
    "classes = ['CD', 'HYP', 'MI', 'NORM', 'STTC']\n",
    "n_leads = 12\n",
    "# vgg16_model = ECG_CRNN(classes, n_leads, config)\n",
    "\n",
    "\n",
    "\n",
    "model_graph = draw_graph(ECG_CRNN(classes, n_leads, config), input_size=(1, 12, 1000), expand_nested=True)\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1799baab-cbcd-4889-b06f-4795def01f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(torch.nn.Module):\n",
    "    \"\"\"Simple RNN\"\"\"\n",
    "\n",
    "    def __init__(self, inplace: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.hid_dim = 2\n",
    "        self.input_dim = 3\n",
    "        self.max_length = 4\n",
    "        self.lstm = torch.nn.LSTMCell(self.input_dim, self.hid_dim)\n",
    "        self.activation = torch.nn.LeakyReLU(inplace=inplace)\n",
    "        self.projection = torch.nn.Linear(self.hid_dim, self.input_dim)\n",
    "\n",
    "    def forward(self, token_embedding: torch.Tensor) -> torch.Tensor:\n",
    "        b_size = token_embedding.size()[0]\n",
    "        hx = torch.randn(b_size, self.hid_dim, device=token_embedding.device)\n",
    "        cx = torch.randn(b_size, self.hid_dim, device=token_embedding.device)\n",
    "\n",
    "        for _ in range(self.max_length):\n",
    "            hx, cx = self.lstm(token_embedding, (hx, cx))\n",
    "            hx = self.activation(hx)\n",
    "\n",
    "        return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6f10692a-cd74-4a9a-bfb5-ec7d08e902cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_graph_1 = draw_graph(\n",
    "    SimpleRNN(), input_size=(2, 3),\n",
    "    graph_name='RecursiveNet',\n",
    "    roll=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11414e43-6885-4051-bef8-f9c72f322d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(dot.exe:120320): Pango-WARNING **: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Title: RecursiveNet Pages: 1 -->\n",
       "<svg width=\"296pt\" height=\"295pt\"\n",
       " viewBox=\"0.00 0.00 296.00 294.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 290.5)\">\n",
       "<title>RecursiveNet</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-290.5 292,-290.5 292,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"149.38,-286.5 53.62,-286.5 53.62,-252.5 149.38,-252.5 149.38,-286.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"53.62,-252.5 53.62,-286.5 115.38,-286.5 115.38,-252.5 53.62,-252.5\"/>\n",
       "<text text-anchor=\"start\" x=\"58.62\" y=\"-272\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"68\" y=\"-260\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"115.38,-252.5 115.38,-286.5 149.38,-286.5 149.38,-252.5 115.38,-252.5\"/>\n",
       "<text text-anchor=\"start\" x=\"120.38\" y=\"-266\" font-family=\"Linux libertine\" font-size=\"10.00\">(2, 3)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"188.5,-205.25 14.5,-205.25 14.5,-161.25 188.5,-161.25 188.5,-205.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"14.5,-161.25 14.5,-205.25 63.5,-205.25 63.5,-161.25 14.5,-161.25\"/>\n",
       "<text text-anchor=\"start\" x=\"19.12\" y=\"-185.75\" font-family=\"Linux libertine\" font-size=\"10.00\">LSTMCell</text>\n",
       "<text text-anchor=\"start\" x=\"22.5\" y=\"-173.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"63.5,-183.25 63.5,-205.25 106.5,-205.25 106.5,-183.25 63.5,-183.25\"/>\n",
       "<text text-anchor=\"start\" x=\"72.62\" y=\"-190.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"106.5,-183.25 106.5,-205.25 188.5,-205.25 188.5,-183.25 106.5,-183.25\"/>\n",
       "<text text-anchor=\"start\" x=\"111.12\" y=\"-190.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(2, 3), 2 x (2, 2) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"63.5,-161.25 63.5,-183.25 106.5,-183.25 106.5,-161.25 63.5,-161.25\"/>\n",
       "<text text-anchor=\"start\" x=\"68.12\" y=\"-168.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"106.5,-161.25 106.5,-183.25 188.5,-183.25 188.5,-161.25 106.5,-161.25\"/>\n",
       "<text text-anchor=\"start\" x=\"126.12\" y=\"-168.75\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (2, 2) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M101.5,-252.65C101.5,-242.47 101.5,-228.87 101.5,-216.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"105,-216.64 101.5,-206.64 98,-216.64 105,-216.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.75\" y=\"-225\" font-family=\"Times New Roman,serif\" font-size=\"10.00\"> x4</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.4,-190.7C199.32,-189.39 206.5,-186.9 206.5,-183.25 206.5,-181.08 203.97,-179.32 199.63,-177.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.37,-174.56 189.89,-176.09 199.04,-181.43 200.37,-174.56\"/>\n",
       "<text text-anchor=\"middle\" x=\"211.75\" y=\"-179.38\" font-family=\"Times New Roman,serif\" font-size=\"10.00\"> x3</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"135,-114 0,-114 0,-70 135,-70 135,-114\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-70 0,-114 55,-114 55,-70 0,-70\"/>\n",
       "<text text-anchor=\"start\" x=\"4.62\" y=\"-94.5\" font-family=\"Linux libertine\" font-size=\"10.00\">LeakyReLU</text>\n",
       "<text text-anchor=\"start\" x=\"11\" y=\"-82.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"55,-92 55,-114 98,-114 98,-92 55,-92\"/>\n",
       "<text text-anchor=\"start\" x=\"64.12\" y=\"-99.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98,-92 98,-114 135,-114 135,-92 98,-92\"/>\n",
       "<text text-anchor=\"start\" x=\"103\" y=\"-99.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(2, 2) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"55,-70 55,-92 98,-92 98,-70 55,-70\"/>\n",
       "<text text-anchor=\"start\" x=\"59.62\" y=\"-77.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98,-70 98,-92 135,-92 135,-70 98,-70\"/>\n",
       "<text text-anchor=\"start\" x=\"103\" y=\"-77.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(2, 2) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M80.08,-161.64C75.61,-156.12 71.5,-149.84 69,-143.25 66.85,-137.58 65.76,-131.29 65.31,-125.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.81,-125.1 65.14,-115.16 61.81,-125.21 68.81,-125.1\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.75\" y=\"-133.75\" font-family=\"Times New Roman,serif\" font-size=\"10.00\"> x3</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"288,-114 153,-114 153,-70 288,-70 288,-114\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"153,-70 153,-114 208,-114 208,-70 153,-70\"/>\n",
       "<text text-anchor=\"start\" x=\"157.62\" y=\"-94.5\" font-family=\"Linux libertine\" font-size=\"10.00\">LeakyReLU</text>\n",
       "<text text-anchor=\"start\" x=\"164\" y=\"-82.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"208,-92 208,-114 251,-114 251,-92 208,-92\"/>\n",
       "<text text-anchor=\"start\" x=\"217.12\" y=\"-99.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"251,-92 251,-114 288,-114 288,-92 251,-92\"/>\n",
       "<text text-anchor=\"start\" x=\"256\" y=\"-99.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(2, 2) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"208,-70 208,-92 251,-92 251,-70 208,-70\"/>\n",
       "<text text-anchor=\"start\" x=\"212.62\" y=\"-77.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"251,-70 251,-92 288,-92 288,-70 251,-70\"/>\n",
       "<text text-anchor=\"start\" x=\"256\" y=\"-77.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(2, 2) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129.4,-161.32C145.66,-149.13 166.36,-133.6 183.92,-120.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.66,-123.5 191.56,-114.7 181.46,-117.9 185.66,-123.5\"/>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.46,-113.9C79.65,-124.89 84.87,-138.59 89.53,-150.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"86.24,-152.04 93.08,-160.14 92.79,-149.54 86.24,-152.04\"/>\n",
       "<text text-anchor=\"middle\" x=\"91.75\" y=\"-133.75\" font-family=\"Times New Roman,serif\" font-size=\"10.00\"> x3</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"271.38,-34 169.62,-34 169.62,0 271.38,0 271.38,-34\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"169.62,0 169.62,-34 237.38,-34 237.38,0 169.62,0\"/>\n",
       "<text text-anchor=\"start\" x=\"174.62\" y=\"-19.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"187\" y=\"-7.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"237.38,0 237.38,-34 271.38,-34 271.38,0 237.38,0\"/>\n",
       "<text text-anchor=\"start\" x=\"242.38\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(2, 2)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.5,-70.28C220.5,-62.46 220.5,-53.45 220.5,-45.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224,-45.18 220.5,-35.18 217,-45.18 224,-45.18\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x248ceb26f30>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz-11.0.0-win64/bin/'\n",
    "model_graph_1.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186dd52-2dcd-4f1d-960c-82479be7c614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d39f4e6-f25d-46f4-8139-041fd3dec5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(dot.exe:125516): Pango-WARNING **: couldn't load font \"Times Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"3951pt\" height=\"681pt\"\n",
       " viewBox=\"0.00 0.00 3950.75 681.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 645)\">\n",
       "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-72,36 -72,-645 3878.75,-645 3878.75,36 -72,36\"/>\n",
       "<!-- /outputs/7 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>/outputs/7</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-252 0,-252 0,-216 54,-216 54,-252\"/>\n",
       "<text text-anchor=\"start\" x=\"8.25\" y=\"-230.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/10 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>/outputs/10</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"152.5,-252 90,-252 90,-216 152.5,-216 152.5,-252\"/>\n",
       "<text text-anchor=\"start\" x=\"98\" y=\"-230.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n",
       "</g>\n",
       "<!-- /outputs/7&#45;&gt;/outputs/10 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>/outputs/7&#45;&gt;/outputs/10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.19,-234C61.72,-234 70.13,-234 78.36,-234\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"78.24,-237.5 88.24,-234 78.24,-230.5 78.24,-237.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/15 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>/outputs/15</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"152.5,-198 90,-198 90,-162 152.5,-162 152.5,-198\"/>\n",
       "<text text-anchor=\"start\" x=\"98\" y=\"-176.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n",
       "</g>\n",
       "<!-- /outputs/7&#45;&gt;/outputs/15 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>/outputs/7&#45;&gt;/outputs/15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.19,-218.67C62.24,-213.96 71.29,-208.66 80.05,-203.53\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"81.59,-206.69 88.45,-198.61 78.05,-200.65 81.59,-206.69\"/>\n",
       "</g>\n",
       "<!-- /outputs/8 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>/outputs/8</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-90 0,-90 0,-54 54,-54 54,-90\"/>\n",
       "<text text-anchor=\"start\" x=\"8.25\" y=\"-68.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/12 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>/outputs/12</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"152.5,-144 90,-144 90,-108 152.5,-108 152.5,-144\"/>\n",
       "<text text-anchor=\"start\" x=\"98\" y=\"-122.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n",
       "</g>\n",
       "<!-- /outputs/8&#45;&gt;/outputs/12 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>/outputs/8&#45;&gt;/outputs/12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.19,-87.33C62.24,-92.04 71.29,-97.34 80.05,-102.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"78.05,-105.35 88.45,-107.39 81.59,-99.31 78.05,-105.35\"/>\n",
       "</g>\n",
       "<!-- /outputs/17 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>/outputs/17</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"152.5,-90 90,-90 90,-54 152.5,-54 152.5,-90\"/>\n",
       "<text text-anchor=\"start\" x=\"98\" y=\"-68.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n",
       "</g>\n",
       "<!-- /outputs/8&#45;&gt;/outputs/17 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>/outputs/8&#45;&gt;/outputs/17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.19,-72C61.72,-72 70.13,-72 78.36,-72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"78.24,-75.5 88.24,-72 78.24,-68.5 78.24,-75.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/9 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>/outputs/9</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-306 0,-306 0,-270 54,-270 54,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"8.25\" y=\"-284.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/9&#45;&gt;/outputs/10 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>/outputs/9&#45;&gt;/outputs/10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.19,-272.67C62.24,-267.96 71.29,-262.66 80.05,-257.53\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"81.59,-260.69 88.45,-252.61 78.05,-254.65 81.59,-260.69\"/>\n",
       "</g>\n",
       "<!-- /outputs/13 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>/outputs/13</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"242.5,-248 188.5,-248 188.5,-212 242.5,-212 242.5,-248\"/>\n",
       "<text text-anchor=\"start\" x=\"200.88\" y=\"-226.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n",
       "</g>\n",
       "<!-- /outputs/10&#45;&gt;/outputs/13 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>/outputs/10&#45;&gt;/outputs/13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M152.97,-232.67C160.64,-232.34 168.97,-231.97 176.93,-231.63\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"176.89,-235.13 186.72,-231.2 176.58,-228.14 176.89,-235.13\"/>\n",
       "</g>\n",
       "<!-- /outputs/11 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>/outputs/11</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-144 0,-144 0,-108 54,-108 54,-144\"/>\n",
       "<text text-anchor=\"start\" x=\"8.25\" y=\"-122.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/11&#45;&gt;/outputs/12 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>/outputs/11&#45;&gt;/outputs/12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.19,-126C61.72,-126 70.13,-126 78.36,-126\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"78.24,-129.5 88.24,-126 78.24,-122.5 78.24,-129.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/12&#45;&gt;/outputs/13 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>/outputs/12&#45;&gt;/outputs/13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.82,-144.46C146.81,-147.24 149.78,-150.14 152.5,-153 167.38,-168.66 182.62,-187.54 194.26,-202.68\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.26,-204.51 200.1,-210.36 196.84,-200.28 191.26,-204.51\"/>\n",
       "</g>\n",
       "<!-- /outputs/19 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>/outputs/19</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"368.75,-248 278.5,-248 278.5,-212 368.75,-212 368.75,-248\"/>\n",
       "<text text-anchor=\"start\" x=\"286.5\" y=\"-226.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">ConstantOfShape</text>\n",
       "</g>\n",
       "<!-- /outputs/13&#45;&gt;/outputs/19 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>/outputs/13&#45;&gt;/outputs/19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M242.73,-230C250.08,-230 258.35,-230 266.72,-230\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"266.59,-233.5 276.59,-230 266.59,-226.5 266.59,-233.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/14 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>/outputs/14</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-198 0,-198 0,-162 54,-162 54,-198\"/>\n",
       "<text text-anchor=\"start\" x=\"8.25\" y=\"-176.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/14&#45;&gt;/outputs/15 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>/outputs/14&#45;&gt;/outputs/15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.19,-180C61.72,-180 70.13,-180 78.36,-180\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"78.24,-183.5 88.24,-180 78.24,-176.5 78.24,-183.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/18 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>/outputs/18</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"242.5,-121 188.5,-121 188.5,-85 242.5,-85 242.5,-121\"/>\n",
       "<text text-anchor=\"start\" x=\"200.88\" y=\"-99.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n",
       "</g>\n",
       "<!-- /outputs/15&#45;&gt;/outputs/18 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>/outputs/15&#45;&gt;/outputs/18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M144.11,-161.75C155.97,-151.85 170.83,-139.45 183.83,-128.6\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.88,-131.45 191.31,-122.35 181.39,-126.07 185.88,-131.45\"/>\n",
       "</g>\n",
       "<!-- /outputs/16 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>/outputs/16</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-36 0,-36 0,0 54,0 54,-36\"/>\n",
       "<text text-anchor=\"start\" x=\"8.25\" y=\"-14.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/16&#45;&gt;/outputs/17 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>/outputs/16&#45;&gt;/outputs/17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.19,-33.33C62.24,-38.04 71.29,-43.34 80.05,-48.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"78.05,-51.35 88.45,-53.39 81.59,-45.31 78.05,-51.35\"/>\n",
       "</g>\n",
       "<!-- /outputs/17&#45;&gt;/outputs/18 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>/outputs/17&#45;&gt;/outputs/18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M152.97,-82.32C160.82,-84.96 169.35,-87.83 177.49,-90.56\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"176.21,-93.82 186.8,-93.69 178.44,-87.19 176.21,-93.82\"/>\n",
       "</g>\n",
       "<!-- /outputs/21 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>/outputs/21</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"368.75,-121 278.5,-121 278.5,-85 368.75,-85 368.75,-121\"/>\n",
       "<text text-anchor=\"start\" x=\"286.5\" y=\"-99.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">ConstantOfShape</text>\n",
       "</g>\n",
       "<!-- /outputs/18&#45;&gt;/outputs/21 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>/outputs/18&#45;&gt;/outputs/21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M242.73,-103C250.08,-103 258.35,-103 266.72,-103\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"266.59,-106.5 276.59,-103 266.59,-99.5 266.59,-106.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/20 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>/outputs/20</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"503.25,-248 404.75,-248 404.75,-212 503.25,-212 503.25,-248\"/>\n",
       "<text text-anchor=\"start\" x=\"412.75\" y=\"-226.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">RandomNormalLike</text>\n",
       "</g>\n",
       "<!-- /outputs/19&#45;&gt;/outputs/20 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>/outputs/19&#45;&gt;/outputs/20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M369.16,-230C376.94,-230 385.14,-230 393.25,-230\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"393.08,-233.5 403.08,-230 393.08,-226.5 393.08,-233.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/23 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>/outputs/23</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"593.25,-248 539.25,-248 539.25,-212 593.25,-212 593.25,-248\"/>\n",
       "<text text-anchor=\"start\" x=\"553.12\" y=\"-226.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- /outputs/20&#45;&gt;/outputs/23 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>/outputs/20&#45;&gt;/outputs/23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M503.68,-230C511.63,-230 519.76,-230 527.4,-230\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"527.39,-233.5 537.39,-230 527.39,-226.5 527.39,-233.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/22 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>/outputs/22</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"817.75,-121 719.25,-121 719.25,-85 817.75,-85 817.75,-121\"/>\n",
       "<text text-anchor=\"start\" x=\"727.25\" y=\"-99.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">RandomNormalLike</text>\n",
       "</g>\n",
       "<!-- /outputs/21&#45;&gt;/outputs/22 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>/outputs/21&#45;&gt;/outputs/22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M369.12,-103C449.18,-103 617.55,-103 707.64,-103\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"707.51,-106.5 717.51,-103 707.51,-99.5 707.51,-106.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/35 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>/outputs/35</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"997.75,-167 943.75,-167 943.75,-131 997.75,-131 997.75,-167\"/>\n",
       "<text text-anchor=\"start\" x=\"963.25\" y=\"-145.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/22&#45;&gt;/outputs/35 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>/outputs/22&#45;&gt;/outputs/35</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M818.15,-106.4C844.95,-109.09 878.59,-113.82 907.75,-122 916.16,-124.36 924.92,-127.63 933.11,-131.08\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"931.53,-134.21 942.1,-135.05 934.36,-127.81 931.53,-134.21\"/>\n",
       "</g>\n",
       "<!-- /outputs/25 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>/outputs/25</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"683.25,-244 629.25,-244 629.25,-208 683.25,-208 683.25,-244\"/>\n",
       "<text text-anchor=\"start\" x=\"648\" y=\"-222.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\n",
       "</g>\n",
       "<!-- /outputs/23&#45;&gt;/outputs/25 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>/outputs/23&#45;&gt;/outputs/25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M593.65,-228.8C601.14,-228.46 609.43,-228.08 617.45,-227.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"617.52,-231.22 627.35,-227.27 617.21,-224.23 617.52,-231.22\"/>\n",
       "</g>\n",
       "<!-- /outputs/24 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>/outputs/24</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"593.25,-194 539.25,-194 539.25,-158 593.25,-158 593.25,-194\"/>\n",
       "<text text-anchor=\"start\" x=\"553.12\" y=\"-172.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- /outputs/24&#45;&gt;/outputs/25 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>/outputs/24&#45;&gt;/outputs/25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M593.65,-191C601.66,-195.55 610.59,-200.63 619.12,-205.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"617.13,-208.36 627.55,-210.26 620.58,-202.28 617.13,-208.36\"/>\n",
       "</g>\n",
       "<!-- /outputs/27/28/29/30 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>/outputs/27/28/29/30</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"795.5,-229 741.5,-229 741.5,-193 795.5,-193 795.5,-229\"/>\n",
       "<text text-anchor=\"start\" x=\"759.12\" y=\"-207.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Split</text>\n",
       "</g>\n",
       "<!-- /outputs/25&#45;&gt;/outputs/27/28/29/30 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>/outputs/25&#45;&gt;/outputs/27/28/29/30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M683.66,-222.41C697.57,-220.51 714.86,-218.16 730.12,-216.09\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"730.37,-219.58 739.81,-214.77 729.43,-212.65 730.37,-219.58\"/>\n",
       "</g>\n",
       "<!-- /outputs/26 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>/outputs/26</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"683.25,-190 629.25,-190 629.25,-154 683.25,-154 683.25,-190\"/>\n",
       "<text text-anchor=\"start\" x=\"637.5\" y=\"-168.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/26&#45;&gt;/outputs/27/28/29/30 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>/outputs/26&#45;&gt;/outputs/27/28/29/30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M683.66,-181.34C697.7,-186.31 715.2,-192.5 730.57,-197.94\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"729.29,-201.19 739.88,-201.23 731.62,-194.6 729.29,-201.19\"/>\n",
       "</g>\n",
       "<!-- /outputs/31 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>/outputs/31</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"907.75,-275 853.75,-275 853.75,-239 907.75,-239 907.75,-275\"/>\n",
       "<text text-anchor=\"start\" x=\"863.5\" y=\"-253.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/27/28/29/30&#45;&gt;/outputs/31 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>/outputs/27/28/29/30&#45;&gt;/outputs/31</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M795.91,-222.02C810.09,-227.94 827.79,-235.32 843.27,-241.78\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"841.58,-244.87 852.16,-245.49 844.28,-238.41 841.58,-244.87\"/>\n",
       "</g>\n",
       "<!-- /outputs/32 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>/outputs/32</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"907.75,-167 853.75,-167 853.75,-131 907.75,-131 907.75,-167\"/>\n",
       "<text text-anchor=\"start\" x=\"863.5\" y=\"-145.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/27/28/29/30&#45;&gt;/outputs/32 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>/outputs/27/28/29/30&#45;&gt;/outputs/32</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M795.91,-196.15C810.23,-188.1 828.13,-178.03 843.71,-169.27\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"845.24,-172.42 852.24,-164.47 841.81,-166.32 845.24,-172.42\"/>\n",
       "</g>\n",
       "<!-- /outputs/33 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>/outputs/33</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"907.75,-221 853.75,-221 853.75,-185 907.75,-185 907.75,-221\"/>\n",
       "<text text-anchor=\"start\" x=\"869.88\" y=\"-199.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Tanh</text>\n",
       "</g>\n",
       "<!-- /outputs/27/28/29/30&#45;&gt;/outputs/33 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>/outputs/27/28/29/30&#45;&gt;/outputs/33</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M795.91,-209.08C809.82,-208.07 827.11,-206.82 842.37,-205.71\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"842.33,-209.22 852.05,-205.01 841.82,-202.24 842.33,-209.22\"/>\n",
       "</g>\n",
       "<!-- /outputs/34 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>/outputs/34</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1087.75,-321 1033.75,-321 1033.75,-285 1087.75,-285 1087.75,-321\"/>\n",
       "<text text-anchor=\"start\" x=\"1043.5\" y=\"-299.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/27/28/29/30&#45;&gt;/outputs/34 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>/outputs/27/28/29/30&#45;&gt;/outputs/34</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M784.43,-229.3C799.8,-246.69 825.44,-271.93 853.75,-284 908.86,-307.5 979.62,-308.44 1022.23,-306.24\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1022.19,-309.75 1031.96,-305.65 1021.76,-302.77 1022.19,-309.75\"/>\n",
       "</g>\n",
       "<!-- /outputs/36 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>/outputs/36</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"997.75,-221 943.75,-221 943.75,-185 997.75,-185 997.75,-221\"/>\n",
       "<text text-anchor=\"start\" x=\"963.25\" y=\"-199.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/31&#45;&gt;/outputs/36 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>/outputs/31&#45;&gt;/outputs/36</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M908.15,-240.8C916.16,-235.89 925.09,-230.4 933.62,-225.17\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"935.38,-228.2 942.08,-219.98 931.72,-222.23 935.38,-228.2\"/>\n",
       "</g>\n",
       "<!-- /outputs/32&#45;&gt;/outputs/35 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>/outputs/32&#45;&gt;/outputs/35</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M908.15,-149C915.64,-149 923.93,-149 931.95,-149\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"931.85,-152.5 941.85,-149 931.85,-145.5 931.85,-152.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/33&#45;&gt;/outputs/36 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>/outputs/33&#45;&gt;/outputs/36</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M908.15,-203C915.64,-203 923.93,-203 931.95,-203\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"931.85,-206.5 941.85,-203 931.85,-199.5 931.85,-206.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/39 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>/outputs/39</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1267.75,-321 1213.75,-321 1213.75,-285 1267.75,-285 1267.75,-321\"/>\n",
       "<text text-anchor=\"start\" x=\"1233.25\" y=\"-299.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/34&#45;&gt;/outputs/39 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>/outputs/34&#45;&gt;/outputs/39</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1088.01,-303C1118.12,-303 1167.71,-303 1201.96,-303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1201.86,-306.5 1211.86,-303 1201.86,-299.5 1201.86,-306.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/37 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>/outputs/37</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1087.75,-221 1033.75,-221 1033.75,-185 1087.75,-185 1087.75,-221\"/>\n",
       "<text text-anchor=\"start\" x=\"1052.5\" y=\"-199.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\n",
       "</g>\n",
       "<!-- /outputs/35&#45;&gt;/outputs/37 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>/outputs/35&#45;&gt;/outputs/37</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M998.15,-165.2C1006.16,-170.11 1015.09,-175.6 1023.62,-180.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1021.72,-183.77 1032.08,-186.02 1025.38,-177.8 1021.72,-183.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/36&#45;&gt;/outputs/37 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>/outputs/36&#45;&gt;/outputs/37</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M998.15,-203C1005.64,-203 1013.93,-203 1021.95,-203\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1021.85,-206.5 1031.85,-203 1021.85,-199.5 1021.85,-206.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/38 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>/outputs/38</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1177.75,-271 1123.75,-271 1123.75,-235 1177.75,-235 1177.75,-271\"/>\n",
       "<text text-anchor=\"start\" x=\"1139.88\" y=\"-249.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Tanh</text>\n",
       "</g>\n",
       "<!-- /outputs/37&#45;&gt;/outputs/38 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>/outputs/37&#45;&gt;/outputs/38</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1088.15,-218C1096.16,-222.55 1105.09,-227.63 1113.62,-232.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1111.63,-235.36 1122.05,-237.26 1115.08,-229.28 1111.63,-235.36\"/>\n",
       "</g>\n",
       "<!-- /outputs/53 -->\n",
       "<g id=\"node41\" class=\"node\">\n",
       "<title>/outputs/53</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1812.5,-267 1758.5,-267 1758.5,-231 1812.5,-231 1812.5,-267\"/>\n",
       "<text text-anchor=\"start\" x=\"1778\" y=\"-245.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/37&#45;&gt;/outputs/53 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>/outputs/37&#45;&gt;/outputs/53</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1087.99,-203C1122.71,-203 1185.82,-203 1239.75,-203 1239.75,-203 1239.75,-203 1606.5,-203 1658.74,-203 1672.39,-207.23 1722.5,-222 1730.88,-224.47 1739.62,-227.78 1747.81,-231.24\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1746.24,-234.37 1756.8,-235.21 1749.06,-227.97 1746.24,-234.37\"/>\n",
       "</g>\n",
       "<!-- /outputs/38&#45;&gt;/outputs/39 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>/outputs/38&#45;&gt;/outputs/39</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1178.15,-268C1186.16,-272.55 1195.09,-277.63 1203.62,-282.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1201.63,-285.36 1212.05,-287.26 1205.08,-279.28 1201.63,-285.36\"/>\n",
       "</g>\n",
       "<!-- /outputs/40 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>/outputs/40</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1362.5,-321 1303.75,-321 1303.75,-285 1362.5,-285 1362.5,-321\"/>\n",
       "<text text-anchor=\"start\" x=\"1311.75\" y=\"-299.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">LeakyRelu</text>\n",
       "</g>\n",
       "<!-- /outputs/39&#45;&gt;/outputs/40 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>/outputs/39&#45;&gt;/outputs/40</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1267.89,-303C1275.47,-303 1283.93,-303 1292.16,-303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1292,-306.5 1302,-303 1292,-299.5 1292,-306.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/41 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>/outputs/41</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1452.5,-321 1398.5,-321 1398.5,-285 1452.5,-285 1452.5,-321\"/>\n",
       "<text text-anchor=\"start\" x=\"1412.38\" y=\"-299.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- /outputs/40&#45;&gt;/outputs/41 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>/outputs/40&#45;&gt;/outputs/41</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1362.72,-303C1370.36,-303 1378.74,-303 1386.8,-303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1386.72,-306.5 1396.72,-303 1386.72,-299.5 1386.72,-306.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/43 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>/outputs/43</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1542.5,-321 1488.5,-321 1488.5,-285 1542.5,-285 1542.5,-321\"/>\n",
       "<text text-anchor=\"start\" x=\"1507.25\" y=\"-299.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\n",
       "</g>\n",
       "<!-- /outputs/41&#45;&gt;/outputs/43 -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>/outputs/41&#45;&gt;/outputs/43</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1452.9,-303C1460.39,-303 1468.68,-303 1476.7,-303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1476.6,-306.5 1486.6,-303 1476.6,-299.5 1476.6,-306.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/42 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>/outputs/42</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1452.5,-267 1398.5,-267 1398.5,-231 1452.5,-231 1452.5,-267\"/>\n",
       "<text text-anchor=\"start\" x=\"1412.38\" y=\"-245.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- /outputs/42&#45;&gt;/outputs/43 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>/outputs/42&#45;&gt;/outputs/43</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1452.9,-265.2C1460.91,-270.11 1469.84,-275.6 1478.37,-280.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1476.47,-283.77 1486.83,-286.02 1480.13,-277.8 1476.47,-283.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/45/46/47/48 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>/outputs/45/46/47/48</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1632.5,-321 1578.5,-321 1578.5,-285 1632.5,-285 1632.5,-321\"/>\n",
       "<text text-anchor=\"start\" x=\"1596.12\" y=\"-299.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Split</text>\n",
       "</g>\n",
       "<!-- /outputs/43&#45;&gt;/outputs/45/46/47/48 -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>/outputs/43&#45;&gt;/outputs/45/46/47/48</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1542.9,-303C1550.39,-303 1558.68,-303 1566.7,-303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1566.6,-306.5 1576.6,-303 1566.6,-299.5 1566.6,-306.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/44 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>/outputs/44</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1542.5,-267 1488.5,-267 1488.5,-231 1542.5,-231 1542.5,-267\"/>\n",
       "<text text-anchor=\"start\" x=\"1496.75\" y=\"-245.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/44&#45;&gt;/outputs/45/46/47/48 -->\n",
       "<g id=\"edge41\" class=\"edge\">\n",
       "<title>/outputs/44&#45;&gt;/outputs/45/46/47/48</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1542.9,-265.2C1550.91,-270.11 1559.84,-275.6 1568.37,-280.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1566.47,-283.77 1576.83,-286.02 1570.13,-277.8 1566.47,-283.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/49 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>/outputs/49</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1722.5,-375 1668.5,-375 1668.5,-339 1722.5,-339 1722.5,-375\"/>\n",
       "<text text-anchor=\"start\" x=\"1678.25\" y=\"-353.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/45/46/47/48&#45;&gt;/outputs/49 -->\n",
       "<g id=\"edge42\" class=\"edge\">\n",
       "<title>/outputs/45/46/47/48&#45;&gt;/outputs/49</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1632.9,-319.2C1640.91,-324.11 1649.84,-329.6 1658.37,-334.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1656.47,-337.77 1666.83,-340.02 1660.13,-331.8 1656.47,-337.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/50 -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>/outputs/50</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1722.5,-267 1668.5,-267 1668.5,-231 1722.5,-231 1722.5,-267\"/>\n",
       "<text text-anchor=\"start\" x=\"1678.25\" y=\"-245.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/45/46/47/48&#45;&gt;/outputs/50 -->\n",
       "<g id=\"edge43\" class=\"edge\">\n",
       "<title>/outputs/45/46/47/48&#45;&gt;/outputs/50</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1632.9,-286.8C1640.91,-281.89 1649.84,-276.4 1658.37,-271.17\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1660.13,-274.2 1666.83,-265.98 1656.47,-268.23 1660.13,-274.2\"/>\n",
       "</g>\n",
       "<!-- /outputs/51 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>/outputs/51</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1722.5,-321 1668.5,-321 1668.5,-285 1722.5,-285 1722.5,-321\"/>\n",
       "<text text-anchor=\"start\" x=\"1684.62\" y=\"-299.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Tanh</text>\n",
       "</g>\n",
       "<!-- /outputs/45/46/47/48&#45;&gt;/outputs/51 -->\n",
       "<g id=\"edge44\" class=\"edge\">\n",
       "<title>/outputs/45/46/47/48&#45;&gt;/outputs/51</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1632.9,-303C1640.39,-303 1648.68,-303 1656.7,-303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1656.6,-306.5 1666.6,-303 1656.6,-299.5 1656.6,-306.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/52 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>/outputs/52</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1902.5,-421 1848.5,-421 1848.5,-385 1902.5,-385 1902.5,-421\"/>\n",
       "<text text-anchor=\"start\" x=\"1858.25\" y=\"-399.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/45/46/47/48&#45;&gt;/outputs/52 -->\n",
       "<g id=\"edge45\" class=\"edge\">\n",
       "<title>/outputs/45/46/47/48&#45;&gt;/outputs/52</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1614.92,-321.42C1624.78,-340.66 1643.08,-369.96 1668.5,-384 1721.23,-413.13 1793.3,-412.25 1836.72,-408.17\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1837.09,-411.65 1846.67,-407.12 1836.35,-404.69 1837.09,-411.65\"/>\n",
       "</g>\n",
       "<!-- /outputs/54 -->\n",
       "<g id=\"node42\" class=\"node\">\n",
       "<title>/outputs/54</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1812.5,-321 1758.5,-321 1758.5,-285 1812.5,-285 1812.5,-321\"/>\n",
       "<text text-anchor=\"start\" x=\"1778\" y=\"-299.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/49&#45;&gt;/outputs/54 -->\n",
       "<g id=\"edge46\" class=\"edge\">\n",
       "<title>/outputs/49&#45;&gt;/outputs/54</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1722.9,-340.8C1730.91,-335.89 1739.84,-330.4 1748.37,-325.17\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1750.13,-328.2 1756.83,-319.98 1746.47,-322.23 1750.13,-328.2\"/>\n",
       "</g>\n",
       "<!-- /outputs/50&#45;&gt;/outputs/53 -->\n",
       "<g id=\"edge47\" class=\"edge\">\n",
       "<title>/outputs/50&#45;&gt;/outputs/53</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1722.9,-249C1730.39,-249 1738.68,-249 1746.7,-249\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1746.6,-252.5 1756.6,-249 1746.6,-245.5 1746.6,-252.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/51&#45;&gt;/outputs/54 -->\n",
       "<g id=\"edge48\" class=\"edge\">\n",
       "<title>/outputs/51&#45;&gt;/outputs/54</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1722.9,-303C1730.39,-303 1738.68,-303 1746.7,-303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1746.6,-306.5 1756.6,-303 1746.6,-299.5 1746.6,-306.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/57 -->\n",
       "<g id=\"node45\" class=\"node\">\n",
       "<title>/outputs/57</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2082.5,-421 2028.5,-421 2028.5,-385 2082.5,-385 2082.5,-421\"/>\n",
       "<text text-anchor=\"start\" x=\"2048\" y=\"-399.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/52&#45;&gt;/outputs/57 -->\n",
       "<g id=\"edge49\" class=\"edge\">\n",
       "<title>/outputs/52&#45;&gt;/outputs/57</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1902.76,-403C1932.87,-403 1982.46,-403 2016.71,-403\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2016.61,-406.5 2026.61,-403 2016.61,-399.5 2016.61,-406.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/55 -->\n",
       "<g id=\"node43\" class=\"node\">\n",
       "<title>/outputs/55</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1902.5,-321 1848.5,-321 1848.5,-285 1902.5,-285 1902.5,-321\"/>\n",
       "<text text-anchor=\"start\" x=\"1867.25\" y=\"-299.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\n",
       "</g>\n",
       "<!-- /outputs/53&#45;&gt;/outputs/55 -->\n",
       "<g id=\"edge50\" class=\"edge\">\n",
       "<title>/outputs/53&#45;&gt;/outputs/55</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1812.9,-265.2C1820.91,-270.11 1829.84,-275.6 1838.37,-280.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1836.47,-283.77 1846.83,-286.02 1840.13,-277.8 1836.47,-283.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/54&#45;&gt;/outputs/55 -->\n",
       "<g id=\"edge51\" class=\"edge\">\n",
       "<title>/outputs/54&#45;&gt;/outputs/55</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1812.9,-303C1820.39,-303 1828.68,-303 1836.7,-303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1836.6,-306.5 1846.6,-303 1836.6,-299.5 1836.6,-306.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/56 -->\n",
       "<g id=\"node44\" class=\"node\">\n",
       "<title>/outputs/56</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1992.5,-371 1938.5,-371 1938.5,-335 1992.5,-335 1992.5,-371\"/>\n",
       "<text text-anchor=\"start\" x=\"1954.62\" y=\"-349.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Tanh</text>\n",
       "</g>\n",
       "<!-- /outputs/55&#45;&gt;/outputs/56 -->\n",
       "<g id=\"edge52\" class=\"edge\">\n",
       "<title>/outputs/55&#45;&gt;/outputs/56</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1902.9,-318C1910.91,-322.55 1919.84,-327.63 1928.37,-332.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1926.38,-335.36 1936.8,-337.26 1929.83,-329.28 1926.38,-335.36\"/>\n",
       "</g>\n",
       "<!-- /outputs/71 -->\n",
       "<g id=\"node56\" class=\"node\">\n",
       "<title>/outputs/71</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2627.25,-367 2573.25,-367 2573.25,-331 2627.25,-331 2627.25,-367\"/>\n",
       "<text text-anchor=\"start\" x=\"2592.75\" y=\"-345.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/55&#45;&gt;/outputs/71 -->\n",
       "<g id=\"edge53\" class=\"edge\">\n",
       "<title>/outputs/55&#45;&gt;/outputs/71</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1902.74,-303C1937.46,-303 2000.57,-303 2054.5,-303 2054.5,-303 2054.5,-303 2421.25,-303 2473.49,-303 2487.14,-307.23 2537.25,-322 2545.63,-324.47 2554.37,-327.78 2562.56,-331.24\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2560.99,-334.37 2571.55,-335.21 2563.81,-327.97 2560.99,-334.37\"/>\n",
       "</g>\n",
       "<!-- /outputs/56&#45;&gt;/outputs/57 -->\n",
       "<g id=\"edge54\" class=\"edge\">\n",
       "<title>/outputs/56&#45;&gt;/outputs/57</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1992.9,-368C2000.91,-372.55 2009.84,-377.63 2018.37,-382.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2016.38,-385.36 2026.8,-387.26 2019.83,-379.28 2016.38,-385.36\"/>\n",
       "</g>\n",
       "<!-- /outputs/58 -->\n",
       "<g id=\"node46\" class=\"node\">\n",
       "<title>/outputs/58</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2177.25,-421 2118.5,-421 2118.5,-385 2177.25,-385 2177.25,-421\"/>\n",
       "<text text-anchor=\"start\" x=\"2126.5\" y=\"-399.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">LeakyRelu</text>\n",
       "</g>\n",
       "<!-- /outputs/57&#45;&gt;/outputs/58 -->\n",
       "<g id=\"edge55\" class=\"edge\">\n",
       "<title>/outputs/57&#45;&gt;/outputs/58</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2082.64,-403C2090.22,-403 2098.68,-403 2106.91,-403\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2106.75,-406.5 2116.75,-403 2106.75,-399.5 2106.75,-406.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/59 -->\n",
       "<g id=\"node47\" class=\"node\">\n",
       "<title>/outputs/59</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2267.25,-421 2213.25,-421 2213.25,-385 2267.25,-385 2267.25,-421\"/>\n",
       "<text text-anchor=\"start\" x=\"2227.12\" y=\"-399.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- /outputs/58&#45;&gt;/outputs/59 -->\n",
       "<g id=\"edge56\" class=\"edge\">\n",
       "<title>/outputs/58&#45;&gt;/outputs/59</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2177.47,-403C2185.11,-403 2193.49,-403 2201.55,-403\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2201.47,-406.5 2211.47,-403 2201.47,-399.5 2201.47,-406.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/61 -->\n",
       "<g id=\"node49\" class=\"node\">\n",
       "<title>/outputs/61</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2357.25,-421 2303.25,-421 2303.25,-385 2357.25,-385 2357.25,-421\"/>\n",
       "<text text-anchor=\"start\" x=\"2322\" y=\"-399.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\n",
       "</g>\n",
       "<!-- /outputs/59&#45;&gt;/outputs/61 -->\n",
       "<g id=\"edge57\" class=\"edge\">\n",
       "<title>/outputs/59&#45;&gt;/outputs/61</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2267.65,-403C2275.14,-403 2283.43,-403 2291.45,-403\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2291.35,-406.5 2301.35,-403 2291.35,-399.5 2291.35,-406.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/60 -->\n",
       "<g id=\"node48\" class=\"node\">\n",
       "<title>/outputs/60</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2267.25,-367 2213.25,-367 2213.25,-331 2267.25,-331 2267.25,-367\"/>\n",
       "<text text-anchor=\"start\" x=\"2227.12\" y=\"-345.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- /outputs/60&#45;&gt;/outputs/61 -->\n",
       "<g id=\"edge58\" class=\"edge\">\n",
       "<title>/outputs/60&#45;&gt;/outputs/61</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2267.65,-365.2C2275.66,-370.11 2284.59,-375.6 2293.12,-380.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2291.22,-383.77 2301.58,-386.02 2294.88,-377.8 2291.22,-383.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/63/64/65/66 -->\n",
       "<g id=\"node51\" class=\"node\">\n",
       "<title>/outputs/63/64/65/66</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2447.25,-421 2393.25,-421 2393.25,-385 2447.25,-385 2447.25,-421\"/>\n",
       "<text text-anchor=\"start\" x=\"2410.88\" y=\"-399.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Split</text>\n",
       "</g>\n",
       "<!-- /outputs/61&#45;&gt;/outputs/63/64/65/66 -->\n",
       "<g id=\"edge59\" class=\"edge\">\n",
       "<title>/outputs/61&#45;&gt;/outputs/63/64/65/66</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2357.65,-403C2365.14,-403 2373.43,-403 2381.45,-403\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2381.35,-406.5 2391.35,-403 2381.35,-399.5 2381.35,-406.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/62 -->\n",
       "<g id=\"node50\" class=\"node\">\n",
       "<title>/outputs/62</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2357.25,-367 2303.25,-367 2303.25,-331 2357.25,-331 2357.25,-367\"/>\n",
       "<text text-anchor=\"start\" x=\"2311.5\" y=\"-345.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/62&#45;&gt;/outputs/63/64/65/66 -->\n",
       "<g id=\"edge60\" class=\"edge\">\n",
       "<title>/outputs/62&#45;&gt;/outputs/63/64/65/66</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2357.65,-365.2C2365.66,-370.11 2374.59,-375.6 2383.12,-380.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2381.22,-383.77 2391.58,-386.02 2384.88,-377.8 2381.22,-383.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/67 -->\n",
       "<g id=\"node52\" class=\"node\">\n",
       "<title>/outputs/67</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2537.25,-475 2483.25,-475 2483.25,-439 2537.25,-439 2537.25,-475\"/>\n",
       "<text text-anchor=\"start\" x=\"2493\" y=\"-453.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/63/64/65/66&#45;&gt;/outputs/67 -->\n",
       "<g id=\"edge61\" class=\"edge\">\n",
       "<title>/outputs/63/64/65/66&#45;&gt;/outputs/67</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2447.65,-419.2C2455.66,-424.11 2464.59,-429.6 2473.12,-434.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2471.22,-437.77 2481.58,-440.02 2474.88,-431.8 2471.22,-437.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/68 -->\n",
       "<g id=\"node53\" class=\"node\">\n",
       "<title>/outputs/68</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2537.25,-367 2483.25,-367 2483.25,-331 2537.25,-331 2537.25,-367\"/>\n",
       "<text text-anchor=\"start\" x=\"2493\" y=\"-345.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/63/64/65/66&#45;&gt;/outputs/68 -->\n",
       "<g id=\"edge62\" class=\"edge\">\n",
       "<title>/outputs/63/64/65/66&#45;&gt;/outputs/68</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2447.65,-386.8C2455.66,-381.89 2464.59,-376.4 2473.12,-371.17\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2474.88,-374.2 2481.58,-365.98 2471.22,-368.23 2474.88,-374.2\"/>\n",
       "</g>\n",
       "<!-- /outputs/69 -->\n",
       "<g id=\"node54\" class=\"node\">\n",
       "<title>/outputs/69</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2537.25,-421 2483.25,-421 2483.25,-385 2537.25,-385 2537.25,-421\"/>\n",
       "<text text-anchor=\"start\" x=\"2499.38\" y=\"-399.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Tanh</text>\n",
       "</g>\n",
       "<!-- /outputs/63/64/65/66&#45;&gt;/outputs/69 -->\n",
       "<g id=\"edge63\" class=\"edge\">\n",
       "<title>/outputs/63/64/65/66&#45;&gt;/outputs/69</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2447.65,-403C2455.14,-403 2463.43,-403 2471.45,-403\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2471.35,-406.5 2481.35,-403 2471.35,-399.5 2471.35,-406.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/70 -->\n",
       "<g id=\"node55\" class=\"node\">\n",
       "<title>/outputs/70</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2717.25,-521 2663.25,-521 2663.25,-485 2717.25,-485 2717.25,-521\"/>\n",
       "<text text-anchor=\"start\" x=\"2673\" y=\"-499.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/63/64/65/66&#45;&gt;/outputs/70 -->\n",
       "<g id=\"edge64\" class=\"edge\">\n",
       "<title>/outputs/63/64/65/66&#45;&gt;/outputs/70</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2429.67,-421.42C2439.53,-440.66 2457.83,-469.96 2483.25,-484 2535.98,-513.13 2608.05,-512.25 2651.47,-508.17\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2651.84,-511.65 2661.42,-507.12 2651.1,-504.69 2651.84,-511.65\"/>\n",
       "</g>\n",
       "<!-- /outputs/72 -->\n",
       "<g id=\"node57\" class=\"node\">\n",
       "<title>/outputs/72</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2627.25,-421 2573.25,-421 2573.25,-385 2627.25,-385 2627.25,-421\"/>\n",
       "<text text-anchor=\"start\" x=\"2592.75\" y=\"-399.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/67&#45;&gt;/outputs/72 -->\n",
       "<g id=\"edge65\" class=\"edge\">\n",
       "<title>/outputs/67&#45;&gt;/outputs/72</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2537.65,-440.8C2545.66,-435.89 2554.59,-430.4 2563.12,-425.17\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2564.88,-428.2 2571.58,-419.98 2561.22,-422.23 2564.88,-428.2\"/>\n",
       "</g>\n",
       "<!-- /outputs/68&#45;&gt;/outputs/71 -->\n",
       "<g id=\"edge66\" class=\"edge\">\n",
       "<title>/outputs/68&#45;&gt;/outputs/71</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2537.65,-349C2545.14,-349 2553.43,-349 2561.45,-349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2561.35,-352.5 2571.35,-349 2561.35,-345.5 2561.35,-352.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/69&#45;&gt;/outputs/72 -->\n",
       "<g id=\"edge67\" class=\"edge\">\n",
       "<title>/outputs/69&#45;&gt;/outputs/72</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2537.65,-403C2545.14,-403 2553.43,-403 2561.45,-403\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2561.35,-406.5 2571.35,-403 2561.35,-399.5 2561.35,-406.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/75 -->\n",
       "<g id=\"node60\" class=\"node\">\n",
       "<title>/outputs/75</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2897.25,-521 2843.25,-521 2843.25,-485 2897.25,-485 2897.25,-521\"/>\n",
       "<text text-anchor=\"start\" x=\"2862.75\" y=\"-499.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/70&#45;&gt;/outputs/75 -->\n",
       "<g id=\"edge68\" class=\"edge\">\n",
       "<title>/outputs/70&#45;&gt;/outputs/75</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2717.51,-503C2747.62,-503 2797.21,-503 2831.46,-503\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2831.36,-506.5 2841.36,-503 2831.36,-499.5 2831.36,-506.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/73 -->\n",
       "<g id=\"node58\" class=\"node\">\n",
       "<title>/outputs/73</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2717.25,-421 2663.25,-421 2663.25,-385 2717.25,-385 2717.25,-421\"/>\n",
       "<text text-anchor=\"start\" x=\"2682\" y=\"-399.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\n",
       "</g>\n",
       "<!-- /outputs/71&#45;&gt;/outputs/73 -->\n",
       "<g id=\"edge69\" class=\"edge\">\n",
       "<title>/outputs/71&#45;&gt;/outputs/73</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2627.65,-365.2C2635.66,-370.11 2644.59,-375.6 2653.12,-380.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2651.22,-383.77 2661.58,-386.02 2654.88,-377.8 2651.22,-383.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/72&#45;&gt;/outputs/73 -->\n",
       "<g id=\"edge70\" class=\"edge\">\n",
       "<title>/outputs/72&#45;&gt;/outputs/73</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2627.65,-403C2635.14,-403 2643.43,-403 2651.45,-403\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2651.35,-406.5 2661.35,-403 2651.35,-399.5 2651.35,-406.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/74 -->\n",
       "<g id=\"node59\" class=\"node\">\n",
       "<title>/outputs/74</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2807.25,-471 2753.25,-471 2753.25,-435 2807.25,-435 2807.25,-471\"/>\n",
       "<text text-anchor=\"start\" x=\"2769.38\" y=\"-449.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Tanh</text>\n",
       "</g>\n",
       "<!-- /outputs/73&#45;&gt;/outputs/74 -->\n",
       "<g id=\"edge71\" class=\"edge\">\n",
       "<title>/outputs/73&#45;&gt;/outputs/74</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2717.65,-418C2725.66,-422.55 2734.59,-427.63 2743.12,-432.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2741.13,-435.36 2751.55,-437.26 2744.58,-429.28 2741.13,-435.36\"/>\n",
       "</g>\n",
       "<!-- /outputs/89 -->\n",
       "<g id=\"node71\" class=\"node\">\n",
       "<title>/outputs/89</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3442,-467 3388,-467 3388,-431 3442,-431 3442,-467\"/>\n",
       "<text text-anchor=\"start\" x=\"3407.5\" y=\"-445.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/73&#45;&gt;/outputs/89 -->\n",
       "<g id=\"edge72\" class=\"edge\">\n",
       "<title>/outputs/73&#45;&gt;/outputs/89</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2717.49,-403C2752.21,-403 2815.32,-403 2869.25,-403 2869.25,-403 2869.25,-403 3236,-403 3288.24,-403 3301.89,-407.23 3352,-422 3360.38,-424.47 3369.12,-427.78 3377.31,-431.24\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3375.74,-434.37 3386.3,-435.21 3378.56,-427.97 3375.74,-434.37\"/>\n",
       "</g>\n",
       "<!-- /outputs/74&#45;&gt;/outputs/75 -->\n",
       "<g id=\"edge73\" class=\"edge\">\n",
       "<title>/outputs/74&#45;&gt;/outputs/75</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2807.65,-468C2815.66,-472.55 2824.59,-477.63 2833.12,-482.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2831.13,-485.36 2841.55,-487.26 2834.58,-479.28 2831.13,-485.36\"/>\n",
       "</g>\n",
       "<!-- /outputs/76 -->\n",
       "<g id=\"node61\" class=\"node\">\n",
       "<title>/outputs/76</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2992,-521 2933.25,-521 2933.25,-485 2992,-485 2992,-521\"/>\n",
       "<text text-anchor=\"start\" x=\"2941.25\" y=\"-499.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">LeakyRelu</text>\n",
       "</g>\n",
       "<!-- /outputs/75&#45;&gt;/outputs/76 -->\n",
       "<g id=\"edge74\" class=\"edge\">\n",
       "<title>/outputs/75&#45;&gt;/outputs/76</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2897.39,-503C2904.97,-503 2913.43,-503 2921.66,-503\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2921.5,-506.5 2931.5,-503 2921.5,-499.5 2921.5,-506.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/77 -->\n",
       "<g id=\"node62\" class=\"node\">\n",
       "<title>/outputs/77</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3082,-521 3028,-521 3028,-485 3082,-485 3082,-521\"/>\n",
       "<text text-anchor=\"start\" x=\"3041.88\" y=\"-499.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- /outputs/76&#45;&gt;/outputs/77 -->\n",
       "<g id=\"edge75\" class=\"edge\">\n",
       "<title>/outputs/76&#45;&gt;/outputs/77</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M2992.22,-503C2999.86,-503 3008.24,-503 3016.3,-503\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3016.22,-506.5 3026.22,-503 3016.22,-499.5 3016.22,-506.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/79 -->\n",
       "<g id=\"node64\" class=\"node\">\n",
       "<title>/outputs/79</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3172,-521 3118,-521 3118,-485 3172,-485 3172,-521\"/>\n",
       "<text text-anchor=\"start\" x=\"3136.75\" y=\"-499.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\n",
       "</g>\n",
       "<!-- /outputs/77&#45;&gt;/outputs/79 -->\n",
       "<g id=\"edge76\" class=\"edge\">\n",
       "<title>/outputs/77&#45;&gt;/outputs/79</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3082.4,-503C3089.89,-503 3098.18,-503 3106.2,-503\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3106.1,-506.5 3116.1,-503 3106.1,-499.5 3106.1,-506.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/78 -->\n",
       "<g id=\"node63\" class=\"node\">\n",
       "<title>/outputs/78</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3082,-467 3028,-467 3028,-431 3082,-431 3082,-467\"/>\n",
       "<text text-anchor=\"start\" x=\"3041.88\" y=\"-445.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- /outputs/78&#45;&gt;/outputs/79 -->\n",
       "<g id=\"edge77\" class=\"edge\">\n",
       "<title>/outputs/78&#45;&gt;/outputs/79</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3082.4,-465.2C3090.41,-470.11 3099.34,-475.6 3107.87,-480.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3105.97,-483.77 3116.33,-486.02 3109.63,-477.8 3105.97,-483.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/81/82/83/84 -->\n",
       "<g id=\"node66\" class=\"node\">\n",
       "<title>/outputs/81/82/83/84</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3262,-521 3208,-521 3208,-485 3262,-485 3262,-521\"/>\n",
       "<text text-anchor=\"start\" x=\"3225.62\" y=\"-499.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Split</text>\n",
       "</g>\n",
       "<!-- /outputs/79&#45;&gt;/outputs/81/82/83/84 -->\n",
       "<g id=\"edge78\" class=\"edge\">\n",
       "<title>/outputs/79&#45;&gt;/outputs/81/82/83/84</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3172.4,-503C3179.89,-503 3188.18,-503 3196.2,-503\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3196.1,-506.5 3206.1,-503 3196.1,-499.5 3196.1,-506.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/80 -->\n",
       "<g id=\"node65\" class=\"node\">\n",
       "<title>/outputs/80</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3172,-467 3118,-467 3118,-431 3172,-431 3172,-467\"/>\n",
       "<text text-anchor=\"start\" x=\"3126.25\" y=\"-445.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/80&#45;&gt;/outputs/81/82/83/84 -->\n",
       "<g id=\"edge79\" class=\"edge\">\n",
       "<title>/outputs/80&#45;&gt;/outputs/81/82/83/84</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3172.4,-465.2C3180.41,-470.11 3189.34,-475.6 3197.87,-480.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3195.97,-483.77 3206.33,-486.02 3199.63,-477.8 3195.97,-483.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/85 -->\n",
       "<g id=\"node67\" class=\"node\">\n",
       "<title>/outputs/85</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3352,-575 3298,-575 3298,-539 3352,-539 3352,-575\"/>\n",
       "<text text-anchor=\"start\" x=\"3307.75\" y=\"-553.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/81/82/83/84&#45;&gt;/outputs/85 -->\n",
       "<g id=\"edge80\" class=\"edge\">\n",
       "<title>/outputs/81/82/83/84&#45;&gt;/outputs/85</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3262.4,-519.2C3270.41,-524.11 3279.34,-529.6 3287.87,-534.83\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3285.97,-537.77 3296.33,-540.02 3289.63,-531.8 3285.97,-537.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/86 -->\n",
       "<g id=\"node68\" class=\"node\">\n",
       "<title>/outputs/86</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3352,-467 3298,-467 3298,-431 3352,-431 3352,-467\"/>\n",
       "<text text-anchor=\"start\" x=\"3307.75\" y=\"-445.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/81/82/83/84&#45;&gt;/outputs/86 -->\n",
       "<g id=\"edge81\" class=\"edge\">\n",
       "<title>/outputs/81/82/83/84&#45;&gt;/outputs/86</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3262.4,-486.8C3270.41,-481.89 3279.34,-476.4 3287.87,-471.17\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3289.63,-474.2 3296.33,-465.98 3285.97,-468.23 3289.63,-474.2\"/>\n",
       "</g>\n",
       "<!-- /outputs/87 -->\n",
       "<g id=\"node69\" class=\"node\">\n",
       "<title>/outputs/87</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3352,-521 3298,-521 3298,-485 3352,-485 3352,-521\"/>\n",
       "<text text-anchor=\"start\" x=\"3314.12\" y=\"-499.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Tanh</text>\n",
       "</g>\n",
       "<!-- /outputs/81/82/83/84&#45;&gt;/outputs/87 -->\n",
       "<g id=\"edge82\" class=\"edge\">\n",
       "<title>/outputs/81/82/83/84&#45;&gt;/outputs/87</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3262.4,-503C3269.89,-503 3278.18,-503 3286.2,-503\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3286.1,-506.5 3296.1,-503 3286.1,-499.5 3286.1,-506.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/88 -->\n",
       "<g id=\"node70\" class=\"node\">\n",
       "<title>/outputs/88</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3532,-609 3478,-609 3478,-573 3532,-573 3532,-609\"/>\n",
       "<text text-anchor=\"start\" x=\"3487.75\" y=\"-587.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- /outputs/81/82/83/84&#45;&gt;/outputs/88 -->\n",
       "<g id=\"edge83\" class=\"edge\">\n",
       "<title>/outputs/81/82/83/84&#45;&gt;/outputs/88</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3244.09,-521.36C3253.78,-540.84 3272.02,-570.62 3298,-584 3351.33,-611.47 3423.14,-605.97 3466.37,-598.89\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3466.77,-602.38 3476.01,-597.2 3465.56,-595.48 3466.77,-602.38\"/>\n",
       "</g>\n",
       "<!-- /outputs/90 -->\n",
       "<g id=\"node72\" class=\"node\">\n",
       "<title>/outputs/90</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3442,-532 3388,-532 3388,-496 3442,-496 3442,-532\"/>\n",
       "<text text-anchor=\"start\" x=\"3407.5\" y=\"-510.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/85&#45;&gt;/outputs/90 -->\n",
       "<g id=\"edge84\" class=\"edge\">\n",
       "<title>/outputs/85&#45;&gt;/outputs/90</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3352.4,-544.1C3360.23,-540.27 3368.96,-536.01 3377.32,-531.93\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3378.81,-535.09 3386.26,-527.56 3375.73,-528.8 3378.81,-535.09\"/>\n",
       "</g>\n",
       "<!-- /outputs/86&#45;&gt;/outputs/89 -->\n",
       "<g id=\"edge85\" class=\"edge\">\n",
       "<title>/outputs/86&#45;&gt;/outputs/89</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3352.4,-449C3359.89,-449 3368.18,-449 3376.2,-449\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3376.1,-452.5 3386.1,-449 3376.1,-445.5 3376.1,-452.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/87&#45;&gt;/outputs/90 -->\n",
       "<g id=\"edge86\" class=\"edge\">\n",
       "<title>/outputs/87&#45;&gt;/outputs/90</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3352.4,-506.3C3359.89,-507.24 3368.18,-508.27 3376.2,-509.27\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3375.76,-512.75 3386.11,-510.51 3376.63,-505.8 3375.76,-512.75\"/>\n",
       "</g>\n",
       "<!-- /outputs/93 -->\n",
       "<g id=\"node75\" class=\"node\">\n",
       "<title>/outputs/93</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3712,-559 3658,-559 3658,-523 3712,-523 3712,-559\"/>\n",
       "<text text-anchor=\"start\" x=\"3677.5\" y=\"-537.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- /outputs/88&#45;&gt;/outputs/93 -->\n",
       "<g id=\"edge87\" class=\"edge\">\n",
       "<title>/outputs/88&#45;&gt;/outputs/93</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3532.26,-583.62C3562.5,-575.13 3612.39,-561.11 3646.66,-551.49\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3647.49,-554.89 3656.17,-548.82 3645.6,-548.15 3647.49,-554.89\"/>\n",
       "</g>\n",
       "<!-- /outputs/91 -->\n",
       "<g id=\"node73\" class=\"node\">\n",
       "<title>/outputs/91</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3532,-532 3478,-532 3478,-496 3532,-496 3532,-532\"/>\n",
       "<text text-anchor=\"start\" x=\"3496.75\" y=\"-510.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Add</text>\n",
       "</g>\n",
       "<!-- /outputs/89&#45;&gt;/outputs/91 -->\n",
       "<g id=\"edge88\" class=\"edge\">\n",
       "<title>/outputs/89&#45;&gt;/outputs/91</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3440.98,-467.45C3449.99,-474.11 3460.32,-481.74 3469.97,-488.87\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3467.62,-491.48 3477.74,-494.6 3471.77,-485.85 3467.62,-491.48\"/>\n",
       "</g>\n",
       "<!-- /outputs/90&#45;&gt;/outputs/91 -->\n",
       "<g id=\"edge89\" class=\"edge\">\n",
       "<title>/outputs/90&#45;&gt;/outputs/91</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3442.4,-514C3449.89,-514 3458.18,-514 3466.2,-514\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3466.1,-517.5 3476.1,-514 3466.1,-510.5 3466.1,-517.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/92 -->\n",
       "<g id=\"node74\" class=\"node\">\n",
       "<title>/outputs/92</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3622,-536 3568,-536 3568,-500 3622,-500 3622,-536\"/>\n",
       "<text text-anchor=\"start\" x=\"3584.12\" y=\"-514.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Tanh</text>\n",
       "</g>\n",
       "<!-- /outputs/91&#45;&gt;/outputs/92 -->\n",
       "<g id=\"edge90\" class=\"edge\">\n",
       "<title>/outputs/91&#45;&gt;/outputs/92</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3532.4,-515.2C3539.89,-515.54 3548.18,-515.92 3556.2,-516.28\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3555.96,-519.77 3566.1,-516.73 3556.27,-512.78 3555.96,-519.77\"/>\n",
       "</g>\n",
       "<!-- /outputs/92&#45;&gt;/outputs/93 -->\n",
       "<g id=\"edge91\" class=\"edge\">\n",
       "<title>/outputs/92&#45;&gt;/outputs/93</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3622.4,-524.9C3629.97,-526.88 3638.38,-529.08 3646.48,-531.19\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3645.59,-534.58 3656.15,-533.72 3647.36,-527.81 3645.59,-534.58\"/>\n",
       "</g>\n",
       "<!-- /outputs/94 -->\n",
       "<g id=\"node76\" class=\"node\">\n",
       "<title>/outputs/94</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"3806.75,-559 3748,-559 3748,-523 3806.75,-523 3806.75,-559\"/>\n",
       "<text text-anchor=\"start\" x=\"3756\" y=\"-537.5\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">LeakyRelu</text>\n",
       "</g>\n",
       "<!-- /outputs/93&#45;&gt;/outputs/94 -->\n",
       "<g id=\"edge92\" class=\"edge\">\n",
       "<title>/outputs/93&#45;&gt;/outputs/94</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M3712.14,-541C3719.72,-541 3728.18,-541 3736.41,-541\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3736.25,-544.5 3746.25,-541 3736.25,-537.5 3736.25,-544.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1dfb800ea80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import hiddenlayer as hl\n",
    "import torchvision\n",
    "import torch\n",
    "from torchview import draw_graph\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz-11.0.0-win64/bin/'\n",
    "\n",
    "# AlexNet\n",
    "model = torchvision.models.alexnet()\n",
    "\n",
    "# Build HiddenLayer graph\n",
    "hl_graph = hl.build_graph(SimpleRNN(), torch.zeros([2, 3])).build_dot()\n",
    "\n",
    "# Use a different color theme\n",
    "hl_graph.theme = hl.graph.THEMES[\"blue\"].copy()  # Two options: basic and blue\n",
    "hl_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b2c3db97-262c-4acc-9bf5-13fd83eade44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
