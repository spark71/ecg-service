{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from app.ecg.ecg import Datasets, EcgSignal\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "ptbxl_data = pd.read_csv(r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\labels.csv', index_col=0)\n",
    "# ptbxl_statements = pd.read_csv(Datasets.ptbxl_scp_statements.path, index_col=0)\n",
    "# ptbxl_data['patient_id'] = ptbxl_data['patient_id'].astype(int)\n",
    "# ptbxl_data['nurse'] = ptbxl_data['nurse'].astype('Int64')\n",
    "# ptbxl_data['site'] = ptbxl_data['site'].astype('Int64')\n",
    "# ptbxl_data['validated_by'] = ptbxl_data['validated_by'].astype('Int64')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-07T18:21:13.855229Z"
    }
   },
   "id": "2a8ec33fd3b09926",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ptbxl_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mptbxl_data\u001B[49m\u001B[38;5;241m.\u001B[39minfo()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ptbxl_data' is not defined"
     ]
    }
   ],
   "source": [
    "ptbxl_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:24.796121Z",
     "start_time": "2024-05-05T10:02:24.415908Z"
    }
   },
   "id": "79b12c273058880e",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def get_file_paths(filename):\n",
    "    filename_lr = filename.split('/')[-1].split('_')[0]\n",
    "    return fr\"C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\{filename_lr}.npy\"\n",
    "\n",
    "clean_tags = lambda x: [e.replace(\"'\", \"\")  for e in x[1:-1].split(', ')]\n",
    "ptbxl_data[\"file_paths\"] = ptbxl_data[\"filename_lr\"].apply(get_file_paths)\n",
    "ptbxl_data[\"superdiagnostic\"] = ptbxl_data[\"superdiagnostic\"].apply(clean_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:33.162618Z",
     "start_time": "2024-05-05T10:02:32.992583Z"
    }
   },
   "id": "4461ee8d19ddae25",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "              age  sex  height  weight  nurse  site      device  \\\npatient_id                                                        \n15709.0      56.0    1     NaN    63.0    2.0   0.0   CS-12   E   \n13243.0      19.0    0     NaN    70.0    2.0   0.0   CS-12   E   \n20372.0      37.0    1     NaN    69.0    2.0   0.0   CS-12   E   \n17014.0      24.0    0     NaN    82.0    2.0   0.0   CS-12   E   \n17448.0      19.0    1     NaN    70.0    2.0   0.0   CS-12   E   \n...           ...  ...     ...     ...    ...   ...         ...   \n17180.0      67.0    1     NaN     NaN    1.0   2.0  AT-60    3   \n20703.0     300.0    0     NaN     NaN    1.0   2.0  AT-60    3   \n19311.0      59.0    1     NaN     NaN    1.0   2.0  AT-60    3   \n8873.0       64.0    1     NaN     NaN    1.0   2.0  AT-60    3   \n11744.0      68.0    0     NaN     NaN    1.0   2.0  AT-60    3   \n\n                 recording_date  \\\npatient_id                        \n15709.0     1984-11-09 09:17:34   \n13243.0     1984-11-14 12:55:37   \n20372.0     1984-11-15 12:49:10   \n17014.0     1984-11-15 13:44:57   \n17448.0     1984-11-17 10:43:15   \n...                         ...   \n17180.0     2001-05-31 09:14:35   \n20703.0     2001-06-05 11:33:39   \n19311.0     2001-06-08 10:30:27   \n8873.0      2001-06-09 18:21:49   \n11744.0     2001-06-11 16:43:01   \n\n                                                                                                                                                                                                                                               report  \\\npatient_id                                                                                                                                                                                                                                              \n15709.0                                                                                                                                                                                                        sinusrhythmus periphere niederspannung   \n13243.0                                                                                                                                                                                                           sinusbradykardie sonst normales ekg   \n20372.0                                                                                                                                                                                                                    sinusrhythmus normales ekg   \n17014.0                                                                                                                                                                                                                    sinusrhythmus normales ekg   \n17448.0                                                                                                                                                                                                                    sinusrhythmus normales ekg   \n...                                                                                                                                                                                                                                               ...   \n17180.0     ventrikulÄre extrasystole(n) sinustachykardie linkstyp mÄssige amplitudenkriterien fÜr linkshypertrophie st & t abnorm, wahrscheinlich    anterolaterale ischÄmie oder linksbelastung 4.46                          unbestÄtigter bericht   \n20703.0                                                                                                   sinusrhythmus lagetyp normal qrs(t) abnorm    inferiorer infarkt     wahrscheinlich alt 4.46                          unbestÄtigter bericht   \n19311.0                                                                                                   sinusrhythmus lagetyp normal t abnorm in anterioren ableitungen 4.46                          unbestÄtigter bericht Edit: INJAS 50, (ISCAS)   \n8873.0                                                                                             supraventrikulÄre extrasystole(n) sinusrhythmus linkstyp t abnorm in hochlateralen ableitungen 4.46                          unbestÄtigter bericht   \n11744.0                                                                                                                                           sinusrhythmus p-sinistrocardiale lagetyp normal 4.46                          unbestÄtigter bericht   \n\n                                                           scp_codes  ...  \\\npatient_id                                                            ...   \n15709.0                     {'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}  ...   \n13243.0                                 {'NORM': 80.0, 'SBRAD': 0.0}  ...   \n20372.0                                   {'NORM': 100.0, 'SR': 0.0}  ...   \n17014.0                                   {'NORM': 100.0, 'SR': 0.0}  ...   \n17448.0                                   {'NORM': 100.0, 'SR': 0.0}  ...   \n...                                                              ...  ...   \n17180.0     {'NDT': 100.0, 'PVC': 100.0, 'VCLVH': 0.0, 'STACH': 0.0}  ...   \n20703.0                     {'NORM': 100.0, 'ABQRS': 0.0, 'SR': 0.0}  ...   \n19311.0                                   {'ISCAS': 50.0, 'SR': 0.0}  ...   \n8873.0                                    {'NORM': 100.0, 'SR': 0.0}  ...   \n11744.0                                   {'NORM': 100.0, 'SR': 0.0}  ...   \n\n           electrodes_problems extra_beats pacemaker  strat_fold  \\\npatient_id                                                         \n15709.0                    NaN         NaN       NaN           3   \n13243.0                    NaN         NaN       NaN           2   \n20372.0                    NaN         NaN       NaN           5   \n17014.0                    NaN         NaN       NaN           3   \n17448.0                    NaN         NaN       NaN           4   \n...                        ...         ...       ...         ...   \n17180.0                    NaN         1ES       NaN           7   \n20703.0                    NaN         NaN       NaN           4   \n19311.0                    NaN         NaN       NaN           2   \n8873.0                     NaN        SVES       NaN           8   \n11744.0                    NaN         NaN       NaN           9   \n\n                          filename_lr                filename_hr  \\\npatient_id                                                         \n15709.0     records100/00000/00001_lr  records500/00000/00001_hr   \n13243.0     records100/00000/00002_lr  records500/00000/00002_hr   \n20372.0     records100/00000/00003_lr  records500/00000/00003_hr   \n17014.0     records100/00000/00004_lr  records500/00000/00004_hr   \n17448.0     records100/00000/00005_lr  records500/00000/00005_hr   \n...                               ...                        ...   \n17180.0     records100/21000/21833_lr  records500/21000/21833_hr   \n20703.0     records100/21000/21834_lr  records500/21000/21834_hr   \n19311.0     records100/21000/21835_lr  records500/21000/21835_hr   \n8873.0      records100/21000/21836_lr  records500/21000/21836_hr   \n11744.0     records100/21000/21837_lr  records500/21000/21837_hr   \n\n            scp_codes_len superdiagnostic superdiagnostic_len  \\\npatient_id                                                      \n15709.0                 3          [NORM]                   1   \n13243.0                 2          [NORM]                   1   \n20372.0                 2          [NORM]                   1   \n17014.0                 2          [NORM]                   1   \n17448.0                 2          [NORM]                   1   \n...                   ...             ...                 ...   \n17180.0                 4          [STTC]                   1   \n20703.0                 3          [NORM]                   1   \n19311.0                 2          [STTC]                   1   \n8873.0                  2          [NORM]                   1   \n11744.0                 2          [NORM]                   1   \n\n                                                                                 file_paths  \npatient_id                                                                                   \n15709.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00001.npy  \n13243.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00002.npy  \n20372.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00003.npy  \n17014.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00004.npy  \n17448.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00005.npy  \n...                                                                                     ...  \n17180.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21833.npy  \n20703.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21834.npy  \n19311.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21835.npy  \n8873.0      C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21836.npy  \n11744.0     C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21837.npy  \n\n[21388 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>nurse</th>\n      <th>site</th>\n      <th>device</th>\n      <th>recording_date</th>\n      <th>report</th>\n      <th>scp_codes</th>\n      <th>...</th>\n      <th>electrodes_problems</th>\n      <th>extra_beats</th>\n      <th>pacemaker</th>\n      <th>strat_fold</th>\n      <th>filename_lr</th>\n      <th>filename_hr</th>\n      <th>scp_codes_len</th>\n      <th>superdiagnostic</th>\n      <th>superdiagnostic_len</th>\n      <th>file_paths</th>\n    </tr>\n    <tr>\n      <th>patient_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15709.0</th>\n      <td>56.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>63.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>CS-12   E</td>\n      <td>1984-11-09 09:17:34</td>\n      <td>sinusrhythmus periphere niederspannung</td>\n      <td>{'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>records100/00000/00001_lr</td>\n      <td>records500/00000/00001_hr</td>\n      <td>3</td>\n      <td>[NORM]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00001.npy</td>\n    </tr>\n    <tr>\n      <th>13243.0</th>\n      <td>19.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>70.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>CS-12   E</td>\n      <td>1984-11-14 12:55:37</td>\n      <td>sinusbradykardie sonst normales ekg</td>\n      <td>{'NORM': 80.0, 'SBRAD': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>records100/00000/00002_lr</td>\n      <td>records500/00000/00002_hr</td>\n      <td>2</td>\n      <td>[NORM]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00002.npy</td>\n    </tr>\n    <tr>\n      <th>20372.0</th>\n      <td>37.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>69.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>CS-12   E</td>\n      <td>1984-11-15 12:49:10</td>\n      <td>sinusrhythmus normales ekg</td>\n      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>records100/00000/00003_lr</td>\n      <td>records500/00000/00003_hr</td>\n      <td>2</td>\n      <td>[NORM]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00003.npy</td>\n    </tr>\n    <tr>\n      <th>17014.0</th>\n      <td>24.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>82.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>CS-12   E</td>\n      <td>1984-11-15 13:44:57</td>\n      <td>sinusrhythmus normales ekg</td>\n      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>records100/00000/00004_lr</td>\n      <td>records500/00000/00004_hr</td>\n      <td>2</td>\n      <td>[NORM]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00004.npy</td>\n    </tr>\n    <tr>\n      <th>17448.0</th>\n      <td>19.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>70.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>CS-12   E</td>\n      <td>1984-11-17 10:43:15</td>\n      <td>sinusrhythmus normales ekg</td>\n      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>records100/00000/00005_lr</td>\n      <td>records500/00000/00005_hr</td>\n      <td>2</td>\n      <td>[NORM]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\00005.npy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17180.0</th>\n      <td>67.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>AT-60    3</td>\n      <td>2001-05-31 09:14:35</td>\n      <td>ventrikulÄre extrasystole(n) sinustachykardie linkstyp mÄssige amplitudenkriterien fÜr linkshypertrophie st &amp; t abnorm, wahrscheinlich    anterolaterale ischÄmie oder linksbelastung 4.46                          unbestÄtigter bericht</td>\n      <td>{'NDT': 100.0, 'PVC': 100.0, 'VCLVH': 0.0, 'STACH': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1ES</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>records100/21000/21833_lr</td>\n      <td>records500/21000/21833_hr</td>\n      <td>4</td>\n      <td>[STTC]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21833.npy</td>\n    </tr>\n    <tr>\n      <th>20703.0</th>\n      <td>300.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>AT-60    3</td>\n      <td>2001-06-05 11:33:39</td>\n      <td>sinusrhythmus lagetyp normal qrs(t) abnorm    inferiorer infarkt     wahrscheinlich alt 4.46                          unbestÄtigter bericht</td>\n      <td>{'NORM': 100.0, 'ABQRS': 0.0, 'SR': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>records100/21000/21834_lr</td>\n      <td>records500/21000/21834_hr</td>\n      <td>3</td>\n      <td>[NORM]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21834.npy</td>\n    </tr>\n    <tr>\n      <th>19311.0</th>\n      <td>59.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>AT-60    3</td>\n      <td>2001-06-08 10:30:27</td>\n      <td>sinusrhythmus lagetyp normal t abnorm in anterioren ableitungen 4.46                          unbestÄtigter bericht Edit: INJAS 50, (ISCAS)</td>\n      <td>{'ISCAS': 50.0, 'SR': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>records100/21000/21835_lr</td>\n      <td>records500/21000/21835_hr</td>\n      <td>2</td>\n      <td>[STTC]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21835.npy</td>\n    </tr>\n    <tr>\n      <th>8873.0</th>\n      <td>64.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>AT-60    3</td>\n      <td>2001-06-09 18:21:49</td>\n      <td>supraventrikulÄre extrasystole(n) sinusrhythmus linkstyp t abnorm in hochlateralen ableitungen 4.46                          unbestÄtigter bericht</td>\n      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>SVES</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>records100/21000/21836_lr</td>\n      <td>records500/21000/21836_hr</td>\n      <td>2</td>\n      <td>[NORM]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21836.npy</td>\n    </tr>\n    <tr>\n      <th>11744.0</th>\n      <td>68.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>AT-60    3</td>\n      <td>2001-06-11 16:43:01</td>\n      <td>sinusrhythmus p-sinistrocardiale lagetyp normal 4.46                          unbestÄtigter bericht</td>\n      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>records100/21000/21837_lr</td>\n      <td>records500/21000/21837_hr</td>\n      <td>2</td>\n      <td>[NORM]</td>\n      <td>1</td>\n      <td>C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\npy_signals100\\21837.npy</td>\n    </tr>\n  </tbody>\n</table>\n<p>21388 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptbxl_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T10:14:38.419951Z",
     "start_time": "2024-05-03T10:14:38.376211Z"
    }
   },
   "id": "e073cf86be1dd6c1",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f62b50150dc67d5e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['CD', 'HYP', 'MI', 'NORM', 'STTC']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(ptbxl_data[\"superdiagnostic\"].values)\n",
    "mlb.classes_.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:33.218017Z",
     "start_time": "2024-05-05T10:02:33.210194Z"
    }
   },
   "id": "7b1f96a43fa64a21",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_labels = mlb.transform(ptbxl_data[\"superdiagnostic\"].tolist())\n",
    "ptbxl_data[mlb.classes_.tolist()] = train_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:34.684948Z",
     "start_time": "2024-05-05T10:02:34.666422Z"
    }
   },
   "id": "643096eccfee0d20",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ECGNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd1fb054fea5c0d7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ecg_idx = pd.read_csv(r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\data\\ptbxl\\ptbxl_database.csv')\n",
    "ptbxl_data['ecg_id']=ecg_idx['ecg_id']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90f987bf45fa2937",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQT kernels created, time used = 0.0602 seconds\n",
      "CQT kernels created, time used = 0.0081 seconds\n",
      "CQT kernels created, time used = 0.0084 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\redmi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\nnAudio\\utils.py:429: SyntaxWarning: If fmax is given, n_bins will be ignored\n",
      "  warnings.warn(\"If fmax is given, n_bins will be ignored\", SyntaxWarning)\n",
      "C:\\Users\\redmi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\nnAudio\\utils.py:429: SyntaxWarning: If fmax is given, n_bins will be ignored\n",
      "  warnings.warn(\"If fmax is given, n_bins will be ignored\", SyntaxWarning)\n",
      "C:\\Users\\redmi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ecg-service-WR4KS9pF-py3.12\\Lib\\site-packages\\nnAudio\\utils.py:429: SyntaxWarning: If fmax is given, n_bins will be ignored\n",
      "  warnings.warn(\"If fmax is given, n_bins will be ignored\", SyntaxWarning)\n"
     ]
    }
   ],
   "source": [
    "from app.ecg.ecg import EcgDataset\n",
    "\n",
    "valid_df = ptbxl_data[ptbxl_data['strat_fold'] == 9]\n",
    "test_df = ptbxl_data[ptbxl_data['strat_fold'] == 10]\n",
    "\n",
    "dataset = EcgDataset(ptbxl_data)\n",
    "valid_dataset = EcgDataset(valid_df)\n",
    "test_dataset = EcgDataset(test_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:39.842853Z",
     "start_time": "2024-05-05T10:02:39.753475Z"
    }
   },
   "id": "fd773df0ca24acfc",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from models.ecgnet import ECGNet\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "model = ECGNet()\n",
    "model = model.double()\n",
    "model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\ecgnet_weights_authors.pt'\n",
    "model.load_state_dict(torch.load(model_weights_path, map_location=torch.device('cpu')))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd0df29906ae7f07",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ecg, label = valid_dataset[151]\n",
    "label"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17e122cee8a95095",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prediction = model(ecg)\n",
    "prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72cee354f34b6668",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "softmaxed_pred = torch.softmax(prediction, dim=1).to(torch.float64)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "188244ab06be9ada",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(softmaxed_pred.detach().numpy(), label.numpy().astype(int))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dc03e5d6448a741",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "roc_auc_score(label.numpy().astype(int), prediction.detach().numpy().reshape(-1), average='macro')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e35f022bb3993bc7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "decde7d78034b7b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gt_all = []\n",
    "pred_all = []\n",
    "\n",
    "for id in tqdm(range(len(test_dataset))):\n",
    "    ecg , label = test_dataset[id]\n",
    "    # print(ecg, label)\n",
    "    prediction = model(ecg)\n",
    "    pred_all.append(prediction.detach().numpy())\n",
    "    gt_all.append(label.detach().numpy().astype(int))\n",
    "gt_all_array = np.vstack(gt_all)\n",
    "pred_all_array = np.vstack(pred_all)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd5ea4c22e7352cc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gt_all_array"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddc156ab483e1dfb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "388958f92c5ac114"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from models.metrics import Metrics, metric_summary, AUC, roc_auc_score\n",
    "def evaluate_model(model, loader):\n",
    "    gt_all = []\n",
    "    pred_all = []\n",
    "    for id in tqdm(range(len(loader))):\n",
    "        ecg , label = loader[id]\n",
    "        # print(ecg, label)\n",
    "        prediction = model(ecg)\n",
    "        pred_all.append(prediction.detach().numpy())\n",
    "        gt_all.append(label.detach().numpy().astype(int))\n",
    "    gt_all_array = np.vstack(gt_all)\n",
    "    pred_all_array = np.vstack(pred_all)\n",
    "    roc_score = roc_auc_score(gt_all_array, pred_all_array, average=\"macro\")\n",
    "    acc, mean_acc = Metrics(gt_all_array, pred_all_array)\n",
    "    class_auc = AUC(gt_all_array, pred_all_array)\n",
    "    summary = metric_summary(gt_all_array, pred_all_array)\n",
    "    print(f\"class wise accuracy: {acc}\")\n",
    "    print(f\"accuracy: {mean_acc}\")\n",
    "    print(f\"roc_score : {roc_score}\")\n",
    "    print(f\"class wise AUC : {class_auc}\")\n",
    "    print(f\"F1 score (Max): {summary[0]}\")\n",
    "    print(f\"class wise precision, recall, f1 score : {summary}\")\n",
    "    return gt_all_array, pred_all_array\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:02:49.906375Z",
     "start_time": "2024-05-05T10:02:49.887567Z"
    }
   },
   "id": "69fb1ec6d2fc8767",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "39e43fe271d7d9e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e2ebcdb2582caf93"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6152ee2fbb3df21d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "508f5172eb2500c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c6932d76c1837e46"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "81f6bcc6d4da46c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EcgNet scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c59b4c57d529a01"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Metrics(gt_all_array, pred_all_array)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c04d97fda4adcffa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"ecgNet(ptbxlv1.0.2) - test - aurroc- macro: \", roc_auc_score(gt_all_array, pred_all_array))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fea31f2557d4ef3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "roc_score = roc_auc_score(gt_all_array, pred_all_array, average=\"macro\")\n",
    "acc, mean_acc = Metrics(gt_all_array, pred_all_array)\n",
    "class_auc = AUC(gt_all_array, pred_all_array)\n",
    "summary = metric_summary(gt_all_array, pred_all_array)\n",
    "\n",
    "print(f\"class wise accuracy: {acc}\")\n",
    "print(f\"accuracy: {mean_acc}\")\n",
    "print(f\"roc_score : {roc_score}\")\n",
    "print(f\"class wise AUC : {class_auc}\")\n",
    "print(f\"F1 score (Max): {summary[0]}\")\n",
    "print(f\"class wise precision, recall, f1 score : {summary}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65c4559048a28a77",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_all_array"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "705e3a5f3d881f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_all_array.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cd9010427bbacdd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "16c92ca294fc5c39"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "43dab90f685d0d81"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"ecgNet - valid - aurroc- macro: \", roc_auc_score(np.vstack(gt_all), np.vstack(pred_all)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76120faf77a5dae6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7a5ceeb02518f7b3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "68585738728bba96"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c097057d1a10e485"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet50 CQT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2909445cc75fc42a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "CustomModel(\n  (model): EfficientNet(\n    (conv_stem): Conv2dSame(1, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn1): BatchNormAct2d(\n      24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n    )\n    (blocks): Sequential(\n      (0): Sequential(\n        (0): ConvBnAct(\n          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (drop_path): Identity()\n        )\n        (1): ConvBnAct(\n          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (drop_path): Identity()\n        )\n      )\n      (1): Sequential(\n        (0): EdgeResidual(\n          (conv_exp): Conv2dSame(24, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n          (bn1): BatchNormAct2d(\n            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): EdgeResidual(\n          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): EdgeResidual(\n          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): EdgeResidual(\n          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (2): Sequential(\n        (0): EdgeResidual(\n          (conv_exp): Conv2dSame(48, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n          (bn1): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): EdgeResidual(\n          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): EdgeResidual(\n          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): EdgeResidual(\n          (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (3): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n          (bn2): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n          (bn2): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n          (bn2): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n          (bn2): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n          (bn2): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (5): InvertedResidual(\n          (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n          (bn2): BatchNormAct2d(\n            512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (4): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (bn2): BatchNormAct2d(\n            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (bn2): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (bn2): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (bn2): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (bn2): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (5): InvertedResidual(\n          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (bn2): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (6): InvertedResidual(\n          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (bn2): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (7): InvertedResidual(\n          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (bn2): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (8): InvertedResidual(\n          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (bn2): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (5): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2dSame(960, 960, kernel_size=(3, 3), stride=(2, 2), groups=960, bias=False)\n          (bn2): BatchNormAct2d(\n            960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (5): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (6): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (7): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (8): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (9): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (10): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (11): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (12): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (13): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (14): InvertedResidual(\n          (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n          (bn2): BatchNormAct2d(\n            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n    )\n    (conv_head): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn2): BatchNormAct2d(\n      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n    )\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (classifier): Linear(in_features=1280, out_features=5, bias=True)\n  )\n)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.nn.custom_model_cqt import CustomModel\n",
    "from models.config import CqtCFG\n",
    "import torch\n",
    "\n",
    "model_resnet50cqt = CustomModel(CqtCFG)\n",
    "# model = model.double()\n",
    "model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\resnet50\\resnet50d_fold9_best_score.pth'\n",
    "model_resnet50cqt.load_state_dict(torch.load(model_weights_path, map_location=torch.device('cpu')), strict=False)\n",
    "model_resnet50cqt.eval()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T17:40:21.032667Z",
     "start_time": "2024-05-02T17:40:20.717701Z"
    }
   },
   "id": "8524b9ff0e471477",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "valid_dataset = EcgDataset(valid_df, feature='cqt')\n",
    "test_dataset = EcgDataset(test_df, feature='cqt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e583f00aee24c0a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cqt_im, label = valid_dataset[0]\n",
    "# cqt_im = cqt_im[None, None, :]\n",
    "cqt_im.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82afc5f7af082c58",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_resnet50cqt(cqt_im)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b7d7ebee8990579",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2146/2146 [03:19<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.7688723205964585, 0.874650512581547, 0.7483690587138863, 0.554520037278658, 0.7539608574091333]\n",
      "accuracy: 0.7400745573159366\n",
      "roc_score : 0.48158220540497876\n",
      "class wise AUC : [0.4902048957167067, 0.6007075246769349, 0.410993496609935, 0.431645280265165, 0.4743598297561523]\n",
      "F1 score (Max): 0.39902638981000393\n",
      "class wise precision, recall, f1 score : (0.39902638981000393, 0.48158220540497876, [0.39902638981000393, nan, nan, nan, nan, nan, nan, nan, nan, nan], [0.2630475302889096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8260329294812053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\metrics.py:145: RuntimeWarning: invalid value encountered in divide\n",
      "  2\n"
     ]
    }
   ],
   "source": [
    "gt_v, labels_v = evaluate_model(model_resnet50cqt, valid_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T17:44:08.154112Z",
     "start_time": "2024-05-02T17:40:48.236478Z"
    }
   },
   "id": "3c82b736339110cf",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [03:06<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.7701575532900834, 0.8785912882298424, 0.7451343836886005, 0.5537534754402225, 0.7585727525486562]\n",
      "accuracy: 0.7412418906394811\n",
      "roc_score : 0.4783042559310203\n",
      "class wise AUC : [0.4759435289779123, 0.5896564080265404, 0.4259294436906377, 0.42449719104784994, 0.4754947079121608]\n",
      "F1 score (Max): 0.3997443915639605\n",
      "class wise precision, recall, f1 score : (0.3997443915639605, 0.4783042559310203, [0.3997443915639605, nan, nan, nan, nan, nan, nan, nan, nan, nan], [0.26309082483781276, nan, nan, nan, nan, nan, nan, nan, nan, nan], [0.8317886932344764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    }
   ],
   "source": [
    "gt_t, labels_t = evaluate_model(model_resnet50cqt, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T17:47:15.006619Z",
     "start_time": "2024-05-02T17:44:08.155180Z"
    }
   },
   "id": "74b087034a7a72e6",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "2146"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T17:29:52.588365Z",
     "start_time": "2024-05-02T17:29:52.584387Z"
    }
   },
   "id": "60d5a23779511978",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6fee1bc7e81045f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e37e156c06f6094"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from models.nn.xresnet1d import xresnet1d101\n",
    "from models.nn.inception1d import inception1d\n",
    "from models.nn.resnet1d import resnet1d_wang\n",
    "from models.nn.rnn1d import RNN1d\n",
    "\n",
    "def model_factory(model_name):\n",
    "    model = None\n",
    "    if model_name.lower()=='xresnet1d101':\n",
    "        model = xresnet1d101(input_channels=12, num_classes=5)\n",
    "\n",
    "    if model_name.lower()=='resnet1d_dwang':\n",
    "        model = resnet1d_wang(input_channels=12, num_classes=5)\n",
    "\n",
    "    if model_name.lower()=='inception1d_model':\n",
    "        model = inception1d(input_channels=12, num_classes=5)\n",
    "\n",
    "    if model_name.lower()=='rnn_1d':\n",
    "        model = RNN1d(input_channels=12, num_classes=5)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3484bd88496cb4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Xresnet1d"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5020b92e61353f77"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "XResNet1d(\n  (0): ConvLayer(\n    (0): Conv1d(12, 32, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (1): ConvLayer(\n    (0): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (2): ConvLayer(\n    (0): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (3): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act): ReLU(inplace=True)\n    )\n    (1): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (2): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n  )\n  (5): Sequential(\n    (0): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential(\n        (0): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n      )\n      (act): ReLU(inplace=True)\n    )\n    (1): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (2): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (3): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n  )\n  (6): Sequential(\n    (0): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential(\n        (0): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n      )\n      (act): ReLU(inplace=True)\n    )\n    (1): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (2): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (3): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (4): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (5): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (6): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (7): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (8): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (9): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (10): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (11): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (12): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (13): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (14): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (15): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (16): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (17): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (18): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (19): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (20): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (21): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (22): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n  )\n  (7): Sequential(\n    (0): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential(\n        (0): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n      )\n      (act): ReLU(inplace=True)\n    )\n    (1): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n    (2): ResBlock(\n      (convs): Sequential(\n        (0): ConvLayer(\n          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (1): ConvLayer(\n          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n        )\n        (2): ConvLayer(\n          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (convpath): Sequential(\n        (0): Sequential(\n          (0): ConvLayer(\n            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (1): ConvLayer(\n            (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n          )\n          (2): ConvLayer(\n            (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (idpath): Sequential()\n      (act): ReLU(inplace=True)\n    )\n  )\n  (8): Sequential(\n    (0): AdaptiveConcatPool1d(\n      (ap): AdaptiveAvgPool1d(output_size=1)\n      (mp): AdaptiveMaxPool1d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=512, out_features=5, bias=False)\n  )\n)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.nn.xresnet1d import xresnet1d101\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "xresnet1d_model = xresnet1d101(input_channels=12, num_classes=5)\n",
    "xresnet1d_model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\xresnet1d101\\exp0_xresnet1d101xresnet1d101_fold1_19epoch_best_score.pth'\n",
    "xresnet1d_model.load_state_dict(torch.load(xresnet1d_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "xresnet1d_model.double()\n",
    "xresnet1d_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T11:03:27.002826Z",
     "start_time": "2024-05-04T11:03:26.799545Z"
    }
   },
   "id": "259e254f991b3dc4",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('0.0.weight',\n              tensor([[[ 1.8142e-01,  7.3431e-02,  5.3870e-02,  3.5905e-01,  1.3066e-01],\n                       [ 1.8385e-01, -1.3094e-02,  2.9767e-01, -2.4098e-01, -1.8627e-01],\n                       [ 1.3199e-01,  4.4830e-02,  2.1216e-01,  5.5411e-02, -4.7518e-01],\n                       ...,\n                       [-3.0620e-02, -8.0225e-02,  2.6821e-01, -1.3437e-01,  1.1454e-01],\n                       [ 1.2754e-01, -1.2078e-01, -3.6862e-02,  1.4472e-02,  3.2900e-01],\n                       [ 5.1923e-02, -1.9296e-01,  1.9608e-01,  1.5318e-01, -2.3305e-01]],\n              \n                      [[ 1.5843e-01,  8.3384e-02,  5.8071e-02, -2.7533e-01, -2.3064e-02],\n                       [-7.6667e-02,  1.5067e-01,  2.9896e-02,  4.8615e-02,  1.1374e-01],\n                       [ 1.0984e-01, -2.0519e-01, -3.3914e-01, -2.2472e-01, -1.9918e-01],\n                       ...,\n                       [-1.0513e-01, -1.6065e-01,  3.6400e-01,  2.0428e-02, -3.3001e-01],\n                       [ 1.1119e-01,  1.2087e-01,  5.8882e-02,  5.5821e-02, -5.4590e-02],\n                       [-3.4875e-01, -2.6626e-01, -1.7945e-01,  5.2568e-02,  9.2048e-02]],\n              \n                      [[ 6.7100e-02, -8.9009e-02,  1.1362e-02, -6.5221e-02,  1.4460e-02],\n                       [ 1.9144e-02,  2.3788e-01,  2.7005e-01, -1.4637e-02, -3.3012e-01],\n                       [-8.5369e-02, -1.1732e-01, -6.2112e-02,  3.1848e-01, -1.6402e-02],\n                       ...,\n                       [ 1.5230e-01, -2.4053e-01, -5.9737e-02, -2.0545e-01, -2.1431e-01],\n                       [-1.3712e-01,  2.2459e-01, -2.3323e-01,  1.0478e-01,  2.4299e-01],\n                       [ 2.9252e-02, -1.9998e-01, -1.1249e-02, -1.3829e-01, -2.0762e-01]],\n              \n                      ...,\n              \n                      [[-1.1088e-01,  1.1797e-01, -1.9388e-01, -1.0595e-01,  4.5392e-02],\n                       [ 6.1369e-02, -2.2131e-01,  4.4713e-01, -8.4693e-02, -1.4848e-02],\n                       [-1.6866e-01, -1.4169e-01, -4.8375e-04, -1.9565e-01,  2.5288e-01],\n                       ...,\n                       [-4.7099e-02, -1.3080e-01, -2.2034e-02,  1.3363e-01, -6.2930e-02],\n                       [-2.3401e-01, -1.5473e-01, -4.2944e-01, -1.0522e-01,  1.1997e-01],\n                       [-2.7166e-02, -8.8035e-02, -2.4874e-01,  2.6091e-02,  2.3113e-01]],\n              \n                      [[ 1.7078e-01, -1.6780e-01, -2.8516e-01,  1.4793e-01, -5.6160e-02],\n                       [ 2.4429e-01,  1.0378e-01,  2.6631e-01, -1.5251e-01,  3.9580e-02],\n                       [-1.7805e-02, -6.2298e-01,  1.2660e-01,  1.3032e-01,  1.8159e-01],\n                       ...,\n                       [-1.4208e-01, -1.0314e-01, -4.1072e-02, -6.3404e-03,  2.5427e-01],\n                       [ 9.3824e-03,  9.6014e-02,  1.9215e-01,  2.3597e-01,  1.4155e-01],\n                       [ 2.4701e-02, -1.6221e-01,  2.3640e-01,  2.7928e-01,  2.5473e-01]],\n              \n                      [[-2.2399e-01, -9.9106e-02,  5.2873e-02, -3.5546e-03, -4.3621e-02],\n                       [-1.6182e-01, -1.0037e-01,  6.1368e-02, -4.3329e-02, -4.7866e-02],\n                       [-4.1003e-01,  8.9400e-02,  4.5471e-02,  2.4312e-01, -7.7074e-02],\n                       ...,\n                       [-1.5430e-01, -1.2417e-01, -2.0403e-01, -1.2153e-01,  1.7421e-01],\n                       [-4.0174e-02, -3.6258e-02,  7.3798e-03, -9.7204e-02,  2.9192e-01],\n                       [-1.8855e-01, -1.6982e-02, -8.4379e-02,  1.5244e-01, -9.8980e-02]]],\n                     dtype=torch.float64)),\n             ('0.1.weight',\n              tensor([1.0256, 0.9981, 0.9940, 0.9749, 0.9827, 1.0117, 0.9942, 1.0147, 1.0166,\n                      0.9979, 1.0118, 0.9872, 0.9793, 0.9705, 0.9939, 1.0038, 0.9858, 1.0022,\n                      1.0183, 0.9843, 0.9880, 0.9862, 1.0089, 1.0003, 0.9893, 1.0363, 1.0024,\n                      0.9854, 1.0239, 0.9992, 0.9972, 1.0019], dtype=torch.float64)),\n             ('0.1.bias',\n              tensor([ 0.0285,  0.0121, -0.0014,  0.0013, -0.0237,  0.0207,  0.0100,  0.0021,\n                      -0.0203,  0.0159,  0.0013,  0.0173,  0.0140,  0.0184, -0.0005,  0.0202,\n                       0.0074, -0.0076,  0.0112,  0.0037, -0.0043,  0.0336,  0.0222,  0.0030,\n                      -0.0003,  0.0266, -0.0235,  0.0164,  0.0245,  0.0219,  0.0060,  0.0115],\n                     dtype=torch.float64)),\n             ('0.1.running_mean',\n              tensor([-0.0020, -0.0012,  0.0003,  0.0028, -0.0014,  0.0034,  0.0019, -0.0017,\n                      -0.0013, -0.0001, -0.0010,  0.0011, -0.0020, -0.0005,  0.0011,  0.0011,\n                       0.0015,  0.0004, -0.0025,  0.0009, -0.0022,  0.0016,  0.0014, -0.0010,\n                      -0.0008,  0.0001, -0.0014, -0.0007,  0.0004, -0.0006, -0.0021,  0.0008],\n                     dtype=torch.float64)),\n             ('0.1.running_var',\n              tensor([0.0549, 0.1067, 0.0656, 0.1858, 0.0870, 0.1217, 0.1490, 0.1063, 0.1662,\n                      0.0764, 0.1530, 0.0821, 0.1092, 0.0615, 0.2373, 0.0720, 0.0685, 0.0588,\n                      0.1434, 0.1179, 0.0939, 0.1489, 0.1569, 0.1877, 0.0950, 0.0653, 0.1692,\n                      0.0899, 0.0625, 0.2387, 0.1246, 0.1326], dtype=torch.float64)),\n             ('0.1.num_batches_tracked', tensor(11419)),\n             ('1.0.weight',\n              tensor([[[ 0.1792,  0.1373,  0.0095,  0.0509, -0.0256],\n                       [ 0.0421,  0.0153, -0.1042, -0.0502, -0.0098],\n                       [ 0.1210,  0.0740,  0.2457, -0.2052,  0.0847],\n                       ...,\n                       [-0.0379,  0.0130, -0.1263,  0.1348,  0.0393],\n                       [-0.0458,  0.0491, -0.1407,  0.0286, -0.0296],\n                       [-0.1918, -0.0042, -0.1062, -0.0770,  0.0754]],\n              \n                      [[-0.1043, -0.1417, -0.0277, -0.0091,  0.1257],\n                       [ 0.0358, -0.0465, -0.0784,  0.1200,  0.0426],\n                       [ 0.0471,  0.0922, -0.2601, -0.0401, -0.0515],\n                       ...,\n                       [-0.0601, -0.0150, -0.1416,  0.0053,  0.1024],\n                       [-0.1586,  0.2321, -0.0355, -0.0391, -0.1704],\n                       [-0.1508, -0.0785, -0.0112,  0.1335,  0.0295]],\n              \n                      [[-0.0562,  0.0343,  0.1193, -0.0672,  0.0690],\n                       [ 0.1489, -0.0309, -0.0731,  0.0197,  0.2458],\n                       [-0.1964,  0.1160, -0.1031, -0.0227,  0.0784],\n                       ...,\n                       [ 0.1470,  0.0772,  0.2638, -0.2208, -0.0906],\n                       [ 0.0061, -0.0813,  0.0386,  0.0161,  0.1246],\n                       [ 0.0870,  0.0623,  0.0862, -0.1021,  0.0363]],\n              \n                      ...,\n              \n                      [[ 0.1294,  0.0225,  0.0272, -0.1567, -0.0197],\n                       [ 0.0371,  0.1694, -0.0371,  0.0981,  0.0748],\n                       [-0.0567,  0.0498,  0.0160,  0.0151, -0.0614],\n                       ...,\n                       [-0.1022,  0.0448, -0.0961, -0.0501, -0.2109],\n                       [ 0.1804,  0.0800,  0.1375, -0.2404,  0.1176],\n                       [ 0.1614,  0.0451,  0.0421, -0.0848,  0.0614]],\n              \n                      [[-0.1594, -0.0312,  0.0459,  0.0538, -0.0574],\n                       [-0.2070,  0.0313, -0.0608, -0.0287,  0.0404],\n                       [-0.1018,  0.0286, -0.0148, -0.1065,  0.1594],\n                       ...,\n                       [ 0.0044, -0.0334,  0.0090, -0.0520, -0.1631],\n                       [-0.0564,  0.0025,  0.0222, -0.0024, -0.0766],\n                       [ 0.0654, -0.0813, -0.0262,  0.0583, -0.2343]],\n              \n                      [[ 0.1262,  0.0851,  0.0017, -0.0492, -0.0588],\n                       [-0.1227, -0.0504,  0.0506,  0.0807,  0.0867],\n                       [ 0.0725, -0.0701, -0.0844, -0.0609,  0.1351],\n                       ...,\n                       [ 0.2385,  0.0894, -0.2984,  0.1184,  0.0278],\n                       [-0.1200, -0.0118,  0.0927, -0.0080, -0.0969],\n                       [ 0.1341, -0.0884, -0.0201,  0.0957, -0.2917]]], dtype=torch.float64)),\n             ('1.1.weight',\n              tensor([0.9957, 1.0116, 0.9813, 1.0151, 0.9812, 1.0149, 0.9986, 1.0037, 0.9824,\n                      1.0101, 1.0039, 0.9914, 1.0077, 0.9961, 1.0063, 0.9838, 1.0047, 1.0239,\n                      0.9858, 0.9830, 0.9852, 0.9916, 1.0080, 1.0127, 1.0048, 0.9993, 0.9997,\n                      1.0087, 0.9992, 0.9928, 1.0004, 1.0175], dtype=torch.float64)),\n             ('1.1.bias',\n              tensor([-4.9479e-03,  1.7407e-02,  5.1747e-03, -9.1318e-03, -1.9549e-02,\n                       2.0546e-03, -8.7642e-03,  9.3265e-03, -1.0278e-02,  5.9583e-04,\n                       2.0592e-02,  1.1175e-02,  3.5771e-03,  8.2693e-03,  3.4966e-02,\n                      -2.6960e-05,  6.0321e-03,  7.3801e-03, -1.8404e-03, -3.1908e-03,\n                       8.2527e-03,  8.9980e-03, -5.0678e-03,  2.4535e-02,  2.3169e-02,\n                       7.0387e-03,  2.8083e-02,  3.4305e-02,  7.7073e-03, -4.0067e-03,\n                      -1.7835e-02, -4.8574e-03], dtype=torch.float64)),\n             ('1.1.running_mean',\n              tensor([ 0.1596, -0.1466,  0.3522,  0.2990,  0.4340, -0.1912,  0.5141,  0.3467,\n                       0.4756,  0.0909,  0.1192, -0.0038, -0.1492,  0.4331,  0.2963, -0.1779,\n                      -0.2143, -0.2880,  0.6299,  0.7319,  0.3780, -0.0898,  0.4724, -0.1841,\n                       0.0842,  0.7220, -0.2232, -0.1767,  0.0151, -0.1095,  0.4916,  0.0749],\n                     dtype=torch.float64)),\n             ('1.1.running_var',\n              tensor([0.5603, 1.2079, 0.4409, 0.9406, 0.8824, 1.0851, 1.7819, 0.8829, 1.2970,\n                      1.3613, 0.7377, 0.7159, 1.1056, 0.9248, 0.9388, 0.4989, 0.7867, 0.6205,\n                      0.5819, 1.5427, 0.9711, 1.5751, 1.2026, 0.8510, 0.8826, 1.2662, 0.7732,\n                      2.3372, 0.7388, 0.7145, 1.5672, 0.8055], dtype=torch.float64)),\n             ('1.1.num_batches_tracked', tensor(11419)),\n             ('2.0.weight',\n              tensor([[[-5.0828e-02, -6.8369e-02, -1.4442e-01, -1.0350e-01,  3.6731e-02],\n                       [ 3.3094e-02, -1.9343e-03,  1.4545e-01, -1.1399e-01, -1.1857e-01],\n                       [-9.4462e-02,  4.0412e-02, -1.0198e-01, -1.6336e-01,  1.0333e-01],\n                       ...,\n                       [ 1.4770e-01,  2.0168e-01,  1.5744e-03,  4.4223e-02,  2.4812e-02],\n                       [ 2.1221e-02,  9.1801e-03, -2.2107e-02,  1.9760e-02, -7.6695e-02],\n                       [-1.0747e-01,  1.0171e-01, -4.4595e-02, -1.8845e-02, -1.1914e-01]],\n              \n                      [[ 2.2586e-01,  2.1935e-02,  1.3503e-01, -1.3698e-01, -1.4498e-01],\n                       [-1.5009e-01, -1.4320e-01, -1.8605e-01, -1.1319e-01,  2.3845e-01],\n                       [-1.5216e-01,  2.7589e-02,  9.1368e-02, -5.0800e-03,  5.6975e-02],\n                       ...,\n                       [ 1.1628e-01, -4.5862e-02, -6.3646e-02,  6.0994e-02,  8.9624e-02],\n                       [-8.0859e-02, -7.9648e-02, -1.2451e-01,  7.4267e-02, -2.8675e-01],\n                       [ 8.9720e-02, -1.7418e-01,  7.3221e-02, -6.3739e-02,  1.0362e-01]],\n              \n                      [[ 2.0741e-02,  5.7559e-02,  1.3979e-01,  1.8134e-01, -2.3057e-01],\n                       [ 2.4202e-02,  2.1860e-01,  1.7040e-01,  1.8397e-01,  1.7941e-01],\n                       [-1.8589e-01, -9.2332e-02,  2.7689e-02, -1.0780e-01,  7.1783e-02],\n                       ...,\n                       [-3.1190e-02,  1.5541e-02,  6.9423e-02,  3.1812e-02, -5.8314e-02],\n                       [ 9.1042e-02,  1.9255e-01, -1.6854e-02, -1.8149e-01, -4.0924e-02],\n                       [ 7.2905e-03,  1.3938e-01, -7.9636e-02,  1.0899e-02, -8.6410e-02]],\n              \n                      ...,\n              \n                      [[-1.8332e-02, -1.8266e-01,  1.2075e-02,  1.6065e-01,  4.9590e-02],\n                       [ 9.8270e-02,  4.3527e-02, -1.3785e-01, -1.3253e-01,  4.1328e-02],\n                       [-1.0669e-01, -8.6518e-02,  3.2768e-02, -8.7622e-02, -4.4476e-03],\n                       ...,\n                       [ 2.6281e-01,  7.4776e-02,  4.4956e-02,  2.8837e-02, -2.5415e-02],\n                       [ 9.3166e-02, -9.2009e-02,  9.7770e-03, -1.0860e-01,  6.3465e-02],\n                       [-2.0922e-02, -1.8236e-02,  1.6355e-01,  1.1635e-01, -1.8365e-01]],\n              \n                      [[ 4.7051e-02, -7.6047e-02,  9.4924e-02, -3.0314e-02, -9.0751e-02],\n                       [ 5.6992e-02, -7.8012e-02,  5.9171e-02, -1.5740e-01,  8.6556e-02],\n                       [-6.5004e-02,  7.7237e-02, -2.5840e-01,  3.9884e-02,  2.1299e-02],\n                       ...,\n                       [-2.7318e-02, -5.2195e-03, -3.0119e-02, -1.0867e-01, -3.7999e-02],\n                       [ 2.6635e-02,  5.8282e-02, -4.3859e-02,  2.3174e-02, -9.5806e-02],\n                       [-4.2134e-02, -7.7897e-02, -2.1096e-01,  9.2208e-02,  5.1147e-02]],\n              \n                      [[ 2.7598e-01,  8.4980e-02,  7.3107e-02,  8.8136e-02,  9.6620e-02],\n                       [ 2.1128e-01, -3.2471e-04, -3.5583e-01, -9.6179e-03,  1.2868e-01],\n                       [ 3.0512e-02, -8.7394e-05, -2.6139e-02, -3.2137e-02, -8.1327e-02],\n                       ...,\n                       [-6.7315e-02,  6.6562e-03, -2.2074e-01, -4.8521e-02,  1.1588e-01],\n                       [-3.7663e-02, -2.4684e-03,  1.6399e-01, -1.6640e-01,  1.7227e-01],\n                       [-1.9765e-02, -1.7504e-02,  4.3512e-02, -1.0225e-01, -8.6585e-02]]],\n                     dtype=torch.float64)),\n             ('2.1.weight',\n              tensor([1.0114, 0.9971, 0.9957, 1.0026, 1.0004, 1.0105, 0.9932, 0.9981, 0.9985,\n                      0.9963, 1.0062, 1.0025, 1.0033, 0.9957, 0.9969, 0.9933, 0.9955, 1.0324,\n                      1.0062, 0.9969, 0.9955, 0.9905, 1.0038, 0.9978, 1.0066, 0.9979, 0.9928,\n                      0.9903, 1.0011, 1.0014, 1.0054, 0.9993, 0.9737, 1.0166, 0.9919, 1.0067,\n                      0.9901, 0.9944, 0.9805, 1.0041, 0.9898, 0.9883, 0.9997, 1.0276, 0.9846,\n                      0.9779, 1.0005, 0.9831, 1.0027, 0.9953, 1.0010, 0.9957, 0.9898, 0.9938,\n                      0.9988, 1.0064, 0.9940, 1.0068, 1.0055, 1.0007, 0.9901, 1.0025, 0.9999,\n                      0.9998], dtype=torch.float64)),\n             ('2.1.bias',\n              tensor([ 1.7756e-04, -1.4567e-03,  3.0595e-03,  4.0203e-04, -1.7294e-02,\n                       1.0945e-02,  5.7030e-03,  6.6402e-03, -3.2791e-03, -1.1743e-02,\n                       1.4788e-02,  3.1075e-03,  8.4751e-03, -6.3035e-03,  1.3796e-03,\n                      -1.3271e-03, -8.6666e-03,  5.7363e-03,  1.0790e-02, -1.7395e-02,\n                      -3.5906e-05, -1.7418e-02,  4.4519e-03, -6.3363e-03, -2.2705e-04,\n                      -4.6684e-03, -1.0280e-02, -4.8785e-04, -3.8618e-03, -7.0208e-03,\n                       2.7067e-03, -5.4941e-03, -3.3125e-02, -7.4132e-03, -2.1683e-02,\n                      -7.8934e-03, -1.4289e-03,  8.4682e-04, -2.4302e-02,  1.2000e-02,\n                       7.9497e-03, -6.2727e-03, -7.7637e-03,  1.0559e-02, -2.8605e-03,\n                      -2.4261e-02, -4.2198e-03, -3.7400e-03, -1.1643e-02, -8.2744e-03,\n                      -9.1567e-04, -4.3691e-03,  9.6209e-04,  5.7680e-03,  6.9701e-03,\n                       2.8468e-03, -1.1994e-02, -2.9369e-02, -1.5636e-02,  1.6451e-02,\n                      -5.9218e-04,  9.0850e-03,  4.9926e-03,  9.8020e-03],\n                     dtype=torch.float64)),\n             ('2.1.running_mean',\n              tensor([-4.8069e-01, -2.6039e-01,  2.8728e-01, -1.5051e-01, -6.1899e-02,\n                       2.4802e-01, -1.8004e-01,  5.0455e-01,  1.2221e-01, -2.4687e-01,\n                       5.9205e-01,  5.7208e-01,  5.1030e-01,  1.3644e-02, -5.6590e-01,\n                       6.0137e-01,  8.0631e-01,  3.2527e-01,  4.1364e-01, -4.7557e-02,\n                      -4.7933e-02, -1.8203e-01,  4.6632e-01, -3.3356e-01, -1.8954e-01,\n                       5.5763e-01,  3.1278e-01,  3.4997e-01, -7.8608e-02,  8.4839e-04,\n                      -4.2181e-01, -5.6191e-01, -2.3381e-01,  4.3181e-01, -3.7924e-01,\n                       1.4073e-01, -7.1553e-01, -3.0095e-01, -8.6362e-01,  4.5776e-01,\n                       2.5463e-01, -1.1827e+00,  3.5017e-01,  2.1390e-01, -2.6675e-02,\n                      -2.4968e-01, -2.2583e-01, -5.9503e-01, -6.1239e-01,  2.7020e-01,\n                      -5.5095e-02, -8.2256e-01,  4.6099e-01,  6.3388e-01,  3.3406e-01,\n                      -5.9379e-01, -5.7994e-01, -3.3738e-02,  9.8474e-03, -1.3958e-01,\n                      -4.9425e-01, -7.9121e-02, -9.1969e-02,  7.7951e-02],\n                     dtype=torch.float64)),\n             ('2.1.running_var',\n              tensor([1.3438, 1.2486, 0.7831, 0.8580, 0.6908, 0.5269, 0.8417, 1.5675, 1.3563,\n                      0.6689, 1.1856, 1.4626, 2.0695, 0.5821, 1.6126, 0.7827, 1.4582, 0.5874,\n                      1.5859, 0.4374, 0.5981, 0.6753, 0.8948, 0.9110, 0.9109, 1.2599, 1.4261,\n                      0.9409, 0.9017, 0.4733, 1.1884, 0.8498, 0.8941, 1.3517, 0.8710, 0.9485,\n                      1.6003, 0.9523, 1.6227, 2.1731, 1.0342, 1.6151, 0.9533, 1.3677, 0.9936,\n                      1.1720, 0.8057, 1.6414, 1.9836, 1.3619, 1.2761, 2.3753, 1.0898, 0.5510,\n                      1.0528, 1.3277, 0.7214, 0.6063, 1.0052, 0.8472, 0.9324, 0.8246, 0.6691,\n                      0.8483], dtype=torch.float64)),\n             ('2.1.num_batches_tracked', tensor(11419)),\n             ('4.0.convs.0.0.weight',\n              tensor([[[ 0.1746],\n                       [-0.0420],\n                       [-0.1320],\n                       ...,\n                       [ 0.0063],\n                       [ 0.3850],\n                       [-0.0098]],\n              \n                      [[ 0.1294],\n                       [-0.0562],\n                       [ 0.1448],\n                       ...,\n                       [-0.0543],\n                       [-0.0546],\n                       [-0.3303]],\n              \n                      [[-0.0932],\n                       [ 0.2392],\n                       [-0.1688],\n                       ...,\n                       [-0.0135],\n                       [ 0.0666],\n                       [ 0.2452]],\n              \n                      ...,\n              \n                      [[-0.1935],\n                       [-0.0845],\n                       [-0.0212],\n                       ...,\n                       [ 0.0498],\n                       [-0.2612],\n                       [-0.2907]],\n              \n                      [[ 0.0427],\n                       [-0.0339],\n                       [-0.1776],\n                       ...,\n                       [ 0.0490],\n                       [ 0.4007],\n                       [ 0.1686]],\n              \n                      [[ 0.0069],\n                       [ 0.1651],\n                       [ 0.0134],\n                       ...,\n                       [-0.0243],\n                       [ 0.0017],\n                       [-0.0978]]], dtype=torch.float64)),\n             ('4.0.convs.0.1.weight',\n              tensor([0.9410, 0.9464, 0.9494, 0.9294, 0.9269, 0.9071, 0.9162, 0.9314, 0.9135,\n                      0.9557, 0.9408, 0.9317, 0.9197, 0.9351, 0.9301, 0.9492, 0.9420, 0.9575,\n                      0.9157, 0.9447, 0.9294, 0.9259, 0.9631, 0.9424, 0.9456, 0.9249, 0.9311,\n                      0.9653, 0.9149, 0.9304, 0.9337, 0.9459, 0.9350, 0.9427, 0.9510, 0.9751,\n                      0.9388, 0.9551, 0.9297, 0.9184, 0.9392, 0.9580, 0.9775, 0.9316, 0.9576,\n                      0.9402, 0.9603, 0.9468, 0.9521, 0.9429, 0.8836, 0.9302, 0.9494, 0.9338,\n                      0.9385, 0.9360, 0.9327, 0.9295, 0.9358, 0.9431, 0.9518, 0.9426, 0.9383,\n                      0.9349], dtype=torch.float64)),\n             ('4.0.convs.0.1.bias',\n              tensor([ 0.0028,  0.0144,  0.0082,  0.0130, -0.0006, -0.0198, -0.0031, -0.0119,\n                       0.0035,  0.0060, -0.0094,  0.0054, -0.0023, -0.0021, -0.0075,  0.0091,\n                       0.0080,  0.0044, -0.0122, -0.0044, -0.0018,  0.0097,  0.0095, -0.0269,\n                       0.0108, -0.0034, -0.0017,  0.0225, -0.0076, -0.0115, -0.0174,  0.0045,\n                       0.0060,  0.0119,  0.0073,  0.0172, -0.0093,  0.0063, -0.0069, -0.0007,\n                       0.0037,  0.0200,  0.0199, -0.0028,  0.0109,  0.0058,  0.0099,  0.0014,\n                       0.0109,  0.0195,  0.0047, -0.0081, -0.0088,  0.0024, -0.0090,  0.0062,\n                       0.0017,  0.0110,  0.0064,  0.0052, -0.0165,  0.0071,  0.0025, -0.0123],\n                     dtype=torch.float64)),\n             ('4.0.convs.0.1.running_mean',\n              tensor([ 0.0288, -0.6947, -1.3989, -0.1388, -0.6356,  0.0589,  0.3495,  0.3667,\n                      -0.2734,  0.0275,  0.1114, -0.0786, -0.9753, -0.1181,  0.4053,  1.0251,\n                      -0.0885, -0.3129,  0.1751,  0.0510,  0.4098, -0.2097,  0.2498,  0.1215,\n                      -1.1378, -1.0452, -0.7767,  0.6384, -0.3643,  0.5546,  0.2417, -0.6444,\n                      -0.6747,  0.7507,  0.0939, -0.4402, -0.0805, -0.1808,  0.9426, -0.2130,\n                       0.0316, -0.2371, -0.8432,  0.6800,  0.1722, -1.2820, -0.0020,  0.5011,\n                       0.5566,  0.5801, -0.7212,  0.7273, -1.0379, -1.0848,  0.6063, -0.7894,\n                      -0.2395,  0.2086,  1.1783, -0.2079,  0.3387,  0.1843,  0.3474, -0.1663],\n                     dtype=torch.float64)),\n             ('4.0.convs.0.1.running_var',\n              tensor([0.9093, 0.3288, 1.2500, 1.0267, 1.9935, 0.5738, 1.3001, 0.6802, 1.4648,\n                      0.9332, 0.5026, 1.0385, 1.8875, 1.4962, 0.4556, 2.6793, 0.7422, 0.7846,\n                      0.7842, 0.6218, 0.9284, 0.8746, 0.4477, 0.7632, 1.6916, 1.3841, 0.7723,\n                      0.7409, 1.2389, 1.0836, 1.0241, 1.4053, 0.9130, 0.6950, 0.4817, 0.8633,\n                      1.1623, 0.7273, 3.6174, 0.8238, 0.4124, 0.3190, 0.7826, 1.0245, 0.8575,\n                      2.7454, 0.4495, 1.1720, 0.7981, 0.5640, 1.7969, 0.7823, 0.9723, 1.3142,\n                      1.4376, 1.5796, 0.8547, 1.0106, 2.5988, 0.7706, 0.5973, 0.4879, 1.6286,\n                      0.6235], dtype=torch.float64)),\n             ('4.0.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('4.0.convs.1.0.weight',\n              tensor([[[ 5.9927e-02,  6.8274e-02, -4.0390e-02,  3.6234e-02, -6.9103e-03],\n                       [ 8.1514e-03, -9.0629e-03,  9.3375e-02, -7.7648e-02,  3.6492e-02],\n                       [ 1.8982e-02, -3.2039e-02,  4.4522e-02,  4.4976e-02,  6.2291e-02],\n                       ...,\n                       [-2.3505e-02, -1.4944e-02,  4.9613e-02,  5.3850e-02, -6.4702e-02],\n                       [ 3.3961e-02, -5.3110e-02, -8.0345e-02,  7.2922e-02, -7.2593e-02],\n                       [-5.4968e-02, -1.0503e-01, -1.5031e-02,  1.7999e-02, -3.1293e-02]],\n              \n                      [[ 3.5027e-02, -1.5687e-02,  1.1280e-01,  3.8527e-02,  1.4148e-03],\n                       [-5.1503e-02, -6.7381e-02, -1.5978e-02,  2.4346e-02,  8.8746e-02],\n                       [-5.7680e-02, -5.7985e-02, -6.7163e-02,  3.3340e-02, -2.3775e-02],\n                       ...,\n                       [ 7.8668e-02, -4.9563e-02, -5.7116e-02, -5.1082e-02, -8.0681e-02],\n                       [ 1.8827e-02,  2.2210e-02,  6.5901e-02, -1.4361e-02,  5.2684e-02],\n                       [ 4.9907e-02,  9.4056e-02,  5.0022e-02, -6.5946e-02, -7.0033e-02]],\n              \n                      [[ 3.3378e-03, -2.6650e-02,  3.9939e-02,  2.1888e-02, -1.5442e-01],\n                       [-5.0243e-03, -1.0519e-01,  1.0374e-01,  2.7417e-02,  8.9838e-03],\n                       [ 4.2547e-04,  7.8680e-02,  1.2529e-01,  1.4506e-02, -1.0893e-01],\n                       ...,\n                       [-2.0934e-02, -1.9261e-02,  2.4230e-03, -6.6468e-02, -1.6265e-02],\n                       [-5.4112e-02,  3.9021e-02,  7.9773e-02,  7.3511e-02,  7.8458e-02],\n                       [-3.0795e-02, -1.8086e-04,  2.7099e-02, -7.4484e-02,  1.9612e-03]],\n              \n                      ...,\n              \n                      [[ 2.0474e-02, -1.0542e-02, -1.3959e-01,  6.7694e-02,  2.3214e-03],\n                       [-1.3659e-01, -7.4529e-02, -1.9424e-02,  2.1284e-02,  4.5282e-03],\n                       [ 7.2157e-02,  3.5721e-02,  4.4855e-02,  5.0010e-02, -7.9951e-02],\n                       ...,\n                       [ 8.7118e-02,  1.7825e-01,  1.0842e-01,  3.2669e-02, -7.2359e-02],\n                       [ 2.6878e-02, -3.2675e-02, -7.4717e-02,  3.9410e-02,  4.4540e-02],\n                       [-1.0124e-02,  8.1807e-02, -3.7462e-02,  6.2397e-02,  8.9733e-02]],\n              \n                      [[ 3.5384e-02, -6.6726e-02,  5.0894e-02,  2.0477e-02, -4.3781e-02],\n                       [-3.3403e-02, -5.0487e-02, -1.2854e-01,  1.2611e-01,  6.9323e-02],\n                       [-4.1450e-02, -7.8809e-03, -3.4681e-02, -2.1100e-02, -2.3751e-02],\n                       ...,\n                       [-2.5548e-02,  1.1889e-01, -7.2071e-02, -5.0943e-02,  4.8886e-02],\n                       [ 2.0861e-02, -1.8498e-01,  3.7345e-02, -3.3005e-02, -4.7221e-02],\n                       [-1.0617e-01,  3.8453e-02,  5.3551e-02, -6.6472e-02, -9.4374e-03]],\n              \n                      [[ 3.2852e-02,  6.3174e-02, -1.6339e-02, -1.1742e-01, -8.1334e-02],\n                       [ 1.5913e-01, -2.4457e-02,  3.7992e-02, -1.1894e-01, -6.3139e-02],\n                       [-5.8292e-03,  3.3433e-02, -6.9117e-03, -1.0649e-01,  1.6887e-01],\n                       ...,\n                       [-5.6318e-02,  8.1830e-02,  1.9222e-02, -7.3779e-04, -1.5417e-01],\n                       [ 3.0937e-02, -6.0916e-02,  1.1514e-02,  3.8493e-02, -7.4838e-02],\n                       [ 7.1926e-02, -3.3470e-03, -2.3598e-02,  6.7616e-02, -7.4616e-03]]],\n                     dtype=torch.float64)),\n             ('4.0.convs.1.1.weight',\n              tensor([0.9601, 0.9441, 0.9471, 0.9276, 0.9153, 0.9214, 0.9173, 0.9614, 0.9470,\n                      0.9449, 0.9258, 0.9297, 0.8880, 0.9655, 0.9271, 0.9558, 0.9438, 0.9200,\n                      0.9266, 0.9281, 0.9310, 0.9291, 0.9286, 0.9200, 0.9196, 0.9178, 0.9405,\n                      0.9218, 0.9500, 0.9330, 0.9294, 0.9206, 0.9439, 0.9578, 0.9346, 0.9386,\n                      0.9032, 0.9400, 0.9160, 0.9252, 0.9064, 0.9571, 0.9513, 0.9139, 0.9461,\n                      0.9383, 0.9127, 0.9132, 0.9391, 0.9667, 0.9194, 0.9110, 0.9294, 0.9289,\n                      0.9290, 0.9193, 0.9004, 0.9467, 0.9437, 0.9131, 0.9387, 0.9240, 0.9283,\n                      0.9475], dtype=torch.float64)),\n             ('4.0.convs.1.1.bias',\n              tensor([ 0.0205,  0.0021, -0.0057,  0.0070,  0.0263, -0.0163, -0.0200,  0.0027,\n                       0.0193,  0.0153, -0.0027,  0.0061,  0.0057,  0.0004,  0.0050, -0.0127,\n                      -0.0053, -0.0111, -0.0188, -0.0276, -0.0137, -0.0108, -0.0075, -0.0037,\n                       0.0016,  0.0158, -0.0042, -0.0146, -0.0033,  0.0041,  0.0070,  0.0045,\n                      -0.0189,  0.0119, -0.0027,  0.0158, -0.0045, -0.0251, -0.0005, -0.0134,\n                      -0.0069,  0.0026, -0.0049, -0.0097,  0.0005, -0.0170, -0.0057,  0.0042,\n                       0.0113,  0.0163,  0.0005, -0.0233, -0.0041, -0.0052, -0.0024,  0.0088,\n                      -0.0107, -0.0030,  0.0142,  0.0085,  0.0163,  0.0115,  0.0047,  0.0054],\n                     dtype=torch.float64)),\n             ('4.0.convs.1.1.running_mean',\n              tensor([ 0.0179, -0.1838, -0.5570, -0.1682, -0.1654, -0.3049,  0.3894, -0.3667,\n                      -0.3633, -0.5361,  0.2873, -0.1536, -0.2677,  0.4592,  0.3610, -0.3605,\n                      -0.3594,  0.1621, -0.1345,  0.8120, -0.1837, -0.0708,  0.0167,  0.3869,\n                      -1.0239,  0.1968,  0.6182,  0.1432,  0.0949,  0.1320, -0.0142, -0.4331,\n                       0.0396, -0.0999, -0.1719,  0.2801,  0.0586,  0.2857, -0.5476, -0.0668,\n                      -0.1712, -0.4401,  0.2954, -0.1305,  0.5686,  0.5221,  0.1675, -0.2913,\n                      -0.0250, -0.0948,  0.0491,  0.2049,  0.4022,  0.1831,  0.6375, -0.2636,\n                      -0.3939, -0.2922,  0.1335, -0.2775,  0.0127, -0.4342, -0.4751,  0.2475],\n                     dtype=torch.float64)),\n             ('4.0.convs.1.1.running_var',\n              tensor([0.2934, 0.2929, 0.3221, 0.4556, 0.9250, 0.6531, 0.7796, 0.5129, 0.6016,\n                      0.4659, 0.8327, 0.4469, 0.8770, 0.5347, 0.5710, 0.3896, 0.6005, 0.6432,\n                      0.6615, 0.7063, 0.3380, 0.8666, 0.5421, 0.7303, 0.5533, 0.7084, 0.4544,\n                      0.5445, 0.3721, 0.6700, 0.2868, 0.4392, 0.2813, 0.2978, 0.4167, 0.3246,\n                      0.3871, 0.5671, 0.7886, 0.5021, 0.9942, 0.3277, 0.3627, 0.4183, 0.8153,\n                      0.6375, 1.1438, 0.4741, 0.2797, 0.3257, 0.3939, 0.5186, 0.3771, 0.5812,\n                      0.5004, 0.4194, 0.8015, 0.4835, 0.4035, 0.4456, 0.3946, 0.3558, 0.5419,\n                      0.5156], dtype=torch.float64)),\n             ('4.0.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('4.0.convs.2.0.weight',\n              tensor([[[ 0.0510],\n                       [ 0.0766],\n                       [-0.0025],\n                       ...,\n                       [-0.0554],\n                       [-0.0525],\n                       [ 0.0428]],\n              \n                      [[ 0.0090],\n                       [ 0.0900],\n                       [ 0.1719],\n                       ...,\n                       [-0.0947],\n                       [-0.3793],\n                       [ 0.2105]],\n              \n                      [[-0.0018],\n                       [-0.0758],\n                       [-0.0390],\n                       ...,\n                       [ 0.0780],\n                       [ 0.0383],\n                       [ 0.0042]],\n              \n                      ...,\n              \n                      [[-0.2673],\n                       [ 0.4015],\n                       [ 0.2070],\n                       ...,\n                       [-0.0480],\n                       [ 0.1154],\n                       [-0.0629]],\n              \n                      [[ 0.1003],\n                       [ 0.0125],\n                       [-0.1353],\n                       ...,\n                       [-0.0992],\n                       [-0.2238],\n                       [-0.0396]],\n              \n                      [[ 0.0412],\n                       [-0.0411],\n                       [ 0.2007],\n                       ...,\n                       [ 0.0877],\n                       [ 0.0523],\n                       [-0.1581]]], dtype=torch.float64)),\n             ('4.0.convs.2.1.weight',\n              tensor([-0.0010,  0.0402,  0.0006,  0.0384,  0.0132, -0.0065,  0.0073, -0.0091,\n                       0.0104, -0.0024,  0.0054, -0.0013, -0.0206,  0.0208, -0.0056,  0.0108,\n                      -0.0260,  0.0484, -0.0011,  0.0179,  0.0156,  0.0038,  0.0161, -0.0147,\n                      -0.0097,  0.0317, -0.0101, -0.0127, -0.0042,  0.0111, -0.0005, -0.0376,\n                      -0.0006,  0.0352,  0.0710, -0.0191, -0.0097,  0.0267,  0.0012,  0.0079,\n                      -0.0208,  0.0053,  0.0088, -0.0134, -0.0229,  0.0100, -0.0093, -0.0089,\n                       0.0123, -0.0008,  0.0085, -0.0428, -0.0005,  0.0052,  0.0037,  0.0098,\n                      -0.0033, -0.0096,  0.0138,  0.0061,  0.0082, -0.0095,  0.0025, -0.0049,\n                      -0.0004, -0.0087,  0.0265,  0.0356,  0.0037,  0.0305, -0.0063, -0.0090,\n                       0.0142, -0.0099,  0.0276, -0.0231,  0.0164,  0.0078,  0.0274, -0.0125,\n                       0.0168,  0.0096,  0.0330,  0.0061,  0.0094, -0.0126,  0.0058,  0.0014,\n                      -0.0339,  0.0220, -0.0068,  0.0073, -0.0034,  0.0103, -0.0021, -0.0004,\n                      -0.0031, -0.0106, -0.0197, -0.0001,  0.0278, -0.0101,  0.0189,  0.0072,\n                      -0.0331,  0.0129, -0.0039,  0.0141, -0.0053,  0.0135, -0.0029, -0.0196,\n                       0.0276,  0.0122, -0.0034,  0.0069,  0.0124, -0.0056,  0.0090,  0.0121,\n                       0.0037,  0.0088, -0.0087, -0.0017, -0.0098, -0.0141, -0.0152,  0.0157,\n                      -0.0277, -0.0070,  0.0159,  0.0088,  0.0084,  0.0013,  0.0153,  0.0008,\n                      -0.0127,  0.0139, -0.0066, -0.0175,  0.0073,  0.0099, -0.0060,  0.0243,\n                      -0.0046,  0.0038,  0.0145, -0.0040,  0.0222,  0.0203,  0.0118,  0.0214,\n                      -0.0180, -0.0010,  0.0020,  0.0110, -0.0202,  0.0072,  0.0236,  0.0345,\n                      -0.0081, -0.0163, -0.0128,  0.0027,  0.0130,  0.0044,  0.0211, -0.0040,\n                      -0.0192, -0.0255,  0.0194,  0.0076,  0.0294, -0.0148,  0.0023,  0.0028,\n                       0.0003, -0.0173,  0.0132,  0.0154,  0.0065, -0.0255,  0.0008,  0.0121,\n                      -0.0048,  0.0058, -0.0021, -0.0283, -0.0153, -0.0152,  0.0045,  0.0068,\n                       0.0004, -0.0126, -0.0158,  0.0099, -0.0015,  0.0180,  0.0046,  0.0014,\n                      -0.0118, -0.0125,  0.0005,  0.0100, -0.0213,  0.0012,  0.0289,  0.0189,\n                      -0.0113, -0.0205, -0.0003, -0.0037, -0.0097,  0.0017,  0.0156, -0.0150,\n                      -0.0137, -0.0007, -0.0118, -0.0131, -0.0127, -0.0215, -0.0190,  0.0182,\n                      -0.0051, -0.0271, -0.0124,  0.0209,  0.0346, -0.0065,  0.0122, -0.0052,\n                       0.0243,  0.0228,  0.0050,  0.0172, -0.0099,  0.0012, -0.0091,  0.0051,\n                       0.0001,  0.0034, -0.0192, -0.0020,  0.0169, -0.0136, -0.0008, -0.0167,\n                      -0.0098, -0.0075, -0.0285, -0.0155, -0.0030, -0.0338, -0.0108,  0.0087],\n                     dtype=torch.float64)),\n             ('4.0.convs.2.1.bias',\n              tensor([-7.2795e-04, -3.3469e-03,  2.5615e-02,  1.7376e-03,  9.3212e-03,\n                      -1.6753e-02, -2.9658e-03, -1.4160e-02, -1.3214e-02, -8.7208e-03,\n                      -4.9374e-03, -7.9470e-03,  3.0062e-03, -4.8956e-03, -6.4107e-03,\n                      -1.5175e-02, -1.8393e-02,  2.2720e-02,  4.0796e-03, -4.3133e-03,\n                       3.1041e-03, -1.9059e-02, -4.1501e-03,  3.6664e-04, -9.4798e-03,\n                      -2.1313e-02, -1.9297e-03, -4.5335e-03,  2.6222e-03,  3.8868e-03,\n                      -1.9928e-02, -1.3763e-02, -1.1673e-02, -2.0898e-02,  4.1412e-03,\n                      -1.5855e-02, -3.0226e-03,  4.0745e-03, -1.0940e-02, -1.7874e-02,\n                       4.3854e-03, -7.2711e-03, -1.7059e-02, -1.7811e-02,  7.7646e-03,\n                      -1.0010e-02, -1.3731e-02,  9.3924e-03, -1.1904e-02,  4.3385e-03,\n                      -4.3618e-03, -2.4723e-03,  2.6984e-03, -1.1851e-02, -7.9505e-03,\n                      -6.0253e-03, -4.7125e-04, -5.9180e-03, -1.4574e-02,  5.3121e-03,\n                      -8.4393e-03, -5.2493e-03, -2.3264e-02, -1.6835e-02, -1.1743e-02,\n                      -3.6267e-03, -3.6482e-03, -2.0177e-03, -2.1536e-02, -1.6293e-02,\n                       2.2893e-03, -6.6032e-04,  3.3575e-04, -4.7125e-03, -1.6277e-02,\n                      -1.6786e-02, -2.6764e-02, -1.9008e-02, -5.0277e-03, -1.6644e-02,\n                      -4.6247e-03, -4.1078e-04, -2.2868e-02, -4.6928e-03,  2.6562e-03,\n                      -1.7980e-02,  1.2481e-02,  1.6196e-02, -2.4499e-03,  2.4511e-03,\n                      -1.7947e-02, -4.6330e-03, -1.5217e-02,  4.2939e-03, -5.1057e-03,\n                      -1.4797e-02,  9.6003e-04, -1.2330e-02,  2.5038e-04, -1.0838e-02,\n                       2.3859e-03, -3.7735e-03, -1.2845e-02, -1.1175e-02, -6.7415e-04,\n                       7.2692e-03, -1.1312e-02, -7.4839e-03, -7.9239e-03, -1.2597e-02,\n                      -8.5915e-03, -5.0790e-03,  1.0275e-03,  1.2115e-03, -4.7034e-03,\n                      -4.8503e-03, -6.4275e-03, -7.3991e-03,  5.8259e-03, -2.2010e-03,\n                      -7.3446e-03, -2.2270e-02, -1.3333e-03, -8.2732e-03, -9.4862e-03,\n                      -8.1979e-03, -1.1344e-02,  1.8440e-03,  1.3599e-03, -2.0410e-02,\n                      -9.6839e-03, -7.9098e-03, -3.7910e-03,  1.5697e-05, -6.5700e-03,\n                      -2.1605e-02,  4.2204e-03,  4.0283e-04, -6.4831e-03, -2.0593e-03,\n                      -2.3457e-03,  1.9256e-03, -1.2860e-02, -2.6430e-03, -1.8717e-02,\n                      -1.6861e-02, -1.3022e-02, -1.0280e-02, -1.2432e-03,  1.0246e-02,\n                      -9.3326e-03, -1.5284e-02, -2.7686e-02, -1.0454e-02, -7.1254e-03,\n                      -3.7724e-03,  1.0640e-02,  2.7505e-03, -1.3317e-02, -2.0494e-02,\n                      -7.4842e-03,  2.7243e-02, -9.6145e-03, -3.3994e-03, -5.4003e-03,\n                       4.5228e-03, -8.3312e-03,  2.8939e-02,  1.1500e-04, -2.9051e-02,\n                      -7.2565e-04, -1.3314e-03, -7.2075e-03, -5.3022e-03, -1.7320e-02,\n                      -1.6683e-02, -7.8974e-03,  1.4435e-02, -1.1474e-02, -3.6701e-04,\n                      -1.9463e-03,  2.1519e-02, -1.1158e-02,  2.4624e-03, -4.5132e-03,\n                      -7.7967e-03, -6.0586e-03,  1.3910e-02, -9.0865e-03, -1.1510e-02,\n                      -7.4502e-03, -1.8166e-02, -6.3183e-03, -2.0461e-02, -8.9440e-03,\n                       6.6549e-04, -3.2089e-03, -1.2933e-02, -7.0443e-03, -1.4368e-02,\n                      -8.0977e-03, -1.3865e-02,  9.2988e-03, -1.1243e-02, -3.2124e-03,\n                      -9.6305e-03, -4.0261e-03, -1.5690e-02, -7.7035e-03, -2.3680e-02,\n                       2.4345e-03, -4.0755e-03, -8.5092e-04, -5.7477e-03, -2.0849e-03,\n                       1.8883e-02, -4.3178e-03,  1.6819e-02,  3.9807e-03, -2.4423e-03,\n                       2.5718e-03, -2.9551e-03, -1.3181e-02, -1.3747e-03, -2.2727e-02,\n                       5.7089e-03,  4.4769e-03,  6.1698e-03, -2.0630e-02, -1.0333e-02,\n                       5.9753e-04,  2.3022e-03,  2.1443e-03,  7.5890e-03, -1.0112e-02,\n                      -3.6802e-03,  6.6059e-03,  7.0752e-03, -1.1512e-02, -7.2608e-03,\n                      -7.2489e-03,  3.3995e-03, -1.0654e-02, -1.1668e-02, -8.9250e-03,\n                      -6.6219e-03, -7.4274e-04,  5.4266e-03, -5.8644e-03, -1.6624e-02,\n                      -7.5053e-03, -7.3289e-03, -1.2267e-02, -5.6282e-03,  4.0937e-05,\n                      -5.9866e-04], dtype=torch.float64)),\n             ('4.0.convs.2.1.running_mean',\n              tensor([-1.1578e-01,  1.4158e-01,  2.6433e-01,  3.2712e-01, -1.5668e-02,\n                       1.3126e-01, -2.0683e-02,  1.0507e-01,  2.1800e-03,  1.4118e-01,\n                      -9.5007e-02,  1.9489e-01,  2.0697e-01, -1.8849e-01,  2.4983e-01,\n                       4.3032e-02,  3.2477e-01, -5.4898e-01,  3.7983e-02,  3.7709e-01,\n                      -1.3353e-01, -3.6700e-01, -2.4383e-01,  3.5948e-01, -1.9123e-02,\n                      -6.4727e-02, -2.1877e-01, -2.0409e-02,  1.4432e-01,  5.2703e-02,\n                      -6.1961e-01,  3.3659e-01, -9.3631e-02, -1.0217e-01, -2.5888e-01,\n                       7.7050e-02,  3.5075e-01, -9.0172e-02, -1.0995e-01, -2.3505e-01,\n                      -8.0178e-01, -2.9860e-02,  1.7033e-01, -7.1453e-01, -4.1577e-01,\n                      -1.2391e-01, -2.0914e-01,  7.5619e-02, -2.9508e-01,  3.5578e-02,\n                      -9.6041e-02, -3.0559e-01,  2.7696e-01, -1.6429e-02, -4.4110e-01,\n                      -2.0352e-01, -1.3997e-02, -2.9686e-01,  1.9188e-01, -1.0232e-01,\n                       7.4081e-02,  2.4853e-01, -1.7221e-01,  1.6841e-01,  5.1837e-01,\n                      -1.8933e-02, -5.8636e-01,  2.9902e-02, -1.9554e-01,  1.4545e-01,\n                      -2.5608e-01,  3.5397e-02, -3.4241e-01, -1.6359e-01,  3.4897e-02,\n                      -4.1212e-01,  7.8959e-02, -3.3743e-01, -3.3751e-02,  3.1742e-01,\n                      -3.1577e-01,  2.2491e-01, -7.6560e-01, -7.6081e-01,  2.3304e-02,\n                      -2.2236e-03, -2.4009e-01, -2.0231e-02, -1.2668e-01, -1.6607e-01,\n                      -9.2332e-03,  2.1212e-01, -2.3443e-03,  1.5779e-01,  1.7743e-01,\n                       2.9531e-01,  7.7745e-02,  3.0311e-01, -1.6115e-01, -7.2446e-02,\n                      -9.6247e-02,  2.2273e-01, -2.4288e-01, -1.9972e-01,  1.8564e-01,\n                       1.7285e-01,  2.0827e-01, -1.1654e-01,  2.4553e-01,  1.0188e-01,\n                      -2.0252e-02,  6.3375e-02, -2.1360e-01, -3.4964e-01, -1.0912e-01,\n                      -4.0965e-02, -2.0619e-01, -3.6362e-01, -1.3493e-02, -1.0500e-01,\n                      -2.2794e-03,  3.3153e-02,  1.5774e-01,  4.6913e-02, -8.1025e-02,\n                      -2.7331e-01,  7.1843e-02, -3.2702e-01, -9.6831e-02, -4.8345e-01,\n                      -1.1988e-01, -1.3751e-01, -1.6979e-01,  2.5665e-01,  5.1327e-01,\n                      -1.8191e-01,  1.0861e-01,  4.3320e-01, -4.0506e-01, -2.0047e-02,\n                       1.5334e-01, -3.3304e-01,  1.2437e-01, -7.6602e-03, -2.7165e-02,\n                      -1.5085e-01, -6.8762e-02, -5.6192e-02, -2.0192e-01, -3.6609e-01,\n                       3.8151e-01,  1.5476e-02,  6.4966e-01,  7.7298e-02,  2.2244e-01,\n                      -1.1717e-02, -2.1701e-01,  2.1672e-01, -1.0395e-01, -2.9592e-01,\n                       9.3124e-02, -4.1344e-01,  4.3611e-02, -1.0612e-02, -4.2286e-02,\n                      -2.7401e-01,  2.2494e-02, -1.4385e-01,  6.9536e-02,  2.0816e-01,\n                      -9.1477e-03, -1.5681e-01,  3.4120e-01, -2.2300e-01, -2.9704e-01,\n                       6.0341e-01,  3.9542e-03,  2.3698e-01, -9.6631e-03, -2.2206e-01,\n                       2.4525e-01,  4.4015e-01, -1.4203e-02,  4.0267e-02, -4.8545e-01,\n                      -1.3542e-01, -7.8458e-01,  1.6526e-01,  1.3926e-01,  4.4294e-01,\n                       3.2859e-01,  4.3802e-01, -1.5863e-01,  1.9650e-01, -1.3072e-01,\n                      -3.1467e-01, -1.8309e-01, -1.3033e-01, -1.4226e-01,  2.8452e-02,\n                       1.7161e-01, -1.2408e-01,  5.2814e-02, -3.7975e-02,  6.3113e-01,\n                       1.3134e-01, -1.9547e-02, -1.0505e-01, -2.3531e-01, -7.9773e-04,\n                       5.9743e-02, -4.5676e-01,  3.7886e-02,  1.0505e-01, -2.2532e-01,\n                       2.5387e-01,  1.0116e-01, -2.0516e-01,  4.4582e-01,  3.8690e-02,\n                      -1.1023e-01,  3.5275e-01,  1.0583e-01,  1.2915e-01, -1.2746e-01,\n                      -2.0916e-01,  2.9274e-01,  4.6588e-01,  5.3821e-01,  5.1901e-01,\n                       8.0596e-03, -2.5919e-01, -1.0843e-01,  1.1232e-01, -1.9445e-02,\n                      -5.7027e-02, -4.8326e-01, -4.4388e-02, -4.1745e-02, -2.8202e-01,\n                      -6.7727e-02,  4.1758e-01,  9.1063e-03,  1.3424e-01,  3.5230e-02,\n                      -1.4623e-01, -1.9179e-01,  1.4743e-01, -1.6192e-01, -5.8794e-02,\n                      -1.2120e-02,  3.0112e-01,  3.7555e-02,  1.6582e-01, -6.7952e-01,\n                       2.5598e-02], dtype=torch.float64)),\n             ('4.0.convs.2.1.running_var',\n              tensor([0.0440, 0.2857, 0.1033, 0.2448, 0.3563, 0.1937, 0.1337, 0.2884, 0.1091,\n                      0.1761, 0.1045, 0.0666, 0.1426, 0.2953, 0.1207, 0.1117, 0.5159, 0.5097,\n                      0.1532, 0.2480, 0.3501, 0.2698, 0.2317, 0.2921, 0.3286, 0.1704, 0.2739,\n                      0.2797, 0.1319, 0.1786, 0.2394, 0.0964, 0.1558, 0.2645, 0.2080, 0.3394,\n                      0.1451, 0.2790, 0.0968, 0.4124, 0.3920, 0.2663, 0.1148, 0.2325, 0.3037,\n                      0.1625, 0.1277, 0.2137, 0.1788, 0.1150, 0.1502, 0.3963, 0.1191, 0.1766,\n                      0.1890, 0.1666, 0.0719, 0.4495, 0.2533, 0.3538, 0.1134, 0.1574, 0.0734,\n                      0.0910, 0.2351, 0.1066, 0.3052, 0.4823, 0.0396, 0.4310, 0.2640, 0.0735,\n                      0.0970, 0.2930, 0.3959, 0.1075, 0.1271, 0.2847, 0.2928, 0.1708, 0.3483,\n                      0.1331, 0.6839, 0.3315, 0.3486, 0.5451, 0.1625, 0.1535, 0.3277, 0.2665,\n                      0.4893, 0.1868, 0.0580, 0.1631, 0.0956, 0.0799, 0.1306, 0.2312, 0.1964,\n                      0.0974, 0.3483, 0.3551, 0.1420, 0.1951, 0.1435, 0.0892, 0.3026, 0.3772,\n                      0.1125, 0.1552, 0.0349, 0.4046, 0.3363, 0.1188, 0.1225, 0.1267, 0.1440,\n                      0.2832, 0.2235, 0.2327, 0.0582, 0.1301, 0.2916, 0.1054, 0.1908, 0.3913,\n                      0.1391, 0.1453, 0.3321, 0.1705, 0.0293, 0.1460, 0.3621, 0.1140, 0.1441,\n                      0.0590, 0.0849, 0.2686, 0.1033, 0.1844, 0.2728, 0.1213, 0.0854, 0.0808,\n                      0.0745, 0.2571, 0.1096, 0.1771, 0.2132, 0.3038, 0.3986, 0.1302, 0.2823,\n                      0.0682, 0.0777, 0.2564, 0.2812, 0.1103, 0.1522, 0.1747, 0.0965, 0.2222,\n                      0.0937, 0.1136, 0.4563, 0.3573, 0.4113, 0.0869, 0.3864, 0.2886, 0.1573,\n                      0.0773, 0.2260, 0.0569, 0.2749, 0.2269, 0.1054, 0.3876, 0.1265, 0.0741,\n                      0.1075, 0.1540, 0.1516, 0.2364, 0.2387, 0.1255, 0.2923, 0.1504, 0.0875,\n                      0.1135, 0.2501, 0.2611, 0.0729, 0.1050, 0.1732, 0.3203, 0.1575, 0.1567,\n                      0.2064, 0.0633, 0.1708, 0.0617, 0.2209, 0.2549, 0.2912, 0.1254, 0.1321,\n                      0.1858, 0.1188, 0.2069, 0.0344, 0.0983, 0.1908, 0.1725, 0.1557, 0.2547,\n                      0.1866, 0.0839, 0.2703, 0.4347, 0.1338, 0.2202, 0.0702, 0.2719, 0.2316,\n                      0.3331, 0.1303, 0.3630, 0.3517, 0.2471, 0.1121, 0.1939, 0.3163, 0.2394,\n                      0.0734, 0.2661, 0.3263, 0.0634, 0.2345, 0.1950, 0.0961, 0.2340, 0.3849,\n                      0.1130, 0.2686, 0.1005, 0.0476, 0.3965, 0.1334, 0.1252, 0.3284, 0.2387,\n                      0.1090, 0.2877, 0.2772, 0.0949], dtype=torch.float64)),\n             ('4.0.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('4.0.convpath.0.0.0.weight',\n              tensor([[[ 0.1746],\n                       [-0.0420],\n                       [-0.1320],\n                       ...,\n                       [ 0.0063],\n                       [ 0.3850],\n                       [-0.0098]],\n              \n                      [[ 0.1294],\n                       [-0.0562],\n                       [ 0.1448],\n                       ...,\n                       [-0.0543],\n                       [-0.0546],\n                       [-0.3303]],\n              \n                      [[-0.0932],\n                       [ 0.2392],\n                       [-0.1688],\n                       ...,\n                       [-0.0135],\n                       [ 0.0666],\n                       [ 0.2452]],\n              \n                      ...,\n              \n                      [[-0.1935],\n                       [-0.0845],\n                       [-0.0212],\n                       ...,\n                       [ 0.0498],\n                       [-0.2612],\n                       [-0.2907]],\n              \n                      [[ 0.0427],\n                       [-0.0339],\n                       [-0.1776],\n                       ...,\n                       [ 0.0490],\n                       [ 0.4007],\n                       [ 0.1686]],\n              \n                      [[ 0.0069],\n                       [ 0.1651],\n                       [ 0.0134],\n                       ...,\n                       [-0.0243],\n                       [ 0.0017],\n                       [-0.0978]]], dtype=torch.float64)),\n             ('4.0.convpath.0.0.1.weight',\n              tensor([0.9410, 0.9464, 0.9494, 0.9294, 0.9269, 0.9071, 0.9162, 0.9314, 0.9135,\n                      0.9557, 0.9408, 0.9317, 0.9197, 0.9351, 0.9301, 0.9492, 0.9420, 0.9575,\n                      0.9157, 0.9447, 0.9294, 0.9259, 0.9631, 0.9424, 0.9456, 0.9249, 0.9311,\n                      0.9653, 0.9149, 0.9304, 0.9337, 0.9459, 0.9350, 0.9427, 0.9510, 0.9751,\n                      0.9388, 0.9551, 0.9297, 0.9184, 0.9392, 0.9580, 0.9775, 0.9316, 0.9576,\n                      0.9402, 0.9603, 0.9468, 0.9521, 0.9429, 0.8836, 0.9302, 0.9494, 0.9338,\n                      0.9385, 0.9360, 0.9327, 0.9295, 0.9358, 0.9431, 0.9518, 0.9426, 0.9383,\n                      0.9349], dtype=torch.float64)),\n             ('4.0.convpath.0.0.1.bias',\n              tensor([ 0.0028,  0.0144,  0.0082,  0.0130, -0.0006, -0.0198, -0.0031, -0.0119,\n                       0.0035,  0.0060, -0.0094,  0.0054, -0.0023, -0.0021, -0.0075,  0.0091,\n                       0.0080,  0.0044, -0.0122, -0.0044, -0.0018,  0.0097,  0.0095, -0.0269,\n                       0.0108, -0.0034, -0.0017,  0.0225, -0.0076, -0.0115, -0.0174,  0.0045,\n                       0.0060,  0.0119,  0.0073,  0.0172, -0.0093,  0.0063, -0.0069, -0.0007,\n                       0.0037,  0.0200,  0.0199, -0.0028,  0.0109,  0.0058,  0.0099,  0.0014,\n                       0.0109,  0.0195,  0.0047, -0.0081, -0.0088,  0.0024, -0.0090,  0.0062,\n                       0.0017,  0.0110,  0.0064,  0.0052, -0.0165,  0.0071,  0.0025, -0.0123],\n                     dtype=torch.float64)),\n             ('4.0.convpath.0.0.1.running_mean',\n              tensor([ 0.0288, -0.6947, -1.3989, -0.1388, -0.6356,  0.0589,  0.3495,  0.3667,\n                      -0.2734,  0.0275,  0.1114, -0.0786, -0.9753, -0.1181,  0.4053,  1.0251,\n                      -0.0885, -0.3129,  0.1751,  0.0510,  0.4098, -0.2097,  0.2498,  0.1215,\n                      -1.1378, -1.0452, -0.7767,  0.6384, -0.3643,  0.5546,  0.2417, -0.6444,\n                      -0.6747,  0.7507,  0.0939, -0.4402, -0.0805, -0.1808,  0.9426, -0.2130,\n                       0.0316, -0.2371, -0.8432,  0.6800,  0.1722, -1.2820, -0.0020,  0.5011,\n                       0.5566,  0.5801, -0.7212,  0.7273, -1.0379, -1.0848,  0.6063, -0.7894,\n                      -0.2395,  0.2086,  1.1783, -0.2079,  0.3387,  0.1843,  0.3474, -0.1663],\n                     dtype=torch.float64)),\n             ('4.0.convpath.0.0.1.running_var',\n              tensor([0.9093, 0.3288, 1.2500, 1.0267, 1.9935, 0.5738, 1.3001, 0.6802, 1.4648,\n                      0.9332, 0.5026, 1.0385, 1.8875, 1.4962, 0.4556, 2.6793, 0.7422, 0.7846,\n                      0.7842, 0.6218, 0.9284, 0.8746, 0.4477, 0.7632, 1.6916, 1.3841, 0.7723,\n                      0.7409, 1.2389, 1.0836, 1.0241, 1.4053, 0.9130, 0.6950, 0.4817, 0.8633,\n                      1.1623, 0.7273, 3.6174, 0.8238, 0.4124, 0.3190, 0.7826, 1.0245, 0.8575,\n                      2.7454, 0.4495, 1.1720, 0.7981, 0.5640, 1.7969, 0.7823, 0.9723, 1.3142,\n                      1.4376, 1.5796, 0.8547, 1.0106, 2.5988, 0.7706, 0.5973, 0.4879, 1.6286,\n                      0.6235], dtype=torch.float64)),\n             ('4.0.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('4.0.convpath.0.1.0.weight',\n              tensor([[[ 5.9927e-02,  6.8274e-02, -4.0390e-02,  3.6234e-02, -6.9103e-03],\n                       [ 8.1514e-03, -9.0629e-03,  9.3375e-02, -7.7648e-02,  3.6492e-02],\n                       [ 1.8982e-02, -3.2039e-02,  4.4522e-02,  4.4976e-02,  6.2291e-02],\n                       ...,\n                       [-2.3505e-02, -1.4944e-02,  4.9613e-02,  5.3850e-02, -6.4702e-02],\n                       [ 3.3961e-02, -5.3110e-02, -8.0345e-02,  7.2922e-02, -7.2593e-02],\n                       [-5.4968e-02, -1.0503e-01, -1.5031e-02,  1.7999e-02, -3.1293e-02]],\n              \n                      [[ 3.5027e-02, -1.5687e-02,  1.1280e-01,  3.8527e-02,  1.4148e-03],\n                       [-5.1503e-02, -6.7381e-02, -1.5978e-02,  2.4346e-02,  8.8746e-02],\n                       [-5.7680e-02, -5.7985e-02, -6.7163e-02,  3.3340e-02, -2.3775e-02],\n                       ...,\n                       [ 7.8668e-02, -4.9563e-02, -5.7116e-02, -5.1082e-02, -8.0681e-02],\n                       [ 1.8827e-02,  2.2210e-02,  6.5901e-02, -1.4361e-02,  5.2684e-02],\n                       [ 4.9907e-02,  9.4056e-02,  5.0022e-02, -6.5946e-02, -7.0033e-02]],\n              \n                      [[ 3.3378e-03, -2.6650e-02,  3.9939e-02,  2.1888e-02, -1.5442e-01],\n                       [-5.0243e-03, -1.0519e-01,  1.0374e-01,  2.7417e-02,  8.9838e-03],\n                       [ 4.2547e-04,  7.8680e-02,  1.2529e-01,  1.4506e-02, -1.0893e-01],\n                       ...,\n                       [-2.0934e-02, -1.9261e-02,  2.4230e-03, -6.6468e-02, -1.6265e-02],\n                       [-5.4112e-02,  3.9021e-02,  7.9773e-02,  7.3511e-02,  7.8458e-02],\n                       [-3.0795e-02, -1.8086e-04,  2.7099e-02, -7.4484e-02,  1.9612e-03]],\n              \n                      ...,\n              \n                      [[ 2.0474e-02, -1.0542e-02, -1.3959e-01,  6.7694e-02,  2.3214e-03],\n                       [-1.3659e-01, -7.4529e-02, -1.9424e-02,  2.1284e-02,  4.5282e-03],\n                       [ 7.2157e-02,  3.5721e-02,  4.4855e-02,  5.0010e-02, -7.9951e-02],\n                       ...,\n                       [ 8.7118e-02,  1.7825e-01,  1.0842e-01,  3.2669e-02, -7.2359e-02],\n                       [ 2.6878e-02, -3.2675e-02, -7.4717e-02,  3.9410e-02,  4.4540e-02],\n                       [-1.0124e-02,  8.1807e-02, -3.7462e-02,  6.2397e-02,  8.9733e-02]],\n              \n                      [[ 3.5384e-02, -6.6726e-02,  5.0894e-02,  2.0477e-02, -4.3781e-02],\n                       [-3.3403e-02, -5.0487e-02, -1.2854e-01,  1.2611e-01,  6.9323e-02],\n                       [-4.1450e-02, -7.8809e-03, -3.4681e-02, -2.1100e-02, -2.3751e-02],\n                       ...,\n                       [-2.5548e-02,  1.1889e-01, -7.2071e-02, -5.0943e-02,  4.8886e-02],\n                       [ 2.0861e-02, -1.8498e-01,  3.7345e-02, -3.3005e-02, -4.7221e-02],\n                       [-1.0617e-01,  3.8453e-02,  5.3551e-02, -6.6472e-02, -9.4374e-03]],\n              \n                      [[ 3.2852e-02,  6.3174e-02, -1.6339e-02, -1.1742e-01, -8.1334e-02],\n                       [ 1.5913e-01, -2.4457e-02,  3.7992e-02, -1.1894e-01, -6.3139e-02],\n                       [-5.8292e-03,  3.3433e-02, -6.9117e-03, -1.0649e-01,  1.6887e-01],\n                       ...,\n                       [-5.6318e-02,  8.1830e-02,  1.9222e-02, -7.3779e-04, -1.5417e-01],\n                       [ 3.0937e-02, -6.0916e-02,  1.1514e-02,  3.8493e-02, -7.4838e-02],\n                       [ 7.1926e-02, -3.3470e-03, -2.3598e-02,  6.7616e-02, -7.4616e-03]]],\n                     dtype=torch.float64)),\n             ('4.0.convpath.0.1.1.weight',\n              tensor([0.9601, 0.9441, 0.9471, 0.9276, 0.9153, 0.9214, 0.9173, 0.9614, 0.9470,\n                      0.9449, 0.9258, 0.9297, 0.8880, 0.9655, 0.9271, 0.9558, 0.9438, 0.9200,\n                      0.9266, 0.9281, 0.9310, 0.9291, 0.9286, 0.9200, 0.9196, 0.9178, 0.9405,\n                      0.9218, 0.9500, 0.9330, 0.9294, 0.9206, 0.9439, 0.9578, 0.9346, 0.9386,\n                      0.9032, 0.9400, 0.9160, 0.9252, 0.9064, 0.9571, 0.9513, 0.9139, 0.9461,\n                      0.9383, 0.9127, 0.9132, 0.9391, 0.9667, 0.9194, 0.9110, 0.9294, 0.9289,\n                      0.9290, 0.9193, 0.9004, 0.9467, 0.9437, 0.9131, 0.9387, 0.9240, 0.9283,\n                      0.9475], dtype=torch.float64)),\n             ('4.0.convpath.0.1.1.bias',\n              tensor([ 0.0205,  0.0021, -0.0057,  0.0070,  0.0263, -0.0163, -0.0200,  0.0027,\n                       0.0193,  0.0153, -0.0027,  0.0061,  0.0057,  0.0004,  0.0050, -0.0127,\n                      -0.0053, -0.0111, -0.0188, -0.0276, -0.0137, -0.0108, -0.0075, -0.0037,\n                       0.0016,  0.0158, -0.0042, -0.0146, -0.0033,  0.0041,  0.0070,  0.0045,\n                      -0.0189,  0.0119, -0.0027,  0.0158, -0.0045, -0.0251, -0.0005, -0.0134,\n                      -0.0069,  0.0026, -0.0049, -0.0097,  0.0005, -0.0170, -0.0057,  0.0042,\n                       0.0113,  0.0163,  0.0005, -0.0233, -0.0041, -0.0052, -0.0024,  0.0088,\n                      -0.0107, -0.0030,  0.0142,  0.0085,  0.0163,  0.0115,  0.0047,  0.0054],\n                     dtype=torch.float64)),\n             ('4.0.convpath.0.1.1.running_mean',\n              tensor([ 0.0179, -0.1838, -0.5570, -0.1682, -0.1654, -0.3049,  0.3894, -0.3667,\n                      -0.3633, -0.5361,  0.2873, -0.1536, -0.2677,  0.4592,  0.3610, -0.3605,\n                      -0.3594,  0.1621, -0.1345,  0.8120, -0.1837, -0.0708,  0.0167,  0.3869,\n                      -1.0239,  0.1968,  0.6182,  0.1432,  0.0949,  0.1320, -0.0142, -0.4331,\n                       0.0396, -0.0999, -0.1719,  0.2801,  0.0586,  0.2857, -0.5476, -0.0668,\n                      -0.1712, -0.4401,  0.2954, -0.1305,  0.5686,  0.5221,  0.1675, -0.2913,\n                      -0.0250, -0.0948,  0.0491,  0.2049,  0.4022,  0.1831,  0.6375, -0.2636,\n                      -0.3939, -0.2922,  0.1335, -0.2775,  0.0127, -0.4342, -0.4751,  0.2475],\n                     dtype=torch.float64)),\n             ('4.0.convpath.0.1.1.running_var',\n              tensor([0.2934, 0.2929, 0.3221, 0.4556, 0.9250, 0.6531, 0.7796, 0.5129, 0.6016,\n                      0.4659, 0.8327, 0.4469, 0.8770, 0.5347, 0.5710, 0.3896, 0.6005, 0.6432,\n                      0.6615, 0.7063, 0.3380, 0.8666, 0.5421, 0.7303, 0.5533, 0.7084, 0.4544,\n                      0.5445, 0.3721, 0.6700, 0.2868, 0.4392, 0.2813, 0.2978, 0.4167, 0.3246,\n                      0.3871, 0.5671, 0.7886, 0.5021, 0.9942, 0.3277, 0.3627, 0.4183, 0.8153,\n                      0.6375, 1.1438, 0.4741, 0.2797, 0.3257, 0.3939, 0.5186, 0.3771, 0.5812,\n                      0.5004, 0.4194, 0.8015, 0.4835, 0.4035, 0.4456, 0.3946, 0.3558, 0.5419,\n                      0.5156], dtype=torch.float64)),\n             ('4.0.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('4.0.convpath.0.2.0.weight',\n              tensor([[[ 0.0510],\n                       [ 0.0766],\n                       [-0.0025],\n                       ...,\n                       [-0.0554],\n                       [-0.0525],\n                       [ 0.0428]],\n              \n                      [[ 0.0090],\n                       [ 0.0900],\n                       [ 0.1719],\n                       ...,\n                       [-0.0947],\n                       [-0.3793],\n                       [ 0.2105]],\n              \n                      [[-0.0018],\n                       [-0.0758],\n                       [-0.0390],\n                       ...,\n                       [ 0.0780],\n                       [ 0.0383],\n                       [ 0.0042]],\n              \n                      ...,\n              \n                      [[-0.2673],\n                       [ 0.4015],\n                       [ 0.2070],\n                       ...,\n                       [-0.0480],\n                       [ 0.1154],\n                       [-0.0629]],\n              \n                      [[ 0.1003],\n                       [ 0.0125],\n                       [-0.1353],\n                       ...,\n                       [-0.0992],\n                       [-0.2238],\n                       [-0.0396]],\n              \n                      [[ 0.0412],\n                       [-0.0411],\n                       [ 0.2007],\n                       ...,\n                       [ 0.0877],\n                       [ 0.0523],\n                       [-0.1581]]], dtype=torch.float64)),\n             ('4.0.convpath.0.2.1.weight',\n              tensor([-0.0010,  0.0402,  0.0006,  0.0384,  0.0132, -0.0065,  0.0073, -0.0091,\n                       0.0104, -0.0024,  0.0054, -0.0013, -0.0206,  0.0208, -0.0056,  0.0108,\n                      -0.0260,  0.0484, -0.0011,  0.0179,  0.0156,  0.0038,  0.0161, -0.0147,\n                      -0.0097,  0.0317, -0.0101, -0.0127, -0.0042,  0.0111, -0.0005, -0.0376,\n                      -0.0006,  0.0352,  0.0710, -0.0191, -0.0097,  0.0267,  0.0012,  0.0079,\n                      -0.0208,  0.0053,  0.0088, -0.0134, -0.0229,  0.0100, -0.0093, -0.0089,\n                       0.0123, -0.0008,  0.0085, -0.0428, -0.0005,  0.0052,  0.0037,  0.0098,\n                      -0.0033, -0.0096,  0.0138,  0.0061,  0.0082, -0.0095,  0.0025, -0.0049,\n                      -0.0004, -0.0087,  0.0265,  0.0356,  0.0037,  0.0305, -0.0063, -0.0090,\n                       0.0142, -0.0099,  0.0276, -0.0231,  0.0164,  0.0078,  0.0274, -0.0125,\n                       0.0168,  0.0096,  0.0330,  0.0061,  0.0094, -0.0126,  0.0058,  0.0014,\n                      -0.0339,  0.0220, -0.0068,  0.0073, -0.0034,  0.0103, -0.0021, -0.0004,\n                      -0.0031, -0.0106, -0.0197, -0.0001,  0.0278, -0.0101,  0.0189,  0.0072,\n                      -0.0331,  0.0129, -0.0039,  0.0141, -0.0053,  0.0135, -0.0029, -0.0196,\n                       0.0276,  0.0122, -0.0034,  0.0069,  0.0124, -0.0056,  0.0090,  0.0121,\n                       0.0037,  0.0088, -0.0087, -0.0017, -0.0098, -0.0141, -0.0152,  0.0157,\n                      -0.0277, -0.0070,  0.0159,  0.0088,  0.0084,  0.0013,  0.0153,  0.0008,\n                      -0.0127,  0.0139, -0.0066, -0.0175,  0.0073,  0.0099, -0.0060,  0.0243,\n                      -0.0046,  0.0038,  0.0145, -0.0040,  0.0222,  0.0203,  0.0118,  0.0214,\n                      -0.0180, -0.0010,  0.0020,  0.0110, -0.0202,  0.0072,  0.0236,  0.0345,\n                      -0.0081, -0.0163, -0.0128,  0.0027,  0.0130,  0.0044,  0.0211, -0.0040,\n                      -0.0192, -0.0255,  0.0194,  0.0076,  0.0294, -0.0148,  0.0023,  0.0028,\n                       0.0003, -0.0173,  0.0132,  0.0154,  0.0065, -0.0255,  0.0008,  0.0121,\n                      -0.0048,  0.0058, -0.0021, -0.0283, -0.0153, -0.0152,  0.0045,  0.0068,\n                       0.0004, -0.0126, -0.0158,  0.0099, -0.0015,  0.0180,  0.0046,  0.0014,\n                      -0.0118, -0.0125,  0.0005,  0.0100, -0.0213,  0.0012,  0.0289,  0.0189,\n                      -0.0113, -0.0205, -0.0003, -0.0037, -0.0097,  0.0017,  0.0156, -0.0150,\n                      -0.0137, -0.0007, -0.0118, -0.0131, -0.0127, -0.0215, -0.0190,  0.0182,\n                      -0.0051, -0.0271, -0.0124,  0.0209,  0.0346, -0.0065,  0.0122, -0.0052,\n                       0.0243,  0.0228,  0.0050,  0.0172, -0.0099,  0.0012, -0.0091,  0.0051,\n                       0.0001,  0.0034, -0.0192, -0.0020,  0.0169, -0.0136, -0.0008, -0.0167,\n                      -0.0098, -0.0075, -0.0285, -0.0155, -0.0030, -0.0338, -0.0108,  0.0087],\n                     dtype=torch.float64)),\n             ('4.0.convpath.0.2.1.bias',\n              tensor([-7.2795e-04, -3.3469e-03,  2.5615e-02,  1.7376e-03,  9.3212e-03,\n                      -1.6753e-02, -2.9658e-03, -1.4160e-02, -1.3214e-02, -8.7208e-03,\n                      -4.9374e-03, -7.9470e-03,  3.0062e-03, -4.8956e-03, -6.4107e-03,\n                      -1.5175e-02, -1.8393e-02,  2.2720e-02,  4.0796e-03, -4.3133e-03,\n                       3.1041e-03, -1.9059e-02, -4.1501e-03,  3.6664e-04, -9.4798e-03,\n                      -2.1313e-02, -1.9297e-03, -4.5335e-03,  2.6222e-03,  3.8868e-03,\n                      -1.9928e-02, -1.3763e-02, -1.1673e-02, -2.0898e-02,  4.1412e-03,\n                      -1.5855e-02, -3.0226e-03,  4.0745e-03, -1.0940e-02, -1.7874e-02,\n                       4.3854e-03, -7.2711e-03, -1.7059e-02, -1.7811e-02,  7.7646e-03,\n                      -1.0010e-02, -1.3731e-02,  9.3924e-03, -1.1904e-02,  4.3385e-03,\n                      -4.3618e-03, -2.4723e-03,  2.6984e-03, -1.1851e-02, -7.9505e-03,\n                      -6.0253e-03, -4.7125e-04, -5.9180e-03, -1.4574e-02,  5.3121e-03,\n                      -8.4393e-03, -5.2493e-03, -2.3264e-02, -1.6835e-02, -1.1743e-02,\n                      -3.6267e-03, -3.6482e-03, -2.0177e-03, -2.1536e-02, -1.6293e-02,\n                       2.2893e-03, -6.6032e-04,  3.3575e-04, -4.7125e-03, -1.6277e-02,\n                      -1.6786e-02, -2.6764e-02, -1.9008e-02, -5.0277e-03, -1.6644e-02,\n                      -4.6247e-03, -4.1078e-04, -2.2868e-02, -4.6928e-03,  2.6562e-03,\n                      -1.7980e-02,  1.2481e-02,  1.6196e-02, -2.4499e-03,  2.4511e-03,\n                      -1.7947e-02, -4.6330e-03, -1.5217e-02,  4.2939e-03, -5.1057e-03,\n                      -1.4797e-02,  9.6003e-04, -1.2330e-02,  2.5038e-04, -1.0838e-02,\n                       2.3859e-03, -3.7735e-03, -1.2845e-02, -1.1175e-02, -6.7415e-04,\n                       7.2692e-03, -1.1312e-02, -7.4839e-03, -7.9239e-03, -1.2597e-02,\n                      -8.5915e-03, -5.0790e-03,  1.0275e-03,  1.2115e-03, -4.7034e-03,\n                      -4.8503e-03, -6.4275e-03, -7.3991e-03,  5.8259e-03, -2.2010e-03,\n                      -7.3446e-03, -2.2270e-02, -1.3333e-03, -8.2732e-03, -9.4862e-03,\n                      -8.1979e-03, -1.1344e-02,  1.8440e-03,  1.3599e-03, -2.0410e-02,\n                      -9.6839e-03, -7.9098e-03, -3.7910e-03,  1.5697e-05, -6.5700e-03,\n                      -2.1605e-02,  4.2204e-03,  4.0283e-04, -6.4831e-03, -2.0593e-03,\n                      -2.3457e-03,  1.9256e-03, -1.2860e-02, -2.6430e-03, -1.8717e-02,\n                      -1.6861e-02, -1.3022e-02, -1.0280e-02, -1.2432e-03,  1.0246e-02,\n                      -9.3326e-03, -1.5284e-02, -2.7686e-02, -1.0454e-02, -7.1254e-03,\n                      -3.7724e-03,  1.0640e-02,  2.7505e-03, -1.3317e-02, -2.0494e-02,\n                      -7.4842e-03,  2.7243e-02, -9.6145e-03, -3.3994e-03, -5.4003e-03,\n                       4.5228e-03, -8.3312e-03,  2.8939e-02,  1.1500e-04, -2.9051e-02,\n                      -7.2565e-04, -1.3314e-03, -7.2075e-03, -5.3022e-03, -1.7320e-02,\n                      -1.6683e-02, -7.8974e-03,  1.4435e-02, -1.1474e-02, -3.6701e-04,\n                      -1.9463e-03,  2.1519e-02, -1.1158e-02,  2.4624e-03, -4.5132e-03,\n                      -7.7967e-03, -6.0586e-03,  1.3910e-02, -9.0865e-03, -1.1510e-02,\n                      -7.4502e-03, -1.8166e-02, -6.3183e-03, -2.0461e-02, -8.9440e-03,\n                       6.6549e-04, -3.2089e-03, -1.2933e-02, -7.0443e-03, -1.4368e-02,\n                      -8.0977e-03, -1.3865e-02,  9.2988e-03, -1.1243e-02, -3.2124e-03,\n                      -9.6305e-03, -4.0261e-03, -1.5690e-02, -7.7035e-03, -2.3680e-02,\n                       2.4345e-03, -4.0755e-03, -8.5092e-04, -5.7477e-03, -2.0849e-03,\n                       1.8883e-02, -4.3178e-03,  1.6819e-02,  3.9807e-03, -2.4423e-03,\n                       2.5718e-03, -2.9551e-03, -1.3181e-02, -1.3747e-03, -2.2727e-02,\n                       5.7089e-03,  4.4769e-03,  6.1698e-03, -2.0630e-02, -1.0333e-02,\n                       5.9753e-04,  2.3022e-03,  2.1443e-03,  7.5890e-03, -1.0112e-02,\n                      -3.6802e-03,  6.6059e-03,  7.0752e-03, -1.1512e-02, -7.2608e-03,\n                      -7.2489e-03,  3.3995e-03, -1.0654e-02, -1.1668e-02, -8.9250e-03,\n                      -6.6219e-03, -7.4274e-04,  5.4266e-03, -5.8644e-03, -1.6624e-02,\n                      -7.5053e-03, -7.3289e-03, -1.2267e-02, -5.6282e-03,  4.0937e-05,\n                      -5.9866e-04], dtype=torch.float64)),\n             ('4.0.convpath.0.2.1.running_mean',\n              tensor([-1.1578e-01,  1.4158e-01,  2.6433e-01,  3.2712e-01, -1.5668e-02,\n                       1.3126e-01, -2.0683e-02,  1.0507e-01,  2.1800e-03,  1.4118e-01,\n                      -9.5007e-02,  1.9489e-01,  2.0697e-01, -1.8849e-01,  2.4983e-01,\n                       4.3032e-02,  3.2477e-01, -5.4898e-01,  3.7983e-02,  3.7709e-01,\n                      -1.3353e-01, -3.6700e-01, -2.4383e-01,  3.5948e-01, -1.9123e-02,\n                      -6.4727e-02, -2.1877e-01, -2.0409e-02,  1.4432e-01,  5.2703e-02,\n                      -6.1961e-01,  3.3659e-01, -9.3631e-02, -1.0217e-01, -2.5888e-01,\n                       7.7050e-02,  3.5075e-01, -9.0172e-02, -1.0995e-01, -2.3505e-01,\n                      -8.0178e-01, -2.9860e-02,  1.7033e-01, -7.1453e-01, -4.1577e-01,\n                      -1.2391e-01, -2.0914e-01,  7.5619e-02, -2.9508e-01,  3.5578e-02,\n                      -9.6041e-02, -3.0559e-01,  2.7696e-01, -1.6429e-02, -4.4110e-01,\n                      -2.0352e-01, -1.3997e-02, -2.9686e-01,  1.9188e-01, -1.0232e-01,\n                       7.4081e-02,  2.4853e-01, -1.7221e-01,  1.6841e-01,  5.1837e-01,\n                      -1.8933e-02, -5.8636e-01,  2.9902e-02, -1.9554e-01,  1.4545e-01,\n                      -2.5608e-01,  3.5397e-02, -3.4241e-01, -1.6359e-01,  3.4897e-02,\n                      -4.1212e-01,  7.8959e-02, -3.3743e-01, -3.3751e-02,  3.1742e-01,\n                      -3.1577e-01,  2.2491e-01, -7.6560e-01, -7.6081e-01,  2.3304e-02,\n                      -2.2236e-03, -2.4009e-01, -2.0231e-02, -1.2668e-01, -1.6607e-01,\n                      -9.2332e-03,  2.1212e-01, -2.3443e-03,  1.5779e-01,  1.7743e-01,\n                       2.9531e-01,  7.7745e-02,  3.0311e-01, -1.6115e-01, -7.2446e-02,\n                      -9.6247e-02,  2.2273e-01, -2.4288e-01, -1.9972e-01,  1.8564e-01,\n                       1.7285e-01,  2.0827e-01, -1.1654e-01,  2.4553e-01,  1.0188e-01,\n                      -2.0252e-02,  6.3375e-02, -2.1360e-01, -3.4964e-01, -1.0912e-01,\n                      -4.0965e-02, -2.0619e-01, -3.6362e-01, -1.3493e-02, -1.0500e-01,\n                      -2.2794e-03,  3.3153e-02,  1.5774e-01,  4.6913e-02, -8.1025e-02,\n                      -2.7331e-01,  7.1843e-02, -3.2702e-01, -9.6831e-02, -4.8345e-01,\n                      -1.1988e-01, -1.3751e-01, -1.6979e-01,  2.5665e-01,  5.1327e-01,\n                      -1.8191e-01,  1.0861e-01,  4.3320e-01, -4.0506e-01, -2.0047e-02,\n                       1.5334e-01, -3.3304e-01,  1.2437e-01, -7.6602e-03, -2.7165e-02,\n                      -1.5085e-01, -6.8762e-02, -5.6192e-02, -2.0192e-01, -3.6609e-01,\n                       3.8151e-01,  1.5476e-02,  6.4966e-01,  7.7298e-02,  2.2244e-01,\n                      -1.1717e-02, -2.1701e-01,  2.1672e-01, -1.0395e-01, -2.9592e-01,\n                       9.3124e-02, -4.1344e-01,  4.3611e-02, -1.0612e-02, -4.2286e-02,\n                      -2.7401e-01,  2.2494e-02, -1.4385e-01,  6.9536e-02,  2.0816e-01,\n                      -9.1477e-03, -1.5681e-01,  3.4120e-01, -2.2300e-01, -2.9704e-01,\n                       6.0341e-01,  3.9542e-03,  2.3698e-01, -9.6631e-03, -2.2206e-01,\n                       2.4525e-01,  4.4015e-01, -1.4203e-02,  4.0267e-02, -4.8545e-01,\n                      -1.3542e-01, -7.8458e-01,  1.6526e-01,  1.3926e-01,  4.4294e-01,\n                       3.2859e-01,  4.3802e-01, -1.5863e-01,  1.9650e-01, -1.3072e-01,\n                      -3.1467e-01, -1.8309e-01, -1.3033e-01, -1.4226e-01,  2.8452e-02,\n                       1.7161e-01, -1.2408e-01,  5.2814e-02, -3.7975e-02,  6.3113e-01,\n                       1.3134e-01, -1.9547e-02, -1.0505e-01, -2.3531e-01, -7.9773e-04,\n                       5.9743e-02, -4.5676e-01,  3.7886e-02,  1.0505e-01, -2.2532e-01,\n                       2.5387e-01,  1.0116e-01, -2.0516e-01,  4.4582e-01,  3.8690e-02,\n                      -1.1023e-01,  3.5275e-01,  1.0583e-01,  1.2915e-01, -1.2746e-01,\n                      -2.0916e-01,  2.9274e-01,  4.6588e-01,  5.3821e-01,  5.1901e-01,\n                       8.0596e-03, -2.5919e-01, -1.0843e-01,  1.1232e-01, -1.9445e-02,\n                      -5.7027e-02, -4.8326e-01, -4.4388e-02, -4.1745e-02, -2.8202e-01,\n                      -6.7727e-02,  4.1758e-01,  9.1063e-03,  1.3424e-01,  3.5230e-02,\n                      -1.4623e-01, -1.9179e-01,  1.4743e-01, -1.6192e-01, -5.8794e-02,\n                      -1.2120e-02,  3.0112e-01,  3.7555e-02,  1.6582e-01, -6.7952e-01,\n                       2.5598e-02], dtype=torch.float64)),\n             ('4.0.convpath.0.2.1.running_var',\n              tensor([0.0440, 0.2857, 0.1033, 0.2448, 0.3563, 0.1937, 0.1337, 0.2884, 0.1091,\n                      0.1761, 0.1045, 0.0666, 0.1426, 0.2953, 0.1207, 0.1117, 0.5159, 0.5097,\n                      0.1532, 0.2480, 0.3501, 0.2698, 0.2317, 0.2921, 0.3286, 0.1704, 0.2739,\n                      0.2797, 0.1319, 0.1786, 0.2394, 0.0964, 0.1558, 0.2645, 0.2080, 0.3394,\n                      0.1451, 0.2790, 0.0968, 0.4124, 0.3920, 0.2663, 0.1148, 0.2325, 0.3037,\n                      0.1625, 0.1277, 0.2137, 0.1788, 0.1150, 0.1502, 0.3963, 0.1191, 0.1766,\n                      0.1890, 0.1666, 0.0719, 0.4495, 0.2533, 0.3538, 0.1134, 0.1574, 0.0734,\n                      0.0910, 0.2351, 0.1066, 0.3052, 0.4823, 0.0396, 0.4310, 0.2640, 0.0735,\n                      0.0970, 0.2930, 0.3959, 0.1075, 0.1271, 0.2847, 0.2928, 0.1708, 0.3483,\n                      0.1331, 0.6839, 0.3315, 0.3486, 0.5451, 0.1625, 0.1535, 0.3277, 0.2665,\n                      0.4893, 0.1868, 0.0580, 0.1631, 0.0956, 0.0799, 0.1306, 0.2312, 0.1964,\n                      0.0974, 0.3483, 0.3551, 0.1420, 0.1951, 0.1435, 0.0892, 0.3026, 0.3772,\n                      0.1125, 0.1552, 0.0349, 0.4046, 0.3363, 0.1188, 0.1225, 0.1267, 0.1440,\n                      0.2832, 0.2235, 0.2327, 0.0582, 0.1301, 0.2916, 0.1054, 0.1908, 0.3913,\n                      0.1391, 0.1453, 0.3321, 0.1705, 0.0293, 0.1460, 0.3621, 0.1140, 0.1441,\n                      0.0590, 0.0849, 0.2686, 0.1033, 0.1844, 0.2728, 0.1213, 0.0854, 0.0808,\n                      0.0745, 0.2571, 0.1096, 0.1771, 0.2132, 0.3038, 0.3986, 0.1302, 0.2823,\n                      0.0682, 0.0777, 0.2564, 0.2812, 0.1103, 0.1522, 0.1747, 0.0965, 0.2222,\n                      0.0937, 0.1136, 0.4563, 0.3573, 0.4113, 0.0869, 0.3864, 0.2886, 0.1573,\n                      0.0773, 0.2260, 0.0569, 0.2749, 0.2269, 0.1054, 0.3876, 0.1265, 0.0741,\n                      0.1075, 0.1540, 0.1516, 0.2364, 0.2387, 0.1255, 0.2923, 0.1504, 0.0875,\n                      0.1135, 0.2501, 0.2611, 0.0729, 0.1050, 0.1732, 0.3203, 0.1575, 0.1567,\n                      0.2064, 0.0633, 0.1708, 0.0617, 0.2209, 0.2549, 0.2912, 0.1254, 0.1321,\n                      0.1858, 0.1188, 0.2069, 0.0344, 0.0983, 0.1908, 0.1725, 0.1557, 0.2547,\n                      0.1866, 0.0839, 0.2703, 0.4347, 0.1338, 0.2202, 0.0702, 0.2719, 0.2316,\n                      0.3331, 0.1303, 0.3630, 0.3517, 0.2471, 0.1121, 0.1939, 0.3163, 0.2394,\n                      0.0734, 0.2661, 0.3263, 0.0634, 0.2345, 0.1950, 0.0961, 0.2340, 0.3849,\n                      0.1130, 0.2686, 0.1005, 0.0476, 0.3965, 0.1334, 0.1252, 0.3284, 0.2387,\n                      0.1090, 0.2877, 0.2772, 0.0949], dtype=torch.float64)),\n             ('4.0.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('4.0.idpath.0.0.weight',\n              tensor([[[ 0.2371],\n                       [-0.1335],\n                       [-0.0465],\n                       ...,\n                       [-0.1835],\n                       [-0.0722],\n                       [-0.0436]],\n              \n                      [[ 0.1941],\n                       [ 0.0505],\n                       [ 0.2099],\n                       ...,\n                       [-0.0588],\n                       [-0.1481],\n                       [ 0.3503]],\n              \n                      [[ 0.0784],\n                       [-0.0999],\n                       [-0.0270],\n                       ...,\n                       [ 0.2961],\n                       [-0.0964],\n                       [ 0.0357]],\n              \n                      ...,\n              \n                      [[-0.2864],\n                       [ 0.0104],\n                       [ 0.4332],\n                       ...,\n                       [-0.1639],\n                       [ 0.1635],\n                       [ 0.2124]],\n              \n                      [[-0.3100],\n                       [ 0.1112],\n                       [ 0.1256],\n                       ...,\n                       [-0.2260],\n                       [ 0.0033],\n                       [-0.1250]],\n              \n                      [[-0.3756],\n                       [-0.1132],\n                       [ 0.2205],\n                       ...,\n                       [ 0.2625],\n                       [-0.0005],\n                       [ 0.1064]]], dtype=torch.float64)),\n             ('4.0.idpath.0.1.weight',\n              tensor([0.9899, 0.9824, 0.9867, 0.9679, 0.9973, 0.9892, 0.9583, 0.9404, 0.9615,\n                      0.9586, 0.9701, 0.9832, 0.9786, 0.9867, 0.9710, 0.9294, 0.9548, 0.9788,\n                      0.9627, 0.9578, 0.9739, 0.9662, 0.9949, 0.9772, 0.9567, 0.9724, 0.9845,\n                      0.9837, 0.9708, 0.9963, 0.9528, 0.9863, 1.0066, 0.9463, 0.9603, 0.9606,\n                      0.9729, 1.0011, 0.9757, 0.9697, 0.9732, 0.9775, 0.9606, 0.9744, 0.9868,\n                      0.9760, 0.9787, 0.9791, 0.9345, 0.9854, 1.0190, 1.0158, 0.9773, 0.9724,\n                      0.9816, 0.9519, 0.9817, 0.9234, 0.9368, 1.0043, 0.9823, 0.9696, 0.9711,\n                      0.9843, 0.9397, 0.9648, 0.9767, 0.9516, 0.9720, 0.9588, 0.9889, 0.9830,\n                      0.9764, 0.9731, 0.9502, 0.9751, 0.9602, 0.9705, 0.9735, 0.9602, 0.9886,\n                      0.9951, 0.9676, 0.9561, 0.9720, 0.9620, 0.9869, 0.9823, 0.9570, 0.9744,\n                      0.9620, 0.9792, 0.9648, 0.9761, 0.9881, 0.9818, 0.9535, 0.9648, 0.9865,\n                      0.9678, 0.9452, 0.9687, 0.9472, 0.9923, 0.9709, 0.9663, 0.9583, 0.9719,\n                      0.9608, 0.9806, 0.9737, 0.9827, 0.9671, 0.9711, 0.9711, 0.9621, 0.9691,\n                      0.9510, 0.9827, 0.9779, 0.9810, 0.9487, 0.9751, 0.9684, 0.9717, 0.9313,\n                      0.9700, 0.9847, 0.9775, 0.9662, 0.9711, 0.9684, 0.9756, 0.9507, 0.9763,\n                      0.9642, 0.9899, 0.9498, 0.9751, 0.9727, 0.9932, 0.9663, 0.9639, 0.9772,\n                      0.9708, 0.9459, 0.9901, 0.9599, 0.9720, 0.9931, 0.9517, 0.9690, 0.9540,\n                      0.9521, 0.9547, 0.9940, 0.9938, 0.9691, 0.9623, 0.9908, 0.9780, 0.9787,\n                      0.9626, 0.9590, 0.9565, 0.9826, 0.9616, 0.9626, 0.9545, 0.9438, 0.9604,\n                      0.9647, 0.9671, 0.9750, 0.9663, 0.9644, 0.9725, 0.9607, 0.9718, 0.9748,\n                      0.9791, 0.9593, 0.9779, 0.9776, 0.9611, 0.9653, 0.9592, 0.9726, 0.9787,\n                      0.9741, 0.9462, 0.9669, 0.9383, 0.9544, 0.9553, 0.9541, 0.9711, 0.9869,\n                      0.9726, 0.9643, 0.9848, 0.9401, 0.9652, 0.9685, 0.9784, 0.9838, 0.9782,\n                      0.9645, 0.9837, 0.9679, 0.9736, 0.9738, 0.9907, 0.9538, 0.9618, 0.9776,\n                      0.9695, 0.9916, 0.9942, 0.9467, 0.9680, 0.9828, 0.9716, 0.9848, 0.9423,\n                      0.9755, 0.9756, 0.9802, 0.9567, 0.9511, 0.9770, 0.9797, 0.9755, 0.9649,\n                      0.9667, 0.9578, 0.9769, 0.9926, 0.9693, 0.9522, 0.9628, 0.9777, 0.9542,\n                      0.9772, 0.9768, 0.9743, 0.9740, 0.9384, 0.9838, 0.9520, 0.9527, 0.9462,\n                      0.9894, 0.9455, 0.9685, 0.9804], dtype=torch.float64)),\n             ('4.0.idpath.0.1.bias',\n              tensor([-7.2795e-04, -3.3469e-03,  2.5615e-02,  1.7376e-03,  9.3212e-03,\n                      -1.6753e-02, -2.9658e-03, -1.4160e-02, -1.3214e-02, -8.7208e-03,\n                      -4.9374e-03, -7.9470e-03,  3.0062e-03, -4.8956e-03, -6.4107e-03,\n                      -1.5175e-02, -1.8393e-02,  2.2720e-02,  4.0796e-03, -4.3133e-03,\n                       3.1041e-03, -1.9059e-02, -4.1501e-03,  3.6664e-04, -9.4798e-03,\n                      -2.1313e-02, -1.9297e-03, -4.5335e-03,  2.6222e-03,  3.8868e-03,\n                      -1.9928e-02, -1.3763e-02, -1.1673e-02, -2.0898e-02,  4.1412e-03,\n                      -1.5855e-02, -3.0226e-03,  4.0745e-03, -1.0940e-02, -1.7874e-02,\n                       4.3854e-03, -7.2711e-03, -1.7059e-02, -1.7811e-02,  7.7646e-03,\n                      -1.0010e-02, -1.3731e-02,  9.3924e-03, -1.1904e-02,  4.3385e-03,\n                      -4.3618e-03, -2.4723e-03,  2.6984e-03, -1.1851e-02, -7.9505e-03,\n                      -6.0253e-03, -4.7125e-04, -5.9180e-03, -1.4574e-02,  5.3121e-03,\n                      -8.4393e-03, -5.2493e-03, -2.3264e-02, -1.6835e-02, -1.1743e-02,\n                      -3.6267e-03, -3.6482e-03, -2.0177e-03, -2.1536e-02, -1.6293e-02,\n                       2.2893e-03, -6.6032e-04,  3.3575e-04, -4.7125e-03, -1.6277e-02,\n                      -1.6786e-02, -2.6764e-02, -1.9008e-02, -5.0277e-03, -1.6644e-02,\n                      -4.6247e-03, -4.1078e-04, -2.2868e-02, -4.6928e-03,  2.6562e-03,\n                      -1.7980e-02,  1.2481e-02,  1.6196e-02, -2.4499e-03,  2.4511e-03,\n                      -1.7947e-02, -4.6330e-03, -1.5217e-02,  4.2939e-03, -5.1057e-03,\n                      -1.4797e-02,  9.6003e-04, -1.2330e-02,  2.5038e-04, -1.0838e-02,\n                       2.3859e-03, -3.7735e-03, -1.2845e-02, -1.1175e-02, -6.7415e-04,\n                       7.2692e-03, -1.1312e-02, -7.4839e-03, -7.9239e-03, -1.2597e-02,\n                      -8.5915e-03, -5.0790e-03,  1.0275e-03,  1.2115e-03, -4.7034e-03,\n                      -4.8503e-03, -6.4275e-03, -7.3991e-03,  5.8259e-03, -2.2010e-03,\n                      -7.3446e-03, -2.2270e-02, -1.3333e-03, -8.2732e-03, -9.4862e-03,\n                      -8.1979e-03, -1.1344e-02,  1.8440e-03,  1.3599e-03, -2.0410e-02,\n                      -9.6839e-03, -7.9098e-03, -3.7910e-03,  1.5697e-05, -6.5700e-03,\n                      -2.1605e-02,  4.2204e-03,  4.0283e-04, -6.4831e-03, -2.0593e-03,\n                      -2.3457e-03,  1.9256e-03, -1.2860e-02, -2.6430e-03, -1.8717e-02,\n                      -1.6861e-02, -1.3022e-02, -1.0280e-02, -1.2432e-03,  1.0246e-02,\n                      -9.3326e-03, -1.5284e-02, -2.7686e-02, -1.0454e-02, -7.1254e-03,\n                      -3.7724e-03,  1.0640e-02,  2.7505e-03, -1.3317e-02, -2.0494e-02,\n                      -7.4842e-03,  2.7243e-02, -9.6145e-03, -3.3994e-03, -5.4003e-03,\n                       4.5228e-03, -8.3312e-03,  2.8939e-02,  1.1500e-04, -2.9051e-02,\n                      -7.2565e-04, -1.3314e-03, -7.2075e-03, -5.3022e-03, -1.7320e-02,\n                      -1.6683e-02, -7.8974e-03,  1.4435e-02, -1.1474e-02, -3.6701e-04,\n                      -1.9463e-03,  2.1519e-02, -1.1158e-02,  2.4624e-03, -4.5132e-03,\n                      -7.7967e-03, -6.0586e-03,  1.3910e-02, -9.0865e-03, -1.1510e-02,\n                      -7.4502e-03, -1.8166e-02, -6.3183e-03, -2.0461e-02, -8.9440e-03,\n                       6.6549e-04, -3.2089e-03, -1.2933e-02, -7.0443e-03, -1.4368e-02,\n                      -8.0977e-03, -1.3865e-02,  9.2988e-03, -1.1243e-02, -3.2124e-03,\n                      -9.6305e-03, -4.0261e-03, -1.5690e-02, -7.7035e-03, -2.3680e-02,\n                       2.4345e-03, -4.0755e-03, -8.5092e-04, -5.7477e-03, -2.0849e-03,\n                       1.8883e-02, -4.3178e-03,  1.6819e-02,  3.9807e-03, -2.4423e-03,\n                       2.5718e-03, -2.9551e-03, -1.3181e-02, -1.3747e-03, -2.2727e-02,\n                       5.7089e-03,  4.4769e-03,  6.1698e-03, -2.0630e-02, -1.0333e-02,\n                       5.9753e-04,  2.3022e-03,  2.1443e-03,  7.5890e-03, -1.0112e-02,\n                      -3.6802e-03,  6.6059e-03,  7.0752e-03, -1.1512e-02, -7.2608e-03,\n                      -7.2489e-03,  3.3995e-03, -1.0654e-02, -1.1668e-02, -8.9250e-03,\n                      -6.6219e-03, -7.4274e-04,  5.4266e-03, -5.8644e-03, -1.6624e-02,\n                      -7.5053e-03, -7.3289e-03, -1.2267e-02, -5.6282e-03,  4.0937e-05,\n                      -5.9866e-04], dtype=torch.float64)),\n             ('4.0.idpath.0.1.running_mean',\n              tensor([-8.6970e-01, -8.2516e-01,  1.6050e-01, -8.8245e-01,  4.2306e-01,\n                      -4.2279e-01,  6.2539e-01, -9.7500e-01,  9.2605e-01, -4.4388e-01,\n                       9.0721e-03,  4.7329e-02,  1.7502e+00, -1.0152e+00, -1.5604e-01,\n                       4.0949e-01,  7.2314e-01,  1.1869e-01,  9.5216e-01, -1.2153e+00,\n                      -2.6923e-01, -9.1367e-01, -3.8530e-01,  4.5628e-02, -5.0288e-01,\n                       2.7304e-01,  3.3925e-01,  8.9459e-01,  5.0166e-01, -5.3240e-01,\n                      -1.1842e+00,  5.1935e-01,  4.5725e-01,  1.3716e-01,  1.9574e-01,\n                      -1.1665e+00,  1.0351e-01, -1.4172e-01,  7.7860e-01, -4.0838e-01,\n                      -1.3988e+00,  1.0766e+00,  5.2660e-01, -5.4874e-01, -1.1154e+00,\n                      -1.4901e+00,  4.0023e-01, -7.1698e-01, -9.1563e-01, -1.1361e+00,\n                       2.4823e-01,  3.1645e-01, -4.7132e-01, -6.6839e-01, -1.9266e-01,\n                       2.1838e-01,  2.5450e-01, -1.6479e-02, -1.6050e+00,  7.7678e-01,\n                       4.9202e-01, -7.8607e-01, -2.7392e-01,  4.5334e-02,  4.1335e-02,\n                      -8.4635e-01, -9.8035e-01,  1.5407e+00,  3.5765e-01, -9.7200e-01,\n                       3.8787e-02,  1.0361e+00,  6.0907e-01, -1.7030e+00, -5.0448e-01,\n                       6.1244e-01, -1.8063e-02,  6.6493e-02, -1.2145e+00,  1.4848e+00,\n                       2.7367e-01, -3.5150e-01,  1.6714e+00, -4.3504e-01,  2.4836e-01,\n                      -7.1685e-01,  8.2183e-01,  8.1651e-01, -7.2221e-01,  5.1031e-01,\n                      -5.1642e-01, -4.6254e-01,  4.9409e-01,  9.9144e-01, -8.1668e-01,\n                      -9.5168e-02, -1.1251e+00,  1.1677e+00, -4.1693e-01,  2.5504e-01,\n                      -5.9776e-01, -1.0607e+00,  5.7104e-02,  2.6060e-01, -4.8110e-01,\n                       7.9906e-01, -2.1088e+00, -4.1257e-01, -8.3475e-02,  6.7099e-01,\n                       1.1993e+00, -4.4357e-01,  5.2180e-02, -4.7694e-01, -9.5645e-02,\n                      -2.7651e-01, -8.4560e-01, -9.5772e-01, -1.0573e+00, -1.2443e+00,\n                       1.0095e+00,  1.8683e-01, -3.0580e-01, -2.0634e-01,  1.1915e+00,\n                      -1.4900e+00,  8.4578e-01,  3.9342e-01,  1.2837e+00, -6.0713e-01,\n                       7.5764e-01,  1.1367e-01,  1.6267e-01, -3.5308e-02,  1.4314e+00,\n                      -4.6808e-01,  9.6316e-01,  6.4256e-01,  2.6801e-01,  7.5102e-01,\n                       1.3269e-01, -1.0062e-01,  1.2450e-01,  6.6281e-01,  8.1846e-02,\n                      -1.2012e+00,  6.7323e-01, -5.0267e-01,  2.4565e+00, -7.4361e-01,\n                      -6.8567e-01,  3.5940e-01,  4.6306e-01,  6.1766e-01,  4.3343e-02,\n                      -4.4528e-01,  3.3705e-01, -1.0960e-01, -1.1754e+00,  5.5523e-01,\n                       7.4601e-01, -2.1780e-03, -2.0420e-01,  7.0929e-01, -2.4277e-01,\n                       2.4057e-01, -2.2474e-01, -4.0028e-01, -5.2164e-01,  9.3689e-01,\n                       3.5607e-01, -7.5025e-01, -1.3103e-01,  1.0985e+00, -1.1013e+00,\n                      -9.5393e-01,  1.2212e+00,  1.0217e+00, -3.1593e-01,  8.6217e-01,\n                      -3.1014e-01,  6.5259e-01, -1.0998e+00, -8.7326e-01,  3.7408e-02,\n                      -3.2071e-01, -7.6094e-01,  7.7311e-01, -1.1076e-01, -2.3043e-01,\n                       1.0631e+00,  2.0589e-01,  9.3177e-01, -9.5634e-01,  1.3776e-01,\n                       1.1256e+00, -1.4307e-01,  9.4384e-01, -5.9184e-01,  7.4670e-01,\n                       9.7137e-01, -5.6466e-01, -4.4352e-01,  5.1614e-01, -6.7271e-01,\n                       7.2162e-02,  2.8954e-01,  5.5429e-01, -1.4097e-01, -1.9983e-02,\n                       7.1585e-01, -7.9685e-01,  6.9718e-01, -1.2441e+00,  1.1940e+00,\n                      -5.4630e-01, -2.5207e-01,  4.6007e-01,  1.9865e-01, -1.1386e+00,\n                       8.3696e-02, -2.1574e-01,  3.1598e-01,  4.7775e-01, -3.3512e-01,\n                      -1.0837e+00,  5.3130e-01,  2.3767e-01, -1.2309e+00, -5.4910e-01,\n                       4.5156e-01, -5.6311e-01, -8.1764e-01,  6.0986e-01,  3.6265e-01,\n                      -4.5807e-01,  7.2268e-01,  1.5520e+00, -7.3990e-01, -4.9021e-02,\n                       1.3154e-03,  1.3057e+00, -1.8731e+00,  5.4473e-01,  4.7733e-01,\n                       1.6615e+00, -4.8027e-02, -8.9125e-01,  1.4895e-01, -2.8089e-01,\n                      -1.5938e+00, -1.5455e+00,  7.0318e-01, -6.3224e-01,  3.9002e-02,\n                       1.3062e+00], dtype=torch.float64)),\n             ('4.0.idpath.0.1.running_var',\n              tensor([ 1.9735,  1.0589,  0.9439,  2.3606,  0.3837,  0.6868,  1.8396,  2.1076,\n                       1.8944,  1.2805,  0.7085,  0.7145,  7.2122,  0.6963,  2.2533,  0.5292,\n                       0.9283,  0.5410,  3.0329,  2.9820,  0.7840,  1.1018,  0.6320,  0.7323,\n                       1.7575,  0.8180,  1.2420,  0.6876,  0.9854,  0.7350,  5.0564,  0.6087,\n                       0.6169,  2.6058,  0.5291,  3.4094,  1.0299,  1.7693,  2.2843,  1.9488,\n                       1.9768,  2.2614,  2.4679,  2.2254,  1.3204,  1.8735,  0.7190,  0.6510,\n                       3.8796,  2.6322,  1.2914,  0.5280,  1.1995,  0.5019,  0.8760,  1.8457,\n                       0.9077,  0.9282,  3.7612,  0.6882,  1.2123,  0.9193,  0.6479,  0.4345,\n                       0.8827,  0.9133,  1.4090,  2.9678,  0.8500,  1.9771,  1.8851,  3.0204,\n                       2.4805,  6.2572,  1.6480,  0.9106,  0.5279,  1.1849,  1.7936,  2.7412,\n                       0.6881,  1.4495,  6.7257,  0.9887,  0.6177,  1.6697,  1.9935,  2.1764,\n                       1.1930,  1.2355,  1.1046,  0.9980,  1.3488,  3.1240,  1.0524,  0.5291,\n                       3.6403,  4.3432,  0.6661,  1.1114,  3.0617,  2.0828,  1.3908,  1.7715,\n                       0.8661,  1.0497,  6.6596,  1.0690,  1.0039,  1.5976,  0.6176,  0.7111,\n                       1.2118,  0.9582,  0.7753,  1.6378,  0.6582,  1.4629,  1.1347,  1.9292,\n                       2.7711,  0.5357,  1.5731,  0.4397,  3.0211,  3.8856,  3.0786,  0.9955,\n                       1.3218,  0.8695,  1.6273,  3.1703,  0.7497,  0.7026,  3.4062,  0.7240,\n                       1.2437,  2.6632,  0.8349,  1.5747,  0.4706,  0.6963,  0.4345,  2.2579,\n                       1.3429,  2.5957,  1.0827,  2.3778, 11.6310,  1.0481,  1.4111,  1.1156,\n                       0.8163,  1.0057,  1.1022,  1.6909,  0.5027,  0.5590,  2.7165,  0.7544,\n                       0.9671,  0.7275,  0.4158,  0.9332,  1.1163,  0.6228,  1.7176,  0.6107,\n                       0.6323,  1.7734,  0.7796,  1.4262,  0.5023,  2.5458,  1.9236,  4.3499,\n                       4.0910,  2.5112,  0.8166,  1.2770,  0.6852,  1.5082,  2.8645,  2.2191,\n                       0.6928,  1.9947,  0.7945,  1.8441,  0.8695,  0.4899,  0.9763,  0.7612,\n                       3.0937,  3.0861,  1.2594,  1.1940,  0.5873,  1.8800,  1.3293,  0.6910,\n                       2.8291,  0.4372,  0.5007,  1.0439,  2.2434,  1.2281,  0.9088,  1.4714,\n                       0.7049,  0.5277,  3.8043,  2.6656,  1.6304,  2.3733,  2.6948,  0.5541,\n                       1.3079,  0.6591,  0.8858,  2.0043,  0.6880,  1.0870,  1.7150,  0.5049,\n                       2.7604,  1.2065,  1.0442,  0.7567,  1.4004,  1.9523,  1.3694,  0.7225,\n                       0.8776,  0.6733,  1.0029,  1.4279,  0.7410,  1.5281,  1.3873,  0.8646,\n                       1.1651,  3.7680,  4.5964,  0.6861,  1.5415,  4.8437,  0.9516,  1.4149,\n                       0.4324,  1.5701,  4.9608,  2.8930,  3.2516,  0.9578,  2.3832,  4.0033],\n                     dtype=torch.float64)),\n             ('4.0.idpath.0.1.num_batches_tracked', tensor(11419)),\n             ('4.1.convs.0.0.weight',\n              tensor([[[ 0.0433],\n                       [ 0.0729],\n                       [ 0.0497],\n                       ...,\n                       [ 0.0378],\n                       [-0.0217],\n                       [ 0.0320]],\n              \n                      [[-0.0893],\n                       [ 0.0643],\n                       [ 0.1649],\n                       ...,\n                       [ 0.1981],\n                       [ 0.0114],\n                       [ 0.1326]],\n              \n                      [[-0.0556],\n                       [ 0.0464],\n                       [ 0.2254],\n                       ...,\n                       [ 0.0318],\n                       [-0.0813],\n                       [-0.1020]],\n              \n                      ...,\n              \n                      [[ 0.0480],\n                       [ 0.0273],\n                       [-0.1232],\n                       ...,\n                       [-0.1617],\n                       [ 0.0991],\n                       [-0.0936]],\n              \n                      [[-0.1003],\n                       [-0.0633],\n                       [ 0.0894],\n                       ...,\n                       [-0.0121],\n                       [ 0.0503],\n                       [ 0.0952]],\n              \n                      [[-0.1189],\n                       [-0.0043],\n                       [ 0.0023],\n                       ...,\n                       [-0.1041],\n                       [ 0.0674],\n                       [ 0.1825]]], dtype=torch.float64)),\n             ('4.1.convs.0.1.weight',\n              tensor([1.0034, 0.9469, 0.9723, 0.9739, 0.9762, 0.9611, 0.9750, 0.9575, 0.9692,\n                      0.9740, 0.9631, 0.9902, 0.9811, 0.9544, 0.9580, 0.9519, 0.9656, 0.9779,\n                      0.9203, 0.9478, 0.9605, 0.9497, 0.9386, 0.9533, 0.9459, 0.9430, 0.9711,\n                      0.9746, 0.9570, 0.9580, 0.9550, 0.9575, 0.9650, 0.9662, 0.9379, 0.9584,\n                      0.9631, 0.9687, 0.9597, 0.9515, 0.9964, 0.9618, 0.9581, 0.9556, 0.9415,\n                      0.9436, 0.9656, 0.9670, 0.9596, 0.9680, 0.9446, 0.9494, 0.9810, 0.9658,\n                      0.9638, 0.9320, 0.9919, 0.9957, 0.9370, 0.9610, 0.9799, 0.9369, 0.9505,\n                      0.9705], dtype=torch.float64)),\n             ('4.1.convs.0.1.bias',\n              tensor([ 0.0153,  0.0166,  0.0137,  0.0150,  0.0211,  0.0052, -0.0100,  0.0065,\n                       0.0003,  0.0118,  0.0110,  0.0178,  0.0011,  0.0065, -0.0053, -0.0034,\n                       0.0049,  0.0020, -0.0118, -0.0284,  0.0010, -0.0209, -0.0121,  0.0017,\n                       0.0087,  0.0001,  0.0002, -0.0105,  0.0083, -0.0025, -0.0029, -0.0111,\n                      -0.0021, -0.0002,  0.0023,  0.0011, -0.0021,  0.0015,  0.0120,  0.0040,\n                       0.0162,  0.0051, -0.0001, -0.0158, -0.0049, -0.0089,  0.0185,  0.0267,\n                       0.0002, -0.0048, -0.0005, -0.0045,  0.0029,  0.0089,  0.0153, -0.0133,\n                       0.0173,  0.0082,  0.0004,  0.0038,  0.0062,  0.0119, -0.0027,  0.0164],\n                     dtype=torch.float64)),\n             ('4.1.convs.0.1.running_mean',\n              tensor([-3.6673e-01, -3.1839e-01, -2.2712e-01, -7.3303e-01, -2.6468e-01,\n                      -3.4504e-01, -5.3686e-01,  4.4931e-01, -1.8099e-01,  4.5594e-01,\n                      -2.2706e-01, -2.2970e-02,  4.1870e-01,  6.3956e-04, -7.1862e-01,\n                      -6.0666e-01,  3.2083e-01, -3.1131e-01, -8.1477e-01, -2.6258e-02,\n                      -3.8624e-02,  9.0266e-03, -1.5698e-01, -3.4816e-03, -3.6534e-01,\n                      -2.3503e-02, -6.4681e-01,  2.2677e-01, -3.5768e-01, -6.4312e-01,\n                       6.6613e-02,  8.2632e-01,  4.3019e-01, -9.0011e-03, -6.3850e-01,\n                      -6.4609e-01,  4.2953e-01, -8.5458e-01, -1.0722e+00, -2.4228e-01,\n                      -1.4652e-01, -3.8099e-01, -1.7137e-01,  1.8403e-01, -2.6536e-01,\n                       9.4302e-01, -1.0785e+00, -3.8379e-01,  2.7501e-01, -6.5112e-01,\n                      -1.0300e+00,  3.8694e-01, -4.9725e-01, -2.3615e-02, -9.3182e-02,\n                      -3.1703e-01, -8.7847e-01, -2.0344e-01, -1.5094e-01,  6.0241e-01,\n                      -1.4606e-02, -2.9230e-01, -2.4752e-01,  5.5926e-02],\n                     dtype=torch.float64)),\n             ('4.1.convs.0.1.running_var',\n              tensor([0.8764, 1.0767, 0.4243, 0.4149, 0.5302, 0.5180, 0.5863, 2.0796, 0.6191,\n                      1.3904, 0.3872, 0.3380, 0.3595, 0.4874, 0.3935, 0.6230, 0.3508, 0.4836,\n                      0.6899, 0.7547, 0.4267, 0.7277, 0.6650, 0.4500, 0.4653, 0.4458, 0.6363,\n                      0.4481, 0.3858, 0.5953, 0.4685, 1.1678, 1.1814, 0.7938, 1.5083, 0.6731,\n                      0.5344, 0.4784, 2.1425, 0.4739, 0.5008, 0.5000, 0.9115, 0.7567, 0.4575,\n                      1.5659, 0.8526, 0.6364, 0.3154, 1.6061, 0.4650, 0.7609, 0.4101, 0.7246,\n                      0.4935, 0.8381, 0.3731, 0.4475, 0.9651, 0.5591, 0.3131, 0.7044, 0.7307,\n                      0.4144], dtype=torch.float64)),\n             ('4.1.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('4.1.convs.1.0.weight',\n              tensor([[[ 0.0421, -0.0811,  0.0330,  0.0056,  0.1588],\n                       [ 0.0385, -0.0733, -0.0175,  0.0611,  0.0599],\n                       [ 0.0694, -0.0409, -0.0874,  0.0063,  0.0964],\n                       ...,\n                       [ 0.1517, -0.0267,  0.0746,  0.1003,  0.0089],\n                       [ 0.1306, -0.0173,  0.1154, -0.0595,  0.0261],\n                       [-0.0747,  0.0046,  0.0660, -0.0371, -0.0347]],\n              \n                      [[-0.0505, -0.0011, -0.0235, -0.0683,  0.0868],\n                       [-0.0585,  0.0829,  0.0368,  0.0263, -0.0380],\n                       [ 0.0188,  0.0786,  0.0824,  0.0868,  0.0356],\n                       ...,\n                       [-0.0216,  0.1189,  0.1133, -0.0908, -0.0240],\n                       [-0.0623, -0.0122, -0.0879,  0.0989,  0.0467],\n                       [ 0.0985,  0.1105,  0.0686, -0.0625, -0.0092]],\n              \n                      [[-0.0649,  0.0434, -0.1118, -0.0303,  0.0119],\n                       [-0.0747, -0.1580, -0.0966, -0.0388,  0.0641],\n                       [-0.0063,  0.0922, -0.0461,  0.0850,  0.0342],\n                       ...,\n                       [ 0.1181, -0.0842,  0.0485, -0.0386, -0.0531],\n                       [-0.0632,  0.0632, -0.0538,  0.0249,  0.1037],\n                       [ 0.0170,  0.0047, -0.0239,  0.0354, -0.0418]],\n              \n                      ...,\n              \n                      [[-0.0713,  0.0364,  0.0408, -0.0946, -0.1306],\n                       [ 0.0318, -0.0729, -0.0014,  0.0644, -0.0119],\n                       [-0.1309,  0.0735,  0.0060,  0.0275,  0.0364],\n                       ...,\n                       [ 0.0505,  0.0300, -0.0917,  0.0684,  0.0617],\n                       [ 0.0152,  0.0705, -0.1785,  0.0208,  0.0345],\n                       [-0.1008, -0.0939, -0.0388,  0.1387, -0.0035]],\n              \n                      [[-0.0174, -0.0621,  0.1055, -0.0486,  0.0797],\n                       [-0.0954,  0.0507,  0.0932, -0.0349,  0.0466],\n                       [ 0.0296, -0.0120,  0.0615,  0.0684, -0.0833],\n                       ...,\n                       [-0.0368, -0.0442, -0.1363, -0.0535,  0.0274],\n                       [ 0.0130, -0.0371,  0.0120, -0.0719, -0.0100],\n                       [-0.0099, -0.0539, -0.0553,  0.0409, -0.0248]],\n              \n                      [[ 0.0012, -0.0103,  0.0057, -0.0038, -0.0738],\n                       [ 0.0569, -0.0173,  0.1431,  0.0587,  0.1055],\n                       [ 0.0721, -0.0504, -0.0647, -0.0414,  0.1351],\n                       ...,\n                       [ 0.1394,  0.0234, -0.1823, -0.0278,  0.0474],\n                       [ 0.0502, -0.0492,  0.0562, -0.1517,  0.1205],\n                       [-0.0972, -0.1027, -0.0387, -0.0323,  0.1212]]], dtype=torch.float64)),\n             ('4.1.convs.1.1.weight',\n              tensor([0.9519, 0.9701, 0.9212, 0.9582, 0.9861, 0.9419, 0.9595, 0.9429, 0.9335,\n                      0.9492, 0.9308, 0.9413, 0.9345, 0.9444, 0.9859, 0.9597, 0.9664, 0.9208,\n                      0.9404, 0.9575, 0.9676, 0.9332, 0.9134, 0.9310, 0.9467, 0.9325, 0.9623,\n                      0.9687, 0.9535, 0.9334, 0.9790, 0.9017, 0.9368, 0.9397, 0.9794, 0.9608,\n                      0.9274, 0.9874, 0.9475, 0.9825, 0.9398, 0.9624, 0.9865, 0.9571, 0.9567,\n                      0.9571, 0.9432, 0.9650, 0.9797, 0.9342, 1.0027, 0.9488, 0.9369, 0.9480,\n                      0.9518, 0.9771, 0.9658, 0.9668, 0.9684, 0.9243, 0.9419, 0.9844, 0.8916,\n                      0.9172], dtype=torch.float64)),\n             ('4.1.convs.1.1.bias',\n              tensor([-0.0073, -0.0070, -0.0278,  0.0008, -0.0097,  0.0170, -0.0109,  0.0123,\n                      -0.0126, -0.0060, -0.0172, -0.0096, -0.0213, -0.0343, -0.0014,  0.0089,\n                       0.0007, -0.0041, -0.0048,  0.0138,  0.0153,  0.0054, -0.0250, -0.0197,\n                      -0.0096, -0.0196,  0.0044, -0.0012, -0.0117, -0.0144,  0.0074, -0.0262,\n                      -0.0111, -0.0248, -0.0015, -0.0020, -0.0128, -0.0037,  0.0050,  0.0049,\n                       0.0015,  0.0074,  0.0022,  0.0125,  0.0079,  0.0017,  0.0052, -0.0037,\n                      -0.0035,  0.0158,  0.0056,  0.0064,  0.0012,  0.0051, -0.0112, -0.0139,\n                      -0.0012,  0.0117, -0.0006,  0.0025, -0.0060, -0.0092, -0.0178,  0.0092],\n                     dtype=torch.float64)),\n             ('4.1.convs.1.1.running_mean',\n              tensor([-0.4144, -0.0969, -0.2604,  0.6627, -0.4412, -0.3457, -0.3562, -0.1713,\n                      -0.3696,  0.2287,  0.2960,  0.1665,  0.0549,  0.7175, -0.5444, -0.2100,\n                      -0.8041, -0.9723, -0.4251,  0.3375, -0.6228,  0.0723, -0.8489,  0.6034,\n                       0.1758, -0.2398,  0.3163, -0.1429,  0.0185, -0.2844, -0.3338, -0.2647,\n                       0.2359,  0.2420,  0.2628, -0.3525,  0.0096,  0.1174, -0.0557, -0.1183,\n                      -0.2441, -0.0316,  0.1764,  0.1838, -0.4818, -0.0021,  0.8256,  0.5074,\n                       0.5265, -0.6382, -0.7652,  0.4271, -0.5875, -0.3518,  0.1724, -0.7473,\n                      -0.6198,  0.3020, -0.0731, -0.5738,  0.4999, -0.1328, -0.5350, -0.6916],\n                     dtype=torch.float64)),\n             ('4.1.convs.1.1.running_var',\n              tensor([0.3185, 0.4230, 0.5717, 0.5099, 0.2601, 0.5353, 0.3830, 0.4783, 0.5046,\n                      0.2716, 1.0798, 0.5491, 0.7090, 0.2874, 0.4343, 0.5546, 0.5345, 0.5770,\n                      0.6887, 0.3739, 0.3833, 0.4747, 0.5928, 0.7330, 0.4063, 0.3886, 0.2998,\n                      0.2844, 0.3775, 0.4275, 0.3011, 0.6431, 0.3677, 0.6160, 0.2934, 0.4187,\n                      0.4495, 0.2772, 0.5281, 0.2542, 0.5348, 0.5972, 0.3615, 0.4208, 0.4818,\n                      0.4018, 0.3732, 0.2916, 0.3024, 0.7130, 0.2937, 0.3946, 0.8043, 0.5452,\n                      0.4567, 0.3653, 0.8188, 0.4828, 0.3308, 0.4138, 0.4028, 0.4984, 0.5932,\n                      1.0395], dtype=torch.float64)),\n             ('4.1.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('4.1.convs.2.0.weight',\n              tensor([[[-4.6101e-02],\n                       [-5.3052e-03],\n                       [ 2.2144e-02],\n                       ...,\n                       [-1.2974e-01],\n                       [-1.2044e-01],\n                       [-2.9767e-02]],\n              \n                      [[ 2.1674e-01],\n                       [-4.0478e-01],\n                       [ 1.4100e-01],\n                       ...,\n                       [ 3.0292e-03],\n                       [ 2.1738e-01],\n                       [-6.2854e-02]],\n              \n                      [[-1.6119e-01],\n                       [ 8.5974e-02],\n                       [-1.6059e-01],\n                       ...,\n                       [-2.0828e-01],\n                       [ 4.9563e-02],\n                       [-8.8770e-02]],\n              \n                      ...,\n              \n                      [[-5.1268e-02],\n                       [-2.0679e-01],\n                       [ 3.2676e-02],\n                       ...,\n                       [-1.2844e-01],\n                       [-1.3067e-01],\n                       [-1.4355e-02]],\n              \n                      [[-3.2553e-04],\n                       [-3.2533e-02],\n                       [ 1.0006e-01],\n                       ...,\n                       [-4.8617e-02],\n                       [-6.5942e-02],\n                       [-2.6040e-03]],\n              \n                      [[ 5.1859e-02],\n                       [-3.9522e-02],\n                       [ 8.0912e-02],\n                       ...,\n                       [ 2.6967e-02],\n                       [ 8.0440e-02],\n                       [-1.1511e-01]]], dtype=torch.float64)),\n             ('4.1.convs.2.1.weight',\n              tensor([ 0.0006,  0.0271, -0.0200, -0.0254, -0.0033, -0.0276,  0.0165,  0.0017,\n                       0.0101, -0.0015,  0.0021,  0.0058,  0.0119,  0.0204, -0.0248,  0.0129,\n                      -0.0541, -0.0105, -0.0469,  0.0050,  0.0326, -0.0141,  0.0140, -0.0137,\n                      -0.0193, -0.0108, -0.0451,  0.0168,  0.0093,  0.0074, -0.0149, -0.0254,\n                       0.0060,  0.0114, -0.0335,  0.0128,  0.0080, -0.0051, -0.0257,  0.0371,\n                      -0.0246,  0.0222,  0.0195,  0.0298, -0.0050,  0.0167, -0.0054, -0.0100,\n                      -0.0150,  0.0072,  0.0343,  0.0346,  0.0090, -0.0035, -0.0135,  0.0360,\n                      -0.0065, -0.0309, -0.0179, -0.0117,  0.0054, -0.0186,  0.0038,  0.0211,\n                       0.0168,  0.0161,  0.0170,  0.0025,  0.0218, -0.0335, -0.0044,  0.0165,\n                      -0.0094,  0.0042, -0.0262, -0.0108,  0.0038,  0.0051, -0.0034,  0.0154,\n                       0.0071, -0.0122, -0.0183, -0.0050, -0.0238, -0.0072,  0.0079,  0.0212,\n                       0.0256, -0.0089, -0.0284, -0.0222, -0.0225, -0.0013, -0.0070,  0.0070,\n                      -0.0094, -0.0109, -0.0093,  0.0107,  0.0099, -0.0176,  0.0003, -0.0029,\n                      -0.0096, -0.0106,  0.0208, -0.0257,  0.0153, -0.0080, -0.0014, -0.0194,\n                      -0.0212, -0.0341,  0.0222,  0.0070,  0.0055,  0.0296, -0.0081,  0.0211,\n                       0.0075,  0.0095,  0.0112, -0.0168, -0.0261,  0.0006,  0.0039,  0.0180,\n                      -0.0177,  0.0205, -0.0125,  0.0246,  0.0276,  0.0079, -0.0209,  0.0091,\n                      -0.0278,  0.0272,  0.0085,  0.0115, -0.0051,  0.0166,  0.0098, -0.0059,\n                      -0.0003, -0.0331, -0.0156, -0.0251, -0.0506,  0.0261, -0.0101,  0.0186,\n                      -0.0037,  0.0149, -0.0222,  0.0091,  0.0101,  0.0190,  0.0082, -0.0151,\n                      -0.0077, -0.0064,  0.0231, -0.0130,  0.0003, -0.0157,  0.0394,  0.0025,\n                       0.0040,  0.0407, -0.0074,  0.0196,  0.0116, -0.0345,  0.0138,  0.0100,\n                      -0.0194,  0.0156,  0.0133, -0.0207, -0.0074,  0.0118,  0.0020, -0.0131,\n                      -0.0019, -0.0114,  0.0152, -0.0223,  0.0052,  0.0059, -0.0197, -0.0096,\n                      -0.0113,  0.0507, -0.0087, -0.0268, -0.0180,  0.0057,  0.0189,  0.0065,\n                      -0.0043,  0.0205, -0.0168,  0.0124, -0.0123,  0.0100, -0.0320, -0.0099,\n                      -0.0192,  0.0151, -0.0015,  0.0021,  0.0137,  0.0242,  0.0196, -0.0222,\n                       0.0351,  0.0164, -0.0001,  0.0211,  0.0146, -0.0162,  0.0165,  0.0317,\n                       0.0059, -0.0133, -0.0386,  0.0305, -0.0122,  0.0106, -0.0385,  0.0091,\n                       0.0436,  0.0197,  0.0116, -0.0163,  0.0381, -0.0307, -0.0185,  0.0230,\n                      -0.0032,  0.0292, -0.0257,  0.0247,  0.0152, -0.0286, -0.0087, -0.0035,\n                      -0.0226,  0.0317,  0.0044, -0.0018,  0.0225, -0.0161,  0.0136, -0.0145],\n                     dtype=torch.float64)),\n             ('4.1.convs.2.1.bias',\n              tensor([ 2.6622e-03,  1.3710e-03,  2.4668e-02,  2.1352e-04,  1.2285e-02,\n                      -1.6046e-02, -2.8361e-03,  1.3131e-03, -1.3091e-02, -1.0554e-02,\n                      -4.0515e-03, -5.2755e-03,  1.1840e-02, -1.3139e-02,  6.1576e-03,\n                       5.8622e-03,  3.4388e-02,  7.8671e-03,  3.4197e-02, -8.2476e-04,\n                       4.6450e-03,  6.5258e-03, -3.3595e-03, -3.3237e-07, -5.9572e-04,\n                      -2.2839e-02,  4.4814e-03,  2.7716e-03,  1.3475e-02,  4.0131e-03,\n                      -1.0429e-02,  1.7458e-02, -1.0648e-02,  2.1937e-02, -1.3994e-03,\n                      -2.9416e-03, -8.8909e-03,  4.0522e-03, -1.3585e-02, -1.3022e-02,\n                       3.7569e-03, -6.2779e-03,  1.8634e-03,  1.0811e-02,  4.5246e-03,\n                      -4.9369e-03, -1.2318e-02,  1.0012e-02, -9.1124e-03,  3.8464e-03,\n                       2.4045e-03,  2.5560e-02,  5.3867e-03,  4.8155e-03, -7.4186e-03,\n                       1.6208e-03,  5.6727e-03,  5.4424e-03, -1.7271e-02,  1.0205e-02,\n                      -5.8928e-03, -4.8369e-03, -2.2371e-02, -5.6922e-03,  1.3169e-03,\n                       9.9308e-03, -5.0984e-03,  2.3032e-02,  1.4855e-02, -1.6959e-02,\n                       1.1071e-02,  1.6993e-02, -1.2485e-02, -5.9807e-03,  2.2355e-03,\n                       2.0908e-02, -1.8641e-02, -1.7686e-02, -6.0985e-03, -7.5990e-03,\n                      -1.6724e-03, -1.5206e-04,  1.2970e-02,  6.5865e-03,  3.9908e-03,\n                      -2.1679e-02,  1.6723e-02, -1.2491e-03,  1.2273e-03, -4.7248e-04,\n                       2.9627e-03,  3.4472e-03,  6.1985e-03,  7.4438e-03,  4.6386e-03,\n                      -1.4171e-02,  6.9944e-03,  1.1244e-02,  1.6502e-02, -8.8793e-03,\n                       1.9815e-02,  6.2835e-04, -9.8524e-03, -1.1727e-02, -4.8677e-03,\n                       3.7418e-03, -1.8245e-02,  1.6108e-03,  1.7072e-02, -8.6741e-03,\n                      -1.0533e-02, -4.9054e-03,  1.1514e-02, -3.2844e-03, -4.4382e-03,\n                       1.2024e-02,  8.1511e-03,  1.7058e-02,  8.1910e-03, -7.0219e-03,\n                      -2.2659e-03, -1.5418e-02,  3.3106e-03, -3.1095e-03, -8.8057e-03,\n                       1.4026e-02,  5.6511e-03,  2.5897e-03,  1.5465e-02, -2.8600e-03,\n                      -9.9740e-03,  1.8713e-02, -1.3717e-03,  1.7899e-03, -8.5386e-03,\n                      -1.8533e-02,  2.3566e-04,  7.0790e-03, -3.3251e-03, -4.8542e-03,\n                       8.5347e-04,  1.1521e-02, -1.3889e-02, -1.6653e-04, -1.7692e-02,\n                      -3.8953e-04, -1.4073e-02,  1.5426e-05,  1.5815e-02,  1.7953e-02,\n                       9.4390e-04, -1.3990e-02, -2.8451e-02, -7.1768e-03,  4.4861e-03,\n                      -7.4486e-04,  1.2753e-02,  1.7786e-02, -1.6242e-02, -1.9292e-02,\n                       9.8000e-04,  1.2750e-02, -9.6246e-03,  1.5630e-02,  1.7052e-02,\n                       9.3223e-03, -7.8075e-03,  1.7067e-02,  3.8369e-03,  3.4596e-02,\n                       1.8414e-02, -1.9018e-03, -8.3720e-03,  2.3369e-02, -1.7262e-02,\n                      -4.6177e-03,  8.1083e-03,  2.5694e-02,  1.4343e-02,  1.1967e-03,\n                      -2.8156e-03,  8.1310e-03, -1.0312e-02,  2.2742e-03,  6.6953e-04,\n                       4.3218e-03,  4.9382e-03,  3.7847e-02, -1.1845e-03,  7.0539e-03,\n                      -8.0776e-03, -1.6016e-02, -4.6316e-03, -1.7701e-02, -1.0092e-02,\n                       1.8452e-02, -5.2258e-03,  1.6192e-02,  1.6435e-02, -1.4427e-02,\n                       1.7092e-02, -9.1854e-04,  4.4118e-03,  1.9168e-02,  1.2037e-02,\n                      -8.4665e-03,  8.8794e-03, -1.8915e-02, -5.9494e-03,  4.6580e-03,\n                       4.4639e-03, -5.5465e-03,  2.1049e-02,  1.9274e-03,  8.1752e-04,\n                       1.9156e-02,  6.1877e-03,  1.9708e-02,  1.2506e-02,  1.4080e-02,\n                       4.7879e-04, -6.0023e-03,  7.8806e-05,  5.1932e-03, -4.1084e-03,\n                       2.2269e-02,  1.4264e-02,  1.0377e-02, -2.2722e-02, -6.4449e-03,\n                       9.4013e-03,  7.8985e-03,  2.4517e-02,  4.3109e-03, -2.3704e-03,\n                       9.3053e-03,  1.4397e-02,  7.6741e-03, -7.4824e-03,  4.7430e-03,\n                      -6.8899e-03,  2.2124e-02,  1.1419e-02,  1.3012e-02,  2.4200e-02,\n                       2.0350e-02, -4.9785e-03,  1.4649e-02, -9.2872e-03, -1.4771e-02,\n                       1.9041e-02, -4.2001e-03, -9.0386e-03, -1.4952e-02,  1.5660e-02,\n                       2.1507e-03], dtype=torch.float64)),\n             ('4.1.convs.2.1.running_mean',\n              tensor([-0.3490, -0.3257,  0.1607,  0.0581,  0.0183, -0.3974,  0.0450, -0.0819,\n                      -0.1347,  0.2878, -0.1497, -0.1594, -0.0296, -0.3385, -0.4748, -0.4994,\n                      -0.0017,  0.3245,  0.3709,  0.5779,  0.8045, -0.1701,  0.0842, -0.2556,\n                       1.0248,  0.0246, -0.2827, -0.0964, -0.0681, -0.0657,  0.6462, -0.2160,\n                      -0.0357, -0.1618, -0.3211, -0.1958,  0.1180, -0.2173,  0.2530, -0.0081,\n                       0.2209,  0.5518,  0.1535, -0.2112, -0.0401,  0.5834,  0.0017, -0.1488,\n                       0.3180, -0.2249,  0.1441,  0.3128,  0.0839,  0.2255, -0.1630,  0.0707,\n                       0.3934,  0.1604,  0.3193,  0.4236,  0.2387, -0.3074, -0.1036,  0.2854,\n                      -0.1448,  0.2153, -0.4644, -0.0358, -0.4999, -0.2163,  0.1790, -0.1049,\n                       0.0172,  0.3230, -0.6403, -0.1055, -0.0132,  0.2365, -0.1993,  0.0380,\n                       0.0862, -0.0120,  0.8576, -0.0290,  0.0673, -0.1129,  0.4312,  0.0790,\n                       0.1341, -0.1908,  0.3605, -0.2894,  0.2530, -0.3455, -0.0736,  0.1299,\n                       0.2970, -0.0806, -0.1541, -0.2946, -0.0128,  0.2614, -0.1959, -0.2899,\n                       0.0984, -0.0954,  0.3801,  0.0031, -0.0116, -0.1876,  0.0905, -0.4068,\n                      -0.0514, -0.0556,  0.2250, -0.0541, -0.1580,  0.2824,  0.0340, -0.6819,\n                       0.4667, -0.0944, -0.4318, -0.3325,  0.1531, -0.0955, -0.0187,  0.1850,\n                       0.0992, -0.2054,  0.1328,  0.0035,  0.4837,  0.2113, -0.2163,  0.1285,\n                      -0.0864,  0.4211,  0.0791,  0.2858,  0.2118,  0.0513, -0.2165, -0.4369,\n                      -0.0095,  0.0968,  0.1615, -0.0668, -0.6665, -0.2577, -0.3888, -0.0493,\n                      -0.1449,  0.2557,  0.3586, -0.1919, -0.2868,  0.0563, -0.2434, -0.3951,\n                      -0.0237, -0.2338, -0.0835,  0.0911, -0.1855,  0.3321, -0.2775, -0.1253,\n                      -0.0681,  0.0652, -0.0289, -0.3501,  0.1558,  0.0053, -0.1093,  0.4458,\n                       0.0015, -0.0630,  0.1160,  0.2421,  0.3361, -0.3478,  0.1220,  0.1046,\n                      -0.2545, -0.1493, -0.1746,  0.0453,  0.4640,  0.0444,  0.1427, -0.1335,\n                      -0.0325, -0.0034, -0.3202, -0.1394, -0.0436, -0.1440, -0.2595, -0.1957,\n                      -0.1482, -0.2321,  0.3111,  0.0433, -0.5786,  0.4695, -0.2927,  0.2200,\n                      -0.1819,  0.0233, -0.0233,  0.2821,  0.0142,  0.0471,  0.3861,  0.0291,\n                      -0.3994,  0.3153,  0.0221,  0.0089,  0.2622, -0.1963,  0.2192, -0.0561,\n                      -0.1063, -0.0018, -0.5074,  0.1205, -0.7941,  0.1876, -0.1873,  0.1491,\n                       0.6923, -0.0754, -0.3212, -0.8104,  0.1325, -0.0508, -0.5542, -0.2772,\n                       0.1670,  0.2688, -0.0473,  0.5546,  0.3505,  0.2948,  0.4180,  0.0453,\n                      -0.2492,  0.2728,  0.1289, -0.1012, -0.1065,  0.5638, -0.3831, -0.2564],\n                     dtype=torch.float64)),\n             ('4.1.convs.2.1.running_var',\n              tensor([0.1247, 0.4673, 0.3052, 0.5637, 0.2827, 0.2225, 0.1415, 0.2438, 0.0741,\n                      0.0966, 0.1076, 0.2908, 0.0768, 0.4434, 0.3968, 0.4592, 0.2444, 0.4463,\n                      0.2491, 0.2412, 0.2970, 0.2626, 0.3414, 0.2586, 0.3553, 0.1332, 0.3183,\n                      0.2798, 0.1681, 0.1046, 0.5512, 0.5218, 0.1067, 0.2158, 0.3256, 0.2574,\n                      0.0836, 0.2849, 0.2553, 0.3248, 0.2735, 0.4395, 0.1424, 0.4309, 0.1653,\n                      0.2065, 0.0700, 0.2078, 0.4427, 0.1434, 0.3384, 0.2325, 0.4502, 0.1405,\n                      0.2815, 0.2169, 0.1982, 0.5412, 0.3812, 0.3282, 0.1567, 0.2946, 0.1145,\n                      0.1886, 0.4259, 0.4017, 0.4724, 0.1040, 0.3960, 0.4610, 0.2352, 0.2451,\n                      0.1439, 0.6628, 0.7427, 0.1250, 0.1228, 0.1202, 0.2887, 0.0469, 0.3723,\n                      0.1196, 0.4409, 0.1489, 0.3526, 0.3294, 0.2418, 0.2398, 0.1891, 0.2547,\n                      0.5151, 0.3699, 0.3376, 0.1772, 0.1726, 0.0871, 0.4601, 0.1384, 0.1047,\n                      0.1725, 0.3251, 0.3303, 0.2092, 0.1071, 0.2188, 0.2091, 0.4870, 0.3131,\n                      0.0564, 0.0977, 0.1272, 0.2620, 0.2930, 0.7058, 0.3363, 0.2974, 0.0500,\n                      0.5259, 0.1642, 0.3415, 0.2050, 0.2879, 0.3843, 0.5279, 0.3956, 0.2741,\n                      0.1284, 0.1579, 0.1492, 0.5154, 0.0988, 0.2472, 0.4197, 0.2898, 0.2311,\n                      0.0403, 0.2334, 0.5278, 0.2275, 0.2735, 0.0617, 0.2492, 0.1211, 0.2848,\n                      0.1390, 0.8003, 0.2216, 0.5505, 0.3214, 0.2679, 0.5748, 0.1755, 0.2163,\n                      0.1810, 0.3624, 0.3279, 0.1624, 0.3362, 0.3394, 0.3697, 0.0819, 0.0816,\n                      0.3182, 0.2392, 0.1825, 0.2556, 0.3022, 0.1684, 0.2362, 0.3641, 0.2427,\n                      0.2435, 0.1387, 0.2504, 0.4459, 0.2891, 0.2800, 0.2901, 0.3036, 0.2811,\n                      0.1877, 0.3167, 0.1579, 0.2403, 0.1752, 0.2500, 0.4507, 0.2978, 0.2547,\n                      0.1796, 0.1171, 0.1139, 0.3048, 0.4933, 0.2250, 0.1359, 0.2289, 0.2110,\n                      0.3020, 0.2026, 0.0692, 0.4942, 0.2327, 0.1886, 0.4562, 0.4333, 0.3647,\n                      0.3414, 0.5122, 0.4788, 0.0232, 0.1302, 0.2369, 0.3238, 0.1562, 0.2620,\n                      0.2632, 0.1647, 0.0481, 0.4497, 0.2626, 0.1364, 0.1314, 0.3705, 0.3710,\n                      0.2258, 0.3244, 0.4746, 0.4787, 0.4340, 0.4045, 0.2990, 0.4532, 0.3032,\n                      0.2005, 0.3822, 0.4358, 0.2043, 0.3229, 0.2760, 0.2897, 0.1976, 0.4628,\n                      0.2424, 0.2310, 0.4662, 0.1528, 0.0978, 0.2962, 0.4412, 0.1777, 0.1448,\n                      0.3359, 0.2935, 0.1682, 0.1672], dtype=torch.float64)),\n             ('4.1.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('4.1.convpath.0.0.0.weight',\n              tensor([[[ 0.0433],\n                       [ 0.0729],\n                       [ 0.0497],\n                       ...,\n                       [ 0.0378],\n                       [-0.0217],\n                       [ 0.0320]],\n              \n                      [[-0.0893],\n                       [ 0.0643],\n                       [ 0.1649],\n                       ...,\n                       [ 0.1981],\n                       [ 0.0114],\n                       [ 0.1326]],\n              \n                      [[-0.0556],\n                       [ 0.0464],\n                       [ 0.2254],\n                       ...,\n                       [ 0.0318],\n                       [-0.0813],\n                       [-0.1020]],\n              \n                      ...,\n              \n                      [[ 0.0480],\n                       [ 0.0273],\n                       [-0.1232],\n                       ...,\n                       [-0.1617],\n                       [ 0.0991],\n                       [-0.0936]],\n              \n                      [[-0.1003],\n                       [-0.0633],\n                       [ 0.0894],\n                       ...,\n                       [-0.0121],\n                       [ 0.0503],\n                       [ 0.0952]],\n              \n                      [[-0.1189],\n                       [-0.0043],\n                       [ 0.0023],\n                       ...,\n                       [-0.1041],\n                       [ 0.0674],\n                       [ 0.1825]]], dtype=torch.float64)),\n             ('4.1.convpath.0.0.1.weight',\n              tensor([1.0034, 0.9469, 0.9723, 0.9739, 0.9762, 0.9611, 0.9750, 0.9575, 0.9692,\n                      0.9740, 0.9631, 0.9902, 0.9811, 0.9544, 0.9580, 0.9519, 0.9656, 0.9779,\n                      0.9203, 0.9478, 0.9605, 0.9497, 0.9386, 0.9533, 0.9459, 0.9430, 0.9711,\n                      0.9746, 0.9570, 0.9580, 0.9550, 0.9575, 0.9650, 0.9662, 0.9379, 0.9584,\n                      0.9631, 0.9687, 0.9597, 0.9515, 0.9964, 0.9618, 0.9581, 0.9556, 0.9415,\n                      0.9436, 0.9656, 0.9670, 0.9596, 0.9680, 0.9446, 0.9494, 0.9810, 0.9658,\n                      0.9638, 0.9320, 0.9919, 0.9957, 0.9370, 0.9610, 0.9799, 0.9369, 0.9505,\n                      0.9705], dtype=torch.float64)),\n             ('4.1.convpath.0.0.1.bias',\n              tensor([ 0.0153,  0.0166,  0.0137,  0.0150,  0.0211,  0.0052, -0.0100,  0.0065,\n                       0.0003,  0.0118,  0.0110,  0.0178,  0.0011,  0.0065, -0.0053, -0.0034,\n                       0.0049,  0.0020, -0.0118, -0.0284,  0.0010, -0.0209, -0.0121,  0.0017,\n                       0.0087,  0.0001,  0.0002, -0.0105,  0.0083, -0.0025, -0.0029, -0.0111,\n                      -0.0021, -0.0002,  0.0023,  0.0011, -0.0021,  0.0015,  0.0120,  0.0040,\n                       0.0162,  0.0051, -0.0001, -0.0158, -0.0049, -0.0089,  0.0185,  0.0267,\n                       0.0002, -0.0048, -0.0005, -0.0045,  0.0029,  0.0089,  0.0153, -0.0133,\n                       0.0173,  0.0082,  0.0004,  0.0038,  0.0062,  0.0119, -0.0027,  0.0164],\n                     dtype=torch.float64)),\n             ('4.1.convpath.0.0.1.running_mean',\n              tensor([-3.6673e-01, -3.1839e-01, -2.2712e-01, -7.3303e-01, -2.6468e-01,\n                      -3.4504e-01, -5.3686e-01,  4.4931e-01, -1.8099e-01,  4.5594e-01,\n                      -2.2706e-01, -2.2970e-02,  4.1870e-01,  6.3956e-04, -7.1862e-01,\n                      -6.0666e-01,  3.2083e-01, -3.1131e-01, -8.1477e-01, -2.6258e-02,\n                      -3.8624e-02,  9.0266e-03, -1.5698e-01, -3.4816e-03, -3.6534e-01,\n                      -2.3503e-02, -6.4681e-01,  2.2677e-01, -3.5768e-01, -6.4312e-01,\n                       6.6613e-02,  8.2632e-01,  4.3019e-01, -9.0011e-03, -6.3850e-01,\n                      -6.4609e-01,  4.2953e-01, -8.5458e-01, -1.0722e+00, -2.4228e-01,\n                      -1.4652e-01, -3.8099e-01, -1.7137e-01,  1.8403e-01, -2.6536e-01,\n                       9.4302e-01, -1.0785e+00, -3.8379e-01,  2.7501e-01, -6.5112e-01,\n                      -1.0300e+00,  3.8694e-01, -4.9725e-01, -2.3615e-02, -9.3182e-02,\n                      -3.1703e-01, -8.7847e-01, -2.0344e-01, -1.5094e-01,  6.0241e-01,\n                      -1.4606e-02, -2.9230e-01, -2.4752e-01,  5.5926e-02],\n                     dtype=torch.float64)),\n             ('4.1.convpath.0.0.1.running_var',\n              tensor([0.8764, 1.0767, 0.4243, 0.4149, 0.5302, 0.5180, 0.5863, 2.0796, 0.6191,\n                      1.3904, 0.3872, 0.3380, 0.3595, 0.4874, 0.3935, 0.6230, 0.3508, 0.4836,\n                      0.6899, 0.7547, 0.4267, 0.7277, 0.6650, 0.4500, 0.4653, 0.4458, 0.6363,\n                      0.4481, 0.3858, 0.5953, 0.4685, 1.1678, 1.1814, 0.7938, 1.5083, 0.6731,\n                      0.5344, 0.4784, 2.1425, 0.4739, 0.5008, 0.5000, 0.9115, 0.7567, 0.4575,\n                      1.5659, 0.8526, 0.6364, 0.3154, 1.6061, 0.4650, 0.7609, 0.4101, 0.7246,\n                      0.4935, 0.8381, 0.3731, 0.4475, 0.9651, 0.5591, 0.3131, 0.7044, 0.7307,\n                      0.4144], dtype=torch.float64)),\n             ('4.1.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('4.1.convpath.0.1.0.weight',\n              tensor([[[ 0.0421, -0.0811,  0.0330,  0.0056,  0.1588],\n                       [ 0.0385, -0.0733, -0.0175,  0.0611,  0.0599],\n                       [ 0.0694, -0.0409, -0.0874,  0.0063,  0.0964],\n                       ...,\n                       [ 0.1517, -0.0267,  0.0746,  0.1003,  0.0089],\n                       [ 0.1306, -0.0173,  0.1154, -0.0595,  0.0261],\n                       [-0.0747,  0.0046,  0.0660, -0.0371, -0.0347]],\n              \n                      [[-0.0505, -0.0011, -0.0235, -0.0683,  0.0868],\n                       [-0.0585,  0.0829,  0.0368,  0.0263, -0.0380],\n                       [ 0.0188,  0.0786,  0.0824,  0.0868,  0.0356],\n                       ...,\n                       [-0.0216,  0.1189,  0.1133, -0.0908, -0.0240],\n                       [-0.0623, -0.0122, -0.0879,  0.0989,  0.0467],\n                       [ 0.0985,  0.1105,  0.0686, -0.0625, -0.0092]],\n              \n                      [[-0.0649,  0.0434, -0.1118, -0.0303,  0.0119],\n                       [-0.0747, -0.1580, -0.0966, -0.0388,  0.0641],\n                       [-0.0063,  0.0922, -0.0461,  0.0850,  0.0342],\n                       ...,\n                       [ 0.1181, -0.0842,  0.0485, -0.0386, -0.0531],\n                       [-0.0632,  0.0632, -0.0538,  0.0249,  0.1037],\n                       [ 0.0170,  0.0047, -0.0239,  0.0354, -0.0418]],\n              \n                      ...,\n              \n                      [[-0.0713,  0.0364,  0.0408, -0.0946, -0.1306],\n                       [ 0.0318, -0.0729, -0.0014,  0.0644, -0.0119],\n                       [-0.1309,  0.0735,  0.0060,  0.0275,  0.0364],\n                       ...,\n                       [ 0.0505,  0.0300, -0.0917,  0.0684,  0.0617],\n                       [ 0.0152,  0.0705, -0.1785,  0.0208,  0.0345],\n                       [-0.1008, -0.0939, -0.0388,  0.1387, -0.0035]],\n              \n                      [[-0.0174, -0.0621,  0.1055, -0.0486,  0.0797],\n                       [-0.0954,  0.0507,  0.0932, -0.0349,  0.0466],\n                       [ 0.0296, -0.0120,  0.0615,  0.0684, -0.0833],\n                       ...,\n                       [-0.0368, -0.0442, -0.1363, -0.0535,  0.0274],\n                       [ 0.0130, -0.0371,  0.0120, -0.0719, -0.0100],\n                       [-0.0099, -0.0539, -0.0553,  0.0409, -0.0248]],\n              \n                      [[ 0.0012, -0.0103,  0.0057, -0.0038, -0.0738],\n                       [ 0.0569, -0.0173,  0.1431,  0.0587,  0.1055],\n                       [ 0.0721, -0.0504, -0.0647, -0.0414,  0.1351],\n                       ...,\n                       [ 0.1394,  0.0234, -0.1823, -0.0278,  0.0474],\n                       [ 0.0502, -0.0492,  0.0562, -0.1517,  0.1205],\n                       [-0.0972, -0.1027, -0.0387, -0.0323,  0.1212]]], dtype=torch.float64)),\n             ('4.1.convpath.0.1.1.weight',\n              tensor([0.9519, 0.9701, 0.9212, 0.9582, 0.9861, 0.9419, 0.9595, 0.9429, 0.9335,\n                      0.9492, 0.9308, 0.9413, 0.9345, 0.9444, 0.9859, 0.9597, 0.9664, 0.9208,\n                      0.9404, 0.9575, 0.9676, 0.9332, 0.9134, 0.9310, 0.9467, 0.9325, 0.9623,\n                      0.9687, 0.9535, 0.9334, 0.9790, 0.9017, 0.9368, 0.9397, 0.9794, 0.9608,\n                      0.9274, 0.9874, 0.9475, 0.9825, 0.9398, 0.9624, 0.9865, 0.9571, 0.9567,\n                      0.9571, 0.9432, 0.9650, 0.9797, 0.9342, 1.0027, 0.9488, 0.9369, 0.9480,\n                      0.9518, 0.9771, 0.9658, 0.9668, 0.9684, 0.9243, 0.9419, 0.9844, 0.8916,\n                      0.9172], dtype=torch.float64)),\n             ('4.1.convpath.0.1.1.bias',\n              tensor([-0.0073, -0.0070, -0.0278,  0.0008, -0.0097,  0.0170, -0.0109,  0.0123,\n                      -0.0126, -0.0060, -0.0172, -0.0096, -0.0213, -0.0343, -0.0014,  0.0089,\n                       0.0007, -0.0041, -0.0048,  0.0138,  0.0153,  0.0054, -0.0250, -0.0197,\n                      -0.0096, -0.0196,  0.0044, -0.0012, -0.0117, -0.0144,  0.0074, -0.0262,\n                      -0.0111, -0.0248, -0.0015, -0.0020, -0.0128, -0.0037,  0.0050,  0.0049,\n                       0.0015,  0.0074,  0.0022,  0.0125,  0.0079,  0.0017,  0.0052, -0.0037,\n                      -0.0035,  0.0158,  0.0056,  0.0064,  0.0012,  0.0051, -0.0112, -0.0139,\n                      -0.0012,  0.0117, -0.0006,  0.0025, -0.0060, -0.0092, -0.0178,  0.0092],\n                     dtype=torch.float64)),\n             ('4.1.convpath.0.1.1.running_mean',\n              tensor([-0.4144, -0.0969, -0.2604,  0.6627, -0.4412, -0.3457, -0.3562, -0.1713,\n                      -0.3696,  0.2287,  0.2960,  0.1665,  0.0549,  0.7175, -0.5444, -0.2100,\n                      -0.8041, -0.9723, -0.4251,  0.3375, -0.6228,  0.0723, -0.8489,  0.6034,\n                       0.1758, -0.2398,  0.3163, -0.1429,  0.0185, -0.2844, -0.3338, -0.2647,\n                       0.2359,  0.2420,  0.2628, -0.3525,  0.0096,  0.1174, -0.0557, -0.1183,\n                      -0.2441, -0.0316,  0.1764,  0.1838, -0.4818, -0.0021,  0.8256,  0.5074,\n                       0.5265, -0.6382, -0.7652,  0.4271, -0.5875, -0.3518,  0.1724, -0.7473,\n                      -0.6198,  0.3020, -0.0731, -0.5738,  0.4999, -0.1328, -0.5350, -0.6916],\n                     dtype=torch.float64)),\n             ('4.1.convpath.0.1.1.running_var',\n              tensor([0.3185, 0.4230, 0.5717, 0.5099, 0.2601, 0.5353, 0.3830, 0.4783, 0.5046,\n                      0.2716, 1.0798, 0.5491, 0.7090, 0.2874, 0.4343, 0.5546, 0.5345, 0.5770,\n                      0.6887, 0.3739, 0.3833, 0.4747, 0.5928, 0.7330, 0.4063, 0.3886, 0.2998,\n                      0.2844, 0.3775, 0.4275, 0.3011, 0.6431, 0.3677, 0.6160, 0.2934, 0.4187,\n                      0.4495, 0.2772, 0.5281, 0.2542, 0.5348, 0.5972, 0.3615, 0.4208, 0.4818,\n                      0.4018, 0.3732, 0.2916, 0.3024, 0.7130, 0.2937, 0.3946, 0.8043, 0.5452,\n                      0.4567, 0.3653, 0.8188, 0.4828, 0.3308, 0.4138, 0.4028, 0.4984, 0.5932,\n                      1.0395], dtype=torch.float64)),\n             ('4.1.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('4.1.convpath.0.2.0.weight',\n              tensor([[[-4.6101e-02],\n                       [-5.3052e-03],\n                       [ 2.2144e-02],\n                       ...,\n                       [-1.2974e-01],\n                       [-1.2044e-01],\n                       [-2.9767e-02]],\n              \n                      [[ 2.1674e-01],\n                       [-4.0478e-01],\n                       [ 1.4100e-01],\n                       ...,\n                       [ 3.0292e-03],\n                       [ 2.1738e-01],\n                       [-6.2854e-02]],\n              \n                      [[-1.6119e-01],\n                       [ 8.5974e-02],\n                       [-1.6059e-01],\n                       ...,\n                       [-2.0828e-01],\n                       [ 4.9563e-02],\n                       [-8.8770e-02]],\n              \n                      ...,\n              \n                      [[-5.1268e-02],\n                       [-2.0679e-01],\n                       [ 3.2676e-02],\n                       ...,\n                       [-1.2844e-01],\n                       [-1.3067e-01],\n                       [-1.4355e-02]],\n              \n                      [[-3.2553e-04],\n                       [-3.2533e-02],\n                       [ 1.0006e-01],\n                       ...,\n                       [-4.8617e-02],\n                       [-6.5942e-02],\n                       [-2.6040e-03]],\n              \n                      [[ 5.1859e-02],\n                       [-3.9522e-02],\n                       [ 8.0912e-02],\n                       ...,\n                       [ 2.6967e-02],\n                       [ 8.0440e-02],\n                       [-1.1511e-01]]], dtype=torch.float64)),\n             ('4.1.convpath.0.2.1.weight',\n              tensor([ 0.0006,  0.0271, -0.0200, -0.0254, -0.0033, -0.0276,  0.0165,  0.0017,\n                       0.0101, -0.0015,  0.0021,  0.0058,  0.0119,  0.0204, -0.0248,  0.0129,\n                      -0.0541, -0.0105, -0.0469,  0.0050,  0.0326, -0.0141,  0.0140, -0.0137,\n                      -0.0193, -0.0108, -0.0451,  0.0168,  0.0093,  0.0074, -0.0149, -0.0254,\n                       0.0060,  0.0114, -0.0335,  0.0128,  0.0080, -0.0051, -0.0257,  0.0371,\n                      -0.0246,  0.0222,  0.0195,  0.0298, -0.0050,  0.0167, -0.0054, -0.0100,\n                      -0.0150,  0.0072,  0.0343,  0.0346,  0.0090, -0.0035, -0.0135,  0.0360,\n                      -0.0065, -0.0309, -0.0179, -0.0117,  0.0054, -0.0186,  0.0038,  0.0211,\n                       0.0168,  0.0161,  0.0170,  0.0025,  0.0218, -0.0335, -0.0044,  0.0165,\n                      -0.0094,  0.0042, -0.0262, -0.0108,  0.0038,  0.0051, -0.0034,  0.0154,\n                       0.0071, -0.0122, -0.0183, -0.0050, -0.0238, -0.0072,  0.0079,  0.0212,\n                       0.0256, -0.0089, -0.0284, -0.0222, -0.0225, -0.0013, -0.0070,  0.0070,\n                      -0.0094, -0.0109, -0.0093,  0.0107,  0.0099, -0.0176,  0.0003, -0.0029,\n                      -0.0096, -0.0106,  0.0208, -0.0257,  0.0153, -0.0080, -0.0014, -0.0194,\n                      -0.0212, -0.0341,  0.0222,  0.0070,  0.0055,  0.0296, -0.0081,  0.0211,\n                       0.0075,  0.0095,  0.0112, -0.0168, -0.0261,  0.0006,  0.0039,  0.0180,\n                      -0.0177,  0.0205, -0.0125,  0.0246,  0.0276,  0.0079, -0.0209,  0.0091,\n                      -0.0278,  0.0272,  0.0085,  0.0115, -0.0051,  0.0166,  0.0098, -0.0059,\n                      -0.0003, -0.0331, -0.0156, -0.0251, -0.0506,  0.0261, -0.0101,  0.0186,\n                      -0.0037,  0.0149, -0.0222,  0.0091,  0.0101,  0.0190,  0.0082, -0.0151,\n                      -0.0077, -0.0064,  0.0231, -0.0130,  0.0003, -0.0157,  0.0394,  0.0025,\n                       0.0040,  0.0407, -0.0074,  0.0196,  0.0116, -0.0345,  0.0138,  0.0100,\n                      -0.0194,  0.0156,  0.0133, -0.0207, -0.0074,  0.0118,  0.0020, -0.0131,\n                      -0.0019, -0.0114,  0.0152, -0.0223,  0.0052,  0.0059, -0.0197, -0.0096,\n                      -0.0113,  0.0507, -0.0087, -0.0268, -0.0180,  0.0057,  0.0189,  0.0065,\n                      -0.0043,  0.0205, -0.0168,  0.0124, -0.0123,  0.0100, -0.0320, -0.0099,\n                      -0.0192,  0.0151, -0.0015,  0.0021,  0.0137,  0.0242,  0.0196, -0.0222,\n                       0.0351,  0.0164, -0.0001,  0.0211,  0.0146, -0.0162,  0.0165,  0.0317,\n                       0.0059, -0.0133, -0.0386,  0.0305, -0.0122,  0.0106, -0.0385,  0.0091,\n                       0.0436,  0.0197,  0.0116, -0.0163,  0.0381, -0.0307, -0.0185,  0.0230,\n                      -0.0032,  0.0292, -0.0257,  0.0247,  0.0152, -0.0286, -0.0087, -0.0035,\n                      -0.0226,  0.0317,  0.0044, -0.0018,  0.0225, -0.0161,  0.0136, -0.0145],\n                     dtype=torch.float64)),\n             ('4.1.convpath.0.2.1.bias',\n              tensor([ 2.6622e-03,  1.3710e-03,  2.4668e-02,  2.1352e-04,  1.2285e-02,\n                      -1.6046e-02, -2.8361e-03,  1.3131e-03, -1.3091e-02, -1.0554e-02,\n                      -4.0515e-03, -5.2755e-03,  1.1840e-02, -1.3139e-02,  6.1576e-03,\n                       5.8622e-03,  3.4388e-02,  7.8671e-03,  3.4197e-02, -8.2476e-04,\n                       4.6450e-03,  6.5258e-03, -3.3595e-03, -3.3237e-07, -5.9572e-04,\n                      -2.2839e-02,  4.4814e-03,  2.7716e-03,  1.3475e-02,  4.0131e-03,\n                      -1.0429e-02,  1.7458e-02, -1.0648e-02,  2.1937e-02, -1.3994e-03,\n                      -2.9416e-03, -8.8909e-03,  4.0522e-03, -1.3585e-02, -1.3022e-02,\n                       3.7569e-03, -6.2779e-03,  1.8634e-03,  1.0811e-02,  4.5246e-03,\n                      -4.9369e-03, -1.2318e-02,  1.0012e-02, -9.1124e-03,  3.8464e-03,\n                       2.4045e-03,  2.5560e-02,  5.3867e-03,  4.8155e-03, -7.4186e-03,\n                       1.6208e-03,  5.6727e-03,  5.4424e-03, -1.7271e-02,  1.0205e-02,\n                      -5.8928e-03, -4.8369e-03, -2.2371e-02, -5.6922e-03,  1.3169e-03,\n                       9.9308e-03, -5.0984e-03,  2.3032e-02,  1.4855e-02, -1.6959e-02,\n                       1.1071e-02,  1.6993e-02, -1.2485e-02, -5.9807e-03,  2.2355e-03,\n                       2.0908e-02, -1.8641e-02, -1.7686e-02, -6.0985e-03, -7.5990e-03,\n                      -1.6724e-03, -1.5206e-04,  1.2970e-02,  6.5865e-03,  3.9908e-03,\n                      -2.1679e-02,  1.6723e-02, -1.2491e-03,  1.2273e-03, -4.7248e-04,\n                       2.9627e-03,  3.4472e-03,  6.1985e-03,  7.4438e-03,  4.6386e-03,\n                      -1.4171e-02,  6.9944e-03,  1.1244e-02,  1.6502e-02, -8.8793e-03,\n                       1.9815e-02,  6.2835e-04, -9.8524e-03, -1.1727e-02, -4.8677e-03,\n                       3.7418e-03, -1.8245e-02,  1.6108e-03,  1.7072e-02, -8.6741e-03,\n                      -1.0533e-02, -4.9054e-03,  1.1514e-02, -3.2844e-03, -4.4382e-03,\n                       1.2024e-02,  8.1511e-03,  1.7058e-02,  8.1910e-03, -7.0219e-03,\n                      -2.2659e-03, -1.5418e-02,  3.3106e-03, -3.1095e-03, -8.8057e-03,\n                       1.4026e-02,  5.6511e-03,  2.5897e-03,  1.5465e-02, -2.8600e-03,\n                      -9.9740e-03,  1.8713e-02, -1.3717e-03,  1.7899e-03, -8.5386e-03,\n                      -1.8533e-02,  2.3566e-04,  7.0790e-03, -3.3251e-03, -4.8542e-03,\n                       8.5347e-04,  1.1521e-02, -1.3889e-02, -1.6653e-04, -1.7692e-02,\n                      -3.8953e-04, -1.4073e-02,  1.5426e-05,  1.5815e-02,  1.7953e-02,\n                       9.4390e-04, -1.3990e-02, -2.8451e-02, -7.1768e-03,  4.4861e-03,\n                      -7.4486e-04,  1.2753e-02,  1.7786e-02, -1.6242e-02, -1.9292e-02,\n                       9.8000e-04,  1.2750e-02, -9.6246e-03,  1.5630e-02,  1.7052e-02,\n                       9.3223e-03, -7.8075e-03,  1.7067e-02,  3.8369e-03,  3.4596e-02,\n                       1.8414e-02, -1.9018e-03, -8.3720e-03,  2.3369e-02, -1.7262e-02,\n                      -4.6177e-03,  8.1083e-03,  2.5694e-02,  1.4343e-02,  1.1967e-03,\n                      -2.8156e-03,  8.1310e-03, -1.0312e-02,  2.2742e-03,  6.6953e-04,\n                       4.3218e-03,  4.9382e-03,  3.7847e-02, -1.1845e-03,  7.0539e-03,\n                      -8.0776e-03, -1.6016e-02, -4.6316e-03, -1.7701e-02, -1.0092e-02,\n                       1.8452e-02, -5.2258e-03,  1.6192e-02,  1.6435e-02, -1.4427e-02,\n                       1.7092e-02, -9.1854e-04,  4.4118e-03,  1.9168e-02,  1.2037e-02,\n                      -8.4665e-03,  8.8794e-03, -1.8915e-02, -5.9494e-03,  4.6580e-03,\n                       4.4639e-03, -5.5465e-03,  2.1049e-02,  1.9274e-03,  8.1752e-04,\n                       1.9156e-02,  6.1877e-03,  1.9708e-02,  1.2506e-02,  1.4080e-02,\n                       4.7879e-04, -6.0023e-03,  7.8806e-05,  5.1932e-03, -4.1084e-03,\n                       2.2269e-02,  1.4264e-02,  1.0377e-02, -2.2722e-02, -6.4449e-03,\n                       9.4013e-03,  7.8985e-03,  2.4517e-02,  4.3109e-03, -2.3704e-03,\n                       9.3053e-03,  1.4397e-02,  7.6741e-03, -7.4824e-03,  4.7430e-03,\n                      -6.8899e-03,  2.2124e-02,  1.1419e-02,  1.3012e-02,  2.4200e-02,\n                       2.0350e-02, -4.9785e-03,  1.4649e-02, -9.2872e-03, -1.4771e-02,\n                       1.9041e-02, -4.2001e-03, -9.0386e-03, -1.4952e-02,  1.5660e-02,\n                       2.1507e-03], dtype=torch.float64)),\n             ('4.1.convpath.0.2.1.running_mean',\n              tensor([-0.3490, -0.3257,  0.1607,  0.0581,  0.0183, -0.3974,  0.0450, -0.0819,\n                      -0.1347,  0.2878, -0.1497, -0.1594, -0.0296, -0.3385, -0.4748, -0.4994,\n                      -0.0017,  0.3245,  0.3709,  0.5779,  0.8045, -0.1701,  0.0842, -0.2556,\n                       1.0248,  0.0246, -0.2827, -0.0964, -0.0681, -0.0657,  0.6462, -0.2160,\n                      -0.0357, -0.1618, -0.3211, -0.1958,  0.1180, -0.2173,  0.2530, -0.0081,\n                       0.2209,  0.5518,  0.1535, -0.2112, -0.0401,  0.5834,  0.0017, -0.1488,\n                       0.3180, -0.2249,  0.1441,  0.3128,  0.0839,  0.2255, -0.1630,  0.0707,\n                       0.3934,  0.1604,  0.3193,  0.4236,  0.2387, -0.3074, -0.1036,  0.2854,\n                      -0.1448,  0.2153, -0.4644, -0.0358, -0.4999, -0.2163,  0.1790, -0.1049,\n                       0.0172,  0.3230, -0.6403, -0.1055, -0.0132,  0.2365, -0.1993,  0.0380,\n                       0.0862, -0.0120,  0.8576, -0.0290,  0.0673, -0.1129,  0.4312,  0.0790,\n                       0.1341, -0.1908,  0.3605, -0.2894,  0.2530, -0.3455, -0.0736,  0.1299,\n                       0.2970, -0.0806, -0.1541, -0.2946, -0.0128,  0.2614, -0.1959, -0.2899,\n                       0.0984, -0.0954,  0.3801,  0.0031, -0.0116, -0.1876,  0.0905, -0.4068,\n                      -0.0514, -0.0556,  0.2250, -0.0541, -0.1580,  0.2824,  0.0340, -0.6819,\n                       0.4667, -0.0944, -0.4318, -0.3325,  0.1531, -0.0955, -0.0187,  0.1850,\n                       0.0992, -0.2054,  0.1328,  0.0035,  0.4837,  0.2113, -0.2163,  0.1285,\n                      -0.0864,  0.4211,  0.0791,  0.2858,  0.2118,  0.0513, -0.2165, -0.4369,\n                      -0.0095,  0.0968,  0.1615, -0.0668, -0.6665, -0.2577, -0.3888, -0.0493,\n                      -0.1449,  0.2557,  0.3586, -0.1919, -0.2868,  0.0563, -0.2434, -0.3951,\n                      -0.0237, -0.2338, -0.0835,  0.0911, -0.1855,  0.3321, -0.2775, -0.1253,\n                      -0.0681,  0.0652, -0.0289, -0.3501,  0.1558,  0.0053, -0.1093,  0.4458,\n                       0.0015, -0.0630,  0.1160,  0.2421,  0.3361, -0.3478,  0.1220,  0.1046,\n                      -0.2545, -0.1493, -0.1746,  0.0453,  0.4640,  0.0444,  0.1427, -0.1335,\n                      -0.0325, -0.0034, -0.3202, -0.1394, -0.0436, -0.1440, -0.2595, -0.1957,\n                      -0.1482, -0.2321,  0.3111,  0.0433, -0.5786,  0.4695, -0.2927,  0.2200,\n                      -0.1819,  0.0233, -0.0233,  0.2821,  0.0142,  0.0471,  0.3861,  0.0291,\n                      -0.3994,  0.3153,  0.0221,  0.0089,  0.2622, -0.1963,  0.2192, -0.0561,\n                      -0.1063, -0.0018, -0.5074,  0.1205, -0.7941,  0.1876, -0.1873,  0.1491,\n                       0.6923, -0.0754, -0.3212, -0.8104,  0.1325, -0.0508, -0.5542, -0.2772,\n                       0.1670,  0.2688, -0.0473,  0.5546,  0.3505,  0.2948,  0.4180,  0.0453,\n                      -0.2492,  0.2728,  0.1289, -0.1012, -0.1065,  0.5638, -0.3831, -0.2564],\n                     dtype=torch.float64)),\n             ('4.1.convpath.0.2.1.running_var',\n              tensor([0.1247, 0.4673, 0.3052, 0.5637, 0.2827, 0.2225, 0.1415, 0.2438, 0.0741,\n                      0.0966, 0.1076, 0.2908, 0.0768, 0.4434, 0.3968, 0.4592, 0.2444, 0.4463,\n                      0.2491, 0.2412, 0.2970, 0.2626, 0.3414, 0.2586, 0.3553, 0.1332, 0.3183,\n                      0.2798, 0.1681, 0.1046, 0.5512, 0.5218, 0.1067, 0.2158, 0.3256, 0.2574,\n                      0.0836, 0.2849, 0.2553, 0.3248, 0.2735, 0.4395, 0.1424, 0.4309, 0.1653,\n                      0.2065, 0.0700, 0.2078, 0.4427, 0.1434, 0.3384, 0.2325, 0.4502, 0.1405,\n                      0.2815, 0.2169, 0.1982, 0.5412, 0.3812, 0.3282, 0.1567, 0.2946, 0.1145,\n                      0.1886, 0.4259, 0.4017, 0.4724, 0.1040, 0.3960, 0.4610, 0.2352, 0.2451,\n                      0.1439, 0.6628, 0.7427, 0.1250, 0.1228, 0.1202, 0.2887, 0.0469, 0.3723,\n                      0.1196, 0.4409, 0.1489, 0.3526, 0.3294, 0.2418, 0.2398, 0.1891, 0.2547,\n                      0.5151, 0.3699, 0.3376, 0.1772, 0.1726, 0.0871, 0.4601, 0.1384, 0.1047,\n                      0.1725, 0.3251, 0.3303, 0.2092, 0.1071, 0.2188, 0.2091, 0.4870, 0.3131,\n                      0.0564, 0.0977, 0.1272, 0.2620, 0.2930, 0.7058, 0.3363, 0.2974, 0.0500,\n                      0.5259, 0.1642, 0.3415, 0.2050, 0.2879, 0.3843, 0.5279, 0.3956, 0.2741,\n                      0.1284, 0.1579, 0.1492, 0.5154, 0.0988, 0.2472, 0.4197, 0.2898, 0.2311,\n                      0.0403, 0.2334, 0.5278, 0.2275, 0.2735, 0.0617, 0.2492, 0.1211, 0.2848,\n                      0.1390, 0.8003, 0.2216, 0.5505, 0.3214, 0.2679, 0.5748, 0.1755, 0.2163,\n                      0.1810, 0.3624, 0.3279, 0.1624, 0.3362, 0.3394, 0.3697, 0.0819, 0.0816,\n                      0.3182, 0.2392, 0.1825, 0.2556, 0.3022, 0.1684, 0.2362, 0.3641, 0.2427,\n                      0.2435, 0.1387, 0.2504, 0.4459, 0.2891, 0.2800, 0.2901, 0.3036, 0.2811,\n                      0.1877, 0.3167, 0.1579, 0.2403, 0.1752, 0.2500, 0.4507, 0.2978, 0.2547,\n                      0.1796, 0.1171, 0.1139, 0.3048, 0.4933, 0.2250, 0.1359, 0.2289, 0.2110,\n                      0.3020, 0.2026, 0.0692, 0.4942, 0.2327, 0.1886, 0.4562, 0.4333, 0.3647,\n                      0.3414, 0.5122, 0.4788, 0.0232, 0.1302, 0.2369, 0.3238, 0.1562, 0.2620,\n                      0.2632, 0.1647, 0.0481, 0.4497, 0.2626, 0.1364, 0.1314, 0.3705, 0.3710,\n                      0.2258, 0.3244, 0.4746, 0.4787, 0.4340, 0.4045, 0.2990, 0.4532, 0.3032,\n                      0.2005, 0.3822, 0.4358, 0.2043, 0.3229, 0.2760, 0.2897, 0.1976, 0.4628,\n                      0.2424, 0.2310, 0.4662, 0.1528, 0.0978, 0.2962, 0.4412, 0.1777, 0.1448,\n                      0.3359, 0.2935, 0.1682, 0.1672], dtype=torch.float64)),\n             ('4.1.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('4.2.convs.0.0.weight',\n              tensor([[[ 0.0702],\n                       [-0.1698],\n                       [ 0.0550],\n                       ...,\n                       [ 0.2336],\n                       [ 0.0287],\n                       [ 0.0159]],\n              \n                      [[ 0.0541],\n                       [ 0.0581],\n                       [-0.0672],\n                       ...,\n                       [-0.0276],\n                       [-0.1097],\n                       [ 0.0335]],\n              \n                      [[ 0.0974],\n                       [ 0.0572],\n                       [ 0.1448],\n                       ...,\n                       [-0.1670],\n                       [-0.0445],\n                       [-0.0218]],\n              \n                      ...,\n              \n                      [[-0.0403],\n                       [ 0.0969],\n                       [ 0.0285],\n                       ...,\n                       [ 0.1109],\n                       [-0.1581],\n                       [-0.0688]],\n              \n                      [[ 0.0472],\n                       [ 0.0161],\n                       [ 0.0451],\n                       ...,\n                       [-0.0118],\n                       [ 0.0003],\n                       [-0.1417]],\n              \n                      [[-0.1838],\n                       [ 0.0187],\n                       [ 0.0299],\n                       ...,\n                       [ 0.0636],\n                       [-0.0217],\n                       [-0.1200]]], dtype=torch.float64)),\n             ('4.2.convs.0.1.weight',\n              tensor([0.9464, 0.9544, 0.9544, 0.9406, 0.9657, 0.9796, 0.9911, 0.9462, 0.9470,\n                      0.9485, 0.9590, 0.9834, 0.9869, 0.9393, 0.9201, 0.9573, 0.9800, 0.9343,\n                      0.9711, 0.9364, 0.9834, 0.9484, 0.9501, 0.9312, 0.9601, 0.9669, 0.9615,\n                      0.9540, 0.9825, 0.9531, 0.9683, 0.9648, 0.9747, 0.9481, 0.9748, 0.9592,\n                      0.9760, 0.9416, 0.9526, 0.9392, 0.9587, 0.9612, 0.9515, 0.9770, 0.9669,\n                      0.9689, 0.9870, 0.9921, 0.9594, 0.9754, 0.9709, 0.9670, 0.9544, 0.9562,\n                      0.9368, 0.9454, 0.9812, 0.9478, 0.9984, 0.9660, 0.9485, 0.9321, 0.9549,\n                      0.9644], dtype=torch.float64)),\n             ('4.2.convs.0.1.bias',\n              tensor([-1.9495e-02,  3.5216e-03,  1.2734e-02, -1.2759e-02,  5.8002e-06,\n                       1.2951e-02,  2.4563e-02,  1.0208e-05,  1.7490e-02, -1.7263e-02,\n                       8.1130e-03,  2.0233e-02,  1.7482e-02, -1.1692e-03,  3.6552e-04,\n                      -1.0009e-02,  1.2297e-02, -1.8936e-03,  1.2223e-02, -2.1336e-03,\n                       1.3507e-02,  1.0784e-02,  1.1740e-02, -1.8731e-02, -9.9534e-03,\n                       1.4411e-02, -1.3349e-02, -2.7622e-02, -9.7460e-03,  6.6328e-03,\n                      -9.0697e-03, -1.2296e-02,  2.1980e-03, -2.6876e-02, -1.0755e-02,\n                       1.3761e-02, -2.9314e-03,  3.0514e-03,  3.8375e-03, -1.4342e-02,\n                      -8.1784e-03, -2.2646e-03, -5.7542e-03, -3.3786e-03, -6.6312e-03,\n                       5.9922e-03,  1.9001e-02,  6.6351e-03, -3.8141e-03, -5.8616e-03,\n                       7.4615e-03,  1.0806e-02,  9.1947e-03,  4.5208e-03, -7.6495e-03,\n                       5.2995e-03,  8.5199e-03, -6.4357e-03,  1.5609e-03,  1.5071e-02,\n                      -1.4606e-02, -9.5897e-03, -4.6254e-03,  1.3692e-02],\n                     dtype=torch.float64)),\n             ('4.2.convs.0.1.running_mean',\n              tensor([ 0.8013, -0.2368, -0.0489, -0.2212,  0.0110, -0.5408, -0.5364, -0.1092,\n                      -0.0800,  0.2726, -0.0555, -0.1361, -0.2313, -0.3139,  0.1442,  0.1016,\n                      -0.2290, -0.9682,  0.0298, -0.4661, -0.5634,  0.2962, -0.3537, -0.4533,\n                       0.2838,  0.2925, -0.5299, -0.0292,  0.0045, -0.6137,  0.0535, -0.3243,\n                      -0.2748,  0.1033,  0.4276, -0.0116,  0.7363, -0.7275, -0.3070,  0.5123,\n                      -0.4906, -0.0562,  0.0475,  0.9380, -0.8622,  0.4700, -0.6253, -0.5178,\n                      -0.1892,  0.4800, -0.1133,  0.0089, -0.0762, -0.7750, -0.0866,  0.0789,\n                      -0.8547, -0.6356, -0.6864,  0.0259,  0.1845,  0.1646, -0.2231, -0.2072],\n                     dtype=torch.float64)),\n             ('4.2.convs.0.1.running_var',\n              tensor([0.8658, 1.0441, 0.4828, 0.4140, 0.4526, 0.3806, 0.3011, 0.6723, 0.5109,\n                      1.3491, 0.3508, 0.2678, 0.7463, 0.5745, 0.6340, 0.4593, 0.2861, 1.6291,\n                      0.6184, 0.8625, 0.6584, 0.3762, 1.0309, 0.8042, 0.5474, 0.9957, 0.3217,\n                      0.2816, 0.3237, 1.1559, 0.3513, 1.1314, 0.2869, 0.4829, 0.2436, 0.5693,\n                      0.5492, 0.8320, 0.4094, 0.4211, 0.2751, 0.8711, 0.4345, 0.4309, 0.2922,\n                      0.4506, 0.7352, 0.3182, 0.7248, 0.2263, 0.4969, 0.3575, 0.8962, 0.4385,\n                      0.4293, 0.9178, 0.3657, 0.7007, 0.2615, 1.4762, 0.3850, 0.8489, 0.7226,\n                      0.6106], dtype=torch.float64)),\n             ('4.2.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('4.2.convs.1.0.weight',\n              tensor([[[ 1.5965e-02, -8.7334e-02,  2.3339e-02,  8.5295e-02,  5.2375e-02],\n                       [ 1.7278e-02,  2.4789e-02,  1.3672e-01, -1.1739e-01,  4.4454e-02],\n                       [ 6.7152e-02,  8.4430e-02,  7.5823e-02,  1.0004e-02, -1.0539e-02],\n                       ...,\n                       [ 6.4077e-03,  4.5944e-02,  1.1689e-02,  1.9172e-02, -6.5984e-02],\n                       [-1.5304e-02,  8.0513e-02,  1.2624e-01, -9.9547e-02, -6.2065e-02],\n                       [-6.6264e-02,  1.5129e-02, -5.6860e-02,  7.6153e-02, -2.2226e-03]],\n              \n                      [[ 6.2345e-02, -2.5090e-02, -4.0143e-02, -2.1504e-02, -8.5179e-04],\n                       [ 3.5015e-02,  3.2886e-02,  1.3576e-02,  3.0697e-02, -7.2117e-02],\n                       [ 2.6434e-03,  2.1661e-02, -1.0804e-01, -1.2891e-01, -7.7489e-02],\n                       ...,\n                       [-4.2200e-02,  4.3630e-02,  4.4493e-02,  4.3232e-02, -7.4799e-02],\n                       [ 9.7887e-02, -6.7348e-02,  5.8831e-02,  1.8867e-02,  1.4218e-01],\n                       [-4.9538e-02, -8.2036e-02,  3.4987e-02,  2.5011e-02,  8.4173e-03]],\n              \n                      [[-2.5509e-02, -3.9872e-03,  4.3003e-02, -1.6950e-02,  8.7339e-02],\n                       [ 4.8127e-02,  6.1724e-02, -7.5430e-02, -7.5543e-02,  3.0899e-02],\n                       [-7.6841e-03,  1.8897e-02,  4.7319e-02,  4.9399e-02, -8.9394e-02],\n                       ...,\n                       [ 2.5673e-02,  3.3955e-02, -5.6531e-02, -8.9550e-02, -1.2304e-01],\n                       [ 2.3678e-02, -6.8152e-02,  7.5393e-02, -1.8406e-02, -1.2966e-01],\n                       [ 7.6372e-02,  2.6798e-02,  2.6066e-02, -2.6055e-03,  5.6527e-02]],\n              \n                      ...,\n              \n                      [[ 1.3829e-01,  4.6206e-02,  1.1636e-01,  2.2173e-02, -5.3954e-02],\n                       [ 2.9702e-02,  4.0493e-02, -7.5827e-02, -2.1623e-02, -3.2042e-02],\n                       [-5.0497e-02,  5.0515e-02,  6.9311e-02,  1.3458e-01,  1.6030e-01],\n                       ...,\n                       [ 7.9468e-02,  1.8635e-01, -3.1411e-02,  2.3866e-02, -5.2812e-03],\n                       [ 5.4575e-03, -9.9997e-02, -4.2273e-02, -5.6591e-02,  1.3082e-01],\n                       [-1.3916e-01, -3.5978e-02, -6.6961e-03, -8.0260e-02,  2.1887e-02]],\n              \n                      [[ 7.5167e-02,  6.8957e-02, -7.1652e-02, -8.5743e-02,  1.3428e-01],\n                       [ 3.9528e-02, -1.0137e-02, -1.9709e-02,  9.0289e-03,  1.1808e-02],\n                       [ 7.6913e-02,  9.0583e-02, -1.6944e-01,  1.7404e-01,  2.0995e-02],\n                       ...,\n                       [-2.0166e-02, -1.4202e-02, -4.3247e-02, -2.1059e-02,  1.8705e-01],\n                       [ 2.0755e-02,  5.1492e-02, -4.3478e-02,  4.5100e-02, -7.4607e-02],\n                       [ 8.3739e-02,  3.6374e-02,  1.1067e-01, -6.5703e-04,  4.2008e-02]],\n              \n                      [[-5.6865e-02, -2.6879e-02,  1.1214e-05,  9.6894e-02, -3.4499e-03],\n                       [-1.3260e-01,  5.2316e-02,  6.5022e-02, -6.2424e-02,  9.2010e-02],\n                       [ 3.6169e-02, -8.1982e-02, -3.1340e-02,  2.6578e-02, -1.2896e-02],\n                       ...,\n                       [ 1.8496e-02,  5.0213e-02, -4.0650e-02,  5.9497e-02, -8.6081e-02],\n                       [ 1.1426e-01,  3.3271e-02, -9.0838e-02,  7.1756e-03,  1.0398e-01],\n                       [-2.1491e-02,  7.3455e-02,  2.9381e-02,  1.2381e-02, -1.4010e-02]]],\n                     dtype=torch.float64)),\n             ('4.2.convs.1.1.weight',\n              tensor([0.9423, 0.9662, 0.9396, 0.9476, 0.9674, 0.9272, 0.9681, 0.9722, 0.9339,\n                      0.9761, 0.9349, 0.9861, 0.9671, 0.9391, 0.9457, 0.9982, 0.9010, 0.9275,\n                      0.9353, 0.9832, 0.9404, 0.9281, 0.9358, 0.9515, 0.9156, 0.9391, 0.9292,\n                      0.9614, 0.9226, 0.9436, 0.9280, 0.9120, 0.9815, 0.9537, 0.9291, 0.9343,\n                      0.9925, 0.9345, 0.9737, 0.9434, 0.9873, 0.9853, 0.9333, 0.9774, 0.9498,\n                      0.9194, 0.9493, 0.9525, 0.9345, 0.9618, 0.9711, 0.9491, 0.9519, 0.9380,\n                      0.9567, 0.9804, 0.9453, 0.9842, 0.9697, 0.9792, 0.8994, 0.9496, 0.9489,\n                      0.9191], dtype=torch.float64)),\n             ('4.2.convs.1.1.bias',\n              tensor([-1.3109e-02,  1.8005e-02, -6.5840e-03, -7.9476e-03, -4.4230e-04,\n                      -4.4252e-03, -9.3745e-03,  2.3976e-02,  1.8121e-03,  5.4741e-03,\n                       1.0906e-02,  9.0400e-03,  2.3741e-03, -1.6474e-02,  3.7379e-03,\n                       1.0767e-02, -2.5383e-02, -2.4819e-02,  2.1622e-02,  6.8772e-03,\n                      -1.7393e-02, -1.1126e-02, -2.4145e-02,  7.6955e-04, -2.1592e-02,\n                      -1.5686e-02, -1.0719e-02, -2.8384e-05, -3.7678e-03,  1.4840e-02,\n                      -3.5656e-03, -1.6408e-02, -1.0770e-02, -8.5793e-03, -2.8265e-03,\n                      -1.8730e-02,  2.9778e-02,  3.6265e-03,  1.7948e-02, -1.0905e-02,\n                       6.9440e-03, -6.7054e-03, -1.8334e-02,  1.1669e-02, -1.3875e-02,\n                      -5.9053e-03, -1.1787e-03,  1.8392e-02, -1.8350e-03,  8.8758e-03,\n                       1.0188e-02, -2.2408e-02, -4.3536e-03, -2.8781e-03, -1.5995e-02,\n                       2.6976e-02, -1.3820e-02, -2.4503e-03,  9.3554e-03, -1.0622e-03,\n                      -1.0494e-02, -5.1209e-03, -2.7442e-02, -1.5361e-02],\n                     dtype=torch.float64)),\n             ('4.2.convs.1.1.running_mean',\n              tensor([ 0.5599, -0.6813,  0.5047,  0.0202, -0.4026,  0.0520,  0.3703, -0.3439,\n                      -0.3455, -0.8571, -0.2387, -0.1952,  0.2586, -0.1220,  0.1479, -0.2297,\n                      -0.4347,  0.3835, -0.5195, -0.0291,  0.1048,  0.4773,  1.2663, -0.2231,\n                       0.0830,  0.1964, -0.1539,  0.0284, -0.2582, -0.5224,  0.1370, -0.1453,\n                      -0.3110,  0.3673, -0.7171,  0.3127,  0.3361, -0.0663, -0.6876,  0.4397,\n                      -0.1260,  0.2848, -0.3000, -0.7592, -0.0198, -0.3640, -0.0108,  0.3412,\n                       0.1658, -0.3082, -0.3016,  0.6141,  0.1885, -0.1382, -1.1476, -0.1223,\n                      -0.7389, -0.4085, -0.5790,  0.8025, -0.0469, -0.1233,  0.5507,  0.2853],\n                     dtype=torch.float64)),\n             ('4.2.convs.1.1.running_var',\n              tensor([0.9067, 0.3428, 0.4494, 0.3018, 0.2833, 0.4519, 0.4343, 0.5535, 0.7867,\n                      0.5390, 0.4694, 0.3933, 0.3447, 0.4470, 0.4655, 0.2867, 1.0934, 1.0591,\n                      0.4050, 0.3376, 0.5769, 0.5339, 1.1698, 0.3003, 0.4116, 0.5572, 0.5072,\n                      0.5395, 0.5949, 0.3919, 0.6542, 0.3395, 0.3884, 0.9852, 0.5406, 0.7128,\n                      0.5391, 0.4167, 0.6062, 0.5158, 0.4401, 0.3453, 0.4030, 0.4781, 0.3605,\n                      0.5585, 0.4536, 0.4190, 0.2972, 0.7026, 0.6629, 0.8444, 0.2798, 0.4130,\n                      0.3815, 0.4689, 0.4057, 0.6268, 0.4900, 0.3708, 0.7184, 0.4737, 0.5560,\n                      0.5098], dtype=torch.float64)),\n             ('4.2.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('4.2.convs.2.0.weight',\n              tensor([[[-0.0321],\n                       [-0.1682],\n                       [ 0.0317],\n                       ...,\n                       [ 0.1145],\n                       [-0.1091],\n                       [-0.0575]],\n              \n                      [[-0.1367],\n                       [ 0.0007],\n                       [ 0.0081],\n                       ...,\n                       [-0.0289],\n                       [-0.2310],\n                       [-0.0343]],\n              \n                      [[-0.1589],\n                       [-0.1134],\n                       [ 0.3602],\n                       ...,\n                       [ 0.0616],\n                       [-0.0984],\n                       [-0.1072]],\n              \n                      ...,\n              \n                      [[-0.0441],\n                       [ 0.2674],\n                       [-0.1192],\n                       ...,\n                       [-0.1718],\n                       [-0.0294],\n                       [ 0.2213]],\n              \n                      [[ 0.0906],\n                       [ 0.1696],\n                       [-0.1439],\n                       ...,\n                       [-0.1461],\n                       [-0.0710],\n                       [-0.0285]],\n              \n                      [[ 0.0423],\n                       [-0.3263],\n                       [ 0.0508],\n                       ...,\n                       [-0.0360],\n                       [-0.1137],\n                       [-0.0988]]], dtype=torch.float64)),\n             ('4.2.convs.2.1.weight',\n              tensor([ 0.0042, -0.0382,  0.0169,  0.0011, -0.0347,  0.0163, -0.0213,  0.0145,\n                      -0.0151,  0.0092,  0.0006,  0.0256,  0.0126, -0.0153, -0.0065,  0.0181,\n                      -0.0318, -0.0134, -0.0193,  0.0100,  0.0104,  0.0300, -0.0208,  0.0320,\n                      -0.0220, -0.0164,  0.0122,  0.0164,  0.0200,  0.0077, -0.0025, -0.0379,\n                      -0.0076, -0.0049,  0.0416,  0.0206,  0.0034,  0.0127,  0.0054, -0.0253,\n                      -0.0110,  0.0110, -0.0207, -0.0320,  0.0231, -0.0063, -0.0082, -0.0028,\n                      -0.0250, -0.0130, -0.0179, -0.0020,  0.0167,  0.0182, -0.0031, -0.0101,\n                      -0.0054,  0.0097, -0.0141,  0.0067,  0.0051,  0.0297,  0.0026, -0.0160,\n                      -0.0171,  0.0184,  0.0098, -0.0118,  0.0307, -0.0137, -0.0050,  0.0069,\n                       0.0118, -0.0020, -0.0246, -0.0069, -0.0028,  0.0095, -0.0166,  0.0064,\n                      -0.0104, -0.0068,  0.0499, -0.0194, -0.0130, -0.0101,  0.0283,  0.0318,\n                       0.0528,  0.0088, -0.0092,  0.0177, -0.0045,  0.0023,  0.0003,  0.0174,\n                      -0.0134, -0.0217, -0.0123,  0.0074,  0.0057, -0.0140,  0.0310,  0.0282,\n                      -0.0057,  0.0180,  0.0215,  0.0147,  0.0366,  0.0044, -0.0040,  0.0090,\n                      -0.0362, -0.0171, -0.0110, -0.0152, -0.0031, -0.0073,  0.0117,  0.0077,\n                      -0.0234, -0.0219, -0.0195,  0.0271, -0.0018, -0.0014,  0.0122, -0.0163,\n                       0.0234, -0.0346,  0.0059, -0.0202,  0.0341,  0.0213,  0.0021,  0.0016,\n                      -0.0061, -0.0095,  0.0222,  0.0008, -0.0047, -0.0141, -0.0098,  0.0347,\n                      -0.0047, -0.0378, -0.0214, -0.0105,  0.0021,  0.0161,  0.0256,  0.0007,\n                      -0.0284, -0.0170, -0.0010,  0.0181,  0.0049,  0.0111, -0.0018,  0.0154,\n                      -0.0098,  0.0209, -0.0156,  0.0211,  0.0097, -0.0191, -0.0040,  0.0080,\n                       0.0059, -0.0300,  0.0013,  0.0193, -0.0073,  0.0064,  0.0120,  0.0109,\n                       0.0080,  0.0215, -0.0303, -0.0084,  0.0086, -0.0129, -0.0029, -0.0115,\n                       0.0393, -0.0093, -0.0376,  0.0521,  0.0153, -0.0145,  0.0044,  0.0058,\n                      -0.0270,  0.0194,  0.0249, -0.0024,  0.0042, -0.0095,  0.0025,  0.0011,\n                       0.0021, -0.0277,  0.0147, -0.0127,  0.0033,  0.0045, -0.0342,  0.0207,\n                       0.0100,  0.0192,  0.0058,  0.0103,  0.0002,  0.0090, -0.0087,  0.0029,\n                      -0.0103, -0.0278, -0.0128,  0.0141, -0.0035,  0.0119,  0.0036, -0.0154,\n                       0.0085,  0.0126, -0.0141, -0.0009, -0.0014, -0.0076, -0.0352,  0.0166,\n                      -0.0433,  0.0051, -0.0161,  0.0024, -0.0136, -0.0205, -0.0086,  0.0156,\n                       0.0048, -0.0023, -0.0004,  0.0185, -0.0261, -0.0085, -0.0071,  0.0134,\n                       0.0174, -0.0486, -0.0148,  0.0266, -0.0191,  0.0320, -0.0035,  0.0223],\n                     dtype=torch.float64)),\n             ('4.2.convs.2.1.bias',\n              tensor([ 2.2981e-03,  6.0355e-03,  3.0007e-02, -1.3390e-03,  1.4013e-02,\n                      -1.6159e-02, -3.2799e-03, -1.3372e-03, -1.2572e-02, -9.1693e-03,\n                      -5.5602e-03, -5.7822e-03,  1.4705e-02, -1.3795e-02,  8.6815e-03,\n                       5.6836e-03,  3.3969e-02,  6.5681e-03,  2.4544e-02, -9.3135e-04,\n                       1.7069e-03,  4.4020e-03,  6.4256e-04, -1.0262e-03,  1.7300e-03,\n                      -2.3364e-02,  3.7162e-03,  1.3636e-02,  1.1473e-02,  5.0608e-03,\n                      -8.9330e-03,  2.1448e-02, -1.1811e-02,  1.6927e-02,  1.3091e-02,\n                      -3.2098e-04, -8.9734e-03,  4.5552e-03, -1.3376e-02, -7.0448e-03,\n                       1.0680e-02, -8.3521e-03, -1.8405e-03,  1.1746e-02,  6.9080e-03,\n                      -4.2487e-03, -1.5921e-02,  8.3356e-03, -3.3936e-03, -3.0647e-03,\n                      -1.9244e-03,  3.4782e-03,  1.6608e-02,  2.8802e-02, -7.5906e-03,\n                       2.0866e-03,  2.3706e-03,  5.4979e-03, -1.7742e-02,  9.0638e-03,\n                      -7.1016e-03,  8.6566e-04, -1.9732e-02,  2.8876e-04,  4.0477e-03,\n                       1.4831e-02, -6.1769e-03,  2.3492e-02,  2.4774e-02, -1.7151e-02,\n                       1.1681e-02,  7.9894e-03,  7.3410e-03, -6.5583e-03, -4.5579e-03,\n                       1.7578e-02,  7.3620e-03, -1.8193e-02,  1.6897e-03,  1.0131e-02,\n                      -6.3668e-03,  6.6972e-04,  1.7577e-02,  4.7862e-03,  4.9707e-03,\n                      -2.2640e-02,  1.4011e-02,  1.3818e-02,  6.8424e-03, -3.7594e-03,\n                       5.8248e-03,  1.0848e-02,  1.4915e-02,  6.6864e-03,  5.0534e-03,\n                      -1.2815e-02,  1.1481e-02,  1.0703e-02,  1.3009e-02, -1.1513e-02,\n                       2.2523e-02,  1.2651e-03, -5.1943e-03, -1.3343e-02,  4.8336e-03,\n                       1.1113e-02, -1.1996e-02, -9.7674e-04,  1.7487e-02, -9.8886e-03,\n                      -1.3223e-02, -6.4504e-03,  1.3571e-02,  1.4810e-02,  1.5687e-02,\n                       8.7651e-03,  9.3772e-03,  1.1581e-02,  1.1279e-02, -6.1102e-03,\n                       1.7679e-02, -1.1416e-02,  2.0439e-03,  2.6063e-03, -8.8128e-03,\n                       1.2904e-02,  4.2038e-03,  7.4398e-03,  1.1056e-02, -6.8831e-04,\n                      -7.3310e-03,  6.1786e-03,  2.0150e-03,  5.3117e-03, -7.2624e-03,\n                      -1.6135e-02,  4.1060e-03,  2.9873e-02, -1.4422e-03, -7.6886e-03,\n                       7.2946e-04,  9.8148e-03, -9.9029e-03, -2.2951e-03, -1.5686e-02,\n                      -5.4162e-03,  4.6320e-03, -5.8741e-03,  1.2422e-02,  2.3152e-02,\n                       1.9946e-03, -1.2418e-02, -2.4738e-02,  1.7292e-02, -4.1586e-03,\n                       1.1232e-02,  9.4844e-03,  2.1819e-02, -4.1767e-03, -2.0144e-02,\n                      -9.9166e-05,  1.1130e-02, -1.1883e-02,  1.8993e-02,  1.7969e-02,\n                       1.0380e-02, -7.9747e-03,  2.1661e-02,  1.2728e-02,  2.3638e-02,\n                       1.2848e-02, -4.1754e-03, -8.3021e-03,  2.0047e-02, -1.6692e-02,\n                      -6.1638e-03,  6.3373e-03,  2.3157e-02,  1.6104e-02, -2.4939e-03,\n                      -3.7590e-03,  1.3873e-03, -9.7327e-03, -1.1150e-03,  5.9546e-03,\n                       7.6138e-03,  1.7157e-02,  3.2642e-02, -1.7507e-03,  8.1882e-03,\n                      -7.7682e-03, -1.4533e-02,  3.6442e-03, -1.7871e-02,  1.0974e-02,\n                       1.8575e-02, -4.9975e-03,  1.4283e-02,  1.2792e-02, -1.6664e-02,\n                       1.5296e-02,  3.0710e-03,  9.8463e-04,  1.6290e-02,  3.6353e-03,\n                      -5.9694e-03,  8.4527e-03, -1.6902e-02,  6.0383e-03,  1.0562e-02,\n                       6.0151e-03, -9.1413e-03,  7.7327e-03, -1.0408e-03,  1.8305e-03,\n                       1.2953e-02,  3.5994e-03,  1.0672e-02,  1.2097e-02,  1.0209e-02,\n                      -8.4629e-05, -1.0060e-02,  1.1748e-02,  7.4849e-05, -1.4349e-03,\n                       1.8271e-02,  1.0349e-02,  4.8985e-03, -2.4221e-02, -3.6036e-03,\n                      -2.4693e-03,  1.0476e-02,  2.7278e-02,  3.1265e-03, -1.8923e-03,\n                       6.9213e-03,  1.5240e-02,  6.3762e-03, -9.1332e-03,  5.0912e-03,\n                      -5.5732e-03,  4.1736e-03,  1.1687e-02,  3.5444e-03,  1.3644e-02,\n                       1.8368e-02, -1.2853e-03,  1.3878e-02, -1.0017e-02, -1.4650e-02,\n                       1.9003e-02, -1.2700e-03, -1.0338e-02,  2.2673e-02,  2.3178e-02,\n                       6.8945e-03], dtype=torch.float64)),\n             ('4.2.convs.2.1.running_mean',\n              tensor([ 2.2142e-01, -3.5158e-02,  4.7936e-01,  1.3704e-01,  1.5016e-01,\n                      -2.9301e-01,  2.8332e-01,  1.4424e-01,  2.8096e-01,  6.1163e-01,\n                       8.5292e-02,  7.7581e-02,  6.1009e-02,  1.1685e-01, -6.7240e-01,\n                      -6.9520e-04, -3.9635e-01,  8.0276e-01,  6.6967e-01, -8.1997e-01,\n                       1.6503e-01, -2.0750e-01,  4.3678e-01, -6.5098e-01,  1.7848e-01,\n                      -2.4521e-01, -3.7271e-01,  1.5257e-01,  3.0628e-01,  3.0542e-01,\n                      -2.9402e-01,  8.3692e-01,  6.5709e-02,  6.5633e-02, -3.4898e-01,\n                       4.7584e-01,  1.6067e-02,  1.6485e-01,  2.4903e-01, -4.5836e-01,\n                      -1.1768e-01, -2.3431e-01,  1.8861e-01, -2.9288e-02,  3.6511e-01,\n                      -3.2776e-01, -3.3418e-01, -2.8739e-02,  1.3645e-01,  3.3940e-01,\n                       1.6950e-01, -1.8935e-01,  1.6950e-01,  7.7983e-02,  8.8855e-02,\n                      -6.1477e-02, -2.3188e-01, -6.3246e-02, -2.6731e-01,  8.7092e-02,\n                       1.4543e-01, -4.9972e-02,  3.5225e-01, -2.4500e-01,  1.5744e-01,\n                      -1.2062e-01, -1.9639e-01,  1.0864e-01, -2.0654e-01, -1.0682e-01,\n                      -4.9675e-02, -8.4615e-02, -1.4485e-01,  6.9949e-01,  5.1589e-01,\n                      -8.8552e-02,  1.4291e-02, -1.8502e-01,  4.4828e-01, -2.1247e-01,\n                       1.6623e-01,  2.0076e-01, -3.7122e-01,  7.7382e-01,  2.8990e-01,\n                      -7.4275e-01,  5.1118e-01,  4.3443e-02, -2.5806e-02, -1.3909e-01,\n                      -2.1683e-01,  1.1638e-01,  3.9570e-02, -5.1656e-02, -3.9182e-02,\n                      -2.6096e-02, -5.1525e-01,  2.1138e-01, -1.8937e-01,  6.1392e-01,\n                       4.6584e-02, -3.5009e-01,  1.7265e-01,  1.0096e-01, -3.9140e-01,\n                      -6.0333e-01,  1.2356e-01,  1.3604e-01, -3.1294e-01,  1.1004e-01,\n                       2.2361e-01, -1.0477e-01,  1.4201e-01, -2.6361e-03, -2.4967e-01,\n                       1.2752e-01, -1.0775e-01,  9.8541e-02, -2.6598e-01, -2.1570e-01,\n                      -1.9860e-01,  1.2686e-01, -9.8351e-02,  5.9487e-01, -3.1013e-02,\n                      -8.9968e-02,  6.7673e-01, -2.0401e-01,  1.0732e-01,  2.4746e-01,\n                      -1.3224e-01,  2.6989e-01, -4.6560e-01,  7.1059e-02, -1.3566e-01,\n                       2.8899e-01, -8.2771e-02,  1.2047e-01,  1.1373e-01,  3.0030e-01,\n                      -4.7368e-01,  1.5133e-02, -3.6606e-01, -3.1214e-02,  2.0281e-01,\n                      -6.2564e-02, -7.9454e-01,  8.2024e-01, -1.1752e-01,  1.1513e-02,\n                       1.1064e-01,  3.1738e-01,  2.2243e-01, -4.2587e-02,  3.4996e-03,\n                       3.0102e-01,  1.4794e-01, -2.7961e-01, -1.5764e-01,  2.8097e-01,\n                      -2.8864e-01, -4.7957e-01, -5.0146e-02,  4.9852e-01,  4.6698e-01,\n                       3.2214e-01,  3.0504e-01,  2.9440e-01, -4.2277e-01,  1.7022e-01,\n                       6.4302e-02,  1.0283e-01,  8.1499e-02,  5.0447e-02,  4.7729e-01,\n                       6.8529e-03,  6.2631e-02,  4.5509e-01, -2.7544e-01, -2.9442e-01,\n                      -1.5363e-01,  1.5365e-01,  5.7494e-01,  3.2734e-01,  1.6687e-01,\n                       1.4306e-01,  1.1846e-01,  2.5563e-01, -5.9768e-01, -3.1768e-01,\n                       5.6654e-05, -2.2829e-01,  5.9329e-01, -3.3185e-01, -3.3549e-01,\n                      -4.2196e-02,  8.0192e-02,  2.6960e-01, -1.2091e-01,  1.0461e-01,\n                       4.3255e-01,  1.8091e-01,  4.4113e-01, -4.1657e-02, -5.0203e-01,\n                       3.5528e-02,  4.7656e-01, -1.5542e-01,  6.5555e-02, -2.3467e-01,\n                       1.7397e-01,  1.2085e-01,  2.3107e-01,  2.1652e-01,  1.5883e-01,\n                      -2.4920e-02, -1.2971e-01,  2.5491e-01,  2.0970e-01, -7.3771e-01,\n                      -4.8901e-02,  5.9636e-02,  6.8819e-02, -1.4104e-01,  9.0482e-01,\n                       2.0468e-01, -4.2534e-01, -1.5065e-01,  3.2987e-01, -2.1250e-01,\n                      -3.9264e-01, -9.6778e-02, -3.1806e-01, -1.6343e-01,  3.3466e-01,\n                      -3.8532e-01, -4.0276e-01,  2.7974e-02, -1.2858e-01, -2.5921e-01,\n                      -1.2651e-01,  1.6659e-01, -1.6267e-01, -1.4795e-01, -7.3921e-03,\n                      -1.9303e-01, -5.0223e-01,  4.1150e-01,  3.2483e-01, -4.1626e-02,\n                      -2.3209e-01, -2.6750e-01, -6.4750e-02, -3.3819e-01, -5.1727e-02,\n                      -3.8360e-01], dtype=torch.float64)),\n             ('4.2.convs.2.1.running_var',\n              tensor([0.3494, 0.3664, 0.5004, 0.2424, 0.4853, 0.2903, 0.2619, 0.3312, 0.1057,\n                      0.3090, 0.1433, 0.2842, 0.2199, 0.3126, 0.6621, 0.2775, 0.3625, 0.7359,\n                      0.3012, 0.3333, 0.2643, 0.4854, 0.2571, 0.3565, 0.4389, 0.1531, 0.3283,\n                      0.3391, 0.2246, 0.2702, 0.3921, 0.6336, 0.2376, 0.1874, 0.3359, 0.3782,\n                      0.0775, 0.3302, 0.1297, 0.7002, 0.4018, 0.0763, 0.1583, 0.6357, 0.5126,\n                      0.1717, 0.2589, 0.0645, 0.4337, 0.3108, 0.2681, 0.1602, 0.3169, 0.2280,\n                      0.1088, 0.1705, 0.1895, 0.3184, 0.2708, 0.2359, 0.0773, 0.2504, 0.2813,\n                      0.3729, 0.6203, 0.3734, 0.3693, 0.4202, 0.4217, 0.2804, 0.3392, 0.1044,\n                      0.2604, 0.5761, 0.6272, 0.1467, 0.1798, 0.1571, 0.3038, 0.1496, 0.3359,\n                      0.1670, 0.4270, 0.5396, 0.1584, 0.2921, 0.4444, 0.3492, 0.3100, 0.0724,\n                      0.3694, 0.3629, 0.4728, 0.0720, 0.0826, 0.2072, 0.5206, 0.1613, 0.4708,\n                      0.3128, 0.3138, 0.2628, 0.2690, 0.2873, 0.3417, 0.4148, 0.2431, 0.3579,\n                      0.4063, 0.0342, 0.1433, 0.4559, 0.3074, 0.4460, 0.4856, 0.1305, 0.1772,\n                      0.4879, 0.1669, 0.1863, 0.2000, 0.4973, 0.4043, 0.4526, 0.0449, 0.1972,\n                      0.3342, 0.2001, 0.2827, 0.2879, 0.0789, 0.4231, 0.5012, 0.3574, 0.0993,\n                      0.1236, 0.2986, 0.2042, 0.1935, 0.2214, 0.1848, 0.2062, 0.3228, 0.2898,\n                      0.1555, 0.6018, 0.2927, 0.5353, 0.0708, 0.2957, 0.3032, 0.0721, 0.4335,\n                      0.2709, 0.0514, 0.5275, 0.1669, 0.1499, 0.1675, 0.2188, 0.3065, 0.3264,\n                      0.1616, 0.3622, 0.2976, 0.3722, 0.4573, 0.1545, 0.1959, 0.6024, 0.0432,\n                      0.3219, 0.1022, 0.0954, 0.4639, 0.3849, 0.3074, 0.5008, 0.3763, 0.1747,\n                      0.1534, 0.2606, 0.4120, 0.2213, 0.3451, 0.1596, 0.6406, 0.3423, 0.5384,\n                      0.4377, 0.0987, 0.1373, 0.2969, 0.4314, 0.3624, 0.3267, 0.2923, 0.2659,\n                      0.1215, 0.0513, 0.1512, 0.2044, 0.4376, 0.2054, 0.3051, 0.2576, 0.2613,\n                      0.0522, 0.1541, 0.3856, 0.1245, 0.2651, 0.0817, 0.1799, 0.0465, 0.0550,\n                      0.2209, 0.2880, 0.4932, 0.4446, 0.0395, 0.2346, 0.1144, 0.3688, 0.3867,\n                      0.3351, 0.3443, 0.0668, 0.3079, 0.3591, 0.5042, 0.5272, 0.5843, 0.2058,\n                      0.3878, 0.2597, 0.2097, 0.2800, 0.3690, 0.1457, 0.1344, 0.1432, 0.3141,\n                      0.1558, 0.3444, 0.1713, 0.2369, 0.2696, 0.1473, 0.3800, 0.2939, 0.3554,\n                      0.3341, 0.4072, 0.1675, 0.4181], dtype=torch.float64)),\n             ('4.2.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('4.2.convpath.0.0.0.weight',\n              tensor([[[ 0.0702],\n                       [-0.1698],\n                       [ 0.0550],\n                       ...,\n                       [ 0.2336],\n                       [ 0.0287],\n                       [ 0.0159]],\n              \n                      [[ 0.0541],\n                       [ 0.0581],\n                       [-0.0672],\n                       ...,\n                       [-0.0276],\n                       [-0.1097],\n                       [ 0.0335]],\n              \n                      [[ 0.0974],\n                       [ 0.0572],\n                       [ 0.1448],\n                       ...,\n                       [-0.1670],\n                       [-0.0445],\n                       [-0.0218]],\n              \n                      ...,\n              \n                      [[-0.0403],\n                       [ 0.0969],\n                       [ 0.0285],\n                       ...,\n                       [ 0.1109],\n                       [-0.1581],\n                       [-0.0688]],\n              \n                      [[ 0.0472],\n                       [ 0.0161],\n                       [ 0.0451],\n                       ...,\n                       [-0.0118],\n                       [ 0.0003],\n                       [-0.1417]],\n              \n                      [[-0.1838],\n                       [ 0.0187],\n                       [ 0.0299],\n                       ...,\n                       [ 0.0636],\n                       [-0.0217],\n                       [-0.1200]]], dtype=torch.float64)),\n             ('4.2.convpath.0.0.1.weight',\n              tensor([0.9464, 0.9544, 0.9544, 0.9406, 0.9657, 0.9796, 0.9911, 0.9462, 0.9470,\n                      0.9485, 0.9590, 0.9834, 0.9869, 0.9393, 0.9201, 0.9573, 0.9800, 0.9343,\n                      0.9711, 0.9364, 0.9834, 0.9484, 0.9501, 0.9312, 0.9601, 0.9669, 0.9615,\n                      0.9540, 0.9825, 0.9531, 0.9683, 0.9648, 0.9747, 0.9481, 0.9748, 0.9592,\n                      0.9760, 0.9416, 0.9526, 0.9392, 0.9587, 0.9612, 0.9515, 0.9770, 0.9669,\n                      0.9689, 0.9870, 0.9921, 0.9594, 0.9754, 0.9709, 0.9670, 0.9544, 0.9562,\n                      0.9368, 0.9454, 0.9812, 0.9478, 0.9984, 0.9660, 0.9485, 0.9321, 0.9549,\n                      0.9644], dtype=torch.float64)),\n             ('4.2.convpath.0.0.1.bias',\n              tensor([-1.9495e-02,  3.5216e-03,  1.2734e-02, -1.2759e-02,  5.8002e-06,\n                       1.2951e-02,  2.4563e-02,  1.0208e-05,  1.7490e-02, -1.7263e-02,\n                       8.1130e-03,  2.0233e-02,  1.7482e-02, -1.1692e-03,  3.6552e-04,\n                      -1.0009e-02,  1.2297e-02, -1.8936e-03,  1.2223e-02, -2.1336e-03,\n                       1.3507e-02,  1.0784e-02,  1.1740e-02, -1.8731e-02, -9.9534e-03,\n                       1.4411e-02, -1.3349e-02, -2.7622e-02, -9.7460e-03,  6.6328e-03,\n                      -9.0697e-03, -1.2296e-02,  2.1980e-03, -2.6876e-02, -1.0755e-02,\n                       1.3761e-02, -2.9314e-03,  3.0514e-03,  3.8375e-03, -1.4342e-02,\n                      -8.1784e-03, -2.2646e-03, -5.7542e-03, -3.3786e-03, -6.6312e-03,\n                       5.9922e-03,  1.9001e-02,  6.6351e-03, -3.8141e-03, -5.8616e-03,\n                       7.4615e-03,  1.0806e-02,  9.1947e-03,  4.5208e-03, -7.6495e-03,\n                       5.2995e-03,  8.5199e-03, -6.4357e-03,  1.5609e-03,  1.5071e-02,\n                      -1.4606e-02, -9.5897e-03, -4.6254e-03,  1.3692e-02],\n                     dtype=torch.float64)),\n             ('4.2.convpath.0.0.1.running_mean',\n              tensor([ 0.8013, -0.2368, -0.0489, -0.2212,  0.0110, -0.5408, -0.5364, -0.1092,\n                      -0.0800,  0.2726, -0.0555, -0.1361, -0.2313, -0.3139,  0.1442,  0.1016,\n                      -0.2290, -0.9682,  0.0298, -0.4661, -0.5634,  0.2962, -0.3537, -0.4533,\n                       0.2838,  0.2925, -0.5299, -0.0292,  0.0045, -0.6137,  0.0535, -0.3243,\n                      -0.2748,  0.1033,  0.4276, -0.0116,  0.7363, -0.7275, -0.3070,  0.5123,\n                      -0.4906, -0.0562,  0.0475,  0.9380, -0.8622,  0.4700, -0.6253, -0.5178,\n                      -0.1892,  0.4800, -0.1133,  0.0089, -0.0762, -0.7750, -0.0866,  0.0789,\n                      -0.8547, -0.6356, -0.6864,  0.0259,  0.1845,  0.1646, -0.2231, -0.2072],\n                     dtype=torch.float64)),\n             ('4.2.convpath.0.0.1.running_var',\n              tensor([0.8658, 1.0441, 0.4828, 0.4140, 0.4526, 0.3806, 0.3011, 0.6723, 0.5109,\n                      1.3491, 0.3508, 0.2678, 0.7463, 0.5745, 0.6340, 0.4593, 0.2861, 1.6291,\n                      0.6184, 0.8625, 0.6584, 0.3762, 1.0309, 0.8042, 0.5474, 0.9957, 0.3217,\n                      0.2816, 0.3237, 1.1559, 0.3513, 1.1314, 0.2869, 0.4829, 0.2436, 0.5693,\n                      0.5492, 0.8320, 0.4094, 0.4211, 0.2751, 0.8711, 0.4345, 0.4309, 0.2922,\n                      0.4506, 0.7352, 0.3182, 0.7248, 0.2263, 0.4969, 0.3575, 0.8962, 0.4385,\n                      0.4293, 0.9178, 0.3657, 0.7007, 0.2615, 1.4762, 0.3850, 0.8489, 0.7226,\n                      0.6106], dtype=torch.float64)),\n             ('4.2.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('4.2.convpath.0.1.0.weight',\n              tensor([[[ 1.5965e-02, -8.7334e-02,  2.3339e-02,  8.5295e-02,  5.2375e-02],\n                       [ 1.7278e-02,  2.4789e-02,  1.3672e-01, -1.1739e-01,  4.4454e-02],\n                       [ 6.7152e-02,  8.4430e-02,  7.5823e-02,  1.0004e-02, -1.0539e-02],\n                       ...,\n                       [ 6.4077e-03,  4.5944e-02,  1.1689e-02,  1.9172e-02, -6.5984e-02],\n                       [-1.5304e-02,  8.0513e-02,  1.2624e-01, -9.9547e-02, -6.2065e-02],\n                       [-6.6264e-02,  1.5129e-02, -5.6860e-02,  7.6153e-02, -2.2226e-03]],\n              \n                      [[ 6.2345e-02, -2.5090e-02, -4.0143e-02, -2.1504e-02, -8.5179e-04],\n                       [ 3.5015e-02,  3.2886e-02,  1.3576e-02,  3.0697e-02, -7.2117e-02],\n                       [ 2.6434e-03,  2.1661e-02, -1.0804e-01, -1.2891e-01, -7.7489e-02],\n                       ...,\n                       [-4.2200e-02,  4.3630e-02,  4.4493e-02,  4.3232e-02, -7.4799e-02],\n                       [ 9.7887e-02, -6.7348e-02,  5.8831e-02,  1.8867e-02,  1.4218e-01],\n                       [-4.9538e-02, -8.2036e-02,  3.4987e-02,  2.5011e-02,  8.4173e-03]],\n              \n                      [[-2.5509e-02, -3.9872e-03,  4.3003e-02, -1.6950e-02,  8.7339e-02],\n                       [ 4.8127e-02,  6.1724e-02, -7.5430e-02, -7.5543e-02,  3.0899e-02],\n                       [-7.6841e-03,  1.8897e-02,  4.7319e-02,  4.9399e-02, -8.9394e-02],\n                       ...,\n                       [ 2.5673e-02,  3.3955e-02, -5.6531e-02, -8.9550e-02, -1.2304e-01],\n                       [ 2.3678e-02, -6.8152e-02,  7.5393e-02, -1.8406e-02, -1.2966e-01],\n                       [ 7.6372e-02,  2.6798e-02,  2.6066e-02, -2.6055e-03,  5.6527e-02]],\n              \n                      ...,\n              \n                      [[ 1.3829e-01,  4.6206e-02,  1.1636e-01,  2.2173e-02, -5.3954e-02],\n                       [ 2.9702e-02,  4.0493e-02, -7.5827e-02, -2.1623e-02, -3.2042e-02],\n                       [-5.0497e-02,  5.0515e-02,  6.9311e-02,  1.3458e-01,  1.6030e-01],\n                       ...,\n                       [ 7.9468e-02,  1.8635e-01, -3.1411e-02,  2.3866e-02, -5.2812e-03],\n                       [ 5.4575e-03, -9.9997e-02, -4.2273e-02, -5.6591e-02,  1.3082e-01],\n                       [-1.3916e-01, -3.5978e-02, -6.6961e-03, -8.0260e-02,  2.1887e-02]],\n              \n                      [[ 7.5167e-02,  6.8957e-02, -7.1652e-02, -8.5743e-02,  1.3428e-01],\n                       [ 3.9528e-02, -1.0137e-02, -1.9709e-02,  9.0289e-03,  1.1808e-02],\n                       [ 7.6913e-02,  9.0583e-02, -1.6944e-01,  1.7404e-01,  2.0995e-02],\n                       ...,\n                       [-2.0166e-02, -1.4202e-02, -4.3247e-02, -2.1059e-02,  1.8705e-01],\n                       [ 2.0755e-02,  5.1492e-02, -4.3478e-02,  4.5100e-02, -7.4607e-02],\n                       [ 8.3739e-02,  3.6374e-02,  1.1067e-01, -6.5703e-04,  4.2008e-02]],\n              \n                      [[-5.6865e-02, -2.6879e-02,  1.1214e-05,  9.6894e-02, -3.4499e-03],\n                       [-1.3260e-01,  5.2316e-02,  6.5022e-02, -6.2424e-02,  9.2010e-02],\n                       [ 3.6169e-02, -8.1982e-02, -3.1340e-02,  2.6578e-02, -1.2896e-02],\n                       ...,\n                       [ 1.8496e-02,  5.0213e-02, -4.0650e-02,  5.9497e-02, -8.6081e-02],\n                       [ 1.1426e-01,  3.3271e-02, -9.0838e-02,  7.1756e-03,  1.0398e-01],\n                       [-2.1491e-02,  7.3455e-02,  2.9381e-02,  1.2381e-02, -1.4010e-02]]],\n                     dtype=torch.float64)),\n             ('4.2.convpath.0.1.1.weight',\n              tensor([0.9423, 0.9662, 0.9396, 0.9476, 0.9674, 0.9272, 0.9681, 0.9722, 0.9339,\n                      0.9761, 0.9349, 0.9861, 0.9671, 0.9391, 0.9457, 0.9982, 0.9010, 0.9275,\n                      0.9353, 0.9832, 0.9404, 0.9281, 0.9358, 0.9515, 0.9156, 0.9391, 0.9292,\n                      0.9614, 0.9226, 0.9436, 0.9280, 0.9120, 0.9815, 0.9537, 0.9291, 0.9343,\n                      0.9925, 0.9345, 0.9737, 0.9434, 0.9873, 0.9853, 0.9333, 0.9774, 0.9498,\n                      0.9194, 0.9493, 0.9525, 0.9345, 0.9618, 0.9711, 0.9491, 0.9519, 0.9380,\n                      0.9567, 0.9804, 0.9453, 0.9842, 0.9697, 0.9792, 0.8994, 0.9496, 0.9489,\n                      0.9191], dtype=torch.float64)),\n             ('4.2.convpath.0.1.1.bias',\n              tensor([-1.3109e-02,  1.8005e-02, -6.5840e-03, -7.9476e-03, -4.4230e-04,\n                      -4.4252e-03, -9.3745e-03,  2.3976e-02,  1.8121e-03,  5.4741e-03,\n                       1.0906e-02,  9.0400e-03,  2.3741e-03, -1.6474e-02,  3.7379e-03,\n                       1.0767e-02, -2.5383e-02, -2.4819e-02,  2.1622e-02,  6.8772e-03,\n                      -1.7393e-02, -1.1126e-02, -2.4145e-02,  7.6955e-04, -2.1592e-02,\n                      -1.5686e-02, -1.0719e-02, -2.8384e-05, -3.7678e-03,  1.4840e-02,\n                      -3.5656e-03, -1.6408e-02, -1.0770e-02, -8.5793e-03, -2.8265e-03,\n                      -1.8730e-02,  2.9778e-02,  3.6265e-03,  1.7948e-02, -1.0905e-02,\n                       6.9440e-03, -6.7054e-03, -1.8334e-02,  1.1669e-02, -1.3875e-02,\n                      -5.9053e-03, -1.1787e-03,  1.8392e-02, -1.8350e-03,  8.8758e-03,\n                       1.0188e-02, -2.2408e-02, -4.3536e-03, -2.8781e-03, -1.5995e-02,\n                       2.6976e-02, -1.3820e-02, -2.4503e-03,  9.3554e-03, -1.0622e-03,\n                      -1.0494e-02, -5.1209e-03, -2.7442e-02, -1.5361e-02],\n                     dtype=torch.float64)),\n             ('4.2.convpath.0.1.1.running_mean',\n              tensor([ 0.5599, -0.6813,  0.5047,  0.0202, -0.4026,  0.0520,  0.3703, -0.3439,\n                      -0.3455, -0.8571, -0.2387, -0.1952,  0.2586, -0.1220,  0.1479, -0.2297,\n                      -0.4347,  0.3835, -0.5195, -0.0291,  0.1048,  0.4773,  1.2663, -0.2231,\n                       0.0830,  0.1964, -0.1539,  0.0284, -0.2582, -0.5224,  0.1370, -0.1453,\n                      -0.3110,  0.3673, -0.7171,  0.3127,  0.3361, -0.0663, -0.6876,  0.4397,\n                      -0.1260,  0.2848, -0.3000, -0.7592, -0.0198, -0.3640, -0.0108,  0.3412,\n                       0.1658, -0.3082, -0.3016,  0.6141,  0.1885, -0.1382, -1.1476, -0.1223,\n                      -0.7389, -0.4085, -0.5790,  0.8025, -0.0469, -0.1233,  0.5507,  0.2853],\n                     dtype=torch.float64)),\n             ('4.2.convpath.0.1.1.running_var',\n              tensor([0.9067, 0.3428, 0.4494, 0.3018, 0.2833, 0.4519, 0.4343, 0.5535, 0.7867,\n                      0.5390, 0.4694, 0.3933, 0.3447, 0.4470, 0.4655, 0.2867, 1.0934, 1.0591,\n                      0.4050, 0.3376, 0.5769, 0.5339, 1.1698, 0.3003, 0.4116, 0.5572, 0.5072,\n                      0.5395, 0.5949, 0.3919, 0.6542, 0.3395, 0.3884, 0.9852, 0.5406, 0.7128,\n                      0.5391, 0.4167, 0.6062, 0.5158, 0.4401, 0.3453, 0.4030, 0.4781, 0.3605,\n                      0.5585, 0.4536, 0.4190, 0.2972, 0.7026, 0.6629, 0.8444, 0.2798, 0.4130,\n                      0.3815, 0.4689, 0.4057, 0.6268, 0.4900, 0.3708, 0.7184, 0.4737, 0.5560,\n                      0.5098], dtype=torch.float64)),\n             ('4.2.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('4.2.convpath.0.2.0.weight',\n              tensor([[[-0.0321],\n                       [-0.1682],\n                       [ 0.0317],\n                       ...,\n                       [ 0.1145],\n                       [-0.1091],\n                       [-0.0575]],\n              \n                      [[-0.1367],\n                       [ 0.0007],\n                       [ 0.0081],\n                       ...,\n                       [-0.0289],\n                       [-0.2310],\n                       [-0.0343]],\n              \n                      [[-0.1589],\n                       [-0.1134],\n                       [ 0.3602],\n                       ...,\n                       [ 0.0616],\n                       [-0.0984],\n                       [-0.1072]],\n              \n                      ...,\n              \n                      [[-0.0441],\n                       [ 0.2674],\n                       [-0.1192],\n                       ...,\n                       [-0.1718],\n                       [-0.0294],\n                       [ 0.2213]],\n              \n                      [[ 0.0906],\n                       [ 0.1696],\n                       [-0.1439],\n                       ...,\n                       [-0.1461],\n                       [-0.0710],\n                       [-0.0285]],\n              \n                      [[ 0.0423],\n                       [-0.3263],\n                       [ 0.0508],\n                       ...,\n                       [-0.0360],\n                       [-0.1137],\n                       [-0.0988]]], dtype=torch.float64)),\n             ('4.2.convpath.0.2.1.weight',\n              tensor([ 0.0042, -0.0382,  0.0169,  0.0011, -0.0347,  0.0163, -0.0213,  0.0145,\n                      -0.0151,  0.0092,  0.0006,  0.0256,  0.0126, -0.0153, -0.0065,  0.0181,\n                      -0.0318, -0.0134, -0.0193,  0.0100,  0.0104,  0.0300, -0.0208,  0.0320,\n                      -0.0220, -0.0164,  0.0122,  0.0164,  0.0200,  0.0077, -0.0025, -0.0379,\n                      -0.0076, -0.0049,  0.0416,  0.0206,  0.0034,  0.0127,  0.0054, -0.0253,\n                      -0.0110,  0.0110, -0.0207, -0.0320,  0.0231, -0.0063, -0.0082, -0.0028,\n                      -0.0250, -0.0130, -0.0179, -0.0020,  0.0167,  0.0182, -0.0031, -0.0101,\n                      -0.0054,  0.0097, -0.0141,  0.0067,  0.0051,  0.0297,  0.0026, -0.0160,\n                      -0.0171,  0.0184,  0.0098, -0.0118,  0.0307, -0.0137, -0.0050,  0.0069,\n                       0.0118, -0.0020, -0.0246, -0.0069, -0.0028,  0.0095, -0.0166,  0.0064,\n                      -0.0104, -0.0068,  0.0499, -0.0194, -0.0130, -0.0101,  0.0283,  0.0318,\n                       0.0528,  0.0088, -0.0092,  0.0177, -0.0045,  0.0023,  0.0003,  0.0174,\n                      -0.0134, -0.0217, -0.0123,  0.0074,  0.0057, -0.0140,  0.0310,  0.0282,\n                      -0.0057,  0.0180,  0.0215,  0.0147,  0.0366,  0.0044, -0.0040,  0.0090,\n                      -0.0362, -0.0171, -0.0110, -0.0152, -0.0031, -0.0073,  0.0117,  0.0077,\n                      -0.0234, -0.0219, -0.0195,  0.0271, -0.0018, -0.0014,  0.0122, -0.0163,\n                       0.0234, -0.0346,  0.0059, -0.0202,  0.0341,  0.0213,  0.0021,  0.0016,\n                      -0.0061, -0.0095,  0.0222,  0.0008, -0.0047, -0.0141, -0.0098,  0.0347,\n                      -0.0047, -0.0378, -0.0214, -0.0105,  0.0021,  0.0161,  0.0256,  0.0007,\n                      -0.0284, -0.0170, -0.0010,  0.0181,  0.0049,  0.0111, -0.0018,  0.0154,\n                      -0.0098,  0.0209, -0.0156,  0.0211,  0.0097, -0.0191, -0.0040,  0.0080,\n                       0.0059, -0.0300,  0.0013,  0.0193, -0.0073,  0.0064,  0.0120,  0.0109,\n                       0.0080,  0.0215, -0.0303, -0.0084,  0.0086, -0.0129, -0.0029, -0.0115,\n                       0.0393, -0.0093, -0.0376,  0.0521,  0.0153, -0.0145,  0.0044,  0.0058,\n                      -0.0270,  0.0194,  0.0249, -0.0024,  0.0042, -0.0095,  0.0025,  0.0011,\n                       0.0021, -0.0277,  0.0147, -0.0127,  0.0033,  0.0045, -0.0342,  0.0207,\n                       0.0100,  0.0192,  0.0058,  0.0103,  0.0002,  0.0090, -0.0087,  0.0029,\n                      -0.0103, -0.0278, -0.0128,  0.0141, -0.0035,  0.0119,  0.0036, -0.0154,\n                       0.0085,  0.0126, -0.0141, -0.0009, -0.0014, -0.0076, -0.0352,  0.0166,\n                      -0.0433,  0.0051, -0.0161,  0.0024, -0.0136, -0.0205, -0.0086,  0.0156,\n                       0.0048, -0.0023, -0.0004,  0.0185, -0.0261, -0.0085, -0.0071,  0.0134,\n                       0.0174, -0.0486, -0.0148,  0.0266, -0.0191,  0.0320, -0.0035,  0.0223],\n                     dtype=torch.float64)),\n             ('4.2.convpath.0.2.1.bias',\n              tensor([ 2.2981e-03,  6.0355e-03,  3.0007e-02, -1.3390e-03,  1.4013e-02,\n                      -1.6159e-02, -3.2799e-03, -1.3372e-03, -1.2572e-02, -9.1693e-03,\n                      -5.5602e-03, -5.7822e-03,  1.4705e-02, -1.3795e-02,  8.6815e-03,\n                       5.6836e-03,  3.3969e-02,  6.5681e-03,  2.4544e-02, -9.3135e-04,\n                       1.7069e-03,  4.4020e-03,  6.4256e-04, -1.0262e-03,  1.7300e-03,\n                      -2.3364e-02,  3.7162e-03,  1.3636e-02,  1.1473e-02,  5.0608e-03,\n                      -8.9330e-03,  2.1448e-02, -1.1811e-02,  1.6927e-02,  1.3091e-02,\n                      -3.2098e-04, -8.9734e-03,  4.5552e-03, -1.3376e-02, -7.0448e-03,\n                       1.0680e-02, -8.3521e-03, -1.8405e-03,  1.1746e-02,  6.9080e-03,\n                      -4.2487e-03, -1.5921e-02,  8.3356e-03, -3.3936e-03, -3.0647e-03,\n                      -1.9244e-03,  3.4782e-03,  1.6608e-02,  2.8802e-02, -7.5906e-03,\n                       2.0866e-03,  2.3706e-03,  5.4979e-03, -1.7742e-02,  9.0638e-03,\n                      -7.1016e-03,  8.6566e-04, -1.9732e-02,  2.8876e-04,  4.0477e-03,\n                       1.4831e-02, -6.1769e-03,  2.3492e-02,  2.4774e-02, -1.7151e-02,\n                       1.1681e-02,  7.9894e-03,  7.3410e-03, -6.5583e-03, -4.5579e-03,\n                       1.7578e-02,  7.3620e-03, -1.8193e-02,  1.6897e-03,  1.0131e-02,\n                      -6.3668e-03,  6.6972e-04,  1.7577e-02,  4.7862e-03,  4.9707e-03,\n                      -2.2640e-02,  1.4011e-02,  1.3818e-02,  6.8424e-03, -3.7594e-03,\n                       5.8248e-03,  1.0848e-02,  1.4915e-02,  6.6864e-03,  5.0534e-03,\n                      -1.2815e-02,  1.1481e-02,  1.0703e-02,  1.3009e-02, -1.1513e-02,\n                       2.2523e-02,  1.2651e-03, -5.1943e-03, -1.3343e-02,  4.8336e-03,\n                       1.1113e-02, -1.1996e-02, -9.7674e-04,  1.7487e-02, -9.8886e-03,\n                      -1.3223e-02, -6.4504e-03,  1.3571e-02,  1.4810e-02,  1.5687e-02,\n                       8.7651e-03,  9.3772e-03,  1.1581e-02,  1.1279e-02, -6.1102e-03,\n                       1.7679e-02, -1.1416e-02,  2.0439e-03,  2.6063e-03, -8.8128e-03,\n                       1.2904e-02,  4.2038e-03,  7.4398e-03,  1.1056e-02, -6.8831e-04,\n                      -7.3310e-03,  6.1786e-03,  2.0150e-03,  5.3117e-03, -7.2624e-03,\n                      -1.6135e-02,  4.1060e-03,  2.9873e-02, -1.4422e-03, -7.6886e-03,\n                       7.2946e-04,  9.8148e-03, -9.9029e-03, -2.2951e-03, -1.5686e-02,\n                      -5.4162e-03,  4.6320e-03, -5.8741e-03,  1.2422e-02,  2.3152e-02,\n                       1.9946e-03, -1.2418e-02, -2.4738e-02,  1.7292e-02, -4.1586e-03,\n                       1.1232e-02,  9.4844e-03,  2.1819e-02, -4.1767e-03, -2.0144e-02,\n                      -9.9166e-05,  1.1130e-02, -1.1883e-02,  1.8993e-02,  1.7969e-02,\n                       1.0380e-02, -7.9747e-03,  2.1661e-02,  1.2728e-02,  2.3638e-02,\n                       1.2848e-02, -4.1754e-03, -8.3021e-03,  2.0047e-02, -1.6692e-02,\n                      -6.1638e-03,  6.3373e-03,  2.3157e-02,  1.6104e-02, -2.4939e-03,\n                      -3.7590e-03,  1.3873e-03, -9.7327e-03, -1.1150e-03,  5.9546e-03,\n                       7.6138e-03,  1.7157e-02,  3.2642e-02, -1.7507e-03,  8.1882e-03,\n                      -7.7682e-03, -1.4533e-02,  3.6442e-03, -1.7871e-02,  1.0974e-02,\n                       1.8575e-02, -4.9975e-03,  1.4283e-02,  1.2792e-02, -1.6664e-02,\n                       1.5296e-02,  3.0710e-03,  9.8463e-04,  1.6290e-02,  3.6353e-03,\n                      -5.9694e-03,  8.4527e-03, -1.6902e-02,  6.0383e-03,  1.0562e-02,\n                       6.0151e-03, -9.1413e-03,  7.7327e-03, -1.0408e-03,  1.8305e-03,\n                       1.2953e-02,  3.5994e-03,  1.0672e-02,  1.2097e-02,  1.0209e-02,\n                      -8.4629e-05, -1.0060e-02,  1.1748e-02,  7.4849e-05, -1.4349e-03,\n                       1.8271e-02,  1.0349e-02,  4.8985e-03, -2.4221e-02, -3.6036e-03,\n                      -2.4693e-03,  1.0476e-02,  2.7278e-02,  3.1265e-03, -1.8923e-03,\n                       6.9213e-03,  1.5240e-02,  6.3762e-03, -9.1332e-03,  5.0912e-03,\n                      -5.5732e-03,  4.1736e-03,  1.1687e-02,  3.5444e-03,  1.3644e-02,\n                       1.8368e-02, -1.2853e-03,  1.3878e-02, -1.0017e-02, -1.4650e-02,\n                       1.9003e-02, -1.2700e-03, -1.0338e-02,  2.2673e-02,  2.3178e-02,\n                       6.8945e-03], dtype=torch.float64)),\n             ('4.2.convpath.0.2.1.running_mean',\n              tensor([ 2.2142e-01, -3.5158e-02,  4.7936e-01,  1.3704e-01,  1.5016e-01,\n                      -2.9301e-01,  2.8332e-01,  1.4424e-01,  2.8096e-01,  6.1163e-01,\n                       8.5292e-02,  7.7581e-02,  6.1009e-02,  1.1685e-01, -6.7240e-01,\n                      -6.9520e-04, -3.9635e-01,  8.0276e-01,  6.6967e-01, -8.1997e-01,\n                       1.6503e-01, -2.0750e-01,  4.3678e-01, -6.5098e-01,  1.7848e-01,\n                      -2.4521e-01, -3.7271e-01,  1.5257e-01,  3.0628e-01,  3.0542e-01,\n                      -2.9402e-01,  8.3692e-01,  6.5709e-02,  6.5633e-02, -3.4898e-01,\n                       4.7584e-01,  1.6067e-02,  1.6485e-01,  2.4903e-01, -4.5836e-01,\n                      -1.1768e-01, -2.3431e-01,  1.8861e-01, -2.9288e-02,  3.6511e-01,\n                      -3.2776e-01, -3.3418e-01, -2.8739e-02,  1.3645e-01,  3.3940e-01,\n                       1.6950e-01, -1.8935e-01,  1.6950e-01,  7.7983e-02,  8.8855e-02,\n                      -6.1477e-02, -2.3188e-01, -6.3246e-02, -2.6731e-01,  8.7092e-02,\n                       1.4543e-01, -4.9972e-02,  3.5225e-01, -2.4500e-01,  1.5744e-01,\n                      -1.2062e-01, -1.9639e-01,  1.0864e-01, -2.0654e-01, -1.0682e-01,\n                      -4.9675e-02, -8.4615e-02, -1.4485e-01,  6.9949e-01,  5.1589e-01,\n                      -8.8552e-02,  1.4291e-02, -1.8502e-01,  4.4828e-01, -2.1247e-01,\n                       1.6623e-01,  2.0076e-01, -3.7122e-01,  7.7382e-01,  2.8990e-01,\n                      -7.4275e-01,  5.1118e-01,  4.3443e-02, -2.5806e-02, -1.3909e-01,\n                      -2.1683e-01,  1.1638e-01,  3.9570e-02, -5.1656e-02, -3.9182e-02,\n                      -2.6096e-02, -5.1525e-01,  2.1138e-01, -1.8937e-01,  6.1392e-01,\n                       4.6584e-02, -3.5009e-01,  1.7265e-01,  1.0096e-01, -3.9140e-01,\n                      -6.0333e-01,  1.2356e-01,  1.3604e-01, -3.1294e-01,  1.1004e-01,\n                       2.2361e-01, -1.0477e-01,  1.4201e-01, -2.6361e-03, -2.4967e-01,\n                       1.2752e-01, -1.0775e-01,  9.8541e-02, -2.6598e-01, -2.1570e-01,\n                      -1.9860e-01,  1.2686e-01, -9.8351e-02,  5.9487e-01, -3.1013e-02,\n                      -8.9968e-02,  6.7673e-01, -2.0401e-01,  1.0732e-01,  2.4746e-01,\n                      -1.3224e-01,  2.6989e-01, -4.6560e-01,  7.1059e-02, -1.3566e-01,\n                       2.8899e-01, -8.2771e-02,  1.2047e-01,  1.1373e-01,  3.0030e-01,\n                      -4.7368e-01,  1.5133e-02, -3.6606e-01, -3.1214e-02,  2.0281e-01,\n                      -6.2564e-02, -7.9454e-01,  8.2024e-01, -1.1752e-01,  1.1513e-02,\n                       1.1064e-01,  3.1738e-01,  2.2243e-01, -4.2587e-02,  3.4996e-03,\n                       3.0102e-01,  1.4794e-01, -2.7961e-01, -1.5764e-01,  2.8097e-01,\n                      -2.8864e-01, -4.7957e-01, -5.0146e-02,  4.9852e-01,  4.6698e-01,\n                       3.2214e-01,  3.0504e-01,  2.9440e-01, -4.2277e-01,  1.7022e-01,\n                       6.4302e-02,  1.0283e-01,  8.1499e-02,  5.0447e-02,  4.7729e-01,\n                       6.8529e-03,  6.2631e-02,  4.5509e-01, -2.7544e-01, -2.9442e-01,\n                      -1.5363e-01,  1.5365e-01,  5.7494e-01,  3.2734e-01,  1.6687e-01,\n                       1.4306e-01,  1.1846e-01,  2.5563e-01, -5.9768e-01, -3.1768e-01,\n                       5.6654e-05, -2.2829e-01,  5.9329e-01, -3.3185e-01, -3.3549e-01,\n                      -4.2196e-02,  8.0192e-02,  2.6960e-01, -1.2091e-01,  1.0461e-01,\n                       4.3255e-01,  1.8091e-01,  4.4113e-01, -4.1657e-02, -5.0203e-01,\n                       3.5528e-02,  4.7656e-01, -1.5542e-01,  6.5555e-02, -2.3467e-01,\n                       1.7397e-01,  1.2085e-01,  2.3107e-01,  2.1652e-01,  1.5883e-01,\n                      -2.4920e-02, -1.2971e-01,  2.5491e-01,  2.0970e-01, -7.3771e-01,\n                      -4.8901e-02,  5.9636e-02,  6.8819e-02, -1.4104e-01,  9.0482e-01,\n                       2.0468e-01, -4.2534e-01, -1.5065e-01,  3.2987e-01, -2.1250e-01,\n                      -3.9264e-01, -9.6778e-02, -3.1806e-01, -1.6343e-01,  3.3466e-01,\n                      -3.8532e-01, -4.0276e-01,  2.7974e-02, -1.2858e-01, -2.5921e-01,\n                      -1.2651e-01,  1.6659e-01, -1.6267e-01, -1.4795e-01, -7.3921e-03,\n                      -1.9303e-01, -5.0223e-01,  4.1150e-01,  3.2483e-01, -4.1626e-02,\n                      -2.3209e-01, -2.6750e-01, -6.4750e-02, -3.3819e-01, -5.1727e-02,\n                      -3.8360e-01], dtype=torch.float64)),\n             ('4.2.convpath.0.2.1.running_var',\n              tensor([0.3494, 0.3664, 0.5004, 0.2424, 0.4853, 0.2903, 0.2619, 0.3312, 0.1057,\n                      0.3090, 0.1433, 0.2842, 0.2199, 0.3126, 0.6621, 0.2775, 0.3625, 0.7359,\n                      0.3012, 0.3333, 0.2643, 0.4854, 0.2571, 0.3565, 0.4389, 0.1531, 0.3283,\n                      0.3391, 0.2246, 0.2702, 0.3921, 0.6336, 0.2376, 0.1874, 0.3359, 0.3782,\n                      0.0775, 0.3302, 0.1297, 0.7002, 0.4018, 0.0763, 0.1583, 0.6357, 0.5126,\n                      0.1717, 0.2589, 0.0645, 0.4337, 0.3108, 0.2681, 0.1602, 0.3169, 0.2280,\n                      0.1088, 0.1705, 0.1895, 0.3184, 0.2708, 0.2359, 0.0773, 0.2504, 0.2813,\n                      0.3729, 0.6203, 0.3734, 0.3693, 0.4202, 0.4217, 0.2804, 0.3392, 0.1044,\n                      0.2604, 0.5761, 0.6272, 0.1467, 0.1798, 0.1571, 0.3038, 0.1496, 0.3359,\n                      0.1670, 0.4270, 0.5396, 0.1584, 0.2921, 0.4444, 0.3492, 0.3100, 0.0724,\n                      0.3694, 0.3629, 0.4728, 0.0720, 0.0826, 0.2072, 0.5206, 0.1613, 0.4708,\n                      0.3128, 0.3138, 0.2628, 0.2690, 0.2873, 0.3417, 0.4148, 0.2431, 0.3579,\n                      0.4063, 0.0342, 0.1433, 0.4559, 0.3074, 0.4460, 0.4856, 0.1305, 0.1772,\n                      0.4879, 0.1669, 0.1863, 0.2000, 0.4973, 0.4043, 0.4526, 0.0449, 0.1972,\n                      0.3342, 0.2001, 0.2827, 0.2879, 0.0789, 0.4231, 0.5012, 0.3574, 0.0993,\n                      0.1236, 0.2986, 0.2042, 0.1935, 0.2214, 0.1848, 0.2062, 0.3228, 0.2898,\n                      0.1555, 0.6018, 0.2927, 0.5353, 0.0708, 0.2957, 0.3032, 0.0721, 0.4335,\n                      0.2709, 0.0514, 0.5275, 0.1669, 0.1499, 0.1675, 0.2188, 0.3065, 0.3264,\n                      0.1616, 0.3622, 0.2976, 0.3722, 0.4573, 0.1545, 0.1959, 0.6024, 0.0432,\n                      0.3219, 0.1022, 0.0954, 0.4639, 0.3849, 0.3074, 0.5008, 0.3763, 0.1747,\n                      0.1534, 0.2606, 0.4120, 0.2213, 0.3451, 0.1596, 0.6406, 0.3423, 0.5384,\n                      0.4377, 0.0987, 0.1373, 0.2969, 0.4314, 0.3624, 0.3267, 0.2923, 0.2659,\n                      0.1215, 0.0513, 0.1512, 0.2044, 0.4376, 0.2054, 0.3051, 0.2576, 0.2613,\n                      0.0522, 0.1541, 0.3856, 0.1245, 0.2651, 0.0817, 0.1799, 0.0465, 0.0550,\n                      0.2209, 0.2880, 0.4932, 0.4446, 0.0395, 0.2346, 0.1144, 0.3688, 0.3867,\n                      0.3351, 0.3443, 0.0668, 0.3079, 0.3591, 0.5042, 0.5272, 0.5843, 0.2058,\n                      0.3878, 0.2597, 0.2097, 0.2800, 0.3690, 0.1457, 0.1344, 0.1432, 0.3141,\n                      0.1558, 0.3444, 0.1713, 0.2369, 0.2696, 0.1473, 0.3800, 0.2939, 0.3554,\n                      0.3341, 0.4072, 0.1675, 0.4181], dtype=torch.float64)),\n             ('4.2.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('5.0.convs.0.0.weight',\n              tensor([[[-1.6193e-02],\n                       [ 1.4339e-01],\n                       [-3.9059e-02],\n                       ...,\n                       [-9.8477e-02],\n                       [-4.0168e-03],\n                       [ 1.2020e-01]],\n              \n                      [[-1.2132e-01],\n                       [-2.2085e-02],\n                       [ 4.3886e-02],\n                       ...,\n                       [-6.4113e-02],\n                       [ 1.9117e-02],\n                       [ 7.6345e-02]],\n              \n                      [[-6.9510e-02],\n                       [ 2.0369e-01],\n                       [-6.5022e-02],\n                       ...,\n                       [-4.0309e-02],\n                       [-1.4086e-01],\n                       [-1.7633e-01]],\n              \n                      ...,\n              \n                      [[ 5.3615e-02],\n                       [-2.1643e-01],\n                       [ 1.3548e-04],\n                       ...,\n                       [ 4.9714e-02],\n                       [ 1.3369e-01],\n                       [ 5.6184e-02]],\n              \n                      [[ 6.0763e-02],\n                       [ 1.3545e-01],\n                       [-1.2473e-01],\n                       ...,\n                       [ 8.8573e-02],\n                       [-6.8880e-02],\n                       [ 8.5210e-02]],\n              \n                      [[-3.9655e-02],\n                       [ 2.7945e-02],\n                       [-1.0454e-02],\n                       ...,\n                       [-6.4360e-02],\n                       [ 1.6623e-01],\n                       [ 3.4773e-02]]], dtype=torch.float64)),\n             ('5.0.convs.0.1.weight',\n              tensor([0.9612, 0.9548, 0.9841, 0.8988, 0.9710, 0.9649, 0.9483, 0.9637, 0.9605,\n                      0.9574, 0.9840, 0.9386, 0.9626, 0.9424, 0.9501, 0.9514, 0.9488, 0.9807,\n                      0.9543, 0.9809, 0.9639, 0.9642, 0.9732, 0.9402, 0.9635, 0.9702, 0.9569,\n                      0.9386, 0.9480, 0.9715, 0.9638, 0.9893, 0.9654, 0.9769, 0.9565, 0.9727,\n                      0.9721, 0.9553, 0.9668, 0.9733, 0.9509, 0.9796, 0.9436, 0.9823, 0.9745,\n                      0.9718, 0.9768, 0.9696, 0.9571, 0.9752, 0.9738, 0.9686, 0.9642, 0.9599,\n                      0.9588, 0.9526, 0.9548, 0.9389, 0.9473, 0.9790, 0.9661, 0.9730, 0.9692,\n                      0.9792], dtype=torch.float64)),\n             ('5.0.convs.0.1.bias',\n              tensor([ 5.6125e-03, -1.3392e-02, -2.4821e-03, -2.0347e-02,  2.0468e-03,\n                       1.7624e-02, -2.3028e-02,  9.1761e-03, -7.5666e-03,  4.8939e-03,\n                       1.9081e-02, -7.0951e-03, -1.3071e-02,  2.9753e-03,  1.1719e-02,\n                      -4.5798e-04,  2.9463e-03, -1.8419e-02, -8.9741e-03, -9.1919e-03,\n                      -1.7555e-02,  1.6522e-03,  5.3877e-03, -1.7726e-02,  7.6360e-03,\n                      -7.0222e-05, -1.4356e-02, -8.8763e-03, -1.1436e-02,  1.9395e-02,\n                      -8.7408e-03,  2.0512e-03, -9.0275e-03, -4.8991e-03, -6.0910e-03,\n                      -1.6335e-02,  2.5532e-02, -6.9656e-04, -8.3465e-04, -2.2590e-02,\n                      -6.0248e-04,  1.3854e-02, -7.5309e-03, -1.2159e-02, -3.7264e-03,\n                       9.6112e-03, -6.0236e-03, -5.1005e-04, -9.7465e-04,  2.2000e-02,\n                      -1.7667e-03,  7.9870e-03,  1.7791e-02,  1.1027e-02, -2.3230e-03,\n                      -5.3583e-03,  1.2229e-02, -1.5513e-02,  5.9525e-03, -4.3905e-03,\n                       1.1867e-02, -9.7494e-03,  2.1736e-02, -1.7782e-02],\n                     dtype=torch.float64)),\n             ('5.0.convs.0.1.running_mean',\n              tensor([ 0.5184,  0.9086,  0.5741, -0.3299, -0.2047,  0.6258, -0.1037, -0.2019,\n                       0.1684, -0.5944, -0.1803, -0.2233, -0.1019,  0.2525, -0.4697,  0.5870,\n                       0.5860, -0.2809,  0.5662, -0.1987,  0.1073,  0.2324, -0.2151,  0.6797,\n                      -0.1383,  0.7590,  0.5590, -0.1111,  0.4753, -1.0378,  0.1913,  0.0987,\n                      -0.1458,  0.2429,  0.3652, -0.1003,  0.1869,  0.2412,  0.0066, -0.2072,\n                      -0.2106,  0.0900, -0.0302,  0.1881,  0.1006, -0.1501, -0.4074,  0.2443,\n                      -0.3751, -0.5529, -0.0377, -0.3751, -0.2253, -0.1928, -0.1997, -0.1209,\n                       0.0624, -0.0180, -0.0045,  0.8905, -0.4463, -0.0650, -0.0415, -0.1543],\n                     dtype=torch.float64)),\n             ('5.0.convs.0.1.running_var',\n              tensor([0.3204, 2.5917, 0.3345, 2.0139, 0.6740, 1.3483, 0.4906, 0.7597, 0.3381,\n                      0.3165, 0.7291, 0.6836, 0.6696, 0.3006, 0.7443, 0.3772, 0.6199, 0.3920,\n                      0.7972, 0.5937, 0.3762, 0.2632, 0.6530, 0.4224, 0.3020, 0.8255, 0.3730,\n                      0.3612, 0.7546, 0.4975, 0.3082, 0.3788, 0.2388, 0.3157, 0.7938, 0.3169,\n                      0.3124, 0.4118, 0.4253, 0.3924, 0.4320, 0.3413, 0.4494, 0.4278, 0.3284,\n                      0.4717, 0.2275, 0.3343, 0.7079, 0.4269, 0.3834, 0.3875, 0.5796, 0.2694,\n                      0.7276, 0.3019, 0.8488, 0.6803, 0.8303, 0.9048, 0.2939, 0.3141, 0.3811,\n                      0.4750], dtype=torch.float64)),\n             ('5.0.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('5.0.convs.1.0.weight',\n              tensor([[[-0.0448,  0.0357,  0.0548, -0.0142,  0.1158],\n                       [ 0.0934, -0.1324,  0.0485,  0.1063, -0.0690],\n                       [ 0.0348,  0.0770,  0.0354,  0.0389,  0.1044],\n                       ...,\n                       [ 0.0129,  0.0111,  0.0293,  0.0092,  0.0146],\n                       [-0.0357,  0.0855,  0.0461,  0.0151, -0.0019],\n                       [-0.0180,  0.0213, -0.1474,  0.0530,  0.0009]],\n              \n                      [[-0.0665, -0.0622, -0.0062, -0.0767, -0.0284],\n                       [ 0.0491, -0.0174, -0.0600,  0.1014, -0.0745],\n                       [-0.0595, -0.0391,  0.0708, -0.0292,  0.0896],\n                       ...,\n                       [-0.1708, -0.0805, -0.0025,  0.0614, -0.0696],\n                       [-0.0256, -0.0556,  0.0378,  0.0639, -0.0411],\n                       [-0.0295,  0.0299,  0.0753,  0.0765, -0.1001]],\n              \n                      [[ 0.0183, -0.0517,  0.0201, -0.0020,  0.0108],\n                       [-0.0481, -0.0907, -0.0531,  0.1573, -0.1443],\n                       [ 0.0512, -0.1478, -0.0303,  0.0015, -0.0726],\n                       ...,\n                       [-0.1179,  0.0856,  0.0878, -0.0592, -0.0033],\n                       [-0.0419,  0.0198,  0.1016, -0.0036, -0.0275],\n                       [-0.0559, -0.0811, -0.0427,  0.0792, -0.0459]],\n              \n                      ...,\n              \n                      [[-0.0166,  0.0453, -0.0142,  0.0750,  0.0723],\n                       [-0.2292,  0.0008, -0.0853, -0.0225,  0.0227],\n                       [ 0.0515, -0.0216, -0.0811,  0.1569,  0.0159],\n                       ...,\n                       [-0.0326,  0.0589,  0.0680, -0.0147, -0.0036],\n                       [-0.1047, -0.0337,  0.0281, -0.0784, -0.0937],\n                       [ 0.0115, -0.0332,  0.0809,  0.0160, -0.1283]],\n              \n                      [[-0.0337,  0.0346, -0.1508,  0.0597,  0.0074],\n                       [ 0.0734,  0.0282,  0.1071,  0.1366, -0.1050],\n                       [-0.0843, -0.1389, -0.0381,  0.0454, -0.0269],\n                       ...,\n                       [ 0.1217, -0.0091,  0.0604, -0.0917, -0.0258],\n                       [-0.0517, -0.0253, -0.0178, -0.0871, -0.0597],\n                       [-0.0837, -0.0421, -0.1083, -0.0742, -0.0314]],\n              \n                      [[ 0.0878, -0.0014,  0.1778,  0.1395,  0.1412],\n                       [ 0.0589, -0.0589,  0.0340,  0.0512,  0.0596],\n                       [ 0.0050,  0.0306, -0.0325, -0.0347,  0.0138],\n                       ...,\n                       [-0.0679,  0.0070, -0.1278,  0.0789,  0.0429],\n                       [-0.1009, -0.0607,  0.0052,  0.0444,  0.0069],\n                       [ 0.0751,  0.1174, -0.0734,  0.0062, -0.0279]]], dtype=torch.float64)),\n             ('5.0.convs.1.1.weight',\n              tensor([0.9565, 0.9391, 0.9045, 0.9485, 0.9415, 0.9428, 0.9382, 0.9497, 0.9464,\n                      0.9364, 0.9579, 0.9576, 0.9852, 0.9574, 0.9402, 0.9473, 0.9477, 0.9478,\n                      0.9712, 0.9601, 0.9582, 0.9614, 0.9464, 0.9525, 0.9482, 0.9219, 1.0309,\n                      0.9569, 0.9351, 0.9673, 0.9350, 0.9412, 0.9330, 0.9449, 0.9436, 0.9318,\n                      0.9627, 0.9794, 0.9616, 0.9936, 0.9476, 0.9665, 0.9529, 0.9749, 0.9508,\n                      0.9544, 0.9533, 0.9385, 0.9492, 0.9172, 0.9516, 0.9565, 0.9428, 0.9215,\n                      0.9392, 0.9704, 0.9175, 0.9455, 0.9135, 0.9463, 0.9786, 0.9444, 0.9730,\n                      0.9493], dtype=torch.float64)),\n             ('5.0.convs.1.1.bias',\n              tensor([-0.0023,  0.0058, -0.0468, -0.0162, -0.0238,  0.0217,  0.0097,  0.0063,\n                      -0.0032,  0.0149,  0.0054,  0.0074,  0.0038, -0.0165,  0.0023, -0.0145,\n                      -0.0116,  0.0011,  0.0079, -0.0088, -0.0146, -0.0201, -0.0031, -0.0242,\n                      -0.0147, -0.0113,  0.0183, -0.0150,  0.0066, -0.0048, -0.0028, -0.0090,\n                       0.0058, -0.0044, -0.0322,  0.0027,  0.0091,  0.0210,  0.0085, -0.0055,\n                      -0.0094, -0.0055, -0.0022, -0.0003, -0.0067, -0.0125, -0.0013, -0.0047,\n                       0.0028, -0.0208, -0.0030,  0.0088, -0.0048, -0.0154, -0.0130, -0.0073,\n                      -0.0218, -0.0217,  0.0074, -0.0140, -0.0033,  0.0028,  0.0058,  0.0053],\n                     dtype=torch.float64)),\n             ('5.0.convs.1.1.running_mean',\n              tensor([ 0.0477,  0.3339, -0.6848, -0.7439,  0.0176, -0.1585, -0.1547,  0.2427,\n                      -0.6721, -0.4381,  0.2546, -0.6044, -0.3044,  0.3928, -0.0617,  0.2110,\n                      -0.0649,  0.2224,  0.1284,  0.0156, -0.1217,  1.0216,  0.2337, -0.1605,\n                       0.2719, -0.7570,  0.3986,  0.1255, -0.1715, -0.5823, -0.8623,  0.1904,\n                      -0.9609, -0.2791, -0.4669, -0.0794, -0.5670, -0.3526,  0.0971, -0.0235,\n                      -0.3574,  0.3678,  0.6019, -0.0559, -0.6992, -0.1028, -0.3507, -0.2092,\n                      -0.0458, -0.3558, -0.1932, -0.7560, -0.3781, -0.0841, -0.3318, -0.0981,\n                      -1.0976,  0.0216, -0.3573,  0.7427,  0.2718, -0.0029, -0.3226,  0.4599],\n                     dtype=torch.float64)),\n             ('5.0.convs.1.1.running_var',\n              tensor([0.3984, 0.8305, 0.9275, 0.5564, 0.4883, 0.7233, 0.8415, 0.6282, 1.0628,\n                      0.9651, 0.5015, 0.5064, 0.4811, 0.7187, 0.5319, 0.4739, 0.3040, 0.8534,\n                      0.5360, 0.7670, 0.3634, 0.3463, 0.8624, 0.4742, 0.5167, 1.3145, 0.4158,\n                      0.4635, 0.4657, 0.5020, 0.8875, 1.0591, 0.8111, 0.5291, 0.8666, 0.5639,\n                      0.9157, 0.5246, 0.6922, 0.5077, 0.5403, 0.5968, 0.7983, 0.4020, 0.4601,\n                      0.8705, 0.4634, 0.4453, 0.5179, 0.5025, 0.5840, 0.8594, 0.5312, 1.0335,\n                      0.3983, 0.2820, 1.7544, 0.4584, 0.6945, 1.3581, 0.6393, 0.5620, 0.3810,\n                      1.0840], dtype=torch.float64)),\n             ('5.0.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('5.0.convs.2.0.weight',\n              tensor([[[-0.3310],\n                       [ 0.3236],\n                       [ 0.1253],\n                       ...,\n                       [-0.0280],\n                       [ 0.0421],\n                       [ 0.1964]],\n              \n                      [[ 0.0201],\n                       [ 0.1515],\n                       [-0.1185],\n                       ...,\n                       [-0.1034],\n                       [-0.0609],\n                       [-0.1538]],\n              \n                      [[-0.0711],\n                       [-0.0257],\n                       [-0.0068],\n                       ...,\n                       [ 0.0867],\n                       [ 0.3698],\n                       [ 0.0336]],\n              \n                      ...,\n              \n                      [[ 0.4292],\n                       [ 0.1787],\n                       [ 0.0046],\n                       ...,\n                       [-0.1697],\n                       [ 0.0488],\n                       [ 0.0309]],\n              \n                      [[ 0.0051],\n                       [ 0.1778],\n                       [-0.0798],\n                       ...,\n                       [-0.0313],\n                       [ 0.0990],\n                       [ 0.0843]],\n              \n                      [[ 0.0025],\n                       [ 0.0516],\n                       [ 0.0786],\n                       ...,\n                       [ 0.0079],\n                       [ 0.0168],\n                       [-0.0138]]], dtype=torch.float64)),\n             ('5.0.convs.2.1.weight',\n              tensor([ 4.5432e-02,  8.2374e-03, -1.5719e-02, -4.9548e-03, -2.0598e-02,\n                       6.6469e-04, -9.6774e-04,  9.0064e-03,  1.5192e-02,  9.9131e-03,\n                      -4.8245e-03,  5.7220e-03,  5.8915e-03, -1.1790e-02,  5.4477e-03,\n                       3.1207e-02,  5.7109e-05, -1.6854e-02, -2.8326e-02,  5.8081e-03,\n                       1.1387e-02, -9.0507e-03,  2.5466e-02,  1.7752e-02,  1.3490e-02,\n                       9.0892e-03,  3.4559e-02, -2.9228e-03, -5.3453e-03, -6.2003e-03,\n                      -5.3539e-03, -2.9028e-03, -1.8126e-03, -1.6295e-02,  4.1412e-03,\n                      -6.2688e-04, -5.6938e-03, -1.5535e-03, -2.3495e-02, -2.2071e-02,\n                      -2.0392e-02, -1.3473e-02, -1.7483e-02, -1.8589e-02,  4.6320e-03,\n                       3.0106e-03,  1.4963e-02, -1.9754e-02, -2.3475e-02, -1.2424e-02,\n                       9.3329e-03,  1.5508e-02,  6.2950e-03,  1.9211e-03,  6.5618e-03,\n                       3.4101e-02,  3.8279e-03,  4.6036e-02,  1.4749e-02, -9.1731e-03,\n                       2.6285e-02,  5.0391e-02, -9.7101e-03,  1.5282e-03,  1.1053e-03,\n                      -4.9476e-02,  1.0740e-03, -3.1611e-02,  3.9014e-02,  1.8904e-02,\n                      -2.7035e-02, -1.6833e-02, -6.0979e-03, -2.7552e-02,  1.1287e-02,\n                       4.8214e-02,  6.1762e-03,  2.2982e-02, -2.2863e-02, -8.1260e-03,\n                       7.8631e-03, -1.3750e-02, -1.7340e-02,  2.1449e-02, -1.1954e-02,\n                       6.8070e-03,  3.2363e-02, -1.0328e-02, -3.1706e-02,  1.5025e-02,\n                      -1.3259e-02,  9.3129e-03, -2.0461e-02, -1.0609e-02,  6.5652e-03,\n                       1.7502e-02, -8.9404e-04,  1.1590e-02, -1.7037e-02, -2.8837e-02,\n                       1.7892e-02, -1.8687e-02, -9.4611e-03,  2.1540e-02,  1.9293e-02,\n                       7.5645e-03,  6.8044e-03,  1.6201e-02,  3.9086e-02, -5.4396e-03,\n                       1.5254e-02,  1.5711e-02,  1.7957e-03,  2.9064e-02, -5.9782e-03,\n                      -3.1120e-02, -6.6782e-03, -5.5766e-03, -6.2555e-03,  3.8383e-02,\n                      -1.6606e-02,  2.0551e-02, -6.7405e-03, -4.4888e-03, -5.6200e-03,\n                      -1.0353e-02,  7.0228e-03,  5.0408e-03,  1.5941e-02, -2.5716e-02,\n                       2.3396e-02,  1.9308e-02,  1.2756e-03,  9.9343e-03,  2.9471e-04,\n                       4.8807e-03,  1.2608e-02,  2.4726e-02, -2.0498e-02,  6.5127e-03,\n                       1.4461e-02, -1.6298e-02, -1.5903e-02,  1.0929e-02,  7.4992e-03,\n                      -1.1129e-02,  3.0909e-02, -2.1679e-02,  1.2998e-02,  1.5501e-02,\n                      -3.1060e-02,  8.4022e-03, -8.4538e-03, -3.6138e-02,  9.2362e-03,\n                       1.3818e-02,  1.8956e-02,  3.9033e-02,  1.2070e-02,  2.9674e-03,\n                      -2.7902e-02,  2.3445e-02, -5.6416e-03, -1.3342e-02, -5.7199e-02,\n                      -3.8147e-02, -4.6818e-03,  2.6068e-02,  3.5507e-02,  3.5087e-02,\n                      -1.4904e-02,  1.9209e-02, -2.1884e-02,  7.0171e-03,  6.9575e-03,\n                      -6.8105e-03,  2.1477e-02,  1.7064e-02,  1.8206e-03,  7.9294e-03,\n                       8.1526e-04,  2.1088e-02,  3.1611e-03,  1.1310e-02,  7.3817e-03,\n                       1.0088e-02, -9.3567e-03, -1.2680e-02,  1.0357e-03,  9.2277e-03,\n                       6.2108e-03, -2.3192e-02,  4.1703e-02,  6.3829e-04, -9.2145e-03,\n                       9.7588e-03, -1.3011e-02,  1.3356e-02,  1.2092e-02, -9.9384e-03,\n                      -1.0873e-02, -1.2937e-02, -2.0260e-02,  5.1795e-03, -3.6689e-05,\n                       9.3429e-03, -3.4157e-02, -4.8186e-03, -1.5909e-02,  3.6942e-02,\n                      -2.3008e-02,  8.2630e-03,  8.8086e-03, -2.8541e-02, -3.7564e-02,\n                      -2.2907e-02,  1.3554e-02,  6.1275e-03, -1.7052e-02,  9.4038e-03,\n                      -1.0323e-02,  2.2399e-02, -2.1424e-02,  9.6430e-03, -2.2842e-02,\n                      -1.3418e-02, -1.6006e-02, -9.8159e-03,  3.5593e-03, -2.0933e-02,\n                       1.7416e-02,  2.2278e-04,  2.7365e-02,  1.3456e-02, -1.5015e-02,\n                       5.9859e-03,  7.6125e-03,  4.3295e-02, -9.2453e-03, -2.4580e-02,\n                      -2.2613e-02, -9.7458e-03, -3.7189e-03,  7.1470e-03,  1.8052e-02,\n                       4.6106e-03,  2.6930e-02, -3.1685e-02,  2.4028e-02,  4.4258e-02,\n                       5.5194e-03,  4.2683e-03, -8.4135e-04, -5.8526e-03,  3.9372e-04,\n                      -6.5046e-03], dtype=torch.float64)),\n             ('5.0.convs.2.1.bias',\n              tensor([ 0.0147,  0.0019,  0.0248,  0.0023,  0.0104, -0.0129,  0.0106,  0.0041,\n                       0.0123, -0.0117, -0.0039, -0.0093,  0.0158, -0.0151,  0.0087,  0.0090,\n                       0.0216,  0.0056,  0.0216, -0.0027,  0.0026,  0.0003,  0.0007, -0.0023,\n                       0.0043, -0.0234, -0.0001,  0.0187,  0.0063,  0.0042, -0.0084,  0.0168,\n                      -0.0126,  0.0168,  0.0145, -0.0035,  0.0110,  0.0234, -0.0116, -0.0024,\n                       0.0069, -0.0050, -0.0064,  0.0064,  0.0166, -0.0026, -0.0066,  0.0072,\n                      -0.0052, -0.0051, -0.0071,  0.0042,  0.0180,  0.0199, -0.0114, -0.0067,\n                       0.0016,  0.0087, -0.0015,  0.0088, -0.0108,  0.0059, -0.0107,  0.0130,\n                       0.0001,  0.0061, -0.0082,  0.0180,  0.0096, -0.0143,  0.0103,  0.0107,\n                       0.0110, -0.0081,  0.0038,  0.0179,  0.0101, -0.0209,  0.0060,  0.0116,\n                       0.0165,  0.0011,  0.0169,  0.0082,  0.0017, -0.0260,  0.0068,  0.0093,\n                       0.0077, -0.0044,  0.0057,  0.0212,  0.0131,  0.0048,  0.0048, -0.0112,\n                       0.0086,  0.0083,  0.0181, -0.0104,  0.0230, -0.0007, -0.0088, -0.0175,\n                       0.0050,  0.0063, -0.0169,  0.0044,  0.0128, -0.0092, -0.0120, -0.0033,\n                       0.0137,  0.0091,  0.0077,  0.0099,  0.0098,  0.0126,  0.0123, -0.0108,\n                       0.0124,  0.0150,  0.0042, -0.0024, -0.0090,  0.0110,  0.0080,  0.0065,\n                       0.0071,  0.0107,  0.0099,  0.0040,  0.0068,  0.0097, -0.0073, -0.0176,\n                       0.0038,  0.0198, -0.0062, -0.0085, -0.0029,  0.0076, -0.0107,  0.0167,\n                      -0.0117, -0.0051,  0.0038, -0.0024,  0.0119,  0.0047,  0.0073,  0.0181,\n                       0.0163,  0.0290, -0.0083,  0.0289,  0.0102,  0.0221,  0.0003, -0.0191,\n                       0.0022,  0.0023, -0.0035,  0.0192,  0.0207,  0.0069, -0.0086,  0.0206,\n                       0.0262,  0.0222,  0.0127,  0.0030, -0.0015,  0.0209, -0.0156,  0.0001,\n                       0.0083,  0.0261,  0.0103, -0.0065, -0.0061,  0.0223, -0.0122, -0.0047,\n                       0.0114,  0.0086,  0.0171,  0.0178, -0.0020,  0.0015, -0.0109,  0.0040,\n                       0.0038, -0.0180,  0.0099,  0.0100, -0.0089,  0.0062,  0.0132, -0.0176,\n                       0.0148,  0.0021,  0.0154,  0.0218,  0.0019, -0.0089,  0.0131, -0.0097,\n                       0.0047,  0.0082,  0.0084,  0.0183,  0.0072, -0.0002,  0.0043,  0.0127,\n                       0.0021,  0.0143,  0.0097,  0.0028, -0.0016, -0.0043,  0.0163,  0.0027,\n                      -0.0002,  0.0133,  0.0044,  0.0037, -0.0259, -0.0095, -0.0066,  0.0090,\n                       0.0130,  0.0009,  0.0075,  0.0054,  0.0131,  0.0010, -0.0011,  0.0096,\n                      -0.0033,  0.0074,  0.0115,  0.0002,  0.0110,  0.0138,  0.0092,  0.0165,\n                      -0.0060, -0.0140,  0.0225,  0.0094, -0.0086,  0.0257,  0.0225,  0.0067],\n                     dtype=torch.float64)),\n             ('5.0.convs.2.1.running_mean',\n              tensor([ 0.3068,  0.2695,  0.0776,  0.4544, -0.5410, -0.1558, -0.0646,  0.0819,\n                       0.1777, -0.0867, -0.3025, -0.1962,  0.1169,  0.2370,  0.7053, -0.5405,\n                       0.0034, -0.3865,  0.3976, -0.3870, -0.0672,  0.1951,  0.0920,  0.0077,\n                      -0.9116, -0.1621, -0.1072,  0.0929,  0.1542, -0.0344,  0.1501,  0.4266,\n                       0.0249, -0.1023,  0.3372, -0.1489,  0.0219,  0.1186,  0.1759,  0.1288,\n                      -0.3005, -0.1422,  0.1998, -0.1750,  0.3566,  0.0135, -0.2763, -0.3626,\n                       0.5121,  0.2125,  0.1645,  0.0601, -0.1028, -0.1112, -0.1833,  0.7054,\n                      -0.0551, -0.4247,  0.5521, -0.0291,  0.0439, -0.0471,  0.4200,  0.0063,\n                       0.1596, -0.0735, -0.1166, -0.3348, -0.4262,  0.4699, -0.3280, -0.3540,\n                      -0.2045, -0.1846, -0.2668, -0.0506,  0.0786, -0.0189, -0.3077,  0.0081,\n                       0.3476, -0.0838,  0.6027,  0.3881, -0.3849, -0.3255, -0.1446, -0.4063,\n                       0.1342, -0.3307, -0.4945,  0.1297,  0.2587,  0.2305,  0.3377,  0.1558,\n                      -0.0023,  0.0300, -0.3815, -0.0295,  0.3856, -0.7704,  0.3440, -0.3619,\n                       0.4816, -0.4101, -0.4015,  0.7764, -0.0247, -0.1041,  0.1263,  0.0931,\n                      -0.0343,  0.0951, -0.2040,  0.1746, -0.0692,  0.1366,  0.1881,  0.5210,\n                       0.3116, -0.0848,  0.0143,  0.0965, -0.1428,  0.9029,  0.4707, -0.3619,\n                       0.2360,  0.7910,  0.3600, -0.2074,  0.2835, -0.1444, -0.0809,  0.2841,\n                       0.2771, -0.1851, -0.3721, -0.0889,  0.0468,  0.1656, -0.2878, -0.3578,\n                      -0.1800, -0.0792,  0.2197,  0.1899, -0.1574, -0.1568, -0.5712, -0.2454,\n                       0.2578,  0.1261,  0.5874, -0.2140, -0.2545, -0.3070,  0.0912,  0.0138,\n                      -0.1409, -0.4229, -0.2494,  0.2161, -0.0541, -0.1352,  0.8806, -0.3823,\n                       0.0772, -0.2723, -0.7044, -0.2436,  0.2162,  0.2671,  0.2230, -0.0402,\n                      -0.5560,  0.3005,  0.4770,  0.3008,  0.0926,  0.2380, -0.2429,  0.5389,\n                       0.1737, -0.3125, -0.1936, -0.2913, -0.2511,  0.1921,  0.1616,  0.3423,\n                      -0.3590, -0.3210, -0.0790,  0.0239, -0.0143, -0.0903, -0.1981,  0.1557,\n                      -0.1358,  0.1610,  0.1323, -0.4181, -0.0943, -0.2987,  0.2982,  0.0648,\n                      -0.0996,  0.5974,  0.0950, -0.1230, -0.0476,  0.0067, -0.4163,  0.1145,\n                      -0.1748,  0.2158, -0.2162,  0.1237, -0.5088, -0.1113, -0.0739,  0.3186,\n                       0.3751,  0.1848, -0.0621, -0.0179,  0.4022, -0.1096,  0.1666, -0.1335,\n                       0.3498,  0.1680, -0.0143,  0.3994, -0.2059,  0.6061, -0.3071,  0.6025,\n                      -0.1455,  0.4524, -0.3702,  0.0679,  0.0569, -0.2014,  0.4530, -0.3718,\n                       0.4393,  0.4545,  0.2058,  0.4067, -0.2951, -0.3567,  0.4521, -0.2681],\n                     dtype=torch.float64)),\n             ('5.0.convs.2.1.running_var',\n              tensor([0.3334, 0.3404, 0.2847, 0.3704, 0.2191, 0.1789, 0.1649, 0.2393, 0.1431,\n                      0.3602, 0.2409, 0.2308, 0.1086, 0.1773, 0.3765, 0.2929, 0.0813, 0.2021,\n                      0.2694, 0.2881, 0.1589, 0.2418, 0.3362, 0.1613, 0.4866, 0.1868, 0.7097,\n                      0.1278, 0.1285, 0.1494, 0.4516, 0.2757, 0.0509, 0.4885, 0.2519, 0.1884,\n                      0.1574, 0.1246, 0.1770, 0.3626, 0.1592, 0.1799, 0.0908, 0.3595, 0.1920,\n                      0.2939, 0.2280, 0.1191, 0.3692, 0.1552, 0.1142, 0.3339, 0.0900, 0.1522,\n                      0.1729, 0.2698, 0.0717, 0.5296, 0.4614, 0.2400, 0.3325, 0.4285, 0.2641,\n                      0.0666, 0.3094, 0.3163, 0.1979, 0.2632, 0.5348, 0.4275, 0.4411, 0.2881,\n                      0.1755, 0.4168, 0.4319, 0.1434, 0.1121, 0.3188, 0.3364, 0.1073, 0.1203,\n                      0.2313, 0.5583, 0.3230, 0.2108, 0.4882, 0.2437, 0.3819, 0.3257, 0.1917,\n                      0.6383, 0.2345, 0.2769, 0.3201, 0.1597, 0.3811, 0.2429, 0.2413, 0.3381,\n                      0.4766, 0.4067, 0.3343, 0.1261, 0.3040, 0.4294, 0.2879, 0.2403, 0.7014,\n                      0.3242, 0.1885, 0.0931, 0.2430, 0.2595, 0.2747, 0.3854, 0.3228, 0.2377,\n                      0.2319, 0.2176, 0.3460, 0.1750, 0.2648, 0.4689, 0.4535, 0.1968, 0.4173,\n                      0.4954, 0.1388, 0.1205, 0.4649, 0.3517, 0.1911, 0.2667, 0.0929, 0.0899,\n                      0.2467, 0.1912, 0.1356, 0.2567, 0.0727, 0.2482, 0.3662, 0.2881, 0.3829,\n                      0.2374, 0.2518, 0.1963, 0.3951, 0.3888, 0.2068, 0.5858, 0.2579, 0.2151,\n                      0.2863, 0.2732, 0.2658, 0.4147, 0.4745, 0.1460, 0.2259, 0.3147, 0.3983,\n                      0.1162, 0.2417, 0.2921, 0.1843, 0.3671, 0.3669, 0.3830, 0.4908, 0.3018,\n                      0.2282, 0.1474, 0.2132, 0.5300, 0.3596, 0.3045, 0.2747, 0.2099, 0.1851,\n                      0.1375, 0.4052, 0.5132, 0.6296, 0.1777, 0.2655, 0.3792, 0.2351, 0.2398,\n                      0.2488, 0.0875, 0.4107, 0.3884, 0.2651, 0.1312, 0.2653, 0.2992, 0.2450,\n                      0.3128, 0.0604, 0.3273, 0.2133, 0.2701, 0.4080, 0.1049, 0.2305, 0.4332,\n                      0.0846, 0.2594, 0.4454, 0.1783, 0.2998, 0.1100, 0.3025, 0.2767, 0.1550,\n                      0.3629, 0.1222, 0.2588, 0.3282, 0.2285, 0.1372, 0.1351, 0.2323, 0.3535,\n                      0.1460, 0.3820, 0.2632, 0.3601, 0.3634, 0.4341, 0.1619, 0.2836, 0.3729,\n                      0.1953, 0.2570, 0.2572, 0.3025, 0.3721, 0.2270, 0.4455, 0.4097, 0.3909,\n                      0.2061, 0.1899, 0.1344, 0.3193, 0.4055, 0.2876, 0.4387, 0.2327, 0.2360,\n                      0.0765, 0.3957, 0.1651, 0.1184], dtype=torch.float64)),\n             ('5.0.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('5.0.convpath.0.0.0.weight',\n              tensor([[[-1.6193e-02],\n                       [ 1.4339e-01],\n                       [-3.9059e-02],\n                       ...,\n                       [-9.8477e-02],\n                       [-4.0168e-03],\n                       [ 1.2020e-01]],\n              \n                      [[-1.2132e-01],\n                       [-2.2085e-02],\n                       [ 4.3886e-02],\n                       ...,\n                       [-6.4113e-02],\n                       [ 1.9117e-02],\n                       [ 7.6345e-02]],\n              \n                      [[-6.9510e-02],\n                       [ 2.0369e-01],\n                       [-6.5022e-02],\n                       ...,\n                       [-4.0309e-02],\n                       [-1.4086e-01],\n                       [-1.7633e-01]],\n              \n                      ...,\n              \n                      [[ 5.3615e-02],\n                       [-2.1643e-01],\n                       [ 1.3548e-04],\n                       ...,\n                       [ 4.9714e-02],\n                       [ 1.3369e-01],\n                       [ 5.6184e-02]],\n              \n                      [[ 6.0763e-02],\n                       [ 1.3545e-01],\n                       [-1.2473e-01],\n                       ...,\n                       [ 8.8573e-02],\n                       [-6.8880e-02],\n                       [ 8.5210e-02]],\n              \n                      [[-3.9655e-02],\n                       [ 2.7945e-02],\n                       [-1.0454e-02],\n                       ...,\n                       [-6.4360e-02],\n                       [ 1.6623e-01],\n                       [ 3.4773e-02]]], dtype=torch.float64)),\n             ('5.0.convpath.0.0.1.weight',\n              tensor([0.9612, 0.9548, 0.9841, 0.8988, 0.9710, 0.9649, 0.9483, 0.9637, 0.9605,\n                      0.9574, 0.9840, 0.9386, 0.9626, 0.9424, 0.9501, 0.9514, 0.9488, 0.9807,\n                      0.9543, 0.9809, 0.9639, 0.9642, 0.9732, 0.9402, 0.9635, 0.9702, 0.9569,\n                      0.9386, 0.9480, 0.9715, 0.9638, 0.9893, 0.9654, 0.9769, 0.9565, 0.9727,\n                      0.9721, 0.9553, 0.9668, 0.9733, 0.9509, 0.9796, 0.9436, 0.9823, 0.9745,\n                      0.9718, 0.9768, 0.9696, 0.9571, 0.9752, 0.9738, 0.9686, 0.9642, 0.9599,\n                      0.9588, 0.9526, 0.9548, 0.9389, 0.9473, 0.9790, 0.9661, 0.9730, 0.9692,\n                      0.9792], dtype=torch.float64)),\n             ('5.0.convpath.0.0.1.bias',\n              tensor([ 5.6125e-03, -1.3392e-02, -2.4821e-03, -2.0347e-02,  2.0468e-03,\n                       1.7624e-02, -2.3028e-02,  9.1761e-03, -7.5666e-03,  4.8939e-03,\n                       1.9081e-02, -7.0951e-03, -1.3071e-02,  2.9753e-03,  1.1719e-02,\n                      -4.5798e-04,  2.9463e-03, -1.8419e-02, -8.9741e-03, -9.1919e-03,\n                      -1.7555e-02,  1.6522e-03,  5.3877e-03, -1.7726e-02,  7.6360e-03,\n                      -7.0222e-05, -1.4356e-02, -8.8763e-03, -1.1436e-02,  1.9395e-02,\n                      -8.7408e-03,  2.0512e-03, -9.0275e-03, -4.8991e-03, -6.0910e-03,\n                      -1.6335e-02,  2.5532e-02, -6.9656e-04, -8.3465e-04, -2.2590e-02,\n                      -6.0248e-04,  1.3854e-02, -7.5309e-03, -1.2159e-02, -3.7264e-03,\n                       9.6112e-03, -6.0236e-03, -5.1005e-04, -9.7465e-04,  2.2000e-02,\n                      -1.7667e-03,  7.9870e-03,  1.7791e-02,  1.1027e-02, -2.3230e-03,\n                      -5.3583e-03,  1.2229e-02, -1.5513e-02,  5.9525e-03, -4.3905e-03,\n                       1.1867e-02, -9.7494e-03,  2.1736e-02, -1.7782e-02],\n                     dtype=torch.float64)),\n             ('5.0.convpath.0.0.1.running_mean',\n              tensor([ 0.5184,  0.9086,  0.5741, -0.3299, -0.2047,  0.6258, -0.1037, -0.2019,\n                       0.1684, -0.5944, -0.1803, -0.2233, -0.1019,  0.2525, -0.4697,  0.5870,\n                       0.5860, -0.2809,  0.5662, -0.1987,  0.1073,  0.2324, -0.2151,  0.6797,\n                      -0.1383,  0.7590,  0.5590, -0.1111,  0.4753, -1.0378,  0.1913,  0.0987,\n                      -0.1458,  0.2429,  0.3652, -0.1003,  0.1869,  0.2412,  0.0066, -0.2072,\n                      -0.2106,  0.0900, -0.0302,  0.1881,  0.1006, -0.1501, -0.4074,  0.2443,\n                      -0.3751, -0.5529, -0.0377, -0.3751, -0.2253, -0.1928, -0.1997, -0.1209,\n                       0.0624, -0.0180, -0.0045,  0.8905, -0.4463, -0.0650, -0.0415, -0.1543],\n                     dtype=torch.float64)),\n             ('5.0.convpath.0.0.1.running_var',\n              tensor([0.3204, 2.5917, 0.3345, 2.0139, 0.6740, 1.3483, 0.4906, 0.7597, 0.3381,\n                      0.3165, 0.7291, 0.6836, 0.6696, 0.3006, 0.7443, 0.3772, 0.6199, 0.3920,\n                      0.7972, 0.5937, 0.3762, 0.2632, 0.6530, 0.4224, 0.3020, 0.8255, 0.3730,\n                      0.3612, 0.7546, 0.4975, 0.3082, 0.3788, 0.2388, 0.3157, 0.7938, 0.3169,\n                      0.3124, 0.4118, 0.4253, 0.3924, 0.4320, 0.3413, 0.4494, 0.4278, 0.3284,\n                      0.4717, 0.2275, 0.3343, 0.7079, 0.4269, 0.3834, 0.3875, 0.5796, 0.2694,\n                      0.7276, 0.3019, 0.8488, 0.6803, 0.8303, 0.9048, 0.2939, 0.3141, 0.3811,\n                      0.4750], dtype=torch.float64)),\n             ('5.0.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('5.0.convpath.0.1.0.weight',\n              tensor([[[-0.0448,  0.0357,  0.0548, -0.0142,  0.1158],\n                       [ 0.0934, -0.1324,  0.0485,  0.1063, -0.0690],\n                       [ 0.0348,  0.0770,  0.0354,  0.0389,  0.1044],\n                       ...,\n                       [ 0.0129,  0.0111,  0.0293,  0.0092,  0.0146],\n                       [-0.0357,  0.0855,  0.0461,  0.0151, -0.0019],\n                       [-0.0180,  0.0213, -0.1474,  0.0530,  0.0009]],\n              \n                      [[-0.0665, -0.0622, -0.0062, -0.0767, -0.0284],\n                       [ 0.0491, -0.0174, -0.0600,  0.1014, -0.0745],\n                       [-0.0595, -0.0391,  0.0708, -0.0292,  0.0896],\n                       ...,\n                       [-0.1708, -0.0805, -0.0025,  0.0614, -0.0696],\n                       [-0.0256, -0.0556,  0.0378,  0.0639, -0.0411],\n                       [-0.0295,  0.0299,  0.0753,  0.0765, -0.1001]],\n              \n                      [[ 0.0183, -0.0517,  0.0201, -0.0020,  0.0108],\n                       [-0.0481, -0.0907, -0.0531,  0.1573, -0.1443],\n                       [ 0.0512, -0.1478, -0.0303,  0.0015, -0.0726],\n                       ...,\n                       [-0.1179,  0.0856,  0.0878, -0.0592, -0.0033],\n                       [-0.0419,  0.0198,  0.1016, -0.0036, -0.0275],\n                       [-0.0559, -0.0811, -0.0427,  0.0792, -0.0459]],\n              \n                      ...,\n              \n                      [[-0.0166,  0.0453, -0.0142,  0.0750,  0.0723],\n                       [-0.2292,  0.0008, -0.0853, -0.0225,  0.0227],\n                       [ 0.0515, -0.0216, -0.0811,  0.1569,  0.0159],\n                       ...,\n                       [-0.0326,  0.0589,  0.0680, -0.0147, -0.0036],\n                       [-0.1047, -0.0337,  0.0281, -0.0784, -0.0937],\n                       [ 0.0115, -0.0332,  0.0809,  0.0160, -0.1283]],\n              \n                      [[-0.0337,  0.0346, -0.1508,  0.0597,  0.0074],\n                       [ 0.0734,  0.0282,  0.1071,  0.1366, -0.1050],\n                       [-0.0843, -0.1389, -0.0381,  0.0454, -0.0269],\n                       ...,\n                       [ 0.1217, -0.0091,  0.0604, -0.0917, -0.0258],\n                       [-0.0517, -0.0253, -0.0178, -0.0871, -0.0597],\n                       [-0.0837, -0.0421, -0.1083, -0.0742, -0.0314]],\n              \n                      [[ 0.0878, -0.0014,  0.1778,  0.1395,  0.1412],\n                       [ 0.0589, -0.0589,  0.0340,  0.0512,  0.0596],\n                       [ 0.0050,  0.0306, -0.0325, -0.0347,  0.0138],\n                       ...,\n                       [-0.0679,  0.0070, -0.1278,  0.0789,  0.0429],\n                       [-0.1009, -0.0607,  0.0052,  0.0444,  0.0069],\n                       [ 0.0751,  0.1174, -0.0734,  0.0062, -0.0279]]], dtype=torch.float64)),\n             ('5.0.convpath.0.1.1.weight',\n              tensor([0.9565, 0.9391, 0.9045, 0.9485, 0.9415, 0.9428, 0.9382, 0.9497, 0.9464,\n                      0.9364, 0.9579, 0.9576, 0.9852, 0.9574, 0.9402, 0.9473, 0.9477, 0.9478,\n                      0.9712, 0.9601, 0.9582, 0.9614, 0.9464, 0.9525, 0.9482, 0.9219, 1.0309,\n                      0.9569, 0.9351, 0.9673, 0.9350, 0.9412, 0.9330, 0.9449, 0.9436, 0.9318,\n                      0.9627, 0.9794, 0.9616, 0.9936, 0.9476, 0.9665, 0.9529, 0.9749, 0.9508,\n                      0.9544, 0.9533, 0.9385, 0.9492, 0.9172, 0.9516, 0.9565, 0.9428, 0.9215,\n                      0.9392, 0.9704, 0.9175, 0.9455, 0.9135, 0.9463, 0.9786, 0.9444, 0.9730,\n                      0.9493], dtype=torch.float64)),\n             ('5.0.convpath.0.1.1.bias',\n              tensor([-0.0023,  0.0058, -0.0468, -0.0162, -0.0238,  0.0217,  0.0097,  0.0063,\n                      -0.0032,  0.0149,  0.0054,  0.0074,  0.0038, -0.0165,  0.0023, -0.0145,\n                      -0.0116,  0.0011,  0.0079, -0.0088, -0.0146, -0.0201, -0.0031, -0.0242,\n                      -0.0147, -0.0113,  0.0183, -0.0150,  0.0066, -0.0048, -0.0028, -0.0090,\n                       0.0058, -0.0044, -0.0322,  0.0027,  0.0091,  0.0210,  0.0085, -0.0055,\n                      -0.0094, -0.0055, -0.0022, -0.0003, -0.0067, -0.0125, -0.0013, -0.0047,\n                       0.0028, -0.0208, -0.0030,  0.0088, -0.0048, -0.0154, -0.0130, -0.0073,\n                      -0.0218, -0.0217,  0.0074, -0.0140, -0.0033,  0.0028,  0.0058,  0.0053],\n                     dtype=torch.float64)),\n             ('5.0.convpath.0.1.1.running_mean',\n              tensor([ 0.0477,  0.3339, -0.6848, -0.7439,  0.0176, -0.1585, -0.1547,  0.2427,\n                      -0.6721, -0.4381,  0.2546, -0.6044, -0.3044,  0.3928, -0.0617,  0.2110,\n                      -0.0649,  0.2224,  0.1284,  0.0156, -0.1217,  1.0216,  0.2337, -0.1605,\n                       0.2719, -0.7570,  0.3986,  0.1255, -0.1715, -0.5823, -0.8623,  0.1904,\n                      -0.9609, -0.2791, -0.4669, -0.0794, -0.5670, -0.3526,  0.0971, -0.0235,\n                      -0.3574,  0.3678,  0.6019, -0.0559, -0.6992, -0.1028, -0.3507, -0.2092,\n                      -0.0458, -0.3558, -0.1932, -0.7560, -0.3781, -0.0841, -0.3318, -0.0981,\n                      -1.0976,  0.0216, -0.3573,  0.7427,  0.2718, -0.0029, -0.3226,  0.4599],\n                     dtype=torch.float64)),\n             ('5.0.convpath.0.1.1.running_var',\n              tensor([0.3984, 0.8305, 0.9275, 0.5564, 0.4883, 0.7233, 0.8415, 0.6282, 1.0628,\n                      0.9651, 0.5015, 0.5064, 0.4811, 0.7187, 0.5319, 0.4739, 0.3040, 0.8534,\n                      0.5360, 0.7670, 0.3634, 0.3463, 0.8624, 0.4742, 0.5167, 1.3145, 0.4158,\n                      0.4635, 0.4657, 0.5020, 0.8875, 1.0591, 0.8111, 0.5291, 0.8666, 0.5639,\n                      0.9157, 0.5246, 0.6922, 0.5077, 0.5403, 0.5968, 0.7983, 0.4020, 0.4601,\n                      0.8705, 0.4634, 0.4453, 0.5179, 0.5025, 0.5840, 0.8594, 0.5312, 1.0335,\n                      0.3983, 0.2820, 1.7544, 0.4584, 0.6945, 1.3581, 0.6393, 0.5620, 0.3810,\n                      1.0840], dtype=torch.float64)),\n             ('5.0.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('5.0.convpath.0.2.0.weight',\n              tensor([[[-0.3310],\n                       [ 0.3236],\n                       [ 0.1253],\n                       ...,\n                       [-0.0280],\n                       [ 0.0421],\n                       [ 0.1964]],\n              \n                      [[ 0.0201],\n                       [ 0.1515],\n                       [-0.1185],\n                       ...,\n                       [-0.1034],\n                       [-0.0609],\n                       [-0.1538]],\n              \n                      [[-0.0711],\n                       [-0.0257],\n                       [-0.0068],\n                       ...,\n                       [ 0.0867],\n                       [ 0.3698],\n                       [ 0.0336]],\n              \n                      ...,\n              \n                      [[ 0.4292],\n                       [ 0.1787],\n                       [ 0.0046],\n                       ...,\n                       [-0.1697],\n                       [ 0.0488],\n                       [ 0.0309]],\n              \n                      [[ 0.0051],\n                       [ 0.1778],\n                       [-0.0798],\n                       ...,\n                       [-0.0313],\n                       [ 0.0990],\n                       [ 0.0843]],\n              \n                      [[ 0.0025],\n                       [ 0.0516],\n                       [ 0.0786],\n                       ...,\n                       [ 0.0079],\n                       [ 0.0168],\n                       [-0.0138]]], dtype=torch.float64)),\n             ('5.0.convpath.0.2.1.weight',\n              tensor([ 4.5432e-02,  8.2374e-03, -1.5719e-02, -4.9548e-03, -2.0598e-02,\n                       6.6469e-04, -9.6774e-04,  9.0064e-03,  1.5192e-02,  9.9131e-03,\n                      -4.8245e-03,  5.7220e-03,  5.8915e-03, -1.1790e-02,  5.4477e-03,\n                       3.1207e-02,  5.7109e-05, -1.6854e-02, -2.8326e-02,  5.8081e-03,\n                       1.1387e-02, -9.0507e-03,  2.5466e-02,  1.7752e-02,  1.3490e-02,\n                       9.0892e-03,  3.4559e-02, -2.9228e-03, -5.3453e-03, -6.2003e-03,\n                      -5.3539e-03, -2.9028e-03, -1.8126e-03, -1.6295e-02,  4.1412e-03,\n                      -6.2688e-04, -5.6938e-03, -1.5535e-03, -2.3495e-02, -2.2071e-02,\n                      -2.0392e-02, -1.3473e-02, -1.7483e-02, -1.8589e-02,  4.6320e-03,\n                       3.0106e-03,  1.4963e-02, -1.9754e-02, -2.3475e-02, -1.2424e-02,\n                       9.3329e-03,  1.5508e-02,  6.2950e-03,  1.9211e-03,  6.5618e-03,\n                       3.4101e-02,  3.8279e-03,  4.6036e-02,  1.4749e-02, -9.1731e-03,\n                       2.6285e-02,  5.0391e-02, -9.7101e-03,  1.5282e-03,  1.1053e-03,\n                      -4.9476e-02,  1.0740e-03, -3.1611e-02,  3.9014e-02,  1.8904e-02,\n                      -2.7035e-02, -1.6833e-02, -6.0979e-03, -2.7552e-02,  1.1287e-02,\n                       4.8214e-02,  6.1762e-03,  2.2982e-02, -2.2863e-02, -8.1260e-03,\n                       7.8631e-03, -1.3750e-02, -1.7340e-02,  2.1449e-02, -1.1954e-02,\n                       6.8070e-03,  3.2363e-02, -1.0328e-02, -3.1706e-02,  1.5025e-02,\n                      -1.3259e-02,  9.3129e-03, -2.0461e-02, -1.0609e-02,  6.5652e-03,\n                       1.7502e-02, -8.9404e-04,  1.1590e-02, -1.7037e-02, -2.8837e-02,\n                       1.7892e-02, -1.8687e-02, -9.4611e-03,  2.1540e-02,  1.9293e-02,\n                       7.5645e-03,  6.8044e-03,  1.6201e-02,  3.9086e-02, -5.4396e-03,\n                       1.5254e-02,  1.5711e-02,  1.7957e-03,  2.9064e-02, -5.9782e-03,\n                      -3.1120e-02, -6.6782e-03, -5.5766e-03, -6.2555e-03,  3.8383e-02,\n                      -1.6606e-02,  2.0551e-02, -6.7405e-03, -4.4888e-03, -5.6200e-03,\n                      -1.0353e-02,  7.0228e-03,  5.0408e-03,  1.5941e-02, -2.5716e-02,\n                       2.3396e-02,  1.9308e-02,  1.2756e-03,  9.9343e-03,  2.9471e-04,\n                       4.8807e-03,  1.2608e-02,  2.4726e-02, -2.0498e-02,  6.5127e-03,\n                       1.4461e-02, -1.6298e-02, -1.5903e-02,  1.0929e-02,  7.4992e-03,\n                      -1.1129e-02,  3.0909e-02, -2.1679e-02,  1.2998e-02,  1.5501e-02,\n                      -3.1060e-02,  8.4022e-03, -8.4538e-03, -3.6138e-02,  9.2362e-03,\n                       1.3818e-02,  1.8956e-02,  3.9033e-02,  1.2070e-02,  2.9674e-03,\n                      -2.7902e-02,  2.3445e-02, -5.6416e-03, -1.3342e-02, -5.7199e-02,\n                      -3.8147e-02, -4.6818e-03,  2.6068e-02,  3.5507e-02,  3.5087e-02,\n                      -1.4904e-02,  1.9209e-02, -2.1884e-02,  7.0171e-03,  6.9575e-03,\n                      -6.8105e-03,  2.1477e-02,  1.7064e-02,  1.8206e-03,  7.9294e-03,\n                       8.1526e-04,  2.1088e-02,  3.1611e-03,  1.1310e-02,  7.3817e-03,\n                       1.0088e-02, -9.3567e-03, -1.2680e-02,  1.0357e-03,  9.2277e-03,\n                       6.2108e-03, -2.3192e-02,  4.1703e-02,  6.3829e-04, -9.2145e-03,\n                       9.7588e-03, -1.3011e-02,  1.3356e-02,  1.2092e-02, -9.9384e-03,\n                      -1.0873e-02, -1.2937e-02, -2.0260e-02,  5.1795e-03, -3.6689e-05,\n                       9.3429e-03, -3.4157e-02, -4.8186e-03, -1.5909e-02,  3.6942e-02,\n                      -2.3008e-02,  8.2630e-03,  8.8086e-03, -2.8541e-02, -3.7564e-02,\n                      -2.2907e-02,  1.3554e-02,  6.1275e-03, -1.7052e-02,  9.4038e-03,\n                      -1.0323e-02,  2.2399e-02, -2.1424e-02,  9.6430e-03, -2.2842e-02,\n                      -1.3418e-02, -1.6006e-02, -9.8159e-03,  3.5593e-03, -2.0933e-02,\n                       1.7416e-02,  2.2278e-04,  2.7365e-02,  1.3456e-02, -1.5015e-02,\n                       5.9859e-03,  7.6125e-03,  4.3295e-02, -9.2453e-03, -2.4580e-02,\n                      -2.2613e-02, -9.7458e-03, -3.7189e-03,  7.1470e-03,  1.8052e-02,\n                       4.6106e-03,  2.6930e-02, -3.1685e-02,  2.4028e-02,  4.4258e-02,\n                       5.5194e-03,  4.2683e-03, -8.4135e-04, -5.8526e-03,  3.9372e-04,\n                      -6.5046e-03], dtype=torch.float64)),\n             ('5.0.convpath.0.2.1.bias',\n              tensor([ 0.0147,  0.0019,  0.0248,  0.0023,  0.0104, -0.0129,  0.0106,  0.0041,\n                       0.0123, -0.0117, -0.0039, -0.0093,  0.0158, -0.0151,  0.0087,  0.0090,\n                       0.0216,  0.0056,  0.0216, -0.0027,  0.0026,  0.0003,  0.0007, -0.0023,\n                       0.0043, -0.0234, -0.0001,  0.0187,  0.0063,  0.0042, -0.0084,  0.0168,\n                      -0.0126,  0.0168,  0.0145, -0.0035,  0.0110,  0.0234, -0.0116, -0.0024,\n                       0.0069, -0.0050, -0.0064,  0.0064,  0.0166, -0.0026, -0.0066,  0.0072,\n                      -0.0052, -0.0051, -0.0071,  0.0042,  0.0180,  0.0199, -0.0114, -0.0067,\n                       0.0016,  0.0087, -0.0015,  0.0088, -0.0108,  0.0059, -0.0107,  0.0130,\n                       0.0001,  0.0061, -0.0082,  0.0180,  0.0096, -0.0143,  0.0103,  0.0107,\n                       0.0110, -0.0081,  0.0038,  0.0179,  0.0101, -0.0209,  0.0060,  0.0116,\n                       0.0165,  0.0011,  0.0169,  0.0082,  0.0017, -0.0260,  0.0068,  0.0093,\n                       0.0077, -0.0044,  0.0057,  0.0212,  0.0131,  0.0048,  0.0048, -0.0112,\n                       0.0086,  0.0083,  0.0181, -0.0104,  0.0230, -0.0007, -0.0088, -0.0175,\n                       0.0050,  0.0063, -0.0169,  0.0044,  0.0128, -0.0092, -0.0120, -0.0033,\n                       0.0137,  0.0091,  0.0077,  0.0099,  0.0098,  0.0126,  0.0123, -0.0108,\n                       0.0124,  0.0150,  0.0042, -0.0024, -0.0090,  0.0110,  0.0080,  0.0065,\n                       0.0071,  0.0107,  0.0099,  0.0040,  0.0068,  0.0097, -0.0073, -0.0176,\n                       0.0038,  0.0198, -0.0062, -0.0085, -0.0029,  0.0076, -0.0107,  0.0167,\n                      -0.0117, -0.0051,  0.0038, -0.0024,  0.0119,  0.0047,  0.0073,  0.0181,\n                       0.0163,  0.0290, -0.0083,  0.0289,  0.0102,  0.0221,  0.0003, -0.0191,\n                       0.0022,  0.0023, -0.0035,  0.0192,  0.0207,  0.0069, -0.0086,  0.0206,\n                       0.0262,  0.0222,  0.0127,  0.0030, -0.0015,  0.0209, -0.0156,  0.0001,\n                       0.0083,  0.0261,  0.0103, -0.0065, -0.0061,  0.0223, -0.0122, -0.0047,\n                       0.0114,  0.0086,  0.0171,  0.0178, -0.0020,  0.0015, -0.0109,  0.0040,\n                       0.0038, -0.0180,  0.0099,  0.0100, -0.0089,  0.0062,  0.0132, -0.0176,\n                       0.0148,  0.0021,  0.0154,  0.0218,  0.0019, -0.0089,  0.0131, -0.0097,\n                       0.0047,  0.0082,  0.0084,  0.0183,  0.0072, -0.0002,  0.0043,  0.0127,\n                       0.0021,  0.0143,  0.0097,  0.0028, -0.0016, -0.0043,  0.0163,  0.0027,\n                      -0.0002,  0.0133,  0.0044,  0.0037, -0.0259, -0.0095, -0.0066,  0.0090,\n                       0.0130,  0.0009,  0.0075,  0.0054,  0.0131,  0.0010, -0.0011,  0.0096,\n                      -0.0033,  0.0074,  0.0115,  0.0002,  0.0110,  0.0138,  0.0092,  0.0165,\n                      -0.0060, -0.0140,  0.0225,  0.0094, -0.0086,  0.0257,  0.0225,  0.0067],\n                     dtype=torch.float64)),\n             ('5.0.convpath.0.2.1.running_mean',\n              tensor([ 0.3068,  0.2695,  0.0776,  0.4544, -0.5410, -0.1558, -0.0646,  0.0819,\n                       0.1777, -0.0867, -0.3025, -0.1962,  0.1169,  0.2370,  0.7053, -0.5405,\n                       0.0034, -0.3865,  0.3976, -0.3870, -0.0672,  0.1951,  0.0920,  0.0077,\n                      -0.9116, -0.1621, -0.1072,  0.0929,  0.1542, -0.0344,  0.1501,  0.4266,\n                       0.0249, -0.1023,  0.3372, -0.1489,  0.0219,  0.1186,  0.1759,  0.1288,\n                      -0.3005, -0.1422,  0.1998, -0.1750,  0.3566,  0.0135, -0.2763, -0.3626,\n                       0.5121,  0.2125,  0.1645,  0.0601, -0.1028, -0.1112, -0.1833,  0.7054,\n                      -0.0551, -0.4247,  0.5521, -0.0291,  0.0439, -0.0471,  0.4200,  0.0063,\n                       0.1596, -0.0735, -0.1166, -0.3348, -0.4262,  0.4699, -0.3280, -0.3540,\n                      -0.2045, -0.1846, -0.2668, -0.0506,  0.0786, -0.0189, -0.3077,  0.0081,\n                       0.3476, -0.0838,  0.6027,  0.3881, -0.3849, -0.3255, -0.1446, -0.4063,\n                       0.1342, -0.3307, -0.4945,  0.1297,  0.2587,  0.2305,  0.3377,  0.1558,\n                      -0.0023,  0.0300, -0.3815, -0.0295,  0.3856, -0.7704,  0.3440, -0.3619,\n                       0.4816, -0.4101, -0.4015,  0.7764, -0.0247, -0.1041,  0.1263,  0.0931,\n                      -0.0343,  0.0951, -0.2040,  0.1746, -0.0692,  0.1366,  0.1881,  0.5210,\n                       0.3116, -0.0848,  0.0143,  0.0965, -0.1428,  0.9029,  0.4707, -0.3619,\n                       0.2360,  0.7910,  0.3600, -0.2074,  0.2835, -0.1444, -0.0809,  0.2841,\n                       0.2771, -0.1851, -0.3721, -0.0889,  0.0468,  0.1656, -0.2878, -0.3578,\n                      -0.1800, -0.0792,  0.2197,  0.1899, -0.1574, -0.1568, -0.5712, -0.2454,\n                       0.2578,  0.1261,  0.5874, -0.2140, -0.2545, -0.3070,  0.0912,  0.0138,\n                      -0.1409, -0.4229, -0.2494,  0.2161, -0.0541, -0.1352,  0.8806, -0.3823,\n                       0.0772, -0.2723, -0.7044, -0.2436,  0.2162,  0.2671,  0.2230, -0.0402,\n                      -0.5560,  0.3005,  0.4770,  0.3008,  0.0926,  0.2380, -0.2429,  0.5389,\n                       0.1737, -0.3125, -0.1936, -0.2913, -0.2511,  0.1921,  0.1616,  0.3423,\n                      -0.3590, -0.3210, -0.0790,  0.0239, -0.0143, -0.0903, -0.1981,  0.1557,\n                      -0.1358,  0.1610,  0.1323, -0.4181, -0.0943, -0.2987,  0.2982,  0.0648,\n                      -0.0996,  0.5974,  0.0950, -0.1230, -0.0476,  0.0067, -0.4163,  0.1145,\n                      -0.1748,  0.2158, -0.2162,  0.1237, -0.5088, -0.1113, -0.0739,  0.3186,\n                       0.3751,  0.1848, -0.0621, -0.0179,  0.4022, -0.1096,  0.1666, -0.1335,\n                       0.3498,  0.1680, -0.0143,  0.3994, -0.2059,  0.6061, -0.3071,  0.6025,\n                      -0.1455,  0.4524, -0.3702,  0.0679,  0.0569, -0.2014,  0.4530, -0.3718,\n                       0.4393,  0.4545,  0.2058,  0.4067, -0.2951, -0.3567,  0.4521, -0.2681],\n                     dtype=torch.float64)),\n             ('5.0.convpath.0.2.1.running_var',\n              tensor([0.3334, 0.3404, 0.2847, 0.3704, 0.2191, 0.1789, 0.1649, 0.2393, 0.1431,\n                      0.3602, 0.2409, 0.2308, 0.1086, 0.1773, 0.3765, 0.2929, 0.0813, 0.2021,\n                      0.2694, 0.2881, 0.1589, 0.2418, 0.3362, 0.1613, 0.4866, 0.1868, 0.7097,\n                      0.1278, 0.1285, 0.1494, 0.4516, 0.2757, 0.0509, 0.4885, 0.2519, 0.1884,\n                      0.1574, 0.1246, 0.1770, 0.3626, 0.1592, 0.1799, 0.0908, 0.3595, 0.1920,\n                      0.2939, 0.2280, 0.1191, 0.3692, 0.1552, 0.1142, 0.3339, 0.0900, 0.1522,\n                      0.1729, 0.2698, 0.0717, 0.5296, 0.4614, 0.2400, 0.3325, 0.4285, 0.2641,\n                      0.0666, 0.3094, 0.3163, 0.1979, 0.2632, 0.5348, 0.4275, 0.4411, 0.2881,\n                      0.1755, 0.4168, 0.4319, 0.1434, 0.1121, 0.3188, 0.3364, 0.1073, 0.1203,\n                      0.2313, 0.5583, 0.3230, 0.2108, 0.4882, 0.2437, 0.3819, 0.3257, 0.1917,\n                      0.6383, 0.2345, 0.2769, 0.3201, 0.1597, 0.3811, 0.2429, 0.2413, 0.3381,\n                      0.4766, 0.4067, 0.3343, 0.1261, 0.3040, 0.4294, 0.2879, 0.2403, 0.7014,\n                      0.3242, 0.1885, 0.0931, 0.2430, 0.2595, 0.2747, 0.3854, 0.3228, 0.2377,\n                      0.2319, 0.2176, 0.3460, 0.1750, 0.2648, 0.4689, 0.4535, 0.1968, 0.4173,\n                      0.4954, 0.1388, 0.1205, 0.4649, 0.3517, 0.1911, 0.2667, 0.0929, 0.0899,\n                      0.2467, 0.1912, 0.1356, 0.2567, 0.0727, 0.2482, 0.3662, 0.2881, 0.3829,\n                      0.2374, 0.2518, 0.1963, 0.3951, 0.3888, 0.2068, 0.5858, 0.2579, 0.2151,\n                      0.2863, 0.2732, 0.2658, 0.4147, 0.4745, 0.1460, 0.2259, 0.3147, 0.3983,\n                      0.1162, 0.2417, 0.2921, 0.1843, 0.3671, 0.3669, 0.3830, 0.4908, 0.3018,\n                      0.2282, 0.1474, 0.2132, 0.5300, 0.3596, 0.3045, 0.2747, 0.2099, 0.1851,\n                      0.1375, 0.4052, 0.5132, 0.6296, 0.1777, 0.2655, 0.3792, 0.2351, 0.2398,\n                      0.2488, 0.0875, 0.4107, 0.3884, 0.2651, 0.1312, 0.2653, 0.2992, 0.2450,\n                      0.3128, 0.0604, 0.3273, 0.2133, 0.2701, 0.4080, 0.1049, 0.2305, 0.4332,\n                      0.0846, 0.2594, 0.4454, 0.1783, 0.2998, 0.1100, 0.3025, 0.2767, 0.1550,\n                      0.3629, 0.1222, 0.2588, 0.3282, 0.2285, 0.1372, 0.1351, 0.2323, 0.3535,\n                      0.1460, 0.3820, 0.2632, 0.3601, 0.3634, 0.4341, 0.1619, 0.2836, 0.3729,\n                      0.1953, 0.2570, 0.2572, 0.3025, 0.3721, 0.2270, 0.4455, 0.4097, 0.3909,\n                      0.2061, 0.1899, 0.1344, 0.3193, 0.4055, 0.2876, 0.4387, 0.2327, 0.2360,\n                      0.0765, 0.3957, 0.1651, 0.1184], dtype=torch.float64)),\n             ('5.0.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('5.1.convs.0.0.weight',\n              tensor([[[ 0.0076],\n                       [-0.0982],\n                       [-0.0178],\n                       ...,\n                       [-0.0798],\n                       [-0.0446],\n                       [ 0.0332]],\n              \n                      [[ 0.1163],\n                       [-0.0898],\n                       [ 0.0355],\n                       ...,\n                       [-0.0894],\n                       [ 0.0627],\n                       [ 0.1547]],\n              \n                      [[-0.0080],\n                       [ 0.1616],\n                       [-0.1517],\n                       ...,\n                       [-0.0432],\n                       [-0.0443],\n                       [ 0.0113]],\n              \n                      ...,\n              \n                      [[-0.0169],\n                       [ 0.0508],\n                       [ 0.0046],\n                       ...,\n                       [ 0.1651],\n                       [ 0.1270],\n                       [-0.0545]],\n              \n                      [[-0.0298],\n                       [ 0.1147],\n                       [-0.0598],\n                       ...,\n                       [ 0.0002],\n                       [ 0.1135],\n                       [ 0.0419]],\n              \n                      [[-0.0184],\n                       [-0.0036],\n                       [-0.1082],\n                       ...,\n                       [-0.0426],\n                       [-0.1598],\n                       [-0.0270]]], dtype=torch.float64)),\n             ('5.1.convs.0.1.weight',\n              tensor([0.9542, 0.9726, 0.9547, 0.9844, 0.9470, 0.9612, 0.9635, 0.9581, 0.9643,\n                      0.9584, 0.9628, 0.9636, 0.9591, 0.9880, 0.9528, 0.9826, 0.9588, 0.9508,\n                      0.9822, 0.9764, 0.9798, 0.9575, 0.9815, 0.9557, 0.9573, 0.9787, 0.9932,\n                      0.9611, 0.9849, 0.9847, 0.9721, 0.9414, 0.9655, 0.9875, 0.9560, 0.9877,\n                      0.9514, 0.9880, 0.9545, 0.9745, 1.0012, 0.9487, 0.9591, 0.9452, 0.9579,\n                      0.9613, 0.9584, 0.9899, 0.9645, 0.9808, 0.9528, 0.9768, 0.9631, 0.9795,\n                      0.9749, 0.9608, 0.9955, 0.9540, 0.9649, 0.9630, 0.9609, 0.9487, 0.9520,\n                      0.9967], dtype=torch.float64)),\n             ('5.1.convs.0.1.bias',\n              tensor([ 0.0145,  0.0082,  0.0121,  0.0194,  0.0162,  0.0151, -0.0090,  0.0111,\n                      -0.0068, -0.0026, -0.0111,  0.0037,  0.0070,  0.0081, -0.0133,  0.0097,\n                       0.0055,  0.0033,  0.0151,  0.0097, -0.0045, -0.0224,  0.0100, -0.0079,\n                       0.0030, -0.0071,  0.0152,  0.0025,  0.0202,  0.0090, -0.0188,  0.0089,\n                       0.0130,  0.0257, -0.0005,  0.0115,  0.0046,  0.0253, -0.0070,  0.0055,\n                       0.0017, -0.0224, -0.0131,  0.0144, -0.0069, -0.0004,  0.0199, -0.0056,\n                       0.0127, -0.0062, -0.0092,  0.0128,  0.0008,  0.0133, -0.0085,  0.0076,\n                       0.0454,  0.0092,  0.0159,  0.0154, -0.0173, -0.0076, -0.0145,  0.0306],\n                     dtype=torch.float64)),\n             ('5.1.convs.0.1.running_mean',\n              tensor([-0.4015,  0.3196, -0.3832, -0.4130, -0.6135, -0.0987,  0.5634, -0.4502,\n                      -0.1414,  0.0754,  0.0739, -0.5565,  0.1044, -0.7221,  0.3753, -0.0966,\n                       0.0424, -0.7741,  0.0641,  0.5895,  0.2306, -0.0159,  0.0631, -0.5771,\n                       0.0146,  0.3478,  0.4249, -0.3396, -1.0293,  0.5138,  0.2020, -0.9589,\n                      -0.4396, -0.0913,  0.6810, -0.3692,  0.3011, -1.0276,  0.4403,  0.2252,\n                       0.3268,  0.7222,  0.7186, -0.5876,  0.1908, -0.1902, -0.4671, -0.7667,\n                       0.4031, -0.0417,  0.1755, -0.1440, -0.5106, -0.7178, -0.2990, -0.3281,\n                       0.2159,  0.0703, -0.1432,  0.0612,  0.4324,  0.6224,  0.4043, -0.4857],\n                     dtype=torch.float64)),\n             ('5.1.convs.0.1.running_var',\n              tensor([0.3512, 0.2639, 0.3500, 0.2246, 1.0532, 0.2996, 0.4827, 1.2664, 0.4607,\n                      0.6660, 0.3107, 0.4125, 0.3903, 0.4698, 0.9222, 0.1887, 0.5127, 0.5488,\n                      0.1266, 2.4062, 0.2648, 0.5591, 0.4424, 1.0512, 0.2584, 0.1376, 0.2405,\n                      0.2588, 0.2594, 0.3091, 0.3472, 2.2546, 0.5255, 0.2641, 0.2329, 0.2488,\n                      0.3938, 0.2428, 0.5283, 0.2762, 0.2008, 1.4145, 1.2052, 1.3863, 0.1852,\n                      0.2493, 0.3640, 0.2333, 1.4517, 0.1355, 0.3578, 0.2755, 0.2707, 0.2753,\n                      0.2557, 0.7284, 0.4098, 0.2760, 0.2808, 0.6784, 0.6208, 1.2235, 0.6766,\n                      0.2110], dtype=torch.float64)),\n             ('5.1.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('5.1.convs.1.0.weight',\n              tensor([[[-2.8822e-02,  1.2485e-03,  1.8985e-02, -9.2963e-02, -1.4103e-01],\n                       [-3.8532e-02,  1.1846e-01, -6.4143e-03, -1.3094e-01,  6.5535e-02],\n                       [-9.4960e-02,  1.6787e-02,  4.3510e-02, -6.3501e-02, -5.2746e-02],\n                       ...,\n                       [-3.3159e-02,  9.1410e-03, -9.6063e-02,  4.1033e-02,  1.5353e-02],\n                       [ 1.1296e-02, -4.6843e-03, -3.5706e-02, -5.4735e-02, -2.3998e-02],\n                       [-3.7127e-02,  1.4047e-01, -4.9726e-02,  5.0396e-02, -7.7704e-02]],\n              \n                      [[-7.9695e-02, -6.1371e-02,  8.2181e-02,  2.4825e-03, -4.5607e-02],\n                       [-8.9958e-02, -4.2680e-02, -6.1142e-02, -8.6555e-02, -8.1925e-02],\n                       [-2.7633e-02, -1.2870e-01,  2.1726e-02,  4.6425e-02, -7.2292e-02],\n                       ...,\n                       [-4.1130e-02, -7.8817e-02,  6.3787e-02, -3.8858e-02,  4.6789e-02],\n                       [-1.1209e-01, -4.2281e-02,  1.1450e-01,  5.2905e-02,  8.0796e-02],\n                       [ 1.3445e-01,  1.1298e-01,  3.4486e-02,  1.0648e-01, -6.6742e-03]],\n              \n                      [[-3.8999e-03, -2.0157e-02,  5.9176e-02, -7.8486e-02, -1.4282e-01],\n                       [-2.1463e-02,  1.7024e-02, -1.3019e-02,  1.7350e-02,  2.0830e-02],\n                       [ 1.2035e-02,  1.1232e-01, -1.9243e-01, -1.0697e-01, -2.0361e-02],\n                       ...,\n                       [-1.0004e-02, -9.1690e-02,  4.0629e-02, -1.9581e-01, -3.6702e-02],\n                       [-2.5979e-02, -1.2273e-02, -9.9933e-02, -2.6069e-02, -7.3736e-03],\n                       [ 2.3884e-02,  1.1642e-01, -1.8114e-01, -7.3712e-02,  2.0206e-02]],\n              \n                      ...,\n              \n                      [[ 4.2080e-02, -7.6083e-02,  4.0925e-02,  3.3351e-02, -2.6871e-02],\n                       [-1.9038e-02,  7.3626e-02, -1.3557e-01, -4.8968e-02,  1.0000e-01],\n                       [ 9.3484e-02, -1.2961e-01,  1.0342e-01,  4.6477e-02,  1.1057e-02],\n                       ...,\n                       [ 7.5360e-02,  1.0262e-01,  2.9145e-03, -1.6490e-02, -7.8245e-02],\n                       [ 2.0870e-01,  9.3220e-04,  3.5401e-02, -4.8976e-02,  5.4136e-02],\n                       [ 6.8829e-02,  1.4155e-02,  1.5808e-04, -5.5147e-02, -8.8265e-02]],\n              \n                      [[-2.6412e-03, -1.0583e-01,  7.4697e-02,  2.0400e-02,  9.5265e-02],\n                       [ 1.2656e-01, -7.3105e-02, -7.2432e-02, -2.0990e-02, -1.3040e-02],\n                       [-1.0603e-01,  5.4632e-02, -9.9588e-03, -2.3245e-03, -1.0607e-01],\n                       ...,\n                       [ 5.3532e-03,  7.2195e-02, -3.9823e-02,  6.5705e-02,  4.6370e-02],\n                       [-4.2855e-03,  3.4427e-02,  1.0558e-01,  9.6915e-03, -7.6557e-02],\n                       [ 8.4089e-02, -6.7822e-02,  1.3072e-02, -1.1363e-01,  6.1712e-02]],\n              \n                      [[-1.3348e-02,  3.9903e-02, -2.2272e-02,  4.2507e-02, -6.7797e-02],\n                       [-8.5360e-03, -1.1590e-01, -1.4245e-01, -1.2304e-01,  5.1314e-02],\n                       [ 1.0559e-01, -7.4059e-02,  5.8632e-02, -8.1564e-02,  1.7192e-02],\n                       ...,\n                       [ 5.2315e-02,  1.6432e-01, -4.1654e-02,  1.5325e-02,  2.8996e-02],\n                       [ 6.9300e-03,  3.9455e-02,  8.3214e-03, -1.3036e-01, -7.3669e-02],\n                       [-6.5765e-02, -1.1853e-01,  4.8825e-02,  9.3607e-02, -1.5216e-02]]],\n                     dtype=torch.float64)),\n             ('5.1.convs.1.1.weight',\n              tensor([0.9722, 0.9357, 0.9484, 0.9477, 0.9739, 0.9537, 0.9841, 0.9407, 0.9567,\n                      0.9408, 0.9677, 0.9597, 1.0016, 0.9671, 0.9639, 0.9408, 0.9698, 0.9637,\n                      0.9410, 0.9552, 0.9355, 0.9578, 0.9649, 0.9530, 0.9647, 0.9949, 0.9994,\n                      0.9352, 0.9620, 0.9830, 0.9396, 0.9447, 0.9794, 0.9663, 0.9718, 0.9526,\n                      0.9634, 0.9594, 0.9903, 0.9402, 0.9425, 0.9839, 0.9811, 0.9757, 0.9702,\n                      0.9685, 0.9703, 0.9493, 0.9458, 0.9343, 0.9509, 0.9749, 0.9513, 0.9507,\n                      0.9554, 0.9404, 0.9541, 0.9664, 0.9620, 0.9471, 0.9134, 0.9650, 0.9607,\n                      0.9568], dtype=torch.float64)),\n             ('5.1.convs.1.1.bias',\n              tensor([ 0.0115, -0.0010,  0.0144,  0.0087, -0.0084, -0.0146, -0.0037, -0.0025,\n                       0.0072, -0.0294, -0.0195, -0.0080,  0.0052, -0.0137, -0.0018, -0.0110,\n                      -0.0178,  0.0073, -0.0092,  0.0066,  0.0005, -0.0205,  0.0090, -0.0065,\n                      -0.0090,  0.0028,  0.0182,  0.0011, -0.0046,  0.0104, -0.0083, -0.0009,\n                       0.0114, -0.0061, -0.0067, -0.0157, -0.0099, -0.0049, -0.0079, -0.0008,\n                      -0.0133, -0.0042, -0.0026, -0.0038,  0.0067, -0.0016,  0.0125,  0.0097,\n                      -0.0110, -0.0143, -0.0157,  0.0014, -0.0142,  0.0033,  0.0104,  0.0029,\n                       0.0168, -0.0145, -0.0007, -0.0061, -0.0240, -0.0042, -0.0238,  0.0014],\n                     dtype=torch.float64)),\n             ('5.1.convs.1.1.running_mean',\n              tensor([ 0.2460, -0.7263, -0.8839, -0.4444, -0.2036,  0.5146,  0.0956, -0.1903,\n                      -0.8145, -0.1859,  0.0559, -0.2376, -0.6705,  0.4210, -0.0619, -0.4655,\n                      -0.1691, -0.9954, -0.2535, -0.0864,  0.0398, -0.5552,  0.4488, -1.6294,\n                       0.4878, -0.5536, -0.5203, -0.2061,  0.7451, -0.2923, -0.5234,  0.4983,\n                      -0.1976, -0.6074, -0.2561,  0.1104,  0.3511,  0.2087, -0.7091, -0.1421,\n                       0.2730, -0.2149,  0.7309,  0.1189, -0.1028,  0.1600, -0.3771, -0.3887,\n                       0.8279, -0.0818, -0.1739,  0.3368,  0.2999, -0.8493, -0.1990, -0.5888,\n                      -0.0979, -1.0269,  0.5693,  0.3546, -0.2058,  0.5056, -0.4248, -0.2196],\n                     dtype=torch.float64)),\n             ('5.1.convs.1.1.running_var',\n              tensor([0.3385, 0.7571, 0.9774, 0.4811, 0.4292, 0.3068, 0.5528, 1.1460, 0.5158,\n                      0.5674, 0.6217, 0.5287, 0.4167, 0.6227, 0.7274, 0.4905, 0.3726, 0.5732,\n                      0.6586, 0.5560, 0.9818, 0.7259, 0.4499, 0.5902, 0.4680, 0.4380, 0.3904,\n                      0.7961, 0.9763, 0.7018, 0.6855, 0.4412, 0.4781, 0.4218, 0.6745, 0.4236,\n                      0.6542, 0.5003, 0.5218, 0.5681, 0.3624, 0.3073, 0.5675, 0.4707, 0.4017,\n                      0.8201, 0.4755, 0.7380, 0.6446, 0.6470, 0.4889, 0.3855, 0.8941, 0.7151,\n                      0.4213, 0.6554, 0.5438, 0.4121, 0.5246, 0.4166, 1.0352, 0.4654, 0.6506,\n                      0.3318], dtype=torch.float64)),\n             ('5.1.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('5.1.convs.2.0.weight',\n              tensor([[[ 0.0887],\n                       [-0.1184],\n                       [ 0.0219],\n                       ...,\n                       [-0.0692],\n                       [-0.0604],\n                       [ 0.0245]],\n              \n                      [[-0.1176],\n                       [ 0.0129],\n                       [-0.0251],\n                       ...,\n                       [-0.1393],\n                       [-0.1761],\n                       [-0.1405]],\n              \n                      [[-0.0464],\n                       [-0.0757],\n                       [ 0.2077],\n                       ...,\n                       [-0.0788],\n                       [-0.1461],\n                       [ 0.0595]],\n              \n                      ...,\n              \n                      [[ 0.0047],\n                       [-0.0862],\n                       [ 0.0382],\n                       ...,\n                       [ 0.1366],\n                       [-0.1257],\n                       [-0.0427]],\n              \n                      [[ 0.0675],\n                       [-0.1607],\n                       [-0.1476],\n                       ...,\n                       [ 0.1047],\n                       [-0.3514],\n                       [ 0.0181]],\n              \n                      [[ 0.2848],\n                       [ 0.0039],\n                       [-0.0269],\n                       ...,\n                       [-0.0451],\n                       [ 0.1248],\n                       [-0.1390]]], dtype=torch.float64)),\n             ('5.1.convs.2.1.weight',\n              tensor([-1.4484e-02,  2.4060e-02, -1.5821e-02,  1.7680e-02,  1.0004e-02,\n                       6.7027e-03,  7.1994e-03, -5.7556e-03,  2.7408e-02, -1.5671e-02,\n                       2.8246e-02, -1.3701e-02,  9.5285e-03, -8.2807e-03,  2.7995e-02,\n                       5.1928e-03,  2.7838e-02, -1.2236e-02, -1.1792e-02, -1.2598e-03,\n                       1.3194e-02,  3.9099e-02,  1.8926e-02, -9.4776e-03, -3.3609e-02,\n                      -1.6652e-02,  1.4418e-02, -1.3012e-02,  1.7943e-03,  1.7996e-05,\n                      -1.0830e-02,  3.4367e-02,  6.0117e-03, -7.8726e-03, -1.8774e-02,\n                       1.6318e-02,  8.7413e-03, -2.2869e-02,  3.0065e-02, -5.1092e-02,\n                      -4.1643e-03, -1.0612e-02, -1.0678e-02,  2.8561e-02, -1.4670e-02,\n                      -1.2908e-02, -1.1333e-02,  1.7391e-02, -1.0823e-02,  1.4037e-02,\n                      -2.5065e-02,  7.2836e-03, -5.9721e-03,  4.3940e-03,  1.2836e-03,\n                       1.4670e-02, -6.0508e-03, -4.2665e-04,  5.8563e-03, -2.4786e-02,\n                       1.6972e-03, -1.1594e-02, -2.2277e-02,  2.7276e-02, -2.4767e-02,\n                       2.1095e-05,  1.6215e-02,  1.6422e-02, -1.0606e-02, -1.4994e-02,\n                      -1.5378e-02, -1.0347e-02,  1.5926e-02,  1.2498e-02, -2.7314e-02,\n                      -2.0244e-03, -4.3138e-04,  1.9042e-02,  6.3526e-03,  1.5578e-02,\n                       3.7470e-03,  1.5024e-02, -3.4547e-02, -7.3746e-03,  3.1425e-03,\n                      -7.4004e-03,  8.9991e-03,  8.6577e-03, -2.4076e-02,  1.2354e-02,\n                       4.3793e-02,  1.3150e-02,  3.6373e-03,  2.2131e-03, -1.4569e-02,\n                       4.9260e-03, -1.1855e-02, -1.8495e-02,  2.3242e-02,  7.7317e-03,\n                      -1.7826e-02, -4.1511e-03, -4.6887e-05, -2.9618e-02, -9.9099e-03,\n                       9.9212e-03, -8.5481e-03,  1.7056e-02, -8.1480e-03,  2.2757e-02,\n                       4.1966e-03,  1.2208e-02,  2.9778e-02, -2.2393e-02, -4.9657e-03,\n                       1.0071e-02, -2.8339e-02, -1.7792e-02, -2.3064e-02, -1.0165e-03,\n                      -7.5977e-03, -1.2112e-02, -3.8129e-03, -2.4011e-02, -1.8196e-02,\n                       2.0467e-03, -1.0265e-02,  1.3830e-03, -1.5956e-03,  1.3412e-02,\n                      -3.3821e-02,  2.2743e-02, -2.5334e-03,  4.7229e-03, -1.6918e-04,\n                      -7.7931e-03, -6.5810e-03, -2.3996e-02,  1.7700e-02, -1.1242e-02,\n                      -2.2661e-02,  2.3588e-02,  3.0319e-02, -3.3790e-02, -5.3754e-03,\n                      -3.5318e-02, -2.9229e-02,  1.5058e-02, -2.2024e-03, -3.5551e-03,\n                      -1.4546e-02,  1.1025e-02, -1.7624e-02, -3.8083e-03,  7.2399e-04,\n                       1.1371e-02, -2.7100e-02, -1.9468e-02,  7.0739e-03, -1.2828e-02,\n                       1.0319e-02, -2.7104e-02,  7.1754e-03,  1.8182e-02,  7.7546e-03,\n                      -3.9762e-03, -2.5968e-02,  2.3149e-02,  1.3973e-03,  2.4551e-02,\n                      -2.6404e-02, -1.7582e-02,  1.2709e-02, -2.5211e-02, -1.5519e-02,\n                       1.4110e-02,  3.2698e-02,  3.0017e-02,  1.5884e-02, -2.7614e-02,\n                      -4.8938e-03,  1.5177e-03,  1.8752e-02, -1.9644e-03, -1.4398e-02,\n                      -1.0213e-02, -5.2851e-03, -3.8904e-02,  1.8935e-02, -7.9892e-03,\n                       3.9587e-02,  2.9115e-02, -7.2967e-03,  1.6550e-03, -1.6670e-02,\n                       2.1029e-02, -2.1488e-02,  1.6215e-02,  7.9129e-03, -2.0565e-02,\n                       1.6048e-02, -1.2154e-02,  1.5583e-02, -8.4278e-03,  8.6094e-03,\n                       1.0712e-02, -1.9833e-03, -4.4301e-03,  1.4733e-02, -6.4257e-03,\n                       6.4938e-03,  2.2979e-02, -5.5136e-02, -3.6341e-02,  2.2795e-03,\n                       2.3132e-02, -5.5454e-03,  1.1062e-03,  1.3274e-02,  1.1317e-03,\n                      -3.5712e-03,  2.2272e-02,  1.2925e-02, -5.5573e-03,  2.4395e-02,\n                      -8.0691e-03,  1.2851e-02,  1.9469e-03, -1.2008e-02,  3.6867e-02,\n                       2.0844e-02,  1.2165e-02,  4.1987e-03,  1.8967e-02, -2.3222e-02,\n                      -1.7012e-03, -1.0029e-02,  6.7193e-04, -2.4867e-02,  2.9023e-02,\n                      -7.1035e-03,  2.0554e-02,  1.5082e-02, -4.6764e-03, -4.3468e-02,\n                      -1.4599e-02, -1.4143e-02,  2.4892e-02,  8.1495e-03, -9.3870e-03,\n                      -1.0902e-02,  1.5992e-02, -2.2400e-02, -5.8628e-03,  1.5269e-02,\n                      -3.4191e-02], dtype=torch.float64)),\n             ('5.1.convs.2.1.bias',\n              tensor([ 2.6467e-03,  3.5621e-03,  2.4586e-02,  9.1864e-04,  5.4386e-03,\n                      -1.3073e-02,  1.4003e-02,  4.7672e-03,  1.0467e-02, -7.4992e-03,\n                       7.8223e-03, -8.1994e-03,  1.5500e-02, -1.5284e-02,  1.0318e-02,\n                       1.1017e-02,  2.3494e-02,  5.9243e-03,  2.2890e-02, -3.1521e-03,\n                       2.6486e-03, -3.2956e-03, -9.4196e-04,  6.5877e-03,  2.5979e-03,\n                      -2.4859e-02,  1.9443e-04,  1.9493e-02,  5.1488e-03,  3.9546e-03,\n                      -1.1861e-02,  1.6343e-02, -1.2308e-02,  1.6588e-02,  1.4449e-02,\n                      -2.9676e-03,  8.4376e-03,  2.6566e-02,  7.5975e-04,  1.4410e-03,\n                       4.0850e-03, -1.9492e-03, -4.1031e-03,  1.1416e-02,  1.7308e-02,\n                      -4.6010e-03, -1.0145e-02,  7.5677e-03, -5.0903e-03,  7.8801e-03,\n                      -6.8099e-03,  3.6849e-03,  1.6951e-02,  1.9921e-02, -1.3318e-02,\n                       3.8281e-03,  2.5204e-03,  1.2347e-02,  5.8227e-03,  8.4169e-03,\n                      -1.4195e-02,  5.1661e-03,  2.8175e-03,  1.5309e-02,  7.6095e-04,\n                       5.7642e-04, -9.4214e-03,  1.4950e-02,  6.5317e-03, -1.4393e-02,\n                       8.7542e-03,  1.7641e-02,  1.0705e-02, -8.3376e-03,  3.7260e-03,\n                       1.6089e-02,  9.4727e-03, -1.5217e-02,  8.7095e-03,  1.1258e-02,\n                       1.5661e-02, -2.2282e-04,  1.5608e-02,  8.8063e-03,  1.5374e-03,\n                       5.7068e-03,  5.8167e-03,  6.3144e-03,  1.2047e-02, -5.6070e-03,\n                       7.8076e-03,  2.0185e-02,  2.1289e-02,  3.5340e-03,  5.4981e-03,\n                      -1.3772e-02,  9.1510e-03,  7.6078e-03,  1.9582e-02, -1.1931e-02,\n                       2.8270e-02, -3.5271e-03, -9.0778e-03, -2.3380e-02,  1.3050e-02,\n                       6.4681e-03, -1.9051e-02,  6.6048e-03,  7.6475e-03,  2.2611e-03,\n                      -9.8005e-03, -4.5752e-03,  1.2396e-02,  1.1839e-02,  8.9775e-03,\n                       8.5787e-03,  1.3353e-02,  1.1867e-02,  1.1656e-02, -1.1063e-02,\n                       1.0566e-02,  1.2834e-02,  6.3888e-03,  1.3243e-03, -6.5305e-03,\n                       1.1252e-02,  7.8873e-03,  4.9865e-03,  5.5484e-03,  4.0718e-03,\n                       2.8809e-03,  1.3060e-04,  7.1151e-03,  6.6269e-03, -4.1984e-03,\n                      -1.4836e-02, -5.4421e-04,  1.8262e-02,  9.4871e-03, -8.7651e-03,\n                      -4.2096e-03,  9.2563e-03, -1.3128e-03,  1.6432e-02, -1.0688e-02,\n                      -4.6770e-03,  3.3567e-03, -3.0195e-03,  1.1251e-02,  1.2881e-02,\n                      -1.8275e-03,  2.1332e-02,  1.3575e-02,  1.6090e-02,  7.5408e-03,\n                       1.6935e-02,  1.1664e-02,  1.5063e-02, -5.0726e-04, -1.9454e-02,\n                       4.6041e-03,  1.2843e-03, -5.5430e-03,  2.0276e-02,  9.3970e-03,\n                       6.6393e-03, -7.2259e-03,  2.0915e-02,  1.4294e-02,  1.6495e-02,\n                       1.2451e-02,  4.9003e-03, -5.1965e-03,  2.0434e-02, -1.6000e-02,\n                      -3.0319e-03,  5.5181e-03,  2.7155e-02,  9.9750e-03,  2.1698e-03,\n                      -5.7021e-03,  1.9082e-02, -1.2070e-02, -4.4871e-03,  1.1556e-02,\n                       7.4446e-03,  1.2396e-02,  1.6811e-02,  6.2275e-04,  9.8089e-04,\n                      -1.1326e-02,  8.8346e-03,  1.3930e-02, -1.5289e-02,  9.0687e-03,\n                       9.0314e-03, -1.0433e-02,  5.0957e-03,  1.3083e-02, -1.7574e-02,\n                       1.1813e-02,  2.4866e-03,  1.5218e-02,  2.1210e-02,  1.6170e-03,\n                      -6.4291e-03,  1.9493e-02, -9.3202e-03,  8.3216e-05,  1.1686e-02,\n                       3.9976e-03,  1.5542e-02,  7.6439e-03,  1.4180e-02,  4.6126e-03,\n                       9.1490e-03,  3.1062e-03,  1.4317e-02,  9.1694e-03,  6.7761e-04,\n                      -2.7925e-03, -5.3314e-03,  1.3476e-02,  1.5350e-03,  2.6178e-03,\n                       8.7681e-03,  3.2841e-03,  4.3396e-03, -2.6013e-02, -4.8178e-03,\n                      -1.0945e-02,  9.1176e-03,  1.0112e-02,  4.4025e-03,  2.7864e-03,\n                       5.5671e-03,  9.2334e-03,  2.0519e-04,  6.6878e-03,  1.5838e-02,\n                      -6.5399e-03,  7.2038e-03,  1.2324e-02,  9.2483e-04,  1.0488e-02,\n                       1.3904e-02,  1.0555e-02,  2.2139e-02, -6.6749e-03, -1.2933e-02,\n                       2.2974e-02,  9.9409e-03,  1.0546e-02,  2.4950e-02,  2.2768e-02,\n                       7.5406e-03], dtype=torch.float64)),\n             ('5.1.convs.2.1.running_mean',\n              tensor([ 0.1799,  0.2545, -1.0684, -0.0301,  0.0502, -0.3574, -0.0693, -0.3150,\n                      -0.1281,  0.0464, -0.5032, -0.3386, -0.4414,  0.0697, -0.0848,  0.2036,\n                      -0.0998,  0.2620, -0.4533,  0.1850,  0.3123, -0.1771, -0.2537,  0.3064,\n                       0.7670,  0.5196,  0.1614,  0.5801,  0.4516,  0.0686,  0.4415, -0.3302,\n                      -0.1308, -0.3081,  0.4754,  0.1104,  0.0675,  0.3615, -0.1302,  0.3732,\n                      -0.1112,  0.3024,  0.3030,  0.0607,  0.1409,  0.1522, -0.1603,  0.3408,\n                      -0.2801,  0.3629, -0.1850,  0.1913, -0.1634, -0.1457,  0.2779, -0.4692,\n                      -0.1993,  0.0512, -0.1551,  0.5274, -0.0227,  0.6553, -0.2389, -0.4373,\n                       0.1403,  0.1935, -0.4901, -0.0802,  0.3918, -0.2360, -0.0385,  0.0058,\n                       0.1625,  0.2746, -0.1614,  0.0605,  0.2209, -0.0312,  0.5692, -0.2589,\n                      -0.2791,  0.1027,  0.2905, -0.0795, -0.1235, -0.4761, -0.4858,  0.1625,\n                       0.4696,  0.9872,  0.2046,  0.3632, -0.2589,  0.4811,  0.4034,  0.2007,\n                       0.5738, -0.4710,  0.3987, -0.1481, -0.2564, -0.4176,  0.0557,  0.4308,\n                       0.0284, -0.5646, -0.5781,  0.6282,  0.1819,  0.2029, -0.0011, -0.4480,\n                       0.6909,  0.4385, -0.2755, -0.0793,  0.4621, -0.5441,  0.6407, -0.0380,\n                       0.3739, -0.0545,  0.5805, -0.4208, -0.2036, -0.5364,  0.1907, -0.4222,\n                       0.0274,  0.1612, -0.5792, -0.5994,  0.6857, -0.6049, -0.4200, -0.2065,\n                       0.1632,  0.1546,  0.1242,  0.1398, -0.3307,  0.2271,  0.4490,  0.4329,\n                      -0.0159, -0.1483, -0.4382, -0.2899, -0.1896, -0.5038, -0.1710, -0.0723,\n                       0.3827,  0.0726, -0.2493,  0.2988,  0.1441,  0.2591, -0.7494, -0.0289,\n                      -0.7942,  0.2059, -0.2673, -0.6443, -0.4627, -0.3680, -0.4649, -0.0570,\n                       0.3165, -0.2184, -0.0011,  0.2783,  0.2601, -0.1636,  0.1370,  0.1517,\n                      -0.2626, -0.2333, -0.3996,  0.1684, -0.3741, -0.0440, -0.3362, -0.3169,\n                      -0.3687, -0.2183,  0.2959, -0.3455, -0.0560, -0.1653,  0.2082, -0.3645,\n                      -0.5862,  0.4253, -0.5083,  0.1078, -0.0019,  0.0697, -0.1366, -0.4649,\n                      -0.2601, -0.2101,  0.6666,  0.2146,  0.3121, -0.3148, -0.0060,  0.3212,\n                      -0.0285,  0.1868, -0.3835, -0.0466,  0.1268,  0.0465, -0.2208,  0.4443,\n                      -0.1136, -0.2645,  0.5335,  0.5235, -0.3720, -0.9376,  0.0054, -0.5012,\n                      -0.7063, -0.0275,  0.2142, -0.1865,  0.1894,  0.2918, -0.1469, -0.3304,\n                      -0.2009,  0.4353, -0.2344, -0.2793, -0.3011,  0.0890, -0.2630,  0.0165,\n                       0.6288,  0.4842,  0.4707, -0.0747, -0.0866,  0.0673,  0.3266,  0.4181,\n                      -0.0662, -0.0472,  0.5022,  0.2459, -0.3195, -0.2582, -0.2492, -0.1294],\n                     dtype=torch.float64)),\n             ('5.1.convs.2.1.running_var',\n              tensor([0.5083, 0.4525, 0.4264, 0.4030, 0.2131, 0.2214, 0.0872, 0.2819, 0.2365,\n                      0.3857, 0.3239, 0.2090, 0.2513, 0.2205, 0.4706, 0.2331, 0.4063, 0.5280,\n                      0.1390, 0.4195, 0.3273, 0.4307, 0.3184, 0.3764, 0.6338, 0.3207, 0.3061,\n                      0.4294, 0.2039, 0.1357, 0.3558, 0.3176, 0.3359, 0.4530, 0.3442, 0.5268,\n                      0.2307, 0.3414, 0.4628, 0.4066, 0.0804, 0.1596, 0.2515, 0.4422, 0.2434,\n                      0.2322, 0.6315, 0.3841, 0.7122, 0.4020, 0.2835, 0.2713, 0.2560, 0.1708,\n                      0.3551, 0.3925, 0.2648, 0.1672, 0.3340, 0.3882, 0.0428, 0.5039, 0.4115,\n                      0.3638, 0.4886, 0.2170, 0.3542, 0.2313, 0.3556, 0.4583, 0.3788, 0.2604,\n                      0.1423, 0.5101, 0.4413, 0.0444, 0.1431, 0.3172, 0.4177, 0.4100, 0.2575,\n                      0.2465, 0.2106, 0.2513, 0.2056, 0.4136, 0.3246, 0.2026, 0.4262, 0.5689,\n                      0.4934, 0.3784, 0.2777, 0.2366, 0.1733, 0.3448, 0.5307, 0.2373, 0.4583,\n                      0.3108, 0.3837, 0.2506, 0.0355, 0.2489, 0.1779, 0.2896, 0.3316, 0.3510,\n                      0.2836, 0.1879, 0.0991, 0.3623, 0.4366, 0.5086, 0.2951, 0.3674, 0.2996,\n                      0.4407, 0.2471, 0.1693, 0.1206, 0.3549, 0.5662, 0.4759, 0.2303, 0.2170,\n                      0.1431, 0.2873, 0.0623, 0.3189, 0.2714, 0.2241, 0.2750, 0.2059, 0.2472,\n                      0.1296, 0.0951, 0.6274, 0.2723, 0.1928, 0.2035, 0.2051, 0.2913, 0.2437,\n                      0.1742, 0.3946, 0.1887, 0.4072, 0.0466, 0.5468, 0.4535, 0.2292, 0.3212,\n                      0.2862, 0.4399, 0.3765, 0.5877, 0.2998, 0.4328, 0.0761, 0.2586, 0.2693,\n                      0.1558, 0.1633, 0.2083, 0.2559, 0.5269, 0.3179, 0.3107, 0.3687, 0.2612,\n                      0.3297, 0.3701, 0.2630, 0.4493, 0.5962, 0.3719, 0.4477, 0.4263, 0.4919,\n                      0.2203, 0.2870, 0.3967, 0.4773, 0.3568, 0.5817, 0.3578, 0.6070, 0.2943,\n                      0.0964, 0.2554, 0.6090, 0.3904, 0.3197, 0.2639, 0.2806, 0.2134, 0.1997,\n                      0.2890, 0.4716, 0.1724, 0.3214, 0.3035, 0.1765, 0.1868, 0.3011, 0.1621,\n                      0.0784, 0.2137, 0.2643, 0.1179, 0.3438, 0.4663, 0.2542, 0.0423, 0.4008,\n                      0.3419, 0.1204, 0.3841, 0.4801, 0.2602, 0.3955, 0.0697, 0.4197, 0.6130,\n                      0.2240, 0.2783, 0.1415, 0.4425, 0.3721, 0.2576, 0.1467, 0.1896, 0.4804,\n                      0.3742, 0.2743, 0.2529, 0.0914, 0.4352, 0.4298, 0.1658, 0.1864, 0.4956,\n                      0.2357, 0.2129, 0.1157, 0.2210, 0.4624, 0.0971, 0.3878, 0.3802, 0.5571,\n                      0.2806, 0.4068, 0.4196, 0.3667], dtype=torch.float64)),\n             ('5.1.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('5.1.convpath.0.0.0.weight',\n              tensor([[[ 0.0076],\n                       [-0.0982],\n                       [-0.0178],\n                       ...,\n                       [-0.0798],\n                       [-0.0446],\n                       [ 0.0332]],\n              \n                      [[ 0.1163],\n                       [-0.0898],\n                       [ 0.0355],\n                       ...,\n                       [-0.0894],\n                       [ 0.0627],\n                       [ 0.1547]],\n              \n                      [[-0.0080],\n                       [ 0.1616],\n                       [-0.1517],\n                       ...,\n                       [-0.0432],\n                       [-0.0443],\n                       [ 0.0113]],\n              \n                      ...,\n              \n                      [[-0.0169],\n                       [ 0.0508],\n                       [ 0.0046],\n                       ...,\n                       [ 0.1651],\n                       [ 0.1270],\n                       [-0.0545]],\n              \n                      [[-0.0298],\n                       [ 0.1147],\n                       [-0.0598],\n                       ...,\n                       [ 0.0002],\n                       [ 0.1135],\n                       [ 0.0419]],\n              \n                      [[-0.0184],\n                       [-0.0036],\n                       [-0.1082],\n                       ...,\n                       [-0.0426],\n                       [-0.1598],\n                       [-0.0270]]], dtype=torch.float64)),\n             ('5.1.convpath.0.0.1.weight',\n              tensor([0.9542, 0.9726, 0.9547, 0.9844, 0.9470, 0.9612, 0.9635, 0.9581, 0.9643,\n                      0.9584, 0.9628, 0.9636, 0.9591, 0.9880, 0.9528, 0.9826, 0.9588, 0.9508,\n                      0.9822, 0.9764, 0.9798, 0.9575, 0.9815, 0.9557, 0.9573, 0.9787, 0.9932,\n                      0.9611, 0.9849, 0.9847, 0.9721, 0.9414, 0.9655, 0.9875, 0.9560, 0.9877,\n                      0.9514, 0.9880, 0.9545, 0.9745, 1.0012, 0.9487, 0.9591, 0.9452, 0.9579,\n                      0.9613, 0.9584, 0.9899, 0.9645, 0.9808, 0.9528, 0.9768, 0.9631, 0.9795,\n                      0.9749, 0.9608, 0.9955, 0.9540, 0.9649, 0.9630, 0.9609, 0.9487, 0.9520,\n                      0.9967], dtype=torch.float64)),\n             ('5.1.convpath.0.0.1.bias',\n              tensor([ 0.0145,  0.0082,  0.0121,  0.0194,  0.0162,  0.0151, -0.0090,  0.0111,\n                      -0.0068, -0.0026, -0.0111,  0.0037,  0.0070,  0.0081, -0.0133,  0.0097,\n                       0.0055,  0.0033,  0.0151,  0.0097, -0.0045, -0.0224,  0.0100, -0.0079,\n                       0.0030, -0.0071,  0.0152,  0.0025,  0.0202,  0.0090, -0.0188,  0.0089,\n                       0.0130,  0.0257, -0.0005,  0.0115,  0.0046,  0.0253, -0.0070,  0.0055,\n                       0.0017, -0.0224, -0.0131,  0.0144, -0.0069, -0.0004,  0.0199, -0.0056,\n                       0.0127, -0.0062, -0.0092,  0.0128,  0.0008,  0.0133, -0.0085,  0.0076,\n                       0.0454,  0.0092,  0.0159,  0.0154, -0.0173, -0.0076, -0.0145,  0.0306],\n                     dtype=torch.float64)),\n             ('5.1.convpath.0.0.1.running_mean',\n              tensor([-0.4015,  0.3196, -0.3832, -0.4130, -0.6135, -0.0987,  0.5634, -0.4502,\n                      -0.1414,  0.0754,  0.0739, -0.5565,  0.1044, -0.7221,  0.3753, -0.0966,\n                       0.0424, -0.7741,  0.0641,  0.5895,  0.2306, -0.0159,  0.0631, -0.5771,\n                       0.0146,  0.3478,  0.4249, -0.3396, -1.0293,  0.5138,  0.2020, -0.9589,\n                      -0.4396, -0.0913,  0.6810, -0.3692,  0.3011, -1.0276,  0.4403,  0.2252,\n                       0.3268,  0.7222,  0.7186, -0.5876,  0.1908, -0.1902, -0.4671, -0.7667,\n                       0.4031, -0.0417,  0.1755, -0.1440, -0.5106, -0.7178, -0.2990, -0.3281,\n                       0.2159,  0.0703, -0.1432,  0.0612,  0.4324,  0.6224,  0.4043, -0.4857],\n                     dtype=torch.float64)),\n             ('5.1.convpath.0.0.1.running_var',\n              tensor([0.3512, 0.2639, 0.3500, 0.2246, 1.0532, 0.2996, 0.4827, 1.2664, 0.4607,\n                      0.6660, 0.3107, 0.4125, 0.3903, 0.4698, 0.9222, 0.1887, 0.5127, 0.5488,\n                      0.1266, 2.4062, 0.2648, 0.5591, 0.4424, 1.0512, 0.2584, 0.1376, 0.2405,\n                      0.2588, 0.2594, 0.3091, 0.3472, 2.2546, 0.5255, 0.2641, 0.2329, 0.2488,\n                      0.3938, 0.2428, 0.5283, 0.2762, 0.2008, 1.4145, 1.2052, 1.3863, 0.1852,\n                      0.2493, 0.3640, 0.2333, 1.4517, 0.1355, 0.3578, 0.2755, 0.2707, 0.2753,\n                      0.2557, 0.7284, 0.4098, 0.2760, 0.2808, 0.6784, 0.6208, 1.2235, 0.6766,\n                      0.2110], dtype=torch.float64)),\n             ('5.1.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('5.1.convpath.0.1.0.weight',\n              tensor([[[-2.8822e-02,  1.2485e-03,  1.8985e-02, -9.2963e-02, -1.4103e-01],\n                       [-3.8532e-02,  1.1846e-01, -6.4143e-03, -1.3094e-01,  6.5535e-02],\n                       [-9.4960e-02,  1.6787e-02,  4.3510e-02, -6.3501e-02, -5.2746e-02],\n                       ...,\n                       [-3.3159e-02,  9.1410e-03, -9.6063e-02,  4.1033e-02,  1.5353e-02],\n                       [ 1.1296e-02, -4.6843e-03, -3.5706e-02, -5.4735e-02, -2.3998e-02],\n                       [-3.7127e-02,  1.4047e-01, -4.9726e-02,  5.0396e-02, -7.7704e-02]],\n              \n                      [[-7.9695e-02, -6.1371e-02,  8.2181e-02,  2.4825e-03, -4.5607e-02],\n                       [-8.9958e-02, -4.2680e-02, -6.1142e-02, -8.6555e-02, -8.1925e-02],\n                       [-2.7633e-02, -1.2870e-01,  2.1726e-02,  4.6425e-02, -7.2292e-02],\n                       ...,\n                       [-4.1130e-02, -7.8817e-02,  6.3787e-02, -3.8858e-02,  4.6789e-02],\n                       [-1.1209e-01, -4.2281e-02,  1.1450e-01,  5.2905e-02,  8.0796e-02],\n                       [ 1.3445e-01,  1.1298e-01,  3.4486e-02,  1.0648e-01, -6.6742e-03]],\n              \n                      [[-3.8999e-03, -2.0157e-02,  5.9176e-02, -7.8486e-02, -1.4282e-01],\n                       [-2.1463e-02,  1.7024e-02, -1.3019e-02,  1.7350e-02,  2.0830e-02],\n                       [ 1.2035e-02,  1.1232e-01, -1.9243e-01, -1.0697e-01, -2.0361e-02],\n                       ...,\n                       [-1.0004e-02, -9.1690e-02,  4.0629e-02, -1.9581e-01, -3.6702e-02],\n                       [-2.5979e-02, -1.2273e-02, -9.9933e-02, -2.6069e-02, -7.3736e-03],\n                       [ 2.3884e-02,  1.1642e-01, -1.8114e-01, -7.3712e-02,  2.0206e-02]],\n              \n                      ...,\n              \n                      [[ 4.2080e-02, -7.6083e-02,  4.0925e-02,  3.3351e-02, -2.6871e-02],\n                       [-1.9038e-02,  7.3626e-02, -1.3557e-01, -4.8968e-02,  1.0000e-01],\n                       [ 9.3484e-02, -1.2961e-01,  1.0342e-01,  4.6477e-02,  1.1057e-02],\n                       ...,\n                       [ 7.5360e-02,  1.0262e-01,  2.9145e-03, -1.6490e-02, -7.8245e-02],\n                       [ 2.0870e-01,  9.3220e-04,  3.5401e-02, -4.8976e-02,  5.4136e-02],\n                       [ 6.8829e-02,  1.4155e-02,  1.5808e-04, -5.5147e-02, -8.8265e-02]],\n              \n                      [[-2.6412e-03, -1.0583e-01,  7.4697e-02,  2.0400e-02,  9.5265e-02],\n                       [ 1.2656e-01, -7.3105e-02, -7.2432e-02, -2.0990e-02, -1.3040e-02],\n                       [-1.0603e-01,  5.4632e-02, -9.9588e-03, -2.3245e-03, -1.0607e-01],\n                       ...,\n                       [ 5.3532e-03,  7.2195e-02, -3.9823e-02,  6.5705e-02,  4.6370e-02],\n                       [-4.2855e-03,  3.4427e-02,  1.0558e-01,  9.6915e-03, -7.6557e-02],\n                       [ 8.4089e-02, -6.7822e-02,  1.3072e-02, -1.1363e-01,  6.1712e-02]],\n              \n                      [[-1.3348e-02,  3.9903e-02, -2.2272e-02,  4.2507e-02, -6.7797e-02],\n                       [-8.5360e-03, -1.1590e-01, -1.4245e-01, -1.2304e-01,  5.1314e-02],\n                       [ 1.0559e-01, -7.4059e-02,  5.8632e-02, -8.1564e-02,  1.7192e-02],\n                       ...,\n                       [ 5.2315e-02,  1.6432e-01, -4.1654e-02,  1.5325e-02,  2.8996e-02],\n                       [ 6.9300e-03,  3.9455e-02,  8.3214e-03, -1.3036e-01, -7.3669e-02],\n                       [-6.5765e-02, -1.1853e-01,  4.8825e-02,  9.3607e-02, -1.5216e-02]]],\n                     dtype=torch.float64)),\n             ('5.1.convpath.0.1.1.weight',\n              tensor([0.9722, 0.9357, 0.9484, 0.9477, 0.9739, 0.9537, 0.9841, 0.9407, 0.9567,\n                      0.9408, 0.9677, 0.9597, 1.0016, 0.9671, 0.9639, 0.9408, 0.9698, 0.9637,\n                      0.9410, 0.9552, 0.9355, 0.9578, 0.9649, 0.9530, 0.9647, 0.9949, 0.9994,\n                      0.9352, 0.9620, 0.9830, 0.9396, 0.9447, 0.9794, 0.9663, 0.9718, 0.9526,\n                      0.9634, 0.9594, 0.9903, 0.9402, 0.9425, 0.9839, 0.9811, 0.9757, 0.9702,\n                      0.9685, 0.9703, 0.9493, 0.9458, 0.9343, 0.9509, 0.9749, 0.9513, 0.9507,\n                      0.9554, 0.9404, 0.9541, 0.9664, 0.9620, 0.9471, 0.9134, 0.9650, 0.9607,\n                      0.9568], dtype=torch.float64)),\n             ('5.1.convpath.0.1.1.bias',\n              tensor([ 0.0115, -0.0010,  0.0144,  0.0087, -0.0084, -0.0146, -0.0037, -0.0025,\n                       0.0072, -0.0294, -0.0195, -0.0080,  0.0052, -0.0137, -0.0018, -0.0110,\n                      -0.0178,  0.0073, -0.0092,  0.0066,  0.0005, -0.0205,  0.0090, -0.0065,\n                      -0.0090,  0.0028,  0.0182,  0.0011, -0.0046,  0.0104, -0.0083, -0.0009,\n                       0.0114, -0.0061, -0.0067, -0.0157, -0.0099, -0.0049, -0.0079, -0.0008,\n                      -0.0133, -0.0042, -0.0026, -0.0038,  0.0067, -0.0016,  0.0125,  0.0097,\n                      -0.0110, -0.0143, -0.0157,  0.0014, -0.0142,  0.0033,  0.0104,  0.0029,\n                       0.0168, -0.0145, -0.0007, -0.0061, -0.0240, -0.0042, -0.0238,  0.0014],\n                     dtype=torch.float64)),\n             ('5.1.convpath.0.1.1.running_mean',\n              tensor([ 0.2460, -0.7263, -0.8839, -0.4444, -0.2036,  0.5146,  0.0956, -0.1903,\n                      -0.8145, -0.1859,  0.0559, -0.2376, -0.6705,  0.4210, -0.0619, -0.4655,\n                      -0.1691, -0.9954, -0.2535, -0.0864,  0.0398, -0.5552,  0.4488, -1.6294,\n                       0.4878, -0.5536, -0.5203, -0.2061,  0.7451, -0.2923, -0.5234,  0.4983,\n                      -0.1976, -0.6074, -0.2561,  0.1104,  0.3511,  0.2087, -0.7091, -0.1421,\n                       0.2730, -0.2149,  0.7309,  0.1189, -0.1028,  0.1600, -0.3771, -0.3887,\n                       0.8279, -0.0818, -0.1739,  0.3368,  0.2999, -0.8493, -0.1990, -0.5888,\n                      -0.0979, -1.0269,  0.5693,  0.3546, -0.2058,  0.5056, -0.4248, -0.2196],\n                     dtype=torch.float64)),\n             ('5.1.convpath.0.1.1.running_var',\n              tensor([0.3385, 0.7571, 0.9774, 0.4811, 0.4292, 0.3068, 0.5528, 1.1460, 0.5158,\n                      0.5674, 0.6217, 0.5287, 0.4167, 0.6227, 0.7274, 0.4905, 0.3726, 0.5732,\n                      0.6586, 0.5560, 0.9818, 0.7259, 0.4499, 0.5902, 0.4680, 0.4380, 0.3904,\n                      0.7961, 0.9763, 0.7018, 0.6855, 0.4412, 0.4781, 0.4218, 0.6745, 0.4236,\n                      0.6542, 0.5003, 0.5218, 0.5681, 0.3624, 0.3073, 0.5675, 0.4707, 0.4017,\n                      0.8201, 0.4755, 0.7380, 0.6446, 0.6470, 0.4889, 0.3855, 0.8941, 0.7151,\n                      0.4213, 0.6554, 0.5438, 0.4121, 0.5246, 0.4166, 1.0352, 0.4654, 0.6506,\n                      0.3318], dtype=torch.float64)),\n             ('5.1.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('5.1.convpath.0.2.0.weight',\n              tensor([[[ 0.0887],\n                       [-0.1184],\n                       [ 0.0219],\n                       ...,\n                       [-0.0692],\n                       [-0.0604],\n                       [ 0.0245]],\n              \n                      [[-0.1176],\n                       [ 0.0129],\n                       [-0.0251],\n                       ...,\n                       [-0.1393],\n                       [-0.1761],\n                       [-0.1405]],\n              \n                      [[-0.0464],\n                       [-0.0757],\n                       [ 0.2077],\n                       ...,\n                       [-0.0788],\n                       [-0.1461],\n                       [ 0.0595]],\n              \n                      ...,\n              \n                      [[ 0.0047],\n                       [-0.0862],\n                       [ 0.0382],\n                       ...,\n                       [ 0.1366],\n                       [-0.1257],\n                       [-0.0427]],\n              \n                      [[ 0.0675],\n                       [-0.1607],\n                       [-0.1476],\n                       ...,\n                       [ 0.1047],\n                       [-0.3514],\n                       [ 0.0181]],\n              \n                      [[ 0.2848],\n                       [ 0.0039],\n                       [-0.0269],\n                       ...,\n                       [-0.0451],\n                       [ 0.1248],\n                       [-0.1390]]], dtype=torch.float64)),\n             ('5.1.convpath.0.2.1.weight',\n              tensor([-1.4484e-02,  2.4060e-02, -1.5821e-02,  1.7680e-02,  1.0004e-02,\n                       6.7027e-03,  7.1994e-03, -5.7556e-03,  2.7408e-02, -1.5671e-02,\n                       2.8246e-02, -1.3701e-02,  9.5285e-03, -8.2807e-03,  2.7995e-02,\n                       5.1928e-03,  2.7838e-02, -1.2236e-02, -1.1792e-02, -1.2598e-03,\n                       1.3194e-02,  3.9099e-02,  1.8926e-02, -9.4776e-03, -3.3609e-02,\n                      -1.6652e-02,  1.4418e-02, -1.3012e-02,  1.7943e-03,  1.7996e-05,\n                      -1.0830e-02,  3.4367e-02,  6.0117e-03, -7.8726e-03, -1.8774e-02,\n                       1.6318e-02,  8.7413e-03, -2.2869e-02,  3.0065e-02, -5.1092e-02,\n                      -4.1643e-03, -1.0612e-02, -1.0678e-02,  2.8561e-02, -1.4670e-02,\n                      -1.2908e-02, -1.1333e-02,  1.7391e-02, -1.0823e-02,  1.4037e-02,\n                      -2.5065e-02,  7.2836e-03, -5.9721e-03,  4.3940e-03,  1.2836e-03,\n                       1.4670e-02, -6.0508e-03, -4.2665e-04,  5.8563e-03, -2.4786e-02,\n                       1.6972e-03, -1.1594e-02, -2.2277e-02,  2.7276e-02, -2.4767e-02,\n                       2.1095e-05,  1.6215e-02,  1.6422e-02, -1.0606e-02, -1.4994e-02,\n                      -1.5378e-02, -1.0347e-02,  1.5926e-02,  1.2498e-02, -2.7314e-02,\n                      -2.0244e-03, -4.3138e-04,  1.9042e-02,  6.3526e-03,  1.5578e-02,\n                       3.7470e-03,  1.5024e-02, -3.4547e-02, -7.3746e-03,  3.1425e-03,\n                      -7.4004e-03,  8.9991e-03,  8.6577e-03, -2.4076e-02,  1.2354e-02,\n                       4.3793e-02,  1.3150e-02,  3.6373e-03,  2.2131e-03, -1.4569e-02,\n                       4.9260e-03, -1.1855e-02, -1.8495e-02,  2.3242e-02,  7.7317e-03,\n                      -1.7826e-02, -4.1511e-03, -4.6887e-05, -2.9618e-02, -9.9099e-03,\n                       9.9212e-03, -8.5481e-03,  1.7056e-02, -8.1480e-03,  2.2757e-02,\n                       4.1966e-03,  1.2208e-02,  2.9778e-02, -2.2393e-02, -4.9657e-03,\n                       1.0071e-02, -2.8339e-02, -1.7792e-02, -2.3064e-02, -1.0165e-03,\n                      -7.5977e-03, -1.2112e-02, -3.8129e-03, -2.4011e-02, -1.8196e-02,\n                       2.0467e-03, -1.0265e-02,  1.3830e-03, -1.5956e-03,  1.3412e-02,\n                      -3.3821e-02,  2.2743e-02, -2.5334e-03,  4.7229e-03, -1.6918e-04,\n                      -7.7931e-03, -6.5810e-03, -2.3996e-02,  1.7700e-02, -1.1242e-02,\n                      -2.2661e-02,  2.3588e-02,  3.0319e-02, -3.3790e-02, -5.3754e-03,\n                      -3.5318e-02, -2.9229e-02,  1.5058e-02, -2.2024e-03, -3.5551e-03,\n                      -1.4546e-02,  1.1025e-02, -1.7624e-02, -3.8083e-03,  7.2399e-04,\n                       1.1371e-02, -2.7100e-02, -1.9468e-02,  7.0739e-03, -1.2828e-02,\n                       1.0319e-02, -2.7104e-02,  7.1754e-03,  1.8182e-02,  7.7546e-03,\n                      -3.9762e-03, -2.5968e-02,  2.3149e-02,  1.3973e-03,  2.4551e-02,\n                      -2.6404e-02, -1.7582e-02,  1.2709e-02, -2.5211e-02, -1.5519e-02,\n                       1.4110e-02,  3.2698e-02,  3.0017e-02,  1.5884e-02, -2.7614e-02,\n                      -4.8938e-03,  1.5177e-03,  1.8752e-02, -1.9644e-03, -1.4398e-02,\n                      -1.0213e-02, -5.2851e-03, -3.8904e-02,  1.8935e-02, -7.9892e-03,\n                       3.9587e-02,  2.9115e-02, -7.2967e-03,  1.6550e-03, -1.6670e-02,\n                       2.1029e-02, -2.1488e-02,  1.6215e-02,  7.9129e-03, -2.0565e-02,\n                       1.6048e-02, -1.2154e-02,  1.5583e-02, -8.4278e-03,  8.6094e-03,\n                       1.0712e-02, -1.9833e-03, -4.4301e-03,  1.4733e-02, -6.4257e-03,\n                       6.4938e-03,  2.2979e-02, -5.5136e-02, -3.6341e-02,  2.2795e-03,\n                       2.3132e-02, -5.5454e-03,  1.1062e-03,  1.3274e-02,  1.1317e-03,\n                      -3.5712e-03,  2.2272e-02,  1.2925e-02, -5.5573e-03,  2.4395e-02,\n                      -8.0691e-03,  1.2851e-02,  1.9469e-03, -1.2008e-02,  3.6867e-02,\n                       2.0844e-02,  1.2165e-02,  4.1987e-03,  1.8967e-02, -2.3222e-02,\n                      -1.7012e-03, -1.0029e-02,  6.7193e-04, -2.4867e-02,  2.9023e-02,\n                      -7.1035e-03,  2.0554e-02,  1.5082e-02, -4.6764e-03, -4.3468e-02,\n                      -1.4599e-02, -1.4143e-02,  2.4892e-02,  8.1495e-03, -9.3870e-03,\n                      -1.0902e-02,  1.5992e-02, -2.2400e-02, -5.8628e-03,  1.5269e-02,\n                      -3.4191e-02], dtype=torch.float64)),\n             ('5.1.convpath.0.2.1.bias',\n              tensor([ 2.6467e-03,  3.5621e-03,  2.4586e-02,  9.1864e-04,  5.4386e-03,\n                      -1.3073e-02,  1.4003e-02,  4.7672e-03,  1.0467e-02, -7.4992e-03,\n                       7.8223e-03, -8.1994e-03,  1.5500e-02, -1.5284e-02,  1.0318e-02,\n                       1.1017e-02,  2.3494e-02,  5.9243e-03,  2.2890e-02, -3.1521e-03,\n                       2.6486e-03, -3.2956e-03, -9.4196e-04,  6.5877e-03,  2.5979e-03,\n                      -2.4859e-02,  1.9443e-04,  1.9493e-02,  5.1488e-03,  3.9546e-03,\n                      -1.1861e-02,  1.6343e-02, -1.2308e-02,  1.6588e-02,  1.4449e-02,\n                      -2.9676e-03,  8.4376e-03,  2.6566e-02,  7.5975e-04,  1.4410e-03,\n                       4.0850e-03, -1.9492e-03, -4.1031e-03,  1.1416e-02,  1.7308e-02,\n                      -4.6010e-03, -1.0145e-02,  7.5677e-03, -5.0903e-03,  7.8801e-03,\n                      -6.8099e-03,  3.6849e-03,  1.6951e-02,  1.9921e-02, -1.3318e-02,\n                       3.8281e-03,  2.5204e-03,  1.2347e-02,  5.8227e-03,  8.4169e-03,\n                      -1.4195e-02,  5.1661e-03,  2.8175e-03,  1.5309e-02,  7.6095e-04,\n                       5.7642e-04, -9.4214e-03,  1.4950e-02,  6.5317e-03, -1.4393e-02,\n                       8.7542e-03,  1.7641e-02,  1.0705e-02, -8.3376e-03,  3.7260e-03,\n                       1.6089e-02,  9.4727e-03, -1.5217e-02,  8.7095e-03,  1.1258e-02,\n                       1.5661e-02, -2.2282e-04,  1.5608e-02,  8.8063e-03,  1.5374e-03,\n                       5.7068e-03,  5.8167e-03,  6.3144e-03,  1.2047e-02, -5.6070e-03,\n                       7.8076e-03,  2.0185e-02,  2.1289e-02,  3.5340e-03,  5.4981e-03,\n                      -1.3772e-02,  9.1510e-03,  7.6078e-03,  1.9582e-02, -1.1931e-02,\n                       2.8270e-02, -3.5271e-03, -9.0778e-03, -2.3380e-02,  1.3050e-02,\n                       6.4681e-03, -1.9051e-02,  6.6048e-03,  7.6475e-03,  2.2611e-03,\n                      -9.8005e-03, -4.5752e-03,  1.2396e-02,  1.1839e-02,  8.9775e-03,\n                       8.5787e-03,  1.3353e-02,  1.1867e-02,  1.1656e-02, -1.1063e-02,\n                       1.0566e-02,  1.2834e-02,  6.3888e-03,  1.3243e-03, -6.5305e-03,\n                       1.1252e-02,  7.8873e-03,  4.9865e-03,  5.5484e-03,  4.0718e-03,\n                       2.8809e-03,  1.3060e-04,  7.1151e-03,  6.6269e-03, -4.1984e-03,\n                      -1.4836e-02, -5.4421e-04,  1.8262e-02,  9.4871e-03, -8.7651e-03,\n                      -4.2096e-03,  9.2563e-03, -1.3128e-03,  1.6432e-02, -1.0688e-02,\n                      -4.6770e-03,  3.3567e-03, -3.0195e-03,  1.1251e-02,  1.2881e-02,\n                      -1.8275e-03,  2.1332e-02,  1.3575e-02,  1.6090e-02,  7.5408e-03,\n                       1.6935e-02,  1.1664e-02,  1.5063e-02, -5.0726e-04, -1.9454e-02,\n                       4.6041e-03,  1.2843e-03, -5.5430e-03,  2.0276e-02,  9.3970e-03,\n                       6.6393e-03, -7.2259e-03,  2.0915e-02,  1.4294e-02,  1.6495e-02,\n                       1.2451e-02,  4.9003e-03, -5.1965e-03,  2.0434e-02, -1.6000e-02,\n                      -3.0319e-03,  5.5181e-03,  2.7155e-02,  9.9750e-03,  2.1698e-03,\n                      -5.7021e-03,  1.9082e-02, -1.2070e-02, -4.4871e-03,  1.1556e-02,\n                       7.4446e-03,  1.2396e-02,  1.6811e-02,  6.2275e-04,  9.8089e-04,\n                      -1.1326e-02,  8.8346e-03,  1.3930e-02, -1.5289e-02,  9.0687e-03,\n                       9.0314e-03, -1.0433e-02,  5.0957e-03,  1.3083e-02, -1.7574e-02,\n                       1.1813e-02,  2.4866e-03,  1.5218e-02,  2.1210e-02,  1.6170e-03,\n                      -6.4291e-03,  1.9493e-02, -9.3202e-03,  8.3216e-05,  1.1686e-02,\n                       3.9976e-03,  1.5542e-02,  7.6439e-03,  1.4180e-02,  4.6126e-03,\n                       9.1490e-03,  3.1062e-03,  1.4317e-02,  9.1694e-03,  6.7761e-04,\n                      -2.7925e-03, -5.3314e-03,  1.3476e-02,  1.5350e-03,  2.6178e-03,\n                       8.7681e-03,  3.2841e-03,  4.3396e-03, -2.6013e-02, -4.8178e-03,\n                      -1.0945e-02,  9.1176e-03,  1.0112e-02,  4.4025e-03,  2.7864e-03,\n                       5.5671e-03,  9.2334e-03,  2.0519e-04,  6.6878e-03,  1.5838e-02,\n                      -6.5399e-03,  7.2038e-03,  1.2324e-02,  9.2483e-04,  1.0488e-02,\n                       1.3904e-02,  1.0555e-02,  2.2139e-02, -6.6749e-03, -1.2933e-02,\n                       2.2974e-02,  9.9409e-03,  1.0546e-02,  2.4950e-02,  2.2768e-02,\n                       7.5406e-03], dtype=torch.float64)),\n             ('5.1.convpath.0.2.1.running_mean',\n              tensor([ 0.1799,  0.2545, -1.0684, -0.0301,  0.0502, -0.3574, -0.0693, -0.3150,\n                      -0.1281,  0.0464, -0.5032, -0.3386, -0.4414,  0.0697, -0.0848,  0.2036,\n                      -0.0998,  0.2620, -0.4533,  0.1850,  0.3123, -0.1771, -0.2537,  0.3064,\n                       0.7670,  0.5196,  0.1614,  0.5801,  0.4516,  0.0686,  0.4415, -0.3302,\n                      -0.1308, -0.3081,  0.4754,  0.1104,  0.0675,  0.3615, -0.1302,  0.3732,\n                      -0.1112,  0.3024,  0.3030,  0.0607,  0.1409,  0.1522, -0.1603,  0.3408,\n                      -0.2801,  0.3629, -0.1850,  0.1913, -0.1634, -0.1457,  0.2779, -0.4692,\n                      -0.1993,  0.0512, -0.1551,  0.5274, -0.0227,  0.6553, -0.2389, -0.4373,\n                       0.1403,  0.1935, -0.4901, -0.0802,  0.3918, -0.2360, -0.0385,  0.0058,\n                       0.1625,  0.2746, -0.1614,  0.0605,  0.2209, -0.0312,  0.5692, -0.2589,\n                      -0.2791,  0.1027,  0.2905, -0.0795, -0.1235, -0.4761, -0.4858,  0.1625,\n                       0.4696,  0.9872,  0.2046,  0.3632, -0.2589,  0.4811,  0.4034,  0.2007,\n                       0.5738, -0.4710,  0.3987, -0.1481, -0.2564, -0.4176,  0.0557,  0.4308,\n                       0.0284, -0.5646, -0.5781,  0.6282,  0.1819,  0.2029, -0.0011, -0.4480,\n                       0.6909,  0.4385, -0.2755, -0.0793,  0.4621, -0.5441,  0.6407, -0.0380,\n                       0.3739, -0.0545,  0.5805, -0.4208, -0.2036, -0.5364,  0.1907, -0.4222,\n                       0.0274,  0.1612, -0.5792, -0.5994,  0.6857, -0.6049, -0.4200, -0.2065,\n                       0.1632,  0.1546,  0.1242,  0.1398, -0.3307,  0.2271,  0.4490,  0.4329,\n                      -0.0159, -0.1483, -0.4382, -0.2899, -0.1896, -0.5038, -0.1710, -0.0723,\n                       0.3827,  0.0726, -0.2493,  0.2988,  0.1441,  0.2591, -0.7494, -0.0289,\n                      -0.7942,  0.2059, -0.2673, -0.6443, -0.4627, -0.3680, -0.4649, -0.0570,\n                       0.3165, -0.2184, -0.0011,  0.2783,  0.2601, -0.1636,  0.1370,  0.1517,\n                      -0.2626, -0.2333, -0.3996,  0.1684, -0.3741, -0.0440, -0.3362, -0.3169,\n                      -0.3687, -0.2183,  0.2959, -0.3455, -0.0560, -0.1653,  0.2082, -0.3645,\n                      -0.5862,  0.4253, -0.5083,  0.1078, -0.0019,  0.0697, -0.1366, -0.4649,\n                      -0.2601, -0.2101,  0.6666,  0.2146,  0.3121, -0.3148, -0.0060,  0.3212,\n                      -0.0285,  0.1868, -0.3835, -0.0466,  0.1268,  0.0465, -0.2208,  0.4443,\n                      -0.1136, -0.2645,  0.5335,  0.5235, -0.3720, -0.9376,  0.0054, -0.5012,\n                      -0.7063, -0.0275,  0.2142, -0.1865,  0.1894,  0.2918, -0.1469, -0.3304,\n                      -0.2009,  0.4353, -0.2344, -0.2793, -0.3011,  0.0890, -0.2630,  0.0165,\n                       0.6288,  0.4842,  0.4707, -0.0747, -0.0866,  0.0673,  0.3266,  0.4181,\n                      -0.0662, -0.0472,  0.5022,  0.2459, -0.3195, -0.2582, -0.2492, -0.1294],\n                     dtype=torch.float64)),\n             ('5.1.convpath.0.2.1.running_var',\n              tensor([0.5083, 0.4525, 0.4264, 0.4030, 0.2131, 0.2214, 0.0872, 0.2819, 0.2365,\n                      0.3857, 0.3239, 0.2090, 0.2513, 0.2205, 0.4706, 0.2331, 0.4063, 0.5280,\n                      0.1390, 0.4195, 0.3273, 0.4307, 0.3184, 0.3764, 0.6338, 0.3207, 0.3061,\n                      0.4294, 0.2039, 0.1357, 0.3558, 0.3176, 0.3359, 0.4530, 0.3442, 0.5268,\n                      0.2307, 0.3414, 0.4628, 0.4066, 0.0804, 0.1596, 0.2515, 0.4422, 0.2434,\n                      0.2322, 0.6315, 0.3841, 0.7122, 0.4020, 0.2835, 0.2713, 0.2560, 0.1708,\n                      0.3551, 0.3925, 0.2648, 0.1672, 0.3340, 0.3882, 0.0428, 0.5039, 0.4115,\n                      0.3638, 0.4886, 0.2170, 0.3542, 0.2313, 0.3556, 0.4583, 0.3788, 0.2604,\n                      0.1423, 0.5101, 0.4413, 0.0444, 0.1431, 0.3172, 0.4177, 0.4100, 0.2575,\n                      0.2465, 0.2106, 0.2513, 0.2056, 0.4136, 0.3246, 0.2026, 0.4262, 0.5689,\n                      0.4934, 0.3784, 0.2777, 0.2366, 0.1733, 0.3448, 0.5307, 0.2373, 0.4583,\n                      0.3108, 0.3837, 0.2506, 0.0355, 0.2489, 0.1779, 0.2896, 0.3316, 0.3510,\n                      0.2836, 0.1879, 0.0991, 0.3623, 0.4366, 0.5086, 0.2951, 0.3674, 0.2996,\n                      0.4407, 0.2471, 0.1693, 0.1206, 0.3549, 0.5662, 0.4759, 0.2303, 0.2170,\n                      0.1431, 0.2873, 0.0623, 0.3189, 0.2714, 0.2241, 0.2750, 0.2059, 0.2472,\n                      0.1296, 0.0951, 0.6274, 0.2723, 0.1928, 0.2035, 0.2051, 0.2913, 0.2437,\n                      0.1742, 0.3946, 0.1887, 0.4072, 0.0466, 0.5468, 0.4535, 0.2292, 0.3212,\n                      0.2862, 0.4399, 0.3765, 0.5877, 0.2998, 0.4328, 0.0761, 0.2586, 0.2693,\n                      0.1558, 0.1633, 0.2083, 0.2559, 0.5269, 0.3179, 0.3107, 0.3687, 0.2612,\n                      0.3297, 0.3701, 0.2630, 0.4493, 0.5962, 0.3719, 0.4477, 0.4263, 0.4919,\n                      0.2203, 0.2870, 0.3967, 0.4773, 0.3568, 0.5817, 0.3578, 0.6070, 0.2943,\n                      0.0964, 0.2554, 0.6090, 0.3904, 0.3197, 0.2639, 0.2806, 0.2134, 0.1997,\n                      0.2890, 0.4716, 0.1724, 0.3214, 0.3035, 0.1765, 0.1868, 0.3011, 0.1621,\n                      0.0784, 0.2137, 0.2643, 0.1179, 0.3438, 0.4663, 0.2542, 0.0423, 0.4008,\n                      0.3419, 0.1204, 0.3841, 0.4801, 0.2602, 0.3955, 0.0697, 0.4197, 0.6130,\n                      0.2240, 0.2783, 0.1415, 0.4425, 0.3721, 0.2576, 0.1467, 0.1896, 0.4804,\n                      0.3742, 0.2743, 0.2529, 0.0914, 0.4352, 0.4298, 0.1658, 0.1864, 0.4956,\n                      0.2357, 0.2129, 0.1157, 0.2210, 0.4624, 0.0971, 0.3878, 0.3802, 0.5571,\n                      0.2806, 0.4068, 0.4196, 0.3667], dtype=torch.float64)),\n             ('5.1.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('5.2.convs.0.0.weight',\n              tensor([[[ 0.2465],\n                       [ 0.0327],\n                       [ 0.1565],\n                       ...,\n                       [ 0.0351],\n                       [ 0.2499],\n                       [ 0.0393]],\n              \n                      [[-0.1605],\n                       [-0.0112],\n                       [-0.1289],\n                       ...,\n                       [ 0.0487],\n                       [-0.1187],\n                       [-0.1153]],\n              \n                      [[ 0.0234],\n                       [ 0.0714],\n                       [ 0.0335],\n                       ...,\n                       [-0.0326],\n                       [ 0.1077],\n                       [ 0.0157]],\n              \n                      ...,\n              \n                      [[-0.0647],\n                       [ 0.1698],\n                       [-0.2075],\n                       ...,\n                       [ 0.0198],\n                       [ 0.0900],\n                       [ 0.0786]],\n              \n                      [[ 0.0538],\n                       [ 0.0904],\n                       [-0.0362],\n                       ...,\n                       [ 0.0161],\n                       [ 0.1532],\n                       [ 0.0023]],\n              \n                      [[ 0.1125],\n                       [-0.0409],\n                       [ 0.0799],\n                       ...,\n                       [-0.0316],\n                       [-0.0877],\n                       [ 0.0267]]], dtype=torch.float64)),\n             ('5.2.convs.0.1.weight',\n              tensor([0.9718, 0.9777, 0.9873, 0.9560, 0.9861, 0.9529, 0.9876, 0.9585, 0.9495,\n                      0.9689, 0.9613, 0.9486, 0.9840, 0.9657, 0.9529, 0.9297, 0.9400, 0.9771,\n                      0.9702, 0.9706, 0.9701, 0.9638, 0.9673, 0.9656, 0.9542, 0.9832, 0.9519,\n                      0.9800, 0.9740, 0.9579, 0.9796, 0.9857, 0.9505, 0.9300, 0.9698, 0.9621,\n                      0.9450, 0.9521, 0.9544, 0.9788, 0.9951, 0.9470, 0.9968, 0.9734, 1.0029,\n                      0.9602, 0.9962, 0.9744, 0.9632, 0.9564, 0.9475, 0.9758, 0.9684, 0.9493,\n                      0.9586, 0.9765, 1.0156, 0.9701, 1.0021, 0.9873, 0.9622, 0.9918, 0.9635,\n                      0.9517], dtype=torch.float64)),\n             ('5.2.convs.0.1.bias',\n              tensor([ 0.0128,  0.0049,  0.0139,  0.0025,  0.0016, -0.0142,  0.0261, -0.0112,\n                      -0.0076,  0.0091,  0.0041, -0.0126,  0.0117,  0.0036, -0.0037, -0.0279,\n                      -0.0085, -0.0267, -0.0282,  0.0037, -0.0136, -0.0065,  0.0166,  0.0084,\n                      -0.0028,  0.0073,  0.0134, -0.0006,  0.0160,  0.0039, -0.0076,  0.0151,\n                      -0.0118, -0.0019,  0.0151, -0.0161, -0.0051, -0.0081, -0.0138,  0.0108,\n                       0.0153, -0.0089,  0.0191,  0.0055,  0.0013, -0.0054,  0.0010, -0.0022,\n                      -0.0028, -0.0218, -0.0210, -0.0124, -0.0024, -0.0183,  0.0074, -0.0113,\n                       0.0223,  0.0022,  0.0126,  0.0226,  0.0154,  0.0154,  0.0166, -0.0041],\n                     dtype=torch.float64)),\n             ('5.2.convs.0.1.running_mean',\n              tensor([ 0.1861, -0.4981,  0.1280,  0.3149,  0.5631,  0.1058, -0.5804,  0.5050,\n                       0.4690, -0.0734,  0.2646,  0.2869, -0.1322, -0.5256, -0.1596,  0.6383,\n                      -0.4537, -0.0892,  0.0048,  0.2870, -0.1865, -0.1021,  0.3619,  0.1271,\n                      -0.5318,  0.8270,  0.0630,  0.3405, -0.3889, -0.2037,  0.3884, -0.5711,\n                      -0.3243, -0.1310,  0.2976,  0.3313, -0.2495,  0.1354, -0.3669,  0.2238,\n                      -0.1816,  0.2281,  0.7505, -0.4221, -0.1864, -0.1407, -0.3311,  0.0103,\n                       0.3222,  0.2643,  0.2738,  0.3247, -0.1160, -0.2153, -0.0671, -0.8978,\n                      -0.0743,  0.3005, -0.5724,  0.2061, -0.2143,  0.5772,  0.6037, -0.4130],\n                     dtype=torch.float64)),\n             ('5.2.convs.0.1.running_var',\n              tensor([0.2737, 0.2852, 0.1659, 0.1925, 0.4861, 0.3042, 0.6225, 0.1398, 0.8645,\n                      0.2841, 0.1744, 0.4147, 0.1803, 0.4634, 0.6174, 0.4701, 0.5342, 0.1912,\n                      0.2771, 0.2143, 0.3767, 0.5351, 0.4776, 0.3440, 0.4651, 1.0038, 0.6621,\n                      0.3207, 0.4459, 0.2635, 0.1684, 0.5185, 0.1838, 1.0525, 0.7845, 0.4282,\n                      0.7125, 1.3959, 0.7664, 0.3390, 0.3703, 0.4147, 0.6935, 0.5135, 0.4189,\n                      0.2424, 0.1737, 0.1830, 0.2703, 0.4573, 0.7137, 0.4623, 0.8958, 1.0623,\n                      0.3095, 0.1404, 0.3933, 0.2169, 0.2733, 0.3009, 0.3690, 0.7798, 2.1939,\n                      1.0433], dtype=torch.float64)),\n             ('5.2.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('5.2.convs.1.0.weight',\n              tensor([[[ 0.0267, -0.0278, -0.0824, -0.0077,  0.0798],\n                       [-0.1499, -0.0092, -0.0124,  0.0436, -0.0924],\n                       [-0.0308,  0.0029,  0.1709,  0.0220,  0.0762],\n                       ...,\n                       [-0.0044, -0.1050,  0.0058, -0.0167, -0.0694],\n                       [-0.0729,  0.1170, -0.0244, -0.0123, -0.0150],\n                       [ 0.0932,  0.0632, -0.0174,  0.1201,  0.0390]],\n              \n                      [[ 0.0006,  0.0196,  0.0151, -0.0849, -0.1938],\n                       [-0.0505, -0.0889, -0.0670, -0.0169, -0.0062],\n                       [ 0.1040, -0.0827,  0.0639,  0.0728,  0.0010],\n                       ...,\n                       [ 0.0433, -0.0441,  0.0453,  0.0311, -0.1213],\n                       [ 0.0293,  0.0865,  0.1829,  0.1123, -0.1026],\n                       [ 0.1678,  0.0870,  0.0900,  0.0161, -0.0459]],\n              \n                      [[ 0.1008,  0.0028,  0.0360, -0.0558, -0.0558],\n                       [-0.1065, -0.0553,  0.0231, -0.0518, -0.1905],\n                       [ 0.1324, -0.1144,  0.0928, -0.0772, -0.0241],\n                       ...,\n                       [-0.0225, -0.0419, -0.1298, -0.1394,  0.0419],\n                       [ 0.1130,  0.0456,  0.0146, -0.0136, -0.0062],\n                       [-0.0142, -0.0184, -0.1355, -0.0254, -0.1185]],\n              \n                      ...,\n              \n                      [[ 0.0244,  0.0019, -0.0136, -0.0343,  0.0246],\n                       [-0.1187,  0.0454,  0.0309,  0.0833,  0.1114],\n                       [ 0.0173,  0.0710, -0.0162, -0.1391,  0.0260],\n                       ...,\n                       [-0.0933,  0.1038, -0.0115, -0.1776, -0.0114],\n                       [ 0.0270, -0.1323, -0.0570, -0.0025,  0.0352],\n                       [-0.0348, -0.0544,  0.0174,  0.1369, -0.0911]],\n              \n                      [[ 0.2121,  0.0498, -0.0729,  0.0567,  0.0127],\n                       [-0.0625,  0.0561,  0.0045,  0.0480,  0.0451],\n                       [ 0.0325, -0.0058, -0.0166, -0.0508, -0.0300],\n                       ...,\n                       [-0.0131, -0.0609, -0.0637,  0.0036,  0.0440],\n                       [-0.0642, -0.0043, -0.0678, -0.0191,  0.0035],\n                       [-0.0985,  0.1032,  0.0250,  0.0416,  0.0501]],\n              \n                      [[-0.0639, -0.0551, -0.0403, -0.0509, -0.1249],\n                       [ 0.0133, -0.1062, -0.0041,  0.0765, -0.0700],\n                       [ 0.0836, -0.0446, -0.1639, -0.0522, -0.0371],\n                       ...,\n                       [ 0.0325,  0.0946, -0.0663,  0.1416,  0.0080],\n                       [ 0.1071, -0.0153, -0.0143, -0.0866,  0.0613],\n                       [-0.0047, -0.0542,  0.1036, -0.0031, -0.0496]]], dtype=torch.float64)),\n             ('5.2.convs.1.1.weight',\n              tensor([0.9452, 0.9588, 0.9792, 0.9549, 0.9559, 0.9314, 0.9493, 0.9904, 0.9600,\n                      0.9590, 0.9584, 0.9725, 0.9978, 0.9839, 0.9722, 1.0143, 0.9760, 0.9175,\n                      0.9549, 0.9702, 0.9459, 0.9395, 0.9378, 0.9889, 0.9777, 0.9716, 0.9648,\n                      0.9882, 0.9241, 1.0013, 0.9391, 1.0092, 0.9578, 0.9618, 0.9352, 0.9792,\n                      0.9429, 0.9581, 0.9732, 0.9706, 0.9443, 0.9790, 0.9635, 0.9627, 0.9195,\n                      0.9801, 0.9356, 0.9571, 0.9640, 1.0175, 0.9562, 0.9535, 0.9720, 0.9299,\n                      0.9137, 0.9616, 0.9601, 0.9708, 0.9492, 0.9554, 0.9506, 0.9405, 0.9406,\n                      0.9609], dtype=torch.float64)),\n             ('5.2.convs.1.1.bias',\n              tensor([ 0.0045,  0.0047,  0.0127, -0.0244, -0.0140, -0.0245, -0.0105, -0.0141,\n                       0.0062,  0.0182, -0.0048, -0.0060,  0.0137, -0.0113, -0.0158,  0.0264,\n                      -0.0057, -0.0167,  0.0010, -0.0059, -0.0086,  0.0008, -0.0085,  0.0071,\n                      -0.0100,  0.0156,  0.0007,  0.0075,  0.0046,  0.0374, -0.0289,  0.0265,\n                      -0.0030, -0.0223, -0.0086, -0.0152, -0.0172,  0.0038, -0.0017, -0.0097,\n                       0.0075,  0.0175,  0.0128, -0.0216,  0.0014, -0.0006, -0.0029, -0.0074,\n                      -0.0117,  0.0214,  0.0064, -0.0095, -0.0108, -0.0064, -0.0001,  0.0099,\n                       0.0096,  0.0060,  0.0199, -0.0330, -0.0325, -0.0204, -0.0217,  0.0018],\n                     dtype=torch.float64)),\n             ('5.2.convs.1.1.running_mean',\n              tensor([-0.5590,  0.2872, -0.4774,  0.1880,  0.0862, -0.4153,  0.4243, -0.1905,\n                      -0.3249, -0.8446, -0.1133, -0.7955, -0.0531,  0.3375,  0.7426,  0.0348,\n                      -0.2056, -0.7436, -0.7210,  0.1127, -0.5343, -1.1006,  0.0898, -0.4722,\n                      -0.0682, -0.0822, -0.3062,  0.3147, -0.0716, -0.6074, -0.2978,  0.0640,\n                       0.5326,  0.4372,  0.4151,  0.1852, -0.8952, -0.8330, -0.3593, -1.0658,\n                      -0.2528, -0.5342, -0.4132,  0.6631, -0.6332, -0.3022, -0.5100,  0.5441,\n                      -0.1287, -0.4375, -0.2796, -0.2046, -0.2930, -0.8862, -0.5406,  0.0384,\n                       0.0638,  0.8414, -0.0291, -0.2924,  0.2907, -0.0937, -0.3307, -0.0902],\n                     dtype=torch.float64)),\n             ('5.2.convs.1.1.running_var',\n              tensor([0.7594, 1.2881, 0.9124, 0.5638, 0.8131, 0.6536, 0.4475, 0.3312, 0.4160,\n                      1.1729, 0.4780, 0.5346, 0.4475, 0.3942, 0.6429, 0.4068, 0.9322, 1.0151,\n                      0.6030, 0.3815, 0.8400, 1.0118, 0.5295, 0.8745, 0.5717, 0.5017, 0.5024,\n                      0.3238, 0.6847, 0.7990, 0.6565, 0.4191, 0.6770, 0.9683, 0.5887, 0.4251,\n                      0.4819, 0.6405, 1.3750, 0.8232, 0.7416, 0.6119, 0.4224, 0.9823, 0.9154,\n                      0.7862, 0.4644, 1.0391, 0.6467, 0.4700, 0.5878, 0.4639, 0.4625, 1.9194,\n                      1.3265, 0.8025, 0.4810, 1.4349, 0.3681, 0.8418, 0.7349, 1.0717, 0.3841,\n                      0.9685], dtype=torch.float64)),\n             ('5.2.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('5.2.convs.2.0.weight',\n              tensor([[[ 0.0677],\n                       [-0.0901],\n                       [ 0.1860],\n                       ...,\n                       [ 0.1461],\n                       [-0.0717],\n                       [-0.2872]],\n              \n                      [[ 0.0078],\n                       [-0.0172],\n                       [-0.0999],\n                       ...,\n                       [-0.2508],\n                       [-0.1696],\n                       [ 0.1343]],\n              \n                      [[ 0.0590],\n                       [ 0.0999],\n                       [-0.1416],\n                       ...,\n                       [ 0.2324],\n                       [-0.2262],\n                       [-0.2073]],\n              \n                      ...,\n              \n                      [[-0.0620],\n                       [-0.0539],\n                       [ 0.2210],\n                       ...,\n                       [ 0.0141],\n                       [ 0.0642],\n                       [-0.0649]],\n              \n                      [[-0.0454],\n                       [-0.1227],\n                       [-0.0536],\n                       ...,\n                       [-0.0058],\n                       [-0.0805],\n                       [-0.0226]],\n              \n                      [[-0.0588],\n                       [ 0.1041],\n                       [ 0.0179],\n                       ...,\n                       [ 0.0193],\n                       [ 0.0241],\n                       [-0.2101]]], dtype=torch.float64)),\n             ('5.2.convs.2.1.weight',\n              tensor([-4.6090e-03,  4.4520e-02, -3.5884e-02, -5.1809e-03, -1.1737e-02,\n                       1.9843e-03,  2.5209e-03,  2.0795e-02, -1.6808e-02,  2.8201e-02,\n                       1.2781e-02,  4.1221e-03,  1.1184e-02,  1.8085e-02,  4.1422e-02,\n                       2.3324e-02, -3.2433e-02,  7.9463e-03, -3.4576e-02, -7.4583e-03,\n                      -1.3111e-02,  2.7582e-02, -1.1040e-02, -1.5856e-02,  8.8957e-03,\n                      -2.1841e-02,  3.2805e-02,  1.2532e-02,  1.5146e-02,  1.3258e-02,\n                      -6.7615e-03,  1.9925e-02,  9.7864e-03, -3.6253e-02, -1.2236e-02,\n                      -1.3461e-02,  4.4562e-03,  2.5041e-02, -2.6462e-02, -1.6940e-02,\n                       8.7100e-03,  1.9238e-02,  4.4784e-03,  3.4245e-02,  2.0531e-02,\n                       5.2516e-03, -3.5861e-03, -1.2469e-02, -5.2432e-02,  9.6388e-03,\n                      -5.6816e-04,  6.9154e-03,  8.5357e-03, -2.2981e-02,  1.1508e-02,\n                       1.9899e-02, -1.6698e-02, -8.0961e-03, -2.2956e-02,  3.0904e-03,\n                      -3.7870e-03,  1.5946e-02, -1.2915e-02, -1.0833e-02,  1.2147e-02,\n                       1.4231e-02,  1.2813e-02, -1.9293e-03,  1.0169e-02,  2.4295e-02,\n                      -3.0872e-02,  1.1113e-02,  1.9294e-03, -3.9288e-03, -2.3505e-02,\n                       1.8764e-02,  2.5213e-02,  2.4943e-02, -5.8700e-03,  1.3171e-02,\n                      -1.0873e-02, -6.3622e-03, -1.1389e-02, -1.3333e-02, -1.0907e-02,\n                       3.4652e-03, -1.0699e-02, -7.0520e-03,  1.7228e-02, -1.6052e-02,\n                       1.1300e-02,  1.9971e-05, -2.6295e-02, -1.6014e-02, -3.7381e-03,\n                       3.9927e-03, -1.7577e-02,  1.1085e-02,  5.2897e-02, -4.0533e-03,\n                      -3.3725e-02,  1.3661e-03, -1.1513e-02, -2.3842e-02, -1.5184e-02,\n                       2.5902e-02,  1.0272e-02,  2.5413e-02,  3.3512e-02, -2.3581e-02,\n                      -2.3382e-03, -2.1988e-02, -2.3419e-03, -1.0452e-03, -3.2009e-03,\n                       1.2412e-02,  4.1544e-03,  2.6490e-02,  7.6751e-04,  6.3902e-03,\n                       2.7935e-02, -1.9132e-02, -1.8581e-02,  5.6709e-03, -4.8726e-03,\n                       1.8139e-02,  1.0187e-02, -9.2331e-03,  9.6519e-03, -2.9871e-02,\n                      -2.0533e-02,  1.0392e-02,  4.1550e-03,  2.4514e-03,  1.3863e-02,\n                       4.0471e-03,  4.7898e-02,  2.3197e-02,  1.8580e-02, -2.1985e-02,\n                      -9.0022e-03, -2.2905e-02,  1.1052e-03,  1.7456e-03, -9.1983e-03,\n                       2.3448e-03,  2.3743e-02, -2.3288e-02,  6.8589e-03,  9.5408e-03,\n                      -1.6068e-02, -3.0709e-02, -9.7736e-03,  1.1624e-02,  6.2602e-03,\n                       9.2581e-03,  2.3574e-02, -1.0938e-03,  7.8775e-03, -8.4378e-03,\n                      -2.2444e-02,  1.4696e-02, -1.3945e-02, -1.0824e-02, -2.6026e-02,\n                       8.2813e-03, -1.2789e-02, -1.7927e-02, -1.9098e-03, -2.9530e-02,\n                       2.1569e-02, -3.3837e-02,  1.4654e-02,  1.6397e-03, -2.6433e-02,\n                       1.4694e-02,  7.2873e-03, -4.4663e-02,  5.3338e-03,  7.8448e-03,\n                       1.8089e-02, -8.3196e-03,  9.1017e-03,  8.9745e-03,  1.7489e-02,\n                       1.5938e-02,  7.5342e-04,  3.6302e-02, -2.1499e-02,  3.5404e-03,\n                      -2.8467e-02,  1.4964e-02, -1.2929e-02, -2.4299e-02,  8.2310e-03,\n                       1.0306e-02, -2.4439e-02,  8.6288e-03, -3.1911e-02,  1.4273e-02,\n                       1.1631e-02,  3.3644e-02, -3.9123e-03,  1.5698e-02,  8.3408e-03,\n                      -1.6262e-02, -2.1112e-02,  2.0150e-02,  2.1594e-02,  2.2470e-02,\n                      -8.5558e-03,  8.2238e-03,  8.4670e-03, -4.4100e-03,  1.6837e-03,\n                      -3.2625e-03,  2.3982e-04,  1.1434e-02,  1.4614e-02, -2.4817e-02,\n                       4.8282e-03,  3.4655e-04,  1.5107e-03, -1.4052e-02, -1.4265e-02,\n                       9.9219e-03, -3.9925e-03, -1.8142e-02,  2.0845e-03,  4.8382e-02,\n                      -1.4085e-02,  5.3192e-03,  4.5871e-04, -3.4340e-03,  3.9627e-03,\n                       1.0486e-02,  2.6164e-02,  4.5831e-03,  1.7923e-02,  3.6957e-02,\n                      -4.8271e-03,  2.9398e-03, -1.6607e-02,  1.2179e-02, -3.3932e-03,\n                       1.8982e-03,  8.4003e-03, -2.1865e-02, -8.2961e-03, -1.9538e-02,\n                      -2.2067e-02,  3.1041e-03,  1.8884e-02, -2.1856e-02, -4.0352e-03,\n                       6.4049e-03], dtype=torch.float64)),\n             ('5.2.convs.2.1.bias',\n              tensor([-0.0014,  0.0054,  0.0250, -0.0009,  0.0015, -0.0124,  0.0169,  0.0051,\n                       0.0055, -0.0075,  0.0010, -0.0076,  0.0146, -0.0116,  0.0109,  0.0111,\n                       0.0222,  0.0064,  0.0217, -0.0040, -0.0003, -0.0030, -0.0013,  0.0080,\n                       0.0002, -0.0266,  0.0013,  0.0189,  0.0021,  0.0018, -0.0117,  0.0163,\n                      -0.0144,  0.0174,  0.0141, -0.0006,  0.0066,  0.0260,  0.0155, -0.0001,\n                       0.0041, -0.0093, -0.0032,  0.0134,  0.0152, -0.0066, -0.0137,  0.0090,\n                      -0.0059,  0.0098, -0.0062,  0.0037,  0.0164,  0.0200, -0.0149,  0.0051,\n                       0.0064,  0.0125,  0.0100,  0.0063, -0.0138,  0.0035,  0.0029,  0.0150,\n                      -0.0011, -0.0011, -0.0090,  0.0121,  0.0010, -0.0134,  0.0025,  0.0209,\n                       0.0107, -0.0084,  0.0207,  0.0160,  0.0096, -0.0145,  0.0091,  0.0079,\n                       0.0155, -0.0007,  0.0184,  0.0087,  0.0002,  0.0043,  0.0058,  0.0057,\n                       0.0122, -0.0021,  0.0014,  0.0183,  0.0212,  0.0029,  0.0022, -0.0123,\n                       0.0072,  0.0057,  0.0162, -0.0103,  0.0331, -0.0036, -0.0137, -0.0280,\n                       0.0139,  0.0064,  0.0012,  0.0099,  0.0080,  0.0026, -0.0088, -0.0054,\n                       0.0099,  0.0158,  0.0074,  0.0099,  0.0120,  0.0074,  0.0084, -0.0134,\n                       0.0113,  0.0182,  0.0042,  0.0004, -0.0081,  0.0114,  0.0075,  0.0057,\n                       0.0054,  0.0078,  0.0051,  0.0093,  0.0075,  0.0060, -0.0023, -0.0136,\n                      -0.0054,  0.0135,  0.0146,  0.0177, -0.0078,  0.0060, -0.0006,  0.0140,\n                      -0.0098, -0.0042,  0.0111, -0.0087,  0.0105,  0.0125,  0.0021,  0.0224,\n                       0.0142,  0.0162,  0.0134,  0.0183,  0.0075,  0.0156, -0.0046, -0.0165,\n                       0.0086, -0.0009, -0.0053,  0.0190,  0.0089,  0.0060, -0.0090,  0.0153,\n                       0.0144,  0.0165,  0.0093, -0.0017, -0.0003,  0.0122, -0.0158, -0.0041,\n                       0.0016,  0.0292,  0.0068,  0.0018, -0.0031,  0.0216, -0.0134, -0.0055,\n                       0.0106,  0.0068,  0.0106,  0.0126, -0.0026,  0.0025,  0.0090,  0.0063,\n                       0.0144, -0.0188,  0.0092,  0.0091, -0.0080,  0.0155,  0.0133, -0.0183,\n                       0.0082, -0.0021,  0.0140,  0.0210,  0.0007, -0.0077,  0.0173, -0.0096,\n                       0.0115,  0.0112,  0.0029,  0.0126,  0.0121,  0.0067,  0.0056,  0.0088,\n                       0.0052,  0.0141,  0.0080,  0.0006, -0.0057, -0.0053,  0.0110,  0.0018,\n                      -0.0039,  0.0056,  0.0005,  0.0040, -0.0265,  0.0008, -0.0116,  0.0067,\n                       0.0107,  0.0033,  0.0119,  0.0058,  0.0088,  0.0010,  0.0032,  0.0201,\n                      -0.0081,  0.0029,  0.0125,  0.0022,  0.0072,  0.0144,  0.0079,  0.0151,\n                      -0.0059, -0.0092,  0.0237,  0.0089,  0.0178,  0.0251,  0.0202,  0.0040],\n                     dtype=torch.float64)),\n             ('5.2.convs.2.1.running_mean',\n              tensor([-0.0862, -0.0165, -0.2398,  0.3852, -0.6019, -0.5676,  0.0825, -0.7221,\n                       0.2181, -0.3597,  0.1015,  0.0824, -0.4817, -0.3997,  0.1277, -0.3706,\n                       0.2177,  0.2849,  0.2576,  0.4792, -0.4415, -0.1918,  0.0606,  0.6394,\n                      -0.2762,  0.1784, -0.1828, -0.7421,  0.2326,  0.4814, -0.0799, -0.4709,\n                      -0.5291, -0.1194, -0.0158, -0.1229,  0.4049,  0.4543,  0.7844, -0.0387,\n                      -0.1087,  0.1492, -0.3487, -0.3085, -0.4336, -0.1643, -0.5457, -0.5845,\n                       0.3287, -0.2307,  0.2002,  0.0758,  0.0641,  0.2803, -0.1433,  0.7532,\n                      -0.3457,  0.1953, -0.0031, -0.0913,  0.0674,  0.0324, -0.5562,  0.2221,\n                      -0.9758, -0.5766, -0.2547, -0.0495, -0.0079, -0.3639,  0.2663, -0.0612,\n                       0.5695, -0.0193,  0.3017, -0.3923,  0.2664, -0.1438, -0.8519, -0.4391,\n                       0.5560,  0.0707,  0.2655,  0.6996, -0.4839, -0.3393, -0.2678,  0.2010,\n                       0.3435, -0.2256,  0.9106,  0.0826,  0.0613, -0.3814, -0.6878,  0.3369,\n                       0.2004, -0.0137,  0.6613, -0.1420,  0.3559, -0.1298,  0.1191,  0.7050,\n                      -0.3615,  0.9383, -0.2041,  0.6062, -0.5241, -0.0445, -0.1914, -0.0072,\n                       0.1048,  0.2355, -0.0203, -1.1482, -0.2945, -0.3258,  0.2933,  0.9523,\n                      -0.4485, -1.0821, -0.1384,  0.2491, -0.2982, -0.7233, -0.3215, -0.4616,\n                      -0.1417, -0.0625, -0.4790, -0.0806, -0.6347,  0.0702,  0.1821,  0.1276,\n                       0.1181,  0.1011, -0.2943, -0.9211, -0.1767,  0.0638, -0.0307,  0.4276,\n                       0.0262,  0.0987,  0.2867,  0.0029,  0.2342,  0.3344, -0.5391,  0.1652,\n                      -0.0490, -0.0376, -0.0779,  0.6314, -0.6156,  0.1035,  0.3060,  0.3423,\n                      -0.0016, -0.0583, -0.2557,  0.3799,  0.2874, -0.1679,  0.0842, -0.0640,\n                       0.0222,  0.4106,  0.4494, -0.2461, -0.2516,  0.6102, -0.0346,  0.5627,\n                      -0.1453,  0.0615, -0.3682, -0.4874, -0.0298,  0.1001, -0.5881, -0.4559,\n                       0.2214,  0.5460,  0.0181,  0.6201,  0.2594,  0.4201, -0.0685,  0.2428,\n                      -0.0697,  0.3292,  0.0267,  0.4397,  0.3055,  0.4633,  0.9841, -0.0257,\n                       0.2111,  0.4707,  0.3625, -0.0267,  0.1512, -0.5698, -0.5079,  0.0393,\n                      -0.0893, -0.9192, -0.4831,  0.0691, -0.3910,  0.1755,  0.4904,  0.2875,\n                      -0.6479,  0.3098, -0.5619,  0.6141, -0.1605, -0.1535,  0.3593, -0.4387,\n                       1.1955,  0.0958,  0.2576, -0.0976,  0.7708,  0.3244, -0.6470,  0.1516,\n                       0.2895,  0.0466,  0.1541, -0.1817,  0.2676,  0.2526,  0.6274,  0.4594,\n                       0.0349,  0.0355, -0.3388,  0.4101, -0.1183, -0.3021, -0.1553,  0.4324,\n                      -0.1234, -1.0030,  0.2239,  0.2310,  0.3218,  0.6022, -0.2103, -0.2831],\n                     dtype=torch.float64)),\n             ('5.2.convs.2.1.running_var',\n              tensor([0.3352, 0.2564, 0.2799, 0.4492, 0.5220, 0.1955, 0.2102, 0.3939, 0.1522,\n                      0.7558, 0.2717, 0.1844, 0.2933, 0.2646, 0.3506, 0.3375, 0.2702, 0.4839,\n                      0.3884, 0.2690, 0.2379, 0.4195, 0.3081, 0.5743, 0.3273, 0.2536, 0.2848,\n                      0.3815, 0.3955, 0.3020, 0.2356, 0.5191, 0.2456, 0.3065, 0.3673, 0.5255,\n                      0.1654, 0.2727, 0.3475, 0.3676, 0.3756, 0.3541, 0.0711, 0.3162, 0.2773,\n                      0.2051, 0.2966, 0.3374, 0.3404, 0.2807, 0.1750, 0.4299, 0.3584, 0.2858,\n                      0.2203, 0.3723, 0.2287, 0.3688, 0.2893, 0.2901, 0.0461, 0.3720, 0.4216,\n                      0.2195, 0.4312, 0.4617, 0.2013, 0.1958, 0.3080, 0.3465, 0.4459, 0.2609,\n                      0.2725, 0.4328, 0.3982, 0.2279, 0.3118, 0.2388, 0.3807, 0.2634, 0.4011,\n                      0.1563, 0.3628, 0.3705, 0.3523, 0.4394, 0.2084, 0.2160, 0.2658, 0.2571,\n                      0.3032, 0.1051, 0.3977, 0.3648, 0.2478, 0.3682, 0.5797, 0.1093, 0.2609,\n                      0.4779, 0.3884, 0.1941, 0.2569, 0.5157, 0.2487, 0.3688, 0.2816, 0.4108,\n                      0.3200, 0.1934, 0.1869, 0.3566, 0.3062, 0.4110, 0.3639, 0.4461, 0.3120,\n                      0.3501, 0.3184, 0.2931, 0.2159, 0.3193, 0.3587, 0.3932, 0.1747, 0.4736,\n                      0.3708, 0.2467, 0.1635, 0.3656, 0.5559, 0.2694, 0.3327, 0.3234, 0.1302,\n                      0.1681, 0.2277, 0.2226, 0.3051, 0.3185, 0.3111, 0.2419, 0.1848, 0.1595,\n                      0.1146, 0.1997, 0.2221, 0.3696, 0.2985, 0.5123, 0.2843, 0.3340, 0.1416,\n                      0.3584, 0.1410, 0.3108, 0.3438, 0.1658, 0.2806, 0.2869, 0.3761, 0.2490,\n                      0.2865, 0.2018, 0.3572, 0.4376, 0.3120, 0.1775, 0.1743, 0.3624, 0.2908,\n                      0.2586, 0.2520, 0.0805, 0.3674, 0.6431, 0.3711, 0.3285, 0.1387, 0.2215,\n                      0.4609, 0.3508, 0.2920, 0.2505, 0.2106, 0.2523, 0.2179, 0.2649, 0.3916,\n                      0.3477, 0.3985, 0.2558, 0.2979, 0.5287, 0.3345, 0.2578, 0.2555, 0.2065,\n                      0.4242, 0.2237, 0.1887, 0.1833, 0.2252, 0.3354, 0.1562, 0.3601, 0.1743,\n                      0.2100, 0.4339, 0.4113, 0.1012, 0.1653, 0.1181, 0.3122, 0.3007, 0.2600,\n                      0.3007, 0.2605, 0.2849, 0.3293, 0.1048, 0.2080, 0.1463, 0.4738, 0.5100,\n                      0.2495, 0.1632, 0.4620, 0.3586, 0.3808, 0.2265, 0.2938, 0.0881, 0.0774,\n                      0.3049, 0.1874, 0.3676, 0.3531, 0.6355, 0.3933, 0.3094, 0.0435, 0.4446,\n                      0.4810, 0.1139, 0.1779, 0.1173, 0.2729, 0.1644, 0.5448, 0.2112, 0.3089,\n                      0.2682, 0.3588, 0.1909, 0.3476], dtype=torch.float64)),\n             ('5.2.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('5.2.convpath.0.0.0.weight',\n              tensor([[[ 0.2465],\n                       [ 0.0327],\n                       [ 0.1565],\n                       ...,\n                       [ 0.0351],\n                       [ 0.2499],\n                       [ 0.0393]],\n              \n                      [[-0.1605],\n                       [-0.0112],\n                       [-0.1289],\n                       ...,\n                       [ 0.0487],\n                       [-0.1187],\n                       [-0.1153]],\n              \n                      [[ 0.0234],\n                       [ 0.0714],\n                       [ 0.0335],\n                       ...,\n                       [-0.0326],\n                       [ 0.1077],\n                       [ 0.0157]],\n              \n                      ...,\n              \n                      [[-0.0647],\n                       [ 0.1698],\n                       [-0.2075],\n                       ...,\n                       [ 0.0198],\n                       [ 0.0900],\n                       [ 0.0786]],\n              \n                      [[ 0.0538],\n                       [ 0.0904],\n                       [-0.0362],\n                       ...,\n                       [ 0.0161],\n                       [ 0.1532],\n                       [ 0.0023]],\n              \n                      [[ 0.1125],\n                       [-0.0409],\n                       [ 0.0799],\n                       ...,\n                       [-0.0316],\n                       [-0.0877],\n                       [ 0.0267]]], dtype=torch.float64)),\n             ('5.2.convpath.0.0.1.weight',\n              tensor([0.9718, 0.9777, 0.9873, 0.9560, 0.9861, 0.9529, 0.9876, 0.9585, 0.9495,\n                      0.9689, 0.9613, 0.9486, 0.9840, 0.9657, 0.9529, 0.9297, 0.9400, 0.9771,\n                      0.9702, 0.9706, 0.9701, 0.9638, 0.9673, 0.9656, 0.9542, 0.9832, 0.9519,\n                      0.9800, 0.9740, 0.9579, 0.9796, 0.9857, 0.9505, 0.9300, 0.9698, 0.9621,\n                      0.9450, 0.9521, 0.9544, 0.9788, 0.9951, 0.9470, 0.9968, 0.9734, 1.0029,\n                      0.9602, 0.9962, 0.9744, 0.9632, 0.9564, 0.9475, 0.9758, 0.9684, 0.9493,\n                      0.9586, 0.9765, 1.0156, 0.9701, 1.0021, 0.9873, 0.9622, 0.9918, 0.9635,\n                      0.9517], dtype=torch.float64)),\n             ('5.2.convpath.0.0.1.bias',\n              tensor([ 0.0128,  0.0049,  0.0139,  0.0025,  0.0016, -0.0142,  0.0261, -0.0112,\n                      -0.0076,  0.0091,  0.0041, -0.0126,  0.0117,  0.0036, -0.0037, -0.0279,\n                      -0.0085, -0.0267, -0.0282,  0.0037, -0.0136, -0.0065,  0.0166,  0.0084,\n                      -0.0028,  0.0073,  0.0134, -0.0006,  0.0160,  0.0039, -0.0076,  0.0151,\n                      -0.0118, -0.0019,  0.0151, -0.0161, -0.0051, -0.0081, -0.0138,  0.0108,\n                       0.0153, -0.0089,  0.0191,  0.0055,  0.0013, -0.0054,  0.0010, -0.0022,\n                      -0.0028, -0.0218, -0.0210, -0.0124, -0.0024, -0.0183,  0.0074, -0.0113,\n                       0.0223,  0.0022,  0.0126,  0.0226,  0.0154,  0.0154,  0.0166, -0.0041],\n                     dtype=torch.float64)),\n             ('5.2.convpath.0.0.1.running_mean',\n              tensor([ 0.1861, -0.4981,  0.1280,  0.3149,  0.5631,  0.1058, -0.5804,  0.5050,\n                       0.4690, -0.0734,  0.2646,  0.2869, -0.1322, -0.5256, -0.1596,  0.6383,\n                      -0.4537, -0.0892,  0.0048,  0.2870, -0.1865, -0.1021,  0.3619,  0.1271,\n                      -0.5318,  0.8270,  0.0630,  0.3405, -0.3889, -0.2037,  0.3884, -0.5711,\n                      -0.3243, -0.1310,  0.2976,  0.3313, -0.2495,  0.1354, -0.3669,  0.2238,\n                      -0.1816,  0.2281,  0.7505, -0.4221, -0.1864, -0.1407, -0.3311,  0.0103,\n                       0.3222,  0.2643,  0.2738,  0.3247, -0.1160, -0.2153, -0.0671, -0.8978,\n                      -0.0743,  0.3005, -0.5724,  0.2061, -0.2143,  0.5772,  0.6037, -0.4130],\n                     dtype=torch.float64)),\n             ('5.2.convpath.0.0.1.running_var',\n              tensor([0.2737, 0.2852, 0.1659, 0.1925, 0.4861, 0.3042, 0.6225, 0.1398, 0.8645,\n                      0.2841, 0.1744, 0.4147, 0.1803, 0.4634, 0.6174, 0.4701, 0.5342, 0.1912,\n                      0.2771, 0.2143, 0.3767, 0.5351, 0.4776, 0.3440, 0.4651, 1.0038, 0.6621,\n                      0.3207, 0.4459, 0.2635, 0.1684, 0.5185, 0.1838, 1.0525, 0.7845, 0.4282,\n                      0.7125, 1.3959, 0.7664, 0.3390, 0.3703, 0.4147, 0.6935, 0.5135, 0.4189,\n                      0.2424, 0.1737, 0.1830, 0.2703, 0.4573, 0.7137, 0.4623, 0.8958, 1.0623,\n                      0.3095, 0.1404, 0.3933, 0.2169, 0.2733, 0.3009, 0.3690, 0.7798, 2.1939,\n                      1.0433], dtype=torch.float64)),\n             ('5.2.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('5.2.convpath.0.1.0.weight',\n              tensor([[[ 0.0267, -0.0278, -0.0824, -0.0077,  0.0798],\n                       [-0.1499, -0.0092, -0.0124,  0.0436, -0.0924],\n                       [-0.0308,  0.0029,  0.1709,  0.0220,  0.0762],\n                       ...,\n                       [-0.0044, -0.1050,  0.0058, -0.0167, -0.0694],\n                       [-0.0729,  0.1170, -0.0244, -0.0123, -0.0150],\n                       [ 0.0932,  0.0632, -0.0174,  0.1201,  0.0390]],\n              \n                      [[ 0.0006,  0.0196,  0.0151, -0.0849, -0.1938],\n                       [-0.0505, -0.0889, -0.0670, -0.0169, -0.0062],\n                       [ 0.1040, -0.0827,  0.0639,  0.0728,  0.0010],\n                       ...,\n                       [ 0.0433, -0.0441,  0.0453,  0.0311, -0.1213],\n                       [ 0.0293,  0.0865,  0.1829,  0.1123, -0.1026],\n                       [ 0.1678,  0.0870,  0.0900,  0.0161, -0.0459]],\n              \n                      [[ 0.1008,  0.0028,  0.0360, -0.0558, -0.0558],\n                       [-0.1065, -0.0553,  0.0231, -0.0518, -0.1905],\n                       [ 0.1324, -0.1144,  0.0928, -0.0772, -0.0241],\n                       ...,\n                       [-0.0225, -0.0419, -0.1298, -0.1394,  0.0419],\n                       [ 0.1130,  0.0456,  0.0146, -0.0136, -0.0062],\n                       [-0.0142, -0.0184, -0.1355, -0.0254, -0.1185]],\n              \n                      ...,\n              \n                      [[ 0.0244,  0.0019, -0.0136, -0.0343,  0.0246],\n                       [-0.1187,  0.0454,  0.0309,  0.0833,  0.1114],\n                       [ 0.0173,  0.0710, -0.0162, -0.1391,  0.0260],\n                       ...,\n                       [-0.0933,  0.1038, -0.0115, -0.1776, -0.0114],\n                       [ 0.0270, -0.1323, -0.0570, -0.0025,  0.0352],\n                       [-0.0348, -0.0544,  0.0174,  0.1369, -0.0911]],\n              \n                      [[ 0.2121,  0.0498, -0.0729,  0.0567,  0.0127],\n                       [-0.0625,  0.0561,  0.0045,  0.0480,  0.0451],\n                       [ 0.0325, -0.0058, -0.0166, -0.0508, -0.0300],\n                       ...,\n                       [-0.0131, -0.0609, -0.0637,  0.0036,  0.0440],\n                       [-0.0642, -0.0043, -0.0678, -0.0191,  0.0035],\n                       [-0.0985,  0.1032,  0.0250,  0.0416,  0.0501]],\n              \n                      [[-0.0639, -0.0551, -0.0403, -0.0509, -0.1249],\n                       [ 0.0133, -0.1062, -0.0041,  0.0765, -0.0700],\n                       [ 0.0836, -0.0446, -0.1639, -0.0522, -0.0371],\n                       ...,\n                       [ 0.0325,  0.0946, -0.0663,  0.1416,  0.0080],\n                       [ 0.1071, -0.0153, -0.0143, -0.0866,  0.0613],\n                       [-0.0047, -0.0542,  0.1036, -0.0031, -0.0496]]], dtype=torch.float64)),\n             ('5.2.convpath.0.1.1.weight',\n              tensor([0.9452, 0.9588, 0.9792, 0.9549, 0.9559, 0.9314, 0.9493, 0.9904, 0.9600,\n                      0.9590, 0.9584, 0.9725, 0.9978, 0.9839, 0.9722, 1.0143, 0.9760, 0.9175,\n                      0.9549, 0.9702, 0.9459, 0.9395, 0.9378, 0.9889, 0.9777, 0.9716, 0.9648,\n                      0.9882, 0.9241, 1.0013, 0.9391, 1.0092, 0.9578, 0.9618, 0.9352, 0.9792,\n                      0.9429, 0.9581, 0.9732, 0.9706, 0.9443, 0.9790, 0.9635, 0.9627, 0.9195,\n                      0.9801, 0.9356, 0.9571, 0.9640, 1.0175, 0.9562, 0.9535, 0.9720, 0.9299,\n                      0.9137, 0.9616, 0.9601, 0.9708, 0.9492, 0.9554, 0.9506, 0.9405, 0.9406,\n                      0.9609], dtype=torch.float64)),\n             ('5.2.convpath.0.1.1.bias',\n              tensor([ 0.0045,  0.0047,  0.0127, -0.0244, -0.0140, -0.0245, -0.0105, -0.0141,\n                       0.0062,  0.0182, -0.0048, -0.0060,  0.0137, -0.0113, -0.0158,  0.0264,\n                      -0.0057, -0.0167,  0.0010, -0.0059, -0.0086,  0.0008, -0.0085,  0.0071,\n                      -0.0100,  0.0156,  0.0007,  0.0075,  0.0046,  0.0374, -0.0289,  0.0265,\n                      -0.0030, -0.0223, -0.0086, -0.0152, -0.0172,  0.0038, -0.0017, -0.0097,\n                       0.0075,  0.0175,  0.0128, -0.0216,  0.0014, -0.0006, -0.0029, -0.0074,\n                      -0.0117,  0.0214,  0.0064, -0.0095, -0.0108, -0.0064, -0.0001,  0.0099,\n                       0.0096,  0.0060,  0.0199, -0.0330, -0.0325, -0.0204, -0.0217,  0.0018],\n                     dtype=torch.float64)),\n             ('5.2.convpath.0.1.1.running_mean',\n              tensor([-0.5590,  0.2872, -0.4774,  0.1880,  0.0862, -0.4153,  0.4243, -0.1905,\n                      -0.3249, -0.8446, -0.1133, -0.7955, -0.0531,  0.3375,  0.7426,  0.0348,\n                      -0.2056, -0.7436, -0.7210,  0.1127, -0.5343, -1.1006,  0.0898, -0.4722,\n                      -0.0682, -0.0822, -0.3062,  0.3147, -0.0716, -0.6074, -0.2978,  0.0640,\n                       0.5326,  0.4372,  0.4151,  0.1852, -0.8952, -0.8330, -0.3593, -1.0658,\n                      -0.2528, -0.5342, -0.4132,  0.6631, -0.6332, -0.3022, -0.5100,  0.5441,\n                      -0.1287, -0.4375, -0.2796, -0.2046, -0.2930, -0.8862, -0.5406,  0.0384,\n                       0.0638,  0.8414, -0.0291, -0.2924,  0.2907, -0.0937, -0.3307, -0.0902],\n                     dtype=torch.float64)),\n             ('5.2.convpath.0.1.1.running_var',\n              tensor([0.7594, 1.2881, 0.9124, 0.5638, 0.8131, 0.6536, 0.4475, 0.3312, 0.4160,\n                      1.1729, 0.4780, 0.5346, 0.4475, 0.3942, 0.6429, 0.4068, 0.9322, 1.0151,\n                      0.6030, 0.3815, 0.8400, 1.0118, 0.5295, 0.8745, 0.5717, 0.5017, 0.5024,\n                      0.3238, 0.6847, 0.7990, 0.6565, 0.4191, 0.6770, 0.9683, 0.5887, 0.4251,\n                      0.4819, 0.6405, 1.3750, 0.8232, 0.7416, 0.6119, 0.4224, 0.9823, 0.9154,\n                      0.7862, 0.4644, 1.0391, 0.6467, 0.4700, 0.5878, 0.4639, 0.4625, 1.9194,\n                      1.3265, 0.8025, 0.4810, 1.4349, 0.3681, 0.8418, 0.7349, 1.0717, 0.3841,\n                      0.9685], dtype=torch.float64)),\n             ('5.2.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('5.2.convpath.0.2.0.weight',\n              tensor([[[ 0.0677],\n                       [-0.0901],\n                       [ 0.1860],\n                       ...,\n                       [ 0.1461],\n                       [-0.0717],\n                       [-0.2872]],\n              \n                      [[ 0.0078],\n                       [-0.0172],\n                       [-0.0999],\n                       ...,\n                       [-0.2508],\n                       [-0.1696],\n                       [ 0.1343]],\n              \n                      [[ 0.0590],\n                       [ 0.0999],\n                       [-0.1416],\n                       ...,\n                       [ 0.2324],\n                       [-0.2262],\n                       [-0.2073]],\n              \n                      ...,\n              \n                      [[-0.0620],\n                       [-0.0539],\n                       [ 0.2210],\n                       ...,\n                       [ 0.0141],\n                       [ 0.0642],\n                       [-0.0649]],\n              \n                      [[-0.0454],\n                       [-0.1227],\n                       [-0.0536],\n                       ...,\n                       [-0.0058],\n                       [-0.0805],\n                       [-0.0226]],\n              \n                      [[-0.0588],\n                       [ 0.1041],\n                       [ 0.0179],\n                       ...,\n                       [ 0.0193],\n                       [ 0.0241],\n                       [-0.2101]]], dtype=torch.float64)),\n             ('5.2.convpath.0.2.1.weight',\n              tensor([-4.6090e-03,  4.4520e-02, -3.5884e-02, -5.1809e-03, -1.1737e-02,\n                       1.9843e-03,  2.5209e-03,  2.0795e-02, -1.6808e-02,  2.8201e-02,\n                       1.2781e-02,  4.1221e-03,  1.1184e-02,  1.8085e-02,  4.1422e-02,\n                       2.3324e-02, -3.2433e-02,  7.9463e-03, -3.4576e-02, -7.4583e-03,\n                      -1.3111e-02,  2.7582e-02, -1.1040e-02, -1.5856e-02,  8.8957e-03,\n                      -2.1841e-02,  3.2805e-02,  1.2532e-02,  1.5146e-02,  1.3258e-02,\n                      -6.7615e-03,  1.9925e-02,  9.7864e-03, -3.6253e-02, -1.2236e-02,\n                      -1.3461e-02,  4.4562e-03,  2.5041e-02, -2.6462e-02, -1.6940e-02,\n                       8.7100e-03,  1.9238e-02,  4.4784e-03,  3.4245e-02,  2.0531e-02,\n                       5.2516e-03, -3.5861e-03, -1.2469e-02, -5.2432e-02,  9.6388e-03,\n                      -5.6816e-04,  6.9154e-03,  8.5357e-03, -2.2981e-02,  1.1508e-02,\n                       1.9899e-02, -1.6698e-02, -8.0961e-03, -2.2956e-02,  3.0904e-03,\n                      -3.7870e-03,  1.5946e-02, -1.2915e-02, -1.0833e-02,  1.2147e-02,\n                       1.4231e-02,  1.2813e-02, -1.9293e-03,  1.0169e-02,  2.4295e-02,\n                      -3.0872e-02,  1.1113e-02,  1.9294e-03, -3.9288e-03, -2.3505e-02,\n                       1.8764e-02,  2.5213e-02,  2.4943e-02, -5.8700e-03,  1.3171e-02,\n                      -1.0873e-02, -6.3622e-03, -1.1389e-02, -1.3333e-02, -1.0907e-02,\n                       3.4652e-03, -1.0699e-02, -7.0520e-03,  1.7228e-02, -1.6052e-02,\n                       1.1300e-02,  1.9971e-05, -2.6295e-02, -1.6014e-02, -3.7381e-03,\n                       3.9927e-03, -1.7577e-02,  1.1085e-02,  5.2897e-02, -4.0533e-03,\n                      -3.3725e-02,  1.3661e-03, -1.1513e-02, -2.3842e-02, -1.5184e-02,\n                       2.5902e-02,  1.0272e-02,  2.5413e-02,  3.3512e-02, -2.3581e-02,\n                      -2.3382e-03, -2.1988e-02, -2.3419e-03, -1.0452e-03, -3.2009e-03,\n                       1.2412e-02,  4.1544e-03,  2.6490e-02,  7.6751e-04,  6.3902e-03,\n                       2.7935e-02, -1.9132e-02, -1.8581e-02,  5.6709e-03, -4.8726e-03,\n                       1.8139e-02,  1.0187e-02, -9.2331e-03,  9.6519e-03, -2.9871e-02,\n                      -2.0533e-02,  1.0392e-02,  4.1550e-03,  2.4514e-03,  1.3863e-02,\n                       4.0471e-03,  4.7898e-02,  2.3197e-02,  1.8580e-02, -2.1985e-02,\n                      -9.0022e-03, -2.2905e-02,  1.1052e-03,  1.7456e-03, -9.1983e-03,\n                       2.3448e-03,  2.3743e-02, -2.3288e-02,  6.8589e-03,  9.5408e-03,\n                      -1.6068e-02, -3.0709e-02, -9.7736e-03,  1.1624e-02,  6.2602e-03,\n                       9.2581e-03,  2.3574e-02, -1.0938e-03,  7.8775e-03, -8.4378e-03,\n                      -2.2444e-02,  1.4696e-02, -1.3945e-02, -1.0824e-02, -2.6026e-02,\n                       8.2813e-03, -1.2789e-02, -1.7927e-02, -1.9098e-03, -2.9530e-02,\n                       2.1569e-02, -3.3837e-02,  1.4654e-02,  1.6397e-03, -2.6433e-02,\n                       1.4694e-02,  7.2873e-03, -4.4663e-02,  5.3338e-03,  7.8448e-03,\n                       1.8089e-02, -8.3196e-03,  9.1017e-03,  8.9745e-03,  1.7489e-02,\n                       1.5938e-02,  7.5342e-04,  3.6302e-02, -2.1499e-02,  3.5404e-03,\n                      -2.8467e-02,  1.4964e-02, -1.2929e-02, -2.4299e-02,  8.2310e-03,\n                       1.0306e-02, -2.4439e-02,  8.6288e-03, -3.1911e-02,  1.4273e-02,\n                       1.1631e-02,  3.3644e-02, -3.9123e-03,  1.5698e-02,  8.3408e-03,\n                      -1.6262e-02, -2.1112e-02,  2.0150e-02,  2.1594e-02,  2.2470e-02,\n                      -8.5558e-03,  8.2238e-03,  8.4670e-03, -4.4100e-03,  1.6837e-03,\n                      -3.2625e-03,  2.3982e-04,  1.1434e-02,  1.4614e-02, -2.4817e-02,\n                       4.8282e-03,  3.4655e-04,  1.5107e-03, -1.4052e-02, -1.4265e-02,\n                       9.9219e-03, -3.9925e-03, -1.8142e-02,  2.0845e-03,  4.8382e-02,\n                      -1.4085e-02,  5.3192e-03,  4.5871e-04, -3.4340e-03,  3.9627e-03,\n                       1.0486e-02,  2.6164e-02,  4.5831e-03,  1.7923e-02,  3.6957e-02,\n                      -4.8271e-03,  2.9398e-03, -1.6607e-02,  1.2179e-02, -3.3932e-03,\n                       1.8982e-03,  8.4003e-03, -2.1865e-02, -8.2961e-03, -1.9538e-02,\n                      -2.2067e-02,  3.1041e-03,  1.8884e-02, -2.1856e-02, -4.0352e-03,\n                       6.4049e-03], dtype=torch.float64)),\n             ('5.2.convpath.0.2.1.bias',\n              tensor([-0.0014,  0.0054,  0.0250, -0.0009,  0.0015, -0.0124,  0.0169,  0.0051,\n                       0.0055, -0.0075,  0.0010, -0.0076,  0.0146, -0.0116,  0.0109,  0.0111,\n                       0.0222,  0.0064,  0.0217, -0.0040, -0.0003, -0.0030, -0.0013,  0.0080,\n                       0.0002, -0.0266,  0.0013,  0.0189,  0.0021,  0.0018, -0.0117,  0.0163,\n                      -0.0144,  0.0174,  0.0141, -0.0006,  0.0066,  0.0260,  0.0155, -0.0001,\n                       0.0041, -0.0093, -0.0032,  0.0134,  0.0152, -0.0066, -0.0137,  0.0090,\n                      -0.0059,  0.0098, -0.0062,  0.0037,  0.0164,  0.0200, -0.0149,  0.0051,\n                       0.0064,  0.0125,  0.0100,  0.0063, -0.0138,  0.0035,  0.0029,  0.0150,\n                      -0.0011, -0.0011, -0.0090,  0.0121,  0.0010, -0.0134,  0.0025,  0.0209,\n                       0.0107, -0.0084,  0.0207,  0.0160,  0.0096, -0.0145,  0.0091,  0.0079,\n                       0.0155, -0.0007,  0.0184,  0.0087,  0.0002,  0.0043,  0.0058,  0.0057,\n                       0.0122, -0.0021,  0.0014,  0.0183,  0.0212,  0.0029,  0.0022, -0.0123,\n                       0.0072,  0.0057,  0.0162, -0.0103,  0.0331, -0.0036, -0.0137, -0.0280,\n                       0.0139,  0.0064,  0.0012,  0.0099,  0.0080,  0.0026, -0.0088, -0.0054,\n                       0.0099,  0.0158,  0.0074,  0.0099,  0.0120,  0.0074,  0.0084, -0.0134,\n                       0.0113,  0.0182,  0.0042,  0.0004, -0.0081,  0.0114,  0.0075,  0.0057,\n                       0.0054,  0.0078,  0.0051,  0.0093,  0.0075,  0.0060, -0.0023, -0.0136,\n                      -0.0054,  0.0135,  0.0146,  0.0177, -0.0078,  0.0060, -0.0006,  0.0140,\n                      -0.0098, -0.0042,  0.0111, -0.0087,  0.0105,  0.0125,  0.0021,  0.0224,\n                       0.0142,  0.0162,  0.0134,  0.0183,  0.0075,  0.0156, -0.0046, -0.0165,\n                       0.0086, -0.0009, -0.0053,  0.0190,  0.0089,  0.0060, -0.0090,  0.0153,\n                       0.0144,  0.0165,  0.0093, -0.0017, -0.0003,  0.0122, -0.0158, -0.0041,\n                       0.0016,  0.0292,  0.0068,  0.0018, -0.0031,  0.0216, -0.0134, -0.0055,\n                       0.0106,  0.0068,  0.0106,  0.0126, -0.0026,  0.0025,  0.0090,  0.0063,\n                       0.0144, -0.0188,  0.0092,  0.0091, -0.0080,  0.0155,  0.0133, -0.0183,\n                       0.0082, -0.0021,  0.0140,  0.0210,  0.0007, -0.0077,  0.0173, -0.0096,\n                       0.0115,  0.0112,  0.0029,  0.0126,  0.0121,  0.0067,  0.0056,  0.0088,\n                       0.0052,  0.0141,  0.0080,  0.0006, -0.0057, -0.0053,  0.0110,  0.0018,\n                      -0.0039,  0.0056,  0.0005,  0.0040, -0.0265,  0.0008, -0.0116,  0.0067,\n                       0.0107,  0.0033,  0.0119,  0.0058,  0.0088,  0.0010,  0.0032,  0.0201,\n                      -0.0081,  0.0029,  0.0125,  0.0022,  0.0072,  0.0144,  0.0079,  0.0151,\n                      -0.0059, -0.0092,  0.0237,  0.0089,  0.0178,  0.0251,  0.0202,  0.0040],\n                     dtype=torch.float64)),\n             ('5.2.convpath.0.2.1.running_mean',\n              tensor([-0.0862, -0.0165, -0.2398,  0.3852, -0.6019, -0.5676,  0.0825, -0.7221,\n                       0.2181, -0.3597,  0.1015,  0.0824, -0.4817, -0.3997,  0.1277, -0.3706,\n                       0.2177,  0.2849,  0.2576,  0.4792, -0.4415, -0.1918,  0.0606,  0.6394,\n                      -0.2762,  0.1784, -0.1828, -0.7421,  0.2326,  0.4814, -0.0799, -0.4709,\n                      -0.5291, -0.1194, -0.0158, -0.1229,  0.4049,  0.4543,  0.7844, -0.0387,\n                      -0.1087,  0.1492, -0.3487, -0.3085, -0.4336, -0.1643, -0.5457, -0.5845,\n                       0.3287, -0.2307,  0.2002,  0.0758,  0.0641,  0.2803, -0.1433,  0.7532,\n                      -0.3457,  0.1953, -0.0031, -0.0913,  0.0674,  0.0324, -0.5562,  0.2221,\n                      -0.9758, -0.5766, -0.2547, -0.0495, -0.0079, -0.3639,  0.2663, -0.0612,\n                       0.5695, -0.0193,  0.3017, -0.3923,  0.2664, -0.1438, -0.8519, -0.4391,\n                       0.5560,  0.0707,  0.2655,  0.6996, -0.4839, -0.3393, -0.2678,  0.2010,\n                       0.3435, -0.2256,  0.9106,  0.0826,  0.0613, -0.3814, -0.6878,  0.3369,\n                       0.2004, -0.0137,  0.6613, -0.1420,  0.3559, -0.1298,  0.1191,  0.7050,\n                      -0.3615,  0.9383, -0.2041,  0.6062, -0.5241, -0.0445, -0.1914, -0.0072,\n                       0.1048,  0.2355, -0.0203, -1.1482, -0.2945, -0.3258,  0.2933,  0.9523,\n                      -0.4485, -1.0821, -0.1384,  0.2491, -0.2982, -0.7233, -0.3215, -0.4616,\n                      -0.1417, -0.0625, -0.4790, -0.0806, -0.6347,  0.0702,  0.1821,  0.1276,\n                       0.1181,  0.1011, -0.2943, -0.9211, -0.1767,  0.0638, -0.0307,  0.4276,\n                       0.0262,  0.0987,  0.2867,  0.0029,  0.2342,  0.3344, -0.5391,  0.1652,\n                      -0.0490, -0.0376, -0.0779,  0.6314, -0.6156,  0.1035,  0.3060,  0.3423,\n                      -0.0016, -0.0583, -0.2557,  0.3799,  0.2874, -0.1679,  0.0842, -0.0640,\n                       0.0222,  0.4106,  0.4494, -0.2461, -0.2516,  0.6102, -0.0346,  0.5627,\n                      -0.1453,  0.0615, -0.3682, -0.4874, -0.0298,  0.1001, -0.5881, -0.4559,\n                       0.2214,  0.5460,  0.0181,  0.6201,  0.2594,  0.4201, -0.0685,  0.2428,\n                      -0.0697,  0.3292,  0.0267,  0.4397,  0.3055,  0.4633,  0.9841, -0.0257,\n                       0.2111,  0.4707,  0.3625, -0.0267,  0.1512, -0.5698, -0.5079,  0.0393,\n                      -0.0893, -0.9192, -0.4831,  0.0691, -0.3910,  0.1755,  0.4904,  0.2875,\n                      -0.6479,  0.3098, -0.5619,  0.6141, -0.1605, -0.1535,  0.3593, -0.4387,\n                       1.1955,  0.0958,  0.2576, -0.0976,  0.7708,  0.3244, -0.6470,  0.1516,\n                       0.2895,  0.0466,  0.1541, -0.1817,  0.2676,  0.2526,  0.6274,  0.4594,\n                       0.0349,  0.0355, -0.3388,  0.4101, -0.1183, -0.3021, -0.1553,  0.4324,\n                      -0.1234, -1.0030,  0.2239,  0.2310,  0.3218,  0.6022, -0.2103, -0.2831],\n                     dtype=torch.float64)),\n             ('5.2.convpath.0.2.1.running_var',\n              tensor([0.3352, 0.2564, 0.2799, 0.4492, 0.5220, 0.1955, 0.2102, 0.3939, 0.1522,\n                      0.7558, 0.2717, 0.1844, 0.2933, 0.2646, 0.3506, 0.3375, 0.2702, 0.4839,\n                      0.3884, 0.2690, 0.2379, 0.4195, 0.3081, 0.5743, 0.3273, 0.2536, 0.2848,\n                      0.3815, 0.3955, 0.3020, 0.2356, 0.5191, 0.2456, 0.3065, 0.3673, 0.5255,\n                      0.1654, 0.2727, 0.3475, 0.3676, 0.3756, 0.3541, 0.0711, 0.3162, 0.2773,\n                      0.2051, 0.2966, 0.3374, 0.3404, 0.2807, 0.1750, 0.4299, 0.3584, 0.2858,\n                      0.2203, 0.3723, 0.2287, 0.3688, 0.2893, 0.2901, 0.0461, 0.3720, 0.4216,\n                      0.2195, 0.4312, 0.4617, 0.2013, 0.1958, 0.3080, 0.3465, 0.4459, 0.2609,\n                      0.2725, 0.4328, 0.3982, 0.2279, 0.3118, 0.2388, 0.3807, 0.2634, 0.4011,\n                      0.1563, 0.3628, 0.3705, 0.3523, 0.4394, 0.2084, 0.2160, 0.2658, 0.2571,\n                      0.3032, 0.1051, 0.3977, 0.3648, 0.2478, 0.3682, 0.5797, 0.1093, 0.2609,\n                      0.4779, 0.3884, 0.1941, 0.2569, 0.5157, 0.2487, 0.3688, 0.2816, 0.4108,\n                      0.3200, 0.1934, 0.1869, 0.3566, 0.3062, 0.4110, 0.3639, 0.4461, 0.3120,\n                      0.3501, 0.3184, 0.2931, 0.2159, 0.3193, 0.3587, 0.3932, 0.1747, 0.4736,\n                      0.3708, 0.2467, 0.1635, 0.3656, 0.5559, 0.2694, 0.3327, 0.3234, 0.1302,\n                      0.1681, 0.2277, 0.2226, 0.3051, 0.3185, 0.3111, 0.2419, 0.1848, 0.1595,\n                      0.1146, 0.1997, 0.2221, 0.3696, 0.2985, 0.5123, 0.2843, 0.3340, 0.1416,\n                      0.3584, 0.1410, 0.3108, 0.3438, 0.1658, 0.2806, 0.2869, 0.3761, 0.2490,\n                      0.2865, 0.2018, 0.3572, 0.4376, 0.3120, 0.1775, 0.1743, 0.3624, 0.2908,\n                      0.2586, 0.2520, 0.0805, 0.3674, 0.6431, 0.3711, 0.3285, 0.1387, 0.2215,\n                      0.4609, 0.3508, 0.2920, 0.2505, 0.2106, 0.2523, 0.2179, 0.2649, 0.3916,\n                      0.3477, 0.3985, 0.2558, 0.2979, 0.5287, 0.3345, 0.2578, 0.2555, 0.2065,\n                      0.4242, 0.2237, 0.1887, 0.1833, 0.2252, 0.3354, 0.1562, 0.3601, 0.1743,\n                      0.2100, 0.4339, 0.4113, 0.1012, 0.1653, 0.1181, 0.3122, 0.3007, 0.2600,\n                      0.3007, 0.2605, 0.2849, 0.3293, 0.1048, 0.2080, 0.1463, 0.4738, 0.5100,\n                      0.2495, 0.1632, 0.4620, 0.3586, 0.3808, 0.2265, 0.2938, 0.0881, 0.0774,\n                      0.3049, 0.1874, 0.3676, 0.3531, 0.6355, 0.3933, 0.3094, 0.0435, 0.4446,\n                      0.4810, 0.1139, 0.1779, 0.1173, 0.2729, 0.1644, 0.5448, 0.2112, 0.3089,\n                      0.2682, 0.3588, 0.1909, 0.3476], dtype=torch.float64)),\n             ('5.2.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('5.3.convs.0.0.weight',\n              tensor([[[-0.0730],\n                       [-0.1134],\n                       [ 0.1650],\n                       ...,\n                       [ 0.0808],\n                       [-0.0915],\n                       [ 0.0239]],\n              \n                      [[-0.0908],\n                       [-0.0915],\n                       [-0.0872],\n                       ...,\n                       [ 0.0140],\n                       [ 0.0101],\n                       [ 0.0539]],\n              \n                      [[-0.0190],\n                       [-0.0615],\n                       [ 0.1286],\n                       ...,\n                       [-0.0102],\n                       [-0.0692],\n                       [ 0.0099]],\n              \n                      ...,\n              \n                      [[ 0.0350],\n                       [ 0.0626],\n                       [-0.1071],\n                       ...,\n                       [-0.1013],\n                       [ 0.0263],\n                       [-0.0304]],\n              \n                      [[-0.0144],\n                       [-0.1935],\n                       [-0.0385],\n                       ...,\n                       [-0.0348],\n                       [-0.1080],\n                       [ 0.0330]],\n              \n                      [[ 0.1550],\n                       [-0.1085],\n                       [-0.0084],\n                       ...,\n                       [-0.1381],\n                       [-0.0245],\n                       [ 0.0683]]], dtype=torch.float64)),\n             ('5.3.convs.0.1.weight',\n              tensor([0.9786, 0.9778, 0.9706, 0.9658, 0.9860, 0.9728, 0.9696, 0.9776, 0.9609,\n                      0.9570, 0.9839, 0.9777, 0.9565, 0.9701, 0.9825, 0.9955, 0.9867, 0.9784,\n                      0.9769, 0.9655, 0.9730, 0.9802, 0.9823, 0.9790, 0.9625, 0.9574, 0.9744,\n                      0.9727, 0.9826, 0.9659, 0.9453, 0.9460, 0.9874, 0.9575, 0.9561, 0.9725,\n                      0.9797, 0.9578, 0.9603, 0.9791, 0.9730, 0.9765, 0.9596, 0.9431, 1.0121,\n                      0.9944, 0.9750, 0.9373, 0.9765, 0.9911, 1.0031, 0.9725, 0.9585, 0.9917,\n                      0.9760, 0.9570, 0.9672, 0.9758, 0.9863, 0.9559, 0.9800, 0.9864, 0.9680,\n                      0.9963], dtype=torch.float64)),\n             ('5.3.convs.0.1.bias',\n              tensor([ 0.0014,  0.0052,  0.0156,  0.0109,  0.0148, -0.0193, -0.0044, -0.0066,\n                      -0.0218, -0.0074,  0.0120,  0.0113, -0.0019, -0.0064,  0.0021, -0.0021,\n                       0.0247,  0.0051,  0.0031, -0.0101,  0.0076,  0.0116,  0.0002, -0.0006,\n                       0.0092, -0.0005, -0.0013,  0.0139,  0.0284,  0.0044, -0.0171, -0.0156,\n                       0.0138, -0.0175, -0.0258, -0.0140, -0.0058, -0.0222, -0.0063,  0.0138,\n                      -0.0037, -0.0070,  0.0065, -0.0210,  0.0118,  0.0173, -0.0218, -0.0101,\n                      -0.0074,  0.0121,  0.0318, -0.0030, -0.0146,  0.0008,  0.0159,  0.0116,\n                      -0.0081,  0.0007,  0.0248, -0.0116,  0.0210,  0.0048,  0.0073,  0.0247],\n                     dtype=torch.float64)),\n             ('5.3.convs.0.1.running_mean',\n              tensor([-0.6049, -0.4152,  0.0880,  0.6016, -0.2947,  0.0682,  0.3947,  0.3074,\n                       0.3306,  0.2386,  0.4756,  0.1629, -0.2642,  0.9581, -0.0676, -0.4790,\n                      -0.5742, -0.0540,  0.0568,  0.9929, -0.5000,  0.6728,  0.1925, -0.0654,\n                      -0.0216, -0.4671, -0.0174,  0.2646, -0.2849,  0.6013, -0.0210, -0.5748,\n                      -0.4132,  0.3725,  0.2332, -0.0161, -0.0770,  0.5225,  0.9889,  0.0181,\n                       0.1388,  0.3304,  0.1180,  0.8317,  0.4472, -0.1146,  0.2205, -0.7231,\n                      -0.2235, -0.8052, -0.4622,  0.3173, -0.2066, -0.7538,  0.2552,  0.3281,\n                       0.6575,  0.6886, -0.4073, -0.0605, -0.1072, -0.4732, -0.2691, -0.2825],\n                     dtype=torch.float64)),\n             ('5.3.convs.0.1.running_var',\n              tensor([0.1663, 0.2801, 0.3877, 0.7420, 0.2253, 0.2560, 0.4599, 0.3733, 0.2903,\n                      0.7494, 0.4084, 0.2755, 0.3988, 1.4678, 0.6109, 0.2988, 0.6372, 0.8398,\n                      0.2040, 1.4996, 0.9881, 0.2902, 0.4727, 0.6883, 0.4019, 0.4009, 0.2320,\n                      0.1327, 0.4879, 0.6595, 0.3513, 1.2131, 0.1970, 0.3595, 0.3974, 0.2318,\n                      0.2626, 1.2334, 0.9566, 0.2209, 0.6718, 0.7316, 0.3475, 1.1943, 0.1442,\n                      0.2418, 0.1528, 1.7944, 0.2095, 0.2959, 0.3535, 0.4009, 0.5704, 0.2363,\n                      0.2296, 0.3013, 1.4100, 0.9587, 0.3548, 0.2982, 0.6653, 0.1702, 0.2322,\n                      0.7279], dtype=torch.float64)),\n             ('5.3.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('5.3.convs.1.0.weight',\n              tensor([[[-0.0529,  0.0870, -0.0250,  0.0546,  0.0074],\n                       [ 0.0331, -0.0124, -0.0554, -0.0390,  0.0782],\n                       [ 0.0540, -0.0181, -0.0016,  0.0137,  0.0350],\n                       ...,\n                       [ 0.0212,  0.0664,  0.0009, -0.1306,  0.1132],\n                       [-0.0960,  0.0457, -0.0212,  0.0492, -0.0319],\n                       [ 0.0530,  0.0014, -0.0676,  0.0735,  0.0363]],\n              \n                      [[ 0.0250, -0.0386,  0.0232, -0.0669,  0.0871],\n                       [-0.0066,  0.0420,  0.0360, -0.0262,  0.1177],\n                       [ 0.1677,  0.0365, -0.0677,  0.0751, -0.0389],\n                       ...,\n                       [ 0.0650,  0.1577, -0.1000, -0.1001, -0.0397],\n                       [ 0.0212, -0.0353,  0.0015,  0.0260,  0.0970],\n                       [-0.0315, -0.0904, -0.0573,  0.0627, -0.0076]],\n              \n                      [[ 0.0528,  0.0315,  0.0011,  0.0820, -0.0103],\n                       [-0.0764, -0.0166, -0.0047, -0.0048, -0.0334],\n                       [-0.0849,  0.0603, -0.0143,  0.0054,  0.1008],\n                       ...,\n                       [-0.0322, -0.0064,  0.0578,  0.0246, -0.0345],\n                       [-0.0444, -0.0146, -0.1001, -0.0759, -0.0043],\n                       [-0.0089,  0.0202, -0.0429, -0.0517,  0.0236]],\n              \n                      ...,\n              \n                      [[-0.0516, -0.1299, -0.1958, -0.0887,  0.0070],\n                       [-0.0754,  0.0215, -0.0892, -0.0163,  0.0714],\n                       [-0.0536, -0.0501, -0.0211, -0.0419, -0.1046],\n                       ...,\n                       [-0.0214,  0.0345,  0.0897, -0.0015, -0.0816],\n                       [ 0.0269,  0.0373, -0.0724,  0.1050, -0.0127],\n                       [ 0.0527, -0.0594,  0.0263,  0.0104,  0.0602]],\n              \n                      [[-0.0745,  0.1269,  0.0214, -0.0510,  0.0071],\n                       [-0.0358,  0.0628, -0.1278, -0.0351, -0.0964],\n                       [ 0.0746,  0.0211, -0.0669, -0.0011, -0.1323],\n                       ...,\n                       [-0.1402,  0.0739, -0.0155, -0.0041,  0.1165],\n                       [ 0.0289, -0.0490,  0.0319, -0.0757, -0.1412],\n                       [-0.0327,  0.0836,  0.0412,  0.0508,  0.1160]],\n              \n                      [[-0.0714,  0.0189,  0.0191, -0.0513, -0.0394],\n                       [ 0.0993,  0.0954, -0.0149,  0.0413, -0.0994],\n                       [-0.0009,  0.0225,  0.0552, -0.0738,  0.0180],\n                       ...,\n                       [ 0.0775, -0.0696, -0.0689,  0.0148,  0.0564],\n                       [ 0.1100, -0.1010,  0.0209, -0.0200,  0.0553],\n                       [ 0.0388,  0.0306, -0.0277, -0.0953, -0.1510]]], dtype=torch.float64)),\n             ('5.3.convs.1.1.weight',\n              tensor([0.9712, 0.9686, 0.9774, 0.9857, 0.9447, 0.9638, 0.9759, 0.9681, 0.9739,\n                      0.9489, 0.9634, 0.9911, 0.9767, 0.9604, 0.9125, 0.9784, 0.9857, 1.0201,\n                      0.9657, 0.9684, 0.9673, 0.9682, 0.9592, 0.9708, 0.9859, 0.9612, 0.9841,\n                      0.9182, 0.9323, 0.9360, 0.9872, 0.9521, 0.9134, 0.9420, 0.9441, 0.9799,\n                      0.9475, 0.9789, 0.9809, 0.9924, 0.9897, 0.9663, 0.9367, 0.9943, 0.9568,\n                      0.9608, 0.9547, 0.9970, 0.9461, 0.9758, 0.9220, 0.9497, 0.9568, 0.9759,\n                      0.9547, 0.9492, 0.9339, 0.9457, 0.9599, 0.9555, 0.9553, 0.9648, 0.9713,\n                      0.9562], dtype=torch.float64)),\n             ('5.3.convs.1.1.bias',\n              tensor([-2.1816e-02, -1.7777e-02,  2.5409e-02,  1.4187e-02, -1.8367e-02,\n                      -5.3592e-03, -1.0645e-02, -1.9208e-02,  5.8650e-03, -2.2752e-02,\n                      -1.4683e-02, -1.4344e-02,  9.0271e-03,  5.9783e-04, -6.5306e-03,\n                      -3.2494e-03, -9.8720e-03,  2.1030e-02, -1.5311e-02, -5.8999e-03,\n                      -1.0087e-02,  8.8320e-03, -6.2903e-03, -1.7931e-02, -1.4199e-02,\n                      -2.7993e-02, -5.7738e-03, -4.4619e-03, -1.9864e-02, -4.2919e-03,\n                       1.1007e-02, -2.7539e-02, -2.6813e-02, -3.3304e-03,  1.5825e-02,\n                       1.1213e-02, -9.6899e-03, -5.4661e-03,  4.2204e-03,  3.5011e-05,\n                      -1.5457e-02, -1.1615e-02, -1.3990e-02,  9.1949e-03, -2.7876e-03,\n                      -1.7079e-02,  1.5275e-02,  4.8054e-03, -5.0017e-04, -6.6978e-05,\n                      -2.9418e-02, -8.3716e-03, -5.7128e-04, -1.4547e-02,  9.0625e-04,\n                      -1.5546e-02, -2.1604e-02, -1.0430e-02, -1.1210e-02, -1.6800e-02,\n                      -1.1154e-02,  7.4977e-03,  1.6724e-02, -1.2630e-02],\n                     dtype=torch.float64)),\n             ('5.3.convs.1.1.running_mean',\n              tensor([ 0.2794,  0.1898, -0.0707, -0.0750, -0.1517,  0.0831, -0.5452, -0.6698,\n                      -0.4186,  0.4852, -0.1245, -0.2697,  0.0081, -0.1627, -0.0335,  0.5354,\n                      -0.1779, -0.0325,  0.5645, -0.4776,  0.6304, -0.0719,  0.0135,  0.1194,\n                       0.4775,  0.2816, -0.3085, -0.2595,  0.0542, -0.3208, -0.1225, -0.4261,\n                      -0.8632, -0.3544, -0.6738,  0.4403, -0.6101, -0.1985, -0.3912, -0.1022,\n                      -0.2301, -0.4370, -0.1214, -0.4250, -0.0650,  0.4371, -0.2645, -0.3008,\n                       0.5081, -0.2417, -0.3805, -0.6219, -0.2269, -0.5891, -0.5998, -0.6586,\n                      -0.0526,  0.4790, -0.4874,  0.1390,  0.8981, -0.1165, -0.1777, -0.2286],\n                     dtype=torch.float64)),\n             ('5.3.convs.1.1.running_var',\n              tensor([1.0093, 1.0319, 0.3667, 0.3792, 0.8875, 0.3362, 0.5115, 0.6183, 1.1835,\n                      0.4314, 0.3526, 0.5524, 0.6288, 0.6846, 1.2261, 0.4111, 0.5362, 0.4094,\n                      0.7930, 0.6103, 0.5558, 0.5414, 0.3986, 0.6676, 0.5148, 0.9956, 0.3751,\n                      1.1489, 1.6513, 1.0437, 0.4789, 0.4533, 1.5465, 0.7035, 0.9554, 0.5463,\n                      0.9240, 0.5755, 0.3416, 0.5066, 0.4178, 1.0751, 0.7850, 0.6239, 0.3439,\n                      0.6473, 0.5669, 0.6776, 0.5674, 0.3418, 0.7720, 0.5270, 0.7832, 0.5416,\n                      0.5178, 0.5546, 0.8007, 0.7954, 0.3757, 0.6893, 1.0762, 0.5076, 0.7073,\n                      0.8935], dtype=torch.float64)),\n             ('5.3.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('5.3.convs.2.0.weight',\n              tensor([[[ 0.0703],\n                       [-0.0006],\n                       [-0.0581],\n                       ...,\n                       [ 0.0878],\n                       [-0.0307],\n                       [ 0.0071]],\n              \n                      [[ 0.0391],\n                       [-0.0487],\n                       [-0.0311],\n                       ...,\n                       [ 0.0177],\n                       [-0.0800],\n                       [ 0.1407]],\n              \n                      [[ 0.0334],\n                       [ 0.0831],\n                       [-0.2349],\n                       ...,\n                       [-0.0827],\n                       [ 0.0171],\n                       [-0.2185]],\n              \n                      ...,\n              \n                      [[ 0.4092],\n                       [-0.0551],\n                       [ 0.0535],\n                       ...,\n                       [ 0.0626],\n                       [ 0.1836],\n                       [-0.1450]],\n              \n                      [[-0.0229],\n                       [ 0.0534],\n                       [-0.0155],\n                       ...,\n                       [-0.0672],\n                       [-0.3458],\n                       [-0.1254]],\n              \n                      [[ 0.1801],\n                       [-0.1595],\n                       [ 0.0825],\n                       ...,\n                       [-0.1389],\n                       [ 0.0803],\n                       [-0.1397]]], dtype=torch.float64)),\n             ('5.3.convs.2.1.weight',\n              tensor([-0.0043, -0.0048, -0.0076, -0.0096, -0.0024,  0.0078, -0.0054, -0.0018,\n                      -0.0161,  0.0094, -0.0039, -0.0009, -0.0094, -0.0468, -0.0409, -0.0169,\n                       0.0248,  0.0311,  0.0090, -0.0047,  0.0232,  0.0339,  0.0068, -0.0022,\n                      -0.0076, -0.0106,  0.0022,  0.0011,  0.0164,  0.0198, -0.0260, -0.0493,\n                      -0.0110, -0.0189, -0.0140, -0.0234, -0.0121,  0.0148, -0.0159,  0.0157,\n                       0.0085,  0.0028,  0.0086, -0.0130,  0.0172, -0.0077,  0.0243, -0.0116,\n                       0.0141, -0.0050, -0.0176, -0.0185, -0.0228, -0.0301, -0.0116,  0.0011,\n                      -0.0190, -0.0318, -0.0134, -0.0107,  0.0160, -0.0211,  0.0111, -0.0080,\n                      -0.0082,  0.0165,  0.0062,  0.0200, -0.0136,  0.0167, -0.0028,  0.0012,\n                      -0.0122, -0.0262,  0.0224, -0.0121,  0.0625, -0.0070,  0.0160,  0.0051,\n                       0.0035,  0.0116,  0.0584,  0.0307,  0.0216,  0.0399, -0.0048, -0.0011,\n                       0.0023, -0.0057,  0.0082,  0.0166, -0.0158,  0.0271,  0.0049, -0.0028,\n                       0.0054,  0.0155,  0.0293, -0.0123, -0.0189,  0.0285, -0.0130, -0.0085,\n                       0.0202,  0.0120,  0.0232,  0.0010,  0.0128, -0.0179,  0.0163, -0.0098,\n                       0.0083, -0.0190,  0.0030,  0.0072, -0.0032,  0.0036, -0.0264,  0.0033,\n                       0.0156, -0.0010, -0.0256,  0.0277,  0.0064, -0.0174,  0.0294,  0.0183,\n                       0.0079,  0.0063,  0.0067, -0.0095,  0.0142,  0.0092,  0.0049, -0.0047,\n                       0.0043, -0.0208,  0.0184,  0.0304,  0.0012,  0.0143, -0.0128, -0.0049,\n                       0.0153, -0.0128,  0.0019,  0.0105, -0.0148, -0.0009, -0.0067,  0.0359,\n                       0.0320, -0.0177,  0.0027, -0.0064,  0.0077,  0.0086,  0.0111, -0.0128,\n                      -0.0007, -0.0120, -0.0096,  0.0130,  0.0258,  0.0005, -0.0399, -0.0125,\n                      -0.0372,  0.0053, -0.0138, -0.0078,  0.0428,  0.0188, -0.0082, -0.0133,\n                       0.0075, -0.0141,  0.0098,  0.0240,  0.0141,  0.0172,  0.0400,  0.0072,\n                       0.0112, -0.0246,  0.0142, -0.0422,  0.0095,  0.0167,  0.0447,  0.0014,\n                      -0.0207, -0.0347,  0.0381,  0.0079, -0.0040,  0.0110,  0.0006,  0.0029,\n                       0.0027,  0.0346, -0.0177,  0.0200, -0.0144, -0.0151,  0.0141,  0.0018,\n                      -0.0129,  0.0090, -0.0116, -0.0026,  0.0140,  0.0079,  0.0281,  0.0322,\n                      -0.0195,  0.0380,  0.0477, -0.0143, -0.0024, -0.0009, -0.0166, -0.0057,\n                       0.0170, -0.0004, -0.0047, -0.0142, -0.0093,  0.0173, -0.0024,  0.0042,\n                       0.0067, -0.0186, -0.0036, -0.0500, -0.0015, -0.0265, -0.0206,  0.0310,\n                       0.0043,  0.0139,  0.0267,  0.0133, -0.0083,  0.0040, -0.0115, -0.0189,\n                      -0.0079, -0.0386,  0.0040,  0.0057,  0.0155, -0.0113,  0.0162, -0.0072],\n                     dtype=torch.float64)),\n             ('5.3.convs.2.1.bias',\n              tensor([-6.3887e-04, -4.0647e-03,  2.1364e-02,  6.2034e-03, -1.9000e-03,\n                      -1.3072e-02,  1.7759e-02,  2.2344e-03,  1.2202e-02,  1.9587e-02,\n                      -4.4969e-03, -5.7991e-03,  1.3204e-02, -7.2764e-03,  1.3324e-02,\n                       1.0164e-02,  2.2745e-02,  1.0041e-02,  1.8895e-02, -6.6854e-03,\n                      -5.6202e-04,  5.8272e-03, -2.5647e-03,  6.0610e-03, -3.6746e-03,\n                      -2.5566e-02,  9.2644e-03,  1.0533e-02,  5.8387e-03,  1.8568e-03,\n                      -8.0075e-03,  1.1864e-02, -1.7029e-02,  2.3001e-02,  1.3861e-02,\n                       1.1602e-03,  3.3371e-03,  2.6461e-02,  1.9183e-02,  1.1472e-02,\n                       2.6044e-03, -9.3484e-03, -4.3218e-03,  5.1953e-03,  1.5233e-02,\n                      -7.6972e-03, -2.0580e-03,  1.1362e-02, -8.4105e-03,  6.6046e-03,\n                      -1.9166e-03,  2.4499e-03,  1.6570e-02,  1.9461e-02, -1.3702e-02,\n                      -1.9292e-03,  6.6099e-03,  1.3216e-02,  5.2063e-03,  5.7547e-03,\n                      -1.1355e-02,  6.1355e-03, -5.1213e-04,  1.0585e-02, -2.0086e-03,\n                       1.4981e-02, -9.1195e-03,  1.2142e-02,  1.3030e-03, -1.3168e-02,\n                       3.8022e-03,  1.2216e-02,  1.0980e-02, -6.4504e-03,  2.2738e-02,\n                       8.5880e-03,  8.1136e-03, -1.4326e-02,  8.0742e-03,  7.0039e-03,\n                       1.3571e-02, -3.1573e-03,  1.4684e-02,  7.2891e-03,  6.1078e-04,\n                       7.3977e-03,  8.7112e-03,  4.4942e-03,  1.0875e-02,  7.2141e-03,\n                       1.1323e-03,  1.6197e-02,  1.9573e-02,  5.4885e-04,  4.9150e-03,\n                      -1.1353e-02,  7.1363e-03,  6.0952e-03,  1.0353e-02, -1.0691e-02,\n                       2.8608e-02, -5.6944e-03, -9.4944e-03, -2.2617e-02,  1.2011e-02,\n                       3.8650e-03,  4.4853e-03,  8.4501e-04,  4.5319e-03,  6.5910e-03,\n                      -6.7278e-03, -4.7204e-03,  8.3341e-03,  1.8122e-02,  7.4130e-03,\n                       7.8655e-03,  1.1304e-02,  1.6754e-03,  9.1084e-03, -1.3400e-02,\n                       4.7133e-03,  1.2976e-02,  4.6433e-03,  2.7075e-03, -6.6156e-03,\n                       1.2141e-02,  7.0365e-03,  4.8307e-03,  4.7059e-03,  9.0757e-03,\n                       2.2005e-03,  4.9007e-03,  7.7811e-03,  1.2611e-02,  1.7299e-03,\n                      -1.6393e-02,  4.5643e-04,  1.5586e-02,  1.0813e-02,  1.1029e-02,\n                      -7.0930e-03,  4.3861e-03, -5.3571e-04,  1.2885e-02, -1.2485e-02,\n                      -4.4892e-03,  4.1339e-03, -1.3255e-03,  1.0024e-02,  1.1044e-02,\n                       8.6549e-03,  3.2498e-02,  1.4242e-02,  1.7529e-02,  1.8887e-02,\n                       1.6451e-02,  2.2513e-03,  1.4089e-02, -2.3116e-03, -1.6123e-02,\n                       2.1674e-03,  1.3491e-03,  1.0743e-03,  1.9439e-02,  4.9917e-03,\n                       3.9682e-03, -7.2644e-03,  6.5169e-03,  1.3627e-02,  1.6172e-02,\n                       4.6044e-03, -1.4444e-03,  8.1002e-03,  1.2096e-02, -1.5642e-02,\n                      -3.8141e-03, -8.9964e-04,  2.3817e-02,  5.8831e-03,  9.4751e-03,\n                      -2.8132e-03,  2.2086e-02, -1.4456e-02, -4.4533e-03,  1.4024e-02,\n                       8.6503e-03,  1.1536e-02,  1.8742e-02, -3.3009e-03,  1.1747e-03,\n                       7.6575e-03, -1.2056e-03,  1.8428e-02, -2.1536e-02,  7.4855e-03,\n                       1.1300e-02, -8.5633e-03,  1.6895e-02,  9.6312e-03, -1.5870e-02,\n                       5.8270e-03, -8.8419e-04,  1.2938e-02,  2.1696e-02,  2.4334e-03,\n                      -8.3693e-03,  1.4810e-02, -1.0183e-02,  8.6087e-03,  8.6641e-03,\n                       1.5371e-04,  1.3084e-02,  1.2512e-02,  6.5208e-03,  6.1465e-03,\n                       1.0607e-02,  4.6932e-03,  1.4600e-02,  8.0792e-03,  9.7572e-05,\n                      -6.9314e-03, -6.9845e-03,  1.0003e-02,  2.7858e-02, -3.5712e-03,\n                      -1.2112e-04, -4.3388e-04,  1.6662e-03, -2.5998e-02,  1.8026e-03,\n                       2.0000e-02,  6.1719e-03,  1.1003e-02,  2.3760e-03,  1.0371e-02,\n                       6.4296e-03,  8.1386e-03,  2.8036e-03,  5.3197e-03,  1.4614e-02,\n                      -6.6263e-03,  3.4073e-03,  1.1054e-02, -2.2398e-04,  7.5147e-03,\n                       1.4856e-02,  6.6866e-03,  1.1898e-02, -4.8538e-03, -7.8340e-03,\n                       1.5311e-02,  7.5289e-03,  2.1566e-02,  2.3692e-02,  1.9520e-02,\n                       2.9027e-03], dtype=torch.float64)),\n             ('5.3.convs.2.1.running_mean',\n              tensor([ 0.4124, -0.0096, -0.8011, -0.0950,  0.0559,  0.1874, -0.1256, -0.2686,\n                      -0.5384, -0.0447, -0.2683, -0.4431,  0.3032, -0.1489,  0.9169,  0.4619,\n                      -0.6089,  0.1535, -0.3866,  0.4746,  0.1170,  0.3971,  0.1030,  0.1144,\n                      -0.0110,  0.4086, -0.4751, -0.1057, -0.2841, -0.2941, -0.1534,  1.1162,\n                      -0.3167, -0.1320,  0.0735, -0.1066,  0.3522,  0.1312, -0.1458,  0.6455,\n                       0.0132,  0.2461,  0.1389, -0.2385,  0.2537,  0.4057, -0.0319, -0.5077,\n                      -0.5940, -0.4255, -0.0347,  0.0232,  0.3935,  0.0776, -0.0184,  0.2142,\n                      -0.0068,  1.1388, -0.6292,  0.4449,  0.5935,  0.5635, -0.1454,  0.0300,\n                      -0.0489, -0.1861,  0.3126, -0.6144,  0.1453, -0.6030, -0.0348, -0.0387,\n                       0.2074, -0.0550,  0.3099, -0.2859,  0.3149, -0.1383,  0.1301, -0.1700,\n                      -0.2106, -0.0473, -0.1117,  0.1110, -0.2326, -0.0556, -0.2226, -0.3421,\n                       0.4421, -0.0274, -0.3438, -0.3106, -0.0571, -0.1958, -0.0109, -0.1868,\n                       0.1236,  0.1177, -0.1610, -0.0297,  0.0225,  0.4046, -0.0589, -0.2376,\n                       0.3300,  0.5707,  0.3657,  0.0683, -0.3905,  0.2888,  0.0525, -0.2951,\n                      -0.0175,  0.2864,  0.2144,  0.1488,  0.1579,  0.6209,  0.5971,  0.0825,\n                       0.3387, -0.1079, -0.1861, -0.1857, -0.2171,  0.2297, -0.0247, -0.0258,\n                       0.3134, -0.0514,  0.1340,  0.2164, -0.0396,  0.1412, -0.1937, -0.0121,\n                      -0.1267, -0.3960, -0.3048,  0.1869,  0.4263, -0.1307, -0.2689, -0.2222,\n                       0.2758,  0.4750, -0.1319,  0.7055, -0.1012, -0.2024, -0.3398, -0.3946,\n                      -0.5469,  0.4258,  0.0810,  0.5945, -0.0871, -0.2251, -0.1228, -0.2235,\n                      -0.0515, -0.4006, -0.1299,  0.2699, -0.7675,  0.1228, -0.2362, -0.0265,\n                      -0.1189, -0.0893,  0.3059, -0.6212,  0.3346,  0.2798, -0.2379, -0.1525,\n                      -0.2051,  0.3744, -0.1459,  0.0777, -0.0247,  0.4538,  0.2245,  0.6873,\n                       0.1688,  0.9142, -0.2394,  0.4566, -0.1004,  0.5061,  0.4664,  0.0989,\n                      -0.0176, -0.2184,  0.2568,  0.1067,  0.0287, -0.2602,  0.1708,  0.0301,\n                      -0.3081, -0.3562,  0.0682, -0.2590, -0.3701, -0.2986,  0.0663,  0.1957,\n                      -0.2194, -0.2390,  0.1144,  0.4235, -0.0405,  0.5257,  0.3823,  0.5491,\n                      -1.2602,  0.3709, -0.4742, -0.0184, -0.0997,  0.0065,  0.1146, -0.4412,\n                      -0.2190,  0.0753, -0.2445,  0.1343,  0.2108, -0.3314, -0.3753,  0.2655,\n                      -0.2935, -0.3211,  0.3481, -0.6652,  0.0547,  0.1851, -0.5539,  0.0808,\n                       0.1165,  0.2840, -0.2779, -0.2260, -0.1139, -0.1904, -0.4673,  0.0626,\n                       0.1821, -0.0576,  0.0299, -0.4333,  0.4227,  0.1861,  0.0734,  0.4437],\n                     dtype=torch.float64)),\n             ('5.3.convs.2.1.running_var',\n              tensor([0.1202, 0.3140, 0.2868, 0.2815, 0.2094, 0.2291, 0.2431, 0.1354, 0.1637,\n                      0.3213, 0.2707, 0.1180, 0.2963, 0.3076, 0.3347, 0.4244, 0.6896, 0.4558,\n                      0.3247, 0.3800, 0.2943, 0.5471, 0.6224, 0.1502, 0.3818, 0.3542, 0.2970,\n                      0.1122, 0.2493, 0.2665, 0.2108, 0.3792, 0.1930, 0.3937, 0.2914, 0.1973,\n                      0.1349, 0.2095, 0.3910, 0.5305, 0.2320, 0.0985, 0.1311, 0.3056, 0.2369,\n                      0.4958, 0.3403, 0.1601, 0.4912, 0.2895, 0.2500, 0.3183, 0.4855, 0.3410,\n                      0.2884, 0.1955, 0.3910, 0.3526, 0.3729, 0.2710, 0.3047, 0.3347, 0.4184,\n                      0.3675, 0.4222, 0.0800, 0.2254, 0.2555, 0.3885, 0.3753, 0.2459, 0.0457,\n                      0.2832, 0.3977, 0.3510, 0.1703, 0.4101, 0.1482, 0.4604, 0.2474, 0.3357,\n                      0.2736, 0.3734, 0.4499, 0.3608, 0.3739, 0.3995, 0.4463, 0.1756, 0.1257,\n                      0.5095, 0.2758, 0.1853, 0.6160, 0.3035, 0.1671, 0.3586, 0.1276, 0.1641,\n                      0.5433, 0.3265, 0.3703, 0.2231, 0.2306, 0.4007, 0.4745, 0.6165, 0.4554,\n                      0.2590, 0.2785, 0.1544, 0.3020, 0.3302, 0.2777, 0.2649, 0.2982, 0.2208,\n                      0.4789, 0.3255, 0.1889, 0.1135, 0.0937, 0.2864, 0.5263, 0.1125, 0.2621,\n                      0.3085, 0.1247, 0.2534, 0.3554, 0.1637, 0.2268, 0.3761, 0.0894, 0.1295,\n                      0.0488, 0.2557, 0.2693, 0.2745, 0.2609, 0.1977, 0.2497, 0.3916, 0.2525,\n                      0.1748, 0.7151, 0.0744, 0.3781, 0.1735, 0.1502, 0.3473, 0.2838, 0.4976,\n                      0.5947, 0.1319, 0.3458, 0.2664, 0.2735, 0.3811, 0.2855, 0.2443, 0.2867,\n                      0.1556, 0.1427, 0.4710, 0.1243, 0.4768, 0.2655, 0.4209, 0.3465, 0.2084,\n                      0.3655, 0.2703, 0.2959, 0.5168, 0.3955, 0.3101, 0.1269, 0.1561, 0.1917,\n                      0.1673, 0.2166, 0.3166, 0.3873, 0.2917, 0.4600, 0.3200, 0.2894, 0.1221,\n                      0.4412, 0.4437, 0.2416, 0.4867, 0.4599, 0.2619, 0.2733, 0.0985, 0.3060,\n                      0.1462, 0.3375, 0.2611, 0.4587, 0.3199, 0.3059, 0.6223, 0.5544, 0.2658,\n                      0.0523, 0.3685, 0.4548, 0.1121, 0.0933, 0.4420, 0.1536, 0.2723, 0.2951,\n                      0.4439, 0.2361, 0.2351, 0.2406, 0.1483, 0.1470, 0.1451, 0.4183, 0.5358,\n                      0.1342, 0.3321, 0.3501, 0.3895, 0.4608, 0.1451, 0.3868, 0.3904, 0.3519,\n                      0.2535, 0.4708, 0.2332, 0.3359, 0.3401, 0.3544, 0.0744, 0.3489, 0.3796,\n                      0.1614, 0.1784, 0.2616, 0.0992, 0.2778, 0.1440, 0.3581, 0.1561, 0.3185,\n                      0.2231, 0.5070, 0.2164, 0.3047], dtype=torch.float64)),\n             ('5.3.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('5.3.convpath.0.0.0.weight',\n              tensor([[[-0.0730],\n                       [-0.1134],\n                       [ 0.1650],\n                       ...,\n                       [ 0.0808],\n                       [-0.0915],\n                       [ 0.0239]],\n              \n                      [[-0.0908],\n                       [-0.0915],\n                       [-0.0872],\n                       ...,\n                       [ 0.0140],\n                       [ 0.0101],\n                       [ 0.0539]],\n              \n                      [[-0.0190],\n                       [-0.0615],\n                       [ 0.1286],\n                       ...,\n                       [-0.0102],\n                       [-0.0692],\n                       [ 0.0099]],\n              \n                      ...,\n              \n                      [[ 0.0350],\n                       [ 0.0626],\n                       [-0.1071],\n                       ...,\n                       [-0.1013],\n                       [ 0.0263],\n                       [-0.0304]],\n              \n                      [[-0.0144],\n                       [-0.1935],\n                       [-0.0385],\n                       ...,\n                       [-0.0348],\n                       [-0.1080],\n                       [ 0.0330]],\n              \n                      [[ 0.1550],\n                       [-0.1085],\n                       [-0.0084],\n                       ...,\n                       [-0.1381],\n                       [-0.0245],\n                       [ 0.0683]]], dtype=torch.float64)),\n             ('5.3.convpath.0.0.1.weight',\n              tensor([0.9786, 0.9778, 0.9706, 0.9658, 0.9860, 0.9728, 0.9696, 0.9776, 0.9609,\n                      0.9570, 0.9839, 0.9777, 0.9565, 0.9701, 0.9825, 0.9955, 0.9867, 0.9784,\n                      0.9769, 0.9655, 0.9730, 0.9802, 0.9823, 0.9790, 0.9625, 0.9574, 0.9744,\n                      0.9727, 0.9826, 0.9659, 0.9453, 0.9460, 0.9874, 0.9575, 0.9561, 0.9725,\n                      0.9797, 0.9578, 0.9603, 0.9791, 0.9730, 0.9765, 0.9596, 0.9431, 1.0121,\n                      0.9944, 0.9750, 0.9373, 0.9765, 0.9911, 1.0031, 0.9725, 0.9585, 0.9917,\n                      0.9760, 0.9570, 0.9672, 0.9758, 0.9863, 0.9559, 0.9800, 0.9864, 0.9680,\n                      0.9963], dtype=torch.float64)),\n             ('5.3.convpath.0.0.1.bias',\n              tensor([ 0.0014,  0.0052,  0.0156,  0.0109,  0.0148, -0.0193, -0.0044, -0.0066,\n                      -0.0218, -0.0074,  0.0120,  0.0113, -0.0019, -0.0064,  0.0021, -0.0021,\n                       0.0247,  0.0051,  0.0031, -0.0101,  0.0076,  0.0116,  0.0002, -0.0006,\n                       0.0092, -0.0005, -0.0013,  0.0139,  0.0284,  0.0044, -0.0171, -0.0156,\n                       0.0138, -0.0175, -0.0258, -0.0140, -0.0058, -0.0222, -0.0063,  0.0138,\n                      -0.0037, -0.0070,  0.0065, -0.0210,  0.0118,  0.0173, -0.0218, -0.0101,\n                      -0.0074,  0.0121,  0.0318, -0.0030, -0.0146,  0.0008,  0.0159,  0.0116,\n                      -0.0081,  0.0007,  0.0248, -0.0116,  0.0210,  0.0048,  0.0073,  0.0247],\n                     dtype=torch.float64)),\n             ('5.3.convpath.0.0.1.running_mean',\n              tensor([-0.6049, -0.4152,  0.0880,  0.6016, -0.2947,  0.0682,  0.3947,  0.3074,\n                       0.3306,  0.2386,  0.4756,  0.1629, -0.2642,  0.9581, -0.0676, -0.4790,\n                      -0.5742, -0.0540,  0.0568,  0.9929, -0.5000,  0.6728,  0.1925, -0.0654,\n                      -0.0216, -0.4671, -0.0174,  0.2646, -0.2849,  0.6013, -0.0210, -0.5748,\n                      -0.4132,  0.3725,  0.2332, -0.0161, -0.0770,  0.5225,  0.9889,  0.0181,\n                       0.1388,  0.3304,  0.1180,  0.8317,  0.4472, -0.1146,  0.2205, -0.7231,\n                      -0.2235, -0.8052, -0.4622,  0.3173, -0.2066, -0.7538,  0.2552,  0.3281,\n                       0.6575,  0.6886, -0.4073, -0.0605, -0.1072, -0.4732, -0.2691, -0.2825],\n                     dtype=torch.float64)),\n             ('5.3.convpath.0.0.1.running_var',\n              tensor([0.1663, 0.2801, 0.3877, 0.7420, 0.2253, 0.2560, 0.4599, 0.3733, 0.2903,\n                      0.7494, 0.4084, 0.2755, 0.3988, 1.4678, 0.6109, 0.2988, 0.6372, 0.8398,\n                      0.2040, 1.4996, 0.9881, 0.2902, 0.4727, 0.6883, 0.4019, 0.4009, 0.2320,\n                      0.1327, 0.4879, 0.6595, 0.3513, 1.2131, 0.1970, 0.3595, 0.3974, 0.2318,\n                      0.2626, 1.2334, 0.9566, 0.2209, 0.6718, 0.7316, 0.3475, 1.1943, 0.1442,\n                      0.2418, 0.1528, 1.7944, 0.2095, 0.2959, 0.3535, 0.4009, 0.5704, 0.2363,\n                      0.2296, 0.3013, 1.4100, 0.9587, 0.3548, 0.2982, 0.6653, 0.1702, 0.2322,\n                      0.7279], dtype=torch.float64)),\n             ('5.3.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('5.3.convpath.0.1.0.weight',\n              tensor([[[-0.0529,  0.0870, -0.0250,  0.0546,  0.0074],\n                       [ 0.0331, -0.0124, -0.0554, -0.0390,  0.0782],\n                       [ 0.0540, -0.0181, -0.0016,  0.0137,  0.0350],\n                       ...,\n                       [ 0.0212,  0.0664,  0.0009, -0.1306,  0.1132],\n                       [-0.0960,  0.0457, -0.0212,  0.0492, -0.0319],\n                       [ 0.0530,  0.0014, -0.0676,  0.0735,  0.0363]],\n              \n                      [[ 0.0250, -0.0386,  0.0232, -0.0669,  0.0871],\n                       [-0.0066,  0.0420,  0.0360, -0.0262,  0.1177],\n                       [ 0.1677,  0.0365, -0.0677,  0.0751, -0.0389],\n                       ...,\n                       [ 0.0650,  0.1577, -0.1000, -0.1001, -0.0397],\n                       [ 0.0212, -0.0353,  0.0015,  0.0260,  0.0970],\n                       [-0.0315, -0.0904, -0.0573,  0.0627, -0.0076]],\n              \n                      [[ 0.0528,  0.0315,  0.0011,  0.0820, -0.0103],\n                       [-0.0764, -0.0166, -0.0047, -0.0048, -0.0334],\n                       [-0.0849,  0.0603, -0.0143,  0.0054,  0.1008],\n                       ...,\n                       [-0.0322, -0.0064,  0.0578,  0.0246, -0.0345],\n                       [-0.0444, -0.0146, -0.1001, -0.0759, -0.0043],\n                       [-0.0089,  0.0202, -0.0429, -0.0517,  0.0236]],\n              \n                      ...,\n              \n                      [[-0.0516, -0.1299, -0.1958, -0.0887,  0.0070],\n                       [-0.0754,  0.0215, -0.0892, -0.0163,  0.0714],\n                       [-0.0536, -0.0501, -0.0211, -0.0419, -0.1046],\n                       ...,\n                       [-0.0214,  0.0345,  0.0897, -0.0015, -0.0816],\n                       [ 0.0269,  0.0373, -0.0724,  0.1050, -0.0127],\n                       [ 0.0527, -0.0594,  0.0263,  0.0104,  0.0602]],\n              \n                      [[-0.0745,  0.1269,  0.0214, -0.0510,  0.0071],\n                       [-0.0358,  0.0628, -0.1278, -0.0351, -0.0964],\n                       [ 0.0746,  0.0211, -0.0669, -0.0011, -0.1323],\n                       ...,\n                       [-0.1402,  0.0739, -0.0155, -0.0041,  0.1165],\n                       [ 0.0289, -0.0490,  0.0319, -0.0757, -0.1412],\n                       [-0.0327,  0.0836,  0.0412,  0.0508,  0.1160]],\n              \n                      [[-0.0714,  0.0189,  0.0191, -0.0513, -0.0394],\n                       [ 0.0993,  0.0954, -0.0149,  0.0413, -0.0994],\n                       [-0.0009,  0.0225,  0.0552, -0.0738,  0.0180],\n                       ...,\n                       [ 0.0775, -0.0696, -0.0689,  0.0148,  0.0564],\n                       [ 0.1100, -0.1010,  0.0209, -0.0200,  0.0553],\n                       [ 0.0388,  0.0306, -0.0277, -0.0953, -0.1510]]], dtype=torch.float64)),\n             ('5.3.convpath.0.1.1.weight',\n              tensor([0.9712, 0.9686, 0.9774, 0.9857, 0.9447, 0.9638, 0.9759, 0.9681, 0.9739,\n                      0.9489, 0.9634, 0.9911, 0.9767, 0.9604, 0.9125, 0.9784, 0.9857, 1.0201,\n                      0.9657, 0.9684, 0.9673, 0.9682, 0.9592, 0.9708, 0.9859, 0.9612, 0.9841,\n                      0.9182, 0.9323, 0.9360, 0.9872, 0.9521, 0.9134, 0.9420, 0.9441, 0.9799,\n                      0.9475, 0.9789, 0.9809, 0.9924, 0.9897, 0.9663, 0.9367, 0.9943, 0.9568,\n                      0.9608, 0.9547, 0.9970, 0.9461, 0.9758, 0.9220, 0.9497, 0.9568, 0.9759,\n                      0.9547, 0.9492, 0.9339, 0.9457, 0.9599, 0.9555, 0.9553, 0.9648, 0.9713,\n                      0.9562], dtype=torch.float64)),\n             ('5.3.convpath.0.1.1.bias',\n              tensor([-2.1816e-02, -1.7777e-02,  2.5409e-02,  1.4187e-02, -1.8367e-02,\n                      -5.3592e-03, -1.0645e-02, -1.9208e-02,  5.8650e-03, -2.2752e-02,\n                      -1.4683e-02, -1.4344e-02,  9.0271e-03,  5.9783e-04, -6.5306e-03,\n                      -3.2494e-03, -9.8720e-03,  2.1030e-02, -1.5311e-02, -5.8999e-03,\n                      -1.0087e-02,  8.8320e-03, -6.2903e-03, -1.7931e-02, -1.4199e-02,\n                      -2.7993e-02, -5.7738e-03, -4.4619e-03, -1.9864e-02, -4.2919e-03,\n                       1.1007e-02, -2.7539e-02, -2.6813e-02, -3.3304e-03,  1.5825e-02,\n                       1.1213e-02, -9.6899e-03, -5.4661e-03,  4.2204e-03,  3.5011e-05,\n                      -1.5457e-02, -1.1615e-02, -1.3990e-02,  9.1949e-03, -2.7876e-03,\n                      -1.7079e-02,  1.5275e-02,  4.8054e-03, -5.0017e-04, -6.6978e-05,\n                      -2.9418e-02, -8.3716e-03, -5.7128e-04, -1.4547e-02,  9.0625e-04,\n                      -1.5546e-02, -2.1604e-02, -1.0430e-02, -1.1210e-02, -1.6800e-02,\n                      -1.1154e-02,  7.4977e-03,  1.6724e-02, -1.2630e-02],\n                     dtype=torch.float64)),\n             ('5.3.convpath.0.1.1.running_mean',\n              tensor([ 0.2794,  0.1898, -0.0707, -0.0750, -0.1517,  0.0831, -0.5452, -0.6698,\n                      -0.4186,  0.4852, -0.1245, -0.2697,  0.0081, -0.1627, -0.0335,  0.5354,\n                      -0.1779, -0.0325,  0.5645, -0.4776,  0.6304, -0.0719,  0.0135,  0.1194,\n                       0.4775,  0.2816, -0.3085, -0.2595,  0.0542, -0.3208, -0.1225, -0.4261,\n                      -0.8632, -0.3544, -0.6738,  0.4403, -0.6101, -0.1985, -0.3912, -0.1022,\n                      -0.2301, -0.4370, -0.1214, -0.4250, -0.0650,  0.4371, -0.2645, -0.3008,\n                       0.5081, -0.2417, -0.3805, -0.6219, -0.2269, -0.5891, -0.5998, -0.6586,\n                      -0.0526,  0.4790, -0.4874,  0.1390,  0.8981, -0.1165, -0.1777, -0.2286],\n                     dtype=torch.float64)),\n             ('5.3.convpath.0.1.1.running_var',\n              tensor([1.0093, 1.0319, 0.3667, 0.3792, 0.8875, 0.3362, 0.5115, 0.6183, 1.1835,\n                      0.4314, 0.3526, 0.5524, 0.6288, 0.6846, 1.2261, 0.4111, 0.5362, 0.4094,\n                      0.7930, 0.6103, 0.5558, 0.5414, 0.3986, 0.6676, 0.5148, 0.9956, 0.3751,\n                      1.1489, 1.6513, 1.0437, 0.4789, 0.4533, 1.5465, 0.7035, 0.9554, 0.5463,\n                      0.9240, 0.5755, 0.3416, 0.5066, 0.4178, 1.0751, 0.7850, 0.6239, 0.3439,\n                      0.6473, 0.5669, 0.6776, 0.5674, 0.3418, 0.7720, 0.5270, 0.7832, 0.5416,\n                      0.5178, 0.5546, 0.8007, 0.7954, 0.3757, 0.6893, 1.0762, 0.5076, 0.7073,\n                      0.8935], dtype=torch.float64)),\n             ('5.3.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('5.3.convpath.0.2.0.weight',\n              tensor([[[ 0.0703],\n                       [-0.0006],\n                       [-0.0581],\n                       ...,\n                       [ 0.0878],\n                       [-0.0307],\n                       [ 0.0071]],\n              \n                      [[ 0.0391],\n                       [-0.0487],\n                       [-0.0311],\n                       ...,\n                       [ 0.0177],\n                       [-0.0800],\n                       [ 0.1407]],\n              \n                      [[ 0.0334],\n                       [ 0.0831],\n                       [-0.2349],\n                       ...,\n                       [-0.0827],\n                       [ 0.0171],\n                       [-0.2185]],\n              \n                      ...,\n              \n                      [[ 0.4092],\n                       [-0.0551],\n                       [ 0.0535],\n                       ...,\n                       [ 0.0626],\n                       [ 0.1836],\n                       [-0.1450]],\n              \n                      [[-0.0229],\n                       [ 0.0534],\n                       [-0.0155],\n                       ...,\n                       [-0.0672],\n                       [-0.3458],\n                       [-0.1254]],\n              \n                      [[ 0.1801],\n                       [-0.1595],\n                       [ 0.0825],\n                       ...,\n                       [-0.1389],\n                       [ 0.0803],\n                       [-0.1397]]], dtype=torch.float64)),\n             ('5.3.convpath.0.2.1.weight',\n              tensor([-0.0043, -0.0048, -0.0076, -0.0096, -0.0024,  0.0078, -0.0054, -0.0018,\n                      -0.0161,  0.0094, -0.0039, -0.0009, -0.0094, -0.0468, -0.0409, -0.0169,\n                       0.0248,  0.0311,  0.0090, -0.0047,  0.0232,  0.0339,  0.0068, -0.0022,\n                      -0.0076, -0.0106,  0.0022,  0.0011,  0.0164,  0.0198, -0.0260, -0.0493,\n                      -0.0110, -0.0189, -0.0140, -0.0234, -0.0121,  0.0148, -0.0159,  0.0157,\n                       0.0085,  0.0028,  0.0086, -0.0130,  0.0172, -0.0077,  0.0243, -0.0116,\n                       0.0141, -0.0050, -0.0176, -0.0185, -0.0228, -0.0301, -0.0116,  0.0011,\n                      -0.0190, -0.0318, -0.0134, -0.0107,  0.0160, -0.0211,  0.0111, -0.0080,\n                      -0.0082,  0.0165,  0.0062,  0.0200, -0.0136,  0.0167, -0.0028,  0.0012,\n                      -0.0122, -0.0262,  0.0224, -0.0121,  0.0625, -0.0070,  0.0160,  0.0051,\n                       0.0035,  0.0116,  0.0584,  0.0307,  0.0216,  0.0399, -0.0048, -0.0011,\n                       0.0023, -0.0057,  0.0082,  0.0166, -0.0158,  0.0271,  0.0049, -0.0028,\n                       0.0054,  0.0155,  0.0293, -0.0123, -0.0189,  0.0285, -0.0130, -0.0085,\n                       0.0202,  0.0120,  0.0232,  0.0010,  0.0128, -0.0179,  0.0163, -0.0098,\n                       0.0083, -0.0190,  0.0030,  0.0072, -0.0032,  0.0036, -0.0264,  0.0033,\n                       0.0156, -0.0010, -0.0256,  0.0277,  0.0064, -0.0174,  0.0294,  0.0183,\n                       0.0079,  0.0063,  0.0067, -0.0095,  0.0142,  0.0092,  0.0049, -0.0047,\n                       0.0043, -0.0208,  0.0184,  0.0304,  0.0012,  0.0143, -0.0128, -0.0049,\n                       0.0153, -0.0128,  0.0019,  0.0105, -0.0148, -0.0009, -0.0067,  0.0359,\n                       0.0320, -0.0177,  0.0027, -0.0064,  0.0077,  0.0086,  0.0111, -0.0128,\n                      -0.0007, -0.0120, -0.0096,  0.0130,  0.0258,  0.0005, -0.0399, -0.0125,\n                      -0.0372,  0.0053, -0.0138, -0.0078,  0.0428,  0.0188, -0.0082, -0.0133,\n                       0.0075, -0.0141,  0.0098,  0.0240,  0.0141,  0.0172,  0.0400,  0.0072,\n                       0.0112, -0.0246,  0.0142, -0.0422,  0.0095,  0.0167,  0.0447,  0.0014,\n                      -0.0207, -0.0347,  0.0381,  0.0079, -0.0040,  0.0110,  0.0006,  0.0029,\n                       0.0027,  0.0346, -0.0177,  0.0200, -0.0144, -0.0151,  0.0141,  0.0018,\n                      -0.0129,  0.0090, -0.0116, -0.0026,  0.0140,  0.0079,  0.0281,  0.0322,\n                      -0.0195,  0.0380,  0.0477, -0.0143, -0.0024, -0.0009, -0.0166, -0.0057,\n                       0.0170, -0.0004, -0.0047, -0.0142, -0.0093,  0.0173, -0.0024,  0.0042,\n                       0.0067, -0.0186, -0.0036, -0.0500, -0.0015, -0.0265, -0.0206,  0.0310,\n                       0.0043,  0.0139,  0.0267,  0.0133, -0.0083,  0.0040, -0.0115, -0.0189,\n                      -0.0079, -0.0386,  0.0040,  0.0057,  0.0155, -0.0113,  0.0162, -0.0072],\n                     dtype=torch.float64)),\n             ('5.3.convpath.0.2.1.bias',\n              tensor([-6.3887e-04, -4.0647e-03,  2.1364e-02,  6.2034e-03, -1.9000e-03,\n                      -1.3072e-02,  1.7759e-02,  2.2344e-03,  1.2202e-02,  1.9587e-02,\n                      -4.4969e-03, -5.7991e-03,  1.3204e-02, -7.2764e-03,  1.3324e-02,\n                       1.0164e-02,  2.2745e-02,  1.0041e-02,  1.8895e-02, -6.6854e-03,\n                      -5.6202e-04,  5.8272e-03, -2.5647e-03,  6.0610e-03, -3.6746e-03,\n                      -2.5566e-02,  9.2644e-03,  1.0533e-02,  5.8387e-03,  1.8568e-03,\n                      -8.0075e-03,  1.1864e-02, -1.7029e-02,  2.3001e-02,  1.3861e-02,\n                       1.1602e-03,  3.3371e-03,  2.6461e-02,  1.9183e-02,  1.1472e-02,\n                       2.6044e-03, -9.3484e-03, -4.3218e-03,  5.1953e-03,  1.5233e-02,\n                      -7.6972e-03, -2.0580e-03,  1.1362e-02, -8.4105e-03,  6.6046e-03,\n                      -1.9166e-03,  2.4499e-03,  1.6570e-02,  1.9461e-02, -1.3702e-02,\n                      -1.9292e-03,  6.6099e-03,  1.3216e-02,  5.2063e-03,  5.7547e-03,\n                      -1.1355e-02,  6.1355e-03, -5.1213e-04,  1.0585e-02, -2.0086e-03,\n                       1.4981e-02, -9.1195e-03,  1.2142e-02,  1.3030e-03, -1.3168e-02,\n                       3.8022e-03,  1.2216e-02,  1.0980e-02, -6.4504e-03,  2.2738e-02,\n                       8.5880e-03,  8.1136e-03, -1.4326e-02,  8.0742e-03,  7.0039e-03,\n                       1.3571e-02, -3.1573e-03,  1.4684e-02,  7.2891e-03,  6.1078e-04,\n                       7.3977e-03,  8.7112e-03,  4.4942e-03,  1.0875e-02,  7.2141e-03,\n                       1.1323e-03,  1.6197e-02,  1.9573e-02,  5.4885e-04,  4.9150e-03,\n                      -1.1353e-02,  7.1363e-03,  6.0952e-03,  1.0353e-02, -1.0691e-02,\n                       2.8608e-02, -5.6944e-03, -9.4944e-03, -2.2617e-02,  1.2011e-02,\n                       3.8650e-03,  4.4853e-03,  8.4501e-04,  4.5319e-03,  6.5910e-03,\n                      -6.7278e-03, -4.7204e-03,  8.3341e-03,  1.8122e-02,  7.4130e-03,\n                       7.8655e-03,  1.1304e-02,  1.6754e-03,  9.1084e-03, -1.3400e-02,\n                       4.7133e-03,  1.2976e-02,  4.6433e-03,  2.7075e-03, -6.6156e-03,\n                       1.2141e-02,  7.0365e-03,  4.8307e-03,  4.7059e-03,  9.0757e-03,\n                       2.2005e-03,  4.9007e-03,  7.7811e-03,  1.2611e-02,  1.7299e-03,\n                      -1.6393e-02,  4.5643e-04,  1.5586e-02,  1.0813e-02,  1.1029e-02,\n                      -7.0930e-03,  4.3861e-03, -5.3571e-04,  1.2885e-02, -1.2485e-02,\n                      -4.4892e-03,  4.1339e-03, -1.3255e-03,  1.0024e-02,  1.1044e-02,\n                       8.6549e-03,  3.2498e-02,  1.4242e-02,  1.7529e-02,  1.8887e-02,\n                       1.6451e-02,  2.2513e-03,  1.4089e-02, -2.3116e-03, -1.6123e-02,\n                       2.1674e-03,  1.3491e-03,  1.0743e-03,  1.9439e-02,  4.9917e-03,\n                       3.9682e-03, -7.2644e-03,  6.5169e-03,  1.3627e-02,  1.6172e-02,\n                       4.6044e-03, -1.4444e-03,  8.1002e-03,  1.2096e-02, -1.5642e-02,\n                      -3.8141e-03, -8.9964e-04,  2.3817e-02,  5.8831e-03,  9.4751e-03,\n                      -2.8132e-03,  2.2086e-02, -1.4456e-02, -4.4533e-03,  1.4024e-02,\n                       8.6503e-03,  1.1536e-02,  1.8742e-02, -3.3009e-03,  1.1747e-03,\n                       7.6575e-03, -1.2056e-03,  1.8428e-02, -2.1536e-02,  7.4855e-03,\n                       1.1300e-02, -8.5633e-03,  1.6895e-02,  9.6312e-03, -1.5870e-02,\n                       5.8270e-03, -8.8419e-04,  1.2938e-02,  2.1696e-02,  2.4334e-03,\n                      -8.3693e-03,  1.4810e-02, -1.0183e-02,  8.6087e-03,  8.6641e-03,\n                       1.5371e-04,  1.3084e-02,  1.2512e-02,  6.5208e-03,  6.1465e-03,\n                       1.0607e-02,  4.6932e-03,  1.4600e-02,  8.0792e-03,  9.7572e-05,\n                      -6.9314e-03, -6.9845e-03,  1.0003e-02,  2.7858e-02, -3.5712e-03,\n                      -1.2112e-04, -4.3388e-04,  1.6662e-03, -2.5998e-02,  1.8026e-03,\n                       2.0000e-02,  6.1719e-03,  1.1003e-02,  2.3760e-03,  1.0371e-02,\n                       6.4296e-03,  8.1386e-03,  2.8036e-03,  5.3197e-03,  1.4614e-02,\n                      -6.6263e-03,  3.4073e-03,  1.1054e-02, -2.2398e-04,  7.5147e-03,\n                       1.4856e-02,  6.6866e-03,  1.1898e-02, -4.8538e-03, -7.8340e-03,\n                       1.5311e-02,  7.5289e-03,  2.1566e-02,  2.3692e-02,  1.9520e-02,\n                       2.9027e-03], dtype=torch.float64)),\n             ('5.3.convpath.0.2.1.running_mean',\n              tensor([ 0.4124, -0.0096, -0.8011, -0.0950,  0.0559,  0.1874, -0.1256, -0.2686,\n                      -0.5384, -0.0447, -0.2683, -0.4431,  0.3032, -0.1489,  0.9169,  0.4619,\n                      -0.6089,  0.1535, -0.3866,  0.4746,  0.1170,  0.3971,  0.1030,  0.1144,\n                      -0.0110,  0.4086, -0.4751, -0.1057, -0.2841, -0.2941, -0.1534,  1.1162,\n                      -0.3167, -0.1320,  0.0735, -0.1066,  0.3522,  0.1312, -0.1458,  0.6455,\n                       0.0132,  0.2461,  0.1389, -0.2385,  0.2537,  0.4057, -0.0319, -0.5077,\n                      -0.5940, -0.4255, -0.0347,  0.0232,  0.3935,  0.0776, -0.0184,  0.2142,\n                      -0.0068,  1.1388, -0.6292,  0.4449,  0.5935,  0.5635, -0.1454,  0.0300,\n                      -0.0489, -0.1861,  0.3126, -0.6144,  0.1453, -0.6030, -0.0348, -0.0387,\n                       0.2074, -0.0550,  0.3099, -0.2859,  0.3149, -0.1383,  0.1301, -0.1700,\n                      -0.2106, -0.0473, -0.1117,  0.1110, -0.2326, -0.0556, -0.2226, -0.3421,\n                       0.4421, -0.0274, -0.3438, -0.3106, -0.0571, -0.1958, -0.0109, -0.1868,\n                       0.1236,  0.1177, -0.1610, -0.0297,  0.0225,  0.4046, -0.0589, -0.2376,\n                       0.3300,  0.5707,  0.3657,  0.0683, -0.3905,  0.2888,  0.0525, -0.2951,\n                      -0.0175,  0.2864,  0.2144,  0.1488,  0.1579,  0.6209,  0.5971,  0.0825,\n                       0.3387, -0.1079, -0.1861, -0.1857, -0.2171,  0.2297, -0.0247, -0.0258,\n                       0.3134, -0.0514,  0.1340,  0.2164, -0.0396,  0.1412, -0.1937, -0.0121,\n                      -0.1267, -0.3960, -0.3048,  0.1869,  0.4263, -0.1307, -0.2689, -0.2222,\n                       0.2758,  0.4750, -0.1319,  0.7055, -0.1012, -0.2024, -0.3398, -0.3946,\n                      -0.5469,  0.4258,  0.0810,  0.5945, -0.0871, -0.2251, -0.1228, -0.2235,\n                      -0.0515, -0.4006, -0.1299,  0.2699, -0.7675,  0.1228, -0.2362, -0.0265,\n                      -0.1189, -0.0893,  0.3059, -0.6212,  0.3346,  0.2798, -0.2379, -0.1525,\n                      -0.2051,  0.3744, -0.1459,  0.0777, -0.0247,  0.4538,  0.2245,  0.6873,\n                       0.1688,  0.9142, -0.2394,  0.4566, -0.1004,  0.5061,  0.4664,  0.0989,\n                      -0.0176, -0.2184,  0.2568,  0.1067,  0.0287, -0.2602,  0.1708,  0.0301,\n                      -0.3081, -0.3562,  0.0682, -0.2590, -0.3701, -0.2986,  0.0663,  0.1957,\n                      -0.2194, -0.2390,  0.1144,  0.4235, -0.0405,  0.5257,  0.3823,  0.5491,\n                      -1.2602,  0.3709, -0.4742, -0.0184, -0.0997,  0.0065,  0.1146, -0.4412,\n                      -0.2190,  0.0753, -0.2445,  0.1343,  0.2108, -0.3314, -0.3753,  0.2655,\n                      -0.2935, -0.3211,  0.3481, -0.6652,  0.0547,  0.1851, -0.5539,  0.0808,\n                       0.1165,  0.2840, -0.2779, -0.2260, -0.1139, -0.1904, -0.4673,  0.0626,\n                       0.1821, -0.0576,  0.0299, -0.4333,  0.4227,  0.1861,  0.0734,  0.4437],\n                     dtype=torch.float64)),\n             ('5.3.convpath.0.2.1.running_var',\n              tensor([0.1202, 0.3140, 0.2868, 0.2815, 0.2094, 0.2291, 0.2431, 0.1354, 0.1637,\n                      0.3213, 0.2707, 0.1180, 0.2963, 0.3076, 0.3347, 0.4244, 0.6896, 0.4558,\n                      0.3247, 0.3800, 0.2943, 0.5471, 0.6224, 0.1502, 0.3818, 0.3542, 0.2970,\n                      0.1122, 0.2493, 0.2665, 0.2108, 0.3792, 0.1930, 0.3937, 0.2914, 0.1973,\n                      0.1349, 0.2095, 0.3910, 0.5305, 0.2320, 0.0985, 0.1311, 0.3056, 0.2369,\n                      0.4958, 0.3403, 0.1601, 0.4912, 0.2895, 0.2500, 0.3183, 0.4855, 0.3410,\n                      0.2884, 0.1955, 0.3910, 0.3526, 0.3729, 0.2710, 0.3047, 0.3347, 0.4184,\n                      0.3675, 0.4222, 0.0800, 0.2254, 0.2555, 0.3885, 0.3753, 0.2459, 0.0457,\n                      0.2832, 0.3977, 0.3510, 0.1703, 0.4101, 0.1482, 0.4604, 0.2474, 0.3357,\n                      0.2736, 0.3734, 0.4499, 0.3608, 0.3739, 0.3995, 0.4463, 0.1756, 0.1257,\n                      0.5095, 0.2758, 0.1853, 0.6160, 0.3035, 0.1671, 0.3586, 0.1276, 0.1641,\n                      0.5433, 0.3265, 0.3703, 0.2231, 0.2306, 0.4007, 0.4745, 0.6165, 0.4554,\n                      0.2590, 0.2785, 0.1544, 0.3020, 0.3302, 0.2777, 0.2649, 0.2982, 0.2208,\n                      0.4789, 0.3255, 0.1889, 0.1135, 0.0937, 0.2864, 0.5263, 0.1125, 0.2621,\n                      0.3085, 0.1247, 0.2534, 0.3554, 0.1637, 0.2268, 0.3761, 0.0894, 0.1295,\n                      0.0488, 0.2557, 0.2693, 0.2745, 0.2609, 0.1977, 0.2497, 0.3916, 0.2525,\n                      0.1748, 0.7151, 0.0744, 0.3781, 0.1735, 0.1502, 0.3473, 0.2838, 0.4976,\n                      0.5947, 0.1319, 0.3458, 0.2664, 0.2735, 0.3811, 0.2855, 0.2443, 0.2867,\n                      0.1556, 0.1427, 0.4710, 0.1243, 0.4768, 0.2655, 0.4209, 0.3465, 0.2084,\n                      0.3655, 0.2703, 0.2959, 0.5168, 0.3955, 0.3101, 0.1269, 0.1561, 0.1917,\n                      0.1673, 0.2166, 0.3166, 0.3873, 0.2917, 0.4600, 0.3200, 0.2894, 0.1221,\n                      0.4412, 0.4437, 0.2416, 0.4867, 0.4599, 0.2619, 0.2733, 0.0985, 0.3060,\n                      0.1462, 0.3375, 0.2611, 0.4587, 0.3199, 0.3059, 0.6223, 0.5544, 0.2658,\n                      0.0523, 0.3685, 0.4548, 0.1121, 0.0933, 0.4420, 0.1536, 0.2723, 0.2951,\n                      0.4439, 0.2361, 0.2351, 0.2406, 0.1483, 0.1470, 0.1451, 0.4183, 0.5358,\n                      0.1342, 0.3321, 0.3501, 0.3895, 0.4608, 0.1451, 0.3868, 0.3904, 0.3519,\n                      0.2535, 0.4708, 0.2332, 0.3359, 0.3401, 0.3544, 0.0744, 0.3489, 0.3796,\n                      0.1614, 0.1784, 0.2616, 0.0992, 0.2778, 0.1440, 0.3581, 0.1561, 0.3185,\n                      0.2231, 0.5070, 0.2164, 0.3047], dtype=torch.float64)),\n             ('5.3.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.0.convs.0.0.weight',\n              tensor([[[-2.6970e-02],\n                       [-3.6803e-03],\n                       [-9.6383e-02],\n                       ...,\n                       [-2.8363e-02],\n                       [-1.4273e-01],\n                       [ 1.4194e-01]],\n              \n                      [[ 1.0622e-01],\n                       [-3.8758e-02],\n                       [ 3.5894e-05],\n                       ...,\n                       [-4.5822e-02],\n                       [-5.4668e-03],\n                       [ 7.9421e-03]],\n              \n                      [[-1.6322e-01],\n                       [-6.7668e-02],\n                       [-5.5133e-02],\n                       ...,\n                       [ 1.6949e-01],\n                       [-5.0897e-02],\n                       [-1.2894e-02]],\n              \n                      ...,\n              \n                      [[ 5.1697e-02],\n                       [-4.2094e-02],\n                       [-5.0710e-02],\n                       ...,\n                       [-2.0678e-01],\n                       [-7.9579e-03],\n                       [ 2.0308e-02]],\n              \n                      [[-7.3728e-02],\n                       [ 8.0049e-02],\n                       [-8.1751e-02],\n                       ...,\n                       [-5.0059e-02],\n                       [ 5.4614e-02],\n                       [-1.5907e-01]],\n              \n                      [[-7.7045e-02],\n                       [-1.1295e-01],\n                       [-8.1520e-02],\n                       ...,\n                       [-1.8396e-01],\n                       [ 3.8302e-02],\n                       [-6.1302e-02]]], dtype=torch.float64)),\n             ('6.0.convs.0.1.weight',\n              tensor([0.9733, 0.9626, 0.9769, 0.9667, 0.9645, 0.9621, 0.9552, 0.9773, 0.9869,\n                      0.9764, 0.9850, 0.9834, 0.9512, 0.9561, 0.9595, 0.9639, 0.9866, 0.9504,\n                      0.9536, 0.9499, 0.9648, 0.9685, 0.9470, 0.9857, 0.9731, 0.9530, 0.9857,\n                      0.9613, 0.9664, 0.9704, 0.9583, 0.9523, 0.9583, 0.9381, 0.9631, 0.9477,\n                      0.9694, 0.9740, 0.9530, 0.9843, 0.9656, 0.9630, 0.9602, 0.9750, 0.9555,\n                      0.9664, 0.9937, 0.9696, 0.9714, 0.9809, 0.9755, 0.9606, 0.9642, 0.9594,\n                      0.9875, 0.9568, 0.9527, 0.9711, 0.9613, 0.9579, 0.9654, 0.9781, 0.9494,\n                      0.9917], dtype=torch.float64)),\n             ('6.0.convs.0.1.bias',\n              tensor([ 0.0182,  0.0044,  0.0155,  0.0101, -0.0147,  0.0076,  0.0094,  0.0137,\n                       0.0094, -0.0042,  0.0171,  0.0154, -0.0050, -0.0074, -0.0044,  0.0118,\n                       0.0128,  0.0066, -0.0114, -0.0086, -0.0003,  0.0185,  0.0020, -0.0117,\n                       0.0092,  0.0183,  0.0128,  0.0075,  0.0061, -0.0046, -0.0017, -0.0059,\n                      -0.0078, -0.0038,  0.0109,  0.0027, -0.0155,  0.0233, -0.0079,  0.0159,\n                       0.0030, -0.0032, -0.0107,  0.0217, -0.0026, -0.0086,  0.0032,  0.0018,\n                       0.0169, -0.0049,  0.0017,  0.0022,  0.0052, -0.0124,  0.0073, -0.0054,\n                      -0.0144, -0.0094,  0.0048, -0.0039, -0.0202,  0.0241, -0.0054,  0.0164],\n                     dtype=torch.float64)),\n             ('6.0.convs.0.1.running_mean',\n              tensor([-0.1898,  0.5286,  0.0335, -0.3213, -0.0168, -0.5279,  0.1501, -0.5237,\n                      -0.3966, -0.1989, -0.2629, -0.5886, -0.1360, -0.0880, -0.0809, -0.5115,\n                       0.3257, -0.5946,  0.4340,  0.1103, -0.3697, -1.0466, -0.5314,  0.9367,\n                      -0.1604, -0.5161, -0.5635, -0.1232,  0.2103,  0.4975, -0.0730, -0.8035,\n                       0.0293, -0.4794, -0.3607, -0.3912, -0.3421, -0.1106,  0.0427,  0.5211,\n                       0.3341, -0.2243, -0.1664,  0.5373, -0.6242,  0.2612, -0.0353, -0.0982,\n                      -0.6819,  0.1599, -0.7689,  0.3543,  0.6521, -0.1273, -0.2356,  0.3384,\n                       0.5187, -1.2648,  0.2145,  0.6314,  0.3822, -0.0959, -0.0830, -0.2557],\n                     dtype=torch.float64)),\n             ('6.0.convs.0.1.running_var',\n              tensor([0.2949, 1.3506, 0.2095, 0.3228, 0.5939, 0.3086, 0.4491, 0.2959, 0.2250,\n                      0.2610, 0.2137, 0.3347, 0.4316, 0.3474, 0.2600, 0.4867, 0.1647, 0.4199,\n                      0.3177, 0.3693, 0.3048, 0.3139, 1.1285, 0.2792, 0.3162, 1.4534, 0.2276,\n                      0.3284, 0.5564, 0.6521, 0.2618, 0.6349, 1.4750, 1.1205, 0.4926, 0.3085,\n                      0.2899, 0.2563, 0.6309, 0.6086, 0.2059, 0.5342, 0.2046, 0.1553, 1.0869,\n                      0.2841, 0.2513, 0.2682, 0.4857, 0.2348, 0.2554, 0.4058, 0.8443, 0.3353,\n                      0.2551, 0.6225, 0.5646, 0.4638, 0.4132, 0.6166, 0.3495, 0.5060, 0.3995,\n                      0.2474], dtype=torch.float64)),\n             ('6.0.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.0.convs.1.0.weight',\n              tensor([[[ 1.4300e-02, -1.6613e-01,  5.0351e-02, -1.1099e-02,  8.5365e-02],\n                       [ 9.8312e-02, -5.9451e-02, -6.2093e-02,  7.6365e-02, -2.1359e-02],\n                       [ 5.0143e-02,  5.1288e-02, -2.1402e-02,  4.7861e-02,  1.2735e-01],\n                       ...,\n                       [ 6.7171e-03,  2.4499e-02, -1.1445e-01, -4.8095e-02,  2.6229e-03],\n                       [-8.1411e-02,  8.6263e-02, -5.1260e-03,  2.5771e-02,  7.8661e-02],\n                       [ 7.6977e-02, -7.4010e-02,  9.6184e-02, -1.4804e-01, -3.4727e-02]],\n              \n                      [[ 4.5393e-02, -6.0341e-02, -8.4389e-02,  8.6802e-02, -1.6013e-01],\n                       [-7.9932e-02, -7.5873e-02,  9.5843e-02, -7.6574e-02, -1.0187e-01],\n                       [-3.2304e-02,  5.7686e-02,  1.2541e-01, -1.9176e-02,  1.6634e-02],\n                       ...,\n                       [-3.3401e-02, -7.0081e-02, -3.1010e-02, -9.2812e-02,  1.9510e-02],\n                       [ 8.3299e-02, -4.3040e-05, -3.2365e-02, -3.8651e-02, -4.2099e-02],\n                       [-1.7246e-02, -2.4016e-02, -3.8546e-02, -9.4165e-03,  7.8797e-02]],\n              \n                      [[ 5.0659e-02,  2.5301e-02,  4.9000e-02,  5.0935e-02, -1.6699e-02],\n                       [ 4.4271e-02,  5.2339e-02, -2.9406e-02, -6.1004e-02, -1.2174e-02],\n                       [-1.2739e-01, -1.8848e-01, -1.0607e-01,  5.7483e-02,  8.0239e-02],\n                       ...,\n                       [ 1.0591e-01, -4.4503e-02, -6.2935e-03,  1.1126e-01, -3.5547e-02],\n                       [-3.0620e-02,  1.0402e-01,  3.6872e-02,  2.0736e-02,  1.7067e-01],\n                       [-4.7079e-02,  5.9846e-02, -6.3831e-02, -3.8970e-02,  2.5046e-02]],\n              \n                      ...,\n              \n                      [[ 7.7700e-03,  1.1718e-01,  1.7228e-02, -1.5217e-02,  5.0478e-02],\n                       [-8.2533e-03, -6.7451e-02, -5.0580e-02, -3.5622e-02,  7.3493e-02],\n                       [ 6.5439e-02, -1.9100e-02, -1.4990e-02,  2.9701e-02, -1.0450e-01],\n                       ...,\n                       [-3.1419e-02, -6.2197e-02,  8.9559e-02,  1.3460e-01, -5.9444e-02],\n                       [ 8.3296e-02, -1.0445e-01, -1.3977e-02, -1.0446e-01, -1.7055e-02],\n                       [ 6.5726e-02,  9.9994e-02,  4.3117e-02, -4.6600e-02, -2.3974e-02]],\n              \n                      [[-1.0273e-01, -3.1845e-03, -5.8346e-02, -4.4879e-02,  1.1000e-01],\n                       [ 7.2528e-02, -9.8926e-02, -1.2251e-01, -7.4172e-02, -2.3046e-02],\n                       [-1.9921e-02, -2.2300e-02,  2.7006e-02, -8.2926e-02, -1.2887e-01],\n                       ...,\n                       [ 2.0463e-02, -5.8621e-02, -1.0312e-02,  6.3664e-02, -1.7162e-03],\n                       [-1.1698e-02, -2.3072e-02, -1.0209e-01, -1.2406e-01, -1.1682e-01],\n                       [-2.1273e-03,  3.7681e-02, -5.7927e-02, -5.5688e-02,  3.9049e-02]],\n              \n                      [[ 4.1006e-02, -6.9948e-02, -2.2717e-02, -6.7585e-02, -3.9872e-03],\n                       [-3.9864e-02,  2.0570e-02,  1.7803e-02,  6.2099e-03,  4.8159e-02],\n                       [-3.3721e-03,  9.4295e-02, -4.7379e-02, -6.8278e-02,  8.1723e-02],\n                       ...,\n                       [-9.0028e-02, -6.6673e-02,  9.1409e-02, -1.8492e-02,  1.9293e-02],\n                       [ 7.0934e-02,  4.6042e-02, -8.1902e-02, -1.1503e-01,  2.0710e-02],\n                       [-1.5933e-02,  3.1570e-02,  7.1365e-02, -2.3068e-01,  2.7605e-02]]],\n                     dtype=torch.float64)),\n             ('6.0.convs.1.1.weight',\n              tensor([0.9772, 0.9657, 0.9904, 0.9677, 0.9467, 0.9760, 0.9845, 0.9339, 0.9552,\n                      0.9730, 0.9871, 0.9569, 0.9616, 0.9632, 0.9808, 0.9587, 0.9529, 0.9390,\n                      0.9686, 0.9313, 0.9522, 0.9481, 0.9594, 0.9552, 0.9837, 0.9258, 0.9615,\n                      0.9435, 0.9587, 0.9819, 0.9615, 0.9618, 0.9489, 0.9698, 0.9545, 0.9801,\n                      0.9747, 0.9557, 0.9573, 0.9640, 0.9726, 0.9735, 0.9665, 0.9526, 0.9606,\n                      0.9738, 0.9691, 0.9582, 0.9767, 0.9587, 0.9691, 0.9865, 0.9445, 0.9475,\n                      0.9505, 0.9650, 0.9384, 0.9429, 0.9540, 0.9639, 0.9670, 0.9594, 0.9721,\n                      0.9555], dtype=torch.float64)),\n             ('6.0.convs.1.1.bias',\n              tensor([-0.0031, -0.0078, -0.0057, -0.0053, -0.0112, -0.0063,  0.0148, -0.0183,\n                      -0.0160,  0.0005,  0.0039, -0.0100,  0.0104,  0.0115,  0.0040, -0.0104,\n                      -0.0144,  0.0034,  0.0005, -0.0205, -0.0027,  0.0125,  0.0045, -0.0064,\n                       0.0177, -0.0131,  0.0071, -0.0039, -0.0167,  0.0071, -0.0171, -0.0294,\n                      -0.0149,  0.0221, -0.0059, -0.0067,  0.0125, -0.0113,  0.0044,  0.0022,\n                      -0.0059, -0.0090,  0.0185, -0.0149, -0.0038,  0.0002, -0.0040, -0.0058,\n                      -0.0019, -0.0136,  0.0111, -0.0298, -0.0237, -0.0047,  0.0010,  0.0101,\n                      -0.0135, -0.0108, -0.0042,  0.0065, -0.0105, -0.0132, -0.0063,  0.0028],\n                     dtype=torch.float64)),\n             ('6.0.convs.1.1.running_mean',\n              tensor([ 0.4012, -0.4091,  0.0604, -0.4854, -0.2893, -0.1028, -0.0115,  0.3455,\n                      -0.0449,  0.4850,  0.4138, -0.5967,  0.3608, -0.8848, -0.5577,  0.3049,\n                       0.1373, -0.1257, -0.4323, -0.3823,  0.4486, -0.7119,  0.0787,  0.1405,\n                       0.5263, -0.9175, -0.6052,  0.6887, -1.0031,  0.0758,  0.3468,  0.2492,\n                       0.0186,  0.0636, -0.5071,  0.6360,  0.8923, -0.8908,  0.4495,  0.2354,\n                       0.0971,  0.2575,  0.8363, -0.0414, -0.3072, -0.0315, -0.4707,  0.4006,\n                       0.7368,  0.1495,  0.1364,  0.8887, -0.5170, -0.3615, -0.3102, -0.4515,\n                      -0.9232, -0.9359,  0.2585, -0.4430, -0.0661, -0.2814, -0.2297, -0.1975],\n                     dtype=torch.float64)),\n             ('6.0.convs.1.1.running_var',\n              tensor([0.4697, 0.3462, 0.6115, 0.6543, 0.3535, 0.8766, 0.4727, 0.5686, 0.3484,\n                      0.3092, 0.3595, 0.7819, 0.5885, 0.4289, 0.3098, 0.7597, 0.7137, 0.4922,\n                      0.5136, 0.5295, 0.6163, 0.5648, 0.4553, 0.3683, 0.4510, 0.5584, 0.2478,\n                      0.6515, 0.8206, 0.4619, 0.5173, 0.3721, 0.5299, 0.4317, 0.5280, 0.5363,\n                      0.5326, 0.4945, 0.4166, 0.4753, 0.4615, 0.4844, 0.4739, 0.5528, 0.5394,\n                      0.3477, 0.4482, 0.7215, 0.3526, 0.5556, 0.4774, 0.4855, 0.4149, 0.5104,\n                      0.4351, 0.5948, 0.3415, 0.4312, 0.6211, 0.6765, 0.4514, 0.6177, 0.6639,\n                      0.5058], dtype=torch.float64)),\n             ('6.0.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.0.convs.2.0.weight',\n              tensor([[[ 0.2423],\n                       [ 0.0678],\n                       [-0.1224],\n                       ...,\n                       [-0.0126],\n                       [ 0.0016],\n                       [ 0.0017]],\n              \n                      [[-0.2289],\n                       [-0.2979],\n                       [ 0.2175],\n                       ...,\n                       [ 0.1080],\n                       [ 0.1306],\n                       [-0.1502]],\n              \n                      [[ 0.0911],\n                       [ 0.0726],\n                       [-0.1599],\n                       ...,\n                       [-0.0212],\n                       [-0.0425],\n                       [-0.0222]],\n              \n                      ...,\n              \n                      [[-0.0237],\n                       [-0.0678],\n                       [-0.0063],\n                       ...,\n                       [-0.0885],\n                       [-0.0355],\n                       [ 0.0205]],\n              \n                      [[-0.0423],\n                       [-0.0107],\n                       [ 0.1330],\n                       ...,\n                       [ 0.0471],\n                       [ 0.0839],\n                       [ 0.0514]],\n              \n                      [[ 0.0804],\n                       [-0.0290],\n                       [ 0.0372],\n                       ...,\n                       [ 0.1110],\n                       [-0.1031],\n                       [-0.1347]]], dtype=torch.float64)),\n             ('6.0.convs.2.1.weight',\n              tensor([ 1.2589e-02,  2.2134e-02,  1.4982e-03, -1.0002e-02,  6.8350e-03,\n                       2.7259e-02, -5.5047e-03,  2.3923e-02,  3.1186e-03,  8.5064e-03,\n                       4.6943e-03,  4.6265e-03,  1.0152e-02, -3.9186e-03,  9.8827e-03,\n                      -1.4132e-02,  9.0858e-03,  2.4119e-02,  1.4784e-02, -1.1469e-02,\n                      -3.4464e-04, -3.3942e-02, -1.4982e-02, -1.0714e-02,  3.3634e-02,\n                       2.5132e-02,  5.9036e-03, -1.7812e-03,  1.6919e-03, -1.0305e-02,\n                      -2.4515e-02, -2.3907e-02, -3.6213e-04,  8.4237e-03,  1.2070e-02,\n                      -1.4688e-02, -7.5030e-03,  1.1786e-04,  1.5954e-02,  5.4133e-03,\n                       6.0047e-03, -1.1529e-02,  1.0736e-02,  1.5569e-02, -8.1443e-03,\n                      -7.4892e-04, -1.5531e-02, -5.7282e-03,  3.9492e-03,  2.4710e-03,\n                      -2.0063e-02, -6.8316e-03, -2.2209e-04, -2.2354e-02, -1.4528e-02,\n                      -8.2951e-03,  1.7758e-02, -4.2690e-02, -6.2631e-03,  1.1134e-02,\n                       8.9511e-03,  1.2944e-02,  8.3517e-03, -2.1371e-03,  1.9489e-02,\n                       2.2800e-02, -1.3371e-02, -1.2709e-02,  2.6410e-02, -6.7265e-03,\n                      -1.2115e-02, -8.9795e-03, -1.9000e-02,  1.3643e-02, -9.7831e-03,\n                       1.9139e-02,  2.4012e-02,  1.2607e-02, -1.0823e-02, -2.0259e-02,\n                      -5.5155e-03,  1.7089e-02, -4.3870e-02,  3.0878e-02, -3.4828e-02,\n                      -1.5229e-02,  3.0851e-02, -4.7761e-04, -1.1347e-02, -1.7289e-02,\n                      -4.4876e-02, -6.5281e-04,  1.4520e-02, -5.4784e-03, -3.5537e-03,\n                       3.5752e-03, -3.5605e-02,  1.0840e-03, -1.0007e-03,  2.8729e-02,\n                       4.6823e-03,  8.1020e-03, -2.9972e-03,  1.0286e-02,  2.3756e-02,\n                      -1.4443e-02, -1.1917e-02,  1.3830e-02, -2.6427e-02, -7.4733e-03,\n                      -6.5341e-03,  1.2077e-03,  3.8398e-03,  1.7993e-03,  2.8002e-02,\n                      -1.2012e-02,  6.8674e-03,  4.1180e-03, -4.9496e-04, -1.0257e-02,\n                       1.6305e-02,  2.9369e-02, -9.3340e-03, -5.2921e-03,  1.5934e-02,\n                       1.8353e-02,  3.3962e-03, -1.7315e-02, -2.1504e-03,  3.9781e-04,\n                      -3.2770e-03, -1.8545e-02, -5.0681e-03, -2.8501e-03,  1.6818e-02,\n                      -1.2274e-02,  4.5861e-02, -7.9423e-03,  2.3305e-02,  5.1455e-04,\n                       1.6888e-02,  1.4197e-03,  1.3604e-02,  9.6374e-06,  3.4015e-03,\n                      -2.8965e-02,  7.6350e-03,  3.1075e-03,  5.1877e-03, -6.5824e-05,\n                      -1.2750e-02,  6.0342e-03,  2.4308e-02, -8.0952e-03, -8.7356e-03,\n                      -1.3684e-02, -8.3638e-03,  2.8634e-03, -1.5896e-02, -8.8031e-04,\n                       7.4047e-03,  1.2607e-02,  8.0281e-03,  1.4698e-03,  4.7841e-02,\n                       9.1095e-03,  9.1333e-03,  2.7199e-02, -2.4835e-02, -2.3206e-02,\n                       1.2201e-03, -8.6248e-04, -6.3817e-03,  8.6714e-03,  2.6644e-03,\n                      -8.8644e-03,  8.3611e-03, -1.3300e-02, -1.9668e-02, -2.8264e-02,\n                       3.8536e-02,  1.5099e-02, -7.0421e-03, -3.5954e-03, -8.5808e-03,\n                       1.4133e-02,  9.7383e-03,  2.9362e-02,  1.6455e-02, -2.0519e-03,\n                       1.9844e-02,  1.4509e-02, -4.7951e-03, -3.7688e-02,  1.7180e-02,\n                      -1.8202e-02, -2.2994e-03, -9.3939e-04, -1.7049e-02,  9.0388e-03,\n                      -1.1602e-02,  2.0356e-02,  7.4361e-04, -1.5174e-02,  4.6653e-03,\n                       1.4713e-02,  4.4670e-03,  7.0714e-03,  1.1514e-03,  1.8712e-02,\n                       1.5238e-02, -6.4437e-03, -8.1187e-03, -1.1528e-03,  5.1901e-04,\n                      -3.4911e-03, -8.2275e-03,  1.0125e-02,  3.6172e-02,  1.1648e-02,\n                      -1.4007e-03, -1.9274e-02,  2.6684e-03,  9.2241e-03,  1.9817e-02,\n                       1.3887e-02,  3.9888e-03,  1.5255e-03, -6.2476e-03,  6.0278e-03,\n                       2.5531e-02, -1.1539e-02, -1.4804e-02,  1.4940e-02, -1.3097e-02,\n                       1.2203e-02, -1.5113e-03, -1.0267e-02,  2.2433e-02, -5.5860e-03,\n                       5.8517e-03,  4.7929e-03,  3.0242e-02,  1.7900e-02,  1.5140e-02,\n                      -5.5452e-03, -2.2973e-02, -1.9603e-02,  1.2895e-02, -3.6269e-02,\n                      -5.9550e-03,  9.1785e-03,  1.6192e-02, -4.8521e-03,  3.8073e-02,\n                       1.1540e-02], dtype=torch.float64)),\n             ('6.0.convs.2.1.bias',\n              tensor([-2.6710e-03, -4.4757e-03,  1.9047e-02,  7.9802e-03,  4.5639e-03,\n                       6.3193e-03,  2.1594e-02,  3.1125e-04,  1.1535e-02,  2.0684e-02,\n                       1.0022e-02, -7.4316e-03,  1.3917e-02, -8.1055e-03,  6.9060e-03,\n                       9.1917e-03,  1.7281e-02,  1.3197e-03,  1.6949e-02, -7.9680e-03,\n                      -2.1120e-03,  4.7207e-03,  2.7994e-03,  6.7468e-03, -2.9368e-03,\n                      -1.3028e-02,  6.3551e-03,  1.0486e-02,  3.2672e-03,  6.2418e-04,\n                      -9.8721e-03,  8.7850e-03, -8.5806e-03,  1.5453e-02,  1.8509e-02,\n                      -4.5585e-03,  5.0924e-03,  2.6859e-02,  1.3148e-02,  1.4147e-02,\n                       9.4985e-04, -1.4161e-02, -6.3559e-03,  2.4406e-03,  1.2313e-02,\n                      -1.1858e-02,  1.4381e-02,  6.8018e-03, -1.1003e-02, -1.6633e-03,\n                       3.7283e-03,  2.5442e-03,  8.2851e-03,  2.1109e-02, -1.8510e-03,\n                      -2.5443e-03,  8.0939e-03,  7.5784e-03,  7.7029e-03,  8.8865e-03,\n                      -6.5805e-03,  2.9684e-03,  4.4420e-03,  1.0176e-02, -3.2072e-03,\n                       1.5495e-02, -1.1231e-02,  1.4449e-02, -2.0563e-03, -9.1886e-03,\n                       3.8787e-03,  1.0248e-02,  1.3782e-02, -7.9940e-03,  1.4503e-02,\n                       1.4225e-02,  2.1259e-03, -7.5022e-03,  3.2457e-03,  7.0246e-03,\n                       1.1919e-02, -5.5552e-03,  7.4540e-03,  5.7170e-03, -1.4955e-03,\n                       4.2297e-03,  6.4495e-03,  3.8244e-03,  9.0017e-03,  6.0969e-03,\n                      -1.6878e-03,  2.0648e-02,  1.8853e-02, -7.4074e-04,  5.3471e-03,\n                      -1.6457e-02,  5.8088e-03,  6.4733e-03,  1.1973e-02, -2.4289e-03,\n                       2.6342e-02,  7.8291e-03, -1.6686e-03, -2.0576e-02,  1.4190e-02,\n                       1.0357e-03,  6.9472e-03, -2.2884e-03,  3.9864e-03,  6.8144e-03,\n                      -7.6664e-03, -6.1410e-03,  6.2409e-03,  1.5377e-02,  6.4755e-03,\n                       8.0066e-03,  1.0746e-02,  2.5508e-03,  1.1056e-03, -1.4409e-02,\n                       5.7554e-03,  1.4332e-02, -2.3352e-05,  1.4963e-03, -1.2396e-02,\n                       1.3699e-02,  1.3938e-02,  1.8219e-03,  1.0190e-03,  9.8542e-03,\n                      -9.5031e-04,  7.4841e-03,  1.3461e-02,  1.1462e-02,  9.5348e-03,\n                      -3.4521e-04,  1.0565e-03,  7.6090e-03,  1.2472e-02,  6.2729e-03,\n                      -2.0479e-03, -3.3668e-03, -1.0103e-03,  9.5984e-03, -7.3289e-03,\n                      -5.4630e-03,  4.4780e-03,  1.0373e-03,  1.2046e-02,  1.0613e-02,\n                       1.7689e-03,  1.2276e-02,  5.7251e-03,  1.5362e-02,  1.8950e-02,\n                       1.6699e-02,  2.9974e-04,  1.0392e-02,  4.4700e-04, -1.4558e-02,\n                      -5.9215e-04,  1.6275e-03, -1.7849e-03,  1.7888e-02,  6.5666e-03,\n                       3.5940e-03, -7.0571e-03,  1.2028e-02,  8.0600e-03,  1.5393e-02,\n                       5.2645e-03,  9.0200e-03,  1.3390e-02,  8.2356e-03, -1.3984e-02,\n                      -5.1562e-03, -3.5023e-03,  2.1900e-02,  5.7860e-03,  4.3705e-03,\n                      -1.6601e-03,  1.1240e-02, -8.0598e-03, -9.8081e-03,  1.9230e-02,\n                       3.0851e-03,  1.0214e-02,  1.9930e-02, -3.7627e-03,  2.7477e-03,\n                       5.6262e-03, -3.0982e-03,  1.4564e-02, -1.3703e-02,  1.1121e-02,\n                       8.4436e-03, -4.9463e-03,  1.4878e-02,  8.7587e-03, -8.2572e-03,\n                       3.3886e-03,  8.7394e-03,  2.0713e-02,  1.7387e-02,  5.7210e-03,\n                      -7.1348e-03,  1.4240e-02, -1.4810e-03,  2.3217e-03,  6.9327e-03,\n                       1.6514e-03,  1.3766e-02,  1.5536e-02,  6.6130e-03,  6.5846e-03,\n                       9.7555e-03,  1.0358e-03, -3.1396e-04,  8.0360e-03, -8.6887e-04,\n                      -8.7640e-03, -4.5100e-03,  7.0237e-03,  2.5777e-02, -7.0481e-03,\n                       6.4169e-03, -6.4992e-04,  2.9110e-03, -1.9480e-02,  1.8421e-03,\n                       1.8544e-02,  2.1945e-03,  1.0925e-02,  1.0034e-02,  1.1152e-02,\n                       3.1598e-03,  6.4625e-03, -1.0455e-03,  3.6897e-03,  6.7947e-03,\n                       8.3055e-03,  3.0324e-03,  2.5599e-03,  8.1136e-03,  5.6226e-03,\n                       1.3669e-02,  6.1828e-03,  9.1897e-03,  2.3778e-03, -6.4222e-03,\n                       1.5377e-02,  7.6411e-03,  1.5317e-02,  2.3442e-02,  1.7283e-02,\n                       1.1949e-03], dtype=torch.float64)),\n             ('6.0.convs.2.1.running_mean',\n              tensor([ 3.6377e-01,  1.7554e-02, -2.6962e-01, -4.1481e-01, -1.6189e-01,\n                       5.0392e-01,  1.7596e-01, -7.0541e-01,  7.0634e-01,  4.5587e-01,\n                       5.4911e-01,  1.8238e-01,  3.1880e-01,  5.5257e-01,  7.2893e-01,\n                       6.6627e-01, -4.4744e-02, -2.5096e-01, -4.2137e-01,  1.9596e-01,\n                      -1.1878e-03,  3.9145e-01,  7.4479e-01, -2.1830e-01, -3.9026e-01,\n                      -1.2492e-01,  4.7468e-01,  9.5392e-02,  1.8119e-01, -3.9681e-01,\n                      -2.7664e-01,  1.2552e+00, -2.8184e-01, -5.0011e-01, -3.7969e-01,\n                       5.1232e-01,  2.9533e-01, -3.7860e-01, -5.1598e-01, -1.8300e-01,\n                       4.3152e-03,  1.4463e-01, -4.2384e-01, -3.6366e-02,  1.5020e-01,\n                      -4.9829e-01, -4.0840e-01, -2.5977e-01, -5.3684e-01,  6.8666e-01,\n                       1.9049e-01, -8.3944e-01, -4.2900e-01,  1.4235e-01, -4.6562e-01,\n                       3.2655e-01, -5.0138e-01,  5.2629e-01, -3.9421e-01,  3.3558e-02,\n                       7.4408e-02,  3.9566e-01, -4.2918e-02, -2.3454e-01,  1.0313e-01,\n                       4.8544e-02, -3.6417e-01,  3.7146e-01, -6.2069e-01, -2.9958e-01,\n                      -3.2694e-01,  2.6089e-01,  4.2522e-02, -5.6105e-02, -2.9843e-01,\n                       5.4353e-01,  1.1431e-01, -3.2288e-01, -5.9292e-02,  1.4410e-01,\n                       1.4594e-01,  3.7571e-01,  6.5166e-01, -1.1116e-01,  1.0201e-01,\n                      -1.6946e-01, -3.1272e-01,  9.3765e-01,  2.0867e-01, -2.5698e-01,\n                       6.0670e-03,  1.0732e-01,  3.0473e-01, -8.4131e-02,  1.2448e-02,\n                       4.8148e-03,  5.3295e-01,  1.3120e-01,  2.2328e-01,  2.4700e-01,\n                      -4.6290e-01,  1.7772e-01,  8.1894e-02, -1.4177e-01, -1.0934e-01,\n                      -4.4043e-02, -3.7988e-01,  6.7852e-01,  6.6260e-01,  4.4203e-01,\n                       3.3434e-01, -2.4067e-01,  2.0392e-01, -2.2849e-01,  1.5232e-01,\n                       2.9728e-01, -8.0962e-02, -2.6122e-01, -2.2531e-02, -4.3568e-01,\n                       4.5757e-02,  3.6668e-01,  7.1696e-01,  3.3430e-01,  1.0712e-01,\n                      -3.4559e-01,  2.0120e-01,  1.9433e-02, -2.9892e-01, -1.7277e-01,\n                       1.1715e-01,  7.1933e-01, -1.6211e-01,  2.4701e-01,  7.9156e-02,\n                      -2.2194e-01,  2.5696e-02, -2.0928e-01, -2.3847e-01,  9.2383e-01,\n                      -1.7176e-01,  1.0379e-01,  6.6398e-01,  2.1299e-01,  1.8118e-01,\n                       2.3779e-01,  2.5162e-01,  2.6358e-01, -2.9817e-01,  7.9486e-02,\n                       3.7910e-01, -3.0363e-01, -8.4003e-02,  1.4260e-01, -1.8461e-01,\n                      -5.7784e-02, -3.6613e-01,  5.5125e-02, -2.4391e-02, -8.7965e-03,\n                       2.8361e-01, -2.9177e-01, -5.0725e-01,  1.2631e-01, -9.1693e-01,\n                      -2.3704e-01,  8.8452e-02,  6.6346e-02, -2.1333e-01, -1.7179e-01,\n                      -3.4002e-01,  2.6617e-01,  2.9861e-01, -1.9910e-01,  7.3577e-01,\n                      -6.6514e-01, -6.6696e-01, -1.2186e-01, -2.1923e-02,  2.9851e-01,\n                       5.2749e-01, -5.0299e-01,  2.8115e-01,  1.4221e-01, -9.6480e-02,\n                       1.3441e-02,  7.7165e-01, -3.9838e-01,  3.2533e-01,  6.7849e-01,\n                       3.1344e-01, -3.0429e-01,  3.4668e-01,  4.9948e-01, -4.2529e-03,\n                       1.2933e-01, -3.9582e-01, -4.5942e-02,  1.0172e-01,  2.3336e-01,\n                       3.4618e-01, -1.2381e-01, -1.1693e-01,  4.2156e-01, -3.8208e-01,\n                      -1.0009e-01, -1.5718e-01,  3.1867e-01, -1.1720e-01, -5.1834e-01,\n                      -7.3052e-01, -6.5495e-01,  1.2811e-02, -4.4319e-01,  3.0355e-02,\n                      -6.1308e-02, -1.8974e-01,  2.6507e-01,  1.2711e-01, -9.4675e-01,\n                       2.1744e-01,  4.1437e-01, -5.0084e-02, -2.2246e-02, -2.5358e-01,\n                       2.5616e-01, -1.9389e-02, -8.3695e-02,  3.4118e-01,  2.7205e-01,\n                       2.1946e-01, -1.6800e-01,  1.9707e-01,  4.7704e-01, -3.9518e-01,\n                       7.3016e-02, -8.7250e-02, -1.8092e-01, -1.2146e-01, -2.7383e-01,\n                       6.4702e-01,  2.3325e-01,  3.9800e-01, -1.2917e-01,  3.7474e-01,\n                       1.1956e-02, -6.1496e-02, -3.5286e-01,  8.4307e-01,  4.7302e-02,\n                       5.9140e-01, -4.7060e-01, -3.4064e-01,  3.2771e-01, -2.3994e-01,\n                       4.8034e-03], dtype=torch.float64)),\n             ('6.0.convs.2.1.running_var',\n              tensor([0.4599, 0.5193, 0.1771, 0.3985, 0.3347, 0.4226, 0.0982, 0.5156, 0.2875,\n                      0.3232, 0.3282, 0.1703, 0.2470, 0.2960, 0.5448, 0.2597, 0.2660, 0.3900,\n                      0.2569, 0.5238, 0.0803, 0.4508, 0.3527, 0.3910, 0.4835, 0.2329, 0.2399,\n                      0.3063, 0.2538, 0.3270, 0.3776, 0.7894, 0.0958, 0.3482, 0.3627, 0.3982,\n                      0.3632, 0.1164, 0.2070, 0.7324, 0.2148, 0.4183, 0.2143, 0.4552, 0.3814,\n                      0.2413, 0.3669, 0.1750, 0.2792, 0.2939, 0.3400, 0.2722, 0.3291, 0.2542,\n                      0.4558, 0.2856, 0.3468, 0.3955, 0.3432, 0.4203, 0.2492, 0.2213, 0.1166,\n                      0.0701, 0.4794, 0.3995, 0.2191, 0.2253, 0.4958, 0.2858, 0.3817, 0.3120,\n                      0.2565, 0.6139, 0.4735, 0.2196, 0.4406, 0.2112, 0.5700, 0.1907, 0.2953,\n                      0.2449, 0.3661, 0.4390, 0.3839, 0.5576, 0.3281, 0.4393, 0.5962, 0.3219,\n                      0.4640, 0.0764, 0.4195, 0.4952, 0.2798, 0.2425, 0.3840, 0.0467, 0.1646,\n                      0.1640, 0.2956, 0.1325, 0.1562, 0.1925, 0.3624, 0.3517, 0.3260, 0.4081,\n                      0.5305, 0.1350, 0.3864, 0.4156, 0.3144, 0.2105, 0.2436, 0.5096, 0.1165,\n                      0.1932, 0.1159, 0.4411, 0.2314, 0.5419, 0.6227, 0.2421, 0.3191, 0.4046,\n                      0.5738, 0.2892, 0.2561, 0.2780, 0.1976, 0.4282, 0.4484, 0.1573, 0.3482,\n                      0.3932, 0.3251, 0.1870, 0.5274, 0.4046, 0.4978, 0.0945, 0.5531, 0.1566,\n                      0.1519, 0.6283, 0.4106, 0.3108, 0.1662, 0.2684, 0.5077, 0.2172, 0.3048,\n                      0.2087, 0.3461, 0.3752, 0.2839, 0.1826, 0.3653, 0.0844, 0.4103, 0.3834,\n                      0.3789, 0.1545, 0.4832, 0.1594, 0.6762, 0.3914, 0.3739, 0.4262, 0.1582,\n                      0.0759, 0.1330, 0.2201, 0.6565, 0.4295, 0.4065, 0.3363, 0.4797, 0.2097,\n                      0.4579, 0.2470, 0.3006, 0.2201, 0.4440, 0.3853, 0.3628, 0.4775, 0.2904,\n                      0.1953, 0.5650, 0.7159, 0.2510, 0.4040, 0.3468, 0.4739, 0.2371, 0.1211,\n                      0.4130, 0.1939, 0.1427, 0.2667, 0.1371, 0.2859, 0.2738, 0.3903, 0.1401,\n                      0.1394, 0.1515, 0.5333, 0.3042, 0.2755, 0.2541, 0.3534, 0.0609, 0.3358,\n                      0.4918, 0.2806, 0.3696, 0.3182, 0.0893, 0.3698, 0.1025, 0.2177, 0.4522,\n                      0.2811, 0.1441, 0.2088, 0.3258, 0.3670, 0.1267, 0.2864, 0.4355, 0.2716,\n                      0.2503, 0.3426, 0.0957, 0.1857, 0.5993, 0.2882, 0.2578, 0.1556, 0.2994,\n                      0.2280, 0.3436, 0.1469, 0.3648, 0.3834, 0.6300, 0.4562, 0.3652, 0.5238,\n                      0.3307, 0.3367, 0.3825, 0.2320], dtype=torch.float64)),\n             ('6.0.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.0.convpath.0.0.0.weight',\n              tensor([[[-2.6970e-02],\n                       [-3.6803e-03],\n                       [-9.6383e-02],\n                       ...,\n                       [-2.8363e-02],\n                       [-1.4273e-01],\n                       [ 1.4194e-01]],\n              \n                      [[ 1.0622e-01],\n                       [-3.8758e-02],\n                       [ 3.5894e-05],\n                       ...,\n                       [-4.5822e-02],\n                       [-5.4668e-03],\n                       [ 7.9421e-03]],\n              \n                      [[-1.6322e-01],\n                       [-6.7668e-02],\n                       [-5.5133e-02],\n                       ...,\n                       [ 1.6949e-01],\n                       [-5.0897e-02],\n                       [-1.2894e-02]],\n              \n                      ...,\n              \n                      [[ 5.1697e-02],\n                       [-4.2094e-02],\n                       [-5.0710e-02],\n                       ...,\n                       [-2.0678e-01],\n                       [-7.9579e-03],\n                       [ 2.0308e-02]],\n              \n                      [[-7.3728e-02],\n                       [ 8.0049e-02],\n                       [-8.1751e-02],\n                       ...,\n                       [-5.0059e-02],\n                       [ 5.4614e-02],\n                       [-1.5907e-01]],\n              \n                      [[-7.7045e-02],\n                       [-1.1295e-01],\n                       [-8.1520e-02],\n                       ...,\n                       [-1.8396e-01],\n                       [ 3.8302e-02],\n                       [-6.1302e-02]]], dtype=torch.float64)),\n             ('6.0.convpath.0.0.1.weight',\n              tensor([0.9733, 0.9626, 0.9769, 0.9667, 0.9645, 0.9621, 0.9552, 0.9773, 0.9869,\n                      0.9764, 0.9850, 0.9834, 0.9512, 0.9561, 0.9595, 0.9639, 0.9866, 0.9504,\n                      0.9536, 0.9499, 0.9648, 0.9685, 0.9470, 0.9857, 0.9731, 0.9530, 0.9857,\n                      0.9613, 0.9664, 0.9704, 0.9583, 0.9523, 0.9583, 0.9381, 0.9631, 0.9477,\n                      0.9694, 0.9740, 0.9530, 0.9843, 0.9656, 0.9630, 0.9602, 0.9750, 0.9555,\n                      0.9664, 0.9937, 0.9696, 0.9714, 0.9809, 0.9755, 0.9606, 0.9642, 0.9594,\n                      0.9875, 0.9568, 0.9527, 0.9711, 0.9613, 0.9579, 0.9654, 0.9781, 0.9494,\n                      0.9917], dtype=torch.float64)),\n             ('6.0.convpath.0.0.1.bias',\n              tensor([ 0.0182,  0.0044,  0.0155,  0.0101, -0.0147,  0.0076,  0.0094,  0.0137,\n                       0.0094, -0.0042,  0.0171,  0.0154, -0.0050, -0.0074, -0.0044,  0.0118,\n                       0.0128,  0.0066, -0.0114, -0.0086, -0.0003,  0.0185,  0.0020, -0.0117,\n                       0.0092,  0.0183,  0.0128,  0.0075,  0.0061, -0.0046, -0.0017, -0.0059,\n                      -0.0078, -0.0038,  0.0109,  0.0027, -0.0155,  0.0233, -0.0079,  0.0159,\n                       0.0030, -0.0032, -0.0107,  0.0217, -0.0026, -0.0086,  0.0032,  0.0018,\n                       0.0169, -0.0049,  0.0017,  0.0022,  0.0052, -0.0124,  0.0073, -0.0054,\n                      -0.0144, -0.0094,  0.0048, -0.0039, -0.0202,  0.0241, -0.0054,  0.0164],\n                     dtype=torch.float64)),\n             ('6.0.convpath.0.0.1.running_mean',\n              tensor([-0.1898,  0.5286,  0.0335, -0.3213, -0.0168, -0.5279,  0.1501, -0.5237,\n                      -0.3966, -0.1989, -0.2629, -0.5886, -0.1360, -0.0880, -0.0809, -0.5115,\n                       0.3257, -0.5946,  0.4340,  0.1103, -0.3697, -1.0466, -0.5314,  0.9367,\n                      -0.1604, -0.5161, -0.5635, -0.1232,  0.2103,  0.4975, -0.0730, -0.8035,\n                       0.0293, -0.4794, -0.3607, -0.3912, -0.3421, -0.1106,  0.0427,  0.5211,\n                       0.3341, -0.2243, -0.1664,  0.5373, -0.6242,  0.2612, -0.0353, -0.0982,\n                      -0.6819,  0.1599, -0.7689,  0.3543,  0.6521, -0.1273, -0.2356,  0.3384,\n                       0.5187, -1.2648,  0.2145,  0.6314,  0.3822, -0.0959, -0.0830, -0.2557],\n                     dtype=torch.float64)),\n             ('6.0.convpath.0.0.1.running_var',\n              tensor([0.2949, 1.3506, 0.2095, 0.3228, 0.5939, 0.3086, 0.4491, 0.2959, 0.2250,\n                      0.2610, 0.2137, 0.3347, 0.4316, 0.3474, 0.2600, 0.4867, 0.1647, 0.4199,\n                      0.3177, 0.3693, 0.3048, 0.3139, 1.1285, 0.2792, 0.3162, 1.4534, 0.2276,\n                      0.3284, 0.5564, 0.6521, 0.2618, 0.6349, 1.4750, 1.1205, 0.4926, 0.3085,\n                      0.2899, 0.2563, 0.6309, 0.6086, 0.2059, 0.5342, 0.2046, 0.1553, 1.0869,\n                      0.2841, 0.2513, 0.2682, 0.4857, 0.2348, 0.2554, 0.4058, 0.8443, 0.3353,\n                      0.2551, 0.6225, 0.5646, 0.4638, 0.4132, 0.6166, 0.3495, 0.5060, 0.3995,\n                      0.2474], dtype=torch.float64)),\n             ('6.0.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.0.convpath.0.1.0.weight',\n              tensor([[[ 1.4300e-02, -1.6613e-01,  5.0351e-02, -1.1099e-02,  8.5365e-02],\n                       [ 9.8312e-02, -5.9451e-02, -6.2093e-02,  7.6365e-02, -2.1359e-02],\n                       [ 5.0143e-02,  5.1288e-02, -2.1402e-02,  4.7861e-02,  1.2735e-01],\n                       ...,\n                       [ 6.7171e-03,  2.4499e-02, -1.1445e-01, -4.8095e-02,  2.6229e-03],\n                       [-8.1411e-02,  8.6263e-02, -5.1260e-03,  2.5771e-02,  7.8661e-02],\n                       [ 7.6977e-02, -7.4010e-02,  9.6184e-02, -1.4804e-01, -3.4727e-02]],\n              \n                      [[ 4.5393e-02, -6.0341e-02, -8.4389e-02,  8.6802e-02, -1.6013e-01],\n                       [-7.9932e-02, -7.5873e-02,  9.5843e-02, -7.6574e-02, -1.0187e-01],\n                       [-3.2304e-02,  5.7686e-02,  1.2541e-01, -1.9176e-02,  1.6634e-02],\n                       ...,\n                       [-3.3401e-02, -7.0081e-02, -3.1010e-02, -9.2812e-02,  1.9510e-02],\n                       [ 8.3299e-02, -4.3040e-05, -3.2365e-02, -3.8651e-02, -4.2099e-02],\n                       [-1.7246e-02, -2.4016e-02, -3.8546e-02, -9.4165e-03,  7.8797e-02]],\n              \n                      [[ 5.0659e-02,  2.5301e-02,  4.9000e-02,  5.0935e-02, -1.6699e-02],\n                       [ 4.4271e-02,  5.2339e-02, -2.9406e-02, -6.1004e-02, -1.2174e-02],\n                       [-1.2739e-01, -1.8848e-01, -1.0607e-01,  5.7483e-02,  8.0239e-02],\n                       ...,\n                       [ 1.0591e-01, -4.4503e-02, -6.2935e-03,  1.1126e-01, -3.5547e-02],\n                       [-3.0620e-02,  1.0402e-01,  3.6872e-02,  2.0736e-02,  1.7067e-01],\n                       [-4.7079e-02,  5.9846e-02, -6.3831e-02, -3.8970e-02,  2.5046e-02]],\n              \n                      ...,\n              \n                      [[ 7.7700e-03,  1.1718e-01,  1.7228e-02, -1.5217e-02,  5.0478e-02],\n                       [-8.2533e-03, -6.7451e-02, -5.0580e-02, -3.5622e-02,  7.3493e-02],\n                       [ 6.5439e-02, -1.9100e-02, -1.4990e-02,  2.9701e-02, -1.0450e-01],\n                       ...,\n                       [-3.1419e-02, -6.2197e-02,  8.9559e-02,  1.3460e-01, -5.9444e-02],\n                       [ 8.3296e-02, -1.0445e-01, -1.3977e-02, -1.0446e-01, -1.7055e-02],\n                       [ 6.5726e-02,  9.9994e-02,  4.3117e-02, -4.6600e-02, -2.3974e-02]],\n              \n                      [[-1.0273e-01, -3.1845e-03, -5.8346e-02, -4.4879e-02,  1.1000e-01],\n                       [ 7.2528e-02, -9.8926e-02, -1.2251e-01, -7.4172e-02, -2.3046e-02],\n                       [-1.9921e-02, -2.2300e-02,  2.7006e-02, -8.2926e-02, -1.2887e-01],\n                       ...,\n                       [ 2.0463e-02, -5.8621e-02, -1.0312e-02,  6.3664e-02, -1.7162e-03],\n                       [-1.1698e-02, -2.3072e-02, -1.0209e-01, -1.2406e-01, -1.1682e-01],\n                       [-2.1273e-03,  3.7681e-02, -5.7927e-02, -5.5688e-02,  3.9049e-02]],\n              \n                      [[ 4.1006e-02, -6.9948e-02, -2.2717e-02, -6.7585e-02, -3.9872e-03],\n                       [-3.9864e-02,  2.0570e-02,  1.7803e-02,  6.2099e-03,  4.8159e-02],\n                       [-3.3721e-03,  9.4295e-02, -4.7379e-02, -6.8278e-02,  8.1723e-02],\n                       ...,\n                       [-9.0028e-02, -6.6673e-02,  9.1409e-02, -1.8492e-02,  1.9293e-02],\n                       [ 7.0934e-02,  4.6042e-02, -8.1902e-02, -1.1503e-01,  2.0710e-02],\n                       [-1.5933e-02,  3.1570e-02,  7.1365e-02, -2.3068e-01,  2.7605e-02]]],\n                     dtype=torch.float64)),\n             ('6.0.convpath.0.1.1.weight',\n              tensor([0.9772, 0.9657, 0.9904, 0.9677, 0.9467, 0.9760, 0.9845, 0.9339, 0.9552,\n                      0.9730, 0.9871, 0.9569, 0.9616, 0.9632, 0.9808, 0.9587, 0.9529, 0.9390,\n                      0.9686, 0.9313, 0.9522, 0.9481, 0.9594, 0.9552, 0.9837, 0.9258, 0.9615,\n                      0.9435, 0.9587, 0.9819, 0.9615, 0.9618, 0.9489, 0.9698, 0.9545, 0.9801,\n                      0.9747, 0.9557, 0.9573, 0.9640, 0.9726, 0.9735, 0.9665, 0.9526, 0.9606,\n                      0.9738, 0.9691, 0.9582, 0.9767, 0.9587, 0.9691, 0.9865, 0.9445, 0.9475,\n                      0.9505, 0.9650, 0.9384, 0.9429, 0.9540, 0.9639, 0.9670, 0.9594, 0.9721,\n                      0.9555], dtype=torch.float64)),\n             ('6.0.convpath.0.1.1.bias',\n              tensor([-0.0031, -0.0078, -0.0057, -0.0053, -0.0112, -0.0063,  0.0148, -0.0183,\n                      -0.0160,  0.0005,  0.0039, -0.0100,  0.0104,  0.0115,  0.0040, -0.0104,\n                      -0.0144,  0.0034,  0.0005, -0.0205, -0.0027,  0.0125,  0.0045, -0.0064,\n                       0.0177, -0.0131,  0.0071, -0.0039, -0.0167,  0.0071, -0.0171, -0.0294,\n                      -0.0149,  0.0221, -0.0059, -0.0067,  0.0125, -0.0113,  0.0044,  0.0022,\n                      -0.0059, -0.0090,  0.0185, -0.0149, -0.0038,  0.0002, -0.0040, -0.0058,\n                      -0.0019, -0.0136,  0.0111, -0.0298, -0.0237, -0.0047,  0.0010,  0.0101,\n                      -0.0135, -0.0108, -0.0042,  0.0065, -0.0105, -0.0132, -0.0063,  0.0028],\n                     dtype=torch.float64)),\n             ('6.0.convpath.0.1.1.running_mean',\n              tensor([ 0.4012, -0.4091,  0.0604, -0.4854, -0.2893, -0.1028, -0.0115,  0.3455,\n                      -0.0449,  0.4850,  0.4138, -0.5967,  0.3608, -0.8848, -0.5577,  0.3049,\n                       0.1373, -0.1257, -0.4323, -0.3823,  0.4486, -0.7119,  0.0787,  0.1405,\n                       0.5263, -0.9175, -0.6052,  0.6887, -1.0031,  0.0758,  0.3468,  0.2492,\n                       0.0186,  0.0636, -0.5071,  0.6360,  0.8923, -0.8908,  0.4495,  0.2354,\n                       0.0971,  0.2575,  0.8363, -0.0414, -0.3072, -0.0315, -0.4707,  0.4006,\n                       0.7368,  0.1495,  0.1364,  0.8887, -0.5170, -0.3615, -0.3102, -0.4515,\n                      -0.9232, -0.9359,  0.2585, -0.4430, -0.0661, -0.2814, -0.2297, -0.1975],\n                     dtype=torch.float64)),\n             ('6.0.convpath.0.1.1.running_var',\n              tensor([0.4697, 0.3462, 0.6115, 0.6543, 0.3535, 0.8766, 0.4727, 0.5686, 0.3484,\n                      0.3092, 0.3595, 0.7819, 0.5885, 0.4289, 0.3098, 0.7597, 0.7137, 0.4922,\n                      0.5136, 0.5295, 0.6163, 0.5648, 0.4553, 0.3683, 0.4510, 0.5584, 0.2478,\n                      0.6515, 0.8206, 0.4619, 0.5173, 0.3721, 0.5299, 0.4317, 0.5280, 0.5363,\n                      0.5326, 0.4945, 0.4166, 0.4753, 0.4615, 0.4844, 0.4739, 0.5528, 0.5394,\n                      0.3477, 0.4482, 0.7215, 0.3526, 0.5556, 0.4774, 0.4855, 0.4149, 0.5104,\n                      0.4351, 0.5948, 0.3415, 0.4312, 0.6211, 0.6765, 0.4514, 0.6177, 0.6639,\n                      0.5058], dtype=torch.float64)),\n             ('6.0.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.0.convpath.0.2.0.weight',\n              tensor([[[ 0.2423],\n                       [ 0.0678],\n                       [-0.1224],\n                       ...,\n                       [-0.0126],\n                       [ 0.0016],\n                       [ 0.0017]],\n              \n                      [[-0.2289],\n                       [-0.2979],\n                       [ 0.2175],\n                       ...,\n                       [ 0.1080],\n                       [ 0.1306],\n                       [-0.1502]],\n              \n                      [[ 0.0911],\n                       [ 0.0726],\n                       [-0.1599],\n                       ...,\n                       [-0.0212],\n                       [-0.0425],\n                       [-0.0222]],\n              \n                      ...,\n              \n                      [[-0.0237],\n                       [-0.0678],\n                       [-0.0063],\n                       ...,\n                       [-0.0885],\n                       [-0.0355],\n                       [ 0.0205]],\n              \n                      [[-0.0423],\n                       [-0.0107],\n                       [ 0.1330],\n                       ...,\n                       [ 0.0471],\n                       [ 0.0839],\n                       [ 0.0514]],\n              \n                      [[ 0.0804],\n                       [-0.0290],\n                       [ 0.0372],\n                       ...,\n                       [ 0.1110],\n                       [-0.1031],\n                       [-0.1347]]], dtype=torch.float64)),\n             ('6.0.convpath.0.2.1.weight',\n              tensor([ 1.2589e-02,  2.2134e-02,  1.4982e-03, -1.0002e-02,  6.8350e-03,\n                       2.7259e-02, -5.5047e-03,  2.3923e-02,  3.1186e-03,  8.5064e-03,\n                       4.6943e-03,  4.6265e-03,  1.0152e-02, -3.9186e-03,  9.8827e-03,\n                      -1.4132e-02,  9.0858e-03,  2.4119e-02,  1.4784e-02, -1.1469e-02,\n                      -3.4464e-04, -3.3942e-02, -1.4982e-02, -1.0714e-02,  3.3634e-02,\n                       2.5132e-02,  5.9036e-03, -1.7812e-03,  1.6919e-03, -1.0305e-02,\n                      -2.4515e-02, -2.3907e-02, -3.6213e-04,  8.4237e-03,  1.2070e-02,\n                      -1.4688e-02, -7.5030e-03,  1.1786e-04,  1.5954e-02,  5.4133e-03,\n                       6.0047e-03, -1.1529e-02,  1.0736e-02,  1.5569e-02, -8.1443e-03,\n                      -7.4892e-04, -1.5531e-02, -5.7282e-03,  3.9492e-03,  2.4710e-03,\n                      -2.0063e-02, -6.8316e-03, -2.2209e-04, -2.2354e-02, -1.4528e-02,\n                      -8.2951e-03,  1.7758e-02, -4.2690e-02, -6.2631e-03,  1.1134e-02,\n                       8.9511e-03,  1.2944e-02,  8.3517e-03, -2.1371e-03,  1.9489e-02,\n                       2.2800e-02, -1.3371e-02, -1.2709e-02,  2.6410e-02, -6.7265e-03,\n                      -1.2115e-02, -8.9795e-03, -1.9000e-02,  1.3643e-02, -9.7831e-03,\n                       1.9139e-02,  2.4012e-02,  1.2607e-02, -1.0823e-02, -2.0259e-02,\n                      -5.5155e-03,  1.7089e-02, -4.3870e-02,  3.0878e-02, -3.4828e-02,\n                      -1.5229e-02,  3.0851e-02, -4.7761e-04, -1.1347e-02, -1.7289e-02,\n                      -4.4876e-02, -6.5281e-04,  1.4520e-02, -5.4784e-03, -3.5537e-03,\n                       3.5752e-03, -3.5605e-02,  1.0840e-03, -1.0007e-03,  2.8729e-02,\n                       4.6823e-03,  8.1020e-03, -2.9972e-03,  1.0286e-02,  2.3756e-02,\n                      -1.4443e-02, -1.1917e-02,  1.3830e-02, -2.6427e-02, -7.4733e-03,\n                      -6.5341e-03,  1.2077e-03,  3.8398e-03,  1.7993e-03,  2.8002e-02,\n                      -1.2012e-02,  6.8674e-03,  4.1180e-03, -4.9496e-04, -1.0257e-02,\n                       1.6305e-02,  2.9369e-02, -9.3340e-03, -5.2921e-03,  1.5934e-02,\n                       1.8353e-02,  3.3962e-03, -1.7315e-02, -2.1504e-03,  3.9781e-04,\n                      -3.2770e-03, -1.8545e-02, -5.0681e-03, -2.8501e-03,  1.6818e-02,\n                      -1.2274e-02,  4.5861e-02, -7.9423e-03,  2.3305e-02,  5.1455e-04,\n                       1.6888e-02,  1.4197e-03,  1.3604e-02,  9.6374e-06,  3.4015e-03,\n                      -2.8965e-02,  7.6350e-03,  3.1075e-03,  5.1877e-03, -6.5824e-05,\n                      -1.2750e-02,  6.0342e-03,  2.4308e-02, -8.0952e-03, -8.7356e-03,\n                      -1.3684e-02, -8.3638e-03,  2.8634e-03, -1.5896e-02, -8.8031e-04,\n                       7.4047e-03,  1.2607e-02,  8.0281e-03,  1.4698e-03,  4.7841e-02,\n                       9.1095e-03,  9.1333e-03,  2.7199e-02, -2.4835e-02, -2.3206e-02,\n                       1.2201e-03, -8.6248e-04, -6.3817e-03,  8.6714e-03,  2.6644e-03,\n                      -8.8644e-03,  8.3611e-03, -1.3300e-02, -1.9668e-02, -2.8264e-02,\n                       3.8536e-02,  1.5099e-02, -7.0421e-03, -3.5954e-03, -8.5808e-03,\n                       1.4133e-02,  9.7383e-03,  2.9362e-02,  1.6455e-02, -2.0519e-03,\n                       1.9844e-02,  1.4509e-02, -4.7951e-03, -3.7688e-02,  1.7180e-02,\n                      -1.8202e-02, -2.2994e-03, -9.3939e-04, -1.7049e-02,  9.0388e-03,\n                      -1.1602e-02,  2.0356e-02,  7.4361e-04, -1.5174e-02,  4.6653e-03,\n                       1.4713e-02,  4.4670e-03,  7.0714e-03,  1.1514e-03,  1.8712e-02,\n                       1.5238e-02, -6.4437e-03, -8.1187e-03, -1.1528e-03,  5.1901e-04,\n                      -3.4911e-03, -8.2275e-03,  1.0125e-02,  3.6172e-02,  1.1648e-02,\n                      -1.4007e-03, -1.9274e-02,  2.6684e-03,  9.2241e-03,  1.9817e-02,\n                       1.3887e-02,  3.9888e-03,  1.5255e-03, -6.2476e-03,  6.0278e-03,\n                       2.5531e-02, -1.1539e-02, -1.4804e-02,  1.4940e-02, -1.3097e-02,\n                       1.2203e-02, -1.5113e-03, -1.0267e-02,  2.2433e-02, -5.5860e-03,\n                       5.8517e-03,  4.7929e-03,  3.0242e-02,  1.7900e-02,  1.5140e-02,\n                      -5.5452e-03, -2.2973e-02, -1.9603e-02,  1.2895e-02, -3.6269e-02,\n                      -5.9550e-03,  9.1785e-03,  1.6192e-02, -4.8521e-03,  3.8073e-02,\n                       1.1540e-02], dtype=torch.float64)),\n             ('6.0.convpath.0.2.1.bias',\n              tensor([-2.6710e-03, -4.4757e-03,  1.9047e-02,  7.9802e-03,  4.5639e-03,\n                       6.3193e-03,  2.1594e-02,  3.1125e-04,  1.1535e-02,  2.0684e-02,\n                       1.0022e-02, -7.4316e-03,  1.3917e-02, -8.1055e-03,  6.9060e-03,\n                       9.1917e-03,  1.7281e-02,  1.3197e-03,  1.6949e-02, -7.9680e-03,\n                      -2.1120e-03,  4.7207e-03,  2.7994e-03,  6.7468e-03, -2.9368e-03,\n                      -1.3028e-02,  6.3551e-03,  1.0486e-02,  3.2672e-03,  6.2418e-04,\n                      -9.8721e-03,  8.7850e-03, -8.5806e-03,  1.5453e-02,  1.8509e-02,\n                      -4.5585e-03,  5.0924e-03,  2.6859e-02,  1.3148e-02,  1.4147e-02,\n                       9.4985e-04, -1.4161e-02, -6.3559e-03,  2.4406e-03,  1.2313e-02,\n                      -1.1858e-02,  1.4381e-02,  6.8018e-03, -1.1003e-02, -1.6633e-03,\n                       3.7283e-03,  2.5442e-03,  8.2851e-03,  2.1109e-02, -1.8510e-03,\n                      -2.5443e-03,  8.0939e-03,  7.5784e-03,  7.7029e-03,  8.8865e-03,\n                      -6.5805e-03,  2.9684e-03,  4.4420e-03,  1.0176e-02, -3.2072e-03,\n                       1.5495e-02, -1.1231e-02,  1.4449e-02, -2.0563e-03, -9.1886e-03,\n                       3.8787e-03,  1.0248e-02,  1.3782e-02, -7.9940e-03,  1.4503e-02,\n                       1.4225e-02,  2.1259e-03, -7.5022e-03,  3.2457e-03,  7.0246e-03,\n                       1.1919e-02, -5.5552e-03,  7.4540e-03,  5.7170e-03, -1.4955e-03,\n                       4.2297e-03,  6.4495e-03,  3.8244e-03,  9.0017e-03,  6.0969e-03,\n                      -1.6878e-03,  2.0648e-02,  1.8853e-02, -7.4074e-04,  5.3471e-03,\n                      -1.6457e-02,  5.8088e-03,  6.4733e-03,  1.1973e-02, -2.4289e-03,\n                       2.6342e-02,  7.8291e-03, -1.6686e-03, -2.0576e-02,  1.4190e-02,\n                       1.0357e-03,  6.9472e-03, -2.2884e-03,  3.9864e-03,  6.8144e-03,\n                      -7.6664e-03, -6.1410e-03,  6.2409e-03,  1.5377e-02,  6.4755e-03,\n                       8.0066e-03,  1.0746e-02,  2.5508e-03,  1.1056e-03, -1.4409e-02,\n                       5.7554e-03,  1.4332e-02, -2.3352e-05,  1.4963e-03, -1.2396e-02,\n                       1.3699e-02,  1.3938e-02,  1.8219e-03,  1.0190e-03,  9.8542e-03,\n                      -9.5031e-04,  7.4841e-03,  1.3461e-02,  1.1462e-02,  9.5348e-03,\n                      -3.4521e-04,  1.0565e-03,  7.6090e-03,  1.2472e-02,  6.2729e-03,\n                      -2.0479e-03, -3.3668e-03, -1.0103e-03,  9.5984e-03, -7.3289e-03,\n                      -5.4630e-03,  4.4780e-03,  1.0373e-03,  1.2046e-02,  1.0613e-02,\n                       1.7689e-03,  1.2276e-02,  5.7251e-03,  1.5362e-02,  1.8950e-02,\n                       1.6699e-02,  2.9974e-04,  1.0392e-02,  4.4700e-04, -1.4558e-02,\n                      -5.9215e-04,  1.6275e-03, -1.7849e-03,  1.7888e-02,  6.5666e-03,\n                       3.5940e-03, -7.0571e-03,  1.2028e-02,  8.0600e-03,  1.5393e-02,\n                       5.2645e-03,  9.0200e-03,  1.3390e-02,  8.2356e-03, -1.3984e-02,\n                      -5.1562e-03, -3.5023e-03,  2.1900e-02,  5.7860e-03,  4.3705e-03,\n                      -1.6601e-03,  1.1240e-02, -8.0598e-03, -9.8081e-03,  1.9230e-02,\n                       3.0851e-03,  1.0214e-02,  1.9930e-02, -3.7627e-03,  2.7477e-03,\n                       5.6262e-03, -3.0982e-03,  1.4564e-02, -1.3703e-02,  1.1121e-02,\n                       8.4436e-03, -4.9463e-03,  1.4878e-02,  8.7587e-03, -8.2572e-03,\n                       3.3886e-03,  8.7394e-03,  2.0713e-02,  1.7387e-02,  5.7210e-03,\n                      -7.1348e-03,  1.4240e-02, -1.4810e-03,  2.3217e-03,  6.9327e-03,\n                       1.6514e-03,  1.3766e-02,  1.5536e-02,  6.6130e-03,  6.5846e-03,\n                       9.7555e-03,  1.0358e-03, -3.1396e-04,  8.0360e-03, -8.6887e-04,\n                      -8.7640e-03, -4.5100e-03,  7.0237e-03,  2.5777e-02, -7.0481e-03,\n                       6.4169e-03, -6.4992e-04,  2.9110e-03, -1.9480e-02,  1.8421e-03,\n                       1.8544e-02,  2.1945e-03,  1.0925e-02,  1.0034e-02,  1.1152e-02,\n                       3.1598e-03,  6.4625e-03, -1.0455e-03,  3.6897e-03,  6.7947e-03,\n                       8.3055e-03,  3.0324e-03,  2.5599e-03,  8.1136e-03,  5.6226e-03,\n                       1.3669e-02,  6.1828e-03,  9.1897e-03,  2.3778e-03, -6.4222e-03,\n                       1.5377e-02,  7.6411e-03,  1.5317e-02,  2.3442e-02,  1.7283e-02,\n                       1.1949e-03], dtype=torch.float64)),\n             ('6.0.convpath.0.2.1.running_mean',\n              tensor([ 3.6377e-01,  1.7554e-02, -2.6962e-01, -4.1481e-01, -1.6189e-01,\n                       5.0392e-01,  1.7596e-01, -7.0541e-01,  7.0634e-01,  4.5587e-01,\n                       5.4911e-01,  1.8238e-01,  3.1880e-01,  5.5257e-01,  7.2893e-01,\n                       6.6627e-01, -4.4744e-02, -2.5096e-01, -4.2137e-01,  1.9596e-01,\n                      -1.1878e-03,  3.9145e-01,  7.4479e-01, -2.1830e-01, -3.9026e-01,\n                      -1.2492e-01,  4.7468e-01,  9.5392e-02,  1.8119e-01, -3.9681e-01,\n                      -2.7664e-01,  1.2552e+00, -2.8184e-01, -5.0011e-01, -3.7969e-01,\n                       5.1232e-01,  2.9533e-01, -3.7860e-01, -5.1598e-01, -1.8300e-01,\n                       4.3152e-03,  1.4463e-01, -4.2384e-01, -3.6366e-02,  1.5020e-01,\n                      -4.9829e-01, -4.0840e-01, -2.5977e-01, -5.3684e-01,  6.8666e-01,\n                       1.9049e-01, -8.3944e-01, -4.2900e-01,  1.4235e-01, -4.6562e-01,\n                       3.2655e-01, -5.0138e-01,  5.2629e-01, -3.9421e-01,  3.3558e-02,\n                       7.4408e-02,  3.9566e-01, -4.2918e-02, -2.3454e-01,  1.0313e-01,\n                       4.8544e-02, -3.6417e-01,  3.7146e-01, -6.2069e-01, -2.9958e-01,\n                      -3.2694e-01,  2.6089e-01,  4.2522e-02, -5.6105e-02, -2.9843e-01,\n                       5.4353e-01,  1.1431e-01, -3.2288e-01, -5.9292e-02,  1.4410e-01,\n                       1.4594e-01,  3.7571e-01,  6.5166e-01, -1.1116e-01,  1.0201e-01,\n                      -1.6946e-01, -3.1272e-01,  9.3765e-01,  2.0867e-01, -2.5698e-01,\n                       6.0670e-03,  1.0732e-01,  3.0473e-01, -8.4131e-02,  1.2448e-02,\n                       4.8148e-03,  5.3295e-01,  1.3120e-01,  2.2328e-01,  2.4700e-01,\n                      -4.6290e-01,  1.7772e-01,  8.1894e-02, -1.4177e-01, -1.0934e-01,\n                      -4.4043e-02, -3.7988e-01,  6.7852e-01,  6.6260e-01,  4.4203e-01,\n                       3.3434e-01, -2.4067e-01,  2.0392e-01, -2.2849e-01,  1.5232e-01,\n                       2.9728e-01, -8.0962e-02, -2.6122e-01, -2.2531e-02, -4.3568e-01,\n                       4.5757e-02,  3.6668e-01,  7.1696e-01,  3.3430e-01,  1.0712e-01,\n                      -3.4559e-01,  2.0120e-01,  1.9433e-02, -2.9892e-01, -1.7277e-01,\n                       1.1715e-01,  7.1933e-01, -1.6211e-01,  2.4701e-01,  7.9156e-02,\n                      -2.2194e-01,  2.5696e-02, -2.0928e-01, -2.3847e-01,  9.2383e-01,\n                      -1.7176e-01,  1.0379e-01,  6.6398e-01,  2.1299e-01,  1.8118e-01,\n                       2.3779e-01,  2.5162e-01,  2.6358e-01, -2.9817e-01,  7.9486e-02,\n                       3.7910e-01, -3.0363e-01, -8.4003e-02,  1.4260e-01, -1.8461e-01,\n                      -5.7784e-02, -3.6613e-01,  5.5125e-02, -2.4391e-02, -8.7965e-03,\n                       2.8361e-01, -2.9177e-01, -5.0725e-01,  1.2631e-01, -9.1693e-01,\n                      -2.3704e-01,  8.8452e-02,  6.6346e-02, -2.1333e-01, -1.7179e-01,\n                      -3.4002e-01,  2.6617e-01,  2.9861e-01, -1.9910e-01,  7.3577e-01,\n                      -6.6514e-01, -6.6696e-01, -1.2186e-01, -2.1923e-02,  2.9851e-01,\n                       5.2749e-01, -5.0299e-01,  2.8115e-01,  1.4221e-01, -9.6480e-02,\n                       1.3441e-02,  7.7165e-01, -3.9838e-01,  3.2533e-01,  6.7849e-01,\n                       3.1344e-01, -3.0429e-01,  3.4668e-01,  4.9948e-01, -4.2529e-03,\n                       1.2933e-01, -3.9582e-01, -4.5942e-02,  1.0172e-01,  2.3336e-01,\n                       3.4618e-01, -1.2381e-01, -1.1693e-01,  4.2156e-01, -3.8208e-01,\n                      -1.0009e-01, -1.5718e-01,  3.1867e-01, -1.1720e-01, -5.1834e-01,\n                      -7.3052e-01, -6.5495e-01,  1.2811e-02, -4.4319e-01,  3.0355e-02,\n                      -6.1308e-02, -1.8974e-01,  2.6507e-01,  1.2711e-01, -9.4675e-01,\n                       2.1744e-01,  4.1437e-01, -5.0084e-02, -2.2246e-02, -2.5358e-01,\n                       2.5616e-01, -1.9389e-02, -8.3695e-02,  3.4118e-01,  2.7205e-01,\n                       2.1946e-01, -1.6800e-01,  1.9707e-01,  4.7704e-01, -3.9518e-01,\n                       7.3016e-02, -8.7250e-02, -1.8092e-01, -1.2146e-01, -2.7383e-01,\n                       6.4702e-01,  2.3325e-01,  3.9800e-01, -1.2917e-01,  3.7474e-01,\n                       1.1956e-02, -6.1496e-02, -3.5286e-01,  8.4307e-01,  4.7302e-02,\n                       5.9140e-01, -4.7060e-01, -3.4064e-01,  3.2771e-01, -2.3994e-01,\n                       4.8034e-03], dtype=torch.float64)),\n             ('6.0.convpath.0.2.1.running_var',\n              tensor([0.4599, 0.5193, 0.1771, 0.3985, 0.3347, 0.4226, 0.0982, 0.5156, 0.2875,\n                      0.3232, 0.3282, 0.1703, 0.2470, 0.2960, 0.5448, 0.2597, 0.2660, 0.3900,\n                      0.2569, 0.5238, 0.0803, 0.4508, 0.3527, 0.3910, 0.4835, 0.2329, 0.2399,\n                      0.3063, 0.2538, 0.3270, 0.3776, 0.7894, 0.0958, 0.3482, 0.3627, 0.3982,\n                      0.3632, 0.1164, 0.2070, 0.7324, 0.2148, 0.4183, 0.2143, 0.4552, 0.3814,\n                      0.2413, 0.3669, 0.1750, 0.2792, 0.2939, 0.3400, 0.2722, 0.3291, 0.2542,\n                      0.4558, 0.2856, 0.3468, 0.3955, 0.3432, 0.4203, 0.2492, 0.2213, 0.1166,\n                      0.0701, 0.4794, 0.3995, 0.2191, 0.2253, 0.4958, 0.2858, 0.3817, 0.3120,\n                      0.2565, 0.6139, 0.4735, 0.2196, 0.4406, 0.2112, 0.5700, 0.1907, 0.2953,\n                      0.2449, 0.3661, 0.4390, 0.3839, 0.5576, 0.3281, 0.4393, 0.5962, 0.3219,\n                      0.4640, 0.0764, 0.4195, 0.4952, 0.2798, 0.2425, 0.3840, 0.0467, 0.1646,\n                      0.1640, 0.2956, 0.1325, 0.1562, 0.1925, 0.3624, 0.3517, 0.3260, 0.4081,\n                      0.5305, 0.1350, 0.3864, 0.4156, 0.3144, 0.2105, 0.2436, 0.5096, 0.1165,\n                      0.1932, 0.1159, 0.4411, 0.2314, 0.5419, 0.6227, 0.2421, 0.3191, 0.4046,\n                      0.5738, 0.2892, 0.2561, 0.2780, 0.1976, 0.4282, 0.4484, 0.1573, 0.3482,\n                      0.3932, 0.3251, 0.1870, 0.5274, 0.4046, 0.4978, 0.0945, 0.5531, 0.1566,\n                      0.1519, 0.6283, 0.4106, 0.3108, 0.1662, 0.2684, 0.5077, 0.2172, 0.3048,\n                      0.2087, 0.3461, 0.3752, 0.2839, 0.1826, 0.3653, 0.0844, 0.4103, 0.3834,\n                      0.3789, 0.1545, 0.4832, 0.1594, 0.6762, 0.3914, 0.3739, 0.4262, 0.1582,\n                      0.0759, 0.1330, 0.2201, 0.6565, 0.4295, 0.4065, 0.3363, 0.4797, 0.2097,\n                      0.4579, 0.2470, 0.3006, 0.2201, 0.4440, 0.3853, 0.3628, 0.4775, 0.2904,\n                      0.1953, 0.5650, 0.7159, 0.2510, 0.4040, 0.3468, 0.4739, 0.2371, 0.1211,\n                      0.4130, 0.1939, 0.1427, 0.2667, 0.1371, 0.2859, 0.2738, 0.3903, 0.1401,\n                      0.1394, 0.1515, 0.5333, 0.3042, 0.2755, 0.2541, 0.3534, 0.0609, 0.3358,\n                      0.4918, 0.2806, 0.3696, 0.3182, 0.0893, 0.3698, 0.1025, 0.2177, 0.4522,\n                      0.2811, 0.1441, 0.2088, 0.3258, 0.3670, 0.1267, 0.2864, 0.4355, 0.2716,\n                      0.2503, 0.3426, 0.0957, 0.1857, 0.5993, 0.2882, 0.2578, 0.1556, 0.2994,\n                      0.2280, 0.3436, 0.1469, 0.3648, 0.3834, 0.6300, 0.4562, 0.3652, 0.5238,\n                      0.3307, 0.3367, 0.3825, 0.2320], dtype=torch.float64)),\n             ('6.0.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.1.convs.0.0.weight',\n              tensor([[[-0.0424],\n                       [-0.0052],\n                       [-0.0162],\n                       ...,\n                       [-0.0172],\n                       [ 0.0693],\n                       [ 0.1802]],\n              \n                      [[-0.1415],\n                       [-0.1271],\n                       [-0.0309],\n                       ...,\n                       [-0.0037],\n                       [-0.0752],\n                       [ 0.0457]],\n              \n                      [[-0.0204],\n                       [ 0.0124],\n                       [-0.0841],\n                       ...,\n                       [-0.0590],\n                       [ 0.0378],\n                       [-0.1357]],\n              \n                      ...,\n              \n                      [[ 0.0995],\n                       [-0.0427],\n                       [ 0.0297],\n                       ...,\n                       [ 0.0364],\n                       [-0.1483],\n                       [-0.0230]],\n              \n                      [[-0.0895],\n                       [-0.0080],\n                       [ 0.1440],\n                       ...,\n                       [-0.0309],\n                       [ 0.0486],\n                       [ 0.1555]],\n              \n                      [[ 0.0032],\n                       [ 0.0161],\n                       [ 0.1359],\n                       ...,\n                       [ 0.0351],\n                       [ 0.1254],\n                       [-0.0484]]], dtype=torch.float64)),\n             ('6.1.convs.0.1.weight',\n              tensor([0.9556, 1.0019, 1.0087, 0.9839, 0.9734, 0.9625, 0.9381, 0.9673, 0.9806,\n                      0.9546, 0.9805, 0.9785, 0.9709, 0.9602, 0.9621, 0.9622, 0.9760, 0.9791,\n                      0.9692, 0.9689, 0.9813, 0.9832, 0.9897, 0.9889, 1.0074, 1.0071, 1.0083,\n                      0.9977, 0.9713, 0.9936, 0.9776, 0.9781, 0.9790, 0.9894, 0.9832, 0.9624,\n                      0.9719, 0.9489, 0.9957, 0.9892, 0.9621, 0.9772, 0.9718, 0.9670, 0.9803,\n                      0.9713, 0.9949, 0.9753, 0.9575, 0.9799, 0.9770, 0.9585, 1.0001, 0.9882,\n                      0.9535, 0.9676, 0.9700, 0.9936, 0.9713, 0.9549, 0.9795, 0.9669, 0.9713,\n                      0.9849], dtype=torch.float64)),\n             ('6.1.convs.0.1.bias',\n              tensor([-0.0017, -0.0029, -0.0089,  0.0086,  0.0141, -0.0037, -0.0049, -0.0115,\n                      -0.0026, -0.0092, -0.0023,  0.0075,  0.0085, -0.0089, -0.0108, -0.0087,\n                      -0.0080, -0.0041, -0.0172, -0.0054,  0.0058,  0.0031, -0.0113,  0.0088,\n                       0.0167,  0.0095,  0.0253,  0.0136, -0.0010,  0.0148,  0.0083,  0.0097,\n                       0.0072,  0.0056,  0.0013, -0.0129, -0.0220, -0.0166,  0.0163, -0.0002,\n                      -0.0046, -0.0087, -0.0122, -0.0059,  0.0129,  0.0026,  0.0159, -0.0054,\n                      -0.0165, -0.0112,  0.0132,  0.0044,  0.0175,  0.0075, -0.0178, -0.0023,\n                      -0.0043,  0.0185, -0.0278, -0.0196,  0.0044, -0.0123,  0.0084, -0.0067],\n                     dtype=torch.float64)),\n             ('6.1.convs.0.1.running_mean',\n              tensor([-0.4150, -0.2880, -0.8945, -0.3042, -0.3209, -0.3696,  0.1797,  0.3235,\n                      -0.4861,  0.7383,  0.3577,  0.0531, -0.3761, -0.5580, -0.0362, -0.2112,\n                      -0.7140,  0.7089,  0.7538, -1.0949, -0.4426, -0.3842, -0.0116, -0.2084,\n                      -0.0925, -0.8444,  0.4087,  0.2340, -0.1648,  0.3386, -0.2307,  0.0546,\n                       0.4520, -0.2811, -0.0146,  0.2515,  0.3150, -0.3467, -0.4012, -0.5889,\n                      -0.3563,  0.1232,  0.3213,  0.2147, -0.1321,  0.8876,  0.4366, -0.4667,\n                      -0.2859, -0.2934, -0.5439,  0.3009, -0.2590, -0.5371, -0.6992, -0.2741,\n                       0.6387,  0.0014,  0.6532, -0.2137, -0.0535, -0.3523, -0.2007,  0.1740],\n                     dtype=torch.float64)),\n             ('6.1.convs.0.1.running_var',\n              tensor([0.1284, 0.1352, 0.1480, 0.4249, 0.1864, 0.1490, 1.1221, 0.1556, 0.1418,\n                      1.3059, 0.1094, 0.1480, 0.3749, 0.5922, 0.3826, 0.2936, 0.3074, 0.2663,\n                      1.5858, 0.1791, 0.1160, 0.1212, 0.1502, 0.2258, 0.1906, 0.1150, 0.2483,\n                      0.1860, 0.1966, 0.2237, 0.3810, 0.9359, 0.1306, 0.1491, 0.1347, 0.1381,\n                      0.3361, 0.3937, 0.2071, 0.2376, 0.1224, 0.1280, 0.1185, 0.3536, 0.1533,\n                      0.1641, 0.3471, 0.1896, 0.5365, 0.0846, 0.1462, 1.3340, 0.1304, 0.1195,\n                      0.3710, 0.1689, 1.0295, 0.2006, 0.3087, 0.1431, 0.1711, 0.1458, 0.6250,\n                      0.1392], dtype=torch.float64)),\n             ('6.1.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.1.convs.1.0.weight',\n              tensor([[[-2.0950e-01,  5.1853e-02,  1.7200e-01,  2.6316e-02, -5.6596e-03],\n                       [ 2.4236e-02, -9.5213e-02,  1.2029e-01,  5.4813e-02, -1.4749e-01],\n                       [-6.5424e-02, -4.0944e-02, -5.1758e-02, -1.0551e-01,  1.6669e-02],\n                       ...,\n                       [-1.6925e-01,  8.7979e-02, -1.0981e-01, -7.9609e-02,  9.7839e-02],\n                       [ 4.6368e-02, -7.2487e-04, -3.8773e-02, -1.1093e-02, -7.0569e-02],\n                       [-4.8690e-02,  1.0747e-01,  1.2215e-01,  9.5290e-02, -2.9760e-02]],\n              \n                      [[ 1.1572e-02,  1.5122e-02,  8.7048e-03,  4.8775e-02,  6.6929e-02],\n                       [ 6.1570e-02,  8.4607e-02, -1.7447e-02, -7.0495e-02,  2.7752e-02],\n                       [-8.2153e-02,  2.8278e-02, -2.8629e-02, -4.6675e-03, -5.0332e-02],\n                       ...,\n                       [-7.2105e-02,  5.4642e-02, -6.0589e-02,  2.0942e-02, -1.4742e-01],\n                       [-5.1720e-03,  4.9924e-02, -3.8816e-02,  6.6992e-02, -2.4088e-02],\n                       [ 1.6673e-02,  7.7642e-02, -1.8007e-02, -4.7000e-02, -4.6770e-02]],\n              \n                      [[ 1.0554e-01, -9.4840e-02,  3.5358e-02, -1.0092e-01, -1.0186e-02],\n                       [-1.1118e-01, -5.9017e-02, -4.2867e-02,  1.9443e-04,  1.7456e-02],\n                       [ 6.7793e-03,  6.9719e-02,  2.1501e-02, -5.2033e-02, -8.0415e-02],\n                       ...,\n                       [ 5.1017e-02, -7.1165e-02,  3.5667e-05, -3.5859e-02,  8.8855e-02],\n                       [-5.0787e-03, -8.2741e-02, -2.2271e-02, -1.3771e-03, -2.2313e-02],\n                       [-1.0266e-01, -8.2067e-03,  1.4628e-01,  7.0854e-02,  1.1533e-01]],\n              \n                      ...,\n              \n                      [[ 7.6572e-02, -1.0005e-01, -8.4468e-02, -6.6984e-02,  8.2237e-03],\n                       [-7.0071e-02, -4.2501e-02, -6.1198e-02,  2.0228e-02, -7.6715e-02],\n                       [ 1.0537e-01,  1.1839e-01, -2.3135e-02, -1.3043e-01,  5.2902e-03],\n                       ...,\n                       [-1.7547e-01,  3.9171e-02, -1.0876e-01,  6.3565e-02, -1.7522e-01],\n                       [ 6.0957e-02,  1.6996e-02,  2.4187e-02,  6.2424e-02,  1.1230e-01],\n                       [ 8.5341e-03,  7.3469e-02, -2.6717e-02,  5.3603e-02, -3.6374e-02]],\n              \n                      [[ 2.0410e-01,  8.2785e-02, -1.0192e-01,  5.3371e-02,  4.5274e-02],\n                       [-5.7510e-02, -2.8322e-03, -6.1027e-02, -9.7454e-02,  9.9822e-02],\n                       [-1.6745e-02,  1.7708e-02,  2.5208e-02,  7.8046e-03,  1.9021e-02],\n                       ...,\n                       [-6.5871e-02,  4.6885e-02, -1.5164e-02, -2.4515e-02,  8.3965e-02],\n                       [-1.2700e-01, -8.9268e-03,  2.7877e-02,  1.4866e-01, -1.4576e-01],\n                       [ 1.4306e-02, -2.2543e-02, -3.3897e-02, -1.3741e-02,  1.2444e-01]],\n              \n                      [[-1.2861e-01,  3.9379e-02,  2.0283e-02, -1.3749e-01, -8.0337e-02],\n                       [-1.6939e-02, -8.5982e-02, -2.4563e-02, -7.2682e-02,  3.3371e-02],\n                       [ 2.8970e-02,  2.6279e-02, -3.8103e-02, -1.1201e-02,  9.8238e-03],\n                       ...,\n                       [-4.3107e-02, -4.0265e-02, -1.0508e-01, -9.1465e-03, -6.0057e-02],\n                       [-1.1010e-01,  5.2762e-02, -1.2893e-02, -4.5244e-02, -1.2957e-01],\n                       [-1.7820e-02,  5.2013e-02, -1.4101e-01, -6.1925e-02, -1.0389e-01]]],\n                     dtype=torch.float64)),\n             ('6.1.convs.1.1.weight',\n              tensor([0.9720, 0.9679, 0.9775, 0.9749, 0.9609, 0.9971, 0.9576, 0.9889, 0.9624,\n                      0.9806, 0.9474, 0.9942, 0.9756, 0.9747, 1.0010, 0.9667, 0.9915, 0.9766,\n                      0.9825, 0.9391, 0.9543, 1.0023, 0.9918, 0.9888, 0.9745, 0.9734, 0.9697,\n                      0.9500, 0.9360, 0.9752, 0.9605, 0.9960, 0.9776, 0.9678, 0.9754, 0.9702,\n                      0.9606, 0.9504, 0.9724, 0.9752, 0.9769, 0.9727, 0.9750, 0.9627, 0.9475,\n                      0.9586, 0.9753, 0.9865, 0.9684, 0.9436, 0.9798, 0.9555, 0.9897, 0.9799,\n                      0.9643, 0.9637, 0.9406, 0.9663, 0.9615, 0.9387, 0.9585, 0.9988, 0.9785,\n                      0.9608], dtype=torch.float64)),\n             ('6.1.convs.1.1.bias',\n              tensor([ 0.0045, -0.0058,  0.0110, -0.0134,  0.0036,  0.0029, -0.0203,  0.0089,\n                      -0.0099, -0.0085, -0.0079,  0.0090,  0.0005, -0.0104,  0.0085, -0.0078,\n                       0.0083,  0.0084, -0.0136, -0.0353, -0.0196,  0.0228, -0.0026,  0.0075,\n                      -0.0078,  0.0115, -0.0149, -0.0146, -0.0139, -0.0057, -0.0113,  0.0076,\n                       0.0198,  0.0059,  0.0004,  0.0064, -0.0244, -0.0327, -0.0311, -0.0052,\n                       0.0024, -0.0007,  0.0068, -0.0120, -0.0167, -0.0146,  0.0064, -0.0074,\n                      -0.0020, -0.0026,  0.0059, -0.0109,  0.0022, -0.0041,  0.0040, -0.0100,\n                      -0.0177, -0.0081,  0.0005, -0.0173, -0.0133, -0.0040, -0.0002, -0.0030],\n                     dtype=torch.float64)),\n             ('6.1.convs.1.1.running_mean',\n              tensor([-0.1656, -0.6688, -0.4472, -0.1567,  0.7757, -0.5768,  0.2833, -0.3976,\n                       0.6657, -0.4052,  0.1801, -0.4839, -0.8778, -0.2844, -0.2725, -0.2495,\n                      -0.1189,  0.8925, -0.3347, -0.2087, -0.4131, -0.1935,  0.0613,  0.2266,\n                      -0.9533,  0.0056,  0.9228, -0.4401, -1.0035, -0.3009,  0.2633, -0.8557,\n                      -0.2897,  0.7346, -0.3499,  0.1430,  0.3073,  0.6404,  0.4430,  0.3936,\n                      -0.5687, -0.5230,  0.4855, -1.0240, -0.3783,  0.0242,  0.0474,  0.2459,\n                      -0.5932, -0.3431, -0.1530, -0.2717,  0.7636, -0.4168, -0.5561,  0.6566,\n                       0.3383, -0.0152,  0.0538, -0.4823,  0.7188, -0.0441,  0.2668, -0.7195],\n                     dtype=torch.float64)),\n             ('6.1.convs.1.1.running_var',\n              tensor([0.5525, 0.6694, 0.4685, 0.4331, 1.2383, 0.3676, 1.4682, 0.4152, 1.0946,\n                      0.5143, 0.4961, 0.4534, 0.5306, 0.4656, 0.5585, 0.5626, 0.5448, 0.7693,\n                      0.4146, 0.6038, 0.5043, 0.7914, 0.4437, 0.3316, 0.5336, 0.4510, 0.4652,\n                      0.4602, 0.5756, 0.6658, 0.4250, 0.5382, 0.7333, 0.7666, 0.5531, 0.5333,\n                      0.5438, 0.8516, 0.5218, 0.4936, 0.6635, 0.9291, 0.6418, 0.4868, 0.6685,\n                      0.5711, 0.3934, 0.4378, 0.3515, 0.8665, 0.6973, 0.4516, 0.4504, 0.4979,\n                      0.8210, 0.9745, 0.5085, 0.3770, 0.5947, 0.4277, 0.7694, 0.5036, 0.4561,\n                      0.5399], dtype=torch.float64)),\n             ('6.1.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.1.convs.2.0.weight',\n              tensor([[[ 0.0156],\n                       [ 0.1794],\n                       [-0.0017],\n                       ...,\n                       [ 0.0571],\n                       [-0.1546],\n                       [ 0.0860]],\n              \n                      [[-0.0700],\n                       [-0.3171],\n                       [-0.0454],\n                       ...,\n                       [ 0.0552],\n                       [ 0.1973],\n                       [-0.0720]],\n              \n                      [[ 0.0063],\n                       [-0.1475],\n                       [-0.0504],\n                       ...,\n                       [ 0.0004],\n                       [-0.2594],\n                       [ 0.0226]],\n              \n                      ...,\n              \n                      [[-0.0922],\n                       [ 0.0924],\n                       [-0.1548],\n                       ...,\n                       [-0.0344],\n                       [-0.0150],\n                       [ 0.0429]],\n              \n                      [[-0.0263],\n                       [ 0.1360],\n                       [ 0.1294],\n                       ...,\n                       [ 0.0344],\n                       [-0.1223],\n                       [-0.0304]],\n              \n                      [[-0.2087],\n                       [-0.1865],\n                       [-0.2063],\n                       ...,\n                       [-0.0782],\n                       [ 0.1243],\n                       [ 0.0495]]], dtype=torch.float64)),\n             ('6.1.convs.2.1.weight',\n              tensor([-0.0033,  0.0280, -0.0101,  0.0123, -0.0082,  0.0117, -0.0012,  0.0020,\n                      -0.0283, -0.0020, -0.0126, -0.0198, -0.0071, -0.0270, -0.0178, -0.0426,\n                      -0.0179, -0.0224, -0.0290,  0.0042, -0.0207,  0.0126, -0.0026, -0.0089,\n                       0.0133,  0.0036, -0.0023, -0.0093, -0.0019, -0.0075, -0.0134,  0.0242,\n                      -0.0086,  0.0073, -0.0234,  0.0136, -0.0211,  0.0020, -0.0013, -0.0124,\n                      -0.0205,  0.0061,  0.0094,  0.0056,  0.0177,  0.0272, -0.0025,  0.0091,\n                      -0.0312, -0.0045,  0.0278, -0.0252,  0.0041,  0.0226, -0.0026,  0.0049,\n                      -0.0141, -0.0357,  0.0065,  0.0041,  0.0086, -0.0167,  0.0031,  0.0051,\n                       0.0217, -0.0179, -0.0220, -0.0261, -0.0020, -0.0360,  0.0092, -0.0024,\n                      -0.0127,  0.0064,  0.0205, -0.0087,  0.0014, -0.0240,  0.0097, -0.0319,\n                       0.0042, -0.0075, -0.0158, -0.0147, -0.0129,  0.0066,  0.0042, -0.0085,\n                       0.0139,  0.0096, -0.0123, -0.0225, -0.0230,  0.0178, -0.0299, -0.0063,\n                       0.0007, -0.0356, -0.0404,  0.0108, -0.0062,  0.0092, -0.0289,  0.0280,\n                      -0.0029,  0.0239, -0.0152,  0.0203, -0.0333,  0.0071, -0.0209, -0.0146,\n                      -0.0406,  0.0116, -0.0093,  0.0121, -0.0390, -0.0209,  0.0047,  0.0246,\n                      -0.0080, -0.0132, -0.0223,  0.0052, -0.0090,  0.0140,  0.0082,  0.0144,\n                       0.0374,  0.0013, -0.0153, -0.0033,  0.0109, -0.0022, -0.0115, -0.0100,\n                      -0.0067, -0.0336,  0.0172, -0.0168,  0.0265,  0.0054, -0.0313,  0.0124,\n                       0.0044, -0.0070,  0.0099, -0.0236,  0.0139,  0.0043,  0.0085, -0.0046,\n                      -0.0200, -0.0132, -0.0205,  0.0219,  0.0186, -0.0119, -0.0168, -0.0048,\n                      -0.0146, -0.0232, -0.0193,  0.0346,  0.0309, -0.0276,  0.0190, -0.0002,\n                       0.0524,  0.0060, -0.0008,  0.0144, -0.0172,  0.0115, -0.0091, -0.0027,\n                      -0.0143, -0.0400,  0.0253, -0.0060, -0.0100, -0.0002,  0.0407,  0.0087,\n                      -0.0047,  0.0200, -0.0264, -0.0025, -0.0068,  0.0231,  0.0017, -0.0234,\n                      -0.0071, -0.0362, -0.0341,  0.0026,  0.0278,  0.0019, -0.0050,  0.0093,\n                       0.0108, -0.0234,  0.0132, -0.0211,  0.0109, -0.0061, -0.0059,  0.0157,\n                       0.0063,  0.0085,  0.0014, -0.0033,  0.0156, -0.0193,  0.0040, -0.0451,\n                      -0.0060, -0.0167,  0.0249,  0.0014, -0.0168, -0.0038,  0.0080, -0.0166,\n                       0.0245,  0.0136,  0.0299,  0.0159,  0.0059,  0.0185, -0.0068,  0.0026,\n                       0.0243, -0.0314,  0.0236, -0.0180,  0.0132,  0.0077, -0.0003,  0.0301,\n                      -0.0009,  0.0018,  0.0246,  0.0090,  0.0149, -0.0095,  0.0049, -0.0126,\n                      -0.0120,  0.0106,  0.0088,  0.0144,  0.0105,  0.0286,  0.0085,  0.0058],\n                     dtype=torch.float64)),\n             ('6.1.convs.2.1.bias',\n              tensor([-2.5505e-03, -3.9085e-03,  1.9074e-02,  6.6890e-03,  5.5247e-03,\n                       6.5796e-03,  2.1594e-02,  7.0783e-05,  1.0067e-02,  2.1318e-02,\n                       8.0090e-03, -3.4694e-03,  1.2609e-02, -8.5750e-03,  2.7168e-03,\n                       9.3555e-03,  1.7489e-02,  3.0668e-03,  1.6339e-02, -7.5625e-03,\n                      -2.5801e-03,  1.8615e-03,  2.5624e-03,  6.5700e-03, -4.1444e-03,\n                      -1.3100e-02,  6.5238e-03,  1.0643e-02,  2.4487e-03, -5.4523e-04,\n                       1.5786e-03,  9.3900e-03, -4.1642e-03,  1.4596e-02,  1.9135e-02,\n                       7.7523e-03,  5.3930e-03,  2.6580e-02,  9.6048e-03,  1.3367e-02,\n                       1.0891e-03,  7.8824e-03, -8.0961e-03,  3.7968e-03,  1.2411e-02,\n                      -1.1054e-02,  6.7430e-03,  4.8284e-03, -1.1077e-02,  5.4202e-03,\n                       3.4150e-03,  4.0094e-03,  8.2411e-03,  2.1089e-02,  4.7997e-03,\n                      -1.5240e-03,  6.4084e-03,  6.3923e-03,  7.1305e-03,  8.4037e-03,\n                      -4.8076e-03,  1.9170e-03,  3.9693e-03,  1.0386e-02, -3.5333e-03,\n                       1.1353e-02, -1.1836e-02,  1.4353e-02, -1.0043e-03, -9.0560e-03,\n                       2.8714e-03,  1.1269e-02,  1.1881e-02, -8.1071e-03,  1.4425e-02,\n                       1.8357e-02, -1.2862e-03,  9.0661e-04,  4.5088e-03,  7.1408e-03,\n                       1.1240e-02, -5.0662e-03,  9.4670e-03,  4.5585e-03, -2.5288e-03,\n                       1.0548e-02,  5.1050e-03,  3.0754e-03,  7.7780e-03,  8.3395e-03,\n                      -6.3583e-04,  2.1542e-02,  1.7079e-02, -1.7099e-03,  5.2915e-03,\n                      -1.4536e-02,  2.7706e-03,  5.5363e-03,  1.1953e-02,  7.3071e-03,\n                       2.5124e-02,  7.9315e-03, -1.6831e-03, -2.2741e-02,  1.0062e-02,\n                       1.7996e-03,  3.4937e-03, -3.7026e-03,  4.0731e-03,  9.9470e-03,\n                      -9.0257e-03, -6.2205e-03,  6.0915e-03,  1.5190e-02,  1.3642e-02,\n                       8.0707e-03,  1.0722e-02,  2.5499e-03,  1.2776e-03, -1.4411e-02,\n                       3.6701e-03,  1.3693e-02, -2.9845e-03,  2.4139e-03, -1.0482e-02,\n                       1.4018e-02,  1.8371e-02,  1.7696e-03,  3.3642e-04,  9.8811e-03,\n                      -3.5170e-04,  1.5895e-02,  1.4677e-02,  1.1777e-02, -4.8551e-05,\n                      -1.5621e-03,  1.8747e-02,  8.0064e-03,  1.6684e-02,  4.3264e-03,\n                      -3.0390e-03, -3.6554e-03,  8.3829e-04,  1.0192e-02, -6.2357e-03,\n                      -1.2813e-03,  2.7329e-03,  1.3295e-03,  1.0005e-02,  1.0223e-02,\n                       2.5045e-03,  1.2901e-02,  2.9301e-03,  1.5376e-02,  1.8400e-02,\n                       1.6355e-02, -8.5364e-04,  1.0838e-02, -2.8020e-03, -1.0860e-02,\n                      -2.1172e-03,  1.6197e-03, -8.0019e-04,  1.7816e-02,  1.1950e-02,\n                       2.7652e-03, -7.6293e-03,  7.2079e-03,  5.8560e-03,  1.6358e-02,\n                       5.0898e-03,  9.1835e-03,  1.4028e-02,  8.3954e-03, -1.3888e-02,\n                      -6.6470e-03, -2.6172e-03,  2.1919e-02,  5.8810e-03,  1.7710e-03,\n                      -2.2386e-03,  8.8085e-03, -9.0727e-03, -1.0749e-02,  1.6610e-02,\n                       3.8294e-03,  1.0589e-02,  1.4135e-02, -4.6294e-03,  2.8441e-03,\n                       7.6860e-03, -4.2460e-03,  1.4274e-02, -1.5621e-02,  1.0205e-02,\n                       8.9526e-03, -1.6260e-03,  1.4688e-02,  8.6138e-03, -7.4103e-03,\n                       4.3163e-03,  2.0667e-02,  2.0862e-02,  1.7362e-02,  5.0182e-03,\n                      -6.5817e-03,  1.4792e-02, -3.6902e-03,  2.1740e-03,  5.8518e-03,\n                       1.4639e-04,  1.1807e-02,  1.5026e-02,  6.8936e-03,  6.9249e-03,\n                       9.7913e-03,  3.2702e-03, -7.7497e-05,  6.7784e-03, -1.1610e-03,\n                      -1.1122e-02, -1.9100e-03,  7.0872e-03,  2.5784e-02, -4.9091e-03,\n                       5.4790e-03, -1.1933e-03,  3.5152e-03, -1.8601e-02,  7.6930e-03,\n                       1.7909e-02,  3.7828e-04,  1.0939e-02,  8.6657e-03,  1.0853e-02,\n                       3.2809e-03,  6.1784e-03, -2.6066e-03,  1.0758e-02,  7.0968e-03,\n                       9.9172e-03,  2.6979e-03,  4.0690e-03,  1.2734e-03,  4.1193e-03,\n                       1.4020e-02,  4.5682e-03,  9.6183e-03, -2.9744e-03, -6.3377e-03,\n                       1.5441e-02,  8.3987e-03,  2.1647e-02,  2.3877e-02,  1.2482e-02,\n                       2.3371e-03], dtype=torch.float64)),\n             ('6.1.convs.2.1.running_mean',\n              tensor([-2.0302e-01,  2.3928e-01,  1.1861e-02, -2.9150e-01, -3.4993e-01,\n                      -2.2114e-01,  3.3553e-01, -8.5139e-01, -7.8087e-02,  1.8976e-01,\n                      -4.2974e-01,  1.2698e-01,  2.9693e-01,  2.4106e-01, -3.9244e-01,\n                       1.9130e-02, -3.1942e-01, -3.7289e-01,  3.6165e-01, -3.5788e-01,\n                      -7.6797e-02,  1.7820e-01,  2.2462e-01,  6.1932e-01, -6.8466e-01,\n                       2.9511e-01, -2.2852e-01,  2.1874e-01, -2.1943e-01,  2.1887e-02,\n                       7.8857e-02,  7.3661e-01,  6.3667e-01, -9.2395e-01,  4.4736e-01,\n                       7.0950e-01,  5.1350e-01, -5.4435e-01,  1.4070e-02, -2.0086e-01,\n                       3.9774e-01,  2.9724e-01, -3.4697e-02, -9.6656e-02, -3.4594e-01,\n                      -1.5180e-01, -1.1198e-01, -6.5215e-02,  9.0198e-02, -6.3278e-03,\n                      -3.8864e-01, -8.3079e-01, -3.8943e-01, -3.6461e-02, -1.1616e-01,\n                       7.5818e-01, -1.0705e-01,  1.2509e-02, -7.9266e-02, -2.1095e-01,\n                      -3.6026e-01, -1.4638e-01,  6.0615e-03,  4.0779e-01, -2.4074e-01,\n                      -1.6403e-02,  5.7264e-01, -1.2510e-01,  1.9139e-01,  2.3029e-01,\n                       2.8744e-01,  2.4143e-01, -1.1884e-01, -9.9484e-02, -4.3107e-01,\n                      -5.1000e-01, -1.2783e-01, -5.5991e-01, -1.2030e-01, -3.5053e-01,\n                       2.7037e-01, -1.7367e-02,  5.2911e-01,  2.2383e-01, -4.1650e-01,\n                      -1.7497e-01, -9.1881e-02,  3.9545e-01,  2.2948e-01, -4.3008e-01,\n                       1.0458e-01, -5.4550e-01,  1.8406e-01,  3.9215e-01,  2.6270e-01,\n                      -5.1332e-02,  2.5807e-01, -2.5327e-01, -4.9878e-01,  1.8894e-01,\n                      -6.2112e-01, -1.2263e-03, -3.4638e-01, -1.8756e-01,  2.7836e-01,\n                      -2.2012e-01, -2.6579e-01,  6.3353e-01,  2.4430e-01,  3.5475e-01,\n                       5.4465e-02, -1.2562e-02,  1.1921e-01,  1.4617e-01, -7.0777e-01,\n                      -3.4613e-01,  1.0903e+00,  7.9713e-01, -2.3165e-02,  4.6684e-01,\n                       1.4032e-01,  1.9835e-01,  3.3332e-01,  5.9843e-01,  1.5499e-01,\n                       1.8751e-01, -3.2765e-01,  8.0873e-01,  4.8001e-01,  6.7062e-01,\n                      -1.3014e-02, -2.2429e-01,  5.1441e-01, -3.8093e-01,  1.1214e-01,\n                       1.1483e-01,  3.2469e-01,  6.3021e-01,  3.4559e-01, -3.4341e-01,\n                      -9.6259e-01,  1.9911e-01, -9.7398e-01,  2.4920e-02,  4.8902e-02,\n                       6.4020e-01, -2.0510e-01, -3.4471e-01,  1.2213e-01, -7.2666e-01,\n                      -4.3484e-01, -3.2729e-01, -6.9196e-02,  3.6942e-01,  4.7587e-01,\n                       8.2862e-02,  9.5103e-04,  2.2106e-01,  3.0261e-01, -1.4533e-01,\n                       5.8162e-01,  2.7436e-01,  2.6451e-01, -9.4665e-01, -5.9348e-01,\n                       4.3466e-01, -2.5857e-01,  4.9502e-01,  1.2646e-01,  8.8504e-02,\n                      -1.7012e-02,  1.6124e-01, -7.2137e-01,  1.8796e-01,  9.7766e-01,\n                       8.5715e-01,  3.7755e-01,  1.1222e-01, -3.4441e-01, -2.3366e-01,\n                      -3.7620e-01, -2.0036e-01,  8.0275e-02,  1.8547e-01, -6.5372e-02,\n                       2.9282e-01,  3.2096e-01,  2.6789e-01,  3.0135e-01, -2.2187e-01,\n                       5.1381e-01, -3.7257e-01,  3.3345e-01, -8.3657e-02, -5.8958e-02,\n                      -5.0750e-01, -1.9216e-01,  6.3049e-01,  3.3090e-01, -2.8191e-02,\n                       2.2842e-01,  8.6185e-02,  7.8209e-01,  6.1467e-01, -1.1337e+00,\n                      -3.9464e-01, -2.7485e-01, -1.5055e-02, -1.3589e-03, -3.9779e-01,\n                      -8.3975e-02,  5.1198e-01, -2.9870e-01,  5.9018e-02,  1.4741e-01,\n                      -1.7628e-01,  7.5662e-02, -2.7774e-01, -9.5549e-02, -2.1739e-01,\n                       8.7645e-02,  6.4962e-01,  7.3246e-02, -8.1537e-02, -7.6913e-01,\n                       3.6128e-02, -3.5163e-02,  4.5012e-01, -2.9773e-01,  8.9025e-01,\n                      -1.3018e-01,  1.6535e-01, -6.2737e-01,  2.5452e-01,  1.0737e-01,\n                      -2.8151e-01,  2.4892e-01,  2.7232e-01, -1.1888e-01, -6.7222e-01,\n                       4.2951e-01, -2.8898e-01, -2.6196e-01,  3.5638e-01, -2.3585e-01,\n                      -1.6005e-01,  3.4896e-01, -1.6829e-01, -1.1115e-01,  5.6126e-01,\n                      -7.5377e-01,  1.1297e+00,  1.9611e-01, -1.4428e-02, -1.8066e-02,\n                       2.6949e-01], dtype=torch.float64)),\n             ('6.1.convs.2.1.running_var',\n              tensor([0.5338, 0.5564, 0.2546, 0.4130, 0.1595, 0.5023, 0.3013, 0.5431, 0.3187,\n                      0.1764, 0.3705, 0.5176, 0.0649, 0.4851, 0.5429, 0.5387, 0.3057, 0.3401,\n                      0.2875, 0.4934, 0.3816, 0.4963, 0.3320, 0.5129, 0.4949, 0.4840, 0.2788,\n                      0.2973, 0.2616, 0.1360, 0.6689, 0.4424, 0.6001, 0.3744, 0.3933, 0.3151,\n                      0.3604, 0.2965, 0.1025, 0.4086, 0.4977, 0.3096, 0.2554, 0.1878, 0.1988,\n                      0.3923, 0.1056, 0.2473, 0.4625, 0.1310, 0.4256, 0.4927, 0.3224, 0.5657,\n                      0.3128, 0.2832, 0.4739, 0.3236, 0.5085, 0.2549, 0.1370, 0.4492, 0.2537,\n                      0.1955, 0.3470, 0.1965, 0.5290, 0.3061, 0.2122, 0.5322, 0.4395, 0.1623,\n                      0.2025, 0.4709, 0.5198, 0.2841, 0.3031, 0.3044, 0.5058, 0.3360, 0.1811,\n                      0.2013, 0.3937, 0.4537, 0.5181, 0.7086, 0.3337, 0.3017, 0.5167, 0.1958,\n                      0.3957, 0.4683, 0.4542, 0.2254, 0.4159, 0.2281, 0.3685, 0.2733, 0.2758,\n                      0.2399, 0.3942, 0.3792, 0.3470, 0.3256, 0.1442, 0.3583, 0.4504, 0.4712,\n                      0.3636, 0.2515, 0.3666, 0.4540, 0.8550, 0.3606, 0.3602, 0.4981, 0.3656,\n                      0.5337, 0.3742, 0.4996, 0.2233, 0.3993, 0.4624, 0.4538, 0.3044, 0.5115,\n                      0.1800, 0.3015, 0.3347, 0.1906, 0.2489, 0.2185, 0.3307, 0.2586, 0.2936,\n                      0.2078, 0.1891, 0.4875, 0.5307, 0.2902, 0.6349, 0.2124, 0.5343, 0.4224,\n                      0.1106, 0.5053, 0.1948, 0.3957, 0.1875, 0.4339, 0.4597, 0.2213, 0.3603,\n                      0.5677, 0.3849, 0.4209, 0.3428, 0.3273, 0.6189, 0.2013, 0.2600, 0.3837,\n                      0.2239, 0.7583, 0.7795, 0.6828, 0.5024, 0.5953, 0.4600, 0.3375, 0.1138,\n                      0.3194, 0.4556, 0.1979, 0.3740, 0.3590, 0.2702, 0.3942, 0.3662, 0.1440,\n                      0.3228, 0.2679, 0.4051, 0.5852, 0.2131, 0.4362, 0.3384, 0.2164, 0.2297,\n                      0.5973, 0.2037, 0.5251, 0.2238, 0.4663, 0.4905, 0.1288, 0.4315, 0.3864,\n                      0.2771, 0.1604, 0.2165, 0.3582, 0.3555, 0.3907, 0.3972, 0.3187, 0.0990,\n                      0.2445, 0.3006, 0.4075, 0.0440, 0.3822, 0.2202, 0.6097, 0.1305, 0.3992,\n                      0.2364, 0.3478, 0.3605, 0.4326, 0.2476, 0.2974, 0.2430, 0.3677, 0.4900,\n                      0.3069, 0.4193, 0.3520, 0.4766, 0.4849, 0.3115, 0.1262, 0.5743, 0.3966,\n                      0.3361, 0.4644, 0.3764, 0.1543, 0.3860, 0.4361, 0.2029, 0.1290, 0.6413,\n                      0.2860, 0.2838, 0.3715, 0.1239, 0.5479, 0.2735, 0.5208, 0.6990, 0.4562,\n                      0.1960, 0.4321, 0.1099, 0.2580], dtype=torch.float64)),\n             ('6.1.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.1.convpath.0.0.0.weight',\n              tensor([[[-0.0424],\n                       [-0.0052],\n                       [-0.0162],\n                       ...,\n                       [-0.0172],\n                       [ 0.0693],\n                       [ 0.1802]],\n              \n                      [[-0.1415],\n                       [-0.1271],\n                       [-0.0309],\n                       ...,\n                       [-0.0037],\n                       [-0.0752],\n                       [ 0.0457]],\n              \n                      [[-0.0204],\n                       [ 0.0124],\n                       [-0.0841],\n                       ...,\n                       [-0.0590],\n                       [ 0.0378],\n                       [-0.1357]],\n              \n                      ...,\n              \n                      [[ 0.0995],\n                       [-0.0427],\n                       [ 0.0297],\n                       ...,\n                       [ 0.0364],\n                       [-0.1483],\n                       [-0.0230]],\n              \n                      [[-0.0895],\n                       [-0.0080],\n                       [ 0.1440],\n                       ...,\n                       [-0.0309],\n                       [ 0.0486],\n                       [ 0.1555]],\n              \n                      [[ 0.0032],\n                       [ 0.0161],\n                       [ 0.1359],\n                       ...,\n                       [ 0.0351],\n                       [ 0.1254],\n                       [-0.0484]]], dtype=torch.float64)),\n             ('6.1.convpath.0.0.1.weight',\n              tensor([0.9556, 1.0019, 1.0087, 0.9839, 0.9734, 0.9625, 0.9381, 0.9673, 0.9806,\n                      0.9546, 0.9805, 0.9785, 0.9709, 0.9602, 0.9621, 0.9622, 0.9760, 0.9791,\n                      0.9692, 0.9689, 0.9813, 0.9832, 0.9897, 0.9889, 1.0074, 1.0071, 1.0083,\n                      0.9977, 0.9713, 0.9936, 0.9776, 0.9781, 0.9790, 0.9894, 0.9832, 0.9624,\n                      0.9719, 0.9489, 0.9957, 0.9892, 0.9621, 0.9772, 0.9718, 0.9670, 0.9803,\n                      0.9713, 0.9949, 0.9753, 0.9575, 0.9799, 0.9770, 0.9585, 1.0001, 0.9882,\n                      0.9535, 0.9676, 0.9700, 0.9936, 0.9713, 0.9549, 0.9795, 0.9669, 0.9713,\n                      0.9849], dtype=torch.float64)),\n             ('6.1.convpath.0.0.1.bias',\n              tensor([-0.0017, -0.0029, -0.0089,  0.0086,  0.0141, -0.0037, -0.0049, -0.0115,\n                      -0.0026, -0.0092, -0.0023,  0.0075,  0.0085, -0.0089, -0.0108, -0.0087,\n                      -0.0080, -0.0041, -0.0172, -0.0054,  0.0058,  0.0031, -0.0113,  0.0088,\n                       0.0167,  0.0095,  0.0253,  0.0136, -0.0010,  0.0148,  0.0083,  0.0097,\n                       0.0072,  0.0056,  0.0013, -0.0129, -0.0220, -0.0166,  0.0163, -0.0002,\n                      -0.0046, -0.0087, -0.0122, -0.0059,  0.0129,  0.0026,  0.0159, -0.0054,\n                      -0.0165, -0.0112,  0.0132,  0.0044,  0.0175,  0.0075, -0.0178, -0.0023,\n                      -0.0043,  0.0185, -0.0278, -0.0196,  0.0044, -0.0123,  0.0084, -0.0067],\n                     dtype=torch.float64)),\n             ('6.1.convpath.0.0.1.running_mean',\n              tensor([-0.4150, -0.2880, -0.8945, -0.3042, -0.3209, -0.3696,  0.1797,  0.3235,\n                      -0.4861,  0.7383,  0.3577,  0.0531, -0.3761, -0.5580, -0.0362, -0.2112,\n                      -0.7140,  0.7089,  0.7538, -1.0949, -0.4426, -0.3842, -0.0116, -0.2084,\n                      -0.0925, -0.8444,  0.4087,  0.2340, -0.1648,  0.3386, -0.2307,  0.0546,\n                       0.4520, -0.2811, -0.0146,  0.2515,  0.3150, -0.3467, -0.4012, -0.5889,\n                      -0.3563,  0.1232,  0.3213,  0.2147, -0.1321,  0.8876,  0.4366, -0.4667,\n                      -0.2859, -0.2934, -0.5439,  0.3009, -0.2590, -0.5371, -0.6992, -0.2741,\n                       0.6387,  0.0014,  0.6532, -0.2137, -0.0535, -0.3523, -0.2007,  0.1740],\n                     dtype=torch.float64)),\n             ('6.1.convpath.0.0.1.running_var',\n              tensor([0.1284, 0.1352, 0.1480, 0.4249, 0.1864, 0.1490, 1.1221, 0.1556, 0.1418,\n                      1.3059, 0.1094, 0.1480, 0.3749, 0.5922, 0.3826, 0.2936, 0.3074, 0.2663,\n                      1.5858, 0.1791, 0.1160, 0.1212, 0.1502, 0.2258, 0.1906, 0.1150, 0.2483,\n                      0.1860, 0.1966, 0.2237, 0.3810, 0.9359, 0.1306, 0.1491, 0.1347, 0.1381,\n                      0.3361, 0.3937, 0.2071, 0.2376, 0.1224, 0.1280, 0.1185, 0.3536, 0.1533,\n                      0.1641, 0.3471, 0.1896, 0.5365, 0.0846, 0.1462, 1.3340, 0.1304, 0.1195,\n                      0.3710, 0.1689, 1.0295, 0.2006, 0.3087, 0.1431, 0.1711, 0.1458, 0.6250,\n                      0.1392], dtype=torch.float64)),\n             ('6.1.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.1.convpath.0.1.0.weight',\n              tensor([[[-2.0950e-01,  5.1853e-02,  1.7200e-01,  2.6316e-02, -5.6596e-03],\n                       [ 2.4236e-02, -9.5213e-02,  1.2029e-01,  5.4813e-02, -1.4749e-01],\n                       [-6.5424e-02, -4.0944e-02, -5.1758e-02, -1.0551e-01,  1.6669e-02],\n                       ...,\n                       [-1.6925e-01,  8.7979e-02, -1.0981e-01, -7.9609e-02,  9.7839e-02],\n                       [ 4.6368e-02, -7.2487e-04, -3.8773e-02, -1.1093e-02, -7.0569e-02],\n                       [-4.8690e-02,  1.0747e-01,  1.2215e-01,  9.5290e-02, -2.9760e-02]],\n              \n                      [[ 1.1572e-02,  1.5122e-02,  8.7048e-03,  4.8775e-02,  6.6929e-02],\n                       [ 6.1570e-02,  8.4607e-02, -1.7447e-02, -7.0495e-02,  2.7752e-02],\n                       [-8.2153e-02,  2.8278e-02, -2.8629e-02, -4.6675e-03, -5.0332e-02],\n                       ...,\n                       [-7.2105e-02,  5.4642e-02, -6.0589e-02,  2.0942e-02, -1.4742e-01],\n                       [-5.1720e-03,  4.9924e-02, -3.8816e-02,  6.6992e-02, -2.4088e-02],\n                       [ 1.6673e-02,  7.7642e-02, -1.8007e-02, -4.7000e-02, -4.6770e-02]],\n              \n                      [[ 1.0554e-01, -9.4840e-02,  3.5358e-02, -1.0092e-01, -1.0186e-02],\n                       [-1.1118e-01, -5.9017e-02, -4.2867e-02,  1.9443e-04,  1.7456e-02],\n                       [ 6.7793e-03,  6.9719e-02,  2.1501e-02, -5.2033e-02, -8.0415e-02],\n                       ...,\n                       [ 5.1017e-02, -7.1165e-02,  3.5667e-05, -3.5859e-02,  8.8855e-02],\n                       [-5.0787e-03, -8.2741e-02, -2.2271e-02, -1.3771e-03, -2.2313e-02],\n                       [-1.0266e-01, -8.2067e-03,  1.4628e-01,  7.0854e-02,  1.1533e-01]],\n              \n                      ...,\n              \n                      [[ 7.6572e-02, -1.0005e-01, -8.4468e-02, -6.6984e-02,  8.2237e-03],\n                       [-7.0071e-02, -4.2501e-02, -6.1198e-02,  2.0228e-02, -7.6715e-02],\n                       [ 1.0537e-01,  1.1839e-01, -2.3135e-02, -1.3043e-01,  5.2902e-03],\n                       ...,\n                       [-1.7547e-01,  3.9171e-02, -1.0876e-01,  6.3565e-02, -1.7522e-01],\n                       [ 6.0957e-02,  1.6996e-02,  2.4187e-02,  6.2424e-02,  1.1230e-01],\n                       [ 8.5341e-03,  7.3469e-02, -2.6717e-02,  5.3603e-02, -3.6374e-02]],\n              \n                      [[ 2.0410e-01,  8.2785e-02, -1.0192e-01,  5.3371e-02,  4.5274e-02],\n                       [-5.7510e-02, -2.8322e-03, -6.1027e-02, -9.7454e-02,  9.9822e-02],\n                       [-1.6745e-02,  1.7708e-02,  2.5208e-02,  7.8046e-03,  1.9021e-02],\n                       ...,\n                       [-6.5871e-02,  4.6885e-02, -1.5164e-02, -2.4515e-02,  8.3965e-02],\n                       [-1.2700e-01, -8.9268e-03,  2.7877e-02,  1.4866e-01, -1.4576e-01],\n                       [ 1.4306e-02, -2.2543e-02, -3.3897e-02, -1.3741e-02,  1.2444e-01]],\n              \n                      [[-1.2861e-01,  3.9379e-02,  2.0283e-02, -1.3749e-01, -8.0337e-02],\n                       [-1.6939e-02, -8.5982e-02, -2.4563e-02, -7.2682e-02,  3.3371e-02],\n                       [ 2.8970e-02,  2.6279e-02, -3.8103e-02, -1.1201e-02,  9.8238e-03],\n                       ...,\n                       [-4.3107e-02, -4.0265e-02, -1.0508e-01, -9.1465e-03, -6.0057e-02],\n                       [-1.1010e-01,  5.2762e-02, -1.2893e-02, -4.5244e-02, -1.2957e-01],\n                       [-1.7820e-02,  5.2013e-02, -1.4101e-01, -6.1925e-02, -1.0389e-01]]],\n                     dtype=torch.float64)),\n             ('6.1.convpath.0.1.1.weight',\n              tensor([0.9720, 0.9679, 0.9775, 0.9749, 0.9609, 0.9971, 0.9576, 0.9889, 0.9624,\n                      0.9806, 0.9474, 0.9942, 0.9756, 0.9747, 1.0010, 0.9667, 0.9915, 0.9766,\n                      0.9825, 0.9391, 0.9543, 1.0023, 0.9918, 0.9888, 0.9745, 0.9734, 0.9697,\n                      0.9500, 0.9360, 0.9752, 0.9605, 0.9960, 0.9776, 0.9678, 0.9754, 0.9702,\n                      0.9606, 0.9504, 0.9724, 0.9752, 0.9769, 0.9727, 0.9750, 0.9627, 0.9475,\n                      0.9586, 0.9753, 0.9865, 0.9684, 0.9436, 0.9798, 0.9555, 0.9897, 0.9799,\n                      0.9643, 0.9637, 0.9406, 0.9663, 0.9615, 0.9387, 0.9585, 0.9988, 0.9785,\n                      0.9608], dtype=torch.float64)),\n             ('6.1.convpath.0.1.1.bias',\n              tensor([ 0.0045, -0.0058,  0.0110, -0.0134,  0.0036,  0.0029, -0.0203,  0.0089,\n                      -0.0099, -0.0085, -0.0079,  0.0090,  0.0005, -0.0104,  0.0085, -0.0078,\n                       0.0083,  0.0084, -0.0136, -0.0353, -0.0196,  0.0228, -0.0026,  0.0075,\n                      -0.0078,  0.0115, -0.0149, -0.0146, -0.0139, -0.0057, -0.0113,  0.0076,\n                       0.0198,  0.0059,  0.0004,  0.0064, -0.0244, -0.0327, -0.0311, -0.0052,\n                       0.0024, -0.0007,  0.0068, -0.0120, -0.0167, -0.0146,  0.0064, -0.0074,\n                      -0.0020, -0.0026,  0.0059, -0.0109,  0.0022, -0.0041,  0.0040, -0.0100,\n                      -0.0177, -0.0081,  0.0005, -0.0173, -0.0133, -0.0040, -0.0002, -0.0030],\n                     dtype=torch.float64)),\n             ('6.1.convpath.0.1.1.running_mean',\n              tensor([-0.1656, -0.6688, -0.4472, -0.1567,  0.7757, -0.5768,  0.2833, -0.3976,\n                       0.6657, -0.4052,  0.1801, -0.4839, -0.8778, -0.2844, -0.2725, -0.2495,\n                      -0.1189,  0.8925, -0.3347, -0.2087, -0.4131, -0.1935,  0.0613,  0.2266,\n                      -0.9533,  0.0056,  0.9228, -0.4401, -1.0035, -0.3009,  0.2633, -0.8557,\n                      -0.2897,  0.7346, -0.3499,  0.1430,  0.3073,  0.6404,  0.4430,  0.3936,\n                      -0.5687, -0.5230,  0.4855, -1.0240, -0.3783,  0.0242,  0.0474,  0.2459,\n                      -0.5932, -0.3431, -0.1530, -0.2717,  0.7636, -0.4168, -0.5561,  0.6566,\n                       0.3383, -0.0152,  0.0538, -0.4823,  0.7188, -0.0441,  0.2668, -0.7195],\n                     dtype=torch.float64)),\n             ('6.1.convpath.0.1.1.running_var',\n              tensor([0.5525, 0.6694, 0.4685, 0.4331, 1.2383, 0.3676, 1.4682, 0.4152, 1.0946,\n                      0.5143, 0.4961, 0.4534, 0.5306, 0.4656, 0.5585, 0.5626, 0.5448, 0.7693,\n                      0.4146, 0.6038, 0.5043, 0.7914, 0.4437, 0.3316, 0.5336, 0.4510, 0.4652,\n                      0.4602, 0.5756, 0.6658, 0.4250, 0.5382, 0.7333, 0.7666, 0.5531, 0.5333,\n                      0.5438, 0.8516, 0.5218, 0.4936, 0.6635, 0.9291, 0.6418, 0.4868, 0.6685,\n                      0.5711, 0.3934, 0.4378, 0.3515, 0.8665, 0.6973, 0.4516, 0.4504, 0.4979,\n                      0.8210, 0.9745, 0.5085, 0.3770, 0.5947, 0.4277, 0.7694, 0.5036, 0.4561,\n                      0.5399], dtype=torch.float64)),\n             ('6.1.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.1.convpath.0.2.0.weight',\n              tensor([[[ 0.0156],\n                       [ 0.1794],\n                       [-0.0017],\n                       ...,\n                       [ 0.0571],\n                       [-0.1546],\n                       [ 0.0860]],\n              \n                      [[-0.0700],\n                       [-0.3171],\n                       [-0.0454],\n                       ...,\n                       [ 0.0552],\n                       [ 0.1973],\n                       [-0.0720]],\n              \n                      [[ 0.0063],\n                       [-0.1475],\n                       [-0.0504],\n                       ...,\n                       [ 0.0004],\n                       [-0.2594],\n                       [ 0.0226]],\n              \n                      ...,\n              \n                      [[-0.0922],\n                       [ 0.0924],\n                       [-0.1548],\n                       ...,\n                       [-0.0344],\n                       [-0.0150],\n                       [ 0.0429]],\n              \n                      [[-0.0263],\n                       [ 0.1360],\n                       [ 0.1294],\n                       ...,\n                       [ 0.0344],\n                       [-0.1223],\n                       [-0.0304]],\n              \n                      [[-0.2087],\n                       [-0.1865],\n                       [-0.2063],\n                       ...,\n                       [-0.0782],\n                       [ 0.1243],\n                       [ 0.0495]]], dtype=torch.float64)),\n             ('6.1.convpath.0.2.1.weight',\n              tensor([-0.0033,  0.0280, -0.0101,  0.0123, -0.0082,  0.0117, -0.0012,  0.0020,\n                      -0.0283, -0.0020, -0.0126, -0.0198, -0.0071, -0.0270, -0.0178, -0.0426,\n                      -0.0179, -0.0224, -0.0290,  0.0042, -0.0207,  0.0126, -0.0026, -0.0089,\n                       0.0133,  0.0036, -0.0023, -0.0093, -0.0019, -0.0075, -0.0134,  0.0242,\n                      -0.0086,  0.0073, -0.0234,  0.0136, -0.0211,  0.0020, -0.0013, -0.0124,\n                      -0.0205,  0.0061,  0.0094,  0.0056,  0.0177,  0.0272, -0.0025,  0.0091,\n                      -0.0312, -0.0045,  0.0278, -0.0252,  0.0041,  0.0226, -0.0026,  0.0049,\n                      -0.0141, -0.0357,  0.0065,  0.0041,  0.0086, -0.0167,  0.0031,  0.0051,\n                       0.0217, -0.0179, -0.0220, -0.0261, -0.0020, -0.0360,  0.0092, -0.0024,\n                      -0.0127,  0.0064,  0.0205, -0.0087,  0.0014, -0.0240,  0.0097, -0.0319,\n                       0.0042, -0.0075, -0.0158, -0.0147, -0.0129,  0.0066,  0.0042, -0.0085,\n                       0.0139,  0.0096, -0.0123, -0.0225, -0.0230,  0.0178, -0.0299, -0.0063,\n                       0.0007, -0.0356, -0.0404,  0.0108, -0.0062,  0.0092, -0.0289,  0.0280,\n                      -0.0029,  0.0239, -0.0152,  0.0203, -0.0333,  0.0071, -0.0209, -0.0146,\n                      -0.0406,  0.0116, -0.0093,  0.0121, -0.0390, -0.0209,  0.0047,  0.0246,\n                      -0.0080, -0.0132, -0.0223,  0.0052, -0.0090,  0.0140,  0.0082,  0.0144,\n                       0.0374,  0.0013, -0.0153, -0.0033,  0.0109, -0.0022, -0.0115, -0.0100,\n                      -0.0067, -0.0336,  0.0172, -0.0168,  0.0265,  0.0054, -0.0313,  0.0124,\n                       0.0044, -0.0070,  0.0099, -0.0236,  0.0139,  0.0043,  0.0085, -0.0046,\n                      -0.0200, -0.0132, -0.0205,  0.0219,  0.0186, -0.0119, -0.0168, -0.0048,\n                      -0.0146, -0.0232, -0.0193,  0.0346,  0.0309, -0.0276,  0.0190, -0.0002,\n                       0.0524,  0.0060, -0.0008,  0.0144, -0.0172,  0.0115, -0.0091, -0.0027,\n                      -0.0143, -0.0400,  0.0253, -0.0060, -0.0100, -0.0002,  0.0407,  0.0087,\n                      -0.0047,  0.0200, -0.0264, -0.0025, -0.0068,  0.0231,  0.0017, -0.0234,\n                      -0.0071, -0.0362, -0.0341,  0.0026,  0.0278,  0.0019, -0.0050,  0.0093,\n                       0.0108, -0.0234,  0.0132, -0.0211,  0.0109, -0.0061, -0.0059,  0.0157,\n                       0.0063,  0.0085,  0.0014, -0.0033,  0.0156, -0.0193,  0.0040, -0.0451,\n                      -0.0060, -0.0167,  0.0249,  0.0014, -0.0168, -0.0038,  0.0080, -0.0166,\n                       0.0245,  0.0136,  0.0299,  0.0159,  0.0059,  0.0185, -0.0068,  0.0026,\n                       0.0243, -0.0314,  0.0236, -0.0180,  0.0132,  0.0077, -0.0003,  0.0301,\n                      -0.0009,  0.0018,  0.0246,  0.0090,  0.0149, -0.0095,  0.0049, -0.0126,\n                      -0.0120,  0.0106,  0.0088,  0.0144,  0.0105,  0.0286,  0.0085,  0.0058],\n                     dtype=torch.float64)),\n             ('6.1.convpath.0.2.1.bias',\n              tensor([-2.5505e-03, -3.9085e-03,  1.9074e-02,  6.6890e-03,  5.5247e-03,\n                       6.5796e-03,  2.1594e-02,  7.0783e-05,  1.0067e-02,  2.1318e-02,\n                       8.0090e-03, -3.4694e-03,  1.2609e-02, -8.5750e-03,  2.7168e-03,\n                       9.3555e-03,  1.7489e-02,  3.0668e-03,  1.6339e-02, -7.5625e-03,\n                      -2.5801e-03,  1.8615e-03,  2.5624e-03,  6.5700e-03, -4.1444e-03,\n                      -1.3100e-02,  6.5238e-03,  1.0643e-02,  2.4487e-03, -5.4523e-04,\n                       1.5786e-03,  9.3900e-03, -4.1642e-03,  1.4596e-02,  1.9135e-02,\n                       7.7523e-03,  5.3930e-03,  2.6580e-02,  9.6048e-03,  1.3367e-02,\n                       1.0891e-03,  7.8824e-03, -8.0961e-03,  3.7968e-03,  1.2411e-02,\n                      -1.1054e-02,  6.7430e-03,  4.8284e-03, -1.1077e-02,  5.4202e-03,\n                       3.4150e-03,  4.0094e-03,  8.2411e-03,  2.1089e-02,  4.7997e-03,\n                      -1.5240e-03,  6.4084e-03,  6.3923e-03,  7.1305e-03,  8.4037e-03,\n                      -4.8076e-03,  1.9170e-03,  3.9693e-03,  1.0386e-02, -3.5333e-03,\n                       1.1353e-02, -1.1836e-02,  1.4353e-02, -1.0043e-03, -9.0560e-03,\n                       2.8714e-03,  1.1269e-02,  1.1881e-02, -8.1071e-03,  1.4425e-02,\n                       1.8357e-02, -1.2862e-03,  9.0661e-04,  4.5088e-03,  7.1408e-03,\n                       1.1240e-02, -5.0662e-03,  9.4670e-03,  4.5585e-03, -2.5288e-03,\n                       1.0548e-02,  5.1050e-03,  3.0754e-03,  7.7780e-03,  8.3395e-03,\n                      -6.3583e-04,  2.1542e-02,  1.7079e-02, -1.7099e-03,  5.2915e-03,\n                      -1.4536e-02,  2.7706e-03,  5.5363e-03,  1.1953e-02,  7.3071e-03,\n                       2.5124e-02,  7.9315e-03, -1.6831e-03, -2.2741e-02,  1.0062e-02,\n                       1.7996e-03,  3.4937e-03, -3.7026e-03,  4.0731e-03,  9.9470e-03,\n                      -9.0257e-03, -6.2205e-03,  6.0915e-03,  1.5190e-02,  1.3642e-02,\n                       8.0707e-03,  1.0722e-02,  2.5499e-03,  1.2776e-03, -1.4411e-02,\n                       3.6701e-03,  1.3693e-02, -2.9845e-03,  2.4139e-03, -1.0482e-02,\n                       1.4018e-02,  1.8371e-02,  1.7696e-03,  3.3642e-04,  9.8811e-03,\n                      -3.5170e-04,  1.5895e-02,  1.4677e-02,  1.1777e-02, -4.8551e-05,\n                      -1.5621e-03,  1.8747e-02,  8.0064e-03,  1.6684e-02,  4.3264e-03,\n                      -3.0390e-03, -3.6554e-03,  8.3829e-04,  1.0192e-02, -6.2357e-03,\n                      -1.2813e-03,  2.7329e-03,  1.3295e-03,  1.0005e-02,  1.0223e-02,\n                       2.5045e-03,  1.2901e-02,  2.9301e-03,  1.5376e-02,  1.8400e-02,\n                       1.6355e-02, -8.5364e-04,  1.0838e-02, -2.8020e-03, -1.0860e-02,\n                      -2.1172e-03,  1.6197e-03, -8.0019e-04,  1.7816e-02,  1.1950e-02,\n                       2.7652e-03, -7.6293e-03,  7.2079e-03,  5.8560e-03,  1.6358e-02,\n                       5.0898e-03,  9.1835e-03,  1.4028e-02,  8.3954e-03, -1.3888e-02,\n                      -6.6470e-03, -2.6172e-03,  2.1919e-02,  5.8810e-03,  1.7710e-03,\n                      -2.2386e-03,  8.8085e-03, -9.0727e-03, -1.0749e-02,  1.6610e-02,\n                       3.8294e-03,  1.0589e-02,  1.4135e-02, -4.6294e-03,  2.8441e-03,\n                       7.6860e-03, -4.2460e-03,  1.4274e-02, -1.5621e-02,  1.0205e-02,\n                       8.9526e-03, -1.6260e-03,  1.4688e-02,  8.6138e-03, -7.4103e-03,\n                       4.3163e-03,  2.0667e-02,  2.0862e-02,  1.7362e-02,  5.0182e-03,\n                      -6.5817e-03,  1.4792e-02, -3.6902e-03,  2.1740e-03,  5.8518e-03,\n                       1.4639e-04,  1.1807e-02,  1.5026e-02,  6.8936e-03,  6.9249e-03,\n                       9.7913e-03,  3.2702e-03, -7.7497e-05,  6.7784e-03, -1.1610e-03,\n                      -1.1122e-02, -1.9100e-03,  7.0872e-03,  2.5784e-02, -4.9091e-03,\n                       5.4790e-03, -1.1933e-03,  3.5152e-03, -1.8601e-02,  7.6930e-03,\n                       1.7909e-02,  3.7828e-04,  1.0939e-02,  8.6657e-03,  1.0853e-02,\n                       3.2809e-03,  6.1784e-03, -2.6066e-03,  1.0758e-02,  7.0968e-03,\n                       9.9172e-03,  2.6979e-03,  4.0690e-03,  1.2734e-03,  4.1193e-03,\n                       1.4020e-02,  4.5682e-03,  9.6183e-03, -2.9744e-03, -6.3377e-03,\n                       1.5441e-02,  8.3987e-03,  2.1647e-02,  2.3877e-02,  1.2482e-02,\n                       2.3371e-03], dtype=torch.float64)),\n             ('6.1.convpath.0.2.1.running_mean',\n              tensor([-2.0302e-01,  2.3928e-01,  1.1861e-02, -2.9150e-01, -3.4993e-01,\n                      -2.2114e-01,  3.3553e-01, -8.5139e-01, -7.8087e-02,  1.8976e-01,\n                      -4.2974e-01,  1.2698e-01,  2.9693e-01,  2.4106e-01, -3.9244e-01,\n                       1.9130e-02, -3.1942e-01, -3.7289e-01,  3.6165e-01, -3.5788e-01,\n                      -7.6797e-02,  1.7820e-01,  2.2462e-01,  6.1932e-01, -6.8466e-01,\n                       2.9511e-01, -2.2852e-01,  2.1874e-01, -2.1943e-01,  2.1887e-02,\n                       7.8857e-02,  7.3661e-01,  6.3667e-01, -9.2395e-01,  4.4736e-01,\n                       7.0950e-01,  5.1350e-01, -5.4435e-01,  1.4070e-02, -2.0086e-01,\n                       3.9774e-01,  2.9724e-01, -3.4697e-02, -9.6656e-02, -3.4594e-01,\n                      -1.5180e-01, -1.1198e-01, -6.5215e-02,  9.0198e-02, -6.3278e-03,\n                      -3.8864e-01, -8.3079e-01, -3.8943e-01, -3.6461e-02, -1.1616e-01,\n                       7.5818e-01, -1.0705e-01,  1.2509e-02, -7.9266e-02, -2.1095e-01,\n                      -3.6026e-01, -1.4638e-01,  6.0615e-03,  4.0779e-01, -2.4074e-01,\n                      -1.6403e-02,  5.7264e-01, -1.2510e-01,  1.9139e-01,  2.3029e-01,\n                       2.8744e-01,  2.4143e-01, -1.1884e-01, -9.9484e-02, -4.3107e-01,\n                      -5.1000e-01, -1.2783e-01, -5.5991e-01, -1.2030e-01, -3.5053e-01,\n                       2.7037e-01, -1.7367e-02,  5.2911e-01,  2.2383e-01, -4.1650e-01,\n                      -1.7497e-01, -9.1881e-02,  3.9545e-01,  2.2948e-01, -4.3008e-01,\n                       1.0458e-01, -5.4550e-01,  1.8406e-01,  3.9215e-01,  2.6270e-01,\n                      -5.1332e-02,  2.5807e-01, -2.5327e-01, -4.9878e-01,  1.8894e-01,\n                      -6.2112e-01, -1.2263e-03, -3.4638e-01, -1.8756e-01,  2.7836e-01,\n                      -2.2012e-01, -2.6579e-01,  6.3353e-01,  2.4430e-01,  3.5475e-01,\n                       5.4465e-02, -1.2562e-02,  1.1921e-01,  1.4617e-01, -7.0777e-01,\n                      -3.4613e-01,  1.0903e+00,  7.9713e-01, -2.3165e-02,  4.6684e-01,\n                       1.4032e-01,  1.9835e-01,  3.3332e-01,  5.9843e-01,  1.5499e-01,\n                       1.8751e-01, -3.2765e-01,  8.0873e-01,  4.8001e-01,  6.7062e-01,\n                      -1.3014e-02, -2.2429e-01,  5.1441e-01, -3.8093e-01,  1.1214e-01,\n                       1.1483e-01,  3.2469e-01,  6.3021e-01,  3.4559e-01, -3.4341e-01,\n                      -9.6259e-01,  1.9911e-01, -9.7398e-01,  2.4920e-02,  4.8902e-02,\n                       6.4020e-01, -2.0510e-01, -3.4471e-01,  1.2213e-01, -7.2666e-01,\n                      -4.3484e-01, -3.2729e-01, -6.9196e-02,  3.6942e-01,  4.7587e-01,\n                       8.2862e-02,  9.5103e-04,  2.2106e-01,  3.0261e-01, -1.4533e-01,\n                       5.8162e-01,  2.7436e-01,  2.6451e-01, -9.4665e-01, -5.9348e-01,\n                       4.3466e-01, -2.5857e-01,  4.9502e-01,  1.2646e-01,  8.8504e-02,\n                      -1.7012e-02,  1.6124e-01, -7.2137e-01,  1.8796e-01,  9.7766e-01,\n                       8.5715e-01,  3.7755e-01,  1.1222e-01, -3.4441e-01, -2.3366e-01,\n                      -3.7620e-01, -2.0036e-01,  8.0275e-02,  1.8547e-01, -6.5372e-02,\n                       2.9282e-01,  3.2096e-01,  2.6789e-01,  3.0135e-01, -2.2187e-01,\n                       5.1381e-01, -3.7257e-01,  3.3345e-01, -8.3657e-02, -5.8958e-02,\n                      -5.0750e-01, -1.9216e-01,  6.3049e-01,  3.3090e-01, -2.8191e-02,\n                       2.2842e-01,  8.6185e-02,  7.8209e-01,  6.1467e-01, -1.1337e+00,\n                      -3.9464e-01, -2.7485e-01, -1.5055e-02, -1.3589e-03, -3.9779e-01,\n                      -8.3975e-02,  5.1198e-01, -2.9870e-01,  5.9018e-02,  1.4741e-01,\n                      -1.7628e-01,  7.5662e-02, -2.7774e-01, -9.5549e-02, -2.1739e-01,\n                       8.7645e-02,  6.4962e-01,  7.3246e-02, -8.1537e-02, -7.6913e-01,\n                       3.6128e-02, -3.5163e-02,  4.5012e-01, -2.9773e-01,  8.9025e-01,\n                      -1.3018e-01,  1.6535e-01, -6.2737e-01,  2.5452e-01,  1.0737e-01,\n                      -2.8151e-01,  2.4892e-01,  2.7232e-01, -1.1888e-01, -6.7222e-01,\n                       4.2951e-01, -2.8898e-01, -2.6196e-01,  3.5638e-01, -2.3585e-01,\n                      -1.6005e-01,  3.4896e-01, -1.6829e-01, -1.1115e-01,  5.6126e-01,\n                      -7.5377e-01,  1.1297e+00,  1.9611e-01, -1.4428e-02, -1.8066e-02,\n                       2.6949e-01], dtype=torch.float64)),\n             ('6.1.convpath.0.2.1.running_var',\n              tensor([0.5338, 0.5564, 0.2546, 0.4130, 0.1595, 0.5023, 0.3013, 0.5431, 0.3187,\n                      0.1764, 0.3705, 0.5176, 0.0649, 0.4851, 0.5429, 0.5387, 0.3057, 0.3401,\n                      0.2875, 0.4934, 0.3816, 0.4963, 0.3320, 0.5129, 0.4949, 0.4840, 0.2788,\n                      0.2973, 0.2616, 0.1360, 0.6689, 0.4424, 0.6001, 0.3744, 0.3933, 0.3151,\n                      0.3604, 0.2965, 0.1025, 0.4086, 0.4977, 0.3096, 0.2554, 0.1878, 0.1988,\n                      0.3923, 0.1056, 0.2473, 0.4625, 0.1310, 0.4256, 0.4927, 0.3224, 0.5657,\n                      0.3128, 0.2832, 0.4739, 0.3236, 0.5085, 0.2549, 0.1370, 0.4492, 0.2537,\n                      0.1955, 0.3470, 0.1965, 0.5290, 0.3061, 0.2122, 0.5322, 0.4395, 0.1623,\n                      0.2025, 0.4709, 0.5198, 0.2841, 0.3031, 0.3044, 0.5058, 0.3360, 0.1811,\n                      0.2013, 0.3937, 0.4537, 0.5181, 0.7086, 0.3337, 0.3017, 0.5167, 0.1958,\n                      0.3957, 0.4683, 0.4542, 0.2254, 0.4159, 0.2281, 0.3685, 0.2733, 0.2758,\n                      0.2399, 0.3942, 0.3792, 0.3470, 0.3256, 0.1442, 0.3583, 0.4504, 0.4712,\n                      0.3636, 0.2515, 0.3666, 0.4540, 0.8550, 0.3606, 0.3602, 0.4981, 0.3656,\n                      0.5337, 0.3742, 0.4996, 0.2233, 0.3993, 0.4624, 0.4538, 0.3044, 0.5115,\n                      0.1800, 0.3015, 0.3347, 0.1906, 0.2489, 0.2185, 0.3307, 0.2586, 0.2936,\n                      0.2078, 0.1891, 0.4875, 0.5307, 0.2902, 0.6349, 0.2124, 0.5343, 0.4224,\n                      0.1106, 0.5053, 0.1948, 0.3957, 0.1875, 0.4339, 0.4597, 0.2213, 0.3603,\n                      0.5677, 0.3849, 0.4209, 0.3428, 0.3273, 0.6189, 0.2013, 0.2600, 0.3837,\n                      0.2239, 0.7583, 0.7795, 0.6828, 0.5024, 0.5953, 0.4600, 0.3375, 0.1138,\n                      0.3194, 0.4556, 0.1979, 0.3740, 0.3590, 0.2702, 0.3942, 0.3662, 0.1440,\n                      0.3228, 0.2679, 0.4051, 0.5852, 0.2131, 0.4362, 0.3384, 0.2164, 0.2297,\n                      0.5973, 0.2037, 0.5251, 0.2238, 0.4663, 0.4905, 0.1288, 0.4315, 0.3864,\n                      0.2771, 0.1604, 0.2165, 0.3582, 0.3555, 0.3907, 0.3972, 0.3187, 0.0990,\n                      0.2445, 0.3006, 0.4075, 0.0440, 0.3822, 0.2202, 0.6097, 0.1305, 0.3992,\n                      0.2364, 0.3478, 0.3605, 0.4326, 0.2476, 0.2974, 0.2430, 0.3677, 0.4900,\n                      0.3069, 0.4193, 0.3520, 0.4766, 0.4849, 0.3115, 0.1262, 0.5743, 0.3966,\n                      0.3361, 0.4644, 0.3764, 0.1543, 0.3860, 0.4361, 0.2029, 0.1290, 0.6413,\n                      0.2860, 0.2838, 0.3715, 0.1239, 0.5479, 0.2735, 0.5208, 0.6990, 0.4562,\n                      0.1960, 0.4321, 0.1099, 0.2580], dtype=torch.float64)),\n             ('6.1.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.2.convs.0.0.weight',\n              tensor([[[-0.0565],\n                       [-0.0505],\n                       [-0.1425],\n                       ...,\n                       [ 0.0184],\n                       [ 0.0461],\n                       [-0.0331]],\n              \n                      [[ 0.0799],\n                       [-0.0190],\n                       [ 0.0703],\n                       ...,\n                       [ 0.0497],\n                       [-0.0004],\n                       [-0.0778]],\n              \n                      [[ 0.0756],\n                       [ 0.1013],\n                       [ 0.0731],\n                       ...,\n                       [-0.0379],\n                       [-0.0231],\n                       [ 0.0515]],\n              \n                      ...,\n              \n                      [[-0.0708],\n                       [-0.1675],\n                       [ 0.0322],\n                       ...,\n                       [ 0.1841],\n                       [-0.1723],\n                       [ 0.0598]],\n              \n                      [[ 0.1497],\n                       [-0.0871],\n                       [ 0.0099],\n                       ...,\n                       [ 0.0473],\n                       [-0.0713],\n                       [-0.1062]],\n              \n                      [[-0.0440],\n                       [ 0.0326],\n                       [ 0.1056],\n                       ...,\n                       [-0.0556],\n                       [ 0.0556],\n                       [-0.1885]]], dtype=torch.float64)),\n             ('6.2.convs.0.1.weight',\n              tensor([0.9888, 0.9610, 0.9569, 0.9873, 0.9865, 0.9986, 0.9541, 0.9751, 0.9658,\n                      0.9597, 0.9952, 0.9636, 0.9876, 0.9771, 0.9680, 0.9833, 0.9687, 0.9905,\n                      0.9740, 0.9484, 0.9670, 0.9592, 0.9753, 0.9692, 0.9646, 0.9617, 0.9880,\n                      0.9810, 0.9674, 0.9735, 0.9548, 0.9768, 0.9672, 0.9722, 0.9828, 0.9717,\n                      0.9767, 0.9855, 0.9532, 0.9746, 0.9953, 0.9690, 0.9691, 0.9922, 0.9784,\n                      0.9578, 0.9706, 0.9693, 0.9686, 0.9489, 0.9714, 0.9651, 0.9884, 0.9584,\n                      0.9896, 0.9519, 0.9730, 0.9667, 0.9552, 0.9789, 0.9885, 0.9736, 0.9731,\n                      0.9608], dtype=torch.float64)),\n             ('6.2.convs.0.1.bias',\n              tensor([ 1.1554e-02, -1.6822e-03, -2.7562e-03,  3.4358e-03,  9.6338e-03,\n                      -7.5445e-03,  7.5815e-03,  1.6349e-03, -8.4027e-03, -1.4825e-03,\n                       2.7449e-03,  1.0978e-03,  1.9848e-02,  4.3238e-03,  2.4500e-02,\n                       1.7340e-02,  7.1757e-03,  3.7631e-03, -4.6050e-03, -4.5539e-03,\n                       1.4733e-02, -2.6916e-03,  1.9335e-02,  7.2475e-03, -2.4447e-02,\n                      -1.6473e-02,  2.0872e-02,  9.9249e-03, -6.3243e-03,  2.9428e-03,\n                      -8.3791e-03, -2.2472e-03,  1.9201e-02,  8.5608e-04, -3.1818e-03,\n                      -1.0603e-02, -9.5419e-03,  1.5490e-02, -3.1767e-03,  1.7913e-02,\n                       1.1034e-02, -6.2602e-03,  1.4356e-02,  2.5350e-02,  4.7768e-03,\n                      -3.8693e-03,  9.8540e-03, -8.6633e-03, -6.2785e-03, -1.8505e-02,\n                      -9.9820e-03, -1.1923e-05,  1.6003e-02, -1.2047e-02,  1.2562e-02,\n                       4.5174e-03,  8.5935e-03, -6.3272e-03, -1.4336e-03,  2.1240e-02,\n                       3.5608e-03, -1.0999e-02, -1.5257e-03,  7.5104e-03],\n                     dtype=torch.float64)),\n             ('6.2.convs.0.1.running_mean',\n              tensor([-3.2967e-01, -3.9153e-02, -6.6658e-01, -1.4451e-01, -3.7049e-01,\n                      -1.8816e-01, -5.6564e-02, -6.2019e-01,  8.6744e-01,  5.1065e-01,\n                       5.1709e-02, -1.3599e-01,  2.7698e-01, -8.5152e-01, -2.5491e-01,\n                      -1.3458e-01,  5.8681e-02, -7.2455e-01,  1.2618e+00, -2.8236e-01,\n                      -4.6423e-01, -3.2596e-01, -3.4369e-01,  3.4760e-01,  1.8911e-01,\n                      -2.1844e-01,  7.1364e-02, -1.5297e-01, -3.9064e-01,  1.8795e-01,\n                      -6.8499e-01, -7.0110e-01, -7.8917e-01,  2.7971e-01,  3.5106e-01,\n                      -3.8349e-01,  4.3666e-01, -6.1573e-01, -1.3775e-01, -3.8474e-01,\n                      -5.5215e-01, -7.2952e-04, -6.2953e-01, -3.3484e-01,  7.0126e-01,\n                      -7.2212e-01, -3.9999e-01,  4.5686e-02,  1.4969e-01, -3.1667e-01,\n                       2.4763e-01,  3.2311e-01,  8.9678e-01, -5.2978e-03, -2.5350e-01,\n                      -7.1559e-01,  1.7360e-01,  1.6877e-01,  1.5529e-01, -7.5959e-01,\n                      -1.3622e-01, -1.5824e-01, -1.3703e-01,  1.0238e-01],\n                     dtype=torch.float64)),\n             ('6.2.convs.0.1.running_var',\n              tensor([0.3285, 0.3413, 0.1737, 0.3383, 0.1023, 0.1168, 0.2615, 0.2192, 1.1763,\n                      1.8198, 0.2739, 0.0949, 0.1817, 0.2172, 0.3546, 0.1337, 0.1192, 0.0897,\n                      1.3786, 1.0233, 0.3726, 0.2219, 0.2441, 0.2901, 0.1207, 0.1242, 0.2375,\n                      0.1079, 0.4603, 0.1063, 0.2290, 0.2517, 0.2216, 0.2103, 0.1326, 0.0678,\n                      0.0982, 0.1481, 0.4446, 0.1689, 0.1410, 0.2853, 0.5928, 0.1894, 1.0746,\n                      0.5542, 0.1596, 0.3659, 0.8283, 0.5587, 0.2637, 0.4427, 0.5629, 0.0843,\n                      0.2756, 0.0880, 0.1890, 0.2800, 0.3641, 0.1700, 0.1601, 0.3774, 0.1645,\n                      0.2921], dtype=torch.float64)),\n             ('6.2.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.2.convs.1.0.weight',\n              tensor([[[ 0.0640,  0.0503, -0.0179, -0.1204,  0.0662],\n                       [-0.0277,  0.0530, -0.0696,  0.0966,  0.0788],\n                       [-0.0802, -0.0350, -0.0427, -0.0968,  0.0195],\n                       ...,\n                       [-0.0565, -0.0376, -0.0042,  0.1552, -0.0679],\n                       [-0.0381,  0.0058, -0.0195,  0.1849,  0.0175],\n                       [-0.0399,  0.1749, -0.0332, -0.0042,  0.1379]],\n              \n                      [[-0.0218,  0.0754,  0.1295,  0.1705,  0.0328],\n                       [-0.0254, -0.0737, -0.0940, -0.0510,  0.0290],\n                       [ 0.0725, -0.0674, -0.0428, -0.0116, -0.0693],\n                       ...,\n                       [-0.0133,  0.0700,  0.0033, -0.0816,  0.0349],\n                       [ 0.0849,  0.0050, -0.0462, -0.0440,  0.1171],\n                       [-0.0054, -0.0612, -0.0168, -0.1379,  0.0123]],\n              \n                      [[ 0.0157,  0.1279,  0.0245, -0.0729, -0.0894],\n                       [-0.1057, -0.0653,  0.0606, -0.0190,  0.0418],\n                       [-0.1371,  0.0737,  0.0561, -0.0092, -0.0349],\n                       ...,\n                       [ 0.0511, -0.0160,  0.0816, -0.1216, -0.1560],\n                       [-0.0967,  0.0492, -0.0260,  0.0109, -0.0239],\n                       [-0.0196, -0.0609, -0.0373, -0.1247,  0.0432]],\n              \n                      ...,\n              \n                      [[ 0.0235, -0.1488,  0.0184, -0.0346,  0.0250],\n                       [ 0.0932, -0.1516, -0.0974, -0.0095,  0.0476],\n                       [-0.0590, -0.0941,  0.0122, -0.0764,  0.0366],\n                       ...,\n                       [-0.0107,  0.0310, -0.0095, -0.0037, -0.2250],\n                       [-0.0463, -0.0238,  0.1784, -0.0459,  0.0934],\n                       [-0.0757, -0.1031, -0.0252, -0.0364, -0.1420]],\n              \n                      [[ 0.0908,  0.0338,  0.1147, -0.0511, -0.0121],\n                       [ 0.0419,  0.0296,  0.0499,  0.1017, -0.1364],\n                       [-0.1014,  0.0257,  0.0062, -0.0811,  0.1540],\n                       ...,\n                       [-0.0584, -0.0031, -0.0786, -0.0384,  0.1889],\n                       [ 0.0092, -0.1163,  0.0110, -0.0132,  0.0251],\n                       [ 0.1333, -0.0061,  0.1475, -0.0111, -0.0038]],\n              \n                      [[-0.1530,  0.0294, -0.0312, -0.1085,  0.0727],\n                       [ 0.0472, -0.0804, -0.0971,  0.0183, -0.1105],\n                       [-0.0830, -0.1793, -0.0079,  0.0241, -0.0578],\n                       ...,\n                       [ 0.0029,  0.1342,  0.0206,  0.0863,  0.0962],\n                       [-0.1063, -0.0248,  0.0383,  0.1320,  0.1679],\n                       [ 0.0563,  0.0553,  0.0082,  0.0663,  0.1152]]], dtype=torch.float64)),\n             ('6.2.convs.1.1.weight',\n              tensor([0.9524, 0.9690, 0.9670, 0.9751, 0.9931, 0.9344, 1.0130, 0.9564, 0.9835,\n                      0.9765, 0.9833, 0.9700, 0.9594, 0.9645, 0.9682, 0.9667, 0.9245, 0.9604,\n                      0.9985, 0.9499, 0.9425, 0.9916, 0.9515, 0.9483, 0.9705, 0.9623, 0.9695,\n                      0.9497, 0.9833, 0.9629, 0.9405, 0.9676, 0.9640, 0.9672, 0.9945, 0.9558,\n                      0.9710, 0.9613, 0.9623, 0.9538, 1.0019, 0.9743, 0.9480, 0.9738, 0.9568,\n                      0.9477, 0.9596, 0.9819, 0.9575, 0.9939, 0.9720, 0.9466, 0.9592, 0.9637,\n                      0.9303, 0.9777, 0.9673, 0.9387, 0.9819, 0.9779, 0.9859, 0.9819, 0.9811,\n                      0.9720], dtype=torch.float64)),\n             ('6.2.convs.1.1.bias',\n              tensor([ 2.7470e-03, -1.3765e-02,  6.0983e-03, -4.1245e-04,  5.1237e-03,\n                      -8.1063e-05, -1.5589e-02,  6.4030e-03,  1.3215e-03,  7.0557e-04,\n                       6.4068e-03, -1.6382e-02, -1.9350e-02,  1.0091e-02,  8.8647e-03,\n                       3.3026e-03, -2.7496e-02, -1.7042e-02, -3.3820e-03, -2.7452e-03,\n                      -1.3998e-02,  2.7501e-03, -3.0523e-02, -3.5469e-02, -3.5460e-04,\n                       9.6738e-03,  1.3382e-02,  2.7688e-03,  1.0512e-02, -8.7872e-03,\n                      -1.9938e-02,  1.1889e-02, -3.1059e-02, -2.5302e-02,  8.5192e-03,\n                      -4.5392e-03,  1.5666e-02, -1.5421e-02, -2.6320e-02, -9.8213e-03,\n                       1.8944e-02,  4.0188e-03,  6.4368e-03, -4.7974e-03, -2.2776e-02,\n                      -1.8603e-03, -6.9103e-03,  2.6461e-02, -1.1599e-02, -4.4005e-05,\n                       3.9116e-03, -1.2824e-03, -8.4190e-03, -2.4090e-02, -1.9181e-02,\n                       2.9037e-02,  1.8839e-03,  1.1910e-03,  8.6546e-03,  1.9068e-02,\n                      -6.6260e-03,  2.3253e-02, -1.3991e-02, -4.3950e-03],\n                     dtype=torch.float64)),\n             ('6.2.convs.1.1.running_mean',\n              tensor([-0.3747,  0.7249, -0.0904,  0.2532, -0.5003, -0.0956, -0.1688,  0.0421,\n                       0.3087,  0.8061,  0.2120, -0.1280, -0.1954, -0.6034,  0.2099, -0.4808,\n                      -0.2288,  0.1844, -0.1454,  0.0414,  0.0970,  0.0087,  0.0031,  0.4263,\n                      -0.4281,  0.2461, -0.1865, -0.8033,  0.7010, -0.2709, -0.1924,  0.3431,\n                       0.1772,  0.3815,  0.2237, -0.2250, -0.1793, -0.0759,  0.1836, -0.2223,\n                       0.5368, -0.1475, -0.0458, -0.1367,  0.7305, -0.7653, -0.3082, -0.2958,\n                       0.1892,  0.4999,  0.7705,  0.3761, -0.1520, -0.7156, -0.8855,  0.1022,\n                       0.0028,  0.1753, -0.3458, -0.6135,  1.0683, -1.1924,  0.6468,  0.3145],\n                     dtype=torch.float64)),\n             ('6.2.convs.1.1.running_var',\n              tensor([0.4645, 0.7083, 0.6411, 0.6405, 0.5013, 0.4923, 0.5241, 0.5759, 0.5142,\n                      0.7873, 0.3988, 0.4638, 0.4338, 0.7547, 0.6025, 0.5707, 0.7279, 0.4259,\n                      0.6474, 0.9526, 0.5976, 0.6822, 1.0449, 0.7574, 0.4651, 0.7870, 0.6851,\n                      0.7495, 0.9418, 0.2691, 0.7484, 0.7944, 0.8600, 0.3978, 0.3830, 0.4585,\n                      0.4799, 0.4525, 0.9228, 0.4628, 0.3921, 0.6896, 0.5607, 0.6229, 0.9776,\n                      0.6091, 0.6134, 0.4779, 0.3467, 0.5241, 0.6906, 0.5199, 0.3914, 0.4744,\n                      0.5899, 0.6030, 0.6422, 0.7384, 0.4384, 0.4773, 0.5557, 1.0260, 0.5519,\n                      0.7797], dtype=torch.float64)),\n             ('6.2.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.2.convs.2.0.weight',\n              tensor([[[ 0.2244],\n                       [ 0.2367],\n                       [ 0.1866],\n                       ...,\n                       [ 0.1014],\n                       [-0.0672],\n                       [-0.0143]],\n              \n                      [[ 0.1361],\n                       [-0.0172],\n                       [-0.0235],\n                       ...,\n                       [-0.1010],\n                       [-0.1749],\n                       [-0.0074]],\n              \n                      [[-0.0752],\n                       [ 0.1052],\n                       [-0.0228],\n                       ...,\n                       [-0.1157],\n                       [-0.1313],\n                       [ 0.0004]],\n              \n                      ...,\n              \n                      [[ 0.1466],\n                       [-0.3195],\n                       [ 0.0626],\n                       ...,\n                       [-0.1564],\n                       [ 0.0305],\n                       [-0.0880]],\n              \n                      [[-0.0984],\n                       [ 0.1059],\n                       [ 0.1134],\n                       ...,\n                       [-0.0243],\n                       [-0.1528],\n                       [ 0.0189]],\n              \n                      [[-0.2947],\n                       [ 0.0384],\n                       [-0.1119],\n                       ...,\n                       [ 0.1308],\n                       [-0.1934],\n                       [ 0.1931]]], dtype=torch.float64)),\n             ('6.2.convs.2.1.weight',\n              tensor([-1.7022e-03, -1.1376e-02, -1.3251e-02,  5.4066e-03,  5.2605e-03,\n                       2.1662e-02, -1.0669e-03, -1.5245e-02,  8.5076e-03, -4.7421e-03,\n                       1.2559e-02,  1.7550e-02, -1.6513e-02, -1.0280e-03,  1.5813e-02,\n                      -5.4644e-02, -3.7853e-02, -1.8809e-04,  1.0351e-02, -3.6274e-03,\n                      -1.1859e-02, -3.4023e-03, -2.3923e-02, -1.6862e-02, -6.0764e-03,\n                       8.0165e-03, -8.0430e-03, -2.9811e-03, -1.2213e-02,  1.0960e-03,\n                      -5.2426e-03,  6.5109e-02, -1.0544e-03, -2.0072e-02, -3.2147e-02,\n                       8.5112e-04,  2.4154e-03, -2.0200e-02,  1.4544e-02, -1.5003e-02,\n                       1.8892e-02,  2.6847e-02,  6.2115e-03,  1.6933e-02, -1.0358e-02,\n                       1.2553e-02,  8.0310e-03,  7.3795e-03, -4.4583e-02, -1.5242e-03,\n                       8.8975e-03,  1.2235e-02, -8.5119e-03,  5.0601e-03,  6.8982e-03,\n                       2.8665e-02,  2.0481e-04, -2.2551e-02, -1.7763e-02, -1.6430e-02,\n                      -2.7394e-02, -1.2619e-02,  5.1490e-03,  2.5771e-03, -3.2446e-02,\n                       1.6769e-02,  1.1167e-02,  2.5183e-02,  1.1565e-02,  9.0588e-03,\n                      -1.0020e-02,  3.0873e-02,  1.8678e-02,  1.6038e-02, -2.4860e-02,\n                      -1.9459e-02,  1.2336e-02, -1.2152e-02,  4.4370e-03, -1.7990e-02,\n                       9.3680e-03, -5.5566e-03,  1.6287e-02,  1.7906e-02, -1.3730e-02,\n                       2.0360e-02, -4.1745e-02,  1.9214e-02,  6.0129e-03, -1.8335e-02,\n                       1.3433e-02,  2.7189e-02,  2.0968e-05,  2.5771e-03, -1.1901e-02,\n                       5.6859e-03, -1.5649e-02, -1.7254e-02,  1.9577e-02,  1.7229e-02,\n                       6.8233e-03, -2.2046e-02, -1.6678e-02, -2.5229e-02, -1.0523e-02,\n                       1.7920e-02,  9.8209e-03, -1.0585e-02,  3.0046e-02,  7.0828e-03,\n                       1.1450e-02,  1.0226e-02, -1.4789e-03,  9.4695e-03,  7.8820e-03,\n                       2.8922e-02,  9.2448e-03, -2.1661e-02,  3.3809e-03,  5.0388e-03,\n                       1.0983e-02, -1.1586e-02,  3.4584e-04, -1.7022e-02,  2.5300e-02,\n                       2.1670e-02,  1.0669e-02,  1.5832e-03,  1.3557e-02, -1.2687e-02,\n                       1.1940e-02,  2.5415e-02, -4.0661e-03, -1.5388e-02, -1.9747e-02,\n                      -2.5839e-02,  7.6751e-03, -1.0887e-02,  1.9855e-02,  1.1414e-02,\n                      -7.6104e-04,  2.0603e-04, -1.0158e-03, -1.0813e-03, -3.0590e-03,\n                       4.9907e-03, -1.3375e-02, -1.3059e-02, -2.7876e-02, -1.3792e-03,\n                      -2.5615e-02, -9.0706e-03,  6.5247e-03, -9.4027e-04, -2.5703e-03,\n                       4.5885e-03, -6.3975e-03,  1.1728e-03, -3.9283e-03,  3.4310e-03,\n                      -7.3474e-03,  2.3849e-02,  2.2057e-02,  2.1656e-02, -3.8555e-03,\n                       1.6120e-02, -3.3966e-03,  2.5070e-03, -7.4572e-03, -9.9572e-03,\n                       1.5717e-02,  1.4784e-02, -8.6057e-03,  1.9095e-02, -5.4790e-03,\n                       3.0067e-02, -3.7296e-02,  2.8053e-02,  4.5763e-03,  6.6212e-03,\n                       4.3536e-03,  6.2611e-03,  9.4757e-03, -7.4222e-03, -7.8226e-03,\n                       1.7546e-03,  2.4835e-03,  3.4610e-02,  1.4749e-02,  4.1243e-03,\n                      -2.8901e-03, -1.9672e-02,  1.1439e-02, -2.6164e-02, -2.7266e-02,\n                      -5.8925e-03, -1.7949e-05, -1.2002e-02,  8.1637e-03,  2.3852e-02,\n                      -1.7630e-03, -1.0560e-02, -1.0996e-02,  9.7427e-03,  1.1905e-02,\n                       1.2258e-02, -1.2684e-02,  6.6713e-03, -2.8566e-03,  1.2590e-02,\n                       1.7187e-02,  3.0867e-03,  2.5546e-03, -3.6672e-03, -2.8883e-03,\n                       1.3775e-02,  4.5662e-03, -9.9767e-03,  2.0074e-02,  4.2469e-03,\n                       1.3227e-02, -1.2160e-02, -1.4508e-02,  1.5343e-02,  1.3865e-02,\n                       1.3456e-02, -3.1871e-03, -3.5910e-03,  5.2389e-02, -6.1178e-04,\n                       1.5347e-02,  2.6553e-03, -6.7049e-03,  1.2972e-03,  1.6571e-02,\n                      -2.5664e-02, -6.8891e-03,  1.1461e-02, -3.2691e-03, -2.7285e-02,\n                       1.8714e-02,  2.5263e-02, -3.5005e-03,  1.2603e-02, -1.2232e-02,\n                      -1.3414e-02,  2.2626e-03,  2.1878e-03, -1.2032e-02,  4.0404e-02,\n                       2.4400e-02, -8.6483e-03, -1.0482e-02,  1.7714e-02, -1.3392e-02,\n                       4.0087e-02], dtype=torch.float64)),\n             ('6.2.convs.2.1.bias',\n              tensor([-2.6506e-03, -2.7597e-03,  1.8489e-02,  7.1597e-03,  5.3737e-03,\n                       3.4115e-03,  2.1322e-02,  7.9633e-04,  1.0076e-02,  2.1337e-02,\n                       6.5399e-03, -7.9954e-03,  1.2075e-02, -6.2468e-03,  4.7535e-03,\n                       7.7885e-03,  1.7050e-02, -3.2981e-04,  1.4969e-02, -8.1884e-03,\n                      -3.8657e-03,  3.2743e-03,  2.0814e-03,  6.6063e-03, -5.2091e-03,\n                      -1.3007e-02,  6.7238e-03,  1.0376e-02,  1.1016e-03, -1.3589e-03,\n                       8.1286e-03,  7.9499e-03, -7.9539e-03,  1.6475e-02,  1.7196e-02,\n                       7.2007e-03,  9.9995e-04,  2.8488e-02,  9.7364e-03,  1.1173e-02,\n                      -1.7008e-04,  1.5342e-02, -9.6732e-03,  4.3593e-03,  1.1487e-02,\n                      -1.0231e-02,  7.2345e-03,  4.1771e-03, -1.1182e-02,  7.9030e-03,\n                       8.4675e-03,  2.2596e-03,  8.3431e-03,  1.6841e-02,  4.1280e-03,\n                      -1.1390e-03,  7.1495e-03,  5.5032e-03,  7.4040e-03,  8.2298e-03,\n                      -7.2225e-03,  1.7846e-03, -1.2505e-03,  1.0236e-02, -4.2406e-03,\n                       1.3371e-02, -1.1343e-02,  1.2300e-02,  4.6490e-03, -9.4152e-03,\n                       2.4298e-03,  1.1077e-02,  9.0883e-03, -8.3255e-03,  1.4961e-02,\n                       1.7883e-02, -1.0875e-03,  3.2563e-03,  3.9161e-03,  6.1038e-03,\n                       1.0946e-02, -5.6871e-03,  8.1497e-03,  2.4928e-03, -6.9493e-04,\n                       1.1725e-02,  5.1670e-03,  2.9004e-03,  9.7825e-03,  9.7240e-03,\n                      -2.7851e-03,  2.3168e-02,  1.6959e-02, -3.1885e-04,  1.3151e-03,\n                      -1.3790e-02,  2.8626e-03,  2.3489e-04,  1.3942e-02,  7.8279e-03,\n                       2.5351e-02,  6.9576e-03, -1.1933e-03, -4.0229e-03,  9.4992e-03,\n                       1.4115e-03,  2.5818e-03,  4.1050e-03,  4.2996e-03,  8.3192e-03,\n                      -7.1330e-03, -6.6807e-03,  6.3420e-03,  1.5616e-02,  1.2415e-02,\n                       8.0969e-03,  1.1597e-02,  2.6486e-03,  1.2993e-03, -1.5338e-02,\n                       2.0556e-03,  1.3725e-02,  1.2186e-03,  1.4313e-03, -1.2165e-02,\n                       1.3019e-02,  1.7083e-02,  2.7128e-03, -1.1586e-03,  9.7261e-03,\n                      -1.5498e-03,  1.5748e-02,  1.4602e-02,  1.2564e-02,  1.1937e-02,\n                      -4.9515e-03,  1.8337e-02,  1.2670e-02,  1.6142e-02,  5.3544e-03,\n                       3.9446e-03, -2.9763e-03, -5.1065e-03,  8.6812e-03, -5.8302e-03,\n                       9.0792e-03,  3.9068e-04, -2.8040e-03,  1.3666e-02,  1.0866e-02,\n                       6.6934e-04,  1.3275e-02,  3.8989e-03,  1.5336e-02,  1.4110e-02,\n                       1.1314e-02,  1.0989e-04,  9.8440e-03, -6.0635e-03, -1.2074e-02,\n                      -3.7622e-04, -3.5491e-03, -1.6917e-04,  1.6661e-02,  1.2875e-02,\n                       2.2027e-03, -8.2765e-03,  9.7156e-03,  2.0198e-03,  1.6068e-02,\n                       5.2907e-03,  6.0659e-03,  1.2907e-02,  8.2801e-03, -1.4323e-02,\n                      -4.8243e-03, -2.0621e-03,  1.4657e-02,  6.2861e-03,  4.8946e-03,\n                      -2.3297e-03,  9.3704e-03, -9.0418e-03, -1.0441e-02,  1.8461e-02,\n                       9.8076e-03,  1.5484e-02,  1.3885e-02, -5.1067e-03, -3.6825e-04,\n                       7.5573e-03, -2.4969e-03,  1.4309e-02, -1.6113e-02,  8.7284e-03,\n                       8.9995e-03, -2.4929e-03,  1.5093e-02,  8.7488e-03, -9.1053e-03,\n                       5.3569e-03,  1.3902e-02,  2.0318e-02,  1.7466e-02,  3.5519e-03,\n                      -5.6560e-03,  1.4802e-02, -2.3311e-03,  1.1098e-02,  5.1774e-03,\n                       2.1149e-03,  1.2048e-02,  1.3731e-02,  6.7681e-03,  1.7393e-02,\n                       1.2463e-03,  3.7993e-03, -1.1772e-03,  5.0294e-03, -1.1857e-03,\n                      -1.0684e-02, -9.0822e-04,  6.9600e-03,  2.5757e-02, -1.9999e-03,\n                       4.3512e-03, -9.6917e-04,  2.5704e-03, -1.6033e-02,  1.3199e-02,\n                       1.6811e-02, -4.8412e-05,  1.1552e-02,  1.1878e-02,  1.1082e-02,\n                       2.9774e-03,  7.1287e-03, -4.4003e-03,  1.1104e-02,  8.4545e-03,\n                       9.5603e-03,  2.6524e-03,  3.1871e-03,  1.4453e-02,  3.4078e-03,\n                       1.3989e-02,  4.8366e-03,  9.8061e-03,  1.7184e-03, -6.5976e-03,\n                       1.5279e-02,  1.0562e-02,  2.2532e-02,  2.2955e-02,  1.2863e-02,\n                       2.0834e-03], dtype=torch.float64)),\n             ('6.2.convs.2.1.running_mean',\n              tensor([ 0.3522, -0.0813, -0.1304, -0.2954, -0.7640,  0.1023, -0.0973,  0.1243,\n                      -0.1896, -0.2991, -0.1124,  0.2451, -0.0316,  0.2352, -0.1390,  0.5835,\n                       0.4169, -0.0889, -0.5751, -0.4950, -0.1464,  0.2097,  0.2573,  0.7620,\n                       0.3616, -0.3275, -0.0792,  0.0384,  0.0427,  0.4075,  0.5461, -0.2450,\n                       0.0164,  0.2700, -0.4034,  0.7175, -0.1472, -0.1556, -0.3581, -0.5702,\n                       0.0107,  0.5626,  0.4257,  0.5722, -0.2764, -0.1523, -0.9421,  0.0461,\n                      -0.1601,  0.2258, -0.1996, -0.0693, -0.2103, -0.0586, -0.3182, -0.1521,\n                       0.3878,  0.6814, -0.5350, -0.3652,  0.3349,  0.3229,  0.3232,  0.1635,\n                       0.2291,  0.1392, -0.0300, -0.5352,  0.4433, -0.3194, -0.1381, -0.3123,\n                       0.1800,  0.1937,  0.0971, -0.2848,  0.3931,  0.5866,  0.3407, -0.0312,\n                       0.6719, -0.1162, -0.3073, -0.4684,  0.0644, -0.4033,  0.6510,  0.0240,\n                       0.4803, -0.1145,  0.0616,  0.5029,  0.0435, -0.1985,  0.2811, -0.0695,\n                       0.2851,  0.1119,  0.2872,  0.6235, -0.6560,  0.0222, -0.4503,  0.4972,\n                      -0.1368, -0.1217, -0.1437, -0.5908, -0.7946, -0.1542, -0.3017, -0.8411,\n                      -0.1843, -0.0681,  0.3614, -0.3598, -0.4919,  0.5461, -0.6681,  0.1425,\n                      -0.0775, -0.0919, -0.1824, -0.1213, -0.0881, -0.2658, -0.3546, -0.4458,\n                      -0.3698,  0.7559,  0.1240,  0.4620, -0.1958, -0.0247,  0.0033, -0.1337,\n                      -0.6016,  0.3826,  0.3471, -0.2096, -0.1403,  0.1143, -0.2747, -0.3022,\n                      -0.5138,  0.3154,  0.2067, -0.1045, -0.4310,  0.1182, -0.0102,  0.5126,\n                       0.6497, -0.0100, -0.0527, -0.1573,  0.2576, -0.2350,  0.3723, -0.0509,\n                      -0.0333, -0.1526, -0.2257, -0.6446, -0.2851,  0.3317, -0.1569,  0.2836,\n                       0.1165, -0.0604,  0.4053,  0.1025, -0.0403, -0.0850, -0.3558,  0.3271,\n                      -0.0161, -0.6606, -0.3766, -0.1923,  0.7222, -0.1280, -0.3245,  0.2282,\n                      -0.2416, -0.2041,  0.5437,  0.3892, -0.1023,  0.4961, -0.6835, -0.0049,\n                       0.0326, -0.3170, -0.3632,  0.2783,  0.0784,  0.8466, -0.4194,  0.5559,\n                       0.2646,  0.1389, -0.5192, -0.8104, -0.6475,  0.3737,  0.1195, -0.1991,\n                      -0.1304, -0.3789, -0.0459,  0.0890, -0.4762,  0.3223,  0.2913, -0.0857,\n                      -0.2560, -0.3350, -0.2318, -0.5118, -0.1558,  0.1437, -0.0434,  0.5131,\n                       0.2125, -0.0766, -0.7140,  0.4749,  0.1095,  0.1000,  0.2875,  0.1644,\n                       0.4801, -0.5007,  0.7435, -0.3381, -0.3252,  0.2114, -0.1248, -0.4524,\n                       0.5585,  0.0158,  1.2131, -0.0219, -0.6156, -0.0477, -0.0438, -0.4385,\n                      -0.0255, -0.4030, -0.0832, -0.1656,  0.6168, -0.1050, -0.1869, -0.7728],\n                     dtype=torch.float64)),\n             ('6.2.convs.2.1.running_var',\n              tensor([0.2378, 0.4902, 0.3368, 0.5906, 0.3393, 0.2509, 0.0600, 0.2325, 0.2108,\n                      0.3386, 0.3620, 0.2510, 0.2186, 0.1726, 0.4183, 0.3221, 0.4245, 0.2269,\n                      0.4129, 0.5467, 0.1195, 0.4282, 0.4757, 0.3516, 0.4977, 0.2466, 0.2125,\n                      0.0584, 0.1759, 0.2186, 0.7331, 0.3321, 0.1434, 0.5338, 0.5722, 0.4480,\n                      0.2087, 0.4217, 0.4184, 0.6348, 0.3648, 0.2657, 0.1909, 0.5662, 0.5494,\n                      0.4367, 0.3972, 0.1830, 0.4380, 0.2261, 0.4417, 0.3027, 0.3028, 0.3174,\n                      0.1868, 0.4151, 0.3554, 0.3814, 0.9358, 0.4534, 0.2225, 0.2971, 0.2342,\n                      0.2162, 0.4246, 0.4172, 1.1902, 0.2424, 0.3305, 0.3207, 0.3558, 0.3134,\n                      0.3076, 0.5999, 0.4427, 0.4164, 0.2763, 0.2535, 0.3296, 0.4463, 0.2715,\n                      0.4236, 0.3746, 0.5306, 0.5046, 0.3750, 0.4778, 0.4524, 0.4178, 0.3538,\n                      0.3656, 0.2036, 0.1546, 0.0711, 0.2048, 0.1856, 0.3902, 0.2982, 0.3169,\n                      0.3354, 0.4942, 0.3836, 0.3643, 0.5595, 0.2144, 0.5039, 0.3139, 0.5496,\n                      0.9384, 0.2348, 0.4127, 0.2349, 0.2948, 0.2848, 0.3347, 0.6235, 0.4990,\n                      0.3871, 0.5138, 0.4266, 0.1477, 0.3579, 0.3220, 0.3552, 0.4692, 0.6977,\n                      0.2203, 0.2437, 0.1521, 0.2410, 0.2712, 0.1746, 0.3575, 0.3617, 0.2571,\n                      0.3429, 0.2563, 0.4791, 0.2951, 0.3356, 0.1367, 0.1192, 0.2966, 0.1963,\n                      0.4084, 0.3080, 0.2643, 0.5187, 0.1951, 0.3701, 0.6142, 0.2385, 0.4989,\n                      0.2441, 0.2401, 0.1438, 0.3080, 0.2142, 0.1981, 0.2093, 0.0906, 0.2960,\n                      0.2971, 0.3199, 0.3755, 0.5390, 0.4250, 0.2757, 0.4050, 0.2706, 0.4222,\n                      0.2824, 0.2964, 0.2135, 0.6213, 0.3488, 0.4648, 0.2685, 0.2096, 0.4153,\n                      0.4092, 0.0872, 0.4577, 0.5605, 0.3782, 0.2821, 0.3524, 0.2713, 0.4215,\n                      0.2953, 0.2687, 0.2936, 0.1806, 0.4749, 0.2269, 0.2818, 0.1544, 0.3318,\n                      0.3626, 0.5501, 0.0863, 0.3014, 0.2974, 0.5053, 0.6464, 0.5075, 0.1905,\n                      0.0869, 0.2248, 0.4334, 0.1802, 0.1772, 0.1590, 0.2956, 0.1407, 0.2136,\n                      0.3377, 0.4073, 0.4597, 0.5461, 0.1621, 0.3343, 0.2630, 0.4574, 0.2107,\n                      0.2579, 0.5428, 0.1945, 0.3673, 0.3057, 0.3077, 0.3292, 0.4597, 0.2568,\n                      0.6644, 0.3426, 0.1052, 0.3926, 0.2360, 0.2873, 0.2087, 0.1994, 0.5011,\n                      0.3198, 0.4959, 0.2558, 0.1818, 0.2627, 0.1612, 0.3269, 0.6329, 0.3860,\n                      0.2504, 0.8461, 0.1192, 0.5047], dtype=torch.float64)),\n             ('6.2.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.2.convpath.0.0.0.weight',\n              tensor([[[-0.0565],\n                       [-0.0505],\n                       [-0.1425],\n                       ...,\n                       [ 0.0184],\n                       [ 0.0461],\n                       [-0.0331]],\n              \n                      [[ 0.0799],\n                       [-0.0190],\n                       [ 0.0703],\n                       ...,\n                       [ 0.0497],\n                       [-0.0004],\n                       [-0.0778]],\n              \n                      [[ 0.0756],\n                       [ 0.1013],\n                       [ 0.0731],\n                       ...,\n                       [-0.0379],\n                       [-0.0231],\n                       [ 0.0515]],\n              \n                      ...,\n              \n                      [[-0.0708],\n                       [-0.1675],\n                       [ 0.0322],\n                       ...,\n                       [ 0.1841],\n                       [-0.1723],\n                       [ 0.0598]],\n              \n                      [[ 0.1497],\n                       [-0.0871],\n                       [ 0.0099],\n                       ...,\n                       [ 0.0473],\n                       [-0.0713],\n                       [-0.1062]],\n              \n                      [[-0.0440],\n                       [ 0.0326],\n                       [ 0.1056],\n                       ...,\n                       [-0.0556],\n                       [ 0.0556],\n                       [-0.1885]]], dtype=torch.float64)),\n             ('6.2.convpath.0.0.1.weight',\n              tensor([0.9888, 0.9610, 0.9569, 0.9873, 0.9865, 0.9986, 0.9541, 0.9751, 0.9658,\n                      0.9597, 0.9952, 0.9636, 0.9876, 0.9771, 0.9680, 0.9833, 0.9687, 0.9905,\n                      0.9740, 0.9484, 0.9670, 0.9592, 0.9753, 0.9692, 0.9646, 0.9617, 0.9880,\n                      0.9810, 0.9674, 0.9735, 0.9548, 0.9768, 0.9672, 0.9722, 0.9828, 0.9717,\n                      0.9767, 0.9855, 0.9532, 0.9746, 0.9953, 0.9690, 0.9691, 0.9922, 0.9784,\n                      0.9578, 0.9706, 0.9693, 0.9686, 0.9489, 0.9714, 0.9651, 0.9884, 0.9584,\n                      0.9896, 0.9519, 0.9730, 0.9667, 0.9552, 0.9789, 0.9885, 0.9736, 0.9731,\n                      0.9608], dtype=torch.float64)),\n             ('6.2.convpath.0.0.1.bias',\n              tensor([ 1.1554e-02, -1.6822e-03, -2.7562e-03,  3.4358e-03,  9.6338e-03,\n                      -7.5445e-03,  7.5815e-03,  1.6349e-03, -8.4027e-03, -1.4825e-03,\n                       2.7449e-03,  1.0978e-03,  1.9848e-02,  4.3238e-03,  2.4500e-02,\n                       1.7340e-02,  7.1757e-03,  3.7631e-03, -4.6050e-03, -4.5539e-03,\n                       1.4733e-02, -2.6916e-03,  1.9335e-02,  7.2475e-03, -2.4447e-02,\n                      -1.6473e-02,  2.0872e-02,  9.9249e-03, -6.3243e-03,  2.9428e-03,\n                      -8.3791e-03, -2.2472e-03,  1.9201e-02,  8.5608e-04, -3.1818e-03,\n                      -1.0603e-02, -9.5419e-03,  1.5490e-02, -3.1767e-03,  1.7913e-02,\n                       1.1034e-02, -6.2602e-03,  1.4356e-02,  2.5350e-02,  4.7768e-03,\n                      -3.8693e-03,  9.8540e-03, -8.6633e-03, -6.2785e-03, -1.8505e-02,\n                      -9.9820e-03, -1.1923e-05,  1.6003e-02, -1.2047e-02,  1.2562e-02,\n                       4.5174e-03,  8.5935e-03, -6.3272e-03, -1.4336e-03,  2.1240e-02,\n                       3.5608e-03, -1.0999e-02, -1.5257e-03,  7.5104e-03],\n                     dtype=torch.float64)),\n             ('6.2.convpath.0.0.1.running_mean',\n              tensor([-3.2967e-01, -3.9153e-02, -6.6658e-01, -1.4451e-01, -3.7049e-01,\n                      -1.8816e-01, -5.6564e-02, -6.2019e-01,  8.6744e-01,  5.1065e-01,\n                       5.1709e-02, -1.3599e-01,  2.7698e-01, -8.5152e-01, -2.5491e-01,\n                      -1.3458e-01,  5.8681e-02, -7.2455e-01,  1.2618e+00, -2.8236e-01,\n                      -4.6423e-01, -3.2596e-01, -3.4369e-01,  3.4760e-01,  1.8911e-01,\n                      -2.1844e-01,  7.1364e-02, -1.5297e-01, -3.9064e-01,  1.8795e-01,\n                      -6.8499e-01, -7.0110e-01, -7.8917e-01,  2.7971e-01,  3.5106e-01,\n                      -3.8349e-01,  4.3666e-01, -6.1573e-01, -1.3775e-01, -3.8474e-01,\n                      -5.5215e-01, -7.2952e-04, -6.2953e-01, -3.3484e-01,  7.0126e-01,\n                      -7.2212e-01, -3.9999e-01,  4.5686e-02,  1.4969e-01, -3.1667e-01,\n                       2.4763e-01,  3.2311e-01,  8.9678e-01, -5.2978e-03, -2.5350e-01,\n                      -7.1559e-01,  1.7360e-01,  1.6877e-01,  1.5529e-01, -7.5959e-01,\n                      -1.3622e-01, -1.5824e-01, -1.3703e-01,  1.0238e-01],\n                     dtype=torch.float64)),\n             ('6.2.convpath.0.0.1.running_var',\n              tensor([0.3285, 0.3413, 0.1737, 0.3383, 0.1023, 0.1168, 0.2615, 0.2192, 1.1763,\n                      1.8198, 0.2739, 0.0949, 0.1817, 0.2172, 0.3546, 0.1337, 0.1192, 0.0897,\n                      1.3786, 1.0233, 0.3726, 0.2219, 0.2441, 0.2901, 0.1207, 0.1242, 0.2375,\n                      0.1079, 0.4603, 0.1063, 0.2290, 0.2517, 0.2216, 0.2103, 0.1326, 0.0678,\n                      0.0982, 0.1481, 0.4446, 0.1689, 0.1410, 0.2853, 0.5928, 0.1894, 1.0746,\n                      0.5542, 0.1596, 0.3659, 0.8283, 0.5587, 0.2637, 0.4427, 0.5629, 0.0843,\n                      0.2756, 0.0880, 0.1890, 0.2800, 0.3641, 0.1700, 0.1601, 0.3774, 0.1645,\n                      0.2921], dtype=torch.float64)),\n             ('6.2.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.2.convpath.0.1.0.weight',\n              tensor([[[ 0.0640,  0.0503, -0.0179, -0.1204,  0.0662],\n                       [-0.0277,  0.0530, -0.0696,  0.0966,  0.0788],\n                       [-0.0802, -0.0350, -0.0427, -0.0968,  0.0195],\n                       ...,\n                       [-0.0565, -0.0376, -0.0042,  0.1552, -0.0679],\n                       [-0.0381,  0.0058, -0.0195,  0.1849,  0.0175],\n                       [-0.0399,  0.1749, -0.0332, -0.0042,  0.1379]],\n              \n                      [[-0.0218,  0.0754,  0.1295,  0.1705,  0.0328],\n                       [-0.0254, -0.0737, -0.0940, -0.0510,  0.0290],\n                       [ 0.0725, -0.0674, -0.0428, -0.0116, -0.0693],\n                       ...,\n                       [-0.0133,  0.0700,  0.0033, -0.0816,  0.0349],\n                       [ 0.0849,  0.0050, -0.0462, -0.0440,  0.1171],\n                       [-0.0054, -0.0612, -0.0168, -0.1379,  0.0123]],\n              \n                      [[ 0.0157,  0.1279,  0.0245, -0.0729, -0.0894],\n                       [-0.1057, -0.0653,  0.0606, -0.0190,  0.0418],\n                       [-0.1371,  0.0737,  0.0561, -0.0092, -0.0349],\n                       ...,\n                       [ 0.0511, -0.0160,  0.0816, -0.1216, -0.1560],\n                       [-0.0967,  0.0492, -0.0260,  0.0109, -0.0239],\n                       [-0.0196, -0.0609, -0.0373, -0.1247,  0.0432]],\n              \n                      ...,\n              \n                      [[ 0.0235, -0.1488,  0.0184, -0.0346,  0.0250],\n                       [ 0.0932, -0.1516, -0.0974, -0.0095,  0.0476],\n                       [-0.0590, -0.0941,  0.0122, -0.0764,  0.0366],\n                       ...,\n                       [-0.0107,  0.0310, -0.0095, -0.0037, -0.2250],\n                       [-0.0463, -0.0238,  0.1784, -0.0459,  0.0934],\n                       [-0.0757, -0.1031, -0.0252, -0.0364, -0.1420]],\n              \n                      [[ 0.0908,  0.0338,  0.1147, -0.0511, -0.0121],\n                       [ 0.0419,  0.0296,  0.0499,  0.1017, -0.1364],\n                       [-0.1014,  0.0257,  0.0062, -0.0811,  0.1540],\n                       ...,\n                       [-0.0584, -0.0031, -0.0786, -0.0384,  0.1889],\n                       [ 0.0092, -0.1163,  0.0110, -0.0132,  0.0251],\n                       [ 0.1333, -0.0061,  0.1475, -0.0111, -0.0038]],\n              \n                      [[-0.1530,  0.0294, -0.0312, -0.1085,  0.0727],\n                       [ 0.0472, -0.0804, -0.0971,  0.0183, -0.1105],\n                       [-0.0830, -0.1793, -0.0079,  0.0241, -0.0578],\n                       ...,\n                       [ 0.0029,  0.1342,  0.0206,  0.0863,  0.0962],\n                       [-0.1063, -0.0248,  0.0383,  0.1320,  0.1679],\n                       [ 0.0563,  0.0553,  0.0082,  0.0663,  0.1152]]], dtype=torch.float64)),\n             ('6.2.convpath.0.1.1.weight',\n              tensor([0.9524, 0.9690, 0.9670, 0.9751, 0.9931, 0.9344, 1.0130, 0.9564, 0.9835,\n                      0.9765, 0.9833, 0.9700, 0.9594, 0.9645, 0.9682, 0.9667, 0.9245, 0.9604,\n                      0.9985, 0.9499, 0.9425, 0.9916, 0.9515, 0.9483, 0.9705, 0.9623, 0.9695,\n                      0.9497, 0.9833, 0.9629, 0.9405, 0.9676, 0.9640, 0.9672, 0.9945, 0.9558,\n                      0.9710, 0.9613, 0.9623, 0.9538, 1.0019, 0.9743, 0.9480, 0.9738, 0.9568,\n                      0.9477, 0.9596, 0.9819, 0.9575, 0.9939, 0.9720, 0.9466, 0.9592, 0.9637,\n                      0.9303, 0.9777, 0.9673, 0.9387, 0.9819, 0.9779, 0.9859, 0.9819, 0.9811,\n                      0.9720], dtype=torch.float64)),\n             ('6.2.convpath.0.1.1.bias',\n              tensor([ 2.7470e-03, -1.3765e-02,  6.0983e-03, -4.1245e-04,  5.1237e-03,\n                      -8.1063e-05, -1.5589e-02,  6.4030e-03,  1.3215e-03,  7.0557e-04,\n                       6.4068e-03, -1.6382e-02, -1.9350e-02,  1.0091e-02,  8.8647e-03,\n                       3.3026e-03, -2.7496e-02, -1.7042e-02, -3.3820e-03, -2.7452e-03,\n                      -1.3998e-02,  2.7501e-03, -3.0523e-02, -3.5469e-02, -3.5460e-04,\n                       9.6738e-03,  1.3382e-02,  2.7688e-03,  1.0512e-02, -8.7872e-03,\n                      -1.9938e-02,  1.1889e-02, -3.1059e-02, -2.5302e-02,  8.5192e-03,\n                      -4.5392e-03,  1.5666e-02, -1.5421e-02, -2.6320e-02, -9.8213e-03,\n                       1.8944e-02,  4.0188e-03,  6.4368e-03, -4.7974e-03, -2.2776e-02,\n                      -1.8603e-03, -6.9103e-03,  2.6461e-02, -1.1599e-02, -4.4005e-05,\n                       3.9116e-03, -1.2824e-03, -8.4190e-03, -2.4090e-02, -1.9181e-02,\n                       2.9037e-02,  1.8839e-03,  1.1910e-03,  8.6546e-03,  1.9068e-02,\n                      -6.6260e-03,  2.3253e-02, -1.3991e-02, -4.3950e-03],\n                     dtype=torch.float64)),\n             ('6.2.convpath.0.1.1.running_mean',\n              tensor([-0.3747,  0.7249, -0.0904,  0.2532, -0.5003, -0.0956, -0.1688,  0.0421,\n                       0.3087,  0.8061,  0.2120, -0.1280, -0.1954, -0.6034,  0.2099, -0.4808,\n                      -0.2288,  0.1844, -0.1454,  0.0414,  0.0970,  0.0087,  0.0031,  0.4263,\n                      -0.4281,  0.2461, -0.1865, -0.8033,  0.7010, -0.2709, -0.1924,  0.3431,\n                       0.1772,  0.3815,  0.2237, -0.2250, -0.1793, -0.0759,  0.1836, -0.2223,\n                       0.5368, -0.1475, -0.0458, -0.1367,  0.7305, -0.7653, -0.3082, -0.2958,\n                       0.1892,  0.4999,  0.7705,  0.3761, -0.1520, -0.7156, -0.8855,  0.1022,\n                       0.0028,  0.1753, -0.3458, -0.6135,  1.0683, -1.1924,  0.6468,  0.3145],\n                     dtype=torch.float64)),\n             ('6.2.convpath.0.1.1.running_var',\n              tensor([0.4645, 0.7083, 0.6411, 0.6405, 0.5013, 0.4923, 0.5241, 0.5759, 0.5142,\n                      0.7873, 0.3988, 0.4638, 0.4338, 0.7547, 0.6025, 0.5707, 0.7279, 0.4259,\n                      0.6474, 0.9526, 0.5976, 0.6822, 1.0449, 0.7574, 0.4651, 0.7870, 0.6851,\n                      0.7495, 0.9418, 0.2691, 0.7484, 0.7944, 0.8600, 0.3978, 0.3830, 0.4585,\n                      0.4799, 0.4525, 0.9228, 0.4628, 0.3921, 0.6896, 0.5607, 0.6229, 0.9776,\n                      0.6091, 0.6134, 0.4779, 0.3467, 0.5241, 0.6906, 0.5199, 0.3914, 0.4744,\n                      0.5899, 0.6030, 0.6422, 0.7384, 0.4384, 0.4773, 0.5557, 1.0260, 0.5519,\n                      0.7797], dtype=torch.float64)),\n             ('6.2.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.2.convpath.0.2.0.weight',\n              tensor([[[ 0.2244],\n                       [ 0.2367],\n                       [ 0.1866],\n                       ...,\n                       [ 0.1014],\n                       [-0.0672],\n                       [-0.0143]],\n              \n                      [[ 0.1361],\n                       [-0.0172],\n                       [-0.0235],\n                       ...,\n                       [-0.1010],\n                       [-0.1749],\n                       [-0.0074]],\n              \n                      [[-0.0752],\n                       [ 0.1052],\n                       [-0.0228],\n                       ...,\n                       [-0.1157],\n                       [-0.1313],\n                       [ 0.0004]],\n              \n                      ...,\n              \n                      [[ 0.1466],\n                       [-0.3195],\n                       [ 0.0626],\n                       ...,\n                       [-0.1564],\n                       [ 0.0305],\n                       [-0.0880]],\n              \n                      [[-0.0984],\n                       [ 0.1059],\n                       [ 0.1134],\n                       ...,\n                       [-0.0243],\n                       [-0.1528],\n                       [ 0.0189]],\n              \n                      [[-0.2947],\n                       [ 0.0384],\n                       [-0.1119],\n                       ...,\n                       [ 0.1308],\n                       [-0.1934],\n                       [ 0.1931]]], dtype=torch.float64)),\n             ('6.2.convpath.0.2.1.weight',\n              tensor([-1.7022e-03, -1.1376e-02, -1.3251e-02,  5.4066e-03,  5.2605e-03,\n                       2.1662e-02, -1.0669e-03, -1.5245e-02,  8.5076e-03, -4.7421e-03,\n                       1.2559e-02,  1.7550e-02, -1.6513e-02, -1.0280e-03,  1.5813e-02,\n                      -5.4644e-02, -3.7853e-02, -1.8809e-04,  1.0351e-02, -3.6274e-03,\n                      -1.1859e-02, -3.4023e-03, -2.3923e-02, -1.6862e-02, -6.0764e-03,\n                       8.0165e-03, -8.0430e-03, -2.9811e-03, -1.2213e-02,  1.0960e-03,\n                      -5.2426e-03,  6.5109e-02, -1.0544e-03, -2.0072e-02, -3.2147e-02,\n                       8.5112e-04,  2.4154e-03, -2.0200e-02,  1.4544e-02, -1.5003e-02,\n                       1.8892e-02,  2.6847e-02,  6.2115e-03,  1.6933e-02, -1.0358e-02,\n                       1.2553e-02,  8.0310e-03,  7.3795e-03, -4.4583e-02, -1.5242e-03,\n                       8.8975e-03,  1.2235e-02, -8.5119e-03,  5.0601e-03,  6.8982e-03,\n                       2.8665e-02,  2.0481e-04, -2.2551e-02, -1.7763e-02, -1.6430e-02,\n                      -2.7394e-02, -1.2619e-02,  5.1490e-03,  2.5771e-03, -3.2446e-02,\n                       1.6769e-02,  1.1167e-02,  2.5183e-02,  1.1565e-02,  9.0588e-03,\n                      -1.0020e-02,  3.0873e-02,  1.8678e-02,  1.6038e-02, -2.4860e-02,\n                      -1.9459e-02,  1.2336e-02, -1.2152e-02,  4.4370e-03, -1.7990e-02,\n                       9.3680e-03, -5.5566e-03,  1.6287e-02,  1.7906e-02, -1.3730e-02,\n                       2.0360e-02, -4.1745e-02,  1.9214e-02,  6.0129e-03, -1.8335e-02,\n                       1.3433e-02,  2.7189e-02,  2.0968e-05,  2.5771e-03, -1.1901e-02,\n                       5.6859e-03, -1.5649e-02, -1.7254e-02,  1.9577e-02,  1.7229e-02,\n                       6.8233e-03, -2.2046e-02, -1.6678e-02, -2.5229e-02, -1.0523e-02,\n                       1.7920e-02,  9.8209e-03, -1.0585e-02,  3.0046e-02,  7.0828e-03,\n                       1.1450e-02,  1.0226e-02, -1.4789e-03,  9.4695e-03,  7.8820e-03,\n                       2.8922e-02,  9.2448e-03, -2.1661e-02,  3.3809e-03,  5.0388e-03,\n                       1.0983e-02, -1.1586e-02,  3.4584e-04, -1.7022e-02,  2.5300e-02,\n                       2.1670e-02,  1.0669e-02,  1.5832e-03,  1.3557e-02, -1.2687e-02,\n                       1.1940e-02,  2.5415e-02, -4.0661e-03, -1.5388e-02, -1.9747e-02,\n                      -2.5839e-02,  7.6751e-03, -1.0887e-02,  1.9855e-02,  1.1414e-02,\n                      -7.6104e-04,  2.0603e-04, -1.0158e-03, -1.0813e-03, -3.0590e-03,\n                       4.9907e-03, -1.3375e-02, -1.3059e-02, -2.7876e-02, -1.3792e-03,\n                      -2.5615e-02, -9.0706e-03,  6.5247e-03, -9.4027e-04, -2.5703e-03,\n                       4.5885e-03, -6.3975e-03,  1.1728e-03, -3.9283e-03,  3.4310e-03,\n                      -7.3474e-03,  2.3849e-02,  2.2057e-02,  2.1656e-02, -3.8555e-03,\n                       1.6120e-02, -3.3966e-03,  2.5070e-03, -7.4572e-03, -9.9572e-03,\n                       1.5717e-02,  1.4784e-02, -8.6057e-03,  1.9095e-02, -5.4790e-03,\n                       3.0067e-02, -3.7296e-02,  2.8053e-02,  4.5763e-03,  6.6212e-03,\n                       4.3536e-03,  6.2611e-03,  9.4757e-03, -7.4222e-03, -7.8226e-03,\n                       1.7546e-03,  2.4835e-03,  3.4610e-02,  1.4749e-02,  4.1243e-03,\n                      -2.8901e-03, -1.9672e-02,  1.1439e-02, -2.6164e-02, -2.7266e-02,\n                      -5.8925e-03, -1.7949e-05, -1.2002e-02,  8.1637e-03,  2.3852e-02,\n                      -1.7630e-03, -1.0560e-02, -1.0996e-02,  9.7427e-03,  1.1905e-02,\n                       1.2258e-02, -1.2684e-02,  6.6713e-03, -2.8566e-03,  1.2590e-02,\n                       1.7187e-02,  3.0867e-03,  2.5546e-03, -3.6672e-03, -2.8883e-03,\n                       1.3775e-02,  4.5662e-03, -9.9767e-03,  2.0074e-02,  4.2469e-03,\n                       1.3227e-02, -1.2160e-02, -1.4508e-02,  1.5343e-02,  1.3865e-02,\n                       1.3456e-02, -3.1871e-03, -3.5910e-03,  5.2389e-02, -6.1178e-04,\n                       1.5347e-02,  2.6553e-03, -6.7049e-03,  1.2972e-03,  1.6571e-02,\n                      -2.5664e-02, -6.8891e-03,  1.1461e-02, -3.2691e-03, -2.7285e-02,\n                       1.8714e-02,  2.5263e-02, -3.5005e-03,  1.2603e-02, -1.2232e-02,\n                      -1.3414e-02,  2.2626e-03,  2.1878e-03, -1.2032e-02,  4.0404e-02,\n                       2.4400e-02, -8.6483e-03, -1.0482e-02,  1.7714e-02, -1.3392e-02,\n                       4.0087e-02], dtype=torch.float64)),\n             ('6.2.convpath.0.2.1.bias',\n              tensor([-2.6506e-03, -2.7597e-03,  1.8489e-02,  7.1597e-03,  5.3737e-03,\n                       3.4115e-03,  2.1322e-02,  7.9633e-04,  1.0076e-02,  2.1337e-02,\n                       6.5399e-03, -7.9954e-03,  1.2075e-02, -6.2468e-03,  4.7535e-03,\n                       7.7885e-03,  1.7050e-02, -3.2981e-04,  1.4969e-02, -8.1884e-03,\n                      -3.8657e-03,  3.2743e-03,  2.0814e-03,  6.6063e-03, -5.2091e-03,\n                      -1.3007e-02,  6.7238e-03,  1.0376e-02,  1.1016e-03, -1.3589e-03,\n                       8.1286e-03,  7.9499e-03, -7.9539e-03,  1.6475e-02,  1.7196e-02,\n                       7.2007e-03,  9.9995e-04,  2.8488e-02,  9.7364e-03,  1.1173e-02,\n                      -1.7008e-04,  1.5342e-02, -9.6732e-03,  4.3593e-03,  1.1487e-02,\n                      -1.0231e-02,  7.2345e-03,  4.1771e-03, -1.1182e-02,  7.9030e-03,\n                       8.4675e-03,  2.2596e-03,  8.3431e-03,  1.6841e-02,  4.1280e-03,\n                      -1.1390e-03,  7.1495e-03,  5.5032e-03,  7.4040e-03,  8.2298e-03,\n                      -7.2225e-03,  1.7846e-03, -1.2505e-03,  1.0236e-02, -4.2406e-03,\n                       1.3371e-02, -1.1343e-02,  1.2300e-02,  4.6490e-03, -9.4152e-03,\n                       2.4298e-03,  1.1077e-02,  9.0883e-03, -8.3255e-03,  1.4961e-02,\n                       1.7883e-02, -1.0875e-03,  3.2563e-03,  3.9161e-03,  6.1038e-03,\n                       1.0946e-02, -5.6871e-03,  8.1497e-03,  2.4928e-03, -6.9493e-04,\n                       1.1725e-02,  5.1670e-03,  2.9004e-03,  9.7825e-03,  9.7240e-03,\n                      -2.7851e-03,  2.3168e-02,  1.6959e-02, -3.1885e-04,  1.3151e-03,\n                      -1.3790e-02,  2.8626e-03,  2.3489e-04,  1.3942e-02,  7.8279e-03,\n                       2.5351e-02,  6.9576e-03, -1.1933e-03, -4.0229e-03,  9.4992e-03,\n                       1.4115e-03,  2.5818e-03,  4.1050e-03,  4.2996e-03,  8.3192e-03,\n                      -7.1330e-03, -6.6807e-03,  6.3420e-03,  1.5616e-02,  1.2415e-02,\n                       8.0969e-03,  1.1597e-02,  2.6486e-03,  1.2993e-03, -1.5338e-02,\n                       2.0556e-03,  1.3725e-02,  1.2186e-03,  1.4313e-03, -1.2165e-02,\n                       1.3019e-02,  1.7083e-02,  2.7128e-03, -1.1586e-03,  9.7261e-03,\n                      -1.5498e-03,  1.5748e-02,  1.4602e-02,  1.2564e-02,  1.1937e-02,\n                      -4.9515e-03,  1.8337e-02,  1.2670e-02,  1.6142e-02,  5.3544e-03,\n                       3.9446e-03, -2.9763e-03, -5.1065e-03,  8.6812e-03, -5.8302e-03,\n                       9.0792e-03,  3.9068e-04, -2.8040e-03,  1.3666e-02,  1.0866e-02,\n                       6.6934e-04,  1.3275e-02,  3.8989e-03,  1.5336e-02,  1.4110e-02,\n                       1.1314e-02,  1.0989e-04,  9.8440e-03, -6.0635e-03, -1.2074e-02,\n                      -3.7622e-04, -3.5491e-03, -1.6917e-04,  1.6661e-02,  1.2875e-02,\n                       2.2027e-03, -8.2765e-03,  9.7156e-03,  2.0198e-03,  1.6068e-02,\n                       5.2907e-03,  6.0659e-03,  1.2907e-02,  8.2801e-03, -1.4323e-02,\n                      -4.8243e-03, -2.0621e-03,  1.4657e-02,  6.2861e-03,  4.8946e-03,\n                      -2.3297e-03,  9.3704e-03, -9.0418e-03, -1.0441e-02,  1.8461e-02,\n                       9.8076e-03,  1.5484e-02,  1.3885e-02, -5.1067e-03, -3.6825e-04,\n                       7.5573e-03, -2.4969e-03,  1.4309e-02, -1.6113e-02,  8.7284e-03,\n                       8.9995e-03, -2.4929e-03,  1.5093e-02,  8.7488e-03, -9.1053e-03,\n                       5.3569e-03,  1.3902e-02,  2.0318e-02,  1.7466e-02,  3.5519e-03,\n                      -5.6560e-03,  1.4802e-02, -2.3311e-03,  1.1098e-02,  5.1774e-03,\n                       2.1149e-03,  1.2048e-02,  1.3731e-02,  6.7681e-03,  1.7393e-02,\n                       1.2463e-03,  3.7993e-03, -1.1772e-03,  5.0294e-03, -1.1857e-03,\n                      -1.0684e-02, -9.0822e-04,  6.9600e-03,  2.5757e-02, -1.9999e-03,\n                       4.3512e-03, -9.6917e-04,  2.5704e-03, -1.6033e-02,  1.3199e-02,\n                       1.6811e-02, -4.8412e-05,  1.1552e-02,  1.1878e-02,  1.1082e-02,\n                       2.9774e-03,  7.1287e-03, -4.4003e-03,  1.1104e-02,  8.4545e-03,\n                       9.5603e-03,  2.6524e-03,  3.1871e-03,  1.4453e-02,  3.4078e-03,\n                       1.3989e-02,  4.8366e-03,  9.8061e-03,  1.7184e-03, -6.5976e-03,\n                       1.5279e-02,  1.0562e-02,  2.2532e-02,  2.2955e-02,  1.2863e-02,\n                       2.0834e-03], dtype=torch.float64)),\n             ('6.2.convpath.0.2.1.running_mean',\n              tensor([ 0.3522, -0.0813, -0.1304, -0.2954, -0.7640,  0.1023, -0.0973,  0.1243,\n                      -0.1896, -0.2991, -0.1124,  0.2451, -0.0316,  0.2352, -0.1390,  0.5835,\n                       0.4169, -0.0889, -0.5751, -0.4950, -0.1464,  0.2097,  0.2573,  0.7620,\n                       0.3616, -0.3275, -0.0792,  0.0384,  0.0427,  0.4075,  0.5461, -0.2450,\n                       0.0164,  0.2700, -0.4034,  0.7175, -0.1472, -0.1556, -0.3581, -0.5702,\n                       0.0107,  0.5626,  0.4257,  0.5722, -0.2764, -0.1523, -0.9421,  0.0461,\n                      -0.1601,  0.2258, -0.1996, -0.0693, -0.2103, -0.0586, -0.3182, -0.1521,\n                       0.3878,  0.6814, -0.5350, -0.3652,  0.3349,  0.3229,  0.3232,  0.1635,\n                       0.2291,  0.1392, -0.0300, -0.5352,  0.4433, -0.3194, -0.1381, -0.3123,\n                       0.1800,  0.1937,  0.0971, -0.2848,  0.3931,  0.5866,  0.3407, -0.0312,\n                       0.6719, -0.1162, -0.3073, -0.4684,  0.0644, -0.4033,  0.6510,  0.0240,\n                       0.4803, -0.1145,  0.0616,  0.5029,  0.0435, -0.1985,  0.2811, -0.0695,\n                       0.2851,  0.1119,  0.2872,  0.6235, -0.6560,  0.0222, -0.4503,  0.4972,\n                      -0.1368, -0.1217, -0.1437, -0.5908, -0.7946, -0.1542, -0.3017, -0.8411,\n                      -0.1843, -0.0681,  0.3614, -0.3598, -0.4919,  0.5461, -0.6681,  0.1425,\n                      -0.0775, -0.0919, -0.1824, -0.1213, -0.0881, -0.2658, -0.3546, -0.4458,\n                      -0.3698,  0.7559,  0.1240,  0.4620, -0.1958, -0.0247,  0.0033, -0.1337,\n                      -0.6016,  0.3826,  0.3471, -0.2096, -0.1403,  0.1143, -0.2747, -0.3022,\n                      -0.5138,  0.3154,  0.2067, -0.1045, -0.4310,  0.1182, -0.0102,  0.5126,\n                       0.6497, -0.0100, -0.0527, -0.1573,  0.2576, -0.2350,  0.3723, -0.0509,\n                      -0.0333, -0.1526, -0.2257, -0.6446, -0.2851,  0.3317, -0.1569,  0.2836,\n                       0.1165, -0.0604,  0.4053,  0.1025, -0.0403, -0.0850, -0.3558,  0.3271,\n                      -0.0161, -0.6606, -0.3766, -0.1923,  0.7222, -0.1280, -0.3245,  0.2282,\n                      -0.2416, -0.2041,  0.5437,  0.3892, -0.1023,  0.4961, -0.6835, -0.0049,\n                       0.0326, -0.3170, -0.3632,  0.2783,  0.0784,  0.8466, -0.4194,  0.5559,\n                       0.2646,  0.1389, -0.5192, -0.8104, -0.6475,  0.3737,  0.1195, -0.1991,\n                      -0.1304, -0.3789, -0.0459,  0.0890, -0.4762,  0.3223,  0.2913, -0.0857,\n                      -0.2560, -0.3350, -0.2318, -0.5118, -0.1558,  0.1437, -0.0434,  0.5131,\n                       0.2125, -0.0766, -0.7140,  0.4749,  0.1095,  0.1000,  0.2875,  0.1644,\n                       0.4801, -0.5007,  0.7435, -0.3381, -0.3252,  0.2114, -0.1248, -0.4524,\n                       0.5585,  0.0158,  1.2131, -0.0219, -0.6156, -0.0477, -0.0438, -0.4385,\n                      -0.0255, -0.4030, -0.0832, -0.1656,  0.6168, -0.1050, -0.1869, -0.7728],\n                     dtype=torch.float64)),\n             ('6.2.convpath.0.2.1.running_var',\n              tensor([0.2378, 0.4902, 0.3368, 0.5906, 0.3393, 0.2509, 0.0600, 0.2325, 0.2108,\n                      0.3386, 0.3620, 0.2510, 0.2186, 0.1726, 0.4183, 0.3221, 0.4245, 0.2269,\n                      0.4129, 0.5467, 0.1195, 0.4282, 0.4757, 0.3516, 0.4977, 0.2466, 0.2125,\n                      0.0584, 0.1759, 0.2186, 0.7331, 0.3321, 0.1434, 0.5338, 0.5722, 0.4480,\n                      0.2087, 0.4217, 0.4184, 0.6348, 0.3648, 0.2657, 0.1909, 0.5662, 0.5494,\n                      0.4367, 0.3972, 0.1830, 0.4380, 0.2261, 0.4417, 0.3027, 0.3028, 0.3174,\n                      0.1868, 0.4151, 0.3554, 0.3814, 0.9358, 0.4534, 0.2225, 0.2971, 0.2342,\n                      0.2162, 0.4246, 0.4172, 1.1902, 0.2424, 0.3305, 0.3207, 0.3558, 0.3134,\n                      0.3076, 0.5999, 0.4427, 0.4164, 0.2763, 0.2535, 0.3296, 0.4463, 0.2715,\n                      0.4236, 0.3746, 0.5306, 0.5046, 0.3750, 0.4778, 0.4524, 0.4178, 0.3538,\n                      0.3656, 0.2036, 0.1546, 0.0711, 0.2048, 0.1856, 0.3902, 0.2982, 0.3169,\n                      0.3354, 0.4942, 0.3836, 0.3643, 0.5595, 0.2144, 0.5039, 0.3139, 0.5496,\n                      0.9384, 0.2348, 0.4127, 0.2349, 0.2948, 0.2848, 0.3347, 0.6235, 0.4990,\n                      0.3871, 0.5138, 0.4266, 0.1477, 0.3579, 0.3220, 0.3552, 0.4692, 0.6977,\n                      0.2203, 0.2437, 0.1521, 0.2410, 0.2712, 0.1746, 0.3575, 0.3617, 0.2571,\n                      0.3429, 0.2563, 0.4791, 0.2951, 0.3356, 0.1367, 0.1192, 0.2966, 0.1963,\n                      0.4084, 0.3080, 0.2643, 0.5187, 0.1951, 0.3701, 0.6142, 0.2385, 0.4989,\n                      0.2441, 0.2401, 0.1438, 0.3080, 0.2142, 0.1981, 0.2093, 0.0906, 0.2960,\n                      0.2971, 0.3199, 0.3755, 0.5390, 0.4250, 0.2757, 0.4050, 0.2706, 0.4222,\n                      0.2824, 0.2964, 0.2135, 0.6213, 0.3488, 0.4648, 0.2685, 0.2096, 0.4153,\n                      0.4092, 0.0872, 0.4577, 0.5605, 0.3782, 0.2821, 0.3524, 0.2713, 0.4215,\n                      0.2953, 0.2687, 0.2936, 0.1806, 0.4749, 0.2269, 0.2818, 0.1544, 0.3318,\n                      0.3626, 0.5501, 0.0863, 0.3014, 0.2974, 0.5053, 0.6464, 0.5075, 0.1905,\n                      0.0869, 0.2248, 0.4334, 0.1802, 0.1772, 0.1590, 0.2956, 0.1407, 0.2136,\n                      0.3377, 0.4073, 0.4597, 0.5461, 0.1621, 0.3343, 0.2630, 0.4574, 0.2107,\n                      0.2579, 0.5428, 0.1945, 0.3673, 0.3057, 0.3077, 0.3292, 0.4597, 0.2568,\n                      0.6644, 0.3426, 0.1052, 0.3926, 0.2360, 0.2873, 0.2087, 0.1994, 0.5011,\n                      0.3198, 0.4959, 0.2558, 0.1818, 0.2627, 0.1612, 0.3269, 0.6329, 0.3860,\n                      0.2504, 0.8461, 0.1192, 0.5047], dtype=torch.float64)),\n             ('6.2.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.3.convs.0.0.weight',\n              tensor([[[ 0.0836],\n                       [-0.0142],\n                       [-0.2330],\n                       ...,\n                       [ 0.0220],\n                       [-0.0216],\n                       [ 0.1154]],\n              \n                      [[ 0.0897],\n                       [-0.0583],\n                       [-0.0872],\n                       ...,\n                       [ 0.0294],\n                       [-0.0127],\n                       [ 0.0977]],\n              \n                      [[ 0.1077],\n                       [ 0.0071],\n                       [-0.0889],\n                       ...,\n                       [ 0.1597],\n                       [-0.0588],\n                       [-0.0419]],\n              \n                      ...,\n              \n                      [[ 0.0384],\n                       [-0.0324],\n                       [-0.0878],\n                       ...,\n                       [ 0.1114],\n                       [ 0.0493],\n                       [-0.0550]],\n              \n                      [[-0.0477],\n                       [-0.0720],\n                       [-0.0068],\n                       ...,\n                       [-0.0667],\n                       [-0.0595],\n                       [-0.0101]],\n              \n                      [[ 0.0441],\n                       [-0.0778],\n                       [-0.0917],\n                       ...,\n                       [-0.0944],\n                       [ 0.0606],\n                       [-0.1236]]], dtype=torch.float64)),\n             ('6.3.convs.0.1.weight',\n              tensor([0.9935, 0.9731, 0.9612, 0.9738, 0.9545, 0.9781, 0.9811, 0.9550, 0.9498,\n                      0.9865, 0.9717, 0.9801, 0.9979, 0.9713, 0.9737, 0.9673, 0.9912, 0.9685,\n                      0.9740, 0.9688, 0.9852, 0.9917, 0.9636, 0.9742, 0.9627, 0.9533, 0.9680,\n                      0.9567, 0.9669, 0.9962, 0.9536, 0.9725, 0.9687, 0.9831, 0.9744, 0.9902,\n                      0.9760, 0.9582, 0.9558, 0.9759, 0.9432, 0.9873, 0.9957, 0.9624, 0.9565,\n                      0.9778, 0.9841, 0.9503, 0.9769, 0.9862, 0.9582, 0.9417, 0.9666, 0.9403,\n                      0.9589, 0.9697, 0.9408, 0.9820, 0.9826, 0.9694, 0.9604, 0.9714, 0.9497,\n                      0.9740], dtype=torch.float64)),\n             ('6.3.convs.0.1.bias',\n              tensor([ 0.0049,  0.0009,  0.0009,  0.0042,  0.0016, -0.0095,  0.0054, -0.0155,\n                       0.0024,  0.0267,  0.0041, -0.0051,  0.0226, -0.0117,  0.0080, -0.0095,\n                       0.0065, -0.0084,  0.0097, -0.0190,  0.0117,  0.0155, -0.0041,  0.0208,\n                       0.0037,  0.0010,  0.0303, -0.0134, -0.0065,  0.0315, -0.0169,  0.0191,\n                      -0.0140,  0.0043,  0.0091,  0.0245,  0.0149, -0.0093, -0.0061,  0.0071,\n                      -0.0196,  0.0135,  0.0201, -0.0065, -0.0124, -0.0202, -0.0006, -0.0115,\n                       0.0025,  0.0042, -0.0105, -0.0219,  0.0026, -0.0188, -0.0108, -0.0028,\n                       0.0005, -0.0061,  0.0174,  0.0042, -0.0018, -0.0101, -0.0141,  0.0005],\n                     dtype=torch.float64)),\n             ('6.3.convs.0.1.running_mean',\n              tensor([-0.1689, -0.6454,  0.5007, -0.6568, -0.5218,  0.2219,  0.6869,  1.0033,\n                      -0.4050, -0.4411,  0.3008,  0.4656,  0.1833, -0.4233, -0.1463, -0.8737,\n                       0.3207, -0.3210, -0.5028, -0.2203,  0.9405, -0.1224,  0.5320, -0.6759,\n                      -0.4003, -1.3419, -0.7312,  0.2378, -0.5220, -0.0550, -0.3125, -0.0616,\n                       0.2173,  0.5440, -0.7067, -0.4562,  0.4488, -0.8552, -1.0228, -0.0434,\n                       0.2758,  0.3100, -0.0106, -0.5302, -0.2465,  0.7208, -0.5049, -0.3898,\n                       0.3156, -0.8468, -0.0516, -0.3231, -0.5626, -0.5411,  0.5492, -0.1812,\n                      -0.1690,  0.3352,  0.1052, -0.7155,  0.3739,  0.3544, -0.1342, -0.6355],\n                     dtype=torch.float64)),\n             ('6.3.convs.0.1.running_var',\n              tensor([0.2957, 0.1850, 0.6652, 0.1615, 0.1821, 0.1174, 0.1498, 0.9403, 0.2352,\n                      0.1613, 0.1707, 0.1140, 0.2361, 0.3256, 0.2065, 0.3258, 0.1653, 0.1706,\n                      0.1365, 0.2307, 0.1310, 0.1917, 0.2583, 0.5242, 0.1197, 0.5175, 1.2508,\n                      0.0833, 0.6942, 0.2924, 0.7822, 0.1226, 0.1766, 0.1477, 0.1564, 0.2425,\n                      0.1206, 0.7851, 0.4172, 0.4345, 0.5028, 0.2169, 0.2132, 0.9674, 0.3974,\n                      0.1051, 0.1339, 0.3912, 0.3281, 0.1969, 0.2259, 0.2053, 0.2290, 0.2571,\n                      0.7919, 0.1274, 0.2036, 0.1188, 0.1055, 0.4394, 0.3305, 0.4820, 0.3490,\n                      0.4003], dtype=torch.float64)),\n             ('6.3.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.3.convs.1.0.weight',\n              tensor([[[ 4.5031e-02, -6.3458e-02, -6.3075e-02, -1.6577e-02,  5.6874e-02],\n                       [ 2.0491e-02, -2.6789e-02, -3.9041e-02,  1.5200e-02, -5.2503e-02],\n                       [ 1.9974e-02,  5.6953e-02,  4.5140e-02,  4.4333e-02, -1.0485e-01],\n                       ...,\n                       [ 9.7279e-02, -1.6135e-02, -2.0964e-02,  7.8871e-02, -1.7372e-03],\n                       [-9.4632e-02, -5.1138e-02, -5.7390e-02, -8.4832e-02, -5.1471e-02],\n                       [-4.3466e-03, -9.9913e-03,  1.4457e-01,  8.2719e-02, -1.1791e-01]],\n              \n                      [[-1.8770e-03,  4.1147e-03,  4.7226e-02,  8.6625e-02,  2.8036e-02],\n                       [ 3.2393e-02,  6.5667e-02, -2.3525e-02,  2.1569e-02,  2.3630e-02],\n                       [-2.7386e-02, -9.6487e-02, -1.9150e-02, -2.6737e-03, -7.6384e-02],\n                       ...,\n                       [-4.4700e-02,  2.5130e-02, -2.2918e-02, -6.3791e-02, -7.8412e-02],\n                       [ 5.3158e-02,  1.3616e-04,  1.0444e-01,  1.5605e-01, -6.6482e-02],\n                       [-6.2230e-03,  3.8805e-02, -5.4779e-02,  4.8002e-02,  5.7375e-02]],\n              \n                      [[-1.4027e-02, -5.6741e-02,  2.0611e-01, -9.8751e-02, -1.6259e-01],\n                       [ 6.5376e-02,  5.7862e-02, -2.7659e-02, -4.5727e-02, -1.5635e-01],\n                       [-3.7132e-02,  6.7694e-03, -1.8052e-02, -1.2627e-01,  2.8058e-02],\n                       ...,\n                       [ 5.7850e-02,  6.0785e-02, -6.1765e-02, -6.7465e-02, -4.7162e-03],\n                       [ 2.1174e-02,  1.1555e-02, -1.6849e-02,  2.9702e-02, -9.2858e-02],\n                       [-1.2654e-01, -4.5266e-02, -3.7955e-02,  3.1690e-02, -1.2174e-02]],\n              \n                      ...,\n              \n                      [[-3.9478e-02,  1.0042e-01, -8.3087e-02,  4.0227e-03, -6.9969e-02],\n                       [-6.1648e-02, -7.0065e-02, -6.9993e-02, -7.2487e-03,  7.3063e-02],\n                       [ 1.0302e-01, -2.9896e-02, -4.4484e-02, -1.1333e-01, -5.4941e-02],\n                       ...,\n                       [-2.3024e-03,  3.8355e-02,  2.2813e-02, -8.2025e-02,  3.9636e-02],\n                       [-7.8375e-02, -1.0918e-01,  7.3916e-02, -5.5115e-02, -6.6182e-02],\n                       [ 4.9850e-02,  1.5487e-02, -3.5750e-02, -6.2412e-03,  3.0324e-02]],\n              \n                      [[-2.8848e-02,  7.6258e-02,  2.3487e-02, -1.7766e-02,  5.5746e-02],\n                       [-1.4409e-01,  7.5147e-02, -2.4324e-02,  1.8695e-02, -9.0342e-02],\n                       [-4.0029e-02, -7.8973e-03,  2.9468e-02,  1.0257e-02, -4.5983e-02],\n                       ...,\n                       [ 6.9523e-02, -1.2981e-01,  4.3978e-02,  4.7004e-02, -1.5814e-01],\n                       [ 5.6193e-02,  6.7428e-02,  8.7977e-02, -6.6451e-02, -1.1659e-01],\n                       [ 6.6541e-03,  8.6018e-02,  1.7445e-01,  3.7791e-02,  4.5388e-02]],\n              \n                      [[ 1.9111e-02,  8.4569e-02,  9.3869e-02, -1.4621e-02,  2.5622e-02],\n                       [-2.1762e-03,  2.6920e-02, -5.7559e-02,  6.0002e-02, -8.6922e-02],\n                       [-2.2274e-02, -7.2869e-02,  2.4974e-02, -9.8059e-02, -1.1518e-01],\n                       ...,\n                       [-1.1634e-01, -1.4494e-01,  2.5907e-03,  3.9700e-03, -1.0767e-01],\n                       [ 7.5978e-03, -1.0776e-02,  3.6922e-02,  5.9500e-03, -8.0243e-02],\n                       [-1.2482e-01, -8.9399e-02, -9.5219e-02,  6.8358e-02, -4.5209e-02]]],\n                     dtype=torch.float64)),\n             ('6.3.convs.1.1.weight',\n              tensor([0.9680, 0.9565, 0.9494, 0.9710, 0.9973, 0.9857, 0.9568, 0.9794, 0.9721,\n                      0.9667, 0.9802, 0.9445, 0.9960, 0.9518, 0.9400, 0.9668, 0.9868, 0.9472,\n                      0.9522, 0.9545, 0.9489, 0.9434, 0.9712, 0.9665, 0.9481, 1.0015, 0.9505,\n                      0.9442, 0.9477, 0.9436, 0.9783, 0.9651, 0.9572, 0.9627, 0.9491, 0.9419,\n                      0.9517, 0.9593, 0.9588, 0.9845, 0.9700, 0.9549, 0.9760, 0.9631, 0.9469,\n                      0.9668, 0.9415, 0.9701, 0.9775, 0.9446, 0.9570, 0.9635, 0.9743, 0.9721,\n                      1.0181, 0.9883, 0.9804, 0.9659, 0.9889, 0.9456, 0.9781, 0.9373, 0.9710,\n                      0.9605], dtype=torch.float64)),\n             ('6.3.convs.1.1.bias',\n              tensor([-0.0030,  0.0023,  0.0096, -0.0051, -0.0052, -0.0087, -0.0128, -0.0167,\n                       0.0082, -0.0094,  0.0257, -0.0099,  0.0172, -0.0264, -0.0208, -0.0011,\n                       0.0078, -0.0333, -0.0157, -0.0061, -0.0270, -0.0129,  0.0003, -0.0076,\n                      -0.0169,  0.0250, -0.0265, -0.0228, -0.0229, -0.0067, -0.0105,  0.0138,\n                      -0.0258, -0.0145, -0.0125, -0.0164, -0.0027, -0.0085, -0.0033, -0.0064,\n                      -0.0261, -0.0053,  0.0048,  0.0069, -0.0281, -0.0302, -0.0325, -0.0138,\n                       0.0056, -0.0046, -0.0017,  0.0157, -0.0130,  0.0142,  0.0096,  0.0095,\n                       0.0096, -0.0097,  0.0218, -0.0215,  0.0114, -0.0255,  0.0010,  0.0027],\n                     dtype=torch.float64)),\n             ('6.3.convs.1.1.running_mean',\n              tensor([ 2.3425e-01,  3.7149e-01,  4.3241e-01,  8.3932e-02, -4.2117e-01,\n                      -4.5153e-02, -8.0430e-01,  2.1780e-01, -1.6376e-01, -1.0474e-01,\n                      -6.1503e-01, -5.3871e-01, -2.4249e-01,  6.5866e-01, -7.0890e-01,\n                      -3.3458e-01,  1.4502e-01, -4.5255e-01, -3.4243e-01, -5.7911e-01,\n                      -6.2067e-01, -1.4191e-01,  2.0950e-01, -8.8122e-01,  1.0047e-01,\n                      -1.5438e+00, -7.5754e-01, -3.7798e-02, -5.3896e-01, -2.6246e-01,\n                       6.6092e-01, -1.7345e-01,  8.6860e-01, -2.6438e-01, -2.0020e-01,\n                       1.5678e-01,  8.9396e-02,  3.1140e-01,  2.9925e-01,  7.2220e-02,\n                       1.1998e+00, -2.3521e-01,  3.8395e-01,  8.7388e-04, -2.8525e-02,\n                      -2.0763e-02, -2.8935e-01, -3.0140e-01,  1.1521e+00, -5.0367e-01,\n                       2.7059e-01,  1.8194e-01, -4.8049e-01, -2.0566e-01, -3.2340e-01,\n                      -4.2698e-01, -2.9017e-01, -8.7020e-01, -9.4385e-01,  4.9539e-01,\n                      -4.2253e-01, -7.6930e-01, -5.5113e-02, -2.9616e-01],\n                     dtype=torch.float64)),\n             ('6.3.convs.1.1.running_var',\n              tensor([0.5746, 0.4747, 0.5640, 0.6424, 0.3706, 0.6119, 0.4254, 0.5075, 0.5688,\n                      0.4522, 0.4759, 0.4375, 0.3805, 0.5140, 0.4898, 0.4796, 0.3944, 0.4470,\n                      0.6586, 0.5441, 0.4637, 0.4697, 0.3897, 0.4250, 0.4211, 0.4002, 0.7138,\n                      0.5290, 0.3935, 0.6045, 0.4530, 0.8621, 0.4318, 0.5820, 0.5275, 0.3842,\n                      0.3985, 0.3439, 0.7150, 0.3545, 0.5025, 0.4816, 0.5740, 0.4801, 0.6412,\n                      0.3365, 0.6341, 0.4325, 0.4430, 0.6994, 0.2934, 0.5097, 0.3342, 0.6173,\n                      0.3313, 0.5447, 0.5178, 0.3036, 0.3872, 0.3721, 0.5089, 0.5584, 0.4697,\n                      0.7280], dtype=torch.float64)),\n             ('6.3.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.3.convs.2.0.weight',\n              tensor([[[-0.1076],\n                       [-0.0879],\n                       [-0.0580],\n                       ...,\n                       [ 0.0500],\n                       [ 0.0128],\n                       [ 0.0263]],\n              \n                      [[-0.2342],\n                       [-0.0028],\n                       [-0.2151],\n                       ...,\n                       [ 0.0490],\n                       [ 0.1289],\n                       [ 0.0080]],\n              \n                      [[ 0.1034],\n                       [ 0.0496],\n                       [-0.0758],\n                       ...,\n                       [-0.0451],\n                       [-0.1655],\n                       [-0.0212]],\n              \n                      ...,\n              \n                      [[ 0.1794],\n                       [-0.0978],\n                       [-0.3339],\n                       ...,\n                       [ 0.0715],\n                       [-0.0033],\n                       [-0.0014]],\n              \n                      [[-0.0183],\n                       [-0.1509],\n                       [ 0.1345],\n                       ...,\n                       [ 0.0299],\n                       [-0.0301],\n                       [-0.0818]],\n              \n                      [[ 0.2681],\n                       [ 0.3150],\n                       [ 0.0174],\n                       ...,\n                       [ 0.2031],\n                       [-0.0307],\n                       [ 0.0048]]], dtype=torch.float64)),\n             ('6.3.convs.2.1.weight',\n              tensor([ 7.9271e-03,  1.4752e-02, -2.4944e-02,  1.0540e-02, -1.6292e-02,\n                      -1.5966e-02,  3.2396e-02, -1.2903e-02, -7.2734e-04, -4.3549e-02,\n                      -1.0139e-02, -6.7067e-03, -2.5998e-03,  1.0467e-02,  6.9312e-03,\n                      -4.5640e-02,  2.0227e-02,  1.8202e-02, -2.0453e-02, -1.0500e-03,\n                      -7.1799e-03, -1.4364e-02,  1.0086e-04, -1.5460e-02, -2.9384e-02,\n                      -1.2352e-02,  1.8998e-02,  3.4095e-03, -9.8179e-03, -3.6893e-03,\n                      -2.2751e-02,  2.7015e-02,  9.8841e-03,  1.5321e-02, -3.2800e-02,\n                       1.7462e-03,  4.4897e-03, -5.2315e-04, -9.0990e-03,  1.0988e-02,\n                       2.2826e-02,  3.2831e-02, -5.3111e-03, -8.6741e-04, -1.6954e-02,\n                      -6.4237e-03, -4.5184e-03, -2.1553e-03,  1.9586e-02,  2.0786e-03,\n                       7.2736e-03,  2.4172e-02,  1.8243e-02,  3.1963e-02,  8.5083e-03,\n                       6.1561e-02,  5.6541e-03,  3.3565e-02, -2.1821e-02,  7.7970e-03,\n                      -9.6951e-03, -1.2799e-02, -7.0902e-03, -1.3442e-02, -1.5165e-02,\n                       3.2970e-02, -1.3717e-03, -2.3781e-02,  3.1767e-02, -3.0989e-02,\n                       1.8659e-02, -1.5683e-02,  6.2696e-03, -1.0108e-02,  2.3595e-02,\n                      -2.0985e-02,  1.1475e-03, -5.1191e-03,  1.9089e-03, -6.1693e-03,\n                       1.2506e-03,  1.4818e-02, -2.6806e-02, -2.3726e-02,  1.1694e-03,\n                      -3.3108e-02, -2.6355e-02,  8.1053e-03, -1.3698e-02,  1.8181e-03,\n                      -4.5789e-03, -1.7559e-02, -2.6936e-02,  3.1706e-04, -1.3582e-02,\n                      -1.0437e-02, -1.9103e-02, -1.6111e-02,  1.5976e-02, -1.2342e-02,\n                      -1.5933e-02, -2.2652e-02, -1.7446e-02, -4.4654e-02,  1.6962e-02,\n                      -1.6748e-02,  1.5351e-02, -5.8498e-03,  5.8600e-03,  1.1966e-02,\n                      -7.9705e-03,  9.1065e-03, -2.8181e-02,  2.5419e-02, -4.4393e-03,\n                       2.8749e-02,  4.2918e-03,  2.2072e-03,  1.5599e-02, -1.1009e-02,\n                      -8.2406e-03,  4.6298e-02, -1.5521e-02,  9.4074e-03,  2.6572e-02,\n                      -1.3178e-02, -1.0459e-02,  1.7976e-02, -2.4415e-03,  1.6718e-02,\n                       1.8723e-02,  7.3763e-03,  1.3920e-02,  1.6652e-02,  1.6086e-02,\n                      -9.1912e-03, -3.6401e-02,  7.3499e-03, -2.3338e-02,  1.6216e-02,\n                      -3.6649e-03,  1.9585e-03,  8.6547e-03,  1.5867e-03,  1.8214e-02,\n                      -3.9011e-03, -3.4455e-03,  1.3634e-02,  3.0101e-02,  1.8651e-02,\n                       2.5530e-02,  2.8263e-03, -3.8641e-03,  2.9694e-02, -1.4794e-02,\n                       2.0702e-03,  3.5324e-03, -1.5048e-02, -2.2033e-03,  4.3454e-04,\n                      -3.4054e-03, -3.5716e-03, -2.8820e-02, -1.0530e-02, -3.8970e-03,\n                       6.6733e-05, -2.5009e-03, -3.4745e-02,  1.2368e-03,  3.0235e-02,\n                       2.3713e-02, -1.9599e-02,  9.5653e-03, -1.7575e-02,  3.2235e-04,\n                      -2.1831e-03, -1.5232e-02, -2.2780e-04,  3.2814e-02, -2.0912e-02,\n                      -1.6513e-02, -1.2591e-02, -1.9934e-02,  1.3690e-02, -1.7553e-02,\n                       2.1786e-04,  6.8375e-03,  1.0423e-02, -1.0923e-02,  8.3421e-03,\n                      -7.9088e-03,  6.8457e-03,  1.9326e-02,  3.0229e-02,  9.8381e-03,\n                      -2.2590e-03, -1.2541e-02,  1.0267e-02,  2.2497e-02,  6.8712e-03,\n                       7.9821e-03,  5.9914e-03, -1.2369e-02, -2.6366e-02,  2.3968e-02,\n                      -1.6106e-02,  1.4658e-02,  3.2371e-03, -2.8337e-02, -2.1815e-02,\n                      -1.1108e-02, -1.4792e-02, -9.9776e-03,  5.9600e-03,  2.0668e-02,\n                      -2.3164e-02,  6.9716e-04,  6.8160e-04,  2.1876e-02,  4.4789e-03,\n                       1.8181e-03,  2.1077e-02, -2.7272e-03, -3.8133e-02,  1.1089e-02,\n                      -7.2474e-03, -3.6176e-03,  4.6825e-03,  2.1195e-03, -3.5034e-03,\n                       1.4512e-02, -3.9083e-03, -2.5785e-02, -2.2522e-02,  1.7175e-02,\n                       1.7519e-02, -1.1759e-03,  4.7351e-03,  2.8044e-03, -8.2294e-03,\n                       2.8937e-02, -1.6456e-02,  1.3573e-02,  1.7298e-02,  9.1072e-03,\n                       2.6329e-02,  1.8432e-02, -2.6275e-02, -6.1240e-03, -5.0538e-02,\n                       7.8578e-03, -1.4737e-02, -1.5483e-02, -4.0752e-02,  5.3759e-03,\n                       2.3468e-02], dtype=torch.float64)),\n             ('6.3.convs.2.1.bias',\n              tensor([-2.5797e-03, -6.4166e-03,  1.7968e-02,  9.6252e-03,  4.8672e-03,\n                       1.7111e-03,  2.1250e-02,  1.3986e-03,  7.2805e-03,  2.1452e-02,\n                       1.2049e-02, -8.7455e-03,  1.0498e-02, -7.0585e-03,  3.5840e-03,\n                       6.6433e-03,  1.8841e-02, -1.1966e-03,  1.6624e-02, -8.6635e-03,\n                      -1.4258e-03,  2.9578e-03,  2.0191e-03,  7.5122e-03, -6.2062e-03,\n                      -1.3662e-02,  7.8087e-03,  1.0927e-02,  2.4027e-03, -1.8442e-03,\n                       9.1861e-03,  9.4733e-03, -8.5312e-03,  1.6039e-02,  1.5431e-02,\n                       7.0945e-03,  1.2773e-03,  2.4802e-02,  9.6879e-03,  1.3565e-02,\n                       1.0158e-03,  8.0390e-03, -9.3413e-03,  9.7143e-04,  7.6194e-03,\n                      -1.1149e-02,  5.3431e-03,  4.1254e-03, -1.1173e-02,  8.6138e-03,\n                       8.5550e-03,  3.5668e-03,  8.6429e-03,  1.5206e-02,  5.3058e-03,\n                       5.9685e-04,  6.2454e-03,  3.0971e-03,  7.7455e-03,  6.7122e-03,\n                      -6.9629e-03,  9.6579e-04, -1.9555e-03,  1.0024e-02, -4.3331e-03,\n                       1.4677e-02, -1.2219e-02,  1.4050e-02,  3.1068e-03, -1.0353e-02,\n                       3.2450e-03,  1.9400e-03,  2.8112e-03, -7.9846e-03,  1.5279e-02,\n                       1.2359e-02,  9.4672e-04,  5.0230e-03,  3.8470e-03,  3.8547e-03,\n                       1.0760e-02, -5.5447e-03,  7.2977e-03,  4.9505e-03, -1.4065e-03,\n                       1.5111e-02,  2.4747e-03,  7.0994e-04,  9.7134e-03,  9.2644e-03,\n                      -6.6351e-05,  2.3230e-02,  1.6856e-02, -6.2465e-04,  9.1547e-04,\n                      -1.3152e-02,  3.9805e-03, -2.3112e-03,  1.8073e-02, -1.6151e-04,\n                       2.4512e-02,  5.2652e-03, -4.6760e-03, -7.9471e-03,  1.5674e-02,\n                       1.5860e-04,  3.2319e-04,  3.8463e-03,  4.1308e-03,  8.1087e-03,\n                      -7.1594e-03, -6.7726e-03,  4.7677e-03,  1.5856e-02,  1.2056e-02,\n                       7.8134e-03,  1.1585e-02,  3.0279e-03,  1.6566e-03, -1.5232e-02,\n                       2.4739e-03,  1.4688e-02,  1.9706e-03, -2.2335e-03, -1.0827e-02,\n                       1.2731e-02,  1.6649e-02,  2.5848e-03, -1.0972e-03,  1.0482e-02,\n                       2.3559e-03,  1.7923e-02,  1.4908e-02,  1.2129e-02,  1.9872e-02,\n                      -5.5732e-03,  1.7946e-02,  1.0659e-02,  1.6815e-02,  1.3415e-02,\n                       2.9935e-03, -2.8692e-03, -6.2181e-03,  8.4919e-03, -1.1181e-02,\n                       9.1374e-03,  7.5024e-04, -1.9775e-03,  1.0768e-02,  1.0696e-02,\n                       5.5905e-03,  1.1978e-02,  2.6439e-03,  1.5226e-02,  1.3163e-02,\n                       9.9906e-03,  6.4174e-04,  7.8299e-03, -7.2982e-03, -1.1654e-02,\n                      -5.0409e-04, -5.7676e-03,  3.5750e-03,  1.3752e-02,  1.2173e-02,\n                       1.9156e-03, -8.2165e-03,  9.1166e-03,  5.5799e-04,  1.5762e-02,\n                       4.8862e-03,  3.4844e-03,  1.3013e-02,  8.5047e-03, -1.3988e-02,\n                       7.5465e-03,  4.8147e-04,  1.2440e-02,  5.6185e-03,  6.7487e-03,\n                      -1.6659e-03,  9.2644e-03, -8.1001e-03, -1.0956e-02,  1.7238e-02,\n                       9.5468e-03,  1.5040e-02,  1.5780e-02, -2.5404e-03,  4.0520e-03,\n                       6.8105e-03, -1.4866e-03,  1.4260e-02, -1.7143e-02,  8.4410e-03,\n                       8.9528e-03, -2.2591e-03,  1.5966e-02,  9.2660e-03, -3.8299e-03,\n                       5.2248e-03,  1.5178e-02,  2.0447e-02,  1.7305e-02,  3.1560e-03,\n                      -3.1190e-03,  1.4590e-02, -4.3336e-03,  1.1115e-02,  5.5736e-03,\n                      -1.4519e-03,  1.2063e-02,  1.3603e-02,  6.2508e-03,  1.6845e-02,\n                       1.1002e-02,  3.8736e-03, -1.9929e-03,  4.7750e-03, -2.3595e-04,\n                      -1.2766e-02,  1.1142e-03,  6.8171e-03,  2.5343e-02, -1.7622e-03,\n                       2.0054e-03, -2.6380e-03,  1.6573e-03, -1.4969e-02,  1.4265e-02,\n                       1.3984e-02, -2.2679e-04,  1.1407e-02,  1.3016e-02,  7.6625e-03,\n                       3.9857e-03,  7.0756e-03, -3.9548e-03,  1.1298e-02,  1.0375e-02,\n                       5.8061e-03,  2.0565e-03,  2.8068e-03,  1.7745e-02,  2.9343e-03,\n                       1.4018e-02,  4.8125e-03,  9.8152e-03,  2.6523e-03, -8.0405e-03,\n                       1.6091e-02,  1.0336e-02,  2.1011e-02,  2.3282e-02,  1.1866e-02,\n                       1.2871e-02], dtype=torch.float64)),\n             ('6.3.convs.2.1.running_mean',\n              tensor([-0.2267,  0.5422, -0.3213, -0.4263,  0.0984, -0.4728,  0.0652,  1.0632,\n                       0.0396, -0.3144,  0.1486,  0.4458, -0.2995, -0.1862, -0.0224,  0.0589,\n                      -0.0301,  0.1369, -0.5435,  0.1346, -0.2618, -0.0212, -0.3196,  0.6038,\n                       0.0203,  0.0999,  0.2791,  0.0769, -0.0639,  0.1187,  0.3009, -1.2147,\n                       0.0548, -0.4886,  0.6524,  0.1250,  0.1078, -0.1685, -0.0134,  0.0649,\n                      -0.2516, -0.2236, -0.5682,  0.0142, -0.7515, -0.0452, -0.3235, -0.4087,\n                       0.2204,  0.0308, -0.2752,  0.8270,  0.2894, -0.3734,  0.0138,  0.2118,\n                      -0.8439, -0.3997,  0.0901, -0.0333, -0.0534,  0.0550, -0.1423,  0.4303,\n                       0.1166, -0.1768,  0.0517,  0.2433,  0.0671, -0.1288, -0.2415, -0.0478,\n                       0.1379, -0.4132, -0.2211, -0.1956, -0.2170, -0.3617, -0.4722,  0.1780,\n                       0.2271, -0.0401,  1.1079, -0.3459,  0.4742, -0.4362, -0.3101,  0.2097,\n                       0.3725,  0.0055, -0.3125,  0.1083,  0.3245, -0.1293,  0.2052,  0.4252,\n                       0.6518, -0.2515,  0.3633, -0.1881,  0.1247, -0.1707, -0.7745,  0.9025,\n                      -0.0674,  0.1191,  0.0908,  0.2016, -0.6305, -0.0916,  0.4997,  0.6293,\n                      -0.2252, -0.1997,  0.2519, -0.0738, -0.3401, -0.3462, -0.5845, -0.1075,\n                       0.1403, -0.2271, -0.1481, -0.0731, -0.1917, -1.0139, -0.1228,  0.1721,\n                      -0.0847, -0.6929,  0.6839,  0.3688, -0.1183,  0.0117,  0.7924, -0.1750,\n                      -0.5865,  0.3880, -0.3170,  0.4644, -0.1108, -0.0901,  0.4010, -0.0916,\n                      -0.3747,  0.3213, -0.9464,  0.8493,  0.9863,  0.0258,  1.1218, -0.1840,\n                       0.2322, -0.2805,  0.0937, -0.0591, -0.0811,  0.4331,  0.4479,  0.0387,\n                      -0.1105, -0.2983,  0.1763,  0.3549,  0.1889,  0.3164,  0.1144,  0.3418,\n                      -0.4611, -0.1635,  0.0971, -0.0387,  0.2837, -0.0441,  0.0814, -0.4246,\n                       0.1223, -0.4369,  0.0525, -0.1465, -0.2343,  0.2440, -0.7122, -0.0932,\n                       0.2462,  0.2852,  0.1129, -0.1174, -0.2790,  0.4488, -0.0545, -0.3631,\n                       0.4095, -0.4082,  0.0627,  0.3342, -0.2570,  0.3475, -0.4352,  0.3147,\n                       0.9032, -0.0280,  0.0565,  0.5175, -0.5945, -0.1374, -0.8371, -0.0728,\n                       0.0571, -0.6066, -0.2512, -0.4747,  0.1756, -0.2084, -0.0068, -0.4700,\n                       0.5443,  0.7048, -0.8123,  0.1890, -0.2087,  0.0978,  0.1175,  0.0488,\n                      -0.3868, -0.1939,  0.1089, -0.4571, -0.0613, -0.3399,  0.4603,  0.1733,\n                      -0.3530,  0.1698, -0.3653, -0.4882,  0.0573, -0.0095,  0.3071,  0.3315,\n                       0.3030, -0.5403,  0.0657,  0.1266,  0.0201,  0.0203, -0.0623, -0.2637,\n                      -0.3389,  0.3613, -0.1978,  0.2255,  0.3015,  0.4886,  0.4628,  0.4543],\n                     dtype=torch.float64)),\n             ('6.3.convs.2.1.running_var',\n              tensor([0.4341, 0.5010, 0.5003, 0.4717, 0.3296, 0.2574, 0.3748, 0.6318, 0.2433,\n                      0.4302, 0.2385, 0.3211, 0.0777, 0.2710, 0.4782, 0.3720, 0.3314, 0.3843,\n                      0.3304, 0.1331, 0.2116, 0.4893, 0.3066, 0.2812, 0.4371, 0.1976, 0.3328,\n                      0.1834, 0.1537, 0.2551, 0.5762, 0.6211, 0.3570, 0.3631, 0.5047, 0.2072,\n                      0.1735, 0.1507, 0.4816, 0.3639, 0.5588, 0.5165, 0.1427, 0.1776, 0.3557,\n                      0.2238, 0.3823, 0.2334, 0.6126, 0.2091, 0.2440, 0.4523, 0.5193, 0.4251,\n                      0.3072, 0.3365, 0.5630, 0.3503, 0.3632, 0.3673, 0.0628, 0.5931, 0.2075,\n                      0.3491, 0.4900, 0.2878, 0.2552, 0.4274, 0.3382, 0.6454, 0.2184, 0.2065,\n                      0.1440, 0.3929, 0.5260, 0.3500, 0.1571, 0.2379, 0.2796, 0.3024, 0.3227,\n                      0.2230, 0.7174, 0.3552, 0.4536, 0.4973, 0.5176, 0.3347, 0.3335, 0.1594,\n                      0.6222, 0.1895, 0.4836, 0.2193, 0.2678, 0.2000, 0.5660, 0.3048, 0.3450,\n                      0.3924, 0.3225, 0.3510, 0.2847, 0.3685, 0.3997, 0.3987, 0.3094, 0.2452,\n                      0.4192, 0.1789, 0.1316, 0.5826, 0.6280, 0.4521, 0.2742, 0.6394, 0.2055,\n                      0.2683, 0.4585, 0.2726, 0.0637, 0.3251, 0.6829, 0.2007, 0.1782, 0.4782,\n                      0.4326, 0.2947, 0.1405, 0.6025, 0.3042, 0.1580, 0.3477, 0.4006, 0.4220,\n                      0.0915, 0.6197, 0.2680, 0.4636, 0.3206, 0.1654, 0.0536, 0.2961, 0.0555,\n                      0.2196, 0.3075, 0.2937, 0.4027, 0.5107, 0.2758, 0.5003, 0.1201, 0.3101,\n                      0.4930, 0.4281, 0.3523, 0.2032, 0.3536, 0.3066, 0.1138, 0.1840, 0.1884,\n                      0.3643, 0.3074, 0.2156, 0.2430, 0.6827, 0.5311, 0.2100, 0.2853, 0.3571,\n                      0.3646, 0.4040, 0.2706, 0.2679, 0.3508, 0.3773, 0.5498, 0.4243, 0.2326,\n                      0.3234, 0.2553, 0.6887, 0.5037, 0.1880, 0.4436, 0.4816, 0.2002, 0.2692,\n                      0.1627, 0.2520, 0.5069, 0.5069, 0.6947, 0.3158, 0.3466, 0.5558, 0.2225,\n                      0.5419, 0.2837, 0.2488, 0.2575, 0.3021, 0.4223, 0.3250, 0.4568, 0.5204,\n                      0.0493, 0.3865, 0.5032, 0.1194, 0.3346, 0.1460, 0.3589, 0.2040, 0.2098,\n                      0.3106, 0.2590, 0.6542, 0.2730, 0.0955, 0.3001, 0.0792, 0.4771, 0.2620,\n                      0.3220, 0.1112, 0.1713, 0.3128, 0.5375, 0.2936, 0.1748, 0.5022, 0.3253,\n                      0.2516, 0.4851, 0.2133, 0.2062, 0.4364, 0.2585, 0.2966, 0.3104, 0.4686,\n                      0.2842, 0.1494, 0.3829, 0.3308, 0.2755, 0.0891, 0.2700, 0.4172, 0.4015,\n                      0.2388, 0.4631, 0.3016, 0.4052], dtype=torch.float64)),\n             ('6.3.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.3.convpath.0.0.0.weight',\n              tensor([[[ 0.0836],\n                       [-0.0142],\n                       [-0.2330],\n                       ...,\n                       [ 0.0220],\n                       [-0.0216],\n                       [ 0.1154]],\n              \n                      [[ 0.0897],\n                       [-0.0583],\n                       [-0.0872],\n                       ...,\n                       [ 0.0294],\n                       [-0.0127],\n                       [ 0.0977]],\n              \n                      [[ 0.1077],\n                       [ 0.0071],\n                       [-0.0889],\n                       ...,\n                       [ 0.1597],\n                       [-0.0588],\n                       [-0.0419]],\n              \n                      ...,\n              \n                      [[ 0.0384],\n                       [-0.0324],\n                       [-0.0878],\n                       ...,\n                       [ 0.1114],\n                       [ 0.0493],\n                       [-0.0550]],\n              \n                      [[-0.0477],\n                       [-0.0720],\n                       [-0.0068],\n                       ...,\n                       [-0.0667],\n                       [-0.0595],\n                       [-0.0101]],\n              \n                      [[ 0.0441],\n                       [-0.0778],\n                       [-0.0917],\n                       ...,\n                       [-0.0944],\n                       [ 0.0606],\n                       [-0.1236]]], dtype=torch.float64)),\n             ('6.3.convpath.0.0.1.weight',\n              tensor([0.9935, 0.9731, 0.9612, 0.9738, 0.9545, 0.9781, 0.9811, 0.9550, 0.9498,\n                      0.9865, 0.9717, 0.9801, 0.9979, 0.9713, 0.9737, 0.9673, 0.9912, 0.9685,\n                      0.9740, 0.9688, 0.9852, 0.9917, 0.9636, 0.9742, 0.9627, 0.9533, 0.9680,\n                      0.9567, 0.9669, 0.9962, 0.9536, 0.9725, 0.9687, 0.9831, 0.9744, 0.9902,\n                      0.9760, 0.9582, 0.9558, 0.9759, 0.9432, 0.9873, 0.9957, 0.9624, 0.9565,\n                      0.9778, 0.9841, 0.9503, 0.9769, 0.9862, 0.9582, 0.9417, 0.9666, 0.9403,\n                      0.9589, 0.9697, 0.9408, 0.9820, 0.9826, 0.9694, 0.9604, 0.9714, 0.9497,\n                      0.9740], dtype=torch.float64)),\n             ('6.3.convpath.0.0.1.bias',\n              tensor([ 0.0049,  0.0009,  0.0009,  0.0042,  0.0016, -0.0095,  0.0054, -0.0155,\n                       0.0024,  0.0267,  0.0041, -0.0051,  0.0226, -0.0117,  0.0080, -0.0095,\n                       0.0065, -0.0084,  0.0097, -0.0190,  0.0117,  0.0155, -0.0041,  0.0208,\n                       0.0037,  0.0010,  0.0303, -0.0134, -0.0065,  0.0315, -0.0169,  0.0191,\n                      -0.0140,  0.0043,  0.0091,  0.0245,  0.0149, -0.0093, -0.0061,  0.0071,\n                      -0.0196,  0.0135,  0.0201, -0.0065, -0.0124, -0.0202, -0.0006, -0.0115,\n                       0.0025,  0.0042, -0.0105, -0.0219,  0.0026, -0.0188, -0.0108, -0.0028,\n                       0.0005, -0.0061,  0.0174,  0.0042, -0.0018, -0.0101, -0.0141,  0.0005],\n                     dtype=torch.float64)),\n             ('6.3.convpath.0.0.1.running_mean',\n              tensor([-0.1689, -0.6454,  0.5007, -0.6568, -0.5218,  0.2219,  0.6869,  1.0033,\n                      -0.4050, -0.4411,  0.3008,  0.4656,  0.1833, -0.4233, -0.1463, -0.8737,\n                       0.3207, -0.3210, -0.5028, -0.2203,  0.9405, -0.1224,  0.5320, -0.6759,\n                      -0.4003, -1.3419, -0.7312,  0.2378, -0.5220, -0.0550, -0.3125, -0.0616,\n                       0.2173,  0.5440, -0.7067, -0.4562,  0.4488, -0.8552, -1.0228, -0.0434,\n                       0.2758,  0.3100, -0.0106, -0.5302, -0.2465,  0.7208, -0.5049, -0.3898,\n                       0.3156, -0.8468, -0.0516, -0.3231, -0.5626, -0.5411,  0.5492, -0.1812,\n                      -0.1690,  0.3352,  0.1052, -0.7155,  0.3739,  0.3544, -0.1342, -0.6355],\n                     dtype=torch.float64)),\n             ('6.3.convpath.0.0.1.running_var',\n              tensor([0.2957, 0.1850, 0.6652, 0.1615, 0.1821, 0.1174, 0.1498, 0.9403, 0.2352,\n                      0.1613, 0.1707, 0.1140, 0.2361, 0.3256, 0.2065, 0.3258, 0.1653, 0.1706,\n                      0.1365, 0.2307, 0.1310, 0.1917, 0.2583, 0.5242, 0.1197, 0.5175, 1.2508,\n                      0.0833, 0.6942, 0.2924, 0.7822, 0.1226, 0.1766, 0.1477, 0.1564, 0.2425,\n                      0.1206, 0.7851, 0.4172, 0.4345, 0.5028, 0.2169, 0.2132, 0.9674, 0.3974,\n                      0.1051, 0.1339, 0.3912, 0.3281, 0.1969, 0.2259, 0.2053, 0.2290, 0.2571,\n                      0.7919, 0.1274, 0.2036, 0.1188, 0.1055, 0.4394, 0.3305, 0.4820, 0.3490,\n                      0.4003], dtype=torch.float64)),\n             ('6.3.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.3.convpath.0.1.0.weight',\n              tensor([[[ 4.5031e-02, -6.3458e-02, -6.3075e-02, -1.6577e-02,  5.6874e-02],\n                       [ 2.0491e-02, -2.6789e-02, -3.9041e-02,  1.5200e-02, -5.2503e-02],\n                       [ 1.9974e-02,  5.6953e-02,  4.5140e-02,  4.4333e-02, -1.0485e-01],\n                       ...,\n                       [ 9.7279e-02, -1.6135e-02, -2.0964e-02,  7.8871e-02, -1.7372e-03],\n                       [-9.4632e-02, -5.1138e-02, -5.7390e-02, -8.4832e-02, -5.1471e-02],\n                       [-4.3466e-03, -9.9913e-03,  1.4457e-01,  8.2719e-02, -1.1791e-01]],\n              \n                      [[-1.8770e-03,  4.1147e-03,  4.7226e-02,  8.6625e-02,  2.8036e-02],\n                       [ 3.2393e-02,  6.5667e-02, -2.3525e-02,  2.1569e-02,  2.3630e-02],\n                       [-2.7386e-02, -9.6487e-02, -1.9150e-02, -2.6737e-03, -7.6384e-02],\n                       ...,\n                       [-4.4700e-02,  2.5130e-02, -2.2918e-02, -6.3791e-02, -7.8412e-02],\n                       [ 5.3158e-02,  1.3616e-04,  1.0444e-01,  1.5605e-01, -6.6482e-02],\n                       [-6.2230e-03,  3.8805e-02, -5.4779e-02,  4.8002e-02,  5.7375e-02]],\n              \n                      [[-1.4027e-02, -5.6741e-02,  2.0611e-01, -9.8751e-02, -1.6259e-01],\n                       [ 6.5376e-02,  5.7862e-02, -2.7659e-02, -4.5727e-02, -1.5635e-01],\n                       [-3.7132e-02,  6.7694e-03, -1.8052e-02, -1.2627e-01,  2.8058e-02],\n                       ...,\n                       [ 5.7850e-02,  6.0785e-02, -6.1765e-02, -6.7465e-02, -4.7162e-03],\n                       [ 2.1174e-02,  1.1555e-02, -1.6849e-02,  2.9702e-02, -9.2858e-02],\n                       [-1.2654e-01, -4.5266e-02, -3.7955e-02,  3.1690e-02, -1.2174e-02]],\n              \n                      ...,\n              \n                      [[-3.9478e-02,  1.0042e-01, -8.3087e-02,  4.0227e-03, -6.9969e-02],\n                       [-6.1648e-02, -7.0065e-02, -6.9993e-02, -7.2487e-03,  7.3063e-02],\n                       [ 1.0302e-01, -2.9896e-02, -4.4484e-02, -1.1333e-01, -5.4941e-02],\n                       ...,\n                       [-2.3024e-03,  3.8355e-02,  2.2813e-02, -8.2025e-02,  3.9636e-02],\n                       [-7.8375e-02, -1.0918e-01,  7.3916e-02, -5.5115e-02, -6.6182e-02],\n                       [ 4.9850e-02,  1.5487e-02, -3.5750e-02, -6.2412e-03,  3.0324e-02]],\n              \n                      [[-2.8848e-02,  7.6258e-02,  2.3487e-02, -1.7766e-02,  5.5746e-02],\n                       [-1.4409e-01,  7.5147e-02, -2.4324e-02,  1.8695e-02, -9.0342e-02],\n                       [-4.0029e-02, -7.8973e-03,  2.9468e-02,  1.0257e-02, -4.5983e-02],\n                       ...,\n                       [ 6.9523e-02, -1.2981e-01,  4.3978e-02,  4.7004e-02, -1.5814e-01],\n                       [ 5.6193e-02,  6.7428e-02,  8.7977e-02, -6.6451e-02, -1.1659e-01],\n                       [ 6.6541e-03,  8.6018e-02,  1.7445e-01,  3.7791e-02,  4.5388e-02]],\n              \n                      [[ 1.9111e-02,  8.4569e-02,  9.3869e-02, -1.4621e-02,  2.5622e-02],\n                       [-2.1762e-03,  2.6920e-02, -5.7559e-02,  6.0002e-02, -8.6922e-02],\n                       [-2.2274e-02, -7.2869e-02,  2.4974e-02, -9.8059e-02, -1.1518e-01],\n                       ...,\n                       [-1.1634e-01, -1.4494e-01,  2.5907e-03,  3.9700e-03, -1.0767e-01],\n                       [ 7.5978e-03, -1.0776e-02,  3.6922e-02,  5.9500e-03, -8.0243e-02],\n                       [-1.2482e-01, -8.9399e-02, -9.5219e-02,  6.8358e-02, -4.5209e-02]]],\n                     dtype=torch.float64)),\n             ('6.3.convpath.0.1.1.weight',\n              tensor([0.9680, 0.9565, 0.9494, 0.9710, 0.9973, 0.9857, 0.9568, 0.9794, 0.9721,\n                      0.9667, 0.9802, 0.9445, 0.9960, 0.9518, 0.9400, 0.9668, 0.9868, 0.9472,\n                      0.9522, 0.9545, 0.9489, 0.9434, 0.9712, 0.9665, 0.9481, 1.0015, 0.9505,\n                      0.9442, 0.9477, 0.9436, 0.9783, 0.9651, 0.9572, 0.9627, 0.9491, 0.9419,\n                      0.9517, 0.9593, 0.9588, 0.9845, 0.9700, 0.9549, 0.9760, 0.9631, 0.9469,\n                      0.9668, 0.9415, 0.9701, 0.9775, 0.9446, 0.9570, 0.9635, 0.9743, 0.9721,\n                      1.0181, 0.9883, 0.9804, 0.9659, 0.9889, 0.9456, 0.9781, 0.9373, 0.9710,\n                      0.9605], dtype=torch.float64)),\n             ('6.3.convpath.0.1.1.bias',\n              tensor([-0.0030,  0.0023,  0.0096, -0.0051, -0.0052, -0.0087, -0.0128, -0.0167,\n                       0.0082, -0.0094,  0.0257, -0.0099,  0.0172, -0.0264, -0.0208, -0.0011,\n                       0.0078, -0.0333, -0.0157, -0.0061, -0.0270, -0.0129,  0.0003, -0.0076,\n                      -0.0169,  0.0250, -0.0265, -0.0228, -0.0229, -0.0067, -0.0105,  0.0138,\n                      -0.0258, -0.0145, -0.0125, -0.0164, -0.0027, -0.0085, -0.0033, -0.0064,\n                      -0.0261, -0.0053,  0.0048,  0.0069, -0.0281, -0.0302, -0.0325, -0.0138,\n                       0.0056, -0.0046, -0.0017,  0.0157, -0.0130,  0.0142,  0.0096,  0.0095,\n                       0.0096, -0.0097,  0.0218, -0.0215,  0.0114, -0.0255,  0.0010,  0.0027],\n                     dtype=torch.float64)),\n             ('6.3.convpath.0.1.1.running_mean',\n              tensor([ 2.3425e-01,  3.7149e-01,  4.3241e-01,  8.3932e-02, -4.2117e-01,\n                      -4.5153e-02, -8.0430e-01,  2.1780e-01, -1.6376e-01, -1.0474e-01,\n                      -6.1503e-01, -5.3871e-01, -2.4249e-01,  6.5866e-01, -7.0890e-01,\n                      -3.3458e-01,  1.4502e-01, -4.5255e-01, -3.4243e-01, -5.7911e-01,\n                      -6.2067e-01, -1.4191e-01,  2.0950e-01, -8.8122e-01,  1.0047e-01,\n                      -1.5438e+00, -7.5754e-01, -3.7798e-02, -5.3896e-01, -2.6246e-01,\n                       6.6092e-01, -1.7345e-01,  8.6860e-01, -2.6438e-01, -2.0020e-01,\n                       1.5678e-01,  8.9396e-02,  3.1140e-01,  2.9925e-01,  7.2220e-02,\n                       1.1998e+00, -2.3521e-01,  3.8395e-01,  8.7388e-04, -2.8525e-02,\n                      -2.0763e-02, -2.8935e-01, -3.0140e-01,  1.1521e+00, -5.0367e-01,\n                       2.7059e-01,  1.8194e-01, -4.8049e-01, -2.0566e-01, -3.2340e-01,\n                      -4.2698e-01, -2.9017e-01, -8.7020e-01, -9.4385e-01,  4.9539e-01,\n                      -4.2253e-01, -7.6930e-01, -5.5113e-02, -2.9616e-01],\n                     dtype=torch.float64)),\n             ('6.3.convpath.0.1.1.running_var',\n              tensor([0.5746, 0.4747, 0.5640, 0.6424, 0.3706, 0.6119, 0.4254, 0.5075, 0.5688,\n                      0.4522, 0.4759, 0.4375, 0.3805, 0.5140, 0.4898, 0.4796, 0.3944, 0.4470,\n                      0.6586, 0.5441, 0.4637, 0.4697, 0.3897, 0.4250, 0.4211, 0.4002, 0.7138,\n                      0.5290, 0.3935, 0.6045, 0.4530, 0.8621, 0.4318, 0.5820, 0.5275, 0.3842,\n                      0.3985, 0.3439, 0.7150, 0.3545, 0.5025, 0.4816, 0.5740, 0.4801, 0.6412,\n                      0.3365, 0.6341, 0.4325, 0.4430, 0.6994, 0.2934, 0.5097, 0.3342, 0.6173,\n                      0.3313, 0.5447, 0.5178, 0.3036, 0.3872, 0.3721, 0.5089, 0.5584, 0.4697,\n                      0.7280], dtype=torch.float64)),\n             ('6.3.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.3.convpath.0.2.0.weight',\n              tensor([[[-0.1076],\n                       [-0.0879],\n                       [-0.0580],\n                       ...,\n                       [ 0.0500],\n                       [ 0.0128],\n                       [ 0.0263]],\n              \n                      [[-0.2342],\n                       [-0.0028],\n                       [-0.2151],\n                       ...,\n                       [ 0.0490],\n                       [ 0.1289],\n                       [ 0.0080]],\n              \n                      [[ 0.1034],\n                       [ 0.0496],\n                       [-0.0758],\n                       ...,\n                       [-0.0451],\n                       [-0.1655],\n                       [-0.0212]],\n              \n                      ...,\n              \n                      [[ 0.1794],\n                       [-0.0978],\n                       [-0.3339],\n                       ...,\n                       [ 0.0715],\n                       [-0.0033],\n                       [-0.0014]],\n              \n                      [[-0.0183],\n                       [-0.1509],\n                       [ 0.1345],\n                       ...,\n                       [ 0.0299],\n                       [-0.0301],\n                       [-0.0818]],\n              \n                      [[ 0.2681],\n                       [ 0.3150],\n                       [ 0.0174],\n                       ...,\n                       [ 0.2031],\n                       [-0.0307],\n                       [ 0.0048]]], dtype=torch.float64)),\n             ('6.3.convpath.0.2.1.weight',\n              tensor([ 7.9271e-03,  1.4752e-02, -2.4944e-02,  1.0540e-02, -1.6292e-02,\n                      -1.5966e-02,  3.2396e-02, -1.2903e-02, -7.2734e-04, -4.3549e-02,\n                      -1.0139e-02, -6.7067e-03, -2.5998e-03,  1.0467e-02,  6.9312e-03,\n                      -4.5640e-02,  2.0227e-02,  1.8202e-02, -2.0453e-02, -1.0500e-03,\n                      -7.1799e-03, -1.4364e-02,  1.0086e-04, -1.5460e-02, -2.9384e-02,\n                      -1.2352e-02,  1.8998e-02,  3.4095e-03, -9.8179e-03, -3.6893e-03,\n                      -2.2751e-02,  2.7015e-02,  9.8841e-03,  1.5321e-02, -3.2800e-02,\n                       1.7462e-03,  4.4897e-03, -5.2315e-04, -9.0990e-03,  1.0988e-02,\n                       2.2826e-02,  3.2831e-02, -5.3111e-03, -8.6741e-04, -1.6954e-02,\n                      -6.4237e-03, -4.5184e-03, -2.1553e-03,  1.9586e-02,  2.0786e-03,\n                       7.2736e-03,  2.4172e-02,  1.8243e-02,  3.1963e-02,  8.5083e-03,\n                       6.1561e-02,  5.6541e-03,  3.3565e-02, -2.1821e-02,  7.7970e-03,\n                      -9.6951e-03, -1.2799e-02, -7.0902e-03, -1.3442e-02, -1.5165e-02,\n                       3.2970e-02, -1.3717e-03, -2.3781e-02,  3.1767e-02, -3.0989e-02,\n                       1.8659e-02, -1.5683e-02,  6.2696e-03, -1.0108e-02,  2.3595e-02,\n                      -2.0985e-02,  1.1475e-03, -5.1191e-03,  1.9089e-03, -6.1693e-03,\n                       1.2506e-03,  1.4818e-02, -2.6806e-02, -2.3726e-02,  1.1694e-03,\n                      -3.3108e-02, -2.6355e-02,  8.1053e-03, -1.3698e-02,  1.8181e-03,\n                      -4.5789e-03, -1.7559e-02, -2.6936e-02,  3.1706e-04, -1.3582e-02,\n                      -1.0437e-02, -1.9103e-02, -1.6111e-02,  1.5976e-02, -1.2342e-02,\n                      -1.5933e-02, -2.2652e-02, -1.7446e-02, -4.4654e-02,  1.6962e-02,\n                      -1.6748e-02,  1.5351e-02, -5.8498e-03,  5.8600e-03,  1.1966e-02,\n                      -7.9705e-03,  9.1065e-03, -2.8181e-02,  2.5419e-02, -4.4393e-03,\n                       2.8749e-02,  4.2918e-03,  2.2072e-03,  1.5599e-02, -1.1009e-02,\n                      -8.2406e-03,  4.6298e-02, -1.5521e-02,  9.4074e-03,  2.6572e-02,\n                      -1.3178e-02, -1.0459e-02,  1.7976e-02, -2.4415e-03,  1.6718e-02,\n                       1.8723e-02,  7.3763e-03,  1.3920e-02,  1.6652e-02,  1.6086e-02,\n                      -9.1912e-03, -3.6401e-02,  7.3499e-03, -2.3338e-02,  1.6216e-02,\n                      -3.6649e-03,  1.9585e-03,  8.6547e-03,  1.5867e-03,  1.8214e-02,\n                      -3.9011e-03, -3.4455e-03,  1.3634e-02,  3.0101e-02,  1.8651e-02,\n                       2.5530e-02,  2.8263e-03, -3.8641e-03,  2.9694e-02, -1.4794e-02,\n                       2.0702e-03,  3.5324e-03, -1.5048e-02, -2.2033e-03,  4.3454e-04,\n                      -3.4054e-03, -3.5716e-03, -2.8820e-02, -1.0530e-02, -3.8970e-03,\n                       6.6733e-05, -2.5009e-03, -3.4745e-02,  1.2368e-03,  3.0235e-02,\n                       2.3713e-02, -1.9599e-02,  9.5653e-03, -1.7575e-02,  3.2235e-04,\n                      -2.1831e-03, -1.5232e-02, -2.2780e-04,  3.2814e-02, -2.0912e-02,\n                      -1.6513e-02, -1.2591e-02, -1.9934e-02,  1.3690e-02, -1.7553e-02,\n                       2.1786e-04,  6.8375e-03,  1.0423e-02, -1.0923e-02,  8.3421e-03,\n                      -7.9088e-03,  6.8457e-03,  1.9326e-02,  3.0229e-02,  9.8381e-03,\n                      -2.2590e-03, -1.2541e-02,  1.0267e-02,  2.2497e-02,  6.8712e-03,\n                       7.9821e-03,  5.9914e-03, -1.2369e-02, -2.6366e-02,  2.3968e-02,\n                      -1.6106e-02,  1.4658e-02,  3.2371e-03, -2.8337e-02, -2.1815e-02,\n                      -1.1108e-02, -1.4792e-02, -9.9776e-03,  5.9600e-03,  2.0668e-02,\n                      -2.3164e-02,  6.9716e-04,  6.8160e-04,  2.1876e-02,  4.4789e-03,\n                       1.8181e-03,  2.1077e-02, -2.7272e-03, -3.8133e-02,  1.1089e-02,\n                      -7.2474e-03, -3.6176e-03,  4.6825e-03,  2.1195e-03, -3.5034e-03,\n                       1.4512e-02, -3.9083e-03, -2.5785e-02, -2.2522e-02,  1.7175e-02,\n                       1.7519e-02, -1.1759e-03,  4.7351e-03,  2.8044e-03, -8.2294e-03,\n                       2.8937e-02, -1.6456e-02,  1.3573e-02,  1.7298e-02,  9.1072e-03,\n                       2.6329e-02,  1.8432e-02, -2.6275e-02, -6.1240e-03, -5.0538e-02,\n                       7.8578e-03, -1.4737e-02, -1.5483e-02, -4.0752e-02,  5.3759e-03,\n                       2.3468e-02], dtype=torch.float64)),\n             ('6.3.convpath.0.2.1.bias',\n              tensor([-2.5797e-03, -6.4166e-03,  1.7968e-02,  9.6252e-03,  4.8672e-03,\n                       1.7111e-03,  2.1250e-02,  1.3986e-03,  7.2805e-03,  2.1452e-02,\n                       1.2049e-02, -8.7455e-03,  1.0498e-02, -7.0585e-03,  3.5840e-03,\n                       6.6433e-03,  1.8841e-02, -1.1966e-03,  1.6624e-02, -8.6635e-03,\n                      -1.4258e-03,  2.9578e-03,  2.0191e-03,  7.5122e-03, -6.2062e-03,\n                      -1.3662e-02,  7.8087e-03,  1.0927e-02,  2.4027e-03, -1.8442e-03,\n                       9.1861e-03,  9.4733e-03, -8.5312e-03,  1.6039e-02,  1.5431e-02,\n                       7.0945e-03,  1.2773e-03,  2.4802e-02,  9.6879e-03,  1.3565e-02,\n                       1.0158e-03,  8.0390e-03, -9.3413e-03,  9.7143e-04,  7.6194e-03,\n                      -1.1149e-02,  5.3431e-03,  4.1254e-03, -1.1173e-02,  8.6138e-03,\n                       8.5550e-03,  3.5668e-03,  8.6429e-03,  1.5206e-02,  5.3058e-03,\n                       5.9685e-04,  6.2454e-03,  3.0971e-03,  7.7455e-03,  6.7122e-03,\n                      -6.9629e-03,  9.6579e-04, -1.9555e-03,  1.0024e-02, -4.3331e-03,\n                       1.4677e-02, -1.2219e-02,  1.4050e-02,  3.1068e-03, -1.0353e-02,\n                       3.2450e-03,  1.9400e-03,  2.8112e-03, -7.9846e-03,  1.5279e-02,\n                       1.2359e-02,  9.4672e-04,  5.0230e-03,  3.8470e-03,  3.8547e-03,\n                       1.0760e-02, -5.5447e-03,  7.2977e-03,  4.9505e-03, -1.4065e-03,\n                       1.5111e-02,  2.4747e-03,  7.0994e-04,  9.7134e-03,  9.2644e-03,\n                      -6.6351e-05,  2.3230e-02,  1.6856e-02, -6.2465e-04,  9.1547e-04,\n                      -1.3152e-02,  3.9805e-03, -2.3112e-03,  1.8073e-02, -1.6151e-04,\n                       2.4512e-02,  5.2652e-03, -4.6760e-03, -7.9471e-03,  1.5674e-02,\n                       1.5860e-04,  3.2319e-04,  3.8463e-03,  4.1308e-03,  8.1087e-03,\n                      -7.1594e-03, -6.7726e-03,  4.7677e-03,  1.5856e-02,  1.2056e-02,\n                       7.8134e-03,  1.1585e-02,  3.0279e-03,  1.6566e-03, -1.5232e-02,\n                       2.4739e-03,  1.4688e-02,  1.9706e-03, -2.2335e-03, -1.0827e-02,\n                       1.2731e-02,  1.6649e-02,  2.5848e-03, -1.0972e-03,  1.0482e-02,\n                       2.3559e-03,  1.7923e-02,  1.4908e-02,  1.2129e-02,  1.9872e-02,\n                      -5.5732e-03,  1.7946e-02,  1.0659e-02,  1.6815e-02,  1.3415e-02,\n                       2.9935e-03, -2.8692e-03, -6.2181e-03,  8.4919e-03, -1.1181e-02,\n                       9.1374e-03,  7.5024e-04, -1.9775e-03,  1.0768e-02,  1.0696e-02,\n                       5.5905e-03,  1.1978e-02,  2.6439e-03,  1.5226e-02,  1.3163e-02,\n                       9.9906e-03,  6.4174e-04,  7.8299e-03, -7.2982e-03, -1.1654e-02,\n                      -5.0409e-04, -5.7676e-03,  3.5750e-03,  1.3752e-02,  1.2173e-02,\n                       1.9156e-03, -8.2165e-03,  9.1166e-03,  5.5799e-04,  1.5762e-02,\n                       4.8862e-03,  3.4844e-03,  1.3013e-02,  8.5047e-03, -1.3988e-02,\n                       7.5465e-03,  4.8147e-04,  1.2440e-02,  5.6185e-03,  6.7487e-03,\n                      -1.6659e-03,  9.2644e-03, -8.1001e-03, -1.0956e-02,  1.7238e-02,\n                       9.5468e-03,  1.5040e-02,  1.5780e-02, -2.5404e-03,  4.0520e-03,\n                       6.8105e-03, -1.4866e-03,  1.4260e-02, -1.7143e-02,  8.4410e-03,\n                       8.9528e-03, -2.2591e-03,  1.5966e-02,  9.2660e-03, -3.8299e-03,\n                       5.2248e-03,  1.5178e-02,  2.0447e-02,  1.7305e-02,  3.1560e-03,\n                      -3.1190e-03,  1.4590e-02, -4.3336e-03,  1.1115e-02,  5.5736e-03,\n                      -1.4519e-03,  1.2063e-02,  1.3603e-02,  6.2508e-03,  1.6845e-02,\n                       1.1002e-02,  3.8736e-03, -1.9929e-03,  4.7750e-03, -2.3595e-04,\n                      -1.2766e-02,  1.1142e-03,  6.8171e-03,  2.5343e-02, -1.7622e-03,\n                       2.0054e-03, -2.6380e-03,  1.6573e-03, -1.4969e-02,  1.4265e-02,\n                       1.3984e-02, -2.2679e-04,  1.1407e-02,  1.3016e-02,  7.6625e-03,\n                       3.9857e-03,  7.0756e-03, -3.9548e-03,  1.1298e-02,  1.0375e-02,\n                       5.8061e-03,  2.0565e-03,  2.8068e-03,  1.7745e-02,  2.9343e-03,\n                       1.4018e-02,  4.8125e-03,  9.8152e-03,  2.6523e-03, -8.0405e-03,\n                       1.6091e-02,  1.0336e-02,  2.1011e-02,  2.3282e-02,  1.1866e-02,\n                       1.2871e-02], dtype=torch.float64)),\n             ('6.3.convpath.0.2.1.running_mean',\n              tensor([-0.2267,  0.5422, -0.3213, -0.4263,  0.0984, -0.4728,  0.0652,  1.0632,\n                       0.0396, -0.3144,  0.1486,  0.4458, -0.2995, -0.1862, -0.0224,  0.0589,\n                      -0.0301,  0.1369, -0.5435,  0.1346, -0.2618, -0.0212, -0.3196,  0.6038,\n                       0.0203,  0.0999,  0.2791,  0.0769, -0.0639,  0.1187,  0.3009, -1.2147,\n                       0.0548, -0.4886,  0.6524,  0.1250,  0.1078, -0.1685, -0.0134,  0.0649,\n                      -0.2516, -0.2236, -0.5682,  0.0142, -0.7515, -0.0452, -0.3235, -0.4087,\n                       0.2204,  0.0308, -0.2752,  0.8270,  0.2894, -0.3734,  0.0138,  0.2118,\n                      -0.8439, -0.3997,  0.0901, -0.0333, -0.0534,  0.0550, -0.1423,  0.4303,\n                       0.1166, -0.1768,  0.0517,  0.2433,  0.0671, -0.1288, -0.2415, -0.0478,\n                       0.1379, -0.4132, -0.2211, -0.1956, -0.2170, -0.3617, -0.4722,  0.1780,\n                       0.2271, -0.0401,  1.1079, -0.3459,  0.4742, -0.4362, -0.3101,  0.2097,\n                       0.3725,  0.0055, -0.3125,  0.1083,  0.3245, -0.1293,  0.2052,  0.4252,\n                       0.6518, -0.2515,  0.3633, -0.1881,  0.1247, -0.1707, -0.7745,  0.9025,\n                      -0.0674,  0.1191,  0.0908,  0.2016, -0.6305, -0.0916,  0.4997,  0.6293,\n                      -0.2252, -0.1997,  0.2519, -0.0738, -0.3401, -0.3462, -0.5845, -0.1075,\n                       0.1403, -0.2271, -0.1481, -0.0731, -0.1917, -1.0139, -0.1228,  0.1721,\n                      -0.0847, -0.6929,  0.6839,  0.3688, -0.1183,  0.0117,  0.7924, -0.1750,\n                      -0.5865,  0.3880, -0.3170,  0.4644, -0.1108, -0.0901,  0.4010, -0.0916,\n                      -0.3747,  0.3213, -0.9464,  0.8493,  0.9863,  0.0258,  1.1218, -0.1840,\n                       0.2322, -0.2805,  0.0937, -0.0591, -0.0811,  0.4331,  0.4479,  0.0387,\n                      -0.1105, -0.2983,  0.1763,  0.3549,  0.1889,  0.3164,  0.1144,  0.3418,\n                      -0.4611, -0.1635,  0.0971, -0.0387,  0.2837, -0.0441,  0.0814, -0.4246,\n                       0.1223, -0.4369,  0.0525, -0.1465, -0.2343,  0.2440, -0.7122, -0.0932,\n                       0.2462,  0.2852,  0.1129, -0.1174, -0.2790,  0.4488, -0.0545, -0.3631,\n                       0.4095, -0.4082,  0.0627,  0.3342, -0.2570,  0.3475, -0.4352,  0.3147,\n                       0.9032, -0.0280,  0.0565,  0.5175, -0.5945, -0.1374, -0.8371, -0.0728,\n                       0.0571, -0.6066, -0.2512, -0.4747,  0.1756, -0.2084, -0.0068, -0.4700,\n                       0.5443,  0.7048, -0.8123,  0.1890, -0.2087,  0.0978,  0.1175,  0.0488,\n                      -0.3868, -0.1939,  0.1089, -0.4571, -0.0613, -0.3399,  0.4603,  0.1733,\n                      -0.3530,  0.1698, -0.3653, -0.4882,  0.0573, -0.0095,  0.3071,  0.3315,\n                       0.3030, -0.5403,  0.0657,  0.1266,  0.0201,  0.0203, -0.0623, -0.2637,\n                      -0.3389,  0.3613, -0.1978,  0.2255,  0.3015,  0.4886,  0.4628,  0.4543],\n                     dtype=torch.float64)),\n             ('6.3.convpath.0.2.1.running_var',\n              tensor([0.4341, 0.5010, 0.5003, 0.4717, 0.3296, 0.2574, 0.3748, 0.6318, 0.2433,\n                      0.4302, 0.2385, 0.3211, 0.0777, 0.2710, 0.4782, 0.3720, 0.3314, 0.3843,\n                      0.3304, 0.1331, 0.2116, 0.4893, 0.3066, 0.2812, 0.4371, 0.1976, 0.3328,\n                      0.1834, 0.1537, 0.2551, 0.5762, 0.6211, 0.3570, 0.3631, 0.5047, 0.2072,\n                      0.1735, 0.1507, 0.4816, 0.3639, 0.5588, 0.5165, 0.1427, 0.1776, 0.3557,\n                      0.2238, 0.3823, 0.2334, 0.6126, 0.2091, 0.2440, 0.4523, 0.5193, 0.4251,\n                      0.3072, 0.3365, 0.5630, 0.3503, 0.3632, 0.3673, 0.0628, 0.5931, 0.2075,\n                      0.3491, 0.4900, 0.2878, 0.2552, 0.4274, 0.3382, 0.6454, 0.2184, 0.2065,\n                      0.1440, 0.3929, 0.5260, 0.3500, 0.1571, 0.2379, 0.2796, 0.3024, 0.3227,\n                      0.2230, 0.7174, 0.3552, 0.4536, 0.4973, 0.5176, 0.3347, 0.3335, 0.1594,\n                      0.6222, 0.1895, 0.4836, 0.2193, 0.2678, 0.2000, 0.5660, 0.3048, 0.3450,\n                      0.3924, 0.3225, 0.3510, 0.2847, 0.3685, 0.3997, 0.3987, 0.3094, 0.2452,\n                      0.4192, 0.1789, 0.1316, 0.5826, 0.6280, 0.4521, 0.2742, 0.6394, 0.2055,\n                      0.2683, 0.4585, 0.2726, 0.0637, 0.3251, 0.6829, 0.2007, 0.1782, 0.4782,\n                      0.4326, 0.2947, 0.1405, 0.6025, 0.3042, 0.1580, 0.3477, 0.4006, 0.4220,\n                      0.0915, 0.6197, 0.2680, 0.4636, 0.3206, 0.1654, 0.0536, 0.2961, 0.0555,\n                      0.2196, 0.3075, 0.2937, 0.4027, 0.5107, 0.2758, 0.5003, 0.1201, 0.3101,\n                      0.4930, 0.4281, 0.3523, 0.2032, 0.3536, 0.3066, 0.1138, 0.1840, 0.1884,\n                      0.3643, 0.3074, 0.2156, 0.2430, 0.6827, 0.5311, 0.2100, 0.2853, 0.3571,\n                      0.3646, 0.4040, 0.2706, 0.2679, 0.3508, 0.3773, 0.5498, 0.4243, 0.2326,\n                      0.3234, 0.2553, 0.6887, 0.5037, 0.1880, 0.4436, 0.4816, 0.2002, 0.2692,\n                      0.1627, 0.2520, 0.5069, 0.5069, 0.6947, 0.3158, 0.3466, 0.5558, 0.2225,\n                      0.5419, 0.2837, 0.2488, 0.2575, 0.3021, 0.4223, 0.3250, 0.4568, 0.5204,\n                      0.0493, 0.3865, 0.5032, 0.1194, 0.3346, 0.1460, 0.3589, 0.2040, 0.2098,\n                      0.3106, 0.2590, 0.6542, 0.2730, 0.0955, 0.3001, 0.0792, 0.4771, 0.2620,\n                      0.3220, 0.1112, 0.1713, 0.3128, 0.5375, 0.2936, 0.1748, 0.5022, 0.3253,\n                      0.2516, 0.4851, 0.2133, 0.2062, 0.4364, 0.2585, 0.2966, 0.3104, 0.4686,\n                      0.2842, 0.1494, 0.3829, 0.3308, 0.2755, 0.0891, 0.2700, 0.4172, 0.4015,\n                      0.2388, 0.4631, 0.3016, 0.4052], dtype=torch.float64)),\n             ('6.3.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.4.convs.0.0.weight',\n              tensor([[[ 0.1280],\n                       [-0.1035],\n                       [-0.1267],\n                       ...,\n                       [ 0.0234],\n                       [-0.1324],\n                       [-0.0155]],\n              \n                      [[-0.0662],\n                       [ 0.0655],\n                       [-0.0418],\n                       ...,\n                       [ 0.0477],\n                       [ 0.0338],\n                       [-0.0227]],\n              \n                      [[-0.0016],\n                       [-0.2553],\n                       [ 0.1632],\n                       ...,\n                       [ 0.0109],\n                       [ 0.0203],\n                       [-0.0257]],\n              \n                      ...,\n              \n                      [[-0.1318],\n                       [-0.0291],\n                       [-0.0040],\n                       ...,\n                       [ 0.1129],\n                       [ 0.0471],\n                       [ 0.1508]],\n              \n                      [[ 0.0143],\n                       [-0.0080],\n                       [-0.2073],\n                       ...,\n                       [ 0.0025],\n                       [-0.0724],\n                       [-0.0636]],\n              \n                      [[ 0.0787],\n                       [ 0.0510],\n                       [ 0.0584],\n                       ...,\n                       [ 0.0343],\n                       [-0.0017],\n                       [ 0.1709]]], dtype=torch.float64)),\n             ('6.4.convs.0.1.weight',\n              tensor([0.9807, 0.9721, 0.9847, 0.9757, 0.9631, 0.9427, 0.9723, 0.9878, 0.9873,\n                      0.9670, 0.9786, 0.9806, 0.9669, 0.9876, 0.9624, 0.9503, 0.9845, 0.9650,\n                      0.9801, 0.9723, 0.9717, 0.9938, 0.9846, 0.9574, 0.9818, 0.9801, 0.9945,\n                      0.9848, 0.9668, 0.9754, 0.9716, 0.9662, 0.9553, 0.9737, 0.9539, 0.9802,\n                      0.9842, 0.9895, 0.9575, 0.9840, 0.9647, 0.9551, 0.9717, 0.9806, 0.9823,\n                      0.9882, 0.9692, 1.0054, 0.9572, 0.9526, 0.9741, 0.9717, 0.9626, 0.9683,\n                      0.9956, 0.9699, 0.9870, 0.9521, 0.9751, 0.9768, 0.9590, 0.9907, 0.9785,\n                      0.9806], dtype=torch.float64)),\n             ('6.4.convs.0.1.bias',\n              tensor([ 0.0231,  0.0084,  0.0175,  0.0032, -0.0044,  0.0022,  0.0005,  0.0068,\n                       0.0294, -0.0039,  0.0139,  0.0146,  0.0021, -0.0112, -0.0075, -0.0183,\n                      -0.0057, -0.0030,  0.0052,  0.0185,  0.0066, -0.0033,  0.0077, -0.0028,\n                       0.0147,  0.0131,  0.0093,  0.0134, -0.0077,  0.0007,  0.0179, -0.0145,\n                      -0.0117,  0.0109,  0.0050, -0.0123,  0.0012,  0.0095,  0.0069,  0.0093,\n                      -0.0238, -0.0028,  0.0161,  0.0110,  0.0203, -0.0077,  0.0140,  0.0006,\n                       0.0025,  0.0003, -0.0101, -0.0079, -0.0035, -0.0043,  0.0112, -0.0049,\n                       0.0020, -0.0036,  0.0011,  0.0058, -0.0036,  0.0191, -0.0133,  0.0172],\n                     dtype=torch.float64)),\n             ('6.4.convs.0.1.running_mean',\n              tensor([-0.4632,  0.1254, -0.2832,  0.2285, -0.4278,  0.2034,  0.6618,  0.1904,\n                       0.2264,  0.0017,  0.6837, -0.1792, -0.1299,  0.4395,  0.3017,  0.3805,\n                       0.2763, -0.6976, -0.4208, -0.2723, -0.7767, -0.2275, -0.5867,  0.3027,\n                       0.0678,  0.7659, -0.0750,  0.3878, -0.4447, -0.0967, -0.3339,  0.6166,\n                      -0.1603,  0.0918, -0.6660, -0.2460,  0.4202,  0.9156, -0.7886,  0.7088,\n                       0.3207, -0.8936,  0.0956, -0.4044, -0.0597,  0.7690,  0.3459, -0.0099,\n                       0.0109, -0.3409,  0.3994, -0.3050, -0.7988,  0.9873,  0.1096, -0.0741,\n                       0.0498, -0.3661, -0.3707, -0.0149, -0.6798,  0.0506,  0.0972,  0.2328],\n                     dtype=torch.float64)),\n             ('6.4.convs.0.1.running_var',\n              tensor([0.3478, 0.2438, 0.2253, 0.1620, 0.1947, 0.6998, 0.4111, 0.2117, 0.1464,\n                      0.1023, 0.1456, 0.2223, 0.1159, 0.1351, 0.1883, 0.1088, 0.1631, 0.2100,\n                      0.1679, 0.1516, 0.4105, 0.1724, 0.3009, 0.2516, 0.1694, 0.1956, 0.1129,\n                      0.2155, 0.1152, 0.1496, 0.2730, 0.2059, 0.1170, 0.2246, 0.7556, 0.1561,\n                      0.4204, 0.3233, 0.2207, 0.2742, 0.1411, 0.1675, 0.2316, 0.0967, 0.3162,\n                      0.4024, 0.5191, 0.1587, 0.1848, 0.2976, 0.8460, 0.1420, 0.3716, 0.3126,\n                      0.1283, 0.2314, 0.1193, 0.2613, 0.2010, 0.1078, 0.1955, 0.2995, 0.1385,\n                      0.2758], dtype=torch.float64)),\n             ('6.4.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.4.convs.1.0.weight',\n              tensor([[[-0.1009,  0.0396, -0.0098,  0.0778,  0.0400],\n                       [ 0.0229, -0.0880, -0.0927, -0.0935,  0.0848],\n                       [-0.0767,  0.0681,  0.0920, -0.1410, -0.0927],\n                       ...,\n                       [-0.0512,  0.1677,  0.0994, -0.0141,  0.0300],\n                       [-0.0760, -0.0037, -0.0808, -0.0341,  0.1678],\n                       [-0.1196, -0.0016, -0.1586,  0.0782,  0.0169]],\n              \n                      [[ 0.0108,  0.0159,  0.0184, -0.0552, -0.1591],\n                       [-0.0429,  0.0586, -0.0309,  0.0274,  0.0171],\n                       [ 0.0439,  0.0376,  0.0414, -0.0188,  0.0524],\n                       ...,\n                       [ 0.0145, -0.0361,  0.0838, -0.1250,  0.0598],\n                       [-0.0951, -0.1479, -0.0316, -0.0466, -0.0092],\n                       [-0.0773,  0.0057, -0.0394,  0.0655, -0.0480]],\n              \n                      [[ 0.0376, -0.0342,  0.0334, -0.0860,  0.0487],\n                       [ 0.0154, -0.0532,  0.0683,  0.0355, -0.0254],\n                       [ 0.0809,  0.0056,  0.0085,  0.1268, -0.1113],\n                       ...,\n                       [-0.0021,  0.0458, -0.0546, -0.0760,  0.1382],\n                       [-0.0579,  0.0031,  0.0618,  0.1125, -0.0129],\n                       [ 0.0688, -0.1407,  0.0624, -0.0104,  0.1265]],\n              \n                      ...,\n              \n                      [[ 0.0013,  0.0037,  0.0856,  0.1482, -0.0292],\n                       [-0.0881, -0.0076, -0.1153,  0.0297, -0.1292],\n                       [ 0.0674, -0.0180,  0.0214,  0.0931,  0.1507],\n                       ...,\n                       [-0.1210,  0.0269, -0.0213,  0.0953, -0.1508],\n                       [ 0.0710, -0.0595, -0.0486, -0.0358,  0.0326],\n                       [ 0.0008,  0.0471, -0.0873,  0.1042, -0.0103]],\n              \n                      [[ 0.0133, -0.1807, -0.0205, -0.0349, -0.0361],\n                       [ 0.0168, -0.0922, -0.0075, -0.0230, -0.0077],\n                       [-0.1613, -0.0623,  0.1027, -0.0887, -0.0915],\n                       ...,\n                       [ 0.1921, -0.0446, -0.0346, -0.0087, -0.1432],\n                       [ 0.0472,  0.0879,  0.0978, -0.1704, -0.0623],\n                       [ 0.1263,  0.0488, -0.0005, -0.1189, -0.0551]],\n              \n                      [[-0.0630, -0.0381, -0.0110, -0.0004, -0.1338],\n                       [ 0.0687,  0.0397,  0.1359, -0.0807, -0.0480],\n                       [-0.1538,  0.0459, -0.1119, -0.1158, -0.0047],\n                       ...,\n                       [ 0.0625,  0.0423, -0.1700, -0.1070,  0.0294],\n                       [-0.1350,  0.0003,  0.0328,  0.0574, -0.0229],\n                       [-0.0210, -0.0804,  0.0550, -0.0938,  0.0052]]], dtype=torch.float64)),\n             ('6.4.convs.1.1.weight',\n              tensor([0.9490, 0.9618, 0.9643, 0.9565, 0.9953, 0.9524, 0.9949, 0.9843, 0.9873,\n                      0.9507, 0.9973, 0.9819, 0.9750, 0.9403, 0.9757, 1.0033, 0.9857, 0.9775,\n                      0.9479, 0.9468, 0.9538, 0.9975, 0.9537, 0.9758, 0.9871, 0.9519, 0.9517,\n                      0.9497, 0.9672, 0.9589, 0.9285, 0.9483, 0.9615, 0.9537, 0.9729, 0.9673,\n                      1.0058, 0.9735, 1.0046, 0.9411, 0.9842, 0.9448, 0.9451, 0.9805, 0.9532,\n                      0.9596, 0.9459, 0.9615, 1.0006, 0.9495, 0.9503, 0.9809, 0.9946, 0.9711,\n                      0.9747, 0.9663, 0.9565, 0.9702, 0.9744, 0.9638, 0.9725, 0.9726, 0.9660,\n                      0.9129], dtype=torch.float64)),\n             ('6.4.convs.1.1.bias',\n              tensor([ 0.0017, -0.0114, -0.0090, -0.0182, -0.0016, -0.0167,  0.0117,  0.0108,\n                       0.0028, -0.0185,  0.0053, -0.0097, -0.0044, -0.0147, -0.0088, -0.0060,\n                       0.0046,  0.0070, -0.0080, -0.0199, -0.0267,  0.0001, -0.0241,  0.0119,\n                       0.0002, -0.0099, -0.0102, -0.0166, -0.0084, -0.0016, -0.0240,  0.0022,\n                       0.0062, -0.0156,  0.0039, -0.0083,  0.0126, -0.0183,  0.0080, -0.0134,\n                       0.0148, -0.0238,  0.0015,  0.0038, -0.0218, -0.0044, -0.0049, -0.0166,\n                       0.0053, -0.0194, -0.0119, -0.0195,  0.0126, -0.0081,  0.0068, -0.0047,\n                      -0.0144, -0.0002,  0.0217, -0.0168, -0.0189,  0.0076, -0.0035, -0.0436],\n                     dtype=torch.float64)),\n             ('6.4.convs.1.1.running_mean',\n              tensor([ 0.0520, -0.3497,  0.2465,  0.5670, -0.1592,  1.0190, -0.3990, -1.3045,\n                       0.5461, -0.5007, -0.1933,  0.1321,  0.5867, -0.3740,  0.4004, -0.4818,\n                      -0.0083, -0.3740,  0.0236,  0.1452, -0.0501, -0.1232,  0.2434, -0.1064,\n                      -0.5605, -0.7148, -0.4565, -0.5675,  0.3973, -0.2842,  0.3199,  0.2826,\n                      -0.0827,  0.0302, -0.6990,  0.4517,  0.5122, -0.5620, -0.7103, -0.4283,\n                      -0.5415,  0.4392, -1.0027,  0.7853, -0.1548,  0.1258, -0.8138,  0.0936,\n                      -0.8065,  0.1128, -0.0932, -0.3343, -0.7423,  0.4191,  0.7258, -0.4051,\n                       0.2153, -0.1921, -0.2375,  0.0686,  0.2159,  0.1159, -0.0996, -0.1184],\n                     dtype=torch.float64)),\n             ('6.4.convs.1.1.running_var',\n              tensor([1.0626, 0.5801, 0.6503, 0.9425, 0.4242, 0.5902, 0.4234, 0.8099, 0.6436,\n                      0.3924, 0.4306, 0.4521, 0.7153, 0.5366, 0.4428, 0.5372, 0.4932, 0.9594,\n                      0.7078, 0.6520, 0.6870, 0.6246, 0.6585, 0.7185, 0.5546, 0.7186, 0.8713,\n                      0.6144, 0.9297, 0.5674, 0.7979, 0.5965, 0.5661, 0.5799, 0.5042, 0.5999,\n                      0.5258, 0.5599, 0.5901, 0.6729, 0.9104, 0.7179, 1.1477, 0.5352, 0.8912,\n                      0.5603, 0.7482, 0.5773, 0.5991, 0.5261, 0.6770, 0.4682, 0.5949, 0.6587,\n                      0.6382, 0.4620, 0.4947, 0.5200, 0.5374, 0.5990, 0.6383, 0.5406, 0.4891,\n                      0.5751], dtype=torch.float64)),\n             ('6.4.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.4.convs.2.0.weight',\n              tensor([[[-0.0250],\n                       [-0.1015],\n                       [ 0.0820],\n                       ...,\n                       [ 0.0650],\n                       [-0.0890],\n                       [-0.0026]],\n              \n                      [[ 0.1290],\n                       [-0.2047],\n                       [ 0.0978],\n                       ...,\n                       [ 0.1049],\n                       [ 0.0355],\n                       [-0.0473]],\n              \n                      [[-0.0280],\n                       [ 0.0822],\n                       [ 0.1379],\n                       ...,\n                       [ 0.3214],\n                       [ 0.1775],\n                       [-0.0158]],\n              \n                      ...,\n              \n                      [[ 0.0762],\n                       [-0.0503],\n                       [-0.0580],\n                       ...,\n                       [ 0.0658],\n                       [-0.1374],\n                       [-0.0721]],\n              \n                      [[ 0.0442],\n                       [-0.1015],\n                       [-0.0833],\n                       ...,\n                       [ 0.0022],\n                       [ 0.0476],\n                       [ 0.0433]],\n              \n                      [[ 0.0341],\n                       [ 0.0254],\n                       [ 0.0146],\n                       ...,\n                       [-0.0757],\n                       [ 0.0988],\n                       [-0.2498]]], dtype=torch.float64)),\n             ('6.4.convs.2.1.weight',\n              tensor([-0.0011, -0.0479, -0.0201,  0.0160,  0.0068, -0.0148,  0.0082, -0.0030,\n                      -0.0180,  0.0132, -0.0259,  0.0088, -0.0107, -0.0015,  0.0107,  0.0286,\n                      -0.0261,  0.0115,  0.0083, -0.0051, -0.0113, -0.0046,  0.0135,  0.0067,\n                      -0.0220, -0.0050,  0.0052, -0.0052,  0.0071, -0.0080,  0.0073, -0.0215,\n                      -0.0235, -0.0184,  0.0125,  0.0064,  0.0063,  0.0332, -0.0236, -0.0033,\n                      -0.0119, -0.0168,  0.0142,  0.0036, -0.0057, -0.0072, -0.0131,  0.0179,\n                      -0.0249, -0.0043,  0.0108, -0.0013,  0.0071,  0.0055, -0.0088, -0.0206,\n                      -0.0092,  0.0001, -0.0202,  0.0064,  0.0071, -0.0079, -0.0008, -0.0016,\n                      -0.0124, -0.0144,  0.0160, -0.0350,  0.0270, -0.0359,  0.0041, -0.0147,\n                       0.0056, -0.0142,  0.0213, -0.0318,  0.0168,  0.0263, -0.0007,  0.0293,\n                       0.0070, -0.0078,  0.0083,  0.0019, -0.0058,  0.0052,  0.0215, -0.0028,\n                       0.0479, -0.0037, -0.0111,  0.0345, -0.0226,  0.0209, -0.0114,  0.0079,\n                       0.0301, -0.0178, -0.0196,  0.0275, -0.0087,  0.0043, -0.0014, -0.0294,\n                      -0.0147,  0.0415,  0.0185,  0.0046,  0.0017,  0.0207, -0.0186,  0.0057,\n                      -0.0069,  0.0448,  0.0028,  0.0037, -0.0237,  0.0362, -0.0187,  0.0092,\n                       0.0193, -0.0005, -0.0075,  0.0195,  0.0235,  0.0443,  0.0180, -0.0195,\n                       0.0217,  0.0087,  0.0118,  0.0253,  0.0193,  0.0175, -0.0098,  0.0027,\n                      -0.0065,  0.0210, -0.0177,  0.0076, -0.0089, -0.0003,  0.0013, -0.0146,\n                       0.0088, -0.0106, -0.0135,  0.0165,  0.0004, -0.0232,  0.0007,  0.0097,\n                      -0.0303,  0.0294, -0.0061,  0.0088,  0.0110,  0.0155, -0.0024,  0.0074,\n                       0.0199, -0.0048,  0.0156,  0.0182, -0.0261, -0.0236, -0.0208,  0.0117,\n                      -0.0065, -0.0118, -0.0203, -0.0021,  0.0209,  0.0124, -0.0115, -0.0097,\n                       0.0209, -0.0109,  0.0285, -0.0239, -0.0137,  0.0038, -0.0142,  0.0075,\n                       0.0060,  0.0348,  0.0179, -0.0271, -0.0088, -0.0101,  0.0257, -0.0072,\n                       0.0388, -0.0050,  0.0307,  0.0232, -0.0081,  0.0033, -0.0053, -0.0152,\n                       0.0019, -0.0301,  0.0160,  0.0028, -0.0024,  0.0135, -0.0110,  0.0100,\n                      -0.0009,  0.0225, -0.0051, -0.0140, -0.0033, -0.0232, -0.0243, -0.0016,\n                      -0.0181,  0.0059, -0.0318,  0.0182,  0.0135,  0.0002, -0.0116, -0.0438,\n                       0.0155, -0.0041,  0.0100,  0.0062, -0.0251, -0.0057,  0.0244, -0.0029,\n                       0.0138,  0.0174, -0.0226,  0.0022,  0.0054,  0.0005, -0.0127, -0.0399,\n                       0.0104,  0.0035, -0.0016, -0.0032,  0.0158,  0.0068, -0.0008,  0.0151,\n                      -0.0097, -0.0069, -0.0213, -0.0070, -0.0096, -0.0086,  0.0038,  0.0115],\n                     dtype=torch.float64)),\n             ('6.4.convs.2.1.bias',\n              tensor([-1.8370e-03, -2.6875e-03,  1.5379e-02,  1.2035e-02,  4.9408e-03,\n                       1.2134e-03,  1.6583e-02,  1.2081e-03,  9.5634e-03,  2.0832e-02,\n                       1.2867e-02, -1.0210e-02,  1.0119e-02, -6.8539e-03,  4.7702e-03,\n                       5.3555e-03,  1.9853e-02, -3.0166e-03,  1.4356e-02, -8.5206e-03,\n                      -2.6003e-03,  3.7214e-03,  1.6397e-03,  7.2353e-03, -6.6857e-03,\n                      -1.4696e-02,  5.3495e-03,  1.0900e-02,  1.4468e-03, -9.7419e-04,\n                       4.3466e-03,  1.0235e-02, -7.8811e-03,  1.6031e-02,  1.2407e-02,\n                       6.7733e-03, -7.6309e-04,  2.3151e-02,  9.3699e-03,  1.2561e-02,\n                       8.4103e-04,  2.2984e-02, -1.0065e-02,  1.0576e-03,  5.2806e-03,\n                      -1.0564e-02,  7.5361e-03,  3.1138e-03, -1.1481e-02,  1.0546e-02,\n                       8.3467e-03,  1.1713e-02,  9.0517e-03,  1.3792e-02,  5.4382e-03,\n                       9.8816e-03,  7.3442e-03,  2.7423e-03,  9.5493e-03,  5.6132e-03,\n                      -3.9700e-03,  2.7289e-03, -1.9820e-03,  9.1470e-03, -4.1751e-03,\n                       1.5072e-02, -1.1553e-02,  1.3178e-02, -3.0353e-05, -1.1024e-02,\n                       3.0832e-03,  2.1578e-03,  4.1882e-03, -7.9632e-03,  1.4675e-02,\n                       9.4079e-03,  5.2735e-04,  2.4768e-03,  4.5680e-03,  6.0121e-03,\n                       1.0969e-02, -5.3145e-03,  6.8254e-03,  3.7663e-03, -1.8369e-03,\n                       1.4304e-02,  1.6385e-03,  1.0812e-03,  9.0085e-03,  8.3380e-03,\n                      -5.8234e-04,  2.3383e-02,  1.7966e-02, -1.7059e-03,  4.8624e-03,\n                      -1.4463e-02,  5.6700e-03, -1.6406e-03,  1.7180e-02,  5.1274e-03,\n                       2.4426e-02,  2.9203e-03, -2.1263e-03,  2.7024e-04,  1.5335e-02,\n                      -1.0046e-04, -5.4698e-04,  3.4165e-03,  4.5562e-03,  6.4173e-03,\n                      -7.2215e-03, -7.4533e-03,  3.0880e-03,  1.6115e-02,  1.1805e-02,\n                       6.7155e-03,  1.1963e-02,  3.0259e-03,  2.8999e-03, -1.5330e-02,\n                       2.2357e-03,  7.7554e-03,  2.1973e-03, -3.1272e-03, -8.5270e-03,\n                       1.3134e-02,  1.5939e-02,  4.8649e-03, -8.4191e-04,  1.5522e-02,\n                       4.1832e-03,  1.8042e-02,  1.5133e-02,  8.3510e-03,  1.7760e-02,\n                      -7.8655e-03,  1.5849e-02,  7.6290e-03,  1.6681e-02,  1.1034e-02,\n                       1.9224e-03, -2.6729e-03,  1.4353e-02,  7.9760e-03, -1.1313e-02,\n                       8.1680e-03,  1.1053e-03, -2.6305e-03,  1.0372e-02,  9.1032e-03,\n                       4.3696e-03,  1.2062e-02,  3.6035e-03,  1.5166e-02,  1.4700e-02,\n                       8.5381e-03,  1.7248e-04,  7.2469e-03, -4.0253e-03, -1.0292e-02,\n                       1.3818e-03, -6.4041e-03,  1.9709e-03,  1.3232e-02,  1.2248e-02,\n                       1.2898e-03, -6.7087e-03,  8.6962e-03,  4.5678e-04,  1.6007e-02,\n                       5.1131e-03,  9.2164e-03,  1.3119e-02,  9.9323e-03, -1.4023e-02,\n                       6.8301e-03,  2.5819e-05,  1.1927e-02,  5.3145e-03,  5.7587e-03,\n                      -2.4298e-03,  1.0922e-02, -8.6950e-03, -1.0278e-02,  1.8226e-02,\n                       9.3580e-03,  1.4619e-02,  1.5217e-02, -1.8821e-03,  2.8029e-03,\n                       6.2048e-03,  1.0225e-03,  1.4009e-02, -9.7795e-03,  8.8851e-03,\n                       8.1547e-03, -2.1327e-03,  1.6713e-02,  1.0295e-02, -1.1045e-03,\n                       5.1762e-03,  1.5567e-02,  2.0571e-02,  1.7335e-02,  6.9624e-04,\n                      -3.5247e-03,  1.3890e-02, -3.6876e-03,  8.4294e-03,  5.8960e-03,\n                       2.0546e-03,  1.2638e-02,  1.3217e-02,  6.4027e-03,  1.7988e-02,\n                       4.1882e-03,  4.2172e-03, -3.0074e-03,  5.6205e-03, -4.0968e-04,\n                      -1.4860e-02,  2.7172e-03,  6.6953e-03,  2.4314e-02, -2.0668e-03,\n                       2.1919e-03, -2.8550e-03,  1.8016e-03, -1.4178e-02,  1.4157e-02,\n                       1.4764e-02, -5.3188e-04,  1.0742e-02,  1.1818e-02,  4.9984e-03,\n                       5.8159e-03,  7.7722e-03, -5.2791e-03,  1.0704e-02,  1.1160e-02,\n                       2.8725e-03,  4.0150e-03,  4.6042e-03,  7.7357e-03,  2.0129e-03,\n                       1.5003e-02,  9.2370e-04,  9.8652e-03,  2.9754e-03, -9.1533e-03,\n                       1.6761e-02,  1.6266e-02,  1.9418e-02,  1.7963e-02,  1.1984e-02,\n                       9.2275e-03], dtype=torch.float64)),\n             ('6.4.convs.2.1.running_mean',\n              tensor([-0.3974,  0.1077, -0.2802, -0.1166, -0.3220, -0.3529,  0.2312,  0.7063,\n                      -0.2523,  0.1950,  0.1701, -0.2574,  0.6776,  0.4325,  0.1331, -0.0290,\n                       0.5061,  0.3579, -0.1989,  0.7621, -0.3798,  0.2630, -0.0853,  0.4532,\n                      -0.0416, -0.3358,  0.5746, -0.0730,  0.0841,  0.1087, -0.5156,  0.1337,\n                      -0.2527,  0.1759,  0.3452, -0.7231,  0.0842,  0.1331,  0.2891,  0.4821,\n                       0.7246,  0.2932, -0.3362,  0.4722,  0.0842,  0.1145, -0.7889, -0.0069,\n                      -0.1401,  0.6070,  0.5296, -0.4861,  0.0054, -0.7023,  0.2118, -0.3339,\n                       0.9015,  1.0911, -0.5373,  0.6277, -0.0784,  0.3673,  0.1592,  0.0747,\n                       0.3963, -0.3667,  0.6330,  0.0582, -0.1076, -0.1507, -0.0446,  0.6002,\n                      -0.3472, -0.1630,  0.7214, -0.5755, -0.2325,  0.0797, -0.0833,  0.0694,\n                       0.1554,  0.1512, -0.4663, -1.1767,  0.1685,  0.2629, -0.4775, -0.2025,\n                       0.0101, -0.1029, -0.4431,  0.0650,  0.9164,  0.2291,  0.6091, -0.2324,\n                      -0.0886,  0.0518, -0.0926,  0.0344,  0.1858,  0.0606, -0.0819,  0.0348,\n                       0.0800, -0.2929, -0.2003,  0.1831, -0.1717,  0.0143,  0.3365,  0.5760,\n                      -0.2220, -0.1969,  0.2613, -0.0582,  0.4463,  0.1057,  0.1847,  0.3174,\n                      -0.1975,  0.2046,  0.5035, -0.4142, -0.4236, -0.2447, -0.1490,  0.3458,\n                      -0.2327,  0.1259,  0.1543, -0.0733,  0.0867,  0.3355, -0.2515, -0.0154,\n                       0.5075,  0.0990, -0.1883,  0.0694,  0.8120, -0.1108,  0.0098, -0.4889,\n                      -0.0717,  0.5576, -0.3773,  0.6690, -0.3063, -0.3096,  0.2689, -0.3294,\n                       0.2039, -0.5384, -0.0503, -0.0396, -0.2377, -0.1569, -0.1366,  0.3667,\n                       0.0411,  0.3711,  0.0060,  0.5850, -0.6389, -0.0365, -0.5077, -0.1886,\n                      -0.3189,  0.8862, -0.3756,  0.1034,  0.1739, -0.0364,  0.3530, -0.6078,\n                      -0.1116, -0.1238, -0.7973,  0.6964,  0.1805, -0.6911, -0.0254,  0.2004,\n                       0.1116, -0.5385, -0.0997, -0.0338,  0.1931, -0.2240, -0.6057,  0.4758,\n                      -0.0143, -0.7082,  0.7428, -0.1877,  0.0836, -0.6641,  0.1989, -0.7697,\n                       0.0991, -0.0792, -0.0984,  0.2259,  0.2277, -0.1197,  0.2570, -0.1575,\n                       0.1485, -0.5174, -0.3400,  0.0772, -0.2050,  0.3241,  0.0155,  0.0784,\n                      -0.3682, -0.2941,  0.5220, -0.2272, -0.0152,  0.1009,  0.1004,  0.0857,\n                      -0.0244, -0.2347,  0.5105,  0.1286,  0.4996, -0.7752, -0.2557,  0.4114,\n                      -0.3314,  0.0551, -0.2931, -0.0989,  0.2606,  0.0200, -0.6242, -0.3107,\n                       0.3429,  0.2048,  0.9197, -0.0703, -0.1459,  0.1527, -0.0396,  0.3572,\n                       0.0118,  0.7326, -0.1131, -0.0231,  0.0151,  0.5911, -0.1402, -0.6342],\n                     dtype=torch.float64)),\n             ('6.4.convs.2.1.running_var',\n              tensor([0.1472, 0.3486, 0.3716, 0.4395, 0.2278, 0.2498, 0.3794, 0.3718, 0.2803,\n                      0.5386, 0.3291, 0.2888, 0.2754, 0.3337, 0.4292, 0.8511, 0.3940, 0.1962,\n                      0.2334, 0.4054, 0.2737, 0.4964, 0.3211, 0.3978, 0.5242, 0.2952, 0.3626,\n                      0.1308, 0.1969, 0.3664, 0.4631, 0.2625, 0.1587, 0.3955, 0.4356, 0.3696,\n                      0.2841, 0.2831, 0.3106, 0.4150, 0.5758, 0.4147, 0.1488, 0.3322, 0.5514,\n                      0.3669, 0.3603, 0.2739, 0.6134, 0.3705, 0.2440, 0.3284, 0.2875, 0.3740,\n                      0.4224, 0.5076, 0.3784, 0.5399, 0.4553, 0.4227, 0.0906, 0.2788, 0.1779,\n                      0.1031, 0.5642, 0.3690, 0.5450, 0.5527, 0.3077, 0.5021, 0.3690, 0.3127,\n                      0.3319, 0.4763, 0.5411, 0.4104, 0.5561, 0.2190, 0.4986, 0.4855, 0.2188,\n                      0.1709, 0.5330, 0.5350, 0.2796, 0.5786, 0.2239, 0.1199, 0.5622, 0.2679,\n                      0.5376, 0.3589, 0.3462, 0.2620, 0.4688, 0.1897, 0.7321, 0.3546, 0.2433,\n                      0.3423, 0.4263, 0.2544, 0.1348, 0.3485, 0.2557, 0.4167, 0.3867, 0.3730,\n                      0.1049, 0.2623, 0.2799, 0.3925, 0.4872, 0.4792, 0.2730, 0.4597, 0.5872,\n                      0.4667, 0.2628, 0.3703, 0.1727, 0.4204, 0.4452, 0.2528, 0.3729, 0.4062,\n                      0.2096, 0.3934, 0.2032, 0.2258, 0.1944, 0.3173, 0.6244, 0.2070, 0.1861,\n                      0.1173, 0.1743, 0.3277, 0.4274, 0.1691, 0.3133, 0.1068, 0.1015, 0.1829,\n                      0.1817, 0.3939, 0.2331, 0.2442, 0.1533, 0.4312, 0.5259, 0.3514, 0.4361,\n                      0.5202, 0.1493, 0.2379, 0.2297, 0.2928, 0.4470, 0.2550, 0.4084, 0.2241,\n                      0.3954, 0.5241, 0.4574, 0.5664, 0.4213, 0.2277, 0.1479, 0.6103, 0.2624,\n                      0.0888, 0.3613, 0.1309, 0.3847, 0.7010, 0.2637, 0.1558, 0.4992, 0.4508,\n                      0.3919, 0.1336, 0.4430, 0.3949, 0.2622, 0.3572, 0.1893, 0.2983, 0.2198,\n                      0.2234, 0.4277, 0.3513, 0.3864, 0.5135, 0.3570, 0.5219, 0.3487, 0.3159,\n                      0.4473, 0.4838, 0.2142, 0.3459, 0.3073, 0.2444, 0.2054, 0.4050, 0.3725,\n                      0.0875, 0.1595, 0.4734, 0.1919, 0.2168, 0.1162, 0.5572, 0.3566, 0.1770,\n                      0.4158, 0.0842, 0.5791, 0.4591, 0.2192, 0.2521, 0.1524, 0.3314, 0.6056,\n                      0.2725, 0.3667, 0.0607, 0.4667, 0.5683, 0.3986, 0.4278, 0.4730, 0.3376,\n                      0.2636, 0.3059, 0.1421, 0.1268, 0.5653, 0.4599, 0.3672, 0.2235, 0.2915,\n                      0.1495, 0.2015, 0.2248, 0.2086, 0.4980, 0.2256, 0.3493, 0.4005, 0.3727,\n                      0.2864, 0.3785, 0.1070, 0.3987], dtype=torch.float64)),\n             ('6.4.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.4.convpath.0.0.0.weight',\n              tensor([[[ 0.1280],\n                       [-0.1035],\n                       [-0.1267],\n                       ...,\n                       [ 0.0234],\n                       [-0.1324],\n                       [-0.0155]],\n              \n                      [[-0.0662],\n                       [ 0.0655],\n                       [-0.0418],\n                       ...,\n                       [ 0.0477],\n                       [ 0.0338],\n                       [-0.0227]],\n              \n                      [[-0.0016],\n                       [-0.2553],\n                       [ 0.1632],\n                       ...,\n                       [ 0.0109],\n                       [ 0.0203],\n                       [-0.0257]],\n              \n                      ...,\n              \n                      [[-0.1318],\n                       [-0.0291],\n                       [-0.0040],\n                       ...,\n                       [ 0.1129],\n                       [ 0.0471],\n                       [ 0.1508]],\n              \n                      [[ 0.0143],\n                       [-0.0080],\n                       [-0.2073],\n                       ...,\n                       [ 0.0025],\n                       [-0.0724],\n                       [-0.0636]],\n              \n                      [[ 0.0787],\n                       [ 0.0510],\n                       [ 0.0584],\n                       ...,\n                       [ 0.0343],\n                       [-0.0017],\n                       [ 0.1709]]], dtype=torch.float64)),\n             ('6.4.convpath.0.0.1.weight',\n              tensor([0.9807, 0.9721, 0.9847, 0.9757, 0.9631, 0.9427, 0.9723, 0.9878, 0.9873,\n                      0.9670, 0.9786, 0.9806, 0.9669, 0.9876, 0.9624, 0.9503, 0.9845, 0.9650,\n                      0.9801, 0.9723, 0.9717, 0.9938, 0.9846, 0.9574, 0.9818, 0.9801, 0.9945,\n                      0.9848, 0.9668, 0.9754, 0.9716, 0.9662, 0.9553, 0.9737, 0.9539, 0.9802,\n                      0.9842, 0.9895, 0.9575, 0.9840, 0.9647, 0.9551, 0.9717, 0.9806, 0.9823,\n                      0.9882, 0.9692, 1.0054, 0.9572, 0.9526, 0.9741, 0.9717, 0.9626, 0.9683,\n                      0.9956, 0.9699, 0.9870, 0.9521, 0.9751, 0.9768, 0.9590, 0.9907, 0.9785,\n                      0.9806], dtype=torch.float64)),\n             ('6.4.convpath.0.0.1.bias',\n              tensor([ 0.0231,  0.0084,  0.0175,  0.0032, -0.0044,  0.0022,  0.0005,  0.0068,\n                       0.0294, -0.0039,  0.0139,  0.0146,  0.0021, -0.0112, -0.0075, -0.0183,\n                      -0.0057, -0.0030,  0.0052,  0.0185,  0.0066, -0.0033,  0.0077, -0.0028,\n                       0.0147,  0.0131,  0.0093,  0.0134, -0.0077,  0.0007,  0.0179, -0.0145,\n                      -0.0117,  0.0109,  0.0050, -0.0123,  0.0012,  0.0095,  0.0069,  0.0093,\n                      -0.0238, -0.0028,  0.0161,  0.0110,  0.0203, -0.0077,  0.0140,  0.0006,\n                       0.0025,  0.0003, -0.0101, -0.0079, -0.0035, -0.0043,  0.0112, -0.0049,\n                       0.0020, -0.0036,  0.0011,  0.0058, -0.0036,  0.0191, -0.0133,  0.0172],\n                     dtype=torch.float64)),\n             ('6.4.convpath.0.0.1.running_mean',\n              tensor([-0.4632,  0.1254, -0.2832,  0.2285, -0.4278,  0.2034,  0.6618,  0.1904,\n                       0.2264,  0.0017,  0.6837, -0.1792, -0.1299,  0.4395,  0.3017,  0.3805,\n                       0.2763, -0.6976, -0.4208, -0.2723, -0.7767, -0.2275, -0.5867,  0.3027,\n                       0.0678,  0.7659, -0.0750,  0.3878, -0.4447, -0.0967, -0.3339,  0.6166,\n                      -0.1603,  0.0918, -0.6660, -0.2460,  0.4202,  0.9156, -0.7886,  0.7088,\n                       0.3207, -0.8936,  0.0956, -0.4044, -0.0597,  0.7690,  0.3459, -0.0099,\n                       0.0109, -0.3409,  0.3994, -0.3050, -0.7988,  0.9873,  0.1096, -0.0741,\n                       0.0498, -0.3661, -0.3707, -0.0149, -0.6798,  0.0506,  0.0972,  0.2328],\n                     dtype=torch.float64)),\n             ('6.4.convpath.0.0.1.running_var',\n              tensor([0.3478, 0.2438, 0.2253, 0.1620, 0.1947, 0.6998, 0.4111, 0.2117, 0.1464,\n                      0.1023, 0.1456, 0.2223, 0.1159, 0.1351, 0.1883, 0.1088, 0.1631, 0.2100,\n                      0.1679, 0.1516, 0.4105, 0.1724, 0.3009, 0.2516, 0.1694, 0.1956, 0.1129,\n                      0.2155, 0.1152, 0.1496, 0.2730, 0.2059, 0.1170, 0.2246, 0.7556, 0.1561,\n                      0.4204, 0.3233, 0.2207, 0.2742, 0.1411, 0.1675, 0.2316, 0.0967, 0.3162,\n                      0.4024, 0.5191, 0.1587, 0.1848, 0.2976, 0.8460, 0.1420, 0.3716, 0.3126,\n                      0.1283, 0.2314, 0.1193, 0.2613, 0.2010, 0.1078, 0.1955, 0.2995, 0.1385,\n                      0.2758], dtype=torch.float64)),\n             ('6.4.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.4.convpath.0.1.0.weight',\n              tensor([[[-0.1009,  0.0396, -0.0098,  0.0778,  0.0400],\n                       [ 0.0229, -0.0880, -0.0927, -0.0935,  0.0848],\n                       [-0.0767,  0.0681,  0.0920, -0.1410, -0.0927],\n                       ...,\n                       [-0.0512,  0.1677,  0.0994, -0.0141,  0.0300],\n                       [-0.0760, -0.0037, -0.0808, -0.0341,  0.1678],\n                       [-0.1196, -0.0016, -0.1586,  0.0782,  0.0169]],\n              \n                      [[ 0.0108,  0.0159,  0.0184, -0.0552, -0.1591],\n                       [-0.0429,  0.0586, -0.0309,  0.0274,  0.0171],\n                       [ 0.0439,  0.0376,  0.0414, -0.0188,  0.0524],\n                       ...,\n                       [ 0.0145, -0.0361,  0.0838, -0.1250,  0.0598],\n                       [-0.0951, -0.1479, -0.0316, -0.0466, -0.0092],\n                       [-0.0773,  0.0057, -0.0394,  0.0655, -0.0480]],\n              \n                      [[ 0.0376, -0.0342,  0.0334, -0.0860,  0.0487],\n                       [ 0.0154, -0.0532,  0.0683,  0.0355, -0.0254],\n                       [ 0.0809,  0.0056,  0.0085,  0.1268, -0.1113],\n                       ...,\n                       [-0.0021,  0.0458, -0.0546, -0.0760,  0.1382],\n                       [-0.0579,  0.0031,  0.0618,  0.1125, -0.0129],\n                       [ 0.0688, -0.1407,  0.0624, -0.0104,  0.1265]],\n              \n                      ...,\n              \n                      [[ 0.0013,  0.0037,  0.0856,  0.1482, -0.0292],\n                       [-0.0881, -0.0076, -0.1153,  0.0297, -0.1292],\n                       [ 0.0674, -0.0180,  0.0214,  0.0931,  0.1507],\n                       ...,\n                       [-0.1210,  0.0269, -0.0213,  0.0953, -0.1508],\n                       [ 0.0710, -0.0595, -0.0486, -0.0358,  0.0326],\n                       [ 0.0008,  0.0471, -0.0873,  0.1042, -0.0103]],\n              \n                      [[ 0.0133, -0.1807, -0.0205, -0.0349, -0.0361],\n                       [ 0.0168, -0.0922, -0.0075, -0.0230, -0.0077],\n                       [-0.1613, -0.0623,  0.1027, -0.0887, -0.0915],\n                       ...,\n                       [ 0.1921, -0.0446, -0.0346, -0.0087, -0.1432],\n                       [ 0.0472,  0.0879,  0.0978, -0.1704, -0.0623],\n                       [ 0.1263,  0.0488, -0.0005, -0.1189, -0.0551]],\n              \n                      [[-0.0630, -0.0381, -0.0110, -0.0004, -0.1338],\n                       [ 0.0687,  0.0397,  0.1359, -0.0807, -0.0480],\n                       [-0.1538,  0.0459, -0.1119, -0.1158, -0.0047],\n                       ...,\n                       [ 0.0625,  0.0423, -0.1700, -0.1070,  0.0294],\n                       [-0.1350,  0.0003,  0.0328,  0.0574, -0.0229],\n                       [-0.0210, -0.0804,  0.0550, -0.0938,  0.0052]]], dtype=torch.float64)),\n             ('6.4.convpath.0.1.1.weight',\n              tensor([0.9490, 0.9618, 0.9643, 0.9565, 0.9953, 0.9524, 0.9949, 0.9843, 0.9873,\n                      0.9507, 0.9973, 0.9819, 0.9750, 0.9403, 0.9757, 1.0033, 0.9857, 0.9775,\n                      0.9479, 0.9468, 0.9538, 0.9975, 0.9537, 0.9758, 0.9871, 0.9519, 0.9517,\n                      0.9497, 0.9672, 0.9589, 0.9285, 0.9483, 0.9615, 0.9537, 0.9729, 0.9673,\n                      1.0058, 0.9735, 1.0046, 0.9411, 0.9842, 0.9448, 0.9451, 0.9805, 0.9532,\n                      0.9596, 0.9459, 0.9615, 1.0006, 0.9495, 0.9503, 0.9809, 0.9946, 0.9711,\n                      0.9747, 0.9663, 0.9565, 0.9702, 0.9744, 0.9638, 0.9725, 0.9726, 0.9660,\n                      0.9129], dtype=torch.float64)),\n             ('6.4.convpath.0.1.1.bias',\n              tensor([ 0.0017, -0.0114, -0.0090, -0.0182, -0.0016, -0.0167,  0.0117,  0.0108,\n                       0.0028, -0.0185,  0.0053, -0.0097, -0.0044, -0.0147, -0.0088, -0.0060,\n                       0.0046,  0.0070, -0.0080, -0.0199, -0.0267,  0.0001, -0.0241,  0.0119,\n                       0.0002, -0.0099, -0.0102, -0.0166, -0.0084, -0.0016, -0.0240,  0.0022,\n                       0.0062, -0.0156,  0.0039, -0.0083,  0.0126, -0.0183,  0.0080, -0.0134,\n                       0.0148, -0.0238,  0.0015,  0.0038, -0.0218, -0.0044, -0.0049, -0.0166,\n                       0.0053, -0.0194, -0.0119, -0.0195,  0.0126, -0.0081,  0.0068, -0.0047,\n                      -0.0144, -0.0002,  0.0217, -0.0168, -0.0189,  0.0076, -0.0035, -0.0436],\n                     dtype=torch.float64)),\n             ('6.4.convpath.0.1.1.running_mean',\n              tensor([ 0.0520, -0.3497,  0.2465,  0.5670, -0.1592,  1.0190, -0.3990, -1.3045,\n                       0.5461, -0.5007, -0.1933,  0.1321,  0.5867, -0.3740,  0.4004, -0.4818,\n                      -0.0083, -0.3740,  0.0236,  0.1452, -0.0501, -0.1232,  0.2434, -0.1064,\n                      -0.5605, -0.7148, -0.4565, -0.5675,  0.3973, -0.2842,  0.3199,  0.2826,\n                      -0.0827,  0.0302, -0.6990,  0.4517,  0.5122, -0.5620, -0.7103, -0.4283,\n                      -0.5415,  0.4392, -1.0027,  0.7853, -0.1548,  0.1258, -0.8138,  0.0936,\n                      -0.8065,  0.1128, -0.0932, -0.3343, -0.7423,  0.4191,  0.7258, -0.4051,\n                       0.2153, -0.1921, -0.2375,  0.0686,  0.2159,  0.1159, -0.0996, -0.1184],\n                     dtype=torch.float64)),\n             ('6.4.convpath.0.1.1.running_var',\n              tensor([1.0626, 0.5801, 0.6503, 0.9425, 0.4242, 0.5902, 0.4234, 0.8099, 0.6436,\n                      0.3924, 0.4306, 0.4521, 0.7153, 0.5366, 0.4428, 0.5372, 0.4932, 0.9594,\n                      0.7078, 0.6520, 0.6870, 0.6246, 0.6585, 0.7185, 0.5546, 0.7186, 0.8713,\n                      0.6144, 0.9297, 0.5674, 0.7979, 0.5965, 0.5661, 0.5799, 0.5042, 0.5999,\n                      0.5258, 0.5599, 0.5901, 0.6729, 0.9104, 0.7179, 1.1477, 0.5352, 0.8912,\n                      0.5603, 0.7482, 0.5773, 0.5991, 0.5261, 0.6770, 0.4682, 0.5949, 0.6587,\n                      0.6382, 0.4620, 0.4947, 0.5200, 0.5374, 0.5990, 0.6383, 0.5406, 0.4891,\n                      0.5751], dtype=torch.float64)),\n             ('6.4.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.4.convpath.0.2.0.weight',\n              tensor([[[-0.0250],\n                       [-0.1015],\n                       [ 0.0820],\n                       ...,\n                       [ 0.0650],\n                       [-0.0890],\n                       [-0.0026]],\n              \n                      [[ 0.1290],\n                       [-0.2047],\n                       [ 0.0978],\n                       ...,\n                       [ 0.1049],\n                       [ 0.0355],\n                       [-0.0473]],\n              \n                      [[-0.0280],\n                       [ 0.0822],\n                       [ 0.1379],\n                       ...,\n                       [ 0.3214],\n                       [ 0.1775],\n                       [-0.0158]],\n              \n                      ...,\n              \n                      [[ 0.0762],\n                       [-0.0503],\n                       [-0.0580],\n                       ...,\n                       [ 0.0658],\n                       [-0.1374],\n                       [-0.0721]],\n              \n                      [[ 0.0442],\n                       [-0.1015],\n                       [-0.0833],\n                       ...,\n                       [ 0.0022],\n                       [ 0.0476],\n                       [ 0.0433]],\n              \n                      [[ 0.0341],\n                       [ 0.0254],\n                       [ 0.0146],\n                       ...,\n                       [-0.0757],\n                       [ 0.0988],\n                       [-0.2498]]], dtype=torch.float64)),\n             ('6.4.convpath.0.2.1.weight',\n              tensor([-0.0011, -0.0479, -0.0201,  0.0160,  0.0068, -0.0148,  0.0082, -0.0030,\n                      -0.0180,  0.0132, -0.0259,  0.0088, -0.0107, -0.0015,  0.0107,  0.0286,\n                      -0.0261,  0.0115,  0.0083, -0.0051, -0.0113, -0.0046,  0.0135,  0.0067,\n                      -0.0220, -0.0050,  0.0052, -0.0052,  0.0071, -0.0080,  0.0073, -0.0215,\n                      -0.0235, -0.0184,  0.0125,  0.0064,  0.0063,  0.0332, -0.0236, -0.0033,\n                      -0.0119, -0.0168,  0.0142,  0.0036, -0.0057, -0.0072, -0.0131,  0.0179,\n                      -0.0249, -0.0043,  0.0108, -0.0013,  0.0071,  0.0055, -0.0088, -0.0206,\n                      -0.0092,  0.0001, -0.0202,  0.0064,  0.0071, -0.0079, -0.0008, -0.0016,\n                      -0.0124, -0.0144,  0.0160, -0.0350,  0.0270, -0.0359,  0.0041, -0.0147,\n                       0.0056, -0.0142,  0.0213, -0.0318,  0.0168,  0.0263, -0.0007,  0.0293,\n                       0.0070, -0.0078,  0.0083,  0.0019, -0.0058,  0.0052,  0.0215, -0.0028,\n                       0.0479, -0.0037, -0.0111,  0.0345, -0.0226,  0.0209, -0.0114,  0.0079,\n                       0.0301, -0.0178, -0.0196,  0.0275, -0.0087,  0.0043, -0.0014, -0.0294,\n                      -0.0147,  0.0415,  0.0185,  0.0046,  0.0017,  0.0207, -0.0186,  0.0057,\n                      -0.0069,  0.0448,  0.0028,  0.0037, -0.0237,  0.0362, -0.0187,  0.0092,\n                       0.0193, -0.0005, -0.0075,  0.0195,  0.0235,  0.0443,  0.0180, -0.0195,\n                       0.0217,  0.0087,  0.0118,  0.0253,  0.0193,  0.0175, -0.0098,  0.0027,\n                      -0.0065,  0.0210, -0.0177,  0.0076, -0.0089, -0.0003,  0.0013, -0.0146,\n                       0.0088, -0.0106, -0.0135,  0.0165,  0.0004, -0.0232,  0.0007,  0.0097,\n                      -0.0303,  0.0294, -0.0061,  0.0088,  0.0110,  0.0155, -0.0024,  0.0074,\n                       0.0199, -0.0048,  0.0156,  0.0182, -0.0261, -0.0236, -0.0208,  0.0117,\n                      -0.0065, -0.0118, -0.0203, -0.0021,  0.0209,  0.0124, -0.0115, -0.0097,\n                       0.0209, -0.0109,  0.0285, -0.0239, -0.0137,  0.0038, -0.0142,  0.0075,\n                       0.0060,  0.0348,  0.0179, -0.0271, -0.0088, -0.0101,  0.0257, -0.0072,\n                       0.0388, -0.0050,  0.0307,  0.0232, -0.0081,  0.0033, -0.0053, -0.0152,\n                       0.0019, -0.0301,  0.0160,  0.0028, -0.0024,  0.0135, -0.0110,  0.0100,\n                      -0.0009,  0.0225, -0.0051, -0.0140, -0.0033, -0.0232, -0.0243, -0.0016,\n                      -0.0181,  0.0059, -0.0318,  0.0182,  0.0135,  0.0002, -0.0116, -0.0438,\n                       0.0155, -0.0041,  0.0100,  0.0062, -0.0251, -0.0057,  0.0244, -0.0029,\n                       0.0138,  0.0174, -0.0226,  0.0022,  0.0054,  0.0005, -0.0127, -0.0399,\n                       0.0104,  0.0035, -0.0016, -0.0032,  0.0158,  0.0068, -0.0008,  0.0151,\n                      -0.0097, -0.0069, -0.0213, -0.0070, -0.0096, -0.0086,  0.0038,  0.0115],\n                     dtype=torch.float64)),\n             ('6.4.convpath.0.2.1.bias',\n              tensor([-1.8370e-03, -2.6875e-03,  1.5379e-02,  1.2035e-02,  4.9408e-03,\n                       1.2134e-03,  1.6583e-02,  1.2081e-03,  9.5634e-03,  2.0832e-02,\n                       1.2867e-02, -1.0210e-02,  1.0119e-02, -6.8539e-03,  4.7702e-03,\n                       5.3555e-03,  1.9853e-02, -3.0166e-03,  1.4356e-02, -8.5206e-03,\n                      -2.6003e-03,  3.7214e-03,  1.6397e-03,  7.2353e-03, -6.6857e-03,\n                      -1.4696e-02,  5.3495e-03,  1.0900e-02,  1.4468e-03, -9.7419e-04,\n                       4.3466e-03,  1.0235e-02, -7.8811e-03,  1.6031e-02,  1.2407e-02,\n                       6.7733e-03, -7.6309e-04,  2.3151e-02,  9.3699e-03,  1.2561e-02,\n                       8.4103e-04,  2.2984e-02, -1.0065e-02,  1.0576e-03,  5.2806e-03,\n                      -1.0564e-02,  7.5361e-03,  3.1138e-03, -1.1481e-02,  1.0546e-02,\n                       8.3467e-03,  1.1713e-02,  9.0517e-03,  1.3792e-02,  5.4382e-03,\n                       9.8816e-03,  7.3442e-03,  2.7423e-03,  9.5493e-03,  5.6132e-03,\n                      -3.9700e-03,  2.7289e-03, -1.9820e-03,  9.1470e-03, -4.1751e-03,\n                       1.5072e-02, -1.1553e-02,  1.3178e-02, -3.0353e-05, -1.1024e-02,\n                       3.0832e-03,  2.1578e-03,  4.1882e-03, -7.9632e-03,  1.4675e-02,\n                       9.4079e-03,  5.2735e-04,  2.4768e-03,  4.5680e-03,  6.0121e-03,\n                       1.0969e-02, -5.3145e-03,  6.8254e-03,  3.7663e-03, -1.8369e-03,\n                       1.4304e-02,  1.6385e-03,  1.0812e-03,  9.0085e-03,  8.3380e-03,\n                      -5.8234e-04,  2.3383e-02,  1.7966e-02, -1.7059e-03,  4.8624e-03,\n                      -1.4463e-02,  5.6700e-03, -1.6406e-03,  1.7180e-02,  5.1274e-03,\n                       2.4426e-02,  2.9203e-03, -2.1263e-03,  2.7024e-04,  1.5335e-02,\n                      -1.0046e-04, -5.4698e-04,  3.4165e-03,  4.5562e-03,  6.4173e-03,\n                      -7.2215e-03, -7.4533e-03,  3.0880e-03,  1.6115e-02,  1.1805e-02,\n                       6.7155e-03,  1.1963e-02,  3.0259e-03,  2.8999e-03, -1.5330e-02,\n                       2.2357e-03,  7.7554e-03,  2.1973e-03, -3.1272e-03, -8.5270e-03,\n                       1.3134e-02,  1.5939e-02,  4.8649e-03, -8.4191e-04,  1.5522e-02,\n                       4.1832e-03,  1.8042e-02,  1.5133e-02,  8.3510e-03,  1.7760e-02,\n                      -7.8655e-03,  1.5849e-02,  7.6290e-03,  1.6681e-02,  1.1034e-02,\n                       1.9224e-03, -2.6729e-03,  1.4353e-02,  7.9760e-03, -1.1313e-02,\n                       8.1680e-03,  1.1053e-03, -2.6305e-03,  1.0372e-02,  9.1032e-03,\n                       4.3696e-03,  1.2062e-02,  3.6035e-03,  1.5166e-02,  1.4700e-02,\n                       8.5381e-03,  1.7248e-04,  7.2469e-03, -4.0253e-03, -1.0292e-02,\n                       1.3818e-03, -6.4041e-03,  1.9709e-03,  1.3232e-02,  1.2248e-02,\n                       1.2898e-03, -6.7087e-03,  8.6962e-03,  4.5678e-04,  1.6007e-02,\n                       5.1131e-03,  9.2164e-03,  1.3119e-02,  9.9323e-03, -1.4023e-02,\n                       6.8301e-03,  2.5819e-05,  1.1927e-02,  5.3145e-03,  5.7587e-03,\n                      -2.4298e-03,  1.0922e-02, -8.6950e-03, -1.0278e-02,  1.8226e-02,\n                       9.3580e-03,  1.4619e-02,  1.5217e-02, -1.8821e-03,  2.8029e-03,\n                       6.2048e-03,  1.0225e-03,  1.4009e-02, -9.7795e-03,  8.8851e-03,\n                       8.1547e-03, -2.1327e-03,  1.6713e-02,  1.0295e-02, -1.1045e-03,\n                       5.1762e-03,  1.5567e-02,  2.0571e-02,  1.7335e-02,  6.9624e-04,\n                      -3.5247e-03,  1.3890e-02, -3.6876e-03,  8.4294e-03,  5.8960e-03,\n                       2.0546e-03,  1.2638e-02,  1.3217e-02,  6.4027e-03,  1.7988e-02,\n                       4.1882e-03,  4.2172e-03, -3.0074e-03,  5.6205e-03, -4.0968e-04,\n                      -1.4860e-02,  2.7172e-03,  6.6953e-03,  2.4314e-02, -2.0668e-03,\n                       2.1919e-03, -2.8550e-03,  1.8016e-03, -1.4178e-02,  1.4157e-02,\n                       1.4764e-02, -5.3188e-04,  1.0742e-02,  1.1818e-02,  4.9984e-03,\n                       5.8159e-03,  7.7722e-03, -5.2791e-03,  1.0704e-02,  1.1160e-02,\n                       2.8725e-03,  4.0150e-03,  4.6042e-03,  7.7357e-03,  2.0129e-03,\n                       1.5003e-02,  9.2370e-04,  9.8652e-03,  2.9754e-03, -9.1533e-03,\n                       1.6761e-02,  1.6266e-02,  1.9418e-02,  1.7963e-02,  1.1984e-02,\n                       9.2275e-03], dtype=torch.float64)),\n             ('6.4.convpath.0.2.1.running_mean',\n              tensor([-0.3974,  0.1077, -0.2802, -0.1166, -0.3220, -0.3529,  0.2312,  0.7063,\n                      -0.2523,  0.1950,  0.1701, -0.2574,  0.6776,  0.4325,  0.1331, -0.0290,\n                       0.5061,  0.3579, -0.1989,  0.7621, -0.3798,  0.2630, -0.0853,  0.4532,\n                      -0.0416, -0.3358,  0.5746, -0.0730,  0.0841,  0.1087, -0.5156,  0.1337,\n                      -0.2527,  0.1759,  0.3452, -0.7231,  0.0842,  0.1331,  0.2891,  0.4821,\n                       0.7246,  0.2932, -0.3362,  0.4722,  0.0842,  0.1145, -0.7889, -0.0069,\n                      -0.1401,  0.6070,  0.5296, -0.4861,  0.0054, -0.7023,  0.2118, -0.3339,\n                       0.9015,  1.0911, -0.5373,  0.6277, -0.0784,  0.3673,  0.1592,  0.0747,\n                       0.3963, -0.3667,  0.6330,  0.0582, -0.1076, -0.1507, -0.0446,  0.6002,\n                      -0.3472, -0.1630,  0.7214, -0.5755, -0.2325,  0.0797, -0.0833,  0.0694,\n                       0.1554,  0.1512, -0.4663, -1.1767,  0.1685,  0.2629, -0.4775, -0.2025,\n                       0.0101, -0.1029, -0.4431,  0.0650,  0.9164,  0.2291,  0.6091, -0.2324,\n                      -0.0886,  0.0518, -0.0926,  0.0344,  0.1858,  0.0606, -0.0819,  0.0348,\n                       0.0800, -0.2929, -0.2003,  0.1831, -0.1717,  0.0143,  0.3365,  0.5760,\n                      -0.2220, -0.1969,  0.2613, -0.0582,  0.4463,  0.1057,  0.1847,  0.3174,\n                      -0.1975,  0.2046,  0.5035, -0.4142, -0.4236, -0.2447, -0.1490,  0.3458,\n                      -0.2327,  0.1259,  0.1543, -0.0733,  0.0867,  0.3355, -0.2515, -0.0154,\n                       0.5075,  0.0990, -0.1883,  0.0694,  0.8120, -0.1108,  0.0098, -0.4889,\n                      -0.0717,  0.5576, -0.3773,  0.6690, -0.3063, -0.3096,  0.2689, -0.3294,\n                       0.2039, -0.5384, -0.0503, -0.0396, -0.2377, -0.1569, -0.1366,  0.3667,\n                       0.0411,  0.3711,  0.0060,  0.5850, -0.6389, -0.0365, -0.5077, -0.1886,\n                      -0.3189,  0.8862, -0.3756,  0.1034,  0.1739, -0.0364,  0.3530, -0.6078,\n                      -0.1116, -0.1238, -0.7973,  0.6964,  0.1805, -0.6911, -0.0254,  0.2004,\n                       0.1116, -0.5385, -0.0997, -0.0338,  0.1931, -0.2240, -0.6057,  0.4758,\n                      -0.0143, -0.7082,  0.7428, -0.1877,  0.0836, -0.6641,  0.1989, -0.7697,\n                       0.0991, -0.0792, -0.0984,  0.2259,  0.2277, -0.1197,  0.2570, -0.1575,\n                       0.1485, -0.5174, -0.3400,  0.0772, -0.2050,  0.3241,  0.0155,  0.0784,\n                      -0.3682, -0.2941,  0.5220, -0.2272, -0.0152,  0.1009,  0.1004,  0.0857,\n                      -0.0244, -0.2347,  0.5105,  0.1286,  0.4996, -0.7752, -0.2557,  0.4114,\n                      -0.3314,  0.0551, -0.2931, -0.0989,  0.2606,  0.0200, -0.6242, -0.3107,\n                       0.3429,  0.2048,  0.9197, -0.0703, -0.1459,  0.1527, -0.0396,  0.3572,\n                       0.0118,  0.7326, -0.1131, -0.0231,  0.0151,  0.5911, -0.1402, -0.6342],\n                     dtype=torch.float64)),\n             ('6.4.convpath.0.2.1.running_var',\n              tensor([0.1472, 0.3486, 0.3716, 0.4395, 0.2278, 0.2498, 0.3794, 0.3718, 0.2803,\n                      0.5386, 0.3291, 0.2888, 0.2754, 0.3337, 0.4292, 0.8511, 0.3940, 0.1962,\n                      0.2334, 0.4054, 0.2737, 0.4964, 0.3211, 0.3978, 0.5242, 0.2952, 0.3626,\n                      0.1308, 0.1969, 0.3664, 0.4631, 0.2625, 0.1587, 0.3955, 0.4356, 0.3696,\n                      0.2841, 0.2831, 0.3106, 0.4150, 0.5758, 0.4147, 0.1488, 0.3322, 0.5514,\n                      0.3669, 0.3603, 0.2739, 0.6134, 0.3705, 0.2440, 0.3284, 0.2875, 0.3740,\n                      0.4224, 0.5076, 0.3784, 0.5399, 0.4553, 0.4227, 0.0906, 0.2788, 0.1779,\n                      0.1031, 0.5642, 0.3690, 0.5450, 0.5527, 0.3077, 0.5021, 0.3690, 0.3127,\n                      0.3319, 0.4763, 0.5411, 0.4104, 0.5561, 0.2190, 0.4986, 0.4855, 0.2188,\n                      0.1709, 0.5330, 0.5350, 0.2796, 0.5786, 0.2239, 0.1199, 0.5622, 0.2679,\n                      0.5376, 0.3589, 0.3462, 0.2620, 0.4688, 0.1897, 0.7321, 0.3546, 0.2433,\n                      0.3423, 0.4263, 0.2544, 0.1348, 0.3485, 0.2557, 0.4167, 0.3867, 0.3730,\n                      0.1049, 0.2623, 0.2799, 0.3925, 0.4872, 0.4792, 0.2730, 0.4597, 0.5872,\n                      0.4667, 0.2628, 0.3703, 0.1727, 0.4204, 0.4452, 0.2528, 0.3729, 0.4062,\n                      0.2096, 0.3934, 0.2032, 0.2258, 0.1944, 0.3173, 0.6244, 0.2070, 0.1861,\n                      0.1173, 0.1743, 0.3277, 0.4274, 0.1691, 0.3133, 0.1068, 0.1015, 0.1829,\n                      0.1817, 0.3939, 0.2331, 0.2442, 0.1533, 0.4312, 0.5259, 0.3514, 0.4361,\n                      0.5202, 0.1493, 0.2379, 0.2297, 0.2928, 0.4470, 0.2550, 0.4084, 0.2241,\n                      0.3954, 0.5241, 0.4574, 0.5664, 0.4213, 0.2277, 0.1479, 0.6103, 0.2624,\n                      0.0888, 0.3613, 0.1309, 0.3847, 0.7010, 0.2637, 0.1558, 0.4992, 0.4508,\n                      0.3919, 0.1336, 0.4430, 0.3949, 0.2622, 0.3572, 0.1893, 0.2983, 0.2198,\n                      0.2234, 0.4277, 0.3513, 0.3864, 0.5135, 0.3570, 0.5219, 0.3487, 0.3159,\n                      0.4473, 0.4838, 0.2142, 0.3459, 0.3073, 0.2444, 0.2054, 0.4050, 0.3725,\n                      0.0875, 0.1595, 0.4734, 0.1919, 0.2168, 0.1162, 0.5572, 0.3566, 0.1770,\n                      0.4158, 0.0842, 0.5791, 0.4591, 0.2192, 0.2521, 0.1524, 0.3314, 0.6056,\n                      0.2725, 0.3667, 0.0607, 0.4667, 0.5683, 0.3986, 0.4278, 0.4730, 0.3376,\n                      0.2636, 0.3059, 0.1421, 0.1268, 0.5653, 0.4599, 0.3672, 0.2235, 0.2915,\n                      0.1495, 0.2015, 0.2248, 0.2086, 0.4980, 0.2256, 0.3493, 0.4005, 0.3727,\n                      0.2864, 0.3785, 0.1070, 0.3987], dtype=torch.float64)),\n             ('6.4.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.5.convs.0.0.weight',\n              tensor([[[-0.0159],\n                       [ 0.0959],\n                       [ 0.0464],\n                       ...,\n                       [-0.0345],\n                       [-0.0361],\n                       [-0.0095]],\n              \n                      [[-0.0082],\n                       [-0.0873],\n                       [ 0.1419],\n                       ...,\n                       [ 0.0476],\n                       [ 0.1877],\n                       [-0.2293]],\n              \n                      [[ 0.0361],\n                       [-0.0449],\n                       [ 0.0379],\n                       ...,\n                       [-0.0941],\n                       [ 0.0118],\n                       [-0.0568]],\n              \n                      ...,\n              \n                      [[-0.1578],\n                       [-0.1014],\n                       [-0.0985],\n                       ...,\n                       [ 0.0263],\n                       [-0.0787],\n                       [-0.0804]],\n              \n                      [[ 0.0774],\n                       [-0.1321],\n                       [ 0.0956],\n                       ...,\n                       [-0.0218],\n                       [-0.0260],\n                       [-0.0188]],\n              \n                      [[ 0.0756],\n                       [-0.0247],\n                       [-0.0297],\n                       ...,\n                       [ 0.0865],\n                       [ 0.1219],\n                       [-0.0433]]], dtype=torch.float64)),\n             ('6.5.convs.0.1.weight',\n              tensor([0.9698, 0.9699, 0.9490, 0.9663, 0.9633, 0.9676, 0.9883, 0.9712, 0.9682,\n                      0.9791, 0.9616, 0.9649, 0.9606, 0.9528, 0.9664, 1.0263, 0.9790, 0.9987,\n                      0.9737, 0.9548, 0.9581, 0.9872, 1.0118, 0.9746, 0.9829, 0.9680, 0.9722,\n                      0.9765, 0.9793, 0.9638, 0.9805, 0.9741, 0.9685, 0.9728, 0.9462, 0.9585,\n                      0.9784, 0.9931, 0.9571, 0.9883, 0.9809, 0.9737, 0.9720, 0.9975, 0.9671,\n                      0.9515, 0.9789, 0.9919, 0.9769, 0.9802, 0.9564, 0.9679, 0.9916, 0.9757,\n                      0.9393, 0.9593, 0.9758, 0.9667, 0.9846, 0.9941, 1.0062, 0.9416, 0.9720,\n                      0.9351], dtype=torch.float64)),\n             ('6.5.convs.0.1.bias',\n              tensor([ 0.0029,  0.0080,  0.0072,  0.0055,  0.0078,  0.0029,  0.0119, -0.0023,\n                       0.0081,  0.0076,  0.0085,  0.0116,  0.0072, -0.0094, -0.0093,  0.0260,\n                      -0.0009,  0.0249,  0.0107, -0.0103, -0.0106,  0.0146,  0.0177, -0.0025,\n                      -0.0099, -0.0008, -0.0145,  0.0041,  0.0185, -0.0100,  0.0205, -0.0082,\n                       0.0224,  0.0084, -0.0231,  0.0111, -0.0076,  0.0167,  0.0065, -0.0097,\n                      -0.0050, -0.0082, -0.0003,  0.0200,  0.0069, -0.0307, -0.0131,  0.0215,\n                      -0.0119,  0.0096, -0.0119, -0.0108,  0.0265, -0.0052, -0.0056, -0.0024,\n                      -0.0097, -0.0155,  0.0093,  0.0177,  0.0003, -0.0025,  0.0004, -0.0243],\n                     dtype=torch.float64)),\n             ('6.5.convs.0.1.running_mean',\n              tensor([ 0.6289,  0.0562,  0.3036, -0.4673,  0.1196, -0.3437,  0.6448, -0.5550,\n                       0.0174,  0.2705, -1.0050, -0.4373, -0.0208,  1.0133,  0.3290, -0.3679,\n                       0.3730,  0.3480, -0.7210, -0.8384,  0.2152, -0.1795, -0.5973, -0.0460,\n                      -0.2679,  0.2367, -0.3585,  0.4268,  0.1556, -0.1696,  0.0507,  0.2252,\n                      -0.3387, -0.4349,  0.6709, -0.2964,  0.5138,  0.0876,  0.1874,  0.2398,\n                      -0.1897,  0.3736,  0.0685, -0.4554,  0.6861,  1.1062,  0.9155, -0.7769,\n                       0.6319,  0.0610,  0.8805, -0.5538,  0.1561,  0.3953, -0.5522,  0.3013,\n                       0.6577, -0.3548, -0.3693, -0.4058, -0.6066, -0.4633,  0.1709,  0.6844],\n                     dtype=torch.float64)),\n             ('6.5.convs.0.1.running_var',\n              tensor([0.1996, 0.2117, 0.3200, 0.2147, 0.1699, 0.1796, 0.3376, 0.1707, 0.1563,\n                      0.1256, 0.5637, 0.1581, 0.8390, 0.4758, 0.2161, 0.1157, 0.1487, 0.1251,\n                      0.2467, 0.3396, 0.5314, 0.1280, 0.0927, 0.1690, 0.1306, 0.4552, 0.0634,\n                      0.1722, 0.8017, 0.1737, 0.6113, 0.1162, 0.1827, 0.1961, 0.1242, 0.2585,\n                      0.9847, 0.5323, 0.3786, 0.1056, 0.2249, 0.5711, 0.2330, 0.1022, 0.2503,\n                      0.7001, 0.2299, 0.1263, 1.6804, 0.3714, 0.4519, 0.2089, 0.1189, 0.1122,\n                      0.1931, 0.2745, 0.3571, 0.1722, 0.3670, 0.1276, 0.1627, 0.3406, 0.1568,\n                      0.6619], dtype=torch.float64)),\n             ('6.5.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.5.convs.1.0.weight',\n              tensor([[[-0.0469,  0.0620,  0.0896, -0.0159, -0.0578],\n                       [-0.2007, -0.0320,  0.0168,  0.0656,  0.0493],\n                       [-0.0347,  0.0333,  0.0107, -0.0247, -0.0010],\n                       ...,\n                       [ 0.0094, -0.0280, -0.1716, -0.0484,  0.0938],\n                       [-0.0192,  0.0287,  0.0148,  0.0184,  0.0493],\n                       [ 0.1046,  0.0407, -0.0652,  0.0161, -0.0574]],\n              \n                      [[ 0.0285,  0.0449, -0.0022, -0.0601, -0.0216],\n                       [-0.0301,  0.0648, -0.0313,  0.0750,  0.0139],\n                       [ 0.1176, -0.0173, -0.1481, -0.0981, -0.0136],\n                       ...,\n                       [-0.1328, -0.0014, -0.0385,  0.0227,  0.0490],\n                       [-0.1500,  0.0246, -0.0173, -0.0551,  0.0272],\n                       [-0.0817,  0.0874, -0.0957,  0.0768,  0.1392]],\n              \n                      [[ 0.0350, -0.1329,  0.1100, -0.0393,  0.0047],\n                       [ 0.0572, -0.0430, -0.0515,  0.0057,  0.0666],\n                       [ 0.0749,  0.1899,  0.0320,  0.0132,  0.1371],\n                       ...,\n                       [ 0.0552, -0.0441, -0.1381,  0.0138,  0.0652],\n                       [ 0.0761, -0.0697,  0.0660, -0.0914, -0.0111],\n                       [-0.0612,  0.0737,  0.0346, -0.0860, -0.0321]],\n              \n                      ...,\n              \n                      [[-0.0534, -0.0471, -0.0225,  0.0921, -0.0139],\n                       [-0.1966,  0.1848, -0.0647, -0.1086, -0.0737],\n                       [ 0.1921, -0.0128,  0.0160, -0.0588, -0.1794],\n                       ...,\n                       [-0.0194, -0.0011,  0.0822, -0.1450, -0.0185],\n                       [-0.0848,  0.1030,  0.1008, -0.0007,  0.1412],\n                       [-0.0218,  0.0906, -0.0930,  0.0175,  0.0472]],\n              \n                      [[-0.0925,  0.0878,  0.0055, -0.0226, -0.0392],\n                       [-0.0791,  0.0301, -0.0399, -0.0821,  0.1582],\n                       [ 0.0780,  0.0089,  0.0555,  0.0292, -0.0327],\n                       ...,\n                       [-0.0304,  0.0652,  0.0845, -0.0118, -0.0925],\n                       [-0.0663,  0.0998, -0.0152, -0.0046, -0.1432],\n                       [-0.0433,  0.0106,  0.0961, -0.0291, -0.0429]],\n              \n                      [[-0.1359, -0.0836,  0.0608, -0.1169,  0.0488],\n                       [ 0.0846, -0.1247,  0.0931,  0.0566, -0.0603],\n                       [ 0.1391,  0.0735, -0.0932,  0.0539,  0.1275],\n                       ...,\n                       [-0.0027,  0.0183, -0.1515,  0.1310,  0.0492],\n                       [-0.0406,  0.1284,  0.0023,  0.0277,  0.0203],\n                       [-0.0465, -0.0169, -0.0413,  0.0532, -0.0258]]], dtype=torch.float64)),\n             ('6.5.convs.1.1.weight',\n              tensor([0.9866, 0.9551, 0.9633, 0.9620, 0.9669, 0.9623, 0.9590, 0.9494, 0.9760,\n                      0.9734, 0.9512, 0.9907, 0.9916, 0.9903, 0.9243, 0.9717, 0.9820, 0.9616,\n                      0.9932, 0.9839, 0.9753, 0.9651, 0.9564, 0.9578, 0.9592, 0.9431, 0.9829,\n                      0.9404, 0.9402, 1.0097, 0.9711, 0.9377, 0.9708, 0.9900, 0.9713, 0.9596,\n                      0.9559, 0.9666, 0.9822, 0.9464, 0.9589, 0.9544, 0.9912, 0.9783, 0.9498,\n                      0.9262, 0.9456, 0.9297, 0.9514, 0.9746, 0.9519, 0.9529, 0.9439, 0.9671,\n                      0.9795, 0.9525, 0.9734, 0.9753, 0.9439, 1.0004, 0.9893, 0.9808, 0.9160,\n                      1.0033], dtype=torch.float64)),\n             ('6.5.convs.1.1.bias',\n              tensor([-0.0061,  0.0062, -0.0270, -0.0155,  0.0010, -0.0245,  0.0085, -0.0290,\n                       0.0003, -0.0093, -0.0073,  0.0110,  0.0232,  0.0099, -0.0197, -0.0020,\n                       0.0104, -0.0030,  0.0203,  0.0014, -0.0121, -0.0055,  0.0065, -0.0006,\n                      -0.0025, -0.0159,  0.0053,  0.0080, -0.0139,  0.0193, -0.0151, -0.0301,\n                      -0.0219,  0.0183,  0.0124, -0.0274, -0.0250, -0.0095, -0.0007, -0.0188,\n                      -0.0151, -0.0059,  0.0176,  0.0097, -0.0027, -0.0105,  0.0083, -0.0148,\n                      -0.0188, -0.0265, -0.0028, -0.0168, -0.0084, -0.0057,  0.0132, -0.0189,\n                       0.0075,  0.0077, -0.0181,  0.0152,  0.0082, -0.0024, -0.0146,  0.0089],\n                     dtype=torch.float64)),\n             ('6.5.convs.1.1.running_mean',\n              tensor([ 0.6885, -1.2877,  0.3191,  0.5982, -0.4933,  0.3985,  0.1076,  0.2197,\n                       0.1896,  0.4515, -0.6079,  0.4856, -0.7102,  0.3500, -0.1991,  0.1864,\n                       0.0232, -0.7216, -0.7500,  0.1427,  0.5482,  0.0172, -0.2554, -0.0261,\n                      -0.8555, -0.5965, -0.0873, -0.4673, -0.7123,  0.0759,  0.6981,  0.0750,\n                       0.7663, -0.3931, -0.0945,  0.5454, -0.1214, -0.3008, -0.1166,  0.2179,\n                       0.2983, -0.1267, -1.1962,  0.4033, -0.6889, -0.7182, -0.5579, -0.8400,\n                      -0.2914,  1.0688, -0.3007, -0.3782, -0.3093,  1.2386, -0.1279, -0.6222,\n                       0.4311, -0.9213,  0.0225,  0.1456, -0.2438, -0.2756, -0.4038, -1.0030],\n                     dtype=torch.float64)),\n             ('6.5.convs.1.1.running_var',\n              tensor([0.5122, 0.9793, 0.5548, 0.9017, 0.5254, 0.7793, 1.0079, 0.8371, 0.5705,\n                      0.5136, 0.8169, 0.8182, 0.5292, 0.4946, 0.6266, 0.5874, 0.4952, 0.5450,\n                      0.4956, 0.6343, 0.4036, 0.7054, 0.6085, 0.5657, 1.2514, 0.8176, 0.5660,\n                      0.6809, 0.9881, 0.5207, 0.8641, 0.3312, 0.9939, 0.5919, 0.7487, 0.8015,\n                      1.1297, 0.4300, 0.5160, 0.6869, 0.5546, 0.5179, 0.4262, 0.6387, 0.6856,\n                      1.0306, 0.9522, 1.0984, 0.4906, 1.0767, 0.8956, 0.8615, 0.6042, 0.7023,\n                      0.7387, 0.6545, 0.4629, 1.0982, 0.5738, 0.5377, 0.6929, 0.4819, 1.7552,\n                      0.6772], dtype=torch.float64)),\n             ('6.5.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.5.convs.2.0.weight',\n              tensor([[[ 0.0007],\n                       [-0.0225],\n                       [ 0.0369],\n                       ...,\n                       [-0.1321],\n                       [-0.1222],\n                       [ 0.1618]],\n              \n                      [[-0.0804],\n                       [-0.0332],\n                       [-0.2140],\n                       ...,\n                       [ 0.0400],\n                       [-0.1306],\n                       [-0.2144]],\n              \n                      [[ 0.0549],\n                       [ 0.0320],\n                       [-0.0821],\n                       ...,\n                       [ 0.0321],\n                       [ 0.0305],\n                       [-0.0088]],\n              \n                      ...,\n              \n                      [[-0.0743],\n                       [ 0.2200],\n                       [-0.2823],\n                       ...,\n                       [-0.2902],\n                       [ 0.1863],\n                       [-0.0793]],\n              \n                      [[ 0.2339],\n                       [-0.2356],\n                       [ 0.2510],\n                       ...,\n                       [ 0.1311],\n                       [ 0.1117],\n                       [ 0.0206]],\n              \n                      [[ 0.0837],\n                       [ 0.1134],\n                       [ 0.1545],\n                       ...,\n                       [-0.0509],\n                       [-0.0122],\n                       [ 0.0042]]], dtype=torch.float64)),\n             ('6.5.convs.2.1.weight',\n              tensor([-0.0001, -0.0071,  0.0082,  0.0218,  0.0208,  0.0266, -0.0033, -0.0165,\n                       0.0369,  0.0064,  0.0164,  0.0142,  0.0193, -0.0040,  0.0227, -0.0241,\n                      -0.0193, -0.0007, -0.0040, -0.0178,  0.0197,  0.0307, -0.0016, -0.0154,\n                       0.0313, -0.0091,  0.0136,  0.0216, -0.0052,  0.0074,  0.0046, -0.0224,\n                       0.0267, -0.0045, -0.0246,  0.0109,  0.0207, -0.0097, -0.0203, -0.0021,\n                      -0.0233, -0.0091,  0.0092,  0.0101, -0.0090, -0.0069,  0.0155, -0.0030,\n                       0.0180, -0.0128, -0.0195,  0.0072, -0.0088,  0.0172, -0.0135,  0.0013,\n                       0.0223,  0.0198, -0.0169, -0.0200,  0.0105, -0.0012,  0.0061, -0.0065,\n                       0.0152,  0.0119, -0.0062,  0.0287, -0.0093,  0.0145,  0.0084,  0.0005,\n                      -0.0020, -0.0442, -0.0163, -0.0096, -0.0010, -0.0007, -0.0051, -0.0174,\n                      -0.0164, -0.0141, -0.0121,  0.0008, -0.0093, -0.0144,  0.0125,  0.0140,\n                      -0.0401, -0.0126, -0.0085,  0.0324,  0.0231,  0.0050, -0.0077,  0.0027,\n                       0.0168,  0.0205,  0.0087,  0.0304,  0.0074,  0.0103, -0.0138,  0.0123,\n                       0.0037,  0.0075,  0.0071,  0.0034, -0.0065,  0.0242,  0.0010, -0.0063,\n                      -0.0165,  0.0154,  0.0048, -0.0171, -0.0044,  0.0220,  0.0068, -0.0017,\n                       0.0210,  0.0069, -0.0095, -0.0119, -0.0189, -0.0132, -0.0175,  0.0125,\n                      -0.0256, -0.0144, -0.0035, -0.0074,  0.0178,  0.0035,  0.0105,  0.0172,\n                      -0.0072,  0.0021,  0.0164, -0.0152, -0.0045, -0.0131,  0.0119,  0.0080,\n                       0.0189, -0.0001,  0.0106, -0.0018, -0.0253,  0.0015,  0.0063, -0.0175,\n                       0.0273,  0.0155, -0.0046,  0.0007,  0.0050, -0.0153,  0.0231,  0.0093,\n                      -0.0043,  0.0196,  0.0062,  0.0145, -0.0315,  0.0352,  0.0369, -0.0026,\n                      -0.0005,  0.0107,  0.0167,  0.0264, -0.0019,  0.0106, -0.0127,  0.0255,\n                       0.0169,  0.0277, -0.0060,  0.0109, -0.0063,  0.0078,  0.0037, -0.0110,\n                       0.0137,  0.0207,  0.0143, -0.0032,  0.0215,  0.0086,  0.0290,  0.0238,\n                       0.0277, -0.0119, -0.0177, -0.0175, -0.0063, -0.0274,  0.0183,  0.0232,\n                      -0.0022,  0.0091,  0.0226, -0.0306,  0.0113, -0.0112, -0.0269,  0.0103,\n                      -0.0008, -0.0422, -0.0155, -0.0016,  0.0233, -0.0230,  0.0373, -0.0133,\n                       0.0031, -0.0163,  0.0296,  0.0169, -0.0090,  0.0124, -0.0115, -0.0125,\n                      -0.0148, -0.0108, -0.0158, -0.0103,  0.0203, -0.0155,  0.0091, -0.0135,\n                      -0.0169, -0.0189, -0.0072, -0.0001,  0.0170,  0.0206,  0.0081,  0.0027,\n                       0.0352,  0.0142, -0.0082,  0.0022, -0.0198, -0.0248, -0.0072, -0.0484,\n                      -0.0096,  0.0152, -0.0017, -0.0007,  0.0001,  0.0126, -0.0316,  0.0102],\n                     dtype=torch.float64)),\n             ('6.5.convs.2.1.bias',\n              tensor([-1.1678e-03, -3.1923e-03,  1.3112e-02,  2.0858e-02,  4.7208e-03,\n                       4.3608e-04,  1.5750e-02,  1.6490e-03,  9.8747e-03,  2.2442e-02,\n                       1.3793e-02, -5.5202e-03,  9.0527e-03, -5.6862e-03,  6.9908e-03,\n                       4.8064e-03,  2.0773e-02, -3.2974e-03,  1.2745e-02, -8.5603e-03,\n                      -4.9067e-03,  3.5996e-03,  5.5753e-04,  7.2405e-03, -5.7225e-03,\n                      -1.5083e-02,  5.0426e-03,  1.1423e-02,  1.7953e-03, -2.4789e-03,\n                       3.9750e-03,  8.0682e-03, -7.7040e-03,  1.7316e-02,  1.4617e-02,\n                       7.3996e-03, -1.2831e-03,  1.9569e-02,  9.1630e-03,  1.4885e-02,\n                      -8.3387e-04,  2.5908e-02, -6.4297e-03,  1.2283e-03,  3.1307e-03,\n                      -8.8600e-03,  2.7441e-03,  4.8239e-03, -1.1548e-02,  1.3157e-02,\n                       8.5368e-03,  1.2742e-02,  9.1695e-03,  1.4107e-02,  6.0820e-03,\n                       1.5736e-02,  7.8488e-03,  2.3520e-03,  8.5711e-03,  3.6600e-03,\n                      -1.2452e-03,  2.8815e-03,  4.8816e-03,  9.4797e-03, -4.1062e-03,\n                       1.2507e-02, -1.1526e-02,  1.2648e-02, -4.1438e-03, -1.1468e-02,\n                       3.2367e-03,  6.3141e-03,  2.4182e-03, -7.2418e-03,  1.4082e-02,\n                       2.4774e-03,  2.5678e-03,  2.4910e-03,  4.3122e-03, -8.6151e-04,\n                       1.0517e-02, -4.9261e-03,  8.1478e-03,  4.0931e-03, -2.7773e-03,\n                       1.2507e-02,  1.4951e-03,  2.0740e-03,  1.4591e-02,  6.5104e-03,\n                      -7.8116e-04,  2.2174e-02,  1.7469e-02, -3.8160e-04,  8.7713e-03,\n                      -1.5142e-02,  6.4406e-03, -6.3540e-04,  1.1212e-02,  1.0910e-03,\n                       1.9688e-02,  2.3529e-03, -2.2913e-03, -4.8809e-03,  1.0449e-02,\n                       4.0728e-04, -3.5230e-04,  3.4947e-03,  4.1352e-03,  3.9265e-03,\n                      -5.8501e-03, -7.1410e-03,  4.0409e-03,  1.5027e-02,  1.1741e-02,\n                       6.7241e-03,  1.1544e-02,  2.9570e-03,  2.1605e-03, -1.4881e-02,\n                       2.2379e-03,  8.3369e-03,  5.6436e-04, -3.0349e-03, -1.1580e-02,\n                       1.1330e-02,  1.4120e-02,  4.5586e-03,  3.1886e-05,  1.5085e-02,\n                       2.3358e-02,  1.5722e-02,  1.4378e-02,  5.9259e-03,  1.5272e-02,\n                      -9.4663e-03,  1.5928e-02,  6.1710e-03,  1.4116e-02,  7.8326e-03,\n                       9.9809e-03, -3.3011e-03,  1.4455e-02,  7.1306e-03, -8.7077e-03,\n                       1.4016e-02,  6.2895e-03, -1.6422e-03,  1.0654e-02,  8.9558e-03,\n                       6.6912e-03,  1.2681e-02,  3.4863e-03,  1.5336e-02,  1.5329e-02,\n                       8.8705e-03,  8.5649e-04,  7.7767e-03, -3.1015e-03, -9.3596e-03,\n                       3.1068e-03, -3.1637e-03,  2.1641e-04,  1.3721e-02,  1.2348e-02,\n                      -2.4406e-04, -7.7747e-03,  9.3160e-03,  8.9869e-04,  1.5482e-02,\n                       5.1663e-03,  9.8502e-03,  1.0459e-02,  1.0038e-02, -1.3533e-02,\n                       4.9343e-03, -8.7596e-04,  1.1555e-02,  3.7394e-03,  4.2140e-03,\n                      -2.6184e-03,  9.5581e-03, -7.9303e-03, -1.0230e-02,  1.8723e-02,\n                       8.3758e-03,  1.4122e-02,  1.0819e-02, -4.7476e-04,  4.4541e-03,\n                       6.2162e-03,  1.8599e-03,  1.0383e-02, -7.1263e-03,  4.8448e-03,\n                       7.5120e-03, -3.3724e-03,  1.9145e-02,  8.2710e-03,  1.9359e-02,\n                       4.5284e-03,  2.0462e-02,  2.0598e-02,  1.7428e-02,  6.2022e-05,\n                      -6.3827e-04,  1.4967e-02, -2.8858e-03,  7.2059e-03,  4.4177e-03,\n                       1.6921e-03,  1.2562e-02,  1.2954e-02,  6.6632e-03,  1.3517e-02,\n                       5.4235e-03,  3.9152e-03, -2.7745e-03,  3.0169e-03, -1.6081e-04,\n                      -1.6028e-02,  1.1125e-03,  6.0373e-03,  2.0237e-02, -4.3494e-03,\n                       3.8112e-03, -2.7621e-03,  1.7193e-03, -1.4179e-02,  1.4331e-02,\n                       1.2810e-02, -2.0004e-03,  1.0907e-02,  9.4899e-03,  3.5680e-03,\n                       6.7986e-03,  7.4130e-03, -8.2110e-03,  8.9692e-03,  8.9572e-03,\n                       1.9057e-03,  4.3985e-03,  4.4228e-03,  7.5920e-03,  2.3147e-03,\n                       1.5026e-02, -2.5035e-04,  1.0708e-02,  2.8740e-03, -8.9365e-03,\n                       1.7465e-02,  1.8552e-02,  1.7808e-02,  1.7584e-02,  1.1978e-02,\n                       9.0722e-03], dtype=torch.float64)),\n             ('6.5.convs.2.1.running_mean',\n              tensor([-0.0361,  0.1680, -0.1646,  0.1862,  0.1692,  0.0768,  0.2476, -0.3694,\n                       0.2180,  0.4591, -0.0384,  0.4116,  0.1827,  0.1186,  0.7991, -0.1803,\n                      -0.0856,  0.0785, -0.3732,  0.5654, -0.0715, -0.3280, -0.1701,  0.7322,\n                      -0.8324,  0.0994, -0.6030, -0.1757, -0.4184,  0.3869,  0.4321,  0.0448,\n                      -0.5696, -0.4391, -0.5532,  0.3704, -0.0467, -0.1026,  0.4465, -0.5886,\n                       0.5982, -0.5109,  0.0339,  0.4257,  0.0196,  0.5457,  0.7079, -0.0944,\n                       0.4062,  0.1916, -0.1695,  0.5542,  0.2431, -0.6123,  0.8114,  0.4746,\n                      -0.0576,  0.0469,  0.6021,  0.1555,  0.0405,  0.0494,  0.5356, -0.0535,\n                      -0.7021, -0.0441, -0.2569,  0.9482,  0.1479,  0.0841, -0.1419,  0.8612,\n                      -0.2116, -0.2645, -0.3329, -0.2167, -0.1655, -0.1057, -0.6193,  0.4380,\n                      -0.0928, -0.2382,  0.5345, -0.4614, -0.0284,  0.1385, -0.3266,  0.2415,\n                       0.3903, -0.7708, -0.9324,  0.3164,  0.1644,  0.0377, -0.2497,  0.6259,\n                      -0.4679, -0.0775, -0.2853, -0.2560,  0.3264,  0.1414, -0.1178, -0.0971,\n                       0.2791, -0.0492,  0.1263,  0.1476,  0.2262,  0.2986,  0.1013, -0.5593,\n                       0.1161, -0.7467,  0.0815,  0.0659,  0.7355, -0.4172, -0.3645,  0.0763,\n                      -0.1273,  0.9781, -0.0484, -0.6244, -0.1628, -0.5973,  0.2806,  0.6401,\n                      -0.0638,  0.4480, -0.3785, -0.0287,  0.0259,  0.1997, -0.3077,  0.1086,\n                      -0.1784, -0.4023,  0.0107, -0.2770,  0.3481, -0.1480,  0.8255, -0.2505,\n                       0.0561, -0.1016,  0.6592, -0.3125, -0.9027, -0.3901,  0.3778, -0.0851,\n                      -0.1515,  0.1321, -0.4119,  0.3111, -0.2307,  0.0767, -0.6245,  0.0281,\n                      -0.4003, -0.2882, -0.2339, -0.4514,  1.0053, -0.7171, -0.8131,  0.0135,\n                      -0.1555, -0.0196, -0.0322, -0.3982, -0.2445, -0.0233,  0.0771,  0.1680,\n                      -0.2456, -0.3945,  0.1377,  0.1009, -0.0892, -0.1152, -0.1389,  0.0714,\n                      -0.0017, -0.6183, -0.2900, -0.2343, -0.8766,  0.5262, -0.6424, -0.0637,\n                       0.1023, -1.4370, -0.8441, -0.3755, -0.0906, -0.6952, -0.7279,  0.6015,\n                       0.2145,  0.1393, -0.3518,  0.6698,  0.2741, -0.4372, -0.4090,  0.0243,\n                      -0.0687,  0.3457, -0.1099, -0.0027, -0.5067,  0.8749, -0.3518, -0.0383,\n                      -0.0193, -0.7281,  0.3530, -0.0605, -0.1492, -0.1982, -0.1093,  0.2855,\n                       0.3502,  0.0152, -0.8461, -0.3615, -0.0848,  0.0210,  0.1633, -0.0032,\n                       0.2722,  0.1324, -0.0330,  0.2193, -0.4504,  0.3880,  0.9682, -0.1282,\n                       0.1240,  0.1317, -0.1373,  0.0434, -0.1966,  0.6083, -0.5636,  0.4389,\n                       0.4036, -0.1270, -0.8223,  0.0600,  0.0596, -0.1677,  0.5905, -0.0665],\n                     dtype=torch.float64)),\n             ('6.5.convs.2.1.running_var',\n              tensor([0.1397, 0.5604, 0.1581, 0.3884, 0.3366, 0.2859, 0.3670, 0.4328, 0.2415,\n                      0.3887, 0.2474, 0.4844, 0.1749, 0.1436, 0.4473, 0.3128, 0.3727, 0.1979,\n                      0.2311, 0.4493, 0.3325, 0.3443, 0.3211, 0.4673, 0.5442, 0.3565, 0.3445,\n                      0.3611, 0.3431, 0.2579, 0.3480, 0.5796, 0.3409, 0.2687, 0.4687, 0.4586,\n                      0.3769, 0.1463, 0.3254, 0.4541, 0.3221, 0.4925, 0.2308, 0.6912, 0.2945,\n                      0.3488, 0.4200, 0.1980, 0.7530, 0.3342, 0.2181, 0.3332, 0.2866, 0.5371,\n                      0.4247, 0.3883, 0.3121, 0.2710, 0.4582, 0.2523, 0.3140, 0.0775, 0.3054,\n                      0.1081, 0.7139, 0.4092, 0.2880, 0.5081, 0.3732, 0.5536, 0.2296, 0.2827,\n                      0.2353, 0.5687, 0.4606, 0.3634, 0.1712, 0.1268, 0.6385, 0.3082, 0.3096,\n                      0.1579, 0.4247, 0.2575, 0.4443, 0.7131, 0.5025, 0.3626, 0.4818, 0.4804,\n                      0.3684, 0.4124, 0.2857, 0.2290, 0.4815, 0.2078, 0.3984, 0.1389, 0.1876,\n                      0.4210, 0.3745, 0.3359, 0.2730, 0.2130, 0.3158, 0.1287, 0.4849, 0.5211,\n                      0.2518, 0.3471, 0.1475, 0.3549, 0.5391, 0.4179, 0.5497, 0.5160, 0.4492,\n                      0.5797, 0.2222, 0.3421, 0.3285, 0.3419, 0.3883, 0.4151, 0.2998, 0.6282,\n                      0.2886, 0.4031, 0.2554, 0.4954, 0.1408, 0.2014, 0.4737, 0.1443, 0.1878,\n                      0.4274, 0.2010, 0.2830, 0.3303, 0.2659, 0.3211, 0.3447, 0.3757, 0.2542,\n                      0.1635, 0.4201, 0.3199, 0.6092, 0.3950, 0.3346, 0.4007, 0.1630, 0.2453,\n                      0.4922, 0.2011, 0.1639, 0.2569, 0.2182, 0.3577, 0.1246, 0.2104, 0.2572,\n                      0.3045, 0.3355, 0.7313, 0.5353, 0.5047, 0.1876, 0.2742, 0.3983, 0.3997,\n                      0.2635, 0.2337, 0.2416, 0.3575, 0.7485, 0.3279, 0.6272, 0.1778, 0.3045,\n                      0.2869, 0.1915, 0.4269, 0.3705, 0.2517, 0.4039, 0.4680, 0.0831, 0.4340,\n                      0.3152, 0.3870, 0.3992, 0.4045, 0.4737, 0.3611, 0.6323, 0.2540, 0.5208,\n                      0.5764, 0.4656, 0.1827, 0.3169, 0.3335, 0.4904, 0.1990, 0.2878, 0.3710,\n                      0.0941, 0.1493, 0.4490, 0.2366, 0.2705, 0.4054, 0.5103, 0.3166, 0.2974,\n                      0.2964, 0.4758, 0.2610, 0.3913, 0.3401, 0.1990, 0.1937, 0.4235, 0.5163,\n                      0.2335, 0.2796, 0.2841, 0.6113, 0.3644, 0.3823, 0.3750, 0.2662, 0.3206,\n                      0.1455, 0.3110, 0.3324, 0.3319, 0.3935, 0.0495, 0.5328, 0.2288, 0.2699,\n                      0.2181, 0.3549, 0.3519, 0.2817, 0.5131, 0.1355, 0.5481, 0.3814, 0.4090,\n                      0.1956, 0.3608, 0.3629, 0.3920], dtype=torch.float64)),\n             ('6.5.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.5.convpath.0.0.0.weight',\n              tensor([[[-0.0159],\n                       [ 0.0959],\n                       [ 0.0464],\n                       ...,\n                       [-0.0345],\n                       [-0.0361],\n                       [-0.0095]],\n              \n                      [[-0.0082],\n                       [-0.0873],\n                       [ 0.1419],\n                       ...,\n                       [ 0.0476],\n                       [ 0.1877],\n                       [-0.2293]],\n              \n                      [[ 0.0361],\n                       [-0.0449],\n                       [ 0.0379],\n                       ...,\n                       [-0.0941],\n                       [ 0.0118],\n                       [-0.0568]],\n              \n                      ...,\n              \n                      [[-0.1578],\n                       [-0.1014],\n                       [-0.0985],\n                       ...,\n                       [ 0.0263],\n                       [-0.0787],\n                       [-0.0804]],\n              \n                      [[ 0.0774],\n                       [-0.1321],\n                       [ 0.0956],\n                       ...,\n                       [-0.0218],\n                       [-0.0260],\n                       [-0.0188]],\n              \n                      [[ 0.0756],\n                       [-0.0247],\n                       [-0.0297],\n                       ...,\n                       [ 0.0865],\n                       [ 0.1219],\n                       [-0.0433]]], dtype=torch.float64)),\n             ('6.5.convpath.0.0.1.weight',\n              tensor([0.9698, 0.9699, 0.9490, 0.9663, 0.9633, 0.9676, 0.9883, 0.9712, 0.9682,\n                      0.9791, 0.9616, 0.9649, 0.9606, 0.9528, 0.9664, 1.0263, 0.9790, 0.9987,\n                      0.9737, 0.9548, 0.9581, 0.9872, 1.0118, 0.9746, 0.9829, 0.9680, 0.9722,\n                      0.9765, 0.9793, 0.9638, 0.9805, 0.9741, 0.9685, 0.9728, 0.9462, 0.9585,\n                      0.9784, 0.9931, 0.9571, 0.9883, 0.9809, 0.9737, 0.9720, 0.9975, 0.9671,\n                      0.9515, 0.9789, 0.9919, 0.9769, 0.9802, 0.9564, 0.9679, 0.9916, 0.9757,\n                      0.9393, 0.9593, 0.9758, 0.9667, 0.9846, 0.9941, 1.0062, 0.9416, 0.9720,\n                      0.9351], dtype=torch.float64)),\n             ('6.5.convpath.0.0.1.bias',\n              tensor([ 0.0029,  0.0080,  0.0072,  0.0055,  0.0078,  0.0029,  0.0119, -0.0023,\n                       0.0081,  0.0076,  0.0085,  0.0116,  0.0072, -0.0094, -0.0093,  0.0260,\n                      -0.0009,  0.0249,  0.0107, -0.0103, -0.0106,  0.0146,  0.0177, -0.0025,\n                      -0.0099, -0.0008, -0.0145,  0.0041,  0.0185, -0.0100,  0.0205, -0.0082,\n                       0.0224,  0.0084, -0.0231,  0.0111, -0.0076,  0.0167,  0.0065, -0.0097,\n                      -0.0050, -0.0082, -0.0003,  0.0200,  0.0069, -0.0307, -0.0131,  0.0215,\n                      -0.0119,  0.0096, -0.0119, -0.0108,  0.0265, -0.0052, -0.0056, -0.0024,\n                      -0.0097, -0.0155,  0.0093,  0.0177,  0.0003, -0.0025,  0.0004, -0.0243],\n                     dtype=torch.float64)),\n             ('6.5.convpath.0.0.1.running_mean',\n              tensor([ 0.6289,  0.0562,  0.3036, -0.4673,  0.1196, -0.3437,  0.6448, -0.5550,\n                       0.0174,  0.2705, -1.0050, -0.4373, -0.0208,  1.0133,  0.3290, -0.3679,\n                       0.3730,  0.3480, -0.7210, -0.8384,  0.2152, -0.1795, -0.5973, -0.0460,\n                      -0.2679,  0.2367, -0.3585,  0.4268,  0.1556, -0.1696,  0.0507,  0.2252,\n                      -0.3387, -0.4349,  0.6709, -0.2964,  0.5138,  0.0876,  0.1874,  0.2398,\n                      -0.1897,  0.3736,  0.0685, -0.4554,  0.6861,  1.1062,  0.9155, -0.7769,\n                       0.6319,  0.0610,  0.8805, -0.5538,  0.1561,  0.3953, -0.5522,  0.3013,\n                       0.6577, -0.3548, -0.3693, -0.4058, -0.6066, -0.4633,  0.1709,  0.6844],\n                     dtype=torch.float64)),\n             ('6.5.convpath.0.0.1.running_var',\n              tensor([0.1996, 0.2117, 0.3200, 0.2147, 0.1699, 0.1796, 0.3376, 0.1707, 0.1563,\n                      0.1256, 0.5637, 0.1581, 0.8390, 0.4758, 0.2161, 0.1157, 0.1487, 0.1251,\n                      0.2467, 0.3396, 0.5314, 0.1280, 0.0927, 0.1690, 0.1306, 0.4552, 0.0634,\n                      0.1722, 0.8017, 0.1737, 0.6113, 0.1162, 0.1827, 0.1961, 0.1242, 0.2585,\n                      0.9847, 0.5323, 0.3786, 0.1056, 0.2249, 0.5711, 0.2330, 0.1022, 0.2503,\n                      0.7001, 0.2299, 0.1263, 1.6804, 0.3714, 0.4519, 0.2089, 0.1189, 0.1122,\n                      0.1931, 0.2745, 0.3571, 0.1722, 0.3670, 0.1276, 0.1627, 0.3406, 0.1568,\n                      0.6619], dtype=torch.float64)),\n             ('6.5.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.5.convpath.0.1.0.weight',\n              tensor([[[-0.0469,  0.0620,  0.0896, -0.0159, -0.0578],\n                       [-0.2007, -0.0320,  0.0168,  0.0656,  0.0493],\n                       [-0.0347,  0.0333,  0.0107, -0.0247, -0.0010],\n                       ...,\n                       [ 0.0094, -0.0280, -0.1716, -0.0484,  0.0938],\n                       [-0.0192,  0.0287,  0.0148,  0.0184,  0.0493],\n                       [ 0.1046,  0.0407, -0.0652,  0.0161, -0.0574]],\n              \n                      [[ 0.0285,  0.0449, -0.0022, -0.0601, -0.0216],\n                       [-0.0301,  0.0648, -0.0313,  0.0750,  0.0139],\n                       [ 0.1176, -0.0173, -0.1481, -0.0981, -0.0136],\n                       ...,\n                       [-0.1328, -0.0014, -0.0385,  0.0227,  0.0490],\n                       [-0.1500,  0.0246, -0.0173, -0.0551,  0.0272],\n                       [-0.0817,  0.0874, -0.0957,  0.0768,  0.1392]],\n              \n                      [[ 0.0350, -0.1329,  0.1100, -0.0393,  0.0047],\n                       [ 0.0572, -0.0430, -0.0515,  0.0057,  0.0666],\n                       [ 0.0749,  0.1899,  0.0320,  0.0132,  0.1371],\n                       ...,\n                       [ 0.0552, -0.0441, -0.1381,  0.0138,  0.0652],\n                       [ 0.0761, -0.0697,  0.0660, -0.0914, -0.0111],\n                       [-0.0612,  0.0737,  0.0346, -0.0860, -0.0321]],\n              \n                      ...,\n              \n                      [[-0.0534, -0.0471, -0.0225,  0.0921, -0.0139],\n                       [-0.1966,  0.1848, -0.0647, -0.1086, -0.0737],\n                       [ 0.1921, -0.0128,  0.0160, -0.0588, -0.1794],\n                       ...,\n                       [-0.0194, -0.0011,  0.0822, -0.1450, -0.0185],\n                       [-0.0848,  0.1030,  0.1008, -0.0007,  0.1412],\n                       [-0.0218,  0.0906, -0.0930,  0.0175,  0.0472]],\n              \n                      [[-0.0925,  0.0878,  0.0055, -0.0226, -0.0392],\n                       [-0.0791,  0.0301, -0.0399, -0.0821,  0.1582],\n                       [ 0.0780,  0.0089,  0.0555,  0.0292, -0.0327],\n                       ...,\n                       [-0.0304,  0.0652,  0.0845, -0.0118, -0.0925],\n                       [-0.0663,  0.0998, -0.0152, -0.0046, -0.1432],\n                       [-0.0433,  0.0106,  0.0961, -0.0291, -0.0429]],\n              \n                      [[-0.1359, -0.0836,  0.0608, -0.1169,  0.0488],\n                       [ 0.0846, -0.1247,  0.0931,  0.0566, -0.0603],\n                       [ 0.1391,  0.0735, -0.0932,  0.0539,  0.1275],\n                       ...,\n                       [-0.0027,  0.0183, -0.1515,  0.1310,  0.0492],\n                       [-0.0406,  0.1284,  0.0023,  0.0277,  0.0203],\n                       [-0.0465, -0.0169, -0.0413,  0.0532, -0.0258]]], dtype=torch.float64)),\n             ('6.5.convpath.0.1.1.weight',\n              tensor([0.9866, 0.9551, 0.9633, 0.9620, 0.9669, 0.9623, 0.9590, 0.9494, 0.9760,\n                      0.9734, 0.9512, 0.9907, 0.9916, 0.9903, 0.9243, 0.9717, 0.9820, 0.9616,\n                      0.9932, 0.9839, 0.9753, 0.9651, 0.9564, 0.9578, 0.9592, 0.9431, 0.9829,\n                      0.9404, 0.9402, 1.0097, 0.9711, 0.9377, 0.9708, 0.9900, 0.9713, 0.9596,\n                      0.9559, 0.9666, 0.9822, 0.9464, 0.9589, 0.9544, 0.9912, 0.9783, 0.9498,\n                      0.9262, 0.9456, 0.9297, 0.9514, 0.9746, 0.9519, 0.9529, 0.9439, 0.9671,\n                      0.9795, 0.9525, 0.9734, 0.9753, 0.9439, 1.0004, 0.9893, 0.9808, 0.9160,\n                      1.0033], dtype=torch.float64)),\n             ('6.5.convpath.0.1.1.bias',\n              tensor([-0.0061,  0.0062, -0.0270, -0.0155,  0.0010, -0.0245,  0.0085, -0.0290,\n                       0.0003, -0.0093, -0.0073,  0.0110,  0.0232,  0.0099, -0.0197, -0.0020,\n                       0.0104, -0.0030,  0.0203,  0.0014, -0.0121, -0.0055,  0.0065, -0.0006,\n                      -0.0025, -0.0159,  0.0053,  0.0080, -0.0139,  0.0193, -0.0151, -0.0301,\n                      -0.0219,  0.0183,  0.0124, -0.0274, -0.0250, -0.0095, -0.0007, -0.0188,\n                      -0.0151, -0.0059,  0.0176,  0.0097, -0.0027, -0.0105,  0.0083, -0.0148,\n                      -0.0188, -0.0265, -0.0028, -0.0168, -0.0084, -0.0057,  0.0132, -0.0189,\n                       0.0075,  0.0077, -0.0181,  0.0152,  0.0082, -0.0024, -0.0146,  0.0089],\n                     dtype=torch.float64)),\n             ('6.5.convpath.0.1.1.running_mean',\n              tensor([ 0.6885, -1.2877,  0.3191,  0.5982, -0.4933,  0.3985,  0.1076,  0.2197,\n                       0.1896,  0.4515, -0.6079,  0.4856, -0.7102,  0.3500, -0.1991,  0.1864,\n                       0.0232, -0.7216, -0.7500,  0.1427,  0.5482,  0.0172, -0.2554, -0.0261,\n                      -0.8555, -0.5965, -0.0873, -0.4673, -0.7123,  0.0759,  0.6981,  0.0750,\n                       0.7663, -0.3931, -0.0945,  0.5454, -0.1214, -0.3008, -0.1166,  0.2179,\n                       0.2983, -0.1267, -1.1962,  0.4033, -0.6889, -0.7182, -0.5579, -0.8400,\n                      -0.2914,  1.0688, -0.3007, -0.3782, -0.3093,  1.2386, -0.1279, -0.6222,\n                       0.4311, -0.9213,  0.0225,  0.1456, -0.2438, -0.2756, -0.4038, -1.0030],\n                     dtype=torch.float64)),\n             ('6.5.convpath.0.1.1.running_var',\n              tensor([0.5122, 0.9793, 0.5548, 0.9017, 0.5254, 0.7793, 1.0079, 0.8371, 0.5705,\n                      0.5136, 0.8169, 0.8182, 0.5292, 0.4946, 0.6266, 0.5874, 0.4952, 0.5450,\n                      0.4956, 0.6343, 0.4036, 0.7054, 0.6085, 0.5657, 1.2514, 0.8176, 0.5660,\n                      0.6809, 0.9881, 0.5207, 0.8641, 0.3312, 0.9939, 0.5919, 0.7487, 0.8015,\n                      1.1297, 0.4300, 0.5160, 0.6869, 0.5546, 0.5179, 0.4262, 0.6387, 0.6856,\n                      1.0306, 0.9522, 1.0984, 0.4906, 1.0767, 0.8956, 0.8615, 0.6042, 0.7023,\n                      0.7387, 0.6545, 0.4629, 1.0982, 0.5738, 0.5377, 0.6929, 0.4819, 1.7552,\n                      0.6772], dtype=torch.float64)),\n             ('6.5.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.5.convpath.0.2.0.weight',\n              tensor([[[ 0.0007],\n                       [-0.0225],\n                       [ 0.0369],\n                       ...,\n                       [-0.1321],\n                       [-0.1222],\n                       [ 0.1618]],\n              \n                      [[-0.0804],\n                       [-0.0332],\n                       [-0.2140],\n                       ...,\n                       [ 0.0400],\n                       [-0.1306],\n                       [-0.2144]],\n              \n                      [[ 0.0549],\n                       [ 0.0320],\n                       [-0.0821],\n                       ...,\n                       [ 0.0321],\n                       [ 0.0305],\n                       [-0.0088]],\n              \n                      ...,\n              \n                      [[-0.0743],\n                       [ 0.2200],\n                       [-0.2823],\n                       ...,\n                       [-0.2902],\n                       [ 0.1863],\n                       [-0.0793]],\n              \n                      [[ 0.2339],\n                       [-0.2356],\n                       [ 0.2510],\n                       ...,\n                       [ 0.1311],\n                       [ 0.1117],\n                       [ 0.0206]],\n              \n                      [[ 0.0837],\n                       [ 0.1134],\n                       [ 0.1545],\n                       ...,\n                       [-0.0509],\n                       [-0.0122],\n                       [ 0.0042]]], dtype=torch.float64)),\n             ('6.5.convpath.0.2.1.weight',\n              tensor([-0.0001, -0.0071,  0.0082,  0.0218,  0.0208,  0.0266, -0.0033, -0.0165,\n                       0.0369,  0.0064,  0.0164,  0.0142,  0.0193, -0.0040,  0.0227, -0.0241,\n                      -0.0193, -0.0007, -0.0040, -0.0178,  0.0197,  0.0307, -0.0016, -0.0154,\n                       0.0313, -0.0091,  0.0136,  0.0216, -0.0052,  0.0074,  0.0046, -0.0224,\n                       0.0267, -0.0045, -0.0246,  0.0109,  0.0207, -0.0097, -0.0203, -0.0021,\n                      -0.0233, -0.0091,  0.0092,  0.0101, -0.0090, -0.0069,  0.0155, -0.0030,\n                       0.0180, -0.0128, -0.0195,  0.0072, -0.0088,  0.0172, -0.0135,  0.0013,\n                       0.0223,  0.0198, -0.0169, -0.0200,  0.0105, -0.0012,  0.0061, -0.0065,\n                       0.0152,  0.0119, -0.0062,  0.0287, -0.0093,  0.0145,  0.0084,  0.0005,\n                      -0.0020, -0.0442, -0.0163, -0.0096, -0.0010, -0.0007, -0.0051, -0.0174,\n                      -0.0164, -0.0141, -0.0121,  0.0008, -0.0093, -0.0144,  0.0125,  0.0140,\n                      -0.0401, -0.0126, -0.0085,  0.0324,  0.0231,  0.0050, -0.0077,  0.0027,\n                       0.0168,  0.0205,  0.0087,  0.0304,  0.0074,  0.0103, -0.0138,  0.0123,\n                       0.0037,  0.0075,  0.0071,  0.0034, -0.0065,  0.0242,  0.0010, -0.0063,\n                      -0.0165,  0.0154,  0.0048, -0.0171, -0.0044,  0.0220,  0.0068, -0.0017,\n                       0.0210,  0.0069, -0.0095, -0.0119, -0.0189, -0.0132, -0.0175,  0.0125,\n                      -0.0256, -0.0144, -0.0035, -0.0074,  0.0178,  0.0035,  0.0105,  0.0172,\n                      -0.0072,  0.0021,  0.0164, -0.0152, -0.0045, -0.0131,  0.0119,  0.0080,\n                       0.0189, -0.0001,  0.0106, -0.0018, -0.0253,  0.0015,  0.0063, -0.0175,\n                       0.0273,  0.0155, -0.0046,  0.0007,  0.0050, -0.0153,  0.0231,  0.0093,\n                      -0.0043,  0.0196,  0.0062,  0.0145, -0.0315,  0.0352,  0.0369, -0.0026,\n                      -0.0005,  0.0107,  0.0167,  0.0264, -0.0019,  0.0106, -0.0127,  0.0255,\n                       0.0169,  0.0277, -0.0060,  0.0109, -0.0063,  0.0078,  0.0037, -0.0110,\n                       0.0137,  0.0207,  0.0143, -0.0032,  0.0215,  0.0086,  0.0290,  0.0238,\n                       0.0277, -0.0119, -0.0177, -0.0175, -0.0063, -0.0274,  0.0183,  0.0232,\n                      -0.0022,  0.0091,  0.0226, -0.0306,  0.0113, -0.0112, -0.0269,  0.0103,\n                      -0.0008, -0.0422, -0.0155, -0.0016,  0.0233, -0.0230,  0.0373, -0.0133,\n                       0.0031, -0.0163,  0.0296,  0.0169, -0.0090,  0.0124, -0.0115, -0.0125,\n                      -0.0148, -0.0108, -0.0158, -0.0103,  0.0203, -0.0155,  0.0091, -0.0135,\n                      -0.0169, -0.0189, -0.0072, -0.0001,  0.0170,  0.0206,  0.0081,  0.0027,\n                       0.0352,  0.0142, -0.0082,  0.0022, -0.0198, -0.0248, -0.0072, -0.0484,\n                      -0.0096,  0.0152, -0.0017, -0.0007,  0.0001,  0.0126, -0.0316,  0.0102],\n                     dtype=torch.float64)),\n             ('6.5.convpath.0.2.1.bias',\n              tensor([-1.1678e-03, -3.1923e-03,  1.3112e-02,  2.0858e-02,  4.7208e-03,\n                       4.3608e-04,  1.5750e-02,  1.6490e-03,  9.8747e-03,  2.2442e-02,\n                       1.3793e-02, -5.5202e-03,  9.0527e-03, -5.6862e-03,  6.9908e-03,\n                       4.8064e-03,  2.0773e-02, -3.2974e-03,  1.2745e-02, -8.5603e-03,\n                      -4.9067e-03,  3.5996e-03,  5.5753e-04,  7.2405e-03, -5.7225e-03,\n                      -1.5083e-02,  5.0426e-03,  1.1423e-02,  1.7953e-03, -2.4789e-03,\n                       3.9750e-03,  8.0682e-03, -7.7040e-03,  1.7316e-02,  1.4617e-02,\n                       7.3996e-03, -1.2831e-03,  1.9569e-02,  9.1630e-03,  1.4885e-02,\n                      -8.3387e-04,  2.5908e-02, -6.4297e-03,  1.2283e-03,  3.1307e-03,\n                      -8.8600e-03,  2.7441e-03,  4.8239e-03, -1.1548e-02,  1.3157e-02,\n                       8.5368e-03,  1.2742e-02,  9.1695e-03,  1.4107e-02,  6.0820e-03,\n                       1.5736e-02,  7.8488e-03,  2.3520e-03,  8.5711e-03,  3.6600e-03,\n                      -1.2452e-03,  2.8815e-03,  4.8816e-03,  9.4797e-03, -4.1062e-03,\n                       1.2507e-02, -1.1526e-02,  1.2648e-02, -4.1438e-03, -1.1468e-02,\n                       3.2367e-03,  6.3141e-03,  2.4182e-03, -7.2418e-03,  1.4082e-02,\n                       2.4774e-03,  2.5678e-03,  2.4910e-03,  4.3122e-03, -8.6151e-04,\n                       1.0517e-02, -4.9261e-03,  8.1478e-03,  4.0931e-03, -2.7773e-03,\n                       1.2507e-02,  1.4951e-03,  2.0740e-03,  1.4591e-02,  6.5104e-03,\n                      -7.8116e-04,  2.2174e-02,  1.7469e-02, -3.8160e-04,  8.7713e-03,\n                      -1.5142e-02,  6.4406e-03, -6.3540e-04,  1.1212e-02,  1.0910e-03,\n                       1.9688e-02,  2.3529e-03, -2.2913e-03, -4.8809e-03,  1.0449e-02,\n                       4.0728e-04, -3.5230e-04,  3.4947e-03,  4.1352e-03,  3.9265e-03,\n                      -5.8501e-03, -7.1410e-03,  4.0409e-03,  1.5027e-02,  1.1741e-02,\n                       6.7241e-03,  1.1544e-02,  2.9570e-03,  2.1605e-03, -1.4881e-02,\n                       2.2379e-03,  8.3369e-03,  5.6436e-04, -3.0349e-03, -1.1580e-02,\n                       1.1330e-02,  1.4120e-02,  4.5586e-03,  3.1886e-05,  1.5085e-02,\n                       2.3358e-02,  1.5722e-02,  1.4378e-02,  5.9259e-03,  1.5272e-02,\n                      -9.4663e-03,  1.5928e-02,  6.1710e-03,  1.4116e-02,  7.8326e-03,\n                       9.9809e-03, -3.3011e-03,  1.4455e-02,  7.1306e-03, -8.7077e-03,\n                       1.4016e-02,  6.2895e-03, -1.6422e-03,  1.0654e-02,  8.9558e-03,\n                       6.6912e-03,  1.2681e-02,  3.4863e-03,  1.5336e-02,  1.5329e-02,\n                       8.8705e-03,  8.5649e-04,  7.7767e-03, -3.1015e-03, -9.3596e-03,\n                       3.1068e-03, -3.1637e-03,  2.1641e-04,  1.3721e-02,  1.2348e-02,\n                      -2.4406e-04, -7.7747e-03,  9.3160e-03,  8.9869e-04,  1.5482e-02,\n                       5.1663e-03,  9.8502e-03,  1.0459e-02,  1.0038e-02, -1.3533e-02,\n                       4.9343e-03, -8.7596e-04,  1.1555e-02,  3.7394e-03,  4.2140e-03,\n                      -2.6184e-03,  9.5581e-03, -7.9303e-03, -1.0230e-02,  1.8723e-02,\n                       8.3758e-03,  1.4122e-02,  1.0819e-02, -4.7476e-04,  4.4541e-03,\n                       6.2162e-03,  1.8599e-03,  1.0383e-02, -7.1263e-03,  4.8448e-03,\n                       7.5120e-03, -3.3724e-03,  1.9145e-02,  8.2710e-03,  1.9359e-02,\n                       4.5284e-03,  2.0462e-02,  2.0598e-02,  1.7428e-02,  6.2022e-05,\n                      -6.3827e-04,  1.4967e-02, -2.8858e-03,  7.2059e-03,  4.4177e-03,\n                       1.6921e-03,  1.2562e-02,  1.2954e-02,  6.6632e-03,  1.3517e-02,\n                       5.4235e-03,  3.9152e-03, -2.7745e-03,  3.0169e-03, -1.6081e-04,\n                      -1.6028e-02,  1.1125e-03,  6.0373e-03,  2.0237e-02, -4.3494e-03,\n                       3.8112e-03, -2.7621e-03,  1.7193e-03, -1.4179e-02,  1.4331e-02,\n                       1.2810e-02, -2.0004e-03,  1.0907e-02,  9.4899e-03,  3.5680e-03,\n                       6.7986e-03,  7.4130e-03, -8.2110e-03,  8.9692e-03,  8.9572e-03,\n                       1.9057e-03,  4.3985e-03,  4.4228e-03,  7.5920e-03,  2.3147e-03,\n                       1.5026e-02, -2.5035e-04,  1.0708e-02,  2.8740e-03, -8.9365e-03,\n                       1.7465e-02,  1.8552e-02,  1.7808e-02,  1.7584e-02,  1.1978e-02,\n                       9.0722e-03], dtype=torch.float64)),\n             ('6.5.convpath.0.2.1.running_mean',\n              tensor([-0.0361,  0.1680, -0.1646,  0.1862,  0.1692,  0.0768,  0.2476, -0.3694,\n                       0.2180,  0.4591, -0.0384,  0.4116,  0.1827,  0.1186,  0.7991, -0.1803,\n                      -0.0856,  0.0785, -0.3732,  0.5654, -0.0715, -0.3280, -0.1701,  0.7322,\n                      -0.8324,  0.0994, -0.6030, -0.1757, -0.4184,  0.3869,  0.4321,  0.0448,\n                      -0.5696, -0.4391, -0.5532,  0.3704, -0.0467, -0.1026,  0.4465, -0.5886,\n                       0.5982, -0.5109,  0.0339,  0.4257,  0.0196,  0.5457,  0.7079, -0.0944,\n                       0.4062,  0.1916, -0.1695,  0.5542,  0.2431, -0.6123,  0.8114,  0.4746,\n                      -0.0576,  0.0469,  0.6021,  0.1555,  0.0405,  0.0494,  0.5356, -0.0535,\n                      -0.7021, -0.0441, -0.2569,  0.9482,  0.1479,  0.0841, -0.1419,  0.8612,\n                      -0.2116, -0.2645, -0.3329, -0.2167, -0.1655, -0.1057, -0.6193,  0.4380,\n                      -0.0928, -0.2382,  0.5345, -0.4614, -0.0284,  0.1385, -0.3266,  0.2415,\n                       0.3903, -0.7708, -0.9324,  0.3164,  0.1644,  0.0377, -0.2497,  0.6259,\n                      -0.4679, -0.0775, -0.2853, -0.2560,  0.3264,  0.1414, -0.1178, -0.0971,\n                       0.2791, -0.0492,  0.1263,  0.1476,  0.2262,  0.2986,  0.1013, -0.5593,\n                       0.1161, -0.7467,  0.0815,  0.0659,  0.7355, -0.4172, -0.3645,  0.0763,\n                      -0.1273,  0.9781, -0.0484, -0.6244, -0.1628, -0.5973,  0.2806,  0.6401,\n                      -0.0638,  0.4480, -0.3785, -0.0287,  0.0259,  0.1997, -0.3077,  0.1086,\n                      -0.1784, -0.4023,  0.0107, -0.2770,  0.3481, -0.1480,  0.8255, -0.2505,\n                       0.0561, -0.1016,  0.6592, -0.3125, -0.9027, -0.3901,  0.3778, -0.0851,\n                      -0.1515,  0.1321, -0.4119,  0.3111, -0.2307,  0.0767, -0.6245,  0.0281,\n                      -0.4003, -0.2882, -0.2339, -0.4514,  1.0053, -0.7171, -0.8131,  0.0135,\n                      -0.1555, -0.0196, -0.0322, -0.3982, -0.2445, -0.0233,  0.0771,  0.1680,\n                      -0.2456, -0.3945,  0.1377,  0.1009, -0.0892, -0.1152, -0.1389,  0.0714,\n                      -0.0017, -0.6183, -0.2900, -0.2343, -0.8766,  0.5262, -0.6424, -0.0637,\n                       0.1023, -1.4370, -0.8441, -0.3755, -0.0906, -0.6952, -0.7279,  0.6015,\n                       0.2145,  0.1393, -0.3518,  0.6698,  0.2741, -0.4372, -0.4090,  0.0243,\n                      -0.0687,  0.3457, -0.1099, -0.0027, -0.5067,  0.8749, -0.3518, -0.0383,\n                      -0.0193, -0.7281,  0.3530, -0.0605, -0.1492, -0.1982, -0.1093,  0.2855,\n                       0.3502,  0.0152, -0.8461, -0.3615, -0.0848,  0.0210,  0.1633, -0.0032,\n                       0.2722,  0.1324, -0.0330,  0.2193, -0.4504,  0.3880,  0.9682, -0.1282,\n                       0.1240,  0.1317, -0.1373,  0.0434, -0.1966,  0.6083, -0.5636,  0.4389,\n                       0.4036, -0.1270, -0.8223,  0.0600,  0.0596, -0.1677,  0.5905, -0.0665],\n                     dtype=torch.float64)),\n             ('6.5.convpath.0.2.1.running_var',\n              tensor([0.1397, 0.5604, 0.1581, 0.3884, 0.3366, 0.2859, 0.3670, 0.4328, 0.2415,\n                      0.3887, 0.2474, 0.4844, 0.1749, 0.1436, 0.4473, 0.3128, 0.3727, 0.1979,\n                      0.2311, 0.4493, 0.3325, 0.3443, 0.3211, 0.4673, 0.5442, 0.3565, 0.3445,\n                      0.3611, 0.3431, 0.2579, 0.3480, 0.5796, 0.3409, 0.2687, 0.4687, 0.4586,\n                      0.3769, 0.1463, 0.3254, 0.4541, 0.3221, 0.4925, 0.2308, 0.6912, 0.2945,\n                      0.3488, 0.4200, 0.1980, 0.7530, 0.3342, 0.2181, 0.3332, 0.2866, 0.5371,\n                      0.4247, 0.3883, 0.3121, 0.2710, 0.4582, 0.2523, 0.3140, 0.0775, 0.3054,\n                      0.1081, 0.7139, 0.4092, 0.2880, 0.5081, 0.3732, 0.5536, 0.2296, 0.2827,\n                      0.2353, 0.5687, 0.4606, 0.3634, 0.1712, 0.1268, 0.6385, 0.3082, 0.3096,\n                      0.1579, 0.4247, 0.2575, 0.4443, 0.7131, 0.5025, 0.3626, 0.4818, 0.4804,\n                      0.3684, 0.4124, 0.2857, 0.2290, 0.4815, 0.2078, 0.3984, 0.1389, 0.1876,\n                      0.4210, 0.3745, 0.3359, 0.2730, 0.2130, 0.3158, 0.1287, 0.4849, 0.5211,\n                      0.2518, 0.3471, 0.1475, 0.3549, 0.5391, 0.4179, 0.5497, 0.5160, 0.4492,\n                      0.5797, 0.2222, 0.3421, 0.3285, 0.3419, 0.3883, 0.4151, 0.2998, 0.6282,\n                      0.2886, 0.4031, 0.2554, 0.4954, 0.1408, 0.2014, 0.4737, 0.1443, 0.1878,\n                      0.4274, 0.2010, 0.2830, 0.3303, 0.2659, 0.3211, 0.3447, 0.3757, 0.2542,\n                      0.1635, 0.4201, 0.3199, 0.6092, 0.3950, 0.3346, 0.4007, 0.1630, 0.2453,\n                      0.4922, 0.2011, 0.1639, 0.2569, 0.2182, 0.3577, 0.1246, 0.2104, 0.2572,\n                      0.3045, 0.3355, 0.7313, 0.5353, 0.5047, 0.1876, 0.2742, 0.3983, 0.3997,\n                      0.2635, 0.2337, 0.2416, 0.3575, 0.7485, 0.3279, 0.6272, 0.1778, 0.3045,\n                      0.2869, 0.1915, 0.4269, 0.3705, 0.2517, 0.4039, 0.4680, 0.0831, 0.4340,\n                      0.3152, 0.3870, 0.3992, 0.4045, 0.4737, 0.3611, 0.6323, 0.2540, 0.5208,\n                      0.5764, 0.4656, 0.1827, 0.3169, 0.3335, 0.4904, 0.1990, 0.2878, 0.3710,\n                      0.0941, 0.1493, 0.4490, 0.2366, 0.2705, 0.4054, 0.5103, 0.3166, 0.2974,\n                      0.2964, 0.4758, 0.2610, 0.3913, 0.3401, 0.1990, 0.1937, 0.4235, 0.5163,\n                      0.2335, 0.2796, 0.2841, 0.6113, 0.3644, 0.3823, 0.3750, 0.2662, 0.3206,\n                      0.1455, 0.3110, 0.3324, 0.3319, 0.3935, 0.0495, 0.5328, 0.2288, 0.2699,\n                      0.2181, 0.3549, 0.3519, 0.2817, 0.5131, 0.1355, 0.5481, 0.3814, 0.4090,\n                      0.1956, 0.3608, 0.3629, 0.3920], dtype=torch.float64)),\n             ('6.5.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.6.convs.0.0.weight',\n              tensor([[[ 0.0720],\n                       [-0.0094],\n                       [-0.1010],\n                       ...,\n                       [ 0.1000],\n                       [ 0.0120],\n                       [-0.0529]],\n              \n                      [[ 0.1434],\n                       [-0.0673],\n                       [ 0.0486],\n                       ...,\n                       [-0.1109],\n                       [-0.1072],\n                       [ 0.1523]],\n              \n                      [[-0.0274],\n                       [ 0.1305],\n                       [ 0.0422],\n                       ...,\n                       [-0.0935],\n                       [-0.0277],\n                       [ 0.0125]],\n              \n                      ...,\n              \n                      [[-0.1152],\n                       [-0.0443],\n                       [-0.0328],\n                       ...,\n                       [-0.0579],\n                       [-0.0156],\n                       [ 0.1178]],\n              \n                      [[-0.0496],\n                       [-0.0590],\n                       [ 0.0376],\n                       ...,\n                       [ 0.0064],\n                       [ 0.1038],\n                       [ 0.0570]],\n              \n                      [[-0.1157],\n                       [-0.0080],\n                       [-0.0244],\n                       ...,\n                       [-0.0049],\n                       [ 0.0876],\n                       [-0.0689]]], dtype=torch.float64)),\n             ('6.6.convs.0.1.weight',\n              tensor([0.9826, 0.9772, 0.9700, 0.9727, 0.9657, 0.9871, 0.9391, 0.9691, 0.9602,\n                      0.9748, 0.9704, 0.9805, 0.9726, 0.9909, 0.9539, 0.9664, 0.9866, 0.9800,\n                      0.9819, 0.9663, 0.9648, 0.9647, 0.9416, 0.9658, 0.9527, 0.9633, 0.9816,\n                      0.9760, 0.9636, 0.9700, 0.9716, 0.9836, 0.9796, 0.9682, 0.9812, 0.9931,\n                      0.9679, 0.9763, 0.9484, 0.9725, 0.9796, 0.9580, 0.9717, 0.9802, 0.9836,\n                      0.9641, 0.9605, 0.9794, 0.9662, 0.9130, 0.9730, 0.9883, 0.9619, 0.9754,\n                      0.9722, 0.9628, 0.9688, 0.9820, 0.9741, 0.9555, 1.0019, 0.9815, 0.9846,\n                      0.9716], dtype=torch.float64)),\n             ('6.6.convs.0.1.bias',\n              tensor([ 7.9298e-03, -1.6504e-02, -3.5259e-03,  8.8641e-03,  1.7394e-02,\n                       1.4577e-02,  1.8607e-02,  2.6071e-02, -5.6859e-03,  9.7278e-04,\n                      -6.0344e-05,  1.3699e-02, -3.1433e-04,  1.9214e-03, -9.2234e-03,\n                       2.1870e-02,  1.6561e-03, -1.0894e-03, -5.4873e-03,  5.9783e-03,\n                      -1.8316e-03, -1.3388e-02, -1.1787e-02, -1.6116e-02,  1.4448e-02,\n                       1.8852e-02,  4.0475e-03,  1.3361e-02, -7.5687e-05, -1.4079e-02,\n                       9.5640e-03,  3.3048e-04, -5.6489e-03,  6.7681e-03, -4.4522e-03,\n                       1.4801e-02,  5.8675e-03,  8.8917e-03, -7.7835e-03,  7.5822e-03,\n                       1.1792e-02,  9.3591e-03,  5.2178e-03, -5.7296e-03, -2.4171e-03,\n                      -6.0555e-03,  5.0466e-03,  1.2532e-02, -1.7809e-02, -1.4765e-02,\n                      -8.9848e-03,  2.1055e-02, -1.7801e-02,  1.3745e-02,  1.5941e-02,\n                      -5.0243e-03, -1.1437e-02,  8.0832e-03,  1.8227e-03, -5.4222e-04,\n                       1.0704e-03, -3.4518e-03,  4.0056e-03, -6.6958e-03],\n                     dtype=torch.float64)),\n             ('6.6.convs.0.1.running_mean',\n              tensor([-5.6386e-01,  1.8281e-01,  7.2954e-01, -3.3039e-02, -2.1434e-01,\n                      -1.2662e-01, -2.0595e-01,  8.2226e-01,  5.4904e-01,  6.2270e-01,\n                      -1.0588e-01, -2.1881e-01,  6.6683e-01, -1.2798e+00, -1.1339e+00,\n                      -3.1620e-01,  5.2261e-01,  6.9635e-01,  3.8158e-01, -2.8051e-01,\n                       8.0299e-01,  2.6366e-02, -3.3314e-01, -3.3491e-01, -4.9945e-01,\n                      -6.3491e-01,  1.1841e-01,  2.2493e-01, -1.9744e-01, -1.4084e-03,\n                       3.7567e-01,  4.7048e-01, -1.5414e-01,  3.9710e-01,  5.0011e-01,\n                       3.0139e-01, -6.0198e-01, -6.1613e-01, -1.2172e-01,  2.9172e-01,\n                       1.0950e-01, -2.6238e-01,  1.6658e-02, -7.5101e-02, -2.1099e-01,\n                      -2.7900e-01, -2.6838e-01, -5.8714e-01, -6.6472e-02, -8.8720e-01,\n                       4.6803e-01, -7.0157e-01,  1.1955e+00, -4.4172e-01,  5.7278e-01,\n                      -5.2594e-01,  2.3816e-01,  7.0732e-01, -5.6742e-01,  1.1930e+00,\n                      -2.5621e-01,  1.0853e+00,  5.9320e-04,  2.5558e-01],\n                     dtype=torch.float64)),\n             ('6.6.convs.0.1.running_var',\n              tensor([0.1344, 0.1037, 0.5204, 0.1305, 0.2575, 0.1384, 0.5168, 0.2509, 0.3951,\n                      0.4697, 0.3493, 0.1233, 0.6185, 0.1642, 0.1972, 0.2624, 0.3477, 0.1635,\n                      0.1538, 0.0900, 0.1854, 0.2579, 0.6624, 0.1611, 0.1252, 0.8599, 0.1259,\n                      0.1824, 0.1261, 0.1542, 0.8356, 0.5019, 0.1304, 0.6070, 0.1847, 0.1582,\n                      0.3802, 0.1243, 0.5342, 0.2432, 0.1892, 0.2450, 0.1238, 0.1986, 0.2761,\n                      0.5502, 0.3316, 0.2970, 0.1454, 0.9366, 0.1110, 0.0889, 1.0770, 0.2308,\n                      0.4746, 0.4266, 0.0977, 0.3190, 0.1882, 0.8624, 0.1912, 0.7865, 0.1631,\n                      0.2162], dtype=torch.float64)),\n             ('6.6.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.6.convs.1.0.weight',\n              tensor([[[-3.0066e-02, -5.6900e-02,  1.3447e-02,  6.1007e-02, -2.6408e-02],\n                       [ 1.1721e-01,  3.3434e-02, -1.4350e-01, -1.6413e-01, -1.4629e-02],\n                       [-3.3599e-02, -1.1788e-01,  4.2745e-02,  3.7840e-02,  5.7515e-02],\n                       ...,\n                       [ 4.2689e-03,  5.0576e-02,  4.5614e-02, -2.5400e-03,  1.0311e-01],\n                       [-4.6757e-03,  1.2800e-01, -5.6342e-02,  1.1039e-01, -4.3900e-02],\n                       [ 1.3013e-02,  3.2805e-02, -2.8255e-02,  9.8206e-02,  4.0276e-02]],\n              \n                      [[ 3.4694e-02, -1.0677e-02,  5.0294e-02, -3.3899e-02, -4.5415e-02],\n                       [-1.7111e-02, -1.2753e-01, -4.6275e-02,  4.6827e-02, -4.5796e-02],\n                       [-9.6119e-02,  2.5448e-03, -1.5157e-02, -3.9769e-02, -5.2438e-02],\n                       ...,\n                       [-5.1422e-02,  6.8168e-02, -3.5461e-03, -5.2400e-02, -1.8855e-02],\n                       [-4.0516e-02,  2.9087e-02,  2.4410e-02,  8.6184e-02, -3.8822e-02],\n                       [-4.7646e-02, -1.5557e-02, -1.2592e-01, -7.2508e-02,  3.7539e-03]],\n              \n                      [[ 5.7398e-02, -8.8282e-03, -2.5414e-02, -4.0253e-02, -1.2181e-01],\n                       [-2.6151e-02,  1.7202e-02,  6.7190e-02, -8.9942e-02,  6.8232e-02],\n                       [-9.3214e-02,  2.7760e-03, -1.2508e-01, -5.3354e-02,  7.7526e-02],\n                       ...,\n                       [-2.8325e-02,  2.6915e-02, -1.0678e-01,  6.3290e-03, -6.3431e-02],\n                       [ 4.3636e-02,  4.1843e-03,  7.8167e-02, -1.2920e-01, -3.5783e-02],\n                       [ 8.8036e-02, -3.9806e-02, -5.0515e-02, -6.3694e-02, -1.1527e-01]],\n              \n                      ...,\n              \n                      [[-1.0272e-01, -6.3537e-02, -7.3089e-02,  9.1197e-02,  8.4952e-02],\n                       [ 1.6513e-02,  6.2077e-02, -1.1859e-02, -1.1128e-01, -1.1729e-01],\n                       [ 2.7044e-02,  4.0231e-02,  1.3083e-01,  5.9207e-02, -4.5925e-02],\n                       ...,\n                       [-1.5532e-02,  7.5583e-03, -4.4415e-02, -5.0363e-02, -8.7583e-02],\n                       [-4.4164e-02,  1.9960e-01, -6.2176e-03,  3.8471e-02,  1.0878e-01],\n                       [-5.8840e-02,  4.9365e-03, -5.0204e-02, -7.9948e-02,  2.7359e-02]],\n              \n                      [[-3.6332e-02,  5.3392e-02,  3.7117e-02,  1.1546e-02, -5.2246e-02],\n                       [ 1.9101e-01,  1.5129e-01,  2.9943e-03,  3.1230e-02, -4.3205e-02],\n                       [ 3.1995e-03,  1.4586e-01, -8.6100e-03, -2.8414e-02,  4.1754e-02],\n                       ...,\n                       [-1.8093e-01,  7.8644e-02,  1.3567e-01, -6.4919e-02, -1.0376e-01],\n                       [ 2.4963e-02,  4.6311e-02, -6.4594e-02, -1.2299e-01, -1.9182e-02],\n                       [ 5.3916e-02, -1.4304e-02,  1.3473e-02, -1.0688e-01, -6.1820e-02]],\n              \n                      [[ 3.8470e-02,  9.1451e-02,  1.3491e-01,  1.0883e-01,  1.4127e-02],\n                       [-7.3971e-02,  7.8095e-02,  1.6060e-02,  1.1769e-02, -2.1140e-03],\n                       [-9.0929e-02,  1.9203e-02, -2.6688e-02, -2.2390e-01,  3.8489e-03],\n                       ...,\n                       [-1.9679e-01, -4.6309e-02, -4.9521e-02, -4.8222e-02,  1.0800e-01],\n                       [ 6.9955e-04,  7.6519e-02, -6.4069e-02,  1.7861e-02,  1.0596e-01],\n                       [ 4.5725e-02, -7.9735e-02,  1.1775e-04, -3.5031e-02, -2.8898e-02]]],\n                     dtype=torch.float64)),\n             ('6.6.convs.1.1.weight',\n              tensor([0.9680, 0.9587, 0.9682, 0.9753, 0.9702, 0.9587, 0.9913, 0.9515, 0.9494,\n                      0.9544, 0.9475, 0.9881, 0.9767, 0.9523, 0.9459, 1.0162, 0.9399, 0.9699,\n                      0.9474, 0.9757, 0.9637, 0.9530, 0.9710, 0.9687, 0.9377, 0.9752, 0.9835,\n                      0.9622, 1.0168, 0.9539, 0.9566, 0.9384, 0.9664, 0.9498, 0.9305, 0.9308,\n                      0.9792, 0.9477, 0.9717, 0.9467, 0.9542, 0.9583, 0.9872, 0.9404, 0.9615,\n                      0.9669, 0.9855, 0.9583, 0.9749, 0.9724, 0.9795, 0.9752, 0.9532, 0.9597,\n                      0.9783, 0.9754, 0.9642, 0.9502, 0.9550, 0.9724, 0.9720, 1.0049, 0.9688,\n                      0.9859], dtype=torch.float64)),\n             ('6.6.convs.1.1.bias',\n              tensor([-0.0200,  0.0029,  0.0066, -0.0192, -0.0032, -0.0082,  0.0130, -0.0154,\n                      -0.0034, -0.0145, -0.0106,  0.0144,  0.0066,  0.0024, -0.0312,  0.0195,\n                      -0.0150,  0.0093,  0.0137, -0.0142, -0.0120, -0.0225,  0.0153,  0.0027,\n                      -0.0078,  0.0028,  0.0080,  0.0108,  0.0297, -0.0121,  0.0145, -0.0138,\n                      -0.0132, -0.0116, -0.0212, -0.0114, -0.0149, -0.0134, -0.0005, -0.0060,\n                      -0.0307,  0.0186,  0.0178, -0.0115,  0.0013, -0.0180,  0.0138,  0.0062,\n                       0.0083,  0.0159, -0.0168,  0.0167, -0.0120,  0.0249, -0.0004, -0.0107,\n                      -0.0067,  0.0013, -0.0002,  0.0105, -0.0129,  0.0251, -0.0005,  0.0140],\n                     dtype=torch.float64)),\n             ('6.6.convs.1.1.running_mean',\n              tensor([ 0.0941, -0.7252, -0.4760,  0.2748, -0.1647, -0.4858, -0.8490, -0.1793,\n                      -0.0227, -0.2179, -0.1825, -0.5824,  0.0095, -0.1535,  0.3272,  0.1869,\n                       0.0271,  0.2549, -0.5281,  0.4292,  0.4128,  1.4082,  0.5958, -0.8053,\n                      -0.6850, -0.3657, -0.3949, -0.3225, -0.3130,  0.0400, -0.2220, -0.0674,\n                      -0.1557,  0.2255, -1.0208, -0.1347,  0.4071, -1.0269, -0.2208, -0.2801,\n                       0.3742, -0.6952, -0.8007, -0.6675, -0.8257,  0.4606, -0.6977, -0.9755,\n                      -0.3626,  0.1859,  0.1783,  0.6324,  0.3196, -0.4582,  0.1397,  0.8500,\n                       0.4893, -0.3193, -0.2917, -0.3238,  0.5035, -0.2844,  0.3407, -1.3248],\n                     dtype=torch.float64)),\n             ('6.6.convs.1.1.running_var',\n              tensor([0.6036, 0.7538, 0.5866, 0.6633, 0.5593, 0.6855, 0.4369, 0.5545, 0.4075,\n                      0.7970, 1.0802, 0.5327, 0.5672, 0.5359, 0.5905, 0.5326, 0.4028, 0.6563,\n                      0.7827, 0.7444, 0.7562, 1.6093, 0.7848, 0.5746, 0.6527, 0.3406, 0.6831,\n                      0.4689, 0.5869, 0.9397, 0.6967, 0.8706, 0.7356, 1.5085, 0.8688, 0.9156,\n                      0.6068, 0.7849, 0.6778, 0.6203, 0.7855, 0.6776, 0.4891, 0.9342, 0.5915,\n                      0.5578, 0.3665, 0.9074, 0.5117, 0.4519, 0.5025, 0.7112, 0.7933, 0.9678,\n                      0.5106, 0.6453, 0.5198, 0.9181, 0.8019, 0.5727, 0.4667, 0.4739, 0.9411,\n                      1.4261], dtype=torch.float64)),\n             ('6.6.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.6.convs.2.0.weight',\n              tensor([[[-0.1595],\n                       [-0.0641],\n                       [ 0.0956],\n                       ...,\n                       [-0.0179],\n                       [-0.0835],\n                       [-0.0037]],\n              \n                      [[-0.0488],\n                       [-0.1028],\n                       [ 0.0146],\n                       ...,\n                       [-0.0451],\n                       [ 0.0322],\n                       [-0.1033]],\n              \n                      [[-0.0319],\n                       [ 0.0127],\n                       [-0.0140],\n                       ...,\n                       [-0.1225],\n                       [ 0.0479],\n                       [-0.0291]],\n              \n                      ...,\n              \n                      [[ 0.1646],\n                       [-0.0141],\n                       [-0.1006],\n                       ...,\n                       [ 0.1497],\n                       [ 0.0020],\n                       [ 0.1797]],\n              \n                      [[-0.0715],\n                       [ 0.0449],\n                       [ 0.0487],\n                       ...,\n                       [ 0.1228],\n                       [-0.0075],\n                       [-0.0247]],\n              \n                      [[ 0.0327],\n                       [ 0.0197],\n                       [-0.0633],\n                       ...,\n                       [ 0.1074],\n                       [-0.0077],\n                       [-0.0439]]], dtype=torch.float64)),\n             ('6.6.convs.2.1.weight',\n              tensor([ 1.0150e-02, -6.9185e-03,  1.3713e-02, -1.0232e-02,  8.5891e-03,\n                       8.5662e-04,  9.6463e-04,  2.7952e-02, -2.0439e-02, -3.2038e-02,\n                      -1.0341e-02, -2.8828e-02, -2.2906e-03,  6.5147e-03, -8.0612e-03,\n                       3.3665e-02, -1.1520e-02, -1.2285e-02, -2.7464e-03, -3.0818e-02,\n                       1.5915e-02, -2.1413e-02,  9.2876e-03, -5.6457e-03, -2.5190e-02,\n                      -8.6980e-04, -2.2414e-02,  1.5891e-02,  1.0181e-02,  4.0825e-03,\n                      -4.9613e-03,  1.1755e-02,  9.6195e-03, -3.5012e-03,  5.8914e-04,\n                       1.1283e-02,  5.2637e-03,  8.8263e-03,  2.2464e-02, -1.7061e-03,\n                       2.9880e-03,  2.7630e-03, -1.4922e-02, -7.2432e-04,  1.6037e-03,\n                       5.6718e-03, -4.7779e-03,  1.6763e-02, -8.7895e-03,  3.4771e-02,\n                      -8.6616e-03,  9.0280e-03,  9.4141e-03, -1.2205e-02, -1.8254e-02,\n                       3.6123e-02,  1.7818e-03, -3.3514e-02,  1.9809e-02, -1.1498e-02,\n                       8.8276e-03, -1.6572e-02,  1.7389e-03, -1.5630e-02, -2.8822e-02,\n                       2.2343e-02,  9.8016e-04,  2.2395e-02, -2.5321e-02,  3.7378e-02,\n                      -3.1880e-02,  7.3242e-03,  8.9524e-03, -1.1022e-03, -7.9567e-03,\n                      -8.1209e-03,  7.4155e-03,  1.6137e-02,  8.0900e-03, -1.1796e-02,\n                      -2.4412e-02, -8.7004e-03,  7.8374e-03,  8.5154e-03,  3.3320e-02,\n                       1.3653e-03,  1.2235e-02,  1.1917e-02, -1.4693e-02,  2.4134e-02,\n                      -2.6067e-03, -1.4748e-02, -3.9695e-02, -6.8339e-03,  6.2063e-03,\n                      -8.9520e-03,  2.3766e-02, -4.2868e-03, -2.2400e-02,  1.4393e-02,\n                      -1.2527e-03,  1.2413e-02,  2.4075e-02, -2.0689e-02, -1.4978e-02,\n                       1.4390e-02,  1.8197e-02, -5.8271e-03,  2.8548e-02, -8.4787e-04,\n                       9.0904e-03,  1.6414e-02, -2.4509e-03, -3.3220e-02, -2.8567e-02,\n                       2.0956e-02, -5.7126e-03,  1.2938e-02, -6.8211e-04, -3.5662e-03,\n                       2.7866e-02,  1.7067e-02, -2.7390e-04,  1.6938e-02, -1.1377e-02,\n                      -9.3527e-03, -3.1341e-02, -1.3731e-03, -9.3574e-03,  1.1817e-02,\n                       1.2659e-02,  3.7606e-02, -1.3645e-03, -1.9714e-02, -1.1301e-02,\n                      -3.3656e-03,  1.2442e-03,  2.0660e-02,  4.1279e-03,  5.7126e-03,\n                       6.4018e-03, -6.6275e-03,  9.6259e-03, -2.4736e-02,  6.8314e-03,\n                      -8.6778e-03,  8.6942e-03, -9.4880e-03, -1.9828e-02,  3.7420e-03,\n                      -4.4454e-03,  1.6157e-02,  3.2540e-03,  1.0921e-02,  1.1020e-02,\n                       1.3300e-02, -1.1635e-02, -3.0415e-02,  1.2797e-02, -2.3762e-04,\n                      -2.1016e-02, -5.7868e-03,  3.4032e-03,  1.8778e-02,  2.3184e-02,\n                       1.7988e-02,  1.8516e-03,  1.7287e-02,  8.5864e-03,  3.8996e-02,\n                      -9.1970e-03, -1.2124e-02,  1.0203e-02,  2.2397e-03,  1.3022e-02,\n                      -1.0346e-02, -1.0479e-02,  5.5608e-05,  1.5299e-02,  1.1594e-02,\n                       1.1107e-02,  1.0029e-02, -1.5271e-02,  1.2404e-03, -3.0976e-03,\n                      -1.7444e-02, -4.4170e-03, -1.4255e-02,  6.4446e-03,  1.7522e-02,\n                      -1.6760e-02, -1.3052e-02,  2.0311e-02, -1.4137e-02, -1.4519e-02,\n                       7.5137e-03, -8.7557e-03,  2.2173e-02,  2.5515e-02, -1.2209e-02,\n                      -6.2720e-03,  2.4393e-02,  1.8483e-03, -1.5753e-02,  3.3581e-03,\n                       4.6281e-03,  4.5554e-02, -2.5611e-02,  9.6270e-04, -2.1001e-02,\n                      -5.6559e-03,  4.5710e-03,  1.1246e-03, -3.6671e-02,  6.7719e-03,\n                      -1.8243e-02, -5.3325e-03, -5.1157e-03,  2.0348e-02, -1.6542e-02,\n                       4.7618e-03,  1.1616e-02,  4.1344e-03,  1.6350e-02,  1.5259e-02,\n                       9.5261e-03,  9.6563e-03,  1.9315e-02, -5.9309e-04, -3.2346e-02,\n                       1.3660e-03,  9.9181e-03, -6.4819e-03,  2.3366e-02, -8.9760e-03,\n                      -7.7267e-03,  1.2651e-02,  1.1246e-02, -1.8028e-02, -8.1925e-03,\n                      -1.1697e-02,  1.0043e-02,  9.9266e-04,  5.6365e-03, -1.3458e-02,\n                       8.5161e-03, -8.8420e-03, -1.8407e-02,  4.4380e-03, -2.8718e-02,\n                      -1.1123e-02, -1.9702e-02, -2.6554e-03, -2.2865e-02, -2.9003e-03,\n                       5.3596e-05], dtype=torch.float64)),\n             ('6.6.convs.2.1.bias',\n              tensor([-8.3792e-04,  3.4520e-03,  1.3210e-02,  1.5723e-02,  8.9322e-04,\n                       4.7988e-03,  1.1738e-02,  1.7120e-03,  2.2046e-03,  2.2611e-02,\n                       1.4390e-02, -7.9868e-03,  8.1139e-03, -4.6840e-03,  1.1887e-02,\n                       4.0100e-03,  2.1283e-02, -2.5542e-03,  1.3014e-02, -7.5277e-03,\n                      -2.8608e-03,  3.0322e-03,  7.0995e-04,  6.4781e-03, -7.5706e-03,\n                      -1.5647e-02,  3.4617e-03,  8.4863e-03,  5.8509e-04, -2.2938e-03,\n                       3.9236e-03,  8.7355e-03, -9.6032e-03,  1.8149e-02,  1.2896e-02,\n                       1.4812e-02, -3.0728e-03,  1.9824e-02,  6.2865e-03,  1.5273e-02,\n                      -1.2278e-03,  2.3988e-02, -2.9701e-03,  1.8631e-03,  3.4217e-03,\n                      -9.0559e-03,  1.1670e-02,  5.8815e-03, -1.1538e-02,  1.3021e-02,\n                       8.1819e-03,  9.5104e-03,  9.6971e-03,  1.1133e-02,  4.3198e-03,\n                       1.6471e-02,  7.3368e-03,  3.1255e-03,  6.2823e-03,  2.9483e-03,\n                      -1.7716e-03,  2.8475e-03,  4.9976e-03,  8.9434e-03, -4.0464e-03,\n                       1.0568e-02, -1.2458e-02,  1.6330e-02, -4.7043e-03, -1.1872e-02,\n                       2.5532e-03,  5.8576e-03,  1.6502e-03, -7.1843e-03,  1.4609e-02,\n                      -1.0920e-03,  3.3231e-03,  1.3520e-03,  5.0737e-03,  1.7698e-03,\n                       1.0323e-02, -5.8991e-03,  8.2852e-03,  4.0855e-03, -4.8411e-03,\n                       1.2181e-02, -5.5207e-04,  6.4295e-04,  1.3395e-02,  6.5983e-03,\n                      -8.4500e-04,  1.4904e-02,  1.4938e-02, -3.0558e-03,  9.2375e-03,\n                      -1.1740e-02,  6.1342e-03,  2.4766e-03,  1.1535e-02, -2.3214e-03,\n                       1.9170e-02,  1.4898e-03,  5.9829e-03, -4.9193e-04,  1.1518e-02,\n                       5.8428e-04,  1.3346e-03,  3.2009e-03,  4.6381e-03,  8.4240e-03,\n                      -7.3728e-03, -7.3230e-03,  5.0754e-03,  2.0944e-02,  1.1596e-02,\n                       6.6018e-03,  9.5287e-03,  2.8527e-05,  3.4567e-03, -1.4839e-02,\n                      -1.6093e-05,  8.0401e-03, -1.8009e-03, -2.7852e-03, -1.1983e-02,\n                       1.0376e-02,  1.4491e-02,  5.2070e-03,  2.4162e-03,  1.6354e-02,\n                       2.3329e-02,  1.5196e-02,  1.4868e-02,  6.6737e-03,  1.5523e-02,\n                      -6.6983e-03,  1.5797e-02,  9.1371e-03,  1.0598e-02,  8.8044e-03,\n                       1.4434e-02, -3.7489e-03,  1.6393e-02,  6.3892e-03, -7.3140e-03,\n                       1.3741e-02,  3.0642e-03, -1.2913e-03,  8.9991e-03,  9.0917e-03,\n                       6.3211e-03,  1.3197e-02,  1.3214e-02,  1.3775e-02,  1.5297e-02,\n                       9.1409e-03,  1.2826e-03,  7.1325e-03, -1.7783e-03, -1.0423e-02,\n                       4.9193e-03, -4.8071e-03,  6.3248e-04,  1.1793e-02,  1.0697e-02,\n                       1.2110e-04, -8.8667e-03,  1.1457e-02,  9.8033e-04,  1.6094e-02,\n                       6.3129e-03,  7.3345e-03,  1.1404e-02,  1.0406e-02, -1.3451e-02,\n                       2.7757e-03, -6.2231e-04,  1.2838e-02,  3.7241e-03,  4.1717e-03,\n                      -3.1890e-03,  1.1061e-02, -8.1519e-03, -9.0768e-03,  1.9833e-02,\n                       7.4087e-03,  1.3363e-02,  1.0722e-02,  2.6543e-03,  2.6333e-03,\n                       6.1325e-03,  2.3526e-03,  9.8704e-03, -8.1245e-03,  2.4701e-03,\n                       6.2251e-03, -5.2993e-03,  1.9476e-02,  8.3589e-03,  5.9339e-03,\n                       3.2769e-03,  2.1492e-02,  1.9525e-02,  1.6423e-02,  4.3670e-04,\n                      -1.3728e-03,  1.6720e-02, -4.0052e-03,  8.9128e-03,  1.1261e-02,\n                      -1.2157e-03,  1.1640e-02,  1.4352e-02,  8.0657e-03,  1.5759e-02,\n                       4.1711e-04,  4.2417e-03, -5.3075e-03,  2.3169e-03, -3.7946e-04,\n                      -1.4252e-02,  3.1344e-03,  5.3142e-03,  1.8019e-02, -4.9953e-03,\n                       4.4637e-03, -3.0559e-03,  1.8502e-03, -1.4347e-02,  1.4490e-02,\n                       8.4647e-03, -1.7278e-03,  1.1873e-02,  6.4378e-03,  2.3101e-03,\n                       6.9338e-03,  7.6796e-03, -8.8597e-03,  9.5387e-03,  8.5499e-03,\n                       1.8392e-03,  3.9479e-03,  5.1607e-03,  8.0653e-03, -2.6380e-04,\n                       1.4907e-02,  1.1049e-04,  9.7957e-03,  3.1189e-03, -8.3708e-03,\n                       1.7591e-02,  1.8614e-02,  1.5490e-02,  1.6420e-02,  9.7842e-03,\n                       5.4413e-03], dtype=torch.float64)),\n             ('6.6.convs.2.1.running_mean',\n              tensor([ 0.0484, -0.1926,  0.1816,  0.3316, -0.2590,  0.1854, -0.2528, -0.6604,\n                      -0.2257,  0.1922,  0.4257, -0.4847,  0.0887,  0.0806, -0.1255, -0.1654,\n                       0.2206,  0.0214, -0.0264,  0.3489, -0.4619,  0.4529,  0.4506,  0.1608,\n                       0.7995,  0.1404,  0.0711,  0.1421,  0.1377,  0.5238, -0.1551,  0.0569,\n                      -0.1907,  0.4104,  0.1761,  0.7142, -0.2240, -0.2415,  0.1952, -0.2565,\n                      -0.3931, -0.2128,  0.1391,  0.0065,  0.3877, -0.6508, -0.1919,  0.0340,\n                       0.5002, -0.0274,  0.0931,  0.0895,  0.5043,  0.4762, -0.6238,  0.2767,\n                      -0.1511, -0.2778,  0.3921,  0.2665, -0.0646,  0.2660,  0.5649, -0.2741,\n                       0.6009,  0.1316, -0.1592,  0.2648, -0.3628,  0.1258,  0.2464,  0.0032,\n                       0.6792, -0.5942, -0.1350, -0.3891,  0.4269, -0.2334,  0.2270,  0.1406,\n                      -0.5591, -0.6412, -0.2204, -0.5344,  0.1413,  0.2465,  0.1378, -0.2565,\n                      -0.4705, -0.0973,  0.1844, -0.3962, -0.3606, -0.7851,  0.0963, -0.1701,\n                      -0.5814,  0.1935, -0.8287, -0.0381, -0.1375,  0.2189, -0.4572,  0.6118,\n                      -0.1344,  0.0932, -0.0333,  0.1850, -0.2961, -0.0506, -0.4222,  0.3416,\n                       0.1064, -0.0942, -0.1910, -0.5448, -0.1406, -0.2246, -0.4124, -0.1428,\n                      -0.2938,  0.1961,  0.1663,  0.2322,  0.2626, -0.2882,  0.1910,  0.1147,\n                       0.5079, -0.3926,  0.4819,  0.4328, -0.2235,  0.0330,  0.0825,  0.2507,\n                      -0.2024, -0.2794, -0.3877,  0.0224,  0.0988,  0.2233,  0.0967,  0.3191,\n                      -0.0405,  0.1969,  0.0536, -0.7023,  0.0902,  0.1065, -0.5438, -0.5041,\n                      -0.4060, -0.6975,  0.3338,  0.1671, -0.3657, -0.0663,  0.4046, -0.2703,\n                      -0.2009, -0.1549,  0.0495,  0.0402, -0.0366,  0.5080,  0.9068, -0.2483,\n                       0.1388, -0.1797, -0.2635, -0.4339, -0.0016, -0.0620,  0.4554, -0.3511,\n                       0.6290, -0.0385, -0.3367, -0.2932,  0.6035,  0.6757, -1.0276, -0.2959,\n                       0.0119,  0.6055,  0.2138,  0.4180, -0.0505,  0.0391,  0.4353,  0.3378,\n                       0.0899, -0.4953,  0.1470,  0.0720, -0.1669, -0.0405, -0.3347,  0.1149,\n                       0.5975,  0.2934, -0.1084, -0.5374, -0.4014,  0.1703,  0.2183, -0.1230,\n                      -0.3695,  0.4564,  0.2788, -0.1397,  0.0234, -0.0727,  0.7962, -0.1117,\n                       0.4427,  0.0702, -0.8673,  0.3666, -0.2168, -0.3573,  0.3964, -0.3970,\n                      -0.0211,  0.0339, -0.5008, -0.0428, -0.1548, -0.1057, -0.0539,  0.1592,\n                       0.7628,  0.3081, -0.1074, -0.1172,  0.3006,  0.4610,  0.1876,  0.3178,\n                      -0.2453,  0.0965, -0.1813, -0.2003, -0.2240, -0.3855, -0.0112, -0.1242,\n                      -0.2394,  0.3448, -0.0450,  0.6814, -0.0061,  0.0442, -0.0092,  0.1831],\n                     dtype=torch.float64)),\n             ('6.6.convs.2.1.running_var',\n              tensor([0.5060, 0.2928, 0.2521, 0.4997, 0.1346, 0.1000, 0.1168, 0.2703, 0.5808,\n                      0.3028, 0.2458, 0.3926, 0.1400, 0.2547, 0.4106, 0.3270, 0.3710, 0.7666,\n                      0.1764, 0.4358, 0.4899, 0.3624, 0.3437, 0.2658, 0.4583, 0.1680, 0.3590,\n                      0.2896, 0.2077, 0.1671, 0.4181, 0.5252, 0.1416, 0.2487, 0.2686, 0.4966,\n                      0.2268, 0.1677, 0.2946, 0.3562, 0.3239, 0.1804, 0.2591, 0.3475, 0.3891,\n                      0.4138, 0.4242, 0.1954, 0.8952, 0.4279, 0.1313, 0.6890, 0.4056, 0.2695,\n                      0.5453, 0.3662, 0.2550, 0.5828, 0.2958, 0.2703, 0.0883, 0.1876, 0.1781,\n                      0.4064, 0.6415, 0.6943, 0.2571, 0.3134, 0.4579, 0.6150, 0.4098, 0.6087,\n                      0.2605, 0.5889, 0.2772, 0.2720, 0.5186, 0.3161, 0.5636, 0.1956, 0.3959,\n                      0.2378, 0.2326, 0.3771, 0.4046, 0.3989, 0.2930, 0.2763, 0.3002, 0.2368,\n                      0.2471, 0.2825, 0.4424, 0.3397, 0.0973, 0.2647, 0.4230, 0.1425, 0.2961,\n                      0.5732, 0.2965, 0.3911, 0.4025, 0.5569, 0.3308, 0.2962, 0.4059, 0.2956,\n                      0.2929, 0.1580, 0.2754, 0.5503, 0.2243, 0.2799, 0.3702, 0.5863, 0.2564,\n                      0.3825, 0.2024, 0.5363, 0.2963, 0.3553, 0.1630, 0.4539, 0.2036, 0.7385,\n                      0.1736, 0.0701, 0.3150, 0.3583, 0.2097, 0.3979, 0.3020, 0.7779, 0.2743,\n                      0.1458, 0.0742, 0.1964, 0.1535, 0.1818, 0.1685, 0.0873, 0.3572, 0.5351,\n                      0.2114, 0.4553, 0.1298, 0.7119, 0.2393, 0.3721, 0.4882, 0.3819, 0.1922,\n                      0.5164, 0.4325, 0.2892, 0.2629, 0.2532, 0.3939, 0.2186, 0.5735, 0.2830,\n                      0.2749, 0.3364, 0.5277, 0.4928, 0.4210, 0.3123, 0.3560, 0.3859, 0.2993,\n                      0.1585, 0.4988, 0.2331, 0.4092, 0.4772, 0.2176, 0.2631, 0.5189, 0.2200,\n                      0.4529, 0.3984, 0.4933, 0.1653, 0.3275, 0.4449, 0.2048, 0.2948, 0.2100,\n                      0.4726, 0.3029, 0.3962, 0.2390, 0.4861, 0.3897, 0.2782, 0.2649, 0.3535,\n                      0.2940, 0.2564, 0.2433, 0.3392, 0.1744, 0.4631, 0.2398, 0.3812, 0.2768,\n                      0.2944, 0.1773, 0.5339, 0.0971, 0.4645, 0.2403, 0.2807, 0.4763, 0.1225,\n                      0.4769, 0.2908, 0.4497, 0.5328, 0.1445, 0.3494, 0.1842, 0.3403, 0.3770,\n                      0.2697, 0.2160, 0.3205, 0.3376, 0.4268, 0.2101, 0.3005, 0.4034, 0.5217,\n                      0.2343, 0.3558, 0.2110, 0.1964, 0.5977, 0.5221, 0.6663, 0.2049, 0.4839,\n                      0.0876, 0.9857, 0.2702, 0.1396, 0.3188, 0.1138, 0.5938, 0.4612, 0.5259,\n                      0.1380, 0.3365, 0.2664, 0.0693], dtype=torch.float64)),\n             ('6.6.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.6.convpath.0.0.0.weight',\n              tensor([[[ 0.0720],\n                       [-0.0094],\n                       [-0.1010],\n                       ...,\n                       [ 0.1000],\n                       [ 0.0120],\n                       [-0.0529]],\n              \n                      [[ 0.1434],\n                       [-0.0673],\n                       [ 0.0486],\n                       ...,\n                       [-0.1109],\n                       [-0.1072],\n                       [ 0.1523]],\n              \n                      [[-0.0274],\n                       [ 0.1305],\n                       [ 0.0422],\n                       ...,\n                       [-0.0935],\n                       [-0.0277],\n                       [ 0.0125]],\n              \n                      ...,\n              \n                      [[-0.1152],\n                       [-0.0443],\n                       [-0.0328],\n                       ...,\n                       [-0.0579],\n                       [-0.0156],\n                       [ 0.1178]],\n              \n                      [[-0.0496],\n                       [-0.0590],\n                       [ 0.0376],\n                       ...,\n                       [ 0.0064],\n                       [ 0.1038],\n                       [ 0.0570]],\n              \n                      [[-0.1157],\n                       [-0.0080],\n                       [-0.0244],\n                       ...,\n                       [-0.0049],\n                       [ 0.0876],\n                       [-0.0689]]], dtype=torch.float64)),\n             ('6.6.convpath.0.0.1.weight',\n              tensor([0.9826, 0.9772, 0.9700, 0.9727, 0.9657, 0.9871, 0.9391, 0.9691, 0.9602,\n                      0.9748, 0.9704, 0.9805, 0.9726, 0.9909, 0.9539, 0.9664, 0.9866, 0.9800,\n                      0.9819, 0.9663, 0.9648, 0.9647, 0.9416, 0.9658, 0.9527, 0.9633, 0.9816,\n                      0.9760, 0.9636, 0.9700, 0.9716, 0.9836, 0.9796, 0.9682, 0.9812, 0.9931,\n                      0.9679, 0.9763, 0.9484, 0.9725, 0.9796, 0.9580, 0.9717, 0.9802, 0.9836,\n                      0.9641, 0.9605, 0.9794, 0.9662, 0.9130, 0.9730, 0.9883, 0.9619, 0.9754,\n                      0.9722, 0.9628, 0.9688, 0.9820, 0.9741, 0.9555, 1.0019, 0.9815, 0.9846,\n                      0.9716], dtype=torch.float64)),\n             ('6.6.convpath.0.0.1.bias',\n              tensor([ 7.9298e-03, -1.6504e-02, -3.5259e-03,  8.8641e-03,  1.7394e-02,\n                       1.4577e-02,  1.8607e-02,  2.6071e-02, -5.6859e-03,  9.7278e-04,\n                      -6.0344e-05,  1.3699e-02, -3.1433e-04,  1.9214e-03, -9.2234e-03,\n                       2.1870e-02,  1.6561e-03, -1.0894e-03, -5.4873e-03,  5.9783e-03,\n                      -1.8316e-03, -1.3388e-02, -1.1787e-02, -1.6116e-02,  1.4448e-02,\n                       1.8852e-02,  4.0475e-03,  1.3361e-02, -7.5687e-05, -1.4079e-02,\n                       9.5640e-03,  3.3048e-04, -5.6489e-03,  6.7681e-03, -4.4522e-03,\n                       1.4801e-02,  5.8675e-03,  8.8917e-03, -7.7835e-03,  7.5822e-03,\n                       1.1792e-02,  9.3591e-03,  5.2178e-03, -5.7296e-03, -2.4171e-03,\n                      -6.0555e-03,  5.0466e-03,  1.2532e-02, -1.7809e-02, -1.4765e-02,\n                      -8.9848e-03,  2.1055e-02, -1.7801e-02,  1.3745e-02,  1.5941e-02,\n                      -5.0243e-03, -1.1437e-02,  8.0832e-03,  1.8227e-03, -5.4222e-04,\n                       1.0704e-03, -3.4518e-03,  4.0056e-03, -6.6958e-03],\n                     dtype=torch.float64)),\n             ('6.6.convpath.0.0.1.running_mean',\n              tensor([-5.6386e-01,  1.8281e-01,  7.2954e-01, -3.3039e-02, -2.1434e-01,\n                      -1.2662e-01, -2.0595e-01,  8.2226e-01,  5.4904e-01,  6.2270e-01,\n                      -1.0588e-01, -2.1881e-01,  6.6683e-01, -1.2798e+00, -1.1339e+00,\n                      -3.1620e-01,  5.2261e-01,  6.9635e-01,  3.8158e-01, -2.8051e-01,\n                       8.0299e-01,  2.6366e-02, -3.3314e-01, -3.3491e-01, -4.9945e-01,\n                      -6.3491e-01,  1.1841e-01,  2.2493e-01, -1.9744e-01, -1.4084e-03,\n                       3.7567e-01,  4.7048e-01, -1.5414e-01,  3.9710e-01,  5.0011e-01,\n                       3.0139e-01, -6.0198e-01, -6.1613e-01, -1.2172e-01,  2.9172e-01,\n                       1.0950e-01, -2.6238e-01,  1.6658e-02, -7.5101e-02, -2.1099e-01,\n                      -2.7900e-01, -2.6838e-01, -5.8714e-01, -6.6472e-02, -8.8720e-01,\n                       4.6803e-01, -7.0157e-01,  1.1955e+00, -4.4172e-01,  5.7278e-01,\n                      -5.2594e-01,  2.3816e-01,  7.0732e-01, -5.6742e-01,  1.1930e+00,\n                      -2.5621e-01,  1.0853e+00,  5.9320e-04,  2.5558e-01],\n                     dtype=torch.float64)),\n             ('6.6.convpath.0.0.1.running_var',\n              tensor([0.1344, 0.1037, 0.5204, 0.1305, 0.2575, 0.1384, 0.5168, 0.2509, 0.3951,\n                      0.4697, 0.3493, 0.1233, 0.6185, 0.1642, 0.1972, 0.2624, 0.3477, 0.1635,\n                      0.1538, 0.0900, 0.1854, 0.2579, 0.6624, 0.1611, 0.1252, 0.8599, 0.1259,\n                      0.1824, 0.1261, 0.1542, 0.8356, 0.5019, 0.1304, 0.6070, 0.1847, 0.1582,\n                      0.3802, 0.1243, 0.5342, 0.2432, 0.1892, 0.2450, 0.1238, 0.1986, 0.2761,\n                      0.5502, 0.3316, 0.2970, 0.1454, 0.9366, 0.1110, 0.0889, 1.0770, 0.2308,\n                      0.4746, 0.4266, 0.0977, 0.3190, 0.1882, 0.8624, 0.1912, 0.7865, 0.1631,\n                      0.2162], dtype=torch.float64)),\n             ('6.6.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.6.convpath.0.1.0.weight',\n              tensor([[[-3.0066e-02, -5.6900e-02,  1.3447e-02,  6.1007e-02, -2.6408e-02],\n                       [ 1.1721e-01,  3.3434e-02, -1.4350e-01, -1.6413e-01, -1.4629e-02],\n                       [-3.3599e-02, -1.1788e-01,  4.2745e-02,  3.7840e-02,  5.7515e-02],\n                       ...,\n                       [ 4.2689e-03,  5.0576e-02,  4.5614e-02, -2.5400e-03,  1.0311e-01],\n                       [-4.6757e-03,  1.2800e-01, -5.6342e-02,  1.1039e-01, -4.3900e-02],\n                       [ 1.3013e-02,  3.2805e-02, -2.8255e-02,  9.8206e-02,  4.0276e-02]],\n              \n                      [[ 3.4694e-02, -1.0677e-02,  5.0294e-02, -3.3899e-02, -4.5415e-02],\n                       [-1.7111e-02, -1.2753e-01, -4.6275e-02,  4.6827e-02, -4.5796e-02],\n                       [-9.6119e-02,  2.5448e-03, -1.5157e-02, -3.9769e-02, -5.2438e-02],\n                       ...,\n                       [-5.1422e-02,  6.8168e-02, -3.5461e-03, -5.2400e-02, -1.8855e-02],\n                       [-4.0516e-02,  2.9087e-02,  2.4410e-02,  8.6184e-02, -3.8822e-02],\n                       [-4.7646e-02, -1.5557e-02, -1.2592e-01, -7.2508e-02,  3.7539e-03]],\n              \n                      [[ 5.7398e-02, -8.8282e-03, -2.5414e-02, -4.0253e-02, -1.2181e-01],\n                       [-2.6151e-02,  1.7202e-02,  6.7190e-02, -8.9942e-02,  6.8232e-02],\n                       [-9.3214e-02,  2.7760e-03, -1.2508e-01, -5.3354e-02,  7.7526e-02],\n                       ...,\n                       [-2.8325e-02,  2.6915e-02, -1.0678e-01,  6.3290e-03, -6.3431e-02],\n                       [ 4.3636e-02,  4.1843e-03,  7.8167e-02, -1.2920e-01, -3.5783e-02],\n                       [ 8.8036e-02, -3.9806e-02, -5.0515e-02, -6.3694e-02, -1.1527e-01]],\n              \n                      ...,\n              \n                      [[-1.0272e-01, -6.3537e-02, -7.3089e-02,  9.1197e-02,  8.4952e-02],\n                       [ 1.6513e-02,  6.2077e-02, -1.1859e-02, -1.1128e-01, -1.1729e-01],\n                       [ 2.7044e-02,  4.0231e-02,  1.3083e-01,  5.9207e-02, -4.5925e-02],\n                       ...,\n                       [-1.5532e-02,  7.5583e-03, -4.4415e-02, -5.0363e-02, -8.7583e-02],\n                       [-4.4164e-02,  1.9960e-01, -6.2176e-03,  3.8471e-02,  1.0878e-01],\n                       [-5.8840e-02,  4.9365e-03, -5.0204e-02, -7.9948e-02,  2.7359e-02]],\n              \n                      [[-3.6332e-02,  5.3392e-02,  3.7117e-02,  1.1546e-02, -5.2246e-02],\n                       [ 1.9101e-01,  1.5129e-01,  2.9943e-03,  3.1230e-02, -4.3205e-02],\n                       [ 3.1995e-03,  1.4586e-01, -8.6100e-03, -2.8414e-02,  4.1754e-02],\n                       ...,\n                       [-1.8093e-01,  7.8644e-02,  1.3567e-01, -6.4919e-02, -1.0376e-01],\n                       [ 2.4963e-02,  4.6311e-02, -6.4594e-02, -1.2299e-01, -1.9182e-02],\n                       [ 5.3916e-02, -1.4304e-02,  1.3473e-02, -1.0688e-01, -6.1820e-02]],\n              \n                      [[ 3.8470e-02,  9.1451e-02,  1.3491e-01,  1.0883e-01,  1.4127e-02],\n                       [-7.3971e-02,  7.8095e-02,  1.6060e-02,  1.1769e-02, -2.1140e-03],\n                       [-9.0929e-02,  1.9203e-02, -2.6688e-02, -2.2390e-01,  3.8489e-03],\n                       ...,\n                       [-1.9679e-01, -4.6309e-02, -4.9521e-02, -4.8222e-02,  1.0800e-01],\n                       [ 6.9955e-04,  7.6519e-02, -6.4069e-02,  1.7861e-02,  1.0596e-01],\n                       [ 4.5725e-02, -7.9735e-02,  1.1775e-04, -3.5031e-02, -2.8898e-02]]],\n                     dtype=torch.float64)),\n             ('6.6.convpath.0.1.1.weight',\n              tensor([0.9680, 0.9587, 0.9682, 0.9753, 0.9702, 0.9587, 0.9913, 0.9515, 0.9494,\n                      0.9544, 0.9475, 0.9881, 0.9767, 0.9523, 0.9459, 1.0162, 0.9399, 0.9699,\n                      0.9474, 0.9757, 0.9637, 0.9530, 0.9710, 0.9687, 0.9377, 0.9752, 0.9835,\n                      0.9622, 1.0168, 0.9539, 0.9566, 0.9384, 0.9664, 0.9498, 0.9305, 0.9308,\n                      0.9792, 0.9477, 0.9717, 0.9467, 0.9542, 0.9583, 0.9872, 0.9404, 0.9615,\n                      0.9669, 0.9855, 0.9583, 0.9749, 0.9724, 0.9795, 0.9752, 0.9532, 0.9597,\n                      0.9783, 0.9754, 0.9642, 0.9502, 0.9550, 0.9724, 0.9720, 1.0049, 0.9688,\n                      0.9859], dtype=torch.float64)),\n             ('6.6.convpath.0.1.1.bias',\n              tensor([-0.0200,  0.0029,  0.0066, -0.0192, -0.0032, -0.0082,  0.0130, -0.0154,\n                      -0.0034, -0.0145, -0.0106,  0.0144,  0.0066,  0.0024, -0.0312,  0.0195,\n                      -0.0150,  0.0093,  0.0137, -0.0142, -0.0120, -0.0225,  0.0153,  0.0027,\n                      -0.0078,  0.0028,  0.0080,  0.0108,  0.0297, -0.0121,  0.0145, -0.0138,\n                      -0.0132, -0.0116, -0.0212, -0.0114, -0.0149, -0.0134, -0.0005, -0.0060,\n                      -0.0307,  0.0186,  0.0178, -0.0115,  0.0013, -0.0180,  0.0138,  0.0062,\n                       0.0083,  0.0159, -0.0168,  0.0167, -0.0120,  0.0249, -0.0004, -0.0107,\n                      -0.0067,  0.0013, -0.0002,  0.0105, -0.0129,  0.0251, -0.0005,  0.0140],\n                     dtype=torch.float64)),\n             ('6.6.convpath.0.1.1.running_mean',\n              tensor([ 0.0941, -0.7252, -0.4760,  0.2748, -0.1647, -0.4858, -0.8490, -0.1793,\n                      -0.0227, -0.2179, -0.1825, -0.5824,  0.0095, -0.1535,  0.3272,  0.1869,\n                       0.0271,  0.2549, -0.5281,  0.4292,  0.4128,  1.4082,  0.5958, -0.8053,\n                      -0.6850, -0.3657, -0.3949, -0.3225, -0.3130,  0.0400, -0.2220, -0.0674,\n                      -0.1557,  0.2255, -1.0208, -0.1347,  0.4071, -1.0269, -0.2208, -0.2801,\n                       0.3742, -0.6952, -0.8007, -0.6675, -0.8257,  0.4606, -0.6977, -0.9755,\n                      -0.3626,  0.1859,  0.1783,  0.6324,  0.3196, -0.4582,  0.1397,  0.8500,\n                       0.4893, -0.3193, -0.2917, -0.3238,  0.5035, -0.2844,  0.3407, -1.3248],\n                     dtype=torch.float64)),\n             ('6.6.convpath.0.1.1.running_var',\n              tensor([0.6036, 0.7538, 0.5866, 0.6633, 0.5593, 0.6855, 0.4369, 0.5545, 0.4075,\n                      0.7970, 1.0802, 0.5327, 0.5672, 0.5359, 0.5905, 0.5326, 0.4028, 0.6563,\n                      0.7827, 0.7444, 0.7562, 1.6093, 0.7848, 0.5746, 0.6527, 0.3406, 0.6831,\n                      0.4689, 0.5869, 0.9397, 0.6967, 0.8706, 0.7356, 1.5085, 0.8688, 0.9156,\n                      0.6068, 0.7849, 0.6778, 0.6203, 0.7855, 0.6776, 0.4891, 0.9342, 0.5915,\n                      0.5578, 0.3665, 0.9074, 0.5117, 0.4519, 0.5025, 0.7112, 0.7933, 0.9678,\n                      0.5106, 0.6453, 0.5198, 0.9181, 0.8019, 0.5727, 0.4667, 0.4739, 0.9411,\n                      1.4261], dtype=torch.float64)),\n             ('6.6.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.6.convpath.0.2.0.weight',\n              tensor([[[-0.1595],\n                       [-0.0641],\n                       [ 0.0956],\n                       ...,\n                       [-0.0179],\n                       [-0.0835],\n                       [-0.0037]],\n              \n                      [[-0.0488],\n                       [-0.1028],\n                       [ 0.0146],\n                       ...,\n                       [-0.0451],\n                       [ 0.0322],\n                       [-0.1033]],\n              \n                      [[-0.0319],\n                       [ 0.0127],\n                       [-0.0140],\n                       ...,\n                       [-0.1225],\n                       [ 0.0479],\n                       [-0.0291]],\n              \n                      ...,\n              \n                      [[ 0.1646],\n                       [-0.0141],\n                       [-0.1006],\n                       ...,\n                       [ 0.1497],\n                       [ 0.0020],\n                       [ 0.1797]],\n              \n                      [[-0.0715],\n                       [ 0.0449],\n                       [ 0.0487],\n                       ...,\n                       [ 0.1228],\n                       [-0.0075],\n                       [-0.0247]],\n              \n                      [[ 0.0327],\n                       [ 0.0197],\n                       [-0.0633],\n                       ...,\n                       [ 0.1074],\n                       [-0.0077],\n                       [-0.0439]]], dtype=torch.float64)),\n             ('6.6.convpath.0.2.1.weight',\n              tensor([ 1.0150e-02, -6.9185e-03,  1.3713e-02, -1.0232e-02,  8.5891e-03,\n                       8.5662e-04,  9.6463e-04,  2.7952e-02, -2.0439e-02, -3.2038e-02,\n                      -1.0341e-02, -2.8828e-02, -2.2906e-03,  6.5147e-03, -8.0612e-03,\n                       3.3665e-02, -1.1520e-02, -1.2285e-02, -2.7464e-03, -3.0818e-02,\n                       1.5915e-02, -2.1413e-02,  9.2876e-03, -5.6457e-03, -2.5190e-02,\n                      -8.6980e-04, -2.2414e-02,  1.5891e-02,  1.0181e-02,  4.0825e-03,\n                      -4.9613e-03,  1.1755e-02,  9.6195e-03, -3.5012e-03,  5.8914e-04,\n                       1.1283e-02,  5.2637e-03,  8.8263e-03,  2.2464e-02, -1.7061e-03,\n                       2.9880e-03,  2.7630e-03, -1.4922e-02, -7.2432e-04,  1.6037e-03,\n                       5.6718e-03, -4.7779e-03,  1.6763e-02, -8.7895e-03,  3.4771e-02,\n                      -8.6616e-03,  9.0280e-03,  9.4141e-03, -1.2205e-02, -1.8254e-02,\n                       3.6123e-02,  1.7818e-03, -3.3514e-02,  1.9809e-02, -1.1498e-02,\n                       8.8276e-03, -1.6572e-02,  1.7389e-03, -1.5630e-02, -2.8822e-02,\n                       2.2343e-02,  9.8016e-04,  2.2395e-02, -2.5321e-02,  3.7378e-02,\n                      -3.1880e-02,  7.3242e-03,  8.9524e-03, -1.1022e-03, -7.9567e-03,\n                      -8.1209e-03,  7.4155e-03,  1.6137e-02,  8.0900e-03, -1.1796e-02,\n                      -2.4412e-02, -8.7004e-03,  7.8374e-03,  8.5154e-03,  3.3320e-02,\n                       1.3653e-03,  1.2235e-02,  1.1917e-02, -1.4693e-02,  2.4134e-02,\n                      -2.6067e-03, -1.4748e-02, -3.9695e-02, -6.8339e-03,  6.2063e-03,\n                      -8.9520e-03,  2.3766e-02, -4.2868e-03, -2.2400e-02,  1.4393e-02,\n                      -1.2527e-03,  1.2413e-02,  2.4075e-02, -2.0689e-02, -1.4978e-02,\n                       1.4390e-02,  1.8197e-02, -5.8271e-03,  2.8548e-02, -8.4787e-04,\n                       9.0904e-03,  1.6414e-02, -2.4509e-03, -3.3220e-02, -2.8567e-02,\n                       2.0956e-02, -5.7126e-03,  1.2938e-02, -6.8211e-04, -3.5662e-03,\n                       2.7866e-02,  1.7067e-02, -2.7390e-04,  1.6938e-02, -1.1377e-02,\n                      -9.3527e-03, -3.1341e-02, -1.3731e-03, -9.3574e-03,  1.1817e-02,\n                       1.2659e-02,  3.7606e-02, -1.3645e-03, -1.9714e-02, -1.1301e-02,\n                      -3.3656e-03,  1.2442e-03,  2.0660e-02,  4.1279e-03,  5.7126e-03,\n                       6.4018e-03, -6.6275e-03,  9.6259e-03, -2.4736e-02,  6.8314e-03,\n                      -8.6778e-03,  8.6942e-03, -9.4880e-03, -1.9828e-02,  3.7420e-03,\n                      -4.4454e-03,  1.6157e-02,  3.2540e-03,  1.0921e-02,  1.1020e-02,\n                       1.3300e-02, -1.1635e-02, -3.0415e-02,  1.2797e-02, -2.3762e-04,\n                      -2.1016e-02, -5.7868e-03,  3.4032e-03,  1.8778e-02,  2.3184e-02,\n                       1.7988e-02,  1.8516e-03,  1.7287e-02,  8.5864e-03,  3.8996e-02,\n                      -9.1970e-03, -1.2124e-02,  1.0203e-02,  2.2397e-03,  1.3022e-02,\n                      -1.0346e-02, -1.0479e-02,  5.5608e-05,  1.5299e-02,  1.1594e-02,\n                       1.1107e-02,  1.0029e-02, -1.5271e-02,  1.2404e-03, -3.0976e-03,\n                      -1.7444e-02, -4.4170e-03, -1.4255e-02,  6.4446e-03,  1.7522e-02,\n                      -1.6760e-02, -1.3052e-02,  2.0311e-02, -1.4137e-02, -1.4519e-02,\n                       7.5137e-03, -8.7557e-03,  2.2173e-02,  2.5515e-02, -1.2209e-02,\n                      -6.2720e-03,  2.4393e-02,  1.8483e-03, -1.5753e-02,  3.3581e-03,\n                       4.6281e-03,  4.5554e-02, -2.5611e-02,  9.6270e-04, -2.1001e-02,\n                      -5.6559e-03,  4.5710e-03,  1.1246e-03, -3.6671e-02,  6.7719e-03,\n                      -1.8243e-02, -5.3325e-03, -5.1157e-03,  2.0348e-02, -1.6542e-02,\n                       4.7618e-03,  1.1616e-02,  4.1344e-03,  1.6350e-02,  1.5259e-02,\n                       9.5261e-03,  9.6563e-03,  1.9315e-02, -5.9309e-04, -3.2346e-02,\n                       1.3660e-03,  9.9181e-03, -6.4819e-03,  2.3366e-02, -8.9760e-03,\n                      -7.7267e-03,  1.2651e-02,  1.1246e-02, -1.8028e-02, -8.1925e-03,\n                      -1.1697e-02,  1.0043e-02,  9.9266e-04,  5.6365e-03, -1.3458e-02,\n                       8.5161e-03, -8.8420e-03, -1.8407e-02,  4.4380e-03, -2.8718e-02,\n                      -1.1123e-02, -1.9702e-02, -2.6554e-03, -2.2865e-02, -2.9003e-03,\n                       5.3596e-05], dtype=torch.float64)),\n             ('6.6.convpath.0.2.1.bias',\n              tensor([-8.3792e-04,  3.4520e-03,  1.3210e-02,  1.5723e-02,  8.9322e-04,\n                       4.7988e-03,  1.1738e-02,  1.7120e-03,  2.2046e-03,  2.2611e-02,\n                       1.4390e-02, -7.9868e-03,  8.1139e-03, -4.6840e-03,  1.1887e-02,\n                       4.0100e-03,  2.1283e-02, -2.5542e-03,  1.3014e-02, -7.5277e-03,\n                      -2.8608e-03,  3.0322e-03,  7.0995e-04,  6.4781e-03, -7.5706e-03,\n                      -1.5647e-02,  3.4617e-03,  8.4863e-03,  5.8509e-04, -2.2938e-03,\n                       3.9236e-03,  8.7355e-03, -9.6032e-03,  1.8149e-02,  1.2896e-02,\n                       1.4812e-02, -3.0728e-03,  1.9824e-02,  6.2865e-03,  1.5273e-02,\n                      -1.2278e-03,  2.3988e-02, -2.9701e-03,  1.8631e-03,  3.4217e-03,\n                      -9.0559e-03,  1.1670e-02,  5.8815e-03, -1.1538e-02,  1.3021e-02,\n                       8.1819e-03,  9.5104e-03,  9.6971e-03,  1.1133e-02,  4.3198e-03,\n                       1.6471e-02,  7.3368e-03,  3.1255e-03,  6.2823e-03,  2.9483e-03,\n                      -1.7716e-03,  2.8475e-03,  4.9976e-03,  8.9434e-03, -4.0464e-03,\n                       1.0568e-02, -1.2458e-02,  1.6330e-02, -4.7043e-03, -1.1872e-02,\n                       2.5532e-03,  5.8576e-03,  1.6502e-03, -7.1843e-03,  1.4609e-02,\n                      -1.0920e-03,  3.3231e-03,  1.3520e-03,  5.0737e-03,  1.7698e-03,\n                       1.0323e-02, -5.8991e-03,  8.2852e-03,  4.0855e-03, -4.8411e-03,\n                       1.2181e-02, -5.5207e-04,  6.4295e-04,  1.3395e-02,  6.5983e-03,\n                      -8.4500e-04,  1.4904e-02,  1.4938e-02, -3.0558e-03,  9.2375e-03,\n                      -1.1740e-02,  6.1342e-03,  2.4766e-03,  1.1535e-02, -2.3214e-03,\n                       1.9170e-02,  1.4898e-03,  5.9829e-03, -4.9193e-04,  1.1518e-02,\n                       5.8428e-04,  1.3346e-03,  3.2009e-03,  4.6381e-03,  8.4240e-03,\n                      -7.3728e-03, -7.3230e-03,  5.0754e-03,  2.0944e-02,  1.1596e-02,\n                       6.6018e-03,  9.5287e-03,  2.8527e-05,  3.4567e-03, -1.4839e-02,\n                      -1.6093e-05,  8.0401e-03, -1.8009e-03, -2.7852e-03, -1.1983e-02,\n                       1.0376e-02,  1.4491e-02,  5.2070e-03,  2.4162e-03,  1.6354e-02,\n                       2.3329e-02,  1.5196e-02,  1.4868e-02,  6.6737e-03,  1.5523e-02,\n                      -6.6983e-03,  1.5797e-02,  9.1371e-03,  1.0598e-02,  8.8044e-03,\n                       1.4434e-02, -3.7489e-03,  1.6393e-02,  6.3892e-03, -7.3140e-03,\n                       1.3741e-02,  3.0642e-03, -1.2913e-03,  8.9991e-03,  9.0917e-03,\n                       6.3211e-03,  1.3197e-02,  1.3214e-02,  1.3775e-02,  1.5297e-02,\n                       9.1409e-03,  1.2826e-03,  7.1325e-03, -1.7783e-03, -1.0423e-02,\n                       4.9193e-03, -4.8071e-03,  6.3248e-04,  1.1793e-02,  1.0697e-02,\n                       1.2110e-04, -8.8667e-03,  1.1457e-02,  9.8033e-04,  1.6094e-02,\n                       6.3129e-03,  7.3345e-03,  1.1404e-02,  1.0406e-02, -1.3451e-02,\n                       2.7757e-03, -6.2231e-04,  1.2838e-02,  3.7241e-03,  4.1717e-03,\n                      -3.1890e-03,  1.1061e-02, -8.1519e-03, -9.0768e-03,  1.9833e-02,\n                       7.4087e-03,  1.3363e-02,  1.0722e-02,  2.6543e-03,  2.6333e-03,\n                       6.1325e-03,  2.3526e-03,  9.8704e-03, -8.1245e-03,  2.4701e-03,\n                       6.2251e-03, -5.2993e-03,  1.9476e-02,  8.3589e-03,  5.9339e-03,\n                       3.2769e-03,  2.1492e-02,  1.9525e-02,  1.6423e-02,  4.3670e-04,\n                      -1.3728e-03,  1.6720e-02, -4.0052e-03,  8.9128e-03,  1.1261e-02,\n                      -1.2157e-03,  1.1640e-02,  1.4352e-02,  8.0657e-03,  1.5759e-02,\n                       4.1711e-04,  4.2417e-03, -5.3075e-03,  2.3169e-03, -3.7946e-04,\n                      -1.4252e-02,  3.1344e-03,  5.3142e-03,  1.8019e-02, -4.9953e-03,\n                       4.4637e-03, -3.0559e-03,  1.8502e-03, -1.4347e-02,  1.4490e-02,\n                       8.4647e-03, -1.7278e-03,  1.1873e-02,  6.4378e-03,  2.3101e-03,\n                       6.9338e-03,  7.6796e-03, -8.8597e-03,  9.5387e-03,  8.5499e-03,\n                       1.8392e-03,  3.9479e-03,  5.1607e-03,  8.0653e-03, -2.6380e-04,\n                       1.4907e-02,  1.1049e-04,  9.7957e-03,  3.1189e-03, -8.3708e-03,\n                       1.7591e-02,  1.8614e-02,  1.5490e-02,  1.6420e-02,  9.7842e-03,\n                       5.4413e-03], dtype=torch.float64)),\n             ('6.6.convpath.0.2.1.running_mean',\n              tensor([ 0.0484, -0.1926,  0.1816,  0.3316, -0.2590,  0.1854, -0.2528, -0.6604,\n                      -0.2257,  0.1922,  0.4257, -0.4847,  0.0887,  0.0806, -0.1255, -0.1654,\n                       0.2206,  0.0214, -0.0264,  0.3489, -0.4619,  0.4529,  0.4506,  0.1608,\n                       0.7995,  0.1404,  0.0711,  0.1421,  0.1377,  0.5238, -0.1551,  0.0569,\n                      -0.1907,  0.4104,  0.1761,  0.7142, -0.2240, -0.2415,  0.1952, -0.2565,\n                      -0.3931, -0.2128,  0.1391,  0.0065,  0.3877, -0.6508, -0.1919,  0.0340,\n                       0.5002, -0.0274,  0.0931,  0.0895,  0.5043,  0.4762, -0.6238,  0.2767,\n                      -0.1511, -0.2778,  0.3921,  0.2665, -0.0646,  0.2660,  0.5649, -0.2741,\n                       0.6009,  0.1316, -0.1592,  0.2648, -0.3628,  0.1258,  0.2464,  0.0032,\n                       0.6792, -0.5942, -0.1350, -0.3891,  0.4269, -0.2334,  0.2270,  0.1406,\n                      -0.5591, -0.6412, -0.2204, -0.5344,  0.1413,  0.2465,  0.1378, -0.2565,\n                      -0.4705, -0.0973,  0.1844, -0.3962, -0.3606, -0.7851,  0.0963, -0.1701,\n                      -0.5814,  0.1935, -0.8287, -0.0381, -0.1375,  0.2189, -0.4572,  0.6118,\n                      -0.1344,  0.0932, -0.0333,  0.1850, -0.2961, -0.0506, -0.4222,  0.3416,\n                       0.1064, -0.0942, -0.1910, -0.5448, -0.1406, -0.2246, -0.4124, -0.1428,\n                      -0.2938,  0.1961,  0.1663,  0.2322,  0.2626, -0.2882,  0.1910,  0.1147,\n                       0.5079, -0.3926,  0.4819,  0.4328, -0.2235,  0.0330,  0.0825,  0.2507,\n                      -0.2024, -0.2794, -0.3877,  0.0224,  0.0988,  0.2233,  0.0967,  0.3191,\n                      -0.0405,  0.1969,  0.0536, -0.7023,  0.0902,  0.1065, -0.5438, -0.5041,\n                      -0.4060, -0.6975,  0.3338,  0.1671, -0.3657, -0.0663,  0.4046, -0.2703,\n                      -0.2009, -0.1549,  0.0495,  0.0402, -0.0366,  0.5080,  0.9068, -0.2483,\n                       0.1388, -0.1797, -0.2635, -0.4339, -0.0016, -0.0620,  0.4554, -0.3511,\n                       0.6290, -0.0385, -0.3367, -0.2932,  0.6035,  0.6757, -1.0276, -0.2959,\n                       0.0119,  0.6055,  0.2138,  0.4180, -0.0505,  0.0391,  0.4353,  0.3378,\n                       0.0899, -0.4953,  0.1470,  0.0720, -0.1669, -0.0405, -0.3347,  0.1149,\n                       0.5975,  0.2934, -0.1084, -0.5374, -0.4014,  0.1703,  0.2183, -0.1230,\n                      -0.3695,  0.4564,  0.2788, -0.1397,  0.0234, -0.0727,  0.7962, -0.1117,\n                       0.4427,  0.0702, -0.8673,  0.3666, -0.2168, -0.3573,  0.3964, -0.3970,\n                      -0.0211,  0.0339, -0.5008, -0.0428, -0.1548, -0.1057, -0.0539,  0.1592,\n                       0.7628,  0.3081, -0.1074, -0.1172,  0.3006,  0.4610,  0.1876,  0.3178,\n                      -0.2453,  0.0965, -0.1813, -0.2003, -0.2240, -0.3855, -0.0112, -0.1242,\n                      -0.2394,  0.3448, -0.0450,  0.6814, -0.0061,  0.0442, -0.0092,  0.1831],\n                     dtype=torch.float64)),\n             ('6.6.convpath.0.2.1.running_var',\n              tensor([0.5060, 0.2928, 0.2521, 0.4997, 0.1346, 0.1000, 0.1168, 0.2703, 0.5808,\n                      0.3028, 0.2458, 0.3926, 0.1400, 0.2547, 0.4106, 0.3270, 0.3710, 0.7666,\n                      0.1764, 0.4358, 0.4899, 0.3624, 0.3437, 0.2658, 0.4583, 0.1680, 0.3590,\n                      0.2896, 0.2077, 0.1671, 0.4181, 0.5252, 0.1416, 0.2487, 0.2686, 0.4966,\n                      0.2268, 0.1677, 0.2946, 0.3562, 0.3239, 0.1804, 0.2591, 0.3475, 0.3891,\n                      0.4138, 0.4242, 0.1954, 0.8952, 0.4279, 0.1313, 0.6890, 0.4056, 0.2695,\n                      0.5453, 0.3662, 0.2550, 0.5828, 0.2958, 0.2703, 0.0883, 0.1876, 0.1781,\n                      0.4064, 0.6415, 0.6943, 0.2571, 0.3134, 0.4579, 0.6150, 0.4098, 0.6087,\n                      0.2605, 0.5889, 0.2772, 0.2720, 0.5186, 0.3161, 0.5636, 0.1956, 0.3959,\n                      0.2378, 0.2326, 0.3771, 0.4046, 0.3989, 0.2930, 0.2763, 0.3002, 0.2368,\n                      0.2471, 0.2825, 0.4424, 0.3397, 0.0973, 0.2647, 0.4230, 0.1425, 0.2961,\n                      0.5732, 0.2965, 0.3911, 0.4025, 0.5569, 0.3308, 0.2962, 0.4059, 0.2956,\n                      0.2929, 0.1580, 0.2754, 0.5503, 0.2243, 0.2799, 0.3702, 0.5863, 0.2564,\n                      0.3825, 0.2024, 0.5363, 0.2963, 0.3553, 0.1630, 0.4539, 0.2036, 0.7385,\n                      0.1736, 0.0701, 0.3150, 0.3583, 0.2097, 0.3979, 0.3020, 0.7779, 0.2743,\n                      0.1458, 0.0742, 0.1964, 0.1535, 0.1818, 0.1685, 0.0873, 0.3572, 0.5351,\n                      0.2114, 0.4553, 0.1298, 0.7119, 0.2393, 0.3721, 0.4882, 0.3819, 0.1922,\n                      0.5164, 0.4325, 0.2892, 0.2629, 0.2532, 0.3939, 0.2186, 0.5735, 0.2830,\n                      0.2749, 0.3364, 0.5277, 0.4928, 0.4210, 0.3123, 0.3560, 0.3859, 0.2993,\n                      0.1585, 0.4988, 0.2331, 0.4092, 0.4772, 0.2176, 0.2631, 0.5189, 0.2200,\n                      0.4529, 0.3984, 0.4933, 0.1653, 0.3275, 0.4449, 0.2048, 0.2948, 0.2100,\n                      0.4726, 0.3029, 0.3962, 0.2390, 0.4861, 0.3897, 0.2782, 0.2649, 0.3535,\n                      0.2940, 0.2564, 0.2433, 0.3392, 0.1744, 0.4631, 0.2398, 0.3812, 0.2768,\n                      0.2944, 0.1773, 0.5339, 0.0971, 0.4645, 0.2403, 0.2807, 0.4763, 0.1225,\n                      0.4769, 0.2908, 0.4497, 0.5328, 0.1445, 0.3494, 0.1842, 0.3403, 0.3770,\n                      0.2697, 0.2160, 0.3205, 0.3376, 0.4268, 0.2101, 0.3005, 0.4034, 0.5217,\n                      0.2343, 0.3558, 0.2110, 0.1964, 0.5977, 0.5221, 0.6663, 0.2049, 0.4839,\n                      0.0876, 0.9857, 0.2702, 0.1396, 0.3188, 0.1138, 0.5938, 0.4612, 0.5259,\n                      0.1380, 0.3365, 0.2664, 0.0693], dtype=torch.float64)),\n             ('6.6.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.7.convs.0.0.weight',\n              tensor([[[ 0.0036],\n                       [ 0.0511],\n                       [ 0.0028],\n                       ...,\n                       [-0.0313],\n                       [ 0.0247],\n                       [-0.0941]],\n              \n                      [[ 0.1071],\n                       [-0.0338],\n                       [-0.0449],\n                       ...,\n                       [ 0.0546],\n                       [ 0.0115],\n                       [ 0.0233]],\n              \n                      [[-0.1518],\n                       [-0.0357],\n                       [ 0.0094],\n                       ...,\n                       [-0.0946],\n                       [-0.1985],\n                       [-0.0267]],\n              \n                      ...,\n              \n                      [[ 0.0988],\n                       [ 0.0083],\n                       [-0.1697],\n                       ...,\n                       [-0.0075],\n                       [ 0.1128],\n                       [-0.0732]],\n              \n                      [[-0.0474],\n                       [ 0.0256],\n                       [-0.0122],\n                       ...,\n                       [ 0.0858],\n                       [-0.0795],\n                       [-0.0920]],\n              \n                      [[ 0.0310],\n                       [ 0.0110],\n                       [ 0.0396],\n                       ...,\n                       [ 0.0069],\n                       [ 0.0966],\n                       [-0.0250]]], dtype=torch.float64)),\n             ('6.7.convs.0.1.weight',\n              tensor([1.0092, 0.9771, 0.9662, 0.9659, 0.9897, 0.9591, 0.9641, 0.9586, 0.9697,\n                      0.9677, 0.9641, 0.9755, 0.9775, 0.9753, 0.9701, 0.9801, 0.9814, 0.9696,\n                      0.9719, 0.9538, 0.9716, 0.9806, 0.9509, 0.9683, 0.9908, 0.9587, 0.9647,\n                      0.9898, 0.9796, 0.9570, 0.9657, 0.9903, 0.9774, 0.9639, 0.9829, 0.9768,\n                      0.9662, 0.9695, 0.9547, 0.9966, 0.9855, 0.9658, 0.9589, 0.9964, 0.9760,\n                      0.9701, 0.9924, 0.9467, 0.9859, 0.9763, 0.9852, 0.9704, 0.9560, 0.9680,\n                      0.9877, 0.9593, 0.9637, 0.9697, 0.9758, 0.9844, 0.9901, 0.9739, 0.9951,\n                      0.9823], dtype=torch.float64)),\n             ('6.7.convs.0.1.bias',\n              tensor([ 0.0088,  0.0015,  0.0130, -0.0094, -0.0120, -0.0068, -0.0032, -0.0185,\n                       0.0069, -0.0063, -0.0046,  0.0146,  0.0104, -0.0059,  0.0187,  0.0003,\n                      -0.0042,  0.0099, -0.0079,  0.0138, -0.0124, -0.0003, -0.0069,  0.0107,\n                       0.0233, -0.0117, -0.0354,  0.0088, -0.0217, -0.0304, -0.0043,  0.0092,\n                       0.0100, -0.0040,  0.0014, -0.0075, -0.0004, -0.0169, -0.0035,  0.0226,\n                       0.0109,  0.0037, -0.0106,  0.0139, -0.0015, -0.0102, -0.0053,  0.0062,\n                      -0.0085, -0.0195,  0.0149, -0.0066,  0.0011,  0.0076,  0.0231, -0.0053,\n                      -0.0196,  0.0124,  0.0180,  0.0110,  0.0100, -0.0140,  0.0269,  0.0047],\n                     dtype=torch.float64)),\n             ('6.7.convs.0.1.running_mean',\n              tensor([-4.4709e-01,  3.2206e-01,  1.0960e-01, -4.2228e-01,  2.9116e-01,\n                      -2.3160e-01, -4.1198e-02, -3.1612e-01, -7.0481e-02, -1.9745e-01,\n                      -9.3042e-01,  1.6199e-01, -6.2554e-01, -5.8980e-01,  8.8372e-01,\n                       8.8947e-01,  6.5809e-01, -8.4591e-02,  5.3461e-01, -9.0810e-01,\n                      -5.5649e-02, -1.0478e-01,  5.7140e-01,  8.4632e-01, -6.0553e-01,\n                      -1.2738e+00,  5.4283e-01, -3.9438e-01,  8.2325e-02,  9.6874e-01,\n                       1.1020e+00,  1.1073e-01, -4.1470e-01,  1.8697e-02, -6.8545e-01,\n                      -2.8432e-01, -5.8978e-01, -1.8468e-01, -3.6847e-01,  7.4530e-01,\n                      -5.5156e-01, -1.1988e-01, -6.0985e-02, -2.7134e-01, -1.2102e-01,\n                      -2.9494e-02, -5.2589e-01, -6.3264e-01,  1.7223e-01, -6.2544e-01,\n                      -1.2528e-01,  1.8312e-01, -1.1026e+00,  2.1019e-01, -4.5637e-01,\n                       7.4434e-01, -5.0559e-01,  3.1560e-01, -3.5955e-01, -1.2320e-01,\n                      -1.1136e-03,  2.1425e-01, -9.4900e-01,  3.7618e-02],\n                     dtype=torch.float64)),\n             ('6.7.convs.0.1.running_var',\n              tensor([0.0986, 0.2058, 0.5031, 0.3456, 0.0835, 0.3940, 0.1304, 0.1035, 0.1561,\n                      0.1784, 0.2891, 0.2451, 0.1126, 0.1908, 0.6008, 0.5388, 0.3412, 0.1749,\n                      0.4356, 0.5420, 0.1034, 0.1150, 0.4273, 0.1447, 0.7029, 0.2361, 0.7409,\n                      0.1626, 0.2049, 0.8326, 0.5391, 0.1129, 0.5372, 0.1509, 0.0980, 0.2431,\n                      0.1887, 0.1394, 0.2727, 0.1722, 0.1566, 0.1334, 0.2688, 0.1299, 0.0916,\n                      0.1377, 0.0975, 0.5128, 0.0850, 0.1087, 0.1034, 0.1730, 0.3888, 0.4493,\n                      0.1583, 0.4558, 0.1691, 0.3245, 0.1524, 0.0867, 0.1146, 0.4909, 0.1611,\n                      0.1774], dtype=torch.float64)),\n             ('6.7.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.7.convs.1.0.weight',\n              tensor([[[ 1.2412e-01, -1.4575e-01, -5.3326e-03,  1.1730e-01,  1.4899e-01],\n                       [ 3.8330e-02, -1.1052e-01, -1.2683e-01, -1.9285e-02,  2.4551e-02],\n                       [ 5.1682e-02, -7.2520e-02, -6.3742e-02,  2.0752e-02,  4.3689e-02],\n                       ...,\n                       [ 1.8805e-03,  2.3706e-03, -3.2104e-02,  1.2766e-01,  1.3889e-02],\n                       [ 1.2221e-01,  2.7751e-02,  1.8221e-02, -6.5439e-02, -1.5686e-02],\n                       [-2.9641e-02,  2.8005e-02,  4.9285e-02,  3.4803e-02, -6.1880e-02]],\n              \n                      [[ 6.5340e-02, -3.2313e-03,  2.4173e-02,  1.8863e-02, -5.3450e-02],\n                       [ 5.5821e-02, -2.0517e-01,  4.9215e-02, -1.1132e-02, -4.0468e-02],\n                       [-2.3987e-01,  2.3344e-02,  9.7126e-02,  3.5584e-02, -2.8119e-02],\n                       ...,\n                       [-2.2060e-02,  7.0075e-02,  2.9676e-02,  1.6899e-01,  6.7768e-02],\n                       [-1.2153e-01,  9.9617e-02,  5.6672e-02, -6.0307e-03,  1.9294e-02],\n                       [ 3.0212e-02,  8.8563e-02, -2.0466e-01, -1.3635e-02, -1.4361e-01]],\n              \n                      [[-2.7867e-02,  1.3783e-01, -1.3297e-01, -1.3861e-01, -1.1029e-02],\n                       [ 2.0313e-02, -9.1026e-03,  4.6112e-02, -4.5050e-02, -2.4769e-03],\n                       [-1.4907e-02, -1.0210e-01,  3.9924e-02,  4.4094e-02, -2.0041e-02],\n                       ...,\n                       [-4.6338e-02,  1.2205e-01,  1.0770e-01, -1.5950e-03, -4.8658e-02],\n                       [ 9.8997e-02,  7.1829e-03,  1.4762e-01,  1.1187e-01, -6.8476e-02],\n                       [ 3.3564e-02, -1.8746e-02,  8.8012e-02, -6.6003e-02,  1.3959e-01]],\n              \n                      ...,\n              \n                      [[-1.1264e-01, -8.6263e-02, -8.6817e-02, -3.3818e-02, -1.1265e-01],\n                       [-1.8666e-04, -1.0181e-04, -1.0996e-01, -1.4141e-01,  4.1286e-02],\n                       [-1.3787e-01, -2.8461e-02,  1.2039e-01,  4.2411e-02,  1.3354e-02],\n                       ...,\n                       [ 1.1489e-02, -6.3584e-02, -5.0882e-02, -1.8576e-01, -4.8135e-02],\n                       [-9.2282e-02, -6.1507e-02, -5.9662e-02,  8.7831e-02, -5.1142e-03],\n                       [-6.3506e-02, -5.6199e-02,  2.8567e-02, -1.0404e-02, -8.5436e-02]],\n              \n                      [[ 7.4452e-03,  4.8705e-02, -8.8329e-02,  1.1623e-01,  1.2001e-01],\n                       [-6.6653e-02,  2.8182e-02,  8.5429e-02,  5.3588e-03, -8.6607e-02],\n                       [ 7.0300e-02,  1.1531e-01,  1.9382e-02, -7.5359e-02, -8.1458e-02],\n                       ...,\n                       [-1.5523e-01, -8.2766e-02,  8.0274e-02,  4.9847e-02,  5.9008e-02],\n                       [-2.9197e-04, -3.8981e-03, -7.4774e-02, -1.3034e-01, -1.3672e-01],\n                       [ 9.1060e-02, -8.2616e-02, -1.0709e-01,  1.2206e-01, -7.6210e-02]],\n              \n                      [[-8.3405e-02, -1.7157e-01,  7.9575e-02, -6.5555e-02, -7.5904e-03],\n                       [ 1.6140e-01, -1.4048e-01,  5.3992e-02, -4.9909e-02, -1.0861e-01],\n                       [ 2.0310e-02,  1.0672e-01,  1.5073e-02,  2.9792e-02, -5.5447e-03],\n                       ...,\n                       [ 3.0940e-02, -1.0294e-01, -3.5059e-02, -7.3661e-02, -5.8832e-02],\n                       [-2.7469e-02, -4.4009e-02,  2.1994e-02, -5.5769e-02, -1.1637e-01],\n                       [-1.1300e-01, -1.1986e-03,  2.1710e-02,  1.1594e-02, -1.7025e-02]]],\n                     dtype=torch.float64)),\n             ('6.7.convs.1.1.weight',\n              tensor([0.9898, 0.9804, 0.9557, 0.9557, 0.9742, 0.9635, 0.9893, 0.9810, 0.9807,\n                      0.9568, 0.9905, 0.9392, 0.9299, 0.9653, 0.9865, 0.9610, 0.9838, 0.9563,\n                      0.9681, 0.9355, 0.9748, 0.9658, 0.9842, 0.9547, 0.9440, 0.9668, 0.9509,\n                      1.0212, 0.9698, 0.9772, 0.9688, 0.9705, 1.0089, 0.9422, 0.9700, 0.9782,\n                      0.9598, 0.9448, 0.9637, 0.9634, 0.9368, 0.9577, 0.9656, 0.9451, 0.9467,\n                      0.9381, 0.9567, 0.9806, 1.0139, 0.9760, 0.9686, 0.9241, 0.9693, 0.9613,\n                      0.9571, 0.9580, 1.0190, 0.9173, 0.9746, 0.9845, 0.9855, 0.9758, 0.9914,\n                      0.9639], dtype=torch.float64)),\n             ('6.7.convs.1.1.bias',\n              tensor([ 1.7705e-05, -8.3008e-03, -8.9500e-03, -1.1600e-02,  1.3772e-03,\n                      -1.4480e-02,  6.3453e-03,  1.1437e-02,  9.4652e-03,  1.6378e-03,\n                       1.4161e-02, -3.4924e-02,  2.4510e-03, -1.0505e-02,  1.6462e-02,\n                       1.4814e-03,  2.4546e-03, -6.0179e-04,  1.0428e-02, -1.4090e-02,\n                       9.6360e-03, -2.4580e-02,  1.8338e-03, -9.9366e-03, -1.8377e-02,\n                      -1.1654e-02, -6.2127e-03,  2.5345e-02, -2.2487e-02,  4.1988e-03,\n                      -1.4058e-03, -1.4298e-02,  1.5386e-02, -1.9182e-02, -1.4748e-02,\n                      -1.3501e-02, -2.0651e-02, -3.2022e-02, -1.9587e-02, -3.8651e-04,\n                       1.8055e-03, -7.2941e-03, -2.1827e-02, -2.1465e-02, -8.8045e-03,\n                      -1.6548e-02, -1.3357e-02,  2.4029e-03, -9.6427e-04,  5.0055e-03,\n                      -7.4223e-03, -1.8886e-02, -1.0791e-02, -1.0968e-02, -2.4477e-02,\n                       1.5383e-03,  1.4176e-02, -1.1780e-02, -1.8627e-02,  8.8022e-03,\n                      -2.2120e-03,  1.1865e-03,  1.6239e-02,  4.1783e-03],\n                     dtype=torch.float64)),\n             ('6.7.convs.1.1.running_mean',\n              tensor([ 0.6763,  0.0578, -0.0053,  0.3731, -0.2817,  0.7373,  0.0637, -0.3054,\n                      -0.6437,  0.5518, -0.2666, -0.6452, -0.2400,  0.1034, -0.5692, -0.2805,\n                       0.6150, -0.1274,  0.0621, -0.8910,  0.2998, -0.4710,  0.1468,  0.2788,\n                      -0.4233, -0.7493,  1.1968,  0.3071, -0.0312, -0.6981,  0.8295, -0.3217,\n                      -0.2529, -0.4806,  0.3241, -0.4653, -0.0445, -0.0626, -0.6874, -0.0265,\n                      -0.7829,  0.4947,  0.8369,  1.0345, -0.0674, -0.1988,  0.1449,  0.3052,\n                      -0.2444,  0.5238, -0.5866, -0.4534, -0.5170,  0.6356,  0.0155,  0.8364,\n                      -0.8019, -0.5732, -0.2875,  0.0413, -0.0495, -0.6168, -0.3610, -1.0018],\n                     dtype=torch.float64)),\n             ('6.7.convs.1.1.running_var',\n              tensor([0.5579, 0.6839, 0.5906, 0.6224, 0.3973, 0.4943, 0.4226, 0.4361, 0.4040,\n                      0.4330, 0.4934, 0.7146, 0.5885, 0.5839, 0.5970, 0.5087, 0.5757, 0.4699,\n                      0.4642, 0.6962, 0.9654, 0.5364, 0.4381, 0.6028, 0.5308, 0.5356, 0.6284,\n                      0.4491, 0.6183, 0.3979, 0.4790, 0.4408, 0.4883, 0.7334, 0.4007, 0.5635,\n                      0.5321, 1.1600, 0.7589, 0.5066, 0.5667, 0.6680, 0.8357, 0.7251, 0.5130,\n                      0.7356, 0.6498, 0.6084, 0.6986, 0.6872, 0.5915, 0.4531, 1.1778, 0.7638,\n                      0.7015, 0.5247, 0.4970, 0.9974, 0.4244, 0.4558, 0.5693, 0.6700, 0.4813,\n                      0.6685], dtype=torch.float64)),\n             ('6.7.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.7.convs.2.0.weight',\n              tensor([[[ 0.0307],\n                       [ 0.0978],\n                       [-0.0232],\n                       ...,\n                       [-0.0448],\n                       [ 0.1130],\n                       [ 0.0750]],\n              \n                      [[-0.1199],\n                       [-0.0124],\n                       [ 0.0272],\n                       ...,\n                       [-0.1239],\n                       [-0.1719],\n                       [ 0.2395]],\n              \n                      [[ 0.2251],\n                       [ 0.1154],\n                       [ 0.1930],\n                       ...,\n                       [ 0.0430],\n                       [-0.0167],\n                       [ 0.0704]],\n              \n                      ...,\n              \n                      [[-0.0380],\n                       [-0.0914],\n                       [-0.1436],\n                       ...,\n                       [ 0.0092],\n                       [-0.0122],\n                       [-0.0521]],\n              \n                      [[-0.0386],\n                       [-0.1712],\n                       [ 0.3236],\n                       ...,\n                       [-0.0435],\n                       [ 0.0551],\n                       [-0.3284]],\n              \n                      [[ 0.0118],\n                       [-0.0019],\n                       [ 0.0355],\n                       ...,\n                       [ 0.0263],\n                       [ 0.1237],\n                       [-0.0376]]], dtype=torch.float64)),\n             ('6.7.convs.2.1.weight',\n              tensor([-0.0027, -0.0072,  0.0034,  0.0026, -0.0096,  0.0179,  0.0225,  0.0139,\n                       0.0148,  0.0590, -0.0233,  0.0062,  0.0317, -0.0154,  0.0134, -0.0442,\n                       0.0194,  0.0018, -0.0285,  0.0219, -0.0269, -0.0152, -0.0150, -0.0281,\n                      -0.0029,  0.0091, -0.0048,  0.0155,  0.0056, -0.0238,  0.0160, -0.0311,\n                      -0.0100, -0.0139,  0.0302, -0.0047,  0.0228,  0.0119,  0.0073,  0.0071,\n                      -0.0206,  0.0224, -0.0108, -0.0021,  0.0187,  0.0079,  0.0176,  0.0065,\n                       0.0145, -0.0209, -0.0111, -0.0065,  0.0517,  0.0116, -0.0090, -0.0313,\n                       0.0172,  0.0195, -0.0054,  0.0134, -0.0033, -0.0225, -0.0033,  0.0005,\n                       0.0134, -0.0171,  0.0085,  0.0383, -0.0034, -0.0172,  0.0092, -0.0047,\n                       0.0141,  0.0156, -0.0024, -0.0080,  0.0176,  0.0052,  0.0207,  0.0096,\n                      -0.0142, -0.0073, -0.0009,  0.0122, -0.0063, -0.0334,  0.0207,  0.0121,\n                       0.0031, -0.0140,  0.0244,  0.0085, -0.0097, -0.0052, -0.0160,  0.0087,\n                      -0.0061, -0.0181,  0.0182,  0.0094, -0.0050, -0.0372,  0.0071, -0.0371,\n                      -0.0192, -0.0198, -0.0189, -0.0215,  0.0281, -0.0043, -0.0009,  0.0184,\n                      -0.0055, -0.0248,  0.0171,  0.0178, -0.0197, -0.0160, -0.0084, -0.0046,\n                       0.0067, -0.0081, -0.0039, -0.0168,  0.0089, -0.0031,  0.0177, -0.0286,\n                       0.0026,  0.0093, -0.0336,  0.0413,  0.0361,  0.0182, -0.0305, -0.0003,\n                       0.0193, -0.0019,  0.0172,  0.0249, -0.0076,  0.0014, -0.0128,  0.0097,\n                       0.0042, -0.0061, -0.0177, -0.0429, -0.0143,  0.0116,  0.0095, -0.0071,\n                       0.0106,  0.0065,  0.0155,  0.0034,  0.0108, -0.0147, -0.0051,  0.0294,\n                       0.0208, -0.0096,  0.0026,  0.0219, -0.0065,  0.0065,  0.0338, -0.0018,\n                       0.0024,  0.0172,  0.0130,  0.0023,  0.0192, -0.0047, -0.0393, -0.0183,\n                       0.0169, -0.0144,  0.0007,  0.0171, -0.0059,  0.0185, -0.0008,  0.0097,\n                       0.0104,  0.0293, -0.0143, -0.0109, -0.0206, -0.0014,  0.0184, -0.0142,\n                      -0.0182, -0.0191,  0.0098, -0.0166, -0.0107,  0.0636, -0.0131, -0.0144,\n                      -0.0208,  0.0289,  0.0305, -0.0209,  0.0181, -0.0160, -0.0105, -0.0180,\n                       0.0064, -0.0031,  0.0020, -0.0096,  0.0212,  0.0183, -0.0058,  0.0070,\n                       0.0321,  0.0069,  0.0005,  0.0322,  0.0096,  0.0212,  0.0160,  0.0088,\n                       0.0087, -0.0073, -0.0146, -0.0208, -0.0165, -0.0273,  0.0244, -0.0143,\n                       0.0307, -0.0223,  0.0019,  0.0184, -0.0154, -0.0196, -0.0037, -0.0030,\n                      -0.0172, -0.0193,  0.0317,  0.0036,  0.0067, -0.0023, -0.0173, -0.0065,\n                       0.0259,  0.0143, -0.0013, -0.0075,  0.0311, -0.0264, -0.0201, -0.0214],\n                     dtype=torch.float64)),\n             ('6.7.convs.2.1.bias',\n              tensor([-6.4310e-04,  3.0266e-03,  1.3523e-02,  1.4955e-02,  1.3641e-03,\n                       1.9735e-03,  1.1713e-02,  2.0105e-04,  8.8579e-03,  2.3631e-02,\n                       1.4349e-02, -7.5146e-03,  7.0602e-03, -4.0048e-03,  8.2470e-03,\n                       3.5324e-03,  2.3340e-02, -3.0539e-03,  1.3073e-02, -3.9840e-03,\n                      -3.1628e-03,  2.1535e-03,  1.3177e-03,  6.2361e-03, -3.9429e-03,\n                      -1.6749e-02,  3.7209e-03,  9.4102e-03, -5.2147e-05, -4.2308e-03,\n                       4.3546e-03,  9.0270e-03, -7.4598e-03,  1.8011e-02,  1.2783e-02,\n                       1.5365e-02,  3.1660e-03,  1.9537e-02,  6.6100e-03,  1.5355e-02,\n                       8.2375e-04,  2.2604e-02, -3.0727e-03,  1.4347e-03,  3.9175e-03,\n                      -1.0694e-02,  9.7227e-03,  3.7379e-03, -1.0614e-02,  9.8711e-03,\n                       8.6267e-03,  9.2707e-03,  9.5532e-03,  1.0918e-02,  7.9944e-03,\n                       1.5720e-02,  8.2192e-03,  2.4069e-03,  1.0538e-02,  2.2151e-03,\n                      -5.6736e-03,  2.4276e-03,  4.6402e-03,  8.6080e-03, -3.9128e-03,\n                       5.4495e-03, -1.1817e-02,  1.3345e-02,  1.6804e-03, -1.2255e-02,\n                       1.7006e-03,  8.1716e-03,  7.1207e-04, -7.0969e-03,  1.4879e-02,\n                       3.5225e-03,  3.5022e-03, -7.6848e-04,  6.0321e-03,  1.0899e-03,\n                       1.0637e-02, -4.5603e-03,  9.2227e-03,  4.2682e-03, -4.5702e-03,\n                       1.2254e-02,  1.0245e-03,  1.1379e-03,  1.7409e-02,  3.7657e-03,\n                      -8.7677e-04,  1.4606e-02,  1.3548e-02, -1.1512e-03,  9.5210e-03,\n                      -1.2912e-02,  1.3969e-02,  5.5293e-03,  9.4927e-03, -3.2621e-03,\n                       1.9079e-02,  5.5719e-03,  1.5951e-03,  1.0800e-02,  7.4802e-03,\n                      -2.1610e-03, -6.0193e-04,  3.5014e-03,  4.3637e-03,  9.1421e-03,\n                      -9.8225e-03, -7.8711e-03,  5.1215e-03,  1.8343e-02,  1.4099e-02,\n                       6.5407e-03,  9.2268e-03,  1.7546e-03,  3.7921e-03, -1.4732e-02,\n                       2.4878e-03,  9.6280e-03, -1.3666e-03, -1.5058e-03, -1.2413e-02,\n                       9.9689e-03,  1.2171e-02,  5.1879e-03,  2.8381e-03,  1.7530e-02,\n                       2.2984e-02,  1.5166e-02,  1.5671e-02,  8.1236e-03,  1.4446e-02,\n                      -6.7558e-03,  1.6293e-02,  9.0098e-03,  1.2868e-02,  8.2508e-03,\n                       1.5619e-02, -2.9553e-03,  1.6187e-02,  5.7071e-03, -5.3338e-03,\n                       1.3729e-02,  2.3573e-03, -1.7476e-03,  6.9092e-03,  9.2034e-03,\n                       6.6413e-03,  1.1541e-02,  1.2157e-02,  1.3217e-02,  1.5129e-02,\n                       8.6912e-03,  1.0545e-03,  4.7117e-03, -2.6611e-03, -1.0338e-02,\n                       2.1897e-03, -2.4989e-03,  1.7499e-03,  9.1321e-03,  9.3041e-03,\n                      -6.9190e-04, -1.0907e-02,  1.0950e-02,  9.5735e-04,  1.6206e-02,\n                       5.3129e-03,  6.0487e-03,  1.2237e-02,  1.0375e-02, -1.2957e-02,\n                      -8.2148e-04,  7.8217e-04,  1.2156e-02,  3.2341e-03,  7.0064e-03,\n                      -3.6960e-03,  1.1346e-02, -7.3027e-03, -8.7408e-03,  1.9468e-02,\n                       7.2535e-03,  1.3081e-02,  9.9193e-03,  5.1627e-03,  1.2959e-02,\n                       6.4913e-03,  3.7420e-03,  1.0763e-02, -5.3347e-03, -1.0886e-03,\n                       7.5504e-03, -2.6032e-03,  2.0513e-02,  7.8173e-03,  1.9035e-02,\n                       3.1612e-03,  2.3347e-02,  1.9537e-02,  2.0485e-02,  1.4688e-03,\n                      -3.3145e-03,  1.4129e-02, -7.1476e-03,  8.9060e-03,  1.3974e-02,\n                       2.5388e-03,  1.1654e-02,  1.4502e-02,  9.4520e-03,  1.0603e-02,\n                      -2.2536e-04,  4.5945e-03, -4.9269e-03,  2.4814e-03, -1.2555e-04,\n                      -1.2941e-02,  3.7497e-03,  4.9243e-03,  2.3294e-02, -5.0601e-03,\n                       3.1189e-03, -3.6558e-03,  1.1761e-03, -1.5428e-02,  1.3770e-02,\n                       8.6235e-03, -1.5004e-03,  1.1128e-02,  2.9118e-03,  2.4640e-03,\n                       7.7806e-03,  7.7242e-03, -7.3132e-03,  1.0462e-02,  5.2491e-03,\n                       2.5547e-03,  3.1126e-03,  4.9114e-03,  8.1383e-03,  1.9295e-03,\n                       1.5132e-02,  2.3174e-03,  9.1508e-03,  1.0946e-03, -8.9490e-03,\n                       1.7439e-02,  2.2255e-02,  1.6314e-02,  1.6748e-02,  9.9298e-03,\n                       6.0093e-03], dtype=torch.float64)),\n             ('6.7.convs.2.1.running_mean',\n              tensor([ 1.1512e-01, -1.2408e-01,  1.5560e-02, -8.5132e-01, -3.5015e-01,\n                       4.2217e-02,  1.2696e-01, -7.7264e-01, -1.6587e-01,  4.5704e-01,\n                       1.8437e-01, -2.0660e-01,  1.8374e-01,  4.2693e-01,  2.3723e-01,\n                       4.1612e-01,  2.6384e-01, -6.5560e-02,  3.6698e-01, -1.1522e-01,\n                       4.1765e-01, -2.7076e-02, -6.7437e-01,  6.6193e-01, -2.9848e-01,\n                      -2.4320e-02, -5.2726e-01, -2.6279e-01, -1.9906e-01,  2.1640e-01,\n                       2.4205e-01,  7.3942e-01, -4.3810e-01, -4.2748e-01,  9.7373e-01,\n                       4.6799e-02, -1.1484e-01,  1.9489e-01, -9.9132e-03, -2.1565e-01,\n                      -3.7611e-03, -2.0207e-01,  4.1583e-01,  1.0388e-01, -1.8847e-01,\n                       5.9116e-01,  7.7558e-01,  1.8660e-02,  6.1626e-01,  4.5345e-02,\n                       1.9901e-01, -2.9076e-01, -6.0460e-01, -4.8277e-01, -4.7542e-01,\n                      -6.3918e-01, -3.8531e-01, -9.7001e-01,  1.5485e-01, -3.9927e-01,\n                      -8.8332e-02,  1.5185e-01, -2.2313e-01,  8.5599e-02, -5.2458e-01,\n                      -2.3378e-01, -2.2279e-01,  1.9789e-02, -7.0119e-01,  2.5366e-02,\n                       3.8578e-01,  1.2038e-01,  2.3105e-01,  2.8917e-01, -3.9217e-01,\n                       2.2373e-01, -7.5155e-01,  1.3956e-01,  2.8009e-01,  2.9260e-01,\n                       3.3937e-02,  7.4909e-02, -5.6992e-02, -3.9280e-01, -1.8434e-01,\n                       8.0144e-01,  3.0549e-01, -1.0238e-02, -2.0356e-01, -2.1057e-01,\n                       1.9111e-01,  4.2198e-01,  1.5288e-01,  1.4493e-01,  4.0992e-02,\n                       7.3222e-02,  5.2985e-02, -4.6559e-01,  9.3975e-02, -6.7458e-01,\n                       3.8736e-01, -2.9781e-01,  4.2128e-01, -9.1290e-02, -4.8175e-01,\n                       6.7395e-02, -4.4238e-01, -4.1089e-01, -3.8686e-02, -4.1475e-01,\n                       3.6315e-01,  8.0348e-01, -2.1372e-01,  5.6031e-01,  7.4356e-01,\n                      -7.8413e-01, -7.2186e-02, -3.9836e-01,  4.1905e-01, -3.6362e-01,\n                      -2.4260e-01,  2.8073e-01,  3.7776e-01, -5.3364e-01,  8.3810e-02,\n                      -2.7595e-01, -4.9132e-01, -2.2815e-01, -2.9682e-01, -3.7972e-01,\n                       3.6437e-01,  2.2522e-02,  4.9806e-02, -1.7390e-01, -3.9235e-02,\n                      -1.8719e-01, -3.1922e-01,  4.5318e-01, -2.6429e-01, -1.5119e-01,\n                       1.2889e-01,  1.2184e-01,  3.2751e-01,  2.9640e-01, -1.4548e-02,\n                       8.6737e-02,  4.9984e-02, -4.8113e-01, -1.9177e-01,  2.4673e-02,\n                      -4.4606e-02,  8.5359e-01,  3.5509e-02, -1.2024e+00, -7.1799e-02,\n                       2.8443e-01, -3.4485e-01, -2.1267e-01,  5.2309e-01,  7.7542e-01,\n                       1.7128e-01,  6.7273e-01, -4.0564e-01,  3.0869e-01,  3.0037e-02,\n                      -2.1506e-01, -3.0321e-01,  1.7760e-02, -7.1043e-01, -7.5932e-01,\n                      -5.2463e-01,  9.7043e-02,  1.9130e-01, -2.1352e-01, -1.5883e-01,\n                      -9.1983e-02,  2.0166e-01,  7.6388e-01, -3.0779e-01,  3.4648e-02,\n                      -2.2712e-01, -1.8830e-01, -9.3982e-02,  3.6128e-01,  5.3542e-02,\n                       6.5232e-01,  3.7795e-01,  9.1646e-01,  4.2479e-01, -1.1099e-01,\n                       2.3958e-01,  5.0025e-01,  5.2223e-01, -7.7900e-01,  1.0615e+00,\n                       4.9611e-01,  5.0739e-01, -2.3274e-01,  4.7762e-01,  2.6956e-01,\n                      -1.5073e-02,  1.5371e-01, -3.0923e-01,  2.7307e-02,  2.8011e-01,\n                       1.0251e-03,  1.9787e-01,  6.5064e-02, -2.2209e-01,  2.9206e-01,\n                       4.9768e-02, -3.2531e-01,  5.9996e-02,  5.2804e-01,  1.4994e-01,\n                      -6.9907e-01,  2.1000e-01,  2.6851e-01, -6.0916e-02, -1.1554e-01,\n                       5.8100e-02,  5.3631e-01,  1.2036e-01,  5.0412e-01, -5.6109e-01,\n                       7.9764e-02, -2.5969e-01, -4.1700e-01,  5.2554e-02, -1.4842e-01,\n                      -1.7673e-01,  2.0233e-02,  3.8279e-01, -9.5141e-01, -9.7629e-02,\n                      -2.5934e-01, -4.9792e-01, -3.0665e-01,  3.6194e-01,  2.3216e-01,\n                      -4.1103e-01,  4.3288e-01,  1.9449e-01,  1.8349e-01, -4.2285e-01,\n                       1.2935e-01,  2.4047e-01,  2.7934e-01, -1.8135e-01,  1.6763e-01,\n                       3.2113e-01,  8.6672e-01, -4.9214e-01, -1.8051e-01, -2.7455e-01,\n                      -2.3996e-02], dtype=torch.float64)),\n             ('6.7.convs.2.1.running_var',\n              tensor([0.1763, 0.2902, 0.1368, 0.3435, 0.2298, 0.4274, 0.3648, 0.3360, 0.3056,\n                      0.3993, 0.4764, 0.4587, 0.2467, 0.3302, 0.7383, 0.3946, 0.3114, 0.3322,\n                      0.3356, 0.4499, 0.6490, 0.3187, 0.4116, 0.4618, 0.2705, 0.1629, 0.3687,\n                      0.3091, 0.3695, 0.4162, 0.3992, 0.6415, 0.2321, 0.4860, 0.4676, 0.3051,\n                      0.3844, 0.2864, 0.3057, 0.4422, 0.2759, 0.5380, 0.4338, 0.2321, 0.4479,\n                      0.4959, 0.5419, 0.1503, 0.6391, 0.2968, 0.3082, 0.4063, 0.4344, 0.2169,\n                      0.7768, 0.4015, 0.5011, 0.7171, 0.5609, 0.3848, 0.1397, 0.3559, 0.1262,\n                      0.0762, 0.4903, 0.3040, 0.5215, 0.5612, 0.5729, 0.6270, 0.3288, 0.0524,\n                      0.4380, 0.5868, 0.3569, 0.1323, 0.6394, 0.1275, 0.4430, 0.1727, 0.4795,\n                      0.1815, 0.1507, 0.4827, 0.3130, 0.5819, 0.3847, 0.4898, 0.1871, 0.3617,\n                      0.4780, 0.4848, 0.2842, 0.2618, 0.4814, 0.1643, 0.4439, 0.4564, 0.3517,\n                      0.4019, 0.4228, 0.3466, 0.4442, 0.3137, 0.2915, 0.2062, 0.5094, 0.4589,\n                      0.3910, 0.2185, 0.2913, 0.6120, 0.3326, 0.3221, 0.4527, 1.0174, 0.3833,\n                      0.3956, 0.3401, 0.3829, 0.2587, 0.3914, 0.4963, 0.3290, 0.0334, 0.5787,\n                      0.2445, 0.3282, 0.1185, 0.3047, 0.2896, 0.4533, 0.6680, 0.2997, 0.2964,\n                      0.0905, 0.5363, 0.3147, 0.4183, 0.3169, 0.4233, 0.0761, 0.4567, 0.3016,\n                      0.1323, 0.5570, 0.1476, 0.4955, 0.2168, 0.2828, 0.6189, 0.4081, 0.2556,\n                      0.4254, 0.3023, 0.2096, 0.4307, 0.4043, 0.1449, 0.3941, 0.2938, 0.3435,\n                      0.2143, 0.4787, 0.3204, 0.5016, 0.5651, 0.2621, 0.4173, 0.5410, 0.3802,\n                      0.2864, 0.3719, 0.1569, 0.5917, 0.8820, 0.3565, 0.3000, 0.3099, 0.2438,\n                      0.4095, 0.3067, 0.3394, 0.5169, 0.1664, 0.5502, 0.4005, 0.2460, 0.3348,\n                      0.1205, 0.4364, 0.2886, 0.3837, 0.3965, 0.4111, 0.6575, 0.4061, 0.6476,\n                      0.3361, 0.2952, 0.5413, 0.6347, 0.2222, 0.3544, 0.2595, 0.4361, 0.1314,\n                      0.2743, 0.1941, 0.2709, 0.0599, 0.2339, 0.3215, 0.3650, 0.1493, 0.2679,\n                      0.5326, 0.2014, 0.0928, 0.3139, 0.3788, 0.4031, 0.2918, 0.2270, 0.5664,\n                      0.1987, 0.2120, 0.4421, 0.4900, 0.6519, 0.4197, 0.4528, 0.5932, 0.4342,\n                      0.1531, 0.3731, 0.2432, 0.3530, 0.3094, 0.2008, 0.3349, 0.3511, 0.5080,\n                      0.1615, 0.2013, 0.2903, 0.5566, 0.2432, 0.2517, 0.4269, 0.2402, 0.4185,\n                      0.3184, 0.4683, 0.3454, 0.1831], dtype=torch.float64)),\n             ('6.7.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.7.convpath.0.0.0.weight',\n              tensor([[[ 0.0036],\n                       [ 0.0511],\n                       [ 0.0028],\n                       ...,\n                       [-0.0313],\n                       [ 0.0247],\n                       [-0.0941]],\n              \n                      [[ 0.1071],\n                       [-0.0338],\n                       [-0.0449],\n                       ...,\n                       [ 0.0546],\n                       [ 0.0115],\n                       [ 0.0233]],\n              \n                      [[-0.1518],\n                       [-0.0357],\n                       [ 0.0094],\n                       ...,\n                       [-0.0946],\n                       [-0.1985],\n                       [-0.0267]],\n              \n                      ...,\n              \n                      [[ 0.0988],\n                       [ 0.0083],\n                       [-0.1697],\n                       ...,\n                       [-0.0075],\n                       [ 0.1128],\n                       [-0.0732]],\n              \n                      [[-0.0474],\n                       [ 0.0256],\n                       [-0.0122],\n                       ...,\n                       [ 0.0858],\n                       [-0.0795],\n                       [-0.0920]],\n              \n                      [[ 0.0310],\n                       [ 0.0110],\n                       [ 0.0396],\n                       ...,\n                       [ 0.0069],\n                       [ 0.0966],\n                       [-0.0250]]], dtype=torch.float64)),\n             ('6.7.convpath.0.0.1.weight',\n              tensor([1.0092, 0.9771, 0.9662, 0.9659, 0.9897, 0.9591, 0.9641, 0.9586, 0.9697,\n                      0.9677, 0.9641, 0.9755, 0.9775, 0.9753, 0.9701, 0.9801, 0.9814, 0.9696,\n                      0.9719, 0.9538, 0.9716, 0.9806, 0.9509, 0.9683, 0.9908, 0.9587, 0.9647,\n                      0.9898, 0.9796, 0.9570, 0.9657, 0.9903, 0.9774, 0.9639, 0.9829, 0.9768,\n                      0.9662, 0.9695, 0.9547, 0.9966, 0.9855, 0.9658, 0.9589, 0.9964, 0.9760,\n                      0.9701, 0.9924, 0.9467, 0.9859, 0.9763, 0.9852, 0.9704, 0.9560, 0.9680,\n                      0.9877, 0.9593, 0.9637, 0.9697, 0.9758, 0.9844, 0.9901, 0.9739, 0.9951,\n                      0.9823], dtype=torch.float64)),\n             ('6.7.convpath.0.0.1.bias',\n              tensor([ 0.0088,  0.0015,  0.0130, -0.0094, -0.0120, -0.0068, -0.0032, -0.0185,\n                       0.0069, -0.0063, -0.0046,  0.0146,  0.0104, -0.0059,  0.0187,  0.0003,\n                      -0.0042,  0.0099, -0.0079,  0.0138, -0.0124, -0.0003, -0.0069,  0.0107,\n                       0.0233, -0.0117, -0.0354,  0.0088, -0.0217, -0.0304, -0.0043,  0.0092,\n                       0.0100, -0.0040,  0.0014, -0.0075, -0.0004, -0.0169, -0.0035,  0.0226,\n                       0.0109,  0.0037, -0.0106,  0.0139, -0.0015, -0.0102, -0.0053,  0.0062,\n                      -0.0085, -0.0195,  0.0149, -0.0066,  0.0011,  0.0076,  0.0231, -0.0053,\n                      -0.0196,  0.0124,  0.0180,  0.0110,  0.0100, -0.0140,  0.0269,  0.0047],\n                     dtype=torch.float64)),\n             ('6.7.convpath.0.0.1.running_mean',\n              tensor([-4.4709e-01,  3.2206e-01,  1.0960e-01, -4.2228e-01,  2.9116e-01,\n                      -2.3160e-01, -4.1198e-02, -3.1612e-01, -7.0481e-02, -1.9745e-01,\n                      -9.3042e-01,  1.6199e-01, -6.2554e-01, -5.8980e-01,  8.8372e-01,\n                       8.8947e-01,  6.5809e-01, -8.4591e-02,  5.3461e-01, -9.0810e-01,\n                      -5.5649e-02, -1.0478e-01,  5.7140e-01,  8.4632e-01, -6.0553e-01,\n                      -1.2738e+00,  5.4283e-01, -3.9438e-01,  8.2325e-02,  9.6874e-01,\n                       1.1020e+00,  1.1073e-01, -4.1470e-01,  1.8697e-02, -6.8545e-01,\n                      -2.8432e-01, -5.8978e-01, -1.8468e-01, -3.6847e-01,  7.4530e-01,\n                      -5.5156e-01, -1.1988e-01, -6.0985e-02, -2.7134e-01, -1.2102e-01,\n                      -2.9494e-02, -5.2589e-01, -6.3264e-01,  1.7223e-01, -6.2544e-01,\n                      -1.2528e-01,  1.8312e-01, -1.1026e+00,  2.1019e-01, -4.5637e-01,\n                       7.4434e-01, -5.0559e-01,  3.1560e-01, -3.5955e-01, -1.2320e-01,\n                      -1.1136e-03,  2.1425e-01, -9.4900e-01,  3.7618e-02],\n                     dtype=torch.float64)),\n             ('6.7.convpath.0.0.1.running_var',\n              tensor([0.0986, 0.2058, 0.5031, 0.3456, 0.0835, 0.3940, 0.1304, 0.1035, 0.1561,\n                      0.1784, 0.2891, 0.2451, 0.1126, 0.1908, 0.6008, 0.5388, 0.3412, 0.1749,\n                      0.4356, 0.5420, 0.1034, 0.1150, 0.4273, 0.1447, 0.7029, 0.2361, 0.7409,\n                      0.1626, 0.2049, 0.8326, 0.5391, 0.1129, 0.5372, 0.1509, 0.0980, 0.2431,\n                      0.1887, 0.1394, 0.2727, 0.1722, 0.1566, 0.1334, 0.2688, 0.1299, 0.0916,\n                      0.1377, 0.0975, 0.5128, 0.0850, 0.1087, 0.1034, 0.1730, 0.3888, 0.4493,\n                      0.1583, 0.4558, 0.1691, 0.3245, 0.1524, 0.0867, 0.1146, 0.4909, 0.1611,\n                      0.1774], dtype=torch.float64)),\n             ('6.7.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.7.convpath.0.1.0.weight',\n              tensor([[[ 1.2412e-01, -1.4575e-01, -5.3326e-03,  1.1730e-01,  1.4899e-01],\n                       [ 3.8330e-02, -1.1052e-01, -1.2683e-01, -1.9285e-02,  2.4551e-02],\n                       [ 5.1682e-02, -7.2520e-02, -6.3742e-02,  2.0752e-02,  4.3689e-02],\n                       ...,\n                       [ 1.8805e-03,  2.3706e-03, -3.2104e-02,  1.2766e-01,  1.3889e-02],\n                       [ 1.2221e-01,  2.7751e-02,  1.8221e-02, -6.5439e-02, -1.5686e-02],\n                       [-2.9641e-02,  2.8005e-02,  4.9285e-02,  3.4803e-02, -6.1880e-02]],\n              \n                      [[ 6.5340e-02, -3.2313e-03,  2.4173e-02,  1.8863e-02, -5.3450e-02],\n                       [ 5.5821e-02, -2.0517e-01,  4.9215e-02, -1.1132e-02, -4.0468e-02],\n                       [-2.3987e-01,  2.3344e-02,  9.7126e-02,  3.5584e-02, -2.8119e-02],\n                       ...,\n                       [-2.2060e-02,  7.0075e-02,  2.9676e-02,  1.6899e-01,  6.7768e-02],\n                       [-1.2153e-01,  9.9617e-02,  5.6672e-02, -6.0307e-03,  1.9294e-02],\n                       [ 3.0212e-02,  8.8563e-02, -2.0466e-01, -1.3635e-02, -1.4361e-01]],\n              \n                      [[-2.7867e-02,  1.3783e-01, -1.3297e-01, -1.3861e-01, -1.1029e-02],\n                       [ 2.0313e-02, -9.1026e-03,  4.6112e-02, -4.5050e-02, -2.4769e-03],\n                       [-1.4907e-02, -1.0210e-01,  3.9924e-02,  4.4094e-02, -2.0041e-02],\n                       ...,\n                       [-4.6338e-02,  1.2205e-01,  1.0770e-01, -1.5950e-03, -4.8658e-02],\n                       [ 9.8997e-02,  7.1829e-03,  1.4762e-01,  1.1187e-01, -6.8476e-02],\n                       [ 3.3564e-02, -1.8746e-02,  8.8012e-02, -6.6003e-02,  1.3959e-01]],\n              \n                      ...,\n              \n                      [[-1.1264e-01, -8.6263e-02, -8.6817e-02, -3.3818e-02, -1.1265e-01],\n                       [-1.8666e-04, -1.0181e-04, -1.0996e-01, -1.4141e-01,  4.1286e-02],\n                       [-1.3787e-01, -2.8461e-02,  1.2039e-01,  4.2411e-02,  1.3354e-02],\n                       ...,\n                       [ 1.1489e-02, -6.3584e-02, -5.0882e-02, -1.8576e-01, -4.8135e-02],\n                       [-9.2282e-02, -6.1507e-02, -5.9662e-02,  8.7831e-02, -5.1142e-03],\n                       [-6.3506e-02, -5.6199e-02,  2.8567e-02, -1.0404e-02, -8.5436e-02]],\n              \n                      [[ 7.4452e-03,  4.8705e-02, -8.8329e-02,  1.1623e-01,  1.2001e-01],\n                       [-6.6653e-02,  2.8182e-02,  8.5429e-02,  5.3588e-03, -8.6607e-02],\n                       [ 7.0300e-02,  1.1531e-01,  1.9382e-02, -7.5359e-02, -8.1458e-02],\n                       ...,\n                       [-1.5523e-01, -8.2766e-02,  8.0274e-02,  4.9847e-02,  5.9008e-02],\n                       [-2.9197e-04, -3.8981e-03, -7.4774e-02, -1.3034e-01, -1.3672e-01],\n                       [ 9.1060e-02, -8.2616e-02, -1.0709e-01,  1.2206e-01, -7.6210e-02]],\n              \n                      [[-8.3405e-02, -1.7157e-01,  7.9575e-02, -6.5555e-02, -7.5904e-03],\n                       [ 1.6140e-01, -1.4048e-01,  5.3992e-02, -4.9909e-02, -1.0861e-01],\n                       [ 2.0310e-02,  1.0672e-01,  1.5073e-02,  2.9792e-02, -5.5447e-03],\n                       ...,\n                       [ 3.0940e-02, -1.0294e-01, -3.5059e-02, -7.3661e-02, -5.8832e-02],\n                       [-2.7469e-02, -4.4009e-02,  2.1994e-02, -5.5769e-02, -1.1637e-01],\n                       [-1.1300e-01, -1.1986e-03,  2.1710e-02,  1.1594e-02, -1.7025e-02]]],\n                     dtype=torch.float64)),\n             ('6.7.convpath.0.1.1.weight',\n              tensor([0.9898, 0.9804, 0.9557, 0.9557, 0.9742, 0.9635, 0.9893, 0.9810, 0.9807,\n                      0.9568, 0.9905, 0.9392, 0.9299, 0.9653, 0.9865, 0.9610, 0.9838, 0.9563,\n                      0.9681, 0.9355, 0.9748, 0.9658, 0.9842, 0.9547, 0.9440, 0.9668, 0.9509,\n                      1.0212, 0.9698, 0.9772, 0.9688, 0.9705, 1.0089, 0.9422, 0.9700, 0.9782,\n                      0.9598, 0.9448, 0.9637, 0.9634, 0.9368, 0.9577, 0.9656, 0.9451, 0.9467,\n                      0.9381, 0.9567, 0.9806, 1.0139, 0.9760, 0.9686, 0.9241, 0.9693, 0.9613,\n                      0.9571, 0.9580, 1.0190, 0.9173, 0.9746, 0.9845, 0.9855, 0.9758, 0.9914,\n                      0.9639], dtype=torch.float64)),\n             ('6.7.convpath.0.1.1.bias',\n              tensor([ 1.7705e-05, -8.3008e-03, -8.9500e-03, -1.1600e-02,  1.3772e-03,\n                      -1.4480e-02,  6.3453e-03,  1.1437e-02,  9.4652e-03,  1.6378e-03,\n                       1.4161e-02, -3.4924e-02,  2.4510e-03, -1.0505e-02,  1.6462e-02,\n                       1.4814e-03,  2.4546e-03, -6.0179e-04,  1.0428e-02, -1.4090e-02,\n                       9.6360e-03, -2.4580e-02,  1.8338e-03, -9.9366e-03, -1.8377e-02,\n                      -1.1654e-02, -6.2127e-03,  2.5345e-02, -2.2487e-02,  4.1988e-03,\n                      -1.4058e-03, -1.4298e-02,  1.5386e-02, -1.9182e-02, -1.4748e-02,\n                      -1.3501e-02, -2.0651e-02, -3.2022e-02, -1.9587e-02, -3.8651e-04,\n                       1.8055e-03, -7.2941e-03, -2.1827e-02, -2.1465e-02, -8.8045e-03,\n                      -1.6548e-02, -1.3357e-02,  2.4029e-03, -9.6427e-04,  5.0055e-03,\n                      -7.4223e-03, -1.8886e-02, -1.0791e-02, -1.0968e-02, -2.4477e-02,\n                       1.5383e-03,  1.4176e-02, -1.1780e-02, -1.8627e-02,  8.8022e-03,\n                      -2.2120e-03,  1.1865e-03,  1.6239e-02,  4.1783e-03],\n                     dtype=torch.float64)),\n             ('6.7.convpath.0.1.1.running_mean',\n              tensor([ 0.6763,  0.0578, -0.0053,  0.3731, -0.2817,  0.7373,  0.0637, -0.3054,\n                      -0.6437,  0.5518, -0.2666, -0.6452, -0.2400,  0.1034, -0.5692, -0.2805,\n                       0.6150, -0.1274,  0.0621, -0.8910,  0.2998, -0.4710,  0.1468,  0.2788,\n                      -0.4233, -0.7493,  1.1968,  0.3071, -0.0312, -0.6981,  0.8295, -0.3217,\n                      -0.2529, -0.4806,  0.3241, -0.4653, -0.0445, -0.0626, -0.6874, -0.0265,\n                      -0.7829,  0.4947,  0.8369,  1.0345, -0.0674, -0.1988,  0.1449,  0.3052,\n                      -0.2444,  0.5238, -0.5866, -0.4534, -0.5170,  0.6356,  0.0155,  0.8364,\n                      -0.8019, -0.5732, -0.2875,  0.0413, -0.0495, -0.6168, -0.3610, -1.0018],\n                     dtype=torch.float64)),\n             ('6.7.convpath.0.1.1.running_var',\n              tensor([0.5579, 0.6839, 0.5906, 0.6224, 0.3973, 0.4943, 0.4226, 0.4361, 0.4040,\n                      0.4330, 0.4934, 0.7146, 0.5885, 0.5839, 0.5970, 0.5087, 0.5757, 0.4699,\n                      0.4642, 0.6962, 0.9654, 0.5364, 0.4381, 0.6028, 0.5308, 0.5356, 0.6284,\n                      0.4491, 0.6183, 0.3979, 0.4790, 0.4408, 0.4883, 0.7334, 0.4007, 0.5635,\n                      0.5321, 1.1600, 0.7589, 0.5066, 0.5667, 0.6680, 0.8357, 0.7251, 0.5130,\n                      0.7356, 0.6498, 0.6084, 0.6986, 0.6872, 0.5915, 0.4531, 1.1778, 0.7638,\n                      0.7015, 0.5247, 0.4970, 0.9974, 0.4244, 0.4558, 0.5693, 0.6700, 0.4813,\n                      0.6685], dtype=torch.float64)),\n             ('6.7.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.7.convpath.0.2.0.weight',\n              tensor([[[ 0.0307],\n                       [ 0.0978],\n                       [-0.0232],\n                       ...,\n                       [-0.0448],\n                       [ 0.1130],\n                       [ 0.0750]],\n              \n                      [[-0.1199],\n                       [-0.0124],\n                       [ 0.0272],\n                       ...,\n                       [-0.1239],\n                       [-0.1719],\n                       [ 0.2395]],\n              \n                      [[ 0.2251],\n                       [ 0.1154],\n                       [ 0.1930],\n                       ...,\n                       [ 0.0430],\n                       [-0.0167],\n                       [ 0.0704]],\n              \n                      ...,\n              \n                      [[-0.0380],\n                       [-0.0914],\n                       [-0.1436],\n                       ...,\n                       [ 0.0092],\n                       [-0.0122],\n                       [-0.0521]],\n              \n                      [[-0.0386],\n                       [-0.1712],\n                       [ 0.3236],\n                       ...,\n                       [-0.0435],\n                       [ 0.0551],\n                       [-0.3284]],\n              \n                      [[ 0.0118],\n                       [-0.0019],\n                       [ 0.0355],\n                       ...,\n                       [ 0.0263],\n                       [ 0.1237],\n                       [-0.0376]]], dtype=torch.float64)),\n             ('6.7.convpath.0.2.1.weight',\n              tensor([-0.0027, -0.0072,  0.0034,  0.0026, -0.0096,  0.0179,  0.0225,  0.0139,\n                       0.0148,  0.0590, -0.0233,  0.0062,  0.0317, -0.0154,  0.0134, -0.0442,\n                       0.0194,  0.0018, -0.0285,  0.0219, -0.0269, -0.0152, -0.0150, -0.0281,\n                      -0.0029,  0.0091, -0.0048,  0.0155,  0.0056, -0.0238,  0.0160, -0.0311,\n                      -0.0100, -0.0139,  0.0302, -0.0047,  0.0228,  0.0119,  0.0073,  0.0071,\n                      -0.0206,  0.0224, -0.0108, -0.0021,  0.0187,  0.0079,  0.0176,  0.0065,\n                       0.0145, -0.0209, -0.0111, -0.0065,  0.0517,  0.0116, -0.0090, -0.0313,\n                       0.0172,  0.0195, -0.0054,  0.0134, -0.0033, -0.0225, -0.0033,  0.0005,\n                       0.0134, -0.0171,  0.0085,  0.0383, -0.0034, -0.0172,  0.0092, -0.0047,\n                       0.0141,  0.0156, -0.0024, -0.0080,  0.0176,  0.0052,  0.0207,  0.0096,\n                      -0.0142, -0.0073, -0.0009,  0.0122, -0.0063, -0.0334,  0.0207,  0.0121,\n                       0.0031, -0.0140,  0.0244,  0.0085, -0.0097, -0.0052, -0.0160,  0.0087,\n                      -0.0061, -0.0181,  0.0182,  0.0094, -0.0050, -0.0372,  0.0071, -0.0371,\n                      -0.0192, -0.0198, -0.0189, -0.0215,  0.0281, -0.0043, -0.0009,  0.0184,\n                      -0.0055, -0.0248,  0.0171,  0.0178, -0.0197, -0.0160, -0.0084, -0.0046,\n                       0.0067, -0.0081, -0.0039, -0.0168,  0.0089, -0.0031,  0.0177, -0.0286,\n                       0.0026,  0.0093, -0.0336,  0.0413,  0.0361,  0.0182, -0.0305, -0.0003,\n                       0.0193, -0.0019,  0.0172,  0.0249, -0.0076,  0.0014, -0.0128,  0.0097,\n                       0.0042, -0.0061, -0.0177, -0.0429, -0.0143,  0.0116,  0.0095, -0.0071,\n                       0.0106,  0.0065,  0.0155,  0.0034,  0.0108, -0.0147, -0.0051,  0.0294,\n                       0.0208, -0.0096,  0.0026,  0.0219, -0.0065,  0.0065,  0.0338, -0.0018,\n                       0.0024,  0.0172,  0.0130,  0.0023,  0.0192, -0.0047, -0.0393, -0.0183,\n                       0.0169, -0.0144,  0.0007,  0.0171, -0.0059,  0.0185, -0.0008,  0.0097,\n                       0.0104,  0.0293, -0.0143, -0.0109, -0.0206, -0.0014,  0.0184, -0.0142,\n                      -0.0182, -0.0191,  0.0098, -0.0166, -0.0107,  0.0636, -0.0131, -0.0144,\n                      -0.0208,  0.0289,  0.0305, -0.0209,  0.0181, -0.0160, -0.0105, -0.0180,\n                       0.0064, -0.0031,  0.0020, -0.0096,  0.0212,  0.0183, -0.0058,  0.0070,\n                       0.0321,  0.0069,  0.0005,  0.0322,  0.0096,  0.0212,  0.0160,  0.0088,\n                       0.0087, -0.0073, -0.0146, -0.0208, -0.0165, -0.0273,  0.0244, -0.0143,\n                       0.0307, -0.0223,  0.0019,  0.0184, -0.0154, -0.0196, -0.0037, -0.0030,\n                      -0.0172, -0.0193,  0.0317,  0.0036,  0.0067, -0.0023, -0.0173, -0.0065,\n                       0.0259,  0.0143, -0.0013, -0.0075,  0.0311, -0.0264, -0.0201, -0.0214],\n                     dtype=torch.float64)),\n             ('6.7.convpath.0.2.1.bias',\n              tensor([-6.4310e-04,  3.0266e-03,  1.3523e-02,  1.4955e-02,  1.3641e-03,\n                       1.9735e-03,  1.1713e-02,  2.0105e-04,  8.8579e-03,  2.3631e-02,\n                       1.4349e-02, -7.5146e-03,  7.0602e-03, -4.0048e-03,  8.2470e-03,\n                       3.5324e-03,  2.3340e-02, -3.0539e-03,  1.3073e-02, -3.9840e-03,\n                      -3.1628e-03,  2.1535e-03,  1.3177e-03,  6.2361e-03, -3.9429e-03,\n                      -1.6749e-02,  3.7209e-03,  9.4102e-03, -5.2147e-05, -4.2308e-03,\n                       4.3546e-03,  9.0270e-03, -7.4598e-03,  1.8011e-02,  1.2783e-02,\n                       1.5365e-02,  3.1660e-03,  1.9537e-02,  6.6100e-03,  1.5355e-02,\n                       8.2375e-04,  2.2604e-02, -3.0727e-03,  1.4347e-03,  3.9175e-03,\n                      -1.0694e-02,  9.7227e-03,  3.7379e-03, -1.0614e-02,  9.8711e-03,\n                       8.6267e-03,  9.2707e-03,  9.5532e-03,  1.0918e-02,  7.9944e-03,\n                       1.5720e-02,  8.2192e-03,  2.4069e-03,  1.0538e-02,  2.2151e-03,\n                      -5.6736e-03,  2.4276e-03,  4.6402e-03,  8.6080e-03, -3.9128e-03,\n                       5.4495e-03, -1.1817e-02,  1.3345e-02,  1.6804e-03, -1.2255e-02,\n                       1.7006e-03,  8.1716e-03,  7.1207e-04, -7.0969e-03,  1.4879e-02,\n                       3.5225e-03,  3.5022e-03, -7.6848e-04,  6.0321e-03,  1.0899e-03,\n                       1.0637e-02, -4.5603e-03,  9.2227e-03,  4.2682e-03, -4.5702e-03,\n                       1.2254e-02,  1.0245e-03,  1.1379e-03,  1.7409e-02,  3.7657e-03,\n                      -8.7677e-04,  1.4606e-02,  1.3548e-02, -1.1512e-03,  9.5210e-03,\n                      -1.2912e-02,  1.3969e-02,  5.5293e-03,  9.4927e-03, -3.2621e-03,\n                       1.9079e-02,  5.5719e-03,  1.5951e-03,  1.0800e-02,  7.4802e-03,\n                      -2.1610e-03, -6.0193e-04,  3.5014e-03,  4.3637e-03,  9.1421e-03,\n                      -9.8225e-03, -7.8711e-03,  5.1215e-03,  1.8343e-02,  1.4099e-02,\n                       6.5407e-03,  9.2268e-03,  1.7546e-03,  3.7921e-03, -1.4732e-02,\n                       2.4878e-03,  9.6280e-03, -1.3666e-03, -1.5058e-03, -1.2413e-02,\n                       9.9689e-03,  1.2171e-02,  5.1879e-03,  2.8381e-03,  1.7530e-02,\n                       2.2984e-02,  1.5166e-02,  1.5671e-02,  8.1236e-03,  1.4446e-02,\n                      -6.7558e-03,  1.6293e-02,  9.0098e-03,  1.2868e-02,  8.2508e-03,\n                       1.5619e-02, -2.9553e-03,  1.6187e-02,  5.7071e-03, -5.3338e-03,\n                       1.3729e-02,  2.3573e-03, -1.7476e-03,  6.9092e-03,  9.2034e-03,\n                       6.6413e-03,  1.1541e-02,  1.2157e-02,  1.3217e-02,  1.5129e-02,\n                       8.6912e-03,  1.0545e-03,  4.7117e-03, -2.6611e-03, -1.0338e-02,\n                       2.1897e-03, -2.4989e-03,  1.7499e-03,  9.1321e-03,  9.3041e-03,\n                      -6.9190e-04, -1.0907e-02,  1.0950e-02,  9.5735e-04,  1.6206e-02,\n                       5.3129e-03,  6.0487e-03,  1.2237e-02,  1.0375e-02, -1.2957e-02,\n                      -8.2148e-04,  7.8217e-04,  1.2156e-02,  3.2341e-03,  7.0064e-03,\n                      -3.6960e-03,  1.1346e-02, -7.3027e-03, -8.7408e-03,  1.9468e-02,\n                       7.2535e-03,  1.3081e-02,  9.9193e-03,  5.1627e-03,  1.2959e-02,\n                       6.4913e-03,  3.7420e-03,  1.0763e-02, -5.3347e-03, -1.0886e-03,\n                       7.5504e-03, -2.6032e-03,  2.0513e-02,  7.8173e-03,  1.9035e-02,\n                       3.1612e-03,  2.3347e-02,  1.9537e-02,  2.0485e-02,  1.4688e-03,\n                      -3.3145e-03,  1.4129e-02, -7.1476e-03,  8.9060e-03,  1.3974e-02,\n                       2.5388e-03,  1.1654e-02,  1.4502e-02,  9.4520e-03,  1.0603e-02,\n                      -2.2536e-04,  4.5945e-03, -4.9269e-03,  2.4814e-03, -1.2555e-04,\n                      -1.2941e-02,  3.7497e-03,  4.9243e-03,  2.3294e-02, -5.0601e-03,\n                       3.1189e-03, -3.6558e-03,  1.1761e-03, -1.5428e-02,  1.3770e-02,\n                       8.6235e-03, -1.5004e-03,  1.1128e-02,  2.9118e-03,  2.4640e-03,\n                       7.7806e-03,  7.7242e-03, -7.3132e-03,  1.0462e-02,  5.2491e-03,\n                       2.5547e-03,  3.1126e-03,  4.9114e-03,  8.1383e-03,  1.9295e-03,\n                       1.5132e-02,  2.3174e-03,  9.1508e-03,  1.0946e-03, -8.9490e-03,\n                       1.7439e-02,  2.2255e-02,  1.6314e-02,  1.6748e-02,  9.9298e-03,\n                       6.0093e-03], dtype=torch.float64)),\n             ('6.7.convpath.0.2.1.running_mean',\n              tensor([ 1.1512e-01, -1.2408e-01,  1.5560e-02, -8.5132e-01, -3.5015e-01,\n                       4.2217e-02,  1.2696e-01, -7.7264e-01, -1.6587e-01,  4.5704e-01,\n                       1.8437e-01, -2.0660e-01,  1.8374e-01,  4.2693e-01,  2.3723e-01,\n                       4.1612e-01,  2.6384e-01, -6.5560e-02,  3.6698e-01, -1.1522e-01,\n                       4.1765e-01, -2.7076e-02, -6.7437e-01,  6.6193e-01, -2.9848e-01,\n                      -2.4320e-02, -5.2726e-01, -2.6279e-01, -1.9906e-01,  2.1640e-01,\n                       2.4205e-01,  7.3942e-01, -4.3810e-01, -4.2748e-01,  9.7373e-01,\n                       4.6799e-02, -1.1484e-01,  1.9489e-01, -9.9132e-03, -2.1565e-01,\n                      -3.7611e-03, -2.0207e-01,  4.1583e-01,  1.0388e-01, -1.8847e-01,\n                       5.9116e-01,  7.7558e-01,  1.8660e-02,  6.1626e-01,  4.5345e-02,\n                       1.9901e-01, -2.9076e-01, -6.0460e-01, -4.8277e-01, -4.7542e-01,\n                      -6.3918e-01, -3.8531e-01, -9.7001e-01,  1.5485e-01, -3.9927e-01,\n                      -8.8332e-02,  1.5185e-01, -2.2313e-01,  8.5599e-02, -5.2458e-01,\n                      -2.3378e-01, -2.2279e-01,  1.9789e-02, -7.0119e-01,  2.5366e-02,\n                       3.8578e-01,  1.2038e-01,  2.3105e-01,  2.8917e-01, -3.9217e-01,\n                       2.2373e-01, -7.5155e-01,  1.3956e-01,  2.8009e-01,  2.9260e-01,\n                       3.3937e-02,  7.4909e-02, -5.6992e-02, -3.9280e-01, -1.8434e-01,\n                       8.0144e-01,  3.0549e-01, -1.0238e-02, -2.0356e-01, -2.1057e-01,\n                       1.9111e-01,  4.2198e-01,  1.5288e-01,  1.4493e-01,  4.0992e-02,\n                       7.3222e-02,  5.2985e-02, -4.6559e-01,  9.3975e-02, -6.7458e-01,\n                       3.8736e-01, -2.9781e-01,  4.2128e-01, -9.1290e-02, -4.8175e-01,\n                       6.7395e-02, -4.4238e-01, -4.1089e-01, -3.8686e-02, -4.1475e-01,\n                       3.6315e-01,  8.0348e-01, -2.1372e-01,  5.6031e-01,  7.4356e-01,\n                      -7.8413e-01, -7.2186e-02, -3.9836e-01,  4.1905e-01, -3.6362e-01,\n                      -2.4260e-01,  2.8073e-01,  3.7776e-01, -5.3364e-01,  8.3810e-02,\n                      -2.7595e-01, -4.9132e-01, -2.2815e-01, -2.9682e-01, -3.7972e-01,\n                       3.6437e-01,  2.2522e-02,  4.9806e-02, -1.7390e-01, -3.9235e-02,\n                      -1.8719e-01, -3.1922e-01,  4.5318e-01, -2.6429e-01, -1.5119e-01,\n                       1.2889e-01,  1.2184e-01,  3.2751e-01,  2.9640e-01, -1.4548e-02,\n                       8.6737e-02,  4.9984e-02, -4.8113e-01, -1.9177e-01,  2.4673e-02,\n                      -4.4606e-02,  8.5359e-01,  3.5509e-02, -1.2024e+00, -7.1799e-02,\n                       2.8443e-01, -3.4485e-01, -2.1267e-01,  5.2309e-01,  7.7542e-01,\n                       1.7128e-01,  6.7273e-01, -4.0564e-01,  3.0869e-01,  3.0037e-02,\n                      -2.1506e-01, -3.0321e-01,  1.7760e-02, -7.1043e-01, -7.5932e-01,\n                      -5.2463e-01,  9.7043e-02,  1.9130e-01, -2.1352e-01, -1.5883e-01,\n                      -9.1983e-02,  2.0166e-01,  7.6388e-01, -3.0779e-01,  3.4648e-02,\n                      -2.2712e-01, -1.8830e-01, -9.3982e-02,  3.6128e-01,  5.3542e-02,\n                       6.5232e-01,  3.7795e-01,  9.1646e-01,  4.2479e-01, -1.1099e-01,\n                       2.3958e-01,  5.0025e-01,  5.2223e-01, -7.7900e-01,  1.0615e+00,\n                       4.9611e-01,  5.0739e-01, -2.3274e-01,  4.7762e-01,  2.6956e-01,\n                      -1.5073e-02,  1.5371e-01, -3.0923e-01,  2.7307e-02,  2.8011e-01,\n                       1.0251e-03,  1.9787e-01,  6.5064e-02, -2.2209e-01,  2.9206e-01,\n                       4.9768e-02, -3.2531e-01,  5.9996e-02,  5.2804e-01,  1.4994e-01,\n                      -6.9907e-01,  2.1000e-01,  2.6851e-01, -6.0916e-02, -1.1554e-01,\n                       5.8100e-02,  5.3631e-01,  1.2036e-01,  5.0412e-01, -5.6109e-01,\n                       7.9764e-02, -2.5969e-01, -4.1700e-01,  5.2554e-02, -1.4842e-01,\n                      -1.7673e-01,  2.0233e-02,  3.8279e-01, -9.5141e-01, -9.7629e-02,\n                      -2.5934e-01, -4.9792e-01, -3.0665e-01,  3.6194e-01,  2.3216e-01,\n                      -4.1103e-01,  4.3288e-01,  1.9449e-01,  1.8349e-01, -4.2285e-01,\n                       1.2935e-01,  2.4047e-01,  2.7934e-01, -1.8135e-01,  1.6763e-01,\n                       3.2113e-01,  8.6672e-01, -4.9214e-01, -1.8051e-01, -2.7455e-01,\n                      -2.3996e-02], dtype=torch.float64)),\n             ('6.7.convpath.0.2.1.running_var',\n              tensor([0.1763, 0.2902, 0.1368, 0.3435, 0.2298, 0.4274, 0.3648, 0.3360, 0.3056,\n                      0.3993, 0.4764, 0.4587, 0.2467, 0.3302, 0.7383, 0.3946, 0.3114, 0.3322,\n                      0.3356, 0.4499, 0.6490, 0.3187, 0.4116, 0.4618, 0.2705, 0.1629, 0.3687,\n                      0.3091, 0.3695, 0.4162, 0.3992, 0.6415, 0.2321, 0.4860, 0.4676, 0.3051,\n                      0.3844, 0.2864, 0.3057, 0.4422, 0.2759, 0.5380, 0.4338, 0.2321, 0.4479,\n                      0.4959, 0.5419, 0.1503, 0.6391, 0.2968, 0.3082, 0.4063, 0.4344, 0.2169,\n                      0.7768, 0.4015, 0.5011, 0.7171, 0.5609, 0.3848, 0.1397, 0.3559, 0.1262,\n                      0.0762, 0.4903, 0.3040, 0.5215, 0.5612, 0.5729, 0.6270, 0.3288, 0.0524,\n                      0.4380, 0.5868, 0.3569, 0.1323, 0.6394, 0.1275, 0.4430, 0.1727, 0.4795,\n                      0.1815, 0.1507, 0.4827, 0.3130, 0.5819, 0.3847, 0.4898, 0.1871, 0.3617,\n                      0.4780, 0.4848, 0.2842, 0.2618, 0.4814, 0.1643, 0.4439, 0.4564, 0.3517,\n                      0.4019, 0.4228, 0.3466, 0.4442, 0.3137, 0.2915, 0.2062, 0.5094, 0.4589,\n                      0.3910, 0.2185, 0.2913, 0.6120, 0.3326, 0.3221, 0.4527, 1.0174, 0.3833,\n                      0.3956, 0.3401, 0.3829, 0.2587, 0.3914, 0.4963, 0.3290, 0.0334, 0.5787,\n                      0.2445, 0.3282, 0.1185, 0.3047, 0.2896, 0.4533, 0.6680, 0.2997, 0.2964,\n                      0.0905, 0.5363, 0.3147, 0.4183, 0.3169, 0.4233, 0.0761, 0.4567, 0.3016,\n                      0.1323, 0.5570, 0.1476, 0.4955, 0.2168, 0.2828, 0.6189, 0.4081, 0.2556,\n                      0.4254, 0.3023, 0.2096, 0.4307, 0.4043, 0.1449, 0.3941, 0.2938, 0.3435,\n                      0.2143, 0.4787, 0.3204, 0.5016, 0.5651, 0.2621, 0.4173, 0.5410, 0.3802,\n                      0.2864, 0.3719, 0.1569, 0.5917, 0.8820, 0.3565, 0.3000, 0.3099, 0.2438,\n                      0.4095, 0.3067, 0.3394, 0.5169, 0.1664, 0.5502, 0.4005, 0.2460, 0.3348,\n                      0.1205, 0.4364, 0.2886, 0.3837, 0.3965, 0.4111, 0.6575, 0.4061, 0.6476,\n                      0.3361, 0.2952, 0.5413, 0.6347, 0.2222, 0.3544, 0.2595, 0.4361, 0.1314,\n                      0.2743, 0.1941, 0.2709, 0.0599, 0.2339, 0.3215, 0.3650, 0.1493, 0.2679,\n                      0.5326, 0.2014, 0.0928, 0.3139, 0.3788, 0.4031, 0.2918, 0.2270, 0.5664,\n                      0.1987, 0.2120, 0.4421, 0.4900, 0.6519, 0.4197, 0.4528, 0.5932, 0.4342,\n                      0.1531, 0.3731, 0.2432, 0.3530, 0.3094, 0.2008, 0.3349, 0.3511, 0.5080,\n                      0.1615, 0.2013, 0.2903, 0.5566, 0.2432, 0.2517, 0.4269, 0.2402, 0.4185,\n                      0.3184, 0.4683, 0.3454, 0.1831], dtype=torch.float64)),\n             ('6.7.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.8.convs.0.0.weight',\n              tensor([[[ 0.0887],\n                       [ 0.1908],\n                       [ 0.0004],\n                       ...,\n                       [-0.1929],\n                       [-0.0329],\n                       [-0.1482]],\n              \n                      [[ 0.0307],\n                       [-0.0216],\n                       [ 0.0644],\n                       ...,\n                       [-0.0112],\n                       [ 0.0572],\n                       [-0.0078]],\n              \n                      [[ 0.0191],\n                       [-0.0794],\n                       [ 0.1195],\n                       ...,\n                       [ 0.0226],\n                       [ 0.1501],\n                       [-0.0330]],\n              \n                      ...,\n              \n                      [[-0.1072],\n                       [-0.1276],\n                       [-0.0823],\n                       ...,\n                       [ 0.0120],\n                       [ 0.0449],\n                       [ 0.1959]],\n              \n                      [[ 0.0403],\n                       [-0.0069],\n                       [-0.0745],\n                       ...,\n                       [-0.0265],\n                       [-0.0248],\n                       [ 0.1112]],\n              \n                      [[ 0.1272],\n                       [-0.0481],\n                       [ 0.0945],\n                       ...,\n                       [-0.1008],\n                       [ 0.0964],\n                       [-0.0450]]], dtype=torch.float64)),\n             ('6.8.convs.0.1.weight',\n              tensor([0.9432, 0.9569, 0.9626, 0.9683, 0.9310, 0.9730, 0.9851, 0.9899, 0.9576,\n                      0.9435, 0.9778, 0.9775, 0.9517, 0.9398, 0.9644, 0.9703, 0.9685, 0.9793,\n                      0.9998, 0.9856, 0.9785, 0.9639, 0.9547, 0.9304, 0.9758, 0.9599, 0.9863,\n                      0.9660, 0.9646, 0.9637, 0.9421, 0.9563, 0.9599, 0.9494, 0.9684, 0.9598,\n                      0.9766, 0.9847, 0.9537, 0.9395, 0.9668, 0.9661, 0.9245, 0.9577, 0.9434,\n                      0.9514, 0.9694, 0.9903, 0.9736, 0.9632, 0.9549, 0.9508, 0.9575, 0.9883,\n                      0.9784, 0.9684, 0.9587, 0.9708, 0.9473, 0.9809, 0.9349, 0.9334, 0.9571,\n                      0.9861], dtype=torch.float64)),\n             ('6.8.convs.0.1.bias',\n              tensor([ 3.1957e-02,  1.0140e-02, -1.6584e-03, -1.0707e-02,  7.1319e-03,\n                       7.3430e-03,  2.6610e-02,  2.0424e-02,  3.4163e-03, -2.4627e-02,\n                       5.8369e-03,  2.2534e-02, -3.6009e-03, -2.1155e-02,  2.1622e-02,\n                      -5.5873e-03,  4.1890e-03,  1.1985e-02,  3.1749e-02,  1.2038e-02,\n                      -2.6527e-03,  1.9104e-06,  1.1475e-02, -2.4049e-03,  1.8556e-02,\n                       2.0758e-03,  1.2750e-02, -5.8136e-03, -4.4656e-03, -1.1002e-02,\n                      -4.6054e-02, -1.1836e-02,  2.6681e-03,  7.7375e-03, -2.9621e-03,\n                      -2.4369e-03,  4.0917e-02,  1.3131e-02, -1.0694e-02,  1.4191e-03,\n                      -2.2527e-02,  3.8883e-03,  1.4124e-02, -7.3241e-04, -6.1489e-03,\n                      -2.5508e-04,  2.3807e-03,  7.3859e-03,  2.2536e-02, -2.4591e-02,\n                       7.5150e-03,  2.1880e-02,  1.9122e-02,  3.9752e-03,  1.6702e-02,\n                       8.1483e-03, -1.5730e-02,  6.9830e-03,  1.1226e-02,  1.4420e-02,\n                      -3.0214e-02, -1.9035e-02, -7.4814e-03,  1.1744e-02],\n                     dtype=torch.float64)),\n             ('6.8.convs.0.1.running_mean',\n              tensor([-0.2204, -0.0278,  0.6457,  0.0336, -0.8354, -0.0798,  0.1228, -0.2911,\n                      -0.0618, -0.2694, -0.6318, -0.4279, -0.0570, -0.2815,  0.1825,  1.1432,\n                       0.0067, -0.5452, -0.4348,  0.0697,  0.2302, -0.8138,  0.7798, -0.7765,\n                       0.1846,  0.2630, -0.6822,  0.5416,  0.8783,  0.5059,  1.1241,  0.8124,\n                      -0.1576, -0.2033,  0.5400, -0.0798, -0.5909,  0.4723, -0.2114, -0.3814,\n                       1.2772, -0.7225, -1.8504, -0.5363,  0.2021, -0.4371,  1.3005,  0.3725,\n                       0.6895,  0.4853,  1.2390, -0.3840, -0.1612,  0.4755, -0.2910,  0.5571,\n                       1.4032, -0.0836, -0.1793,  0.0949,  1.1415,  0.1029, -0.8563, -0.0079],\n                     dtype=torch.float64)),\n             ('6.8.convs.0.1.running_var',\n              tensor([0.4582, 0.1025, 0.5356, 0.1875, 0.4602, 0.1749, 0.2905, 0.4761, 0.2384,\n                      0.2034, 0.1193, 0.1812, 0.2275, 0.1862, 0.1612, 0.4259, 0.2005, 0.1092,\n                      0.0852, 0.1384, 0.1522, 0.1879, 0.1098, 0.3722, 0.1840, 0.0961, 0.1130,\n                      0.1514, 0.2868, 0.1737, 0.4457, 0.9146, 0.4892, 0.1985, 0.3453, 0.0886,\n                      0.2218, 0.7072, 0.1335, 0.3276, 0.4631, 0.1154, 0.7546, 0.2176, 0.3564,\n                      0.6445, 0.5307, 0.1086, 0.2054, 0.2893, 0.9250, 0.2823, 0.3166, 0.1220,\n                      0.1646, 0.5879, 0.5408, 0.1074, 0.3481, 0.1272, 1.5457, 0.2720, 0.1630,\n                      0.1514], dtype=torch.float64)),\n             ('6.8.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.8.convs.1.0.weight',\n              tensor([[[-0.0518,  0.0130,  0.0303, -0.0033,  0.0088],\n                       [ 0.0079, -0.0090, -0.1094,  0.0184, -0.0313],\n                       [-0.0506, -0.0159,  0.0017, -0.0637, -0.0266],\n                       ...,\n                       [-0.1071, -0.0035, -0.0646,  0.0441,  0.0364],\n                       [ 0.0847, -0.0741, -0.0224,  0.1212,  0.0829],\n                       [-0.0498, -0.0430,  0.0048,  0.0112, -0.1283]],\n              \n                      [[-0.0391,  0.0046,  0.0049, -0.0219, -0.0021],\n                       [ 0.0583, -0.0112,  0.0816, -0.0234,  0.0174],\n                       [-0.0777, -0.1587,  0.0602, -0.1133,  0.2556],\n                       ...,\n                       [ 0.0020,  0.0465, -0.1044,  0.0383,  0.0902],\n                       [ 0.0343,  0.0458, -0.0417,  0.0445,  0.0563],\n                       [ 0.1732,  0.1177, -0.0525,  0.1464, -0.0788]],\n              \n                      [[ 0.0322,  0.0898,  0.0767, -0.0267,  0.0408],\n                       [ 0.0743,  0.0236,  0.0147, -0.0565,  0.0610],\n                       [-0.1611,  0.2096,  0.0791,  0.0728,  0.0279],\n                       ...,\n                       [-0.0043, -0.0694, -0.0986,  0.0419,  0.1003],\n                       [-0.0048,  0.0044,  0.1156,  0.0230, -0.0379],\n                       [ 0.0152,  0.0301, -0.0630,  0.0004, -0.0766]],\n              \n                      ...,\n              \n                      [[-0.0630, -0.0219, -0.0319, -0.0581, -0.0456],\n                       [-0.0712,  0.0174, -0.1281, -0.0300, -0.0455],\n                       [ 0.0344,  0.0816, -0.0424, -0.0353, -0.0677],\n                       ...,\n                       [ 0.0751,  0.0141, -0.0146, -0.0573,  0.0082],\n                       [ 0.0400,  0.1133, -0.0071,  0.0310, -0.0379],\n                       [-0.0820, -0.0514, -0.0392, -0.0518, -0.0698]],\n              \n                      [[ 0.0050,  0.1157,  0.0725,  0.1076, -0.0227],\n                       [ 0.0059, -0.0630,  0.0211,  0.0814, -0.1217],\n                       [-0.1179, -0.0032, -0.1050, -0.0140, -0.1057],\n                       ...,\n                       [ 0.0331,  0.0176, -0.0088,  0.0416,  0.0565],\n                       [-0.1267, -0.0988, -0.0760, -0.0111,  0.0099],\n                       [ 0.0289,  0.1339,  0.1049, -0.0289,  0.0315]],\n              \n                      [[ 0.0555,  0.0048,  0.0929, -0.2199,  0.1547],\n                       [-0.0288,  0.0533, -0.0920,  0.0339, -0.0652],\n                       [-0.0466, -0.0596, -0.0319,  0.0675,  0.0960],\n                       ...,\n                       [-0.1127,  0.1021, -0.1163,  0.0227, -0.0102],\n                       [ 0.0334, -0.0106,  0.0057,  0.0829,  0.0593],\n                       [-0.1318, -0.0246, -0.0258, -0.0428, -0.0154]]], dtype=torch.float64)),\n             ('6.8.convs.1.1.weight',\n              tensor([0.9278, 0.9500, 0.9551, 0.9541, 0.9388, 0.9921, 0.9598, 0.9534, 0.9565,\n                      0.9248, 0.9488, 0.9669, 0.9173, 0.9720, 0.9524, 0.9150, 0.9493, 0.9581,\n                      0.9647, 0.9338, 0.9757, 0.9542, 0.9513, 0.9656, 0.9632, 0.9724, 0.9585,\n                      0.9527, 0.9482, 0.9589, 0.9281, 0.9948, 0.9660, 0.9435, 0.9560, 0.9793,\n                      0.9356, 0.9536, 1.0001, 0.9809, 0.9506, 0.9503, 0.9945, 0.9674, 0.9510,\n                      0.9493, 0.9584, 0.9512, 0.9450, 0.9519, 0.9568, 0.9763, 0.9774, 0.9326,\n                      0.9630, 0.9604, 0.9735, 0.9399, 0.9568, 0.9392, 0.9693, 1.0034, 0.9666,\n                      0.9075], dtype=torch.float64)),\n             ('6.8.convs.1.1.bias',\n              tensor([-0.0088, -0.0028, -0.0014,  0.0045, -0.0145,  0.0160, -0.0064,  0.0038,\n                      -0.0168, -0.0129, -0.0181,  0.0070, -0.0226, -0.0031,  0.0045, -0.0261,\n                      -0.0199, -0.0048,  0.0068, -0.0377,  0.0149,  0.0051,  0.0070, -0.0243,\n                       0.0128, -0.0056, -0.0150, -0.0004,  0.0118,  0.0154, -0.0149,  0.0052,\n                       0.0122, -0.0018, -0.0049,  0.0053, -0.0112, -0.0059,  0.0028, -0.0050,\n                      -0.0138,  0.0017,  0.0344,  0.0010,  0.0092, -0.0243, -0.0063, -0.0213,\n                       0.0029, -0.0055,  0.0131, -0.0009, -0.0124, -0.0060, -0.0158, -0.0096,\n                       0.0107, -0.0114, -0.0173, -0.0238, -0.0017,  0.0032,  0.0090, -0.0083],\n                     dtype=torch.float64)),\n             ('6.8.convs.1.1.running_mean',\n              tensor([-1.6298,  0.5967, -0.2267, -0.1021, -0.6781, -0.4661,  0.1649, -0.5324,\n                      -0.2398, -0.5106,  0.8791,  0.2589, -0.4289, -0.1792,  0.2552, -0.2599,\n                       0.1087,  0.8097,  0.1797,  0.0409,  0.1093, -0.4343, -0.3386,  0.4378,\n                      -1.3861, -0.6613,  0.5684,  0.0300, -0.0107,  0.2593, -0.0712, -0.0664,\n                      -0.1594, -0.6737, -0.4002,  0.3974,  0.1830, -0.4593,  0.0969, -0.6035,\n                       0.8069, -0.1840,  0.1336,  0.2122, -1.0001,  0.4269,  0.2946,  0.2759,\n                      -0.1767,  0.2423, -0.2035, -0.0995,  0.3086,  0.1128,  0.2670,  0.2479,\n                       0.4058,  0.1430,  1.0256, -0.2720,  0.4635,  0.0147,  0.3127, -0.1612],\n                     dtype=torch.float64)),\n             ('6.8.convs.1.1.running_var',\n              tensor([1.4099, 0.8047, 0.4382, 0.4238, 0.5661, 0.5920, 0.7461, 0.5145, 0.5038,\n                      0.8165, 0.5047, 0.7378, 0.7954, 0.5966, 0.5340, 1.1785, 0.4054, 0.6506,\n                      0.6381, 0.5328, 0.5028, 0.5062, 0.9323, 0.4126, 0.5714, 0.3687, 0.5791,\n                      0.4191, 0.4472, 0.5699, 0.5047, 0.4863, 0.4551, 0.7216, 0.5317, 0.6278,\n                      0.7575, 0.5333, 0.4858, 0.6514, 0.8848, 0.5382, 0.4358, 0.5524, 0.9425,\n                      0.9093, 0.4492, 0.3963, 0.4348, 0.5894, 0.5349, 0.4678, 0.5427, 1.0316,\n                      0.3913, 0.9412, 0.5207, 0.6250, 0.5527, 0.6484, 0.6759, 0.3738, 0.5024,\n                      0.8171], dtype=torch.float64)),\n             ('6.8.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.8.convs.2.0.weight',\n              tensor([[[ 0.0015],\n                       [ 0.0618],\n                       [-0.1841],\n                       ...,\n                       [-0.0679],\n                       [-0.0676],\n                       [-0.0832]],\n              \n                      [[ 0.0505],\n                       [ 0.0263],\n                       [-0.1381],\n                       ...,\n                       [-0.1041],\n                       [ 0.1079],\n                       [ 0.0236]],\n              \n                      [[-0.1187],\n                       [ 0.0748],\n                       [ 0.1667],\n                       ...,\n                       [ 0.0186],\n                       [ 0.3160],\n                       [ 0.0510]],\n              \n                      ...,\n              \n                      [[ 0.2023],\n                       [-0.0581],\n                       [-0.0273],\n                       ...,\n                       [-0.0748],\n                       [ 0.0278],\n                       [ 0.0081]],\n              \n                      [[ 0.0643],\n                       [ 0.0100],\n                       [-0.0992],\n                       ...,\n                       [-0.1634],\n                       [ 0.1541],\n                       [-0.0571]],\n              \n                      [[-0.0304],\n                       [-0.1885],\n                       [ 0.2055],\n                       ...,\n                       [-0.0573],\n                       [ 0.1835],\n                       [ 0.1255]]], dtype=torch.float64)),\n             ('6.8.convs.2.1.weight',\n              tensor([-2.0660e-03,  6.1894e-04,  6.3250e-03,  1.7064e-02, -1.0099e-02,\n                       1.7673e-02, -3.9634e-03, -4.3932e-02, -1.2278e-02,  6.6614e-04,\n                      -4.8536e-03,  2.8817e-02, -1.1313e-02, -6.4411e-03, -2.0540e-02,\n                       3.7784e-02, -1.2620e-02,  5.0773e-03, -1.0444e-02, -2.1709e-03,\n                       7.8726e-03, -4.7571e-03, -2.9992e-03, -5.1889e-03,  1.7685e-02,\n                       1.2147e-02, -8.9687e-03,  1.3441e-02,  6.2530e-03,  1.8847e-02,\n                      -1.5009e-02, -9.7421e-03, -8.4602e-04, -2.3385e-02,  9.1652e-03,\n                       1.2196e-03, -1.6587e-02, -9.9816e-03,  8.8335e-03,  3.7598e-03,\n                      -9.4836e-03,  8.7293e-03,  2.1139e-02, -2.7109e-02, -1.3489e-02,\n                      -9.9482e-03,  1.4132e-02,  2.8747e-02,  2.0804e-02,  6.0150e-03,\n                       2.7892e-02,  1.1385e-02, -1.9096e-04,  1.4533e-02,  1.6828e-02,\n                       5.2330e-02,  5.3676e-03,  1.5263e-02,  3.8217e-03,  1.1180e-03,\n                       5.4495e-03, -1.5431e-02,  4.9208e-03, -1.2997e-02,  9.7065e-03,\n                      -2.1196e-03, -9.5240e-03,  5.1660e-03,  2.1239e-02, -7.1946e-03,\n                       2.4575e-02,  2.1187e-02,  1.6203e-03, -9.2737e-04, -9.9068e-03,\n                       8.1525e-03,  2.1399e-02,  3.1293e-02, -4.1452e-03,  2.5280e-02,\n                      -1.4889e-02,  2.9710e-02,  2.2623e-02,  1.7331e-02, -2.1384e-02,\n                      -1.2634e-02,  1.7030e-03, -3.5038e-02,  1.5710e-03, -2.2587e-02,\n                      -7.5919e-03,  1.1272e-02, -8.4926e-03, -3.2500e-03, -4.8428e-03,\n                       2.2297e-02, -2.0893e-02, -1.4037e-02, -9.2617e-03,  1.3383e-02,\n                      -5.2591e-03,  2.2231e-02, -1.8991e-04, -1.8237e-02, -1.5163e-02,\n                      -1.8749e-02,  1.1699e-03,  8.8025e-03,  2.2007e-02,  1.8458e-02,\n                       2.2396e-05, -8.8249e-03, -1.9638e-02, -7.0404e-03,  1.0568e-02,\n                      -9.4188e-03, -2.9178e-03, -7.9452e-03,  1.4475e-02,  1.4389e-02,\n                       1.1300e-02, -1.5614e-02, -1.3186e-02, -1.2972e-02,  3.3864e-03,\n                       4.2606e-03,  3.0071e-02,  1.6589e-02, -1.3806e-02, -1.0296e-02,\n                       8.7019e-03, -3.9943e-03, -1.0120e-02,  2.5465e-03,  1.1756e-02,\n                       1.6570e-02, -1.4678e-02,  1.7318e-02, -4.3515e-03,  9.9493e-03,\n                       6.3169e-03, -1.9369e-02,  1.0131e-02,  4.9987e-03,  9.5437e-03,\n                       5.4485e-03, -2.0513e-02, -1.0796e-02,  7.6728e-03,  2.1991e-03,\n                       1.8767e-02, -3.6478e-03, -3.7939e-02, -1.1497e-02, -2.0247e-03,\n                       1.1245e-02, -1.0048e-02, -5.9844e-03, -1.7954e-02, -2.5308e-03,\n                      -7.8639e-03, -2.1146e-02,  6.5625e-03, -3.7818e-02, -3.1265e-02,\n                       2.0494e-02, -6.8358e-03, -2.1304e-02,  2.4668e-02, -2.2074e-02,\n                       7.6657e-04,  7.2933e-03,  4.7382e-03,  3.4108e-02,  2.0982e-02,\n                      -6.7730e-03, -4.7803e-03, -4.4514e-03, -1.7506e-03, -2.0707e-02,\n                       9.4255e-03, -1.4542e-02, -2.2228e-02, -1.0310e-02,  2.6845e-02,\n                      -4.6161e-04, -1.3318e-02,  9.7507e-03, -5.7632e-04,  1.2703e-02,\n                       6.8255e-03,  3.1781e-03, -4.1467e-02, -1.6447e-03, -1.0374e-02,\n                       2.5607e-02,  1.2754e-03,  8.0096e-03,  1.1529e-02, -1.0046e-02,\n                      -7.8666e-05, -1.5904e-02, -5.1813e-03, -2.2866e-02, -1.3025e-02,\n                      -9.0697e-03, -9.5688e-03, -1.4253e-03, -1.0787e-02, -9.0183e-03,\n                      -2.3644e-02,  1.0649e-02,  5.6574e-03,  2.1107e-02, -9.9541e-03,\n                      -8.3224e-03,  1.4262e-02,  1.1781e-02,  8.4630e-03,  3.3506e-02,\n                       2.7988e-03,  9.4050e-04, -8.3739e-04,  1.8818e-02,  7.9902e-03,\n                       2.7959e-02, -5.3950e-03, -5.4555e-03, -7.4225e-03, -6.0851e-03,\n                      -7.8907e-03, -1.0638e-03,  2.8860e-02,  3.3249e-02,  1.1778e-02,\n                       1.5321e-03, -2.7062e-02,  1.8792e-03,  3.1795e-02,  2.9848e-03,\n                      -1.1837e-03, -2.6049e-02,  4.5981e-03, -7.0127e-03, -1.2022e-02,\n                      -1.9621e-02, -5.9119e-03,  6.3127e-03,  4.7713e-03,  3.5127e-02,\n                      -4.3142e-03,  1.0485e-02, -6.9682e-03,  1.6972e-03,  6.8555e-03,\n                      -9.9427e-03], dtype=torch.float64)),\n             ('6.8.convs.2.1.bias',\n              tensor([-0.0004,  0.0032,  0.0135,  0.0151,  0.0008,  0.0096,  0.0081, -0.0006,\n                       0.0102,  0.0146,  0.0140, -0.0067,  0.0067, -0.0039,  0.0099,  0.0041,\n                       0.0233, -0.0028,  0.0107, -0.0033, -0.0036,  0.0012,  0.0033,  0.0054,\n                      -0.0070, -0.0169,  0.0024,  0.0033, -0.0003,  0.0018,  0.0056,  0.0093,\n                      -0.0065,  0.0181,  0.0095,  0.0156,  0.0026,  0.0160,  0.0051,  0.0152,\n                       0.0002,  0.0197, -0.0114,  0.0020,  0.0048, -0.0102,  0.0085,  0.0027,\n                      -0.0110,  0.0088,  0.0088,  0.0077,  0.0059,  0.0104,  0.0074,  0.0144,\n                       0.0084,  0.0010,  0.0119,  0.0019, -0.0053,  0.0016,  0.0044,  0.0085,\n                      -0.0049,  0.0057, -0.0109,  0.0147,  0.0002, -0.0128,  0.0030,  0.0083,\n                       0.0011, -0.0070,  0.0149,  0.0019,  0.0035,  0.0080,  0.0066,  0.0011,\n                       0.0094, -0.0057,  0.0097,  0.0047, -0.0034,  0.0181,  0.0001,  0.0021,\n                       0.0173,  0.0037,  0.0014,  0.0142,  0.0129, -0.0010,  0.0098, -0.0133,\n                       0.0099,  0.0029,  0.0088, -0.0027,  0.0192,  0.0141,  0.0037,  0.0090,\n                       0.0049, -0.0013, -0.0012,  0.0031,  0.0052,  0.0099, -0.0088, -0.0063,\n                       0.0053,  0.0184,  0.0120,  0.0064,  0.0081,  0.0024,  0.0047, -0.0157,\n                       0.0039,  0.0095, -0.0010, -0.0018, -0.0139,  0.0101,  0.0168,  0.0038,\n                       0.0030,  0.0172,  0.0085,  0.0138,  0.0146,  0.0108,  0.0149, -0.0082,\n                       0.0155,  0.0092,  0.0136,  0.0066,  0.0154, -0.0035,  0.0181,  0.0047,\n                      -0.0082,  0.0140, -0.0005, -0.0013,  0.0067,  0.0115,  0.0062,  0.0120,\n                       0.0123,  0.0132,  0.0123,  0.0086, -0.0006,  0.0027, -0.0018, -0.0114,\n                       0.0024, -0.0011,  0.0006,  0.0076,  0.0106, -0.0016, -0.0117,  0.0105,\n                       0.0009,  0.0165,  0.0046,  0.0046,  0.0120,  0.0105, -0.0135, -0.0006,\n                       0.0010,  0.0110,  0.0023,  0.0067, -0.0049,  0.0111, -0.0064, -0.0093,\n                       0.0194,  0.0074,  0.0140,  0.0109,  0.0025,  0.0120,  0.0072,  0.0026,\n                       0.0095, -0.0056, -0.0011,  0.0072, -0.0013,  0.0126,  0.0068,  0.0216,\n                       0.0008,  0.0223,  0.0202,  0.0229, -0.0002, -0.0038,  0.0110, -0.0039,\n                       0.0085,  0.0141,  0.0043,  0.0113,  0.0141,  0.0079,  0.0096, -0.0028,\n                       0.0043, -0.0052,  0.0023, -0.0013, -0.0132,  0.0028,  0.0042,  0.0219,\n                      -0.0047,  0.0020, -0.0040,  0.0006, -0.0151,  0.0148,  0.0076, -0.0026,\n                       0.0111, -0.0020,  0.0023,  0.0080,  0.0080, -0.0030,  0.0104,  0.0045,\n                       0.0020,  0.0014,  0.0021,  0.0086,  0.0021,  0.0151,  0.0051,  0.0079,\n                      -0.0009, -0.0093,  0.0170,  0.0228,  0.0151,  0.0149,  0.0099,  0.0021],\n                     dtype=torch.float64)),\n             ('6.8.convs.2.1.running_mean',\n              tensor([ 0.1159, -0.0137,  0.7410, -0.1477,  0.1661,  0.3967,  0.0793,  0.5611,\n                       0.1799, -0.0319, -0.2336,  0.5195, -0.1289, -0.2306, -0.6580, -0.5116,\n                       0.6962, -0.2890, -0.1711, -0.2023,  0.1790, -0.1867, -0.4372,  0.0428,\n                       0.1156,  0.2690, -0.4055, -0.3229, -0.3581,  0.2676, -0.2529,  0.4645,\n                      -0.4268, -0.0861, -0.5112, -0.3824,  0.7574,  0.1442, -0.0995,  0.4144,\n                      -0.0211, -0.2888, -0.1424, -0.1503, -0.4178,  0.8322,  0.4718,  0.0326,\n                       0.7618,  0.3057, -0.2362,  0.1053,  0.2424, -0.7095,  0.1386,  0.1266,\n                       0.5873, -0.0427,  0.1808,  0.3648,  0.1174,  0.0725, -0.2795, -0.0715,\n                       0.5193, -0.3861,  0.1673,  0.4257,  0.4400, -0.7069, -0.4454, -0.4281,\n                      -0.1290, -0.0208,  0.1143, -0.0503,  0.0045, -0.2067, -0.4642, -0.2433,\n                       0.0459,  0.7877,  0.0177, -0.3648,  0.1846,  0.4169, -0.4395, -0.5843,\n                       0.4567,  0.1417, -0.2083,  0.3490,  0.9426,  0.4789,  0.0276, -0.3291,\n                       0.8330,  0.2574, -0.1018,  0.1159,  0.1421,  0.2113,  0.0988,  0.3412,\n                      -0.4689,  0.3106, -0.4914,  0.5967,  0.0604,  0.3448,  0.1001, -0.3982,\n                       0.6446, -0.6103, -0.1370,  0.5919,  0.4898, -0.1291,  0.4969,  0.4277,\n                       0.2939, -0.1940, -0.2985,  0.2395, -0.1858, -0.3411, -0.0987,  0.4775,\n                      -0.0458,  0.0413, -0.0783, -0.4770,  0.6629, -0.1620,  0.4461, -0.1445,\n                       0.4373, -0.1012, -0.4723,  0.1519, -0.2175,  0.1791,  0.6385, -0.2598,\n                       0.4639,  0.2256, -0.2096, -0.3468,  0.3014,  0.1304, -0.5765,  0.3320,\n                       0.0998,  0.9359, -0.2059, -0.3830, -0.0552,  0.2897,  0.2846, -0.2405,\n                      -0.0312, -0.1150, -0.1814,  0.0879,  0.4565, -0.1194, -0.6060,  0.3909,\n                       0.1161,  0.2754,  0.1099,  0.0951, -0.2478,  0.1738,  0.3808, -0.6703,\n                       0.1280,  0.2567, -0.1922, -0.0896, -0.0561, -0.2262, -0.1623,  0.2551,\n                       0.1890, -0.2617, -0.4779, -0.1666, -0.2761, -0.1823,  0.0244, -0.3476,\n                      -0.2363,  0.0819, -0.7079,  0.0135,  0.0767,  0.0320, -0.8805, -0.0924,\n                       0.4949, -0.4137,  0.2967, -0.4493,  0.6838,  0.0081, -0.1819,  0.1645,\n                      -0.4065,  0.2712, -0.1391,  0.2511, -0.0148, -0.1054,  0.0798,  0.0577,\n                      -0.0445,  0.0234, -0.3032, -0.2490,  0.7021, -0.3016,  0.2569,  0.4965,\n                      -0.6610,  0.2484, -0.1657, -0.0385, -0.1808,  0.0191, -0.3352, -0.3096,\n                      -0.0980,  0.3494, -0.3370, -0.7736,  0.1320,  0.3128,  0.3571,  0.4100,\n                      -0.3632,  0.3412,  0.2022, -0.0113,  0.1776,  0.3120, -0.0322,  0.6727,\n                       0.4840,  0.2677,  0.4133, -0.8062,  0.2835,  0.0728, -0.1637,  0.0375],\n                     dtype=torch.float64)),\n             ('6.8.convs.2.1.running_var',\n              tensor([0.3131, 0.2214, 0.4029, 0.3736, 0.2030, 0.6149, 0.1290, 0.3326, 0.2118,\n                      0.2424, 0.4482, 0.3895, 0.1123, 0.1762, 0.5959, 0.4870, 0.5400, 0.2294,\n                      0.2258, 0.2409, 0.2662, 0.2771, 0.5799, 0.2755, 0.5192, 0.3729, 0.3981,\n                      0.4239, 0.3520, 0.5760, 0.3890, 0.2803, 0.1983, 0.7171, 0.3963, 0.2549,\n                      0.3774, 0.1636, 0.2394, 0.5444, 0.3875, 0.1465, 0.3366, 0.5421, 0.4360,\n                      0.4335, 0.4146, 0.2315, 0.5576, 0.4395, 0.2119, 0.3486, 0.3084, 0.4547,\n                      0.4153, 0.3878, 0.2441, 0.5182, 0.3914, 0.3755, 0.3423, 0.3149, 0.1911,\n                      0.1972, 0.4211, 0.2972, 0.2511, 0.2881, 0.3434, 0.6015, 0.4407, 0.3647,\n                      0.0646, 0.3392, 0.6173, 0.0527, 0.5048, 0.3148, 0.3481, 0.2721, 0.4421,\n                      0.3588, 0.2930, 0.5231, 0.5032, 0.3703, 0.1605, 0.5395, 0.4735, 0.2658,\n                      0.5975, 0.1284, 0.4673, 0.1443, 0.1685, 0.6273, 0.4873, 0.3019, 0.1427,\n                      0.2882, 0.3931, 0.3412, 0.1803, 0.2269, 0.1602, 0.2294, 0.2659, 0.4944,\n                      0.3455, 0.2896, 0.0716, 0.6064, 0.4627, 0.2357, 0.3840, 0.5266, 0.2983,\n                      0.3467, 0.2290, 0.4340, 0.1351, 0.5061, 0.3095, 0.2900, 0.0330, 0.4188,\n                      0.2931, 0.2847, 0.2788, 0.3848, 0.1568, 0.4488, 0.5208, 0.1838, 0.4784,\n                      0.1478, 0.2446, 0.5200, 0.3699, 0.1732, 0.2872, 0.2159, 0.3063, 0.1164,\n                      0.3239, 0.3604, 0.1791, 0.2543, 0.2354, 0.3987, 0.3668, 0.1216, 0.3318,\n                      0.4317, 0.1393, 0.2775, 0.3093, 0.1151, 0.4070, 0.0447, 0.2356, 0.7675,\n                      0.2077, 0.4274, 0.6192, 0.2019, 0.5733, 0.3382, 0.3867, 0.5960, 0.0860,\n                      0.2045, 0.1622, 0.3619, 0.4721, 0.5748, 0.2399, 0.1650, 0.2395, 0.2019,\n                      0.4937, 0.3256, 0.3229, 0.4685, 0.3831, 0.4127, 0.5499, 0.3474, 0.1676,\n                      0.2568, 0.2955, 0.3824, 0.4490, 0.3106, 0.4571, 0.3477, 0.3462, 0.2034,\n                      0.3862, 0.3842, 0.2164, 0.6655, 0.3199, 0.4448, 0.2740, 0.4521, 0.3082,\n                      0.0527, 0.3335, 0.3234, 0.1416, 0.4814, 0.1701, 0.3295, 0.0600, 0.1818,\n                      0.3069, 0.2889, 0.3005, 0.5281, 0.2835, 0.2013, 0.0670, 0.5376, 0.5892,\n                      0.2222, 0.2181, 0.1420, 0.5640, 0.3340, 0.2773, 0.1507, 0.3601, 0.3815,\n                      0.5260, 0.2706, 0.4315, 0.2458, 0.5923, 0.1059, 0.1006, 0.1753, 0.2817,\n                      0.0482, 0.2484, 0.4449, 0.3710, 0.1765, 0.1929, 0.3517, 0.2442, 0.3323,\n                      0.3718, 0.1559, 0.2805, 0.2836], dtype=torch.float64)),\n             ('6.8.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.8.convpath.0.0.0.weight',\n              tensor([[[ 0.0887],\n                       [ 0.1908],\n                       [ 0.0004],\n                       ...,\n                       [-0.1929],\n                       [-0.0329],\n                       [-0.1482]],\n              \n                      [[ 0.0307],\n                       [-0.0216],\n                       [ 0.0644],\n                       ...,\n                       [-0.0112],\n                       [ 0.0572],\n                       [-0.0078]],\n              \n                      [[ 0.0191],\n                       [-0.0794],\n                       [ 0.1195],\n                       ...,\n                       [ 0.0226],\n                       [ 0.1501],\n                       [-0.0330]],\n              \n                      ...,\n              \n                      [[-0.1072],\n                       [-0.1276],\n                       [-0.0823],\n                       ...,\n                       [ 0.0120],\n                       [ 0.0449],\n                       [ 0.1959]],\n              \n                      [[ 0.0403],\n                       [-0.0069],\n                       [-0.0745],\n                       ...,\n                       [-0.0265],\n                       [-0.0248],\n                       [ 0.1112]],\n              \n                      [[ 0.1272],\n                       [-0.0481],\n                       [ 0.0945],\n                       ...,\n                       [-0.1008],\n                       [ 0.0964],\n                       [-0.0450]]], dtype=torch.float64)),\n             ('6.8.convpath.0.0.1.weight',\n              tensor([0.9432, 0.9569, 0.9626, 0.9683, 0.9310, 0.9730, 0.9851, 0.9899, 0.9576,\n                      0.9435, 0.9778, 0.9775, 0.9517, 0.9398, 0.9644, 0.9703, 0.9685, 0.9793,\n                      0.9998, 0.9856, 0.9785, 0.9639, 0.9547, 0.9304, 0.9758, 0.9599, 0.9863,\n                      0.9660, 0.9646, 0.9637, 0.9421, 0.9563, 0.9599, 0.9494, 0.9684, 0.9598,\n                      0.9766, 0.9847, 0.9537, 0.9395, 0.9668, 0.9661, 0.9245, 0.9577, 0.9434,\n                      0.9514, 0.9694, 0.9903, 0.9736, 0.9632, 0.9549, 0.9508, 0.9575, 0.9883,\n                      0.9784, 0.9684, 0.9587, 0.9708, 0.9473, 0.9809, 0.9349, 0.9334, 0.9571,\n                      0.9861], dtype=torch.float64)),\n             ('6.8.convpath.0.0.1.bias',\n              tensor([ 3.1957e-02,  1.0140e-02, -1.6584e-03, -1.0707e-02,  7.1319e-03,\n                       7.3430e-03,  2.6610e-02,  2.0424e-02,  3.4163e-03, -2.4627e-02,\n                       5.8369e-03,  2.2534e-02, -3.6009e-03, -2.1155e-02,  2.1622e-02,\n                      -5.5873e-03,  4.1890e-03,  1.1985e-02,  3.1749e-02,  1.2038e-02,\n                      -2.6527e-03,  1.9104e-06,  1.1475e-02, -2.4049e-03,  1.8556e-02,\n                       2.0758e-03,  1.2750e-02, -5.8136e-03, -4.4656e-03, -1.1002e-02,\n                      -4.6054e-02, -1.1836e-02,  2.6681e-03,  7.7375e-03, -2.9621e-03,\n                      -2.4369e-03,  4.0917e-02,  1.3131e-02, -1.0694e-02,  1.4191e-03,\n                      -2.2527e-02,  3.8883e-03,  1.4124e-02, -7.3241e-04, -6.1489e-03,\n                      -2.5508e-04,  2.3807e-03,  7.3859e-03,  2.2536e-02, -2.4591e-02,\n                       7.5150e-03,  2.1880e-02,  1.9122e-02,  3.9752e-03,  1.6702e-02,\n                       8.1483e-03, -1.5730e-02,  6.9830e-03,  1.1226e-02,  1.4420e-02,\n                      -3.0214e-02, -1.9035e-02, -7.4814e-03,  1.1744e-02],\n                     dtype=torch.float64)),\n             ('6.8.convpath.0.0.1.running_mean',\n              tensor([-0.2204, -0.0278,  0.6457,  0.0336, -0.8354, -0.0798,  0.1228, -0.2911,\n                      -0.0618, -0.2694, -0.6318, -0.4279, -0.0570, -0.2815,  0.1825,  1.1432,\n                       0.0067, -0.5452, -0.4348,  0.0697,  0.2302, -0.8138,  0.7798, -0.7765,\n                       0.1846,  0.2630, -0.6822,  0.5416,  0.8783,  0.5059,  1.1241,  0.8124,\n                      -0.1576, -0.2033,  0.5400, -0.0798, -0.5909,  0.4723, -0.2114, -0.3814,\n                       1.2772, -0.7225, -1.8504, -0.5363,  0.2021, -0.4371,  1.3005,  0.3725,\n                       0.6895,  0.4853,  1.2390, -0.3840, -0.1612,  0.4755, -0.2910,  0.5571,\n                       1.4032, -0.0836, -0.1793,  0.0949,  1.1415,  0.1029, -0.8563, -0.0079],\n                     dtype=torch.float64)),\n             ('6.8.convpath.0.0.1.running_var',\n              tensor([0.4582, 0.1025, 0.5356, 0.1875, 0.4602, 0.1749, 0.2905, 0.4761, 0.2384,\n                      0.2034, 0.1193, 0.1812, 0.2275, 0.1862, 0.1612, 0.4259, 0.2005, 0.1092,\n                      0.0852, 0.1384, 0.1522, 0.1879, 0.1098, 0.3722, 0.1840, 0.0961, 0.1130,\n                      0.1514, 0.2868, 0.1737, 0.4457, 0.9146, 0.4892, 0.1985, 0.3453, 0.0886,\n                      0.2218, 0.7072, 0.1335, 0.3276, 0.4631, 0.1154, 0.7546, 0.2176, 0.3564,\n                      0.6445, 0.5307, 0.1086, 0.2054, 0.2893, 0.9250, 0.2823, 0.3166, 0.1220,\n                      0.1646, 0.5879, 0.5408, 0.1074, 0.3481, 0.1272, 1.5457, 0.2720, 0.1630,\n                      0.1514], dtype=torch.float64)),\n             ('6.8.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.8.convpath.0.1.0.weight',\n              tensor([[[-0.0518,  0.0130,  0.0303, -0.0033,  0.0088],\n                       [ 0.0079, -0.0090, -0.1094,  0.0184, -0.0313],\n                       [-0.0506, -0.0159,  0.0017, -0.0637, -0.0266],\n                       ...,\n                       [-0.1071, -0.0035, -0.0646,  0.0441,  0.0364],\n                       [ 0.0847, -0.0741, -0.0224,  0.1212,  0.0829],\n                       [-0.0498, -0.0430,  0.0048,  0.0112, -0.1283]],\n              \n                      [[-0.0391,  0.0046,  0.0049, -0.0219, -0.0021],\n                       [ 0.0583, -0.0112,  0.0816, -0.0234,  0.0174],\n                       [-0.0777, -0.1587,  0.0602, -0.1133,  0.2556],\n                       ...,\n                       [ 0.0020,  0.0465, -0.1044,  0.0383,  0.0902],\n                       [ 0.0343,  0.0458, -0.0417,  0.0445,  0.0563],\n                       [ 0.1732,  0.1177, -0.0525,  0.1464, -0.0788]],\n              \n                      [[ 0.0322,  0.0898,  0.0767, -0.0267,  0.0408],\n                       [ 0.0743,  0.0236,  0.0147, -0.0565,  0.0610],\n                       [-0.1611,  0.2096,  0.0791,  0.0728,  0.0279],\n                       ...,\n                       [-0.0043, -0.0694, -0.0986,  0.0419,  0.1003],\n                       [-0.0048,  0.0044,  0.1156,  0.0230, -0.0379],\n                       [ 0.0152,  0.0301, -0.0630,  0.0004, -0.0766]],\n              \n                      ...,\n              \n                      [[-0.0630, -0.0219, -0.0319, -0.0581, -0.0456],\n                       [-0.0712,  0.0174, -0.1281, -0.0300, -0.0455],\n                       [ 0.0344,  0.0816, -0.0424, -0.0353, -0.0677],\n                       ...,\n                       [ 0.0751,  0.0141, -0.0146, -0.0573,  0.0082],\n                       [ 0.0400,  0.1133, -0.0071,  0.0310, -0.0379],\n                       [-0.0820, -0.0514, -0.0392, -0.0518, -0.0698]],\n              \n                      [[ 0.0050,  0.1157,  0.0725,  0.1076, -0.0227],\n                       [ 0.0059, -0.0630,  0.0211,  0.0814, -0.1217],\n                       [-0.1179, -0.0032, -0.1050, -0.0140, -0.1057],\n                       ...,\n                       [ 0.0331,  0.0176, -0.0088,  0.0416,  0.0565],\n                       [-0.1267, -0.0988, -0.0760, -0.0111,  0.0099],\n                       [ 0.0289,  0.1339,  0.1049, -0.0289,  0.0315]],\n              \n                      [[ 0.0555,  0.0048,  0.0929, -0.2199,  0.1547],\n                       [-0.0288,  0.0533, -0.0920,  0.0339, -0.0652],\n                       [-0.0466, -0.0596, -0.0319,  0.0675,  0.0960],\n                       ...,\n                       [-0.1127,  0.1021, -0.1163,  0.0227, -0.0102],\n                       [ 0.0334, -0.0106,  0.0057,  0.0829,  0.0593],\n                       [-0.1318, -0.0246, -0.0258, -0.0428, -0.0154]]], dtype=torch.float64)),\n             ('6.8.convpath.0.1.1.weight',\n              tensor([0.9278, 0.9500, 0.9551, 0.9541, 0.9388, 0.9921, 0.9598, 0.9534, 0.9565,\n                      0.9248, 0.9488, 0.9669, 0.9173, 0.9720, 0.9524, 0.9150, 0.9493, 0.9581,\n                      0.9647, 0.9338, 0.9757, 0.9542, 0.9513, 0.9656, 0.9632, 0.9724, 0.9585,\n                      0.9527, 0.9482, 0.9589, 0.9281, 0.9948, 0.9660, 0.9435, 0.9560, 0.9793,\n                      0.9356, 0.9536, 1.0001, 0.9809, 0.9506, 0.9503, 0.9945, 0.9674, 0.9510,\n                      0.9493, 0.9584, 0.9512, 0.9450, 0.9519, 0.9568, 0.9763, 0.9774, 0.9326,\n                      0.9630, 0.9604, 0.9735, 0.9399, 0.9568, 0.9392, 0.9693, 1.0034, 0.9666,\n                      0.9075], dtype=torch.float64)),\n             ('6.8.convpath.0.1.1.bias',\n              tensor([-0.0088, -0.0028, -0.0014,  0.0045, -0.0145,  0.0160, -0.0064,  0.0038,\n                      -0.0168, -0.0129, -0.0181,  0.0070, -0.0226, -0.0031,  0.0045, -0.0261,\n                      -0.0199, -0.0048,  0.0068, -0.0377,  0.0149,  0.0051,  0.0070, -0.0243,\n                       0.0128, -0.0056, -0.0150, -0.0004,  0.0118,  0.0154, -0.0149,  0.0052,\n                       0.0122, -0.0018, -0.0049,  0.0053, -0.0112, -0.0059,  0.0028, -0.0050,\n                      -0.0138,  0.0017,  0.0344,  0.0010,  0.0092, -0.0243, -0.0063, -0.0213,\n                       0.0029, -0.0055,  0.0131, -0.0009, -0.0124, -0.0060, -0.0158, -0.0096,\n                       0.0107, -0.0114, -0.0173, -0.0238, -0.0017,  0.0032,  0.0090, -0.0083],\n                     dtype=torch.float64)),\n             ('6.8.convpath.0.1.1.running_mean',\n              tensor([-1.6298,  0.5967, -0.2267, -0.1021, -0.6781, -0.4661,  0.1649, -0.5324,\n                      -0.2398, -0.5106,  0.8791,  0.2589, -0.4289, -0.1792,  0.2552, -0.2599,\n                       0.1087,  0.8097,  0.1797,  0.0409,  0.1093, -0.4343, -0.3386,  0.4378,\n                      -1.3861, -0.6613,  0.5684,  0.0300, -0.0107,  0.2593, -0.0712, -0.0664,\n                      -0.1594, -0.6737, -0.4002,  0.3974,  0.1830, -0.4593,  0.0969, -0.6035,\n                       0.8069, -0.1840,  0.1336,  0.2122, -1.0001,  0.4269,  0.2946,  0.2759,\n                      -0.1767,  0.2423, -0.2035, -0.0995,  0.3086,  0.1128,  0.2670,  0.2479,\n                       0.4058,  0.1430,  1.0256, -0.2720,  0.4635,  0.0147,  0.3127, -0.1612],\n                     dtype=torch.float64)),\n             ('6.8.convpath.0.1.1.running_var',\n              tensor([1.4099, 0.8047, 0.4382, 0.4238, 0.5661, 0.5920, 0.7461, 0.5145, 0.5038,\n                      0.8165, 0.5047, 0.7378, 0.7954, 0.5966, 0.5340, 1.1785, 0.4054, 0.6506,\n                      0.6381, 0.5328, 0.5028, 0.5062, 0.9323, 0.4126, 0.5714, 0.3687, 0.5791,\n                      0.4191, 0.4472, 0.5699, 0.5047, 0.4863, 0.4551, 0.7216, 0.5317, 0.6278,\n                      0.7575, 0.5333, 0.4858, 0.6514, 0.8848, 0.5382, 0.4358, 0.5524, 0.9425,\n                      0.9093, 0.4492, 0.3963, 0.4348, 0.5894, 0.5349, 0.4678, 0.5427, 1.0316,\n                      0.3913, 0.9412, 0.5207, 0.6250, 0.5527, 0.6484, 0.6759, 0.3738, 0.5024,\n                      0.8171], dtype=torch.float64)),\n             ('6.8.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.8.convpath.0.2.0.weight',\n              tensor([[[ 0.0015],\n                       [ 0.0618],\n                       [-0.1841],\n                       ...,\n                       [-0.0679],\n                       [-0.0676],\n                       [-0.0832]],\n              \n                      [[ 0.0505],\n                       [ 0.0263],\n                       [-0.1381],\n                       ...,\n                       [-0.1041],\n                       [ 0.1079],\n                       [ 0.0236]],\n              \n                      [[-0.1187],\n                       [ 0.0748],\n                       [ 0.1667],\n                       ...,\n                       [ 0.0186],\n                       [ 0.3160],\n                       [ 0.0510]],\n              \n                      ...,\n              \n                      [[ 0.2023],\n                       [-0.0581],\n                       [-0.0273],\n                       ...,\n                       [-0.0748],\n                       [ 0.0278],\n                       [ 0.0081]],\n              \n                      [[ 0.0643],\n                       [ 0.0100],\n                       [-0.0992],\n                       ...,\n                       [-0.1634],\n                       [ 0.1541],\n                       [-0.0571]],\n              \n                      [[-0.0304],\n                       [-0.1885],\n                       [ 0.2055],\n                       ...,\n                       [-0.0573],\n                       [ 0.1835],\n                       [ 0.1255]]], dtype=torch.float64)),\n             ('6.8.convpath.0.2.1.weight',\n              tensor([-2.0660e-03,  6.1894e-04,  6.3250e-03,  1.7064e-02, -1.0099e-02,\n                       1.7673e-02, -3.9634e-03, -4.3932e-02, -1.2278e-02,  6.6614e-04,\n                      -4.8536e-03,  2.8817e-02, -1.1313e-02, -6.4411e-03, -2.0540e-02,\n                       3.7784e-02, -1.2620e-02,  5.0773e-03, -1.0444e-02, -2.1709e-03,\n                       7.8726e-03, -4.7571e-03, -2.9992e-03, -5.1889e-03,  1.7685e-02,\n                       1.2147e-02, -8.9687e-03,  1.3441e-02,  6.2530e-03,  1.8847e-02,\n                      -1.5009e-02, -9.7421e-03, -8.4602e-04, -2.3385e-02,  9.1652e-03,\n                       1.2196e-03, -1.6587e-02, -9.9816e-03,  8.8335e-03,  3.7598e-03,\n                      -9.4836e-03,  8.7293e-03,  2.1139e-02, -2.7109e-02, -1.3489e-02,\n                      -9.9482e-03,  1.4132e-02,  2.8747e-02,  2.0804e-02,  6.0150e-03,\n                       2.7892e-02,  1.1385e-02, -1.9096e-04,  1.4533e-02,  1.6828e-02,\n                       5.2330e-02,  5.3676e-03,  1.5263e-02,  3.8217e-03,  1.1180e-03,\n                       5.4495e-03, -1.5431e-02,  4.9208e-03, -1.2997e-02,  9.7065e-03,\n                      -2.1196e-03, -9.5240e-03,  5.1660e-03,  2.1239e-02, -7.1946e-03,\n                       2.4575e-02,  2.1187e-02,  1.6203e-03, -9.2737e-04, -9.9068e-03,\n                       8.1525e-03,  2.1399e-02,  3.1293e-02, -4.1452e-03,  2.5280e-02,\n                      -1.4889e-02,  2.9710e-02,  2.2623e-02,  1.7331e-02, -2.1384e-02,\n                      -1.2634e-02,  1.7030e-03, -3.5038e-02,  1.5710e-03, -2.2587e-02,\n                      -7.5919e-03,  1.1272e-02, -8.4926e-03, -3.2500e-03, -4.8428e-03,\n                       2.2297e-02, -2.0893e-02, -1.4037e-02, -9.2617e-03,  1.3383e-02,\n                      -5.2591e-03,  2.2231e-02, -1.8991e-04, -1.8237e-02, -1.5163e-02,\n                      -1.8749e-02,  1.1699e-03,  8.8025e-03,  2.2007e-02,  1.8458e-02,\n                       2.2396e-05, -8.8249e-03, -1.9638e-02, -7.0404e-03,  1.0568e-02,\n                      -9.4188e-03, -2.9178e-03, -7.9452e-03,  1.4475e-02,  1.4389e-02,\n                       1.1300e-02, -1.5614e-02, -1.3186e-02, -1.2972e-02,  3.3864e-03,\n                       4.2606e-03,  3.0071e-02,  1.6589e-02, -1.3806e-02, -1.0296e-02,\n                       8.7019e-03, -3.9943e-03, -1.0120e-02,  2.5465e-03,  1.1756e-02,\n                       1.6570e-02, -1.4678e-02,  1.7318e-02, -4.3515e-03,  9.9493e-03,\n                       6.3169e-03, -1.9369e-02,  1.0131e-02,  4.9987e-03,  9.5437e-03,\n                       5.4485e-03, -2.0513e-02, -1.0796e-02,  7.6728e-03,  2.1991e-03,\n                       1.8767e-02, -3.6478e-03, -3.7939e-02, -1.1497e-02, -2.0247e-03,\n                       1.1245e-02, -1.0048e-02, -5.9844e-03, -1.7954e-02, -2.5308e-03,\n                      -7.8639e-03, -2.1146e-02,  6.5625e-03, -3.7818e-02, -3.1265e-02,\n                       2.0494e-02, -6.8358e-03, -2.1304e-02,  2.4668e-02, -2.2074e-02,\n                       7.6657e-04,  7.2933e-03,  4.7382e-03,  3.4108e-02,  2.0982e-02,\n                      -6.7730e-03, -4.7803e-03, -4.4514e-03, -1.7506e-03, -2.0707e-02,\n                       9.4255e-03, -1.4542e-02, -2.2228e-02, -1.0310e-02,  2.6845e-02,\n                      -4.6161e-04, -1.3318e-02,  9.7507e-03, -5.7632e-04,  1.2703e-02,\n                       6.8255e-03,  3.1781e-03, -4.1467e-02, -1.6447e-03, -1.0374e-02,\n                       2.5607e-02,  1.2754e-03,  8.0096e-03,  1.1529e-02, -1.0046e-02,\n                      -7.8666e-05, -1.5904e-02, -5.1813e-03, -2.2866e-02, -1.3025e-02,\n                      -9.0697e-03, -9.5688e-03, -1.4253e-03, -1.0787e-02, -9.0183e-03,\n                      -2.3644e-02,  1.0649e-02,  5.6574e-03,  2.1107e-02, -9.9541e-03,\n                      -8.3224e-03,  1.4262e-02,  1.1781e-02,  8.4630e-03,  3.3506e-02,\n                       2.7988e-03,  9.4050e-04, -8.3739e-04,  1.8818e-02,  7.9902e-03,\n                       2.7959e-02, -5.3950e-03, -5.4555e-03, -7.4225e-03, -6.0851e-03,\n                      -7.8907e-03, -1.0638e-03,  2.8860e-02,  3.3249e-02,  1.1778e-02,\n                       1.5321e-03, -2.7062e-02,  1.8792e-03,  3.1795e-02,  2.9848e-03,\n                      -1.1837e-03, -2.6049e-02,  4.5981e-03, -7.0127e-03, -1.2022e-02,\n                      -1.9621e-02, -5.9119e-03,  6.3127e-03,  4.7713e-03,  3.5127e-02,\n                      -4.3142e-03,  1.0485e-02, -6.9682e-03,  1.6972e-03,  6.8555e-03,\n                      -9.9427e-03], dtype=torch.float64)),\n             ('6.8.convpath.0.2.1.bias',\n              tensor([-0.0004,  0.0032,  0.0135,  0.0151,  0.0008,  0.0096,  0.0081, -0.0006,\n                       0.0102,  0.0146,  0.0140, -0.0067,  0.0067, -0.0039,  0.0099,  0.0041,\n                       0.0233, -0.0028,  0.0107, -0.0033, -0.0036,  0.0012,  0.0033,  0.0054,\n                      -0.0070, -0.0169,  0.0024,  0.0033, -0.0003,  0.0018,  0.0056,  0.0093,\n                      -0.0065,  0.0181,  0.0095,  0.0156,  0.0026,  0.0160,  0.0051,  0.0152,\n                       0.0002,  0.0197, -0.0114,  0.0020,  0.0048, -0.0102,  0.0085,  0.0027,\n                      -0.0110,  0.0088,  0.0088,  0.0077,  0.0059,  0.0104,  0.0074,  0.0144,\n                       0.0084,  0.0010,  0.0119,  0.0019, -0.0053,  0.0016,  0.0044,  0.0085,\n                      -0.0049,  0.0057, -0.0109,  0.0147,  0.0002, -0.0128,  0.0030,  0.0083,\n                       0.0011, -0.0070,  0.0149,  0.0019,  0.0035,  0.0080,  0.0066,  0.0011,\n                       0.0094, -0.0057,  0.0097,  0.0047, -0.0034,  0.0181,  0.0001,  0.0021,\n                       0.0173,  0.0037,  0.0014,  0.0142,  0.0129, -0.0010,  0.0098, -0.0133,\n                       0.0099,  0.0029,  0.0088, -0.0027,  0.0192,  0.0141,  0.0037,  0.0090,\n                       0.0049, -0.0013, -0.0012,  0.0031,  0.0052,  0.0099, -0.0088, -0.0063,\n                       0.0053,  0.0184,  0.0120,  0.0064,  0.0081,  0.0024,  0.0047, -0.0157,\n                       0.0039,  0.0095, -0.0010, -0.0018, -0.0139,  0.0101,  0.0168,  0.0038,\n                       0.0030,  0.0172,  0.0085,  0.0138,  0.0146,  0.0108,  0.0149, -0.0082,\n                       0.0155,  0.0092,  0.0136,  0.0066,  0.0154, -0.0035,  0.0181,  0.0047,\n                      -0.0082,  0.0140, -0.0005, -0.0013,  0.0067,  0.0115,  0.0062,  0.0120,\n                       0.0123,  0.0132,  0.0123,  0.0086, -0.0006,  0.0027, -0.0018, -0.0114,\n                       0.0024, -0.0011,  0.0006,  0.0076,  0.0106, -0.0016, -0.0117,  0.0105,\n                       0.0009,  0.0165,  0.0046,  0.0046,  0.0120,  0.0105, -0.0135, -0.0006,\n                       0.0010,  0.0110,  0.0023,  0.0067, -0.0049,  0.0111, -0.0064, -0.0093,\n                       0.0194,  0.0074,  0.0140,  0.0109,  0.0025,  0.0120,  0.0072,  0.0026,\n                       0.0095, -0.0056, -0.0011,  0.0072, -0.0013,  0.0126,  0.0068,  0.0216,\n                       0.0008,  0.0223,  0.0202,  0.0229, -0.0002, -0.0038,  0.0110, -0.0039,\n                       0.0085,  0.0141,  0.0043,  0.0113,  0.0141,  0.0079,  0.0096, -0.0028,\n                       0.0043, -0.0052,  0.0023, -0.0013, -0.0132,  0.0028,  0.0042,  0.0219,\n                      -0.0047,  0.0020, -0.0040,  0.0006, -0.0151,  0.0148,  0.0076, -0.0026,\n                       0.0111, -0.0020,  0.0023,  0.0080,  0.0080, -0.0030,  0.0104,  0.0045,\n                       0.0020,  0.0014,  0.0021,  0.0086,  0.0021,  0.0151,  0.0051,  0.0079,\n                      -0.0009, -0.0093,  0.0170,  0.0228,  0.0151,  0.0149,  0.0099,  0.0021],\n                     dtype=torch.float64)),\n             ('6.8.convpath.0.2.1.running_mean',\n              tensor([ 0.1159, -0.0137,  0.7410, -0.1477,  0.1661,  0.3967,  0.0793,  0.5611,\n                       0.1799, -0.0319, -0.2336,  0.5195, -0.1289, -0.2306, -0.6580, -0.5116,\n                       0.6962, -0.2890, -0.1711, -0.2023,  0.1790, -0.1867, -0.4372,  0.0428,\n                       0.1156,  0.2690, -0.4055, -0.3229, -0.3581,  0.2676, -0.2529,  0.4645,\n                      -0.4268, -0.0861, -0.5112, -0.3824,  0.7574,  0.1442, -0.0995,  0.4144,\n                      -0.0211, -0.2888, -0.1424, -0.1503, -0.4178,  0.8322,  0.4718,  0.0326,\n                       0.7618,  0.3057, -0.2362,  0.1053,  0.2424, -0.7095,  0.1386,  0.1266,\n                       0.5873, -0.0427,  0.1808,  0.3648,  0.1174,  0.0725, -0.2795, -0.0715,\n                       0.5193, -0.3861,  0.1673,  0.4257,  0.4400, -0.7069, -0.4454, -0.4281,\n                      -0.1290, -0.0208,  0.1143, -0.0503,  0.0045, -0.2067, -0.4642, -0.2433,\n                       0.0459,  0.7877,  0.0177, -0.3648,  0.1846,  0.4169, -0.4395, -0.5843,\n                       0.4567,  0.1417, -0.2083,  0.3490,  0.9426,  0.4789,  0.0276, -0.3291,\n                       0.8330,  0.2574, -0.1018,  0.1159,  0.1421,  0.2113,  0.0988,  0.3412,\n                      -0.4689,  0.3106, -0.4914,  0.5967,  0.0604,  0.3448,  0.1001, -0.3982,\n                       0.6446, -0.6103, -0.1370,  0.5919,  0.4898, -0.1291,  0.4969,  0.4277,\n                       0.2939, -0.1940, -0.2985,  0.2395, -0.1858, -0.3411, -0.0987,  0.4775,\n                      -0.0458,  0.0413, -0.0783, -0.4770,  0.6629, -0.1620,  0.4461, -0.1445,\n                       0.4373, -0.1012, -0.4723,  0.1519, -0.2175,  0.1791,  0.6385, -0.2598,\n                       0.4639,  0.2256, -0.2096, -0.3468,  0.3014,  0.1304, -0.5765,  0.3320,\n                       0.0998,  0.9359, -0.2059, -0.3830, -0.0552,  0.2897,  0.2846, -0.2405,\n                      -0.0312, -0.1150, -0.1814,  0.0879,  0.4565, -0.1194, -0.6060,  0.3909,\n                       0.1161,  0.2754,  0.1099,  0.0951, -0.2478,  0.1738,  0.3808, -0.6703,\n                       0.1280,  0.2567, -0.1922, -0.0896, -0.0561, -0.2262, -0.1623,  0.2551,\n                       0.1890, -0.2617, -0.4779, -0.1666, -0.2761, -0.1823,  0.0244, -0.3476,\n                      -0.2363,  0.0819, -0.7079,  0.0135,  0.0767,  0.0320, -0.8805, -0.0924,\n                       0.4949, -0.4137,  0.2967, -0.4493,  0.6838,  0.0081, -0.1819,  0.1645,\n                      -0.4065,  0.2712, -0.1391,  0.2511, -0.0148, -0.1054,  0.0798,  0.0577,\n                      -0.0445,  0.0234, -0.3032, -0.2490,  0.7021, -0.3016,  0.2569,  0.4965,\n                      -0.6610,  0.2484, -0.1657, -0.0385, -0.1808,  0.0191, -0.3352, -0.3096,\n                      -0.0980,  0.3494, -0.3370, -0.7736,  0.1320,  0.3128,  0.3571,  0.4100,\n                      -0.3632,  0.3412,  0.2022, -0.0113,  0.1776,  0.3120, -0.0322,  0.6727,\n                       0.4840,  0.2677,  0.4133, -0.8062,  0.2835,  0.0728, -0.1637,  0.0375],\n                     dtype=torch.float64)),\n             ('6.8.convpath.0.2.1.running_var',\n              tensor([0.3131, 0.2214, 0.4029, 0.3736, 0.2030, 0.6149, 0.1290, 0.3326, 0.2118,\n                      0.2424, 0.4482, 0.3895, 0.1123, 0.1762, 0.5959, 0.4870, 0.5400, 0.2294,\n                      0.2258, 0.2409, 0.2662, 0.2771, 0.5799, 0.2755, 0.5192, 0.3729, 0.3981,\n                      0.4239, 0.3520, 0.5760, 0.3890, 0.2803, 0.1983, 0.7171, 0.3963, 0.2549,\n                      0.3774, 0.1636, 0.2394, 0.5444, 0.3875, 0.1465, 0.3366, 0.5421, 0.4360,\n                      0.4335, 0.4146, 0.2315, 0.5576, 0.4395, 0.2119, 0.3486, 0.3084, 0.4547,\n                      0.4153, 0.3878, 0.2441, 0.5182, 0.3914, 0.3755, 0.3423, 0.3149, 0.1911,\n                      0.1972, 0.4211, 0.2972, 0.2511, 0.2881, 0.3434, 0.6015, 0.4407, 0.3647,\n                      0.0646, 0.3392, 0.6173, 0.0527, 0.5048, 0.3148, 0.3481, 0.2721, 0.4421,\n                      0.3588, 0.2930, 0.5231, 0.5032, 0.3703, 0.1605, 0.5395, 0.4735, 0.2658,\n                      0.5975, 0.1284, 0.4673, 0.1443, 0.1685, 0.6273, 0.4873, 0.3019, 0.1427,\n                      0.2882, 0.3931, 0.3412, 0.1803, 0.2269, 0.1602, 0.2294, 0.2659, 0.4944,\n                      0.3455, 0.2896, 0.0716, 0.6064, 0.4627, 0.2357, 0.3840, 0.5266, 0.2983,\n                      0.3467, 0.2290, 0.4340, 0.1351, 0.5061, 0.3095, 0.2900, 0.0330, 0.4188,\n                      0.2931, 0.2847, 0.2788, 0.3848, 0.1568, 0.4488, 0.5208, 0.1838, 0.4784,\n                      0.1478, 0.2446, 0.5200, 0.3699, 0.1732, 0.2872, 0.2159, 0.3063, 0.1164,\n                      0.3239, 0.3604, 0.1791, 0.2543, 0.2354, 0.3987, 0.3668, 0.1216, 0.3318,\n                      0.4317, 0.1393, 0.2775, 0.3093, 0.1151, 0.4070, 0.0447, 0.2356, 0.7675,\n                      0.2077, 0.4274, 0.6192, 0.2019, 0.5733, 0.3382, 0.3867, 0.5960, 0.0860,\n                      0.2045, 0.1622, 0.3619, 0.4721, 0.5748, 0.2399, 0.1650, 0.2395, 0.2019,\n                      0.4937, 0.3256, 0.3229, 0.4685, 0.3831, 0.4127, 0.5499, 0.3474, 0.1676,\n                      0.2568, 0.2955, 0.3824, 0.4490, 0.3106, 0.4571, 0.3477, 0.3462, 0.2034,\n                      0.3862, 0.3842, 0.2164, 0.6655, 0.3199, 0.4448, 0.2740, 0.4521, 0.3082,\n                      0.0527, 0.3335, 0.3234, 0.1416, 0.4814, 0.1701, 0.3295, 0.0600, 0.1818,\n                      0.3069, 0.2889, 0.3005, 0.5281, 0.2835, 0.2013, 0.0670, 0.5376, 0.5892,\n                      0.2222, 0.2181, 0.1420, 0.5640, 0.3340, 0.2773, 0.1507, 0.3601, 0.3815,\n                      0.5260, 0.2706, 0.4315, 0.2458, 0.5923, 0.1059, 0.1006, 0.1753, 0.2817,\n                      0.0482, 0.2484, 0.4449, 0.3710, 0.1765, 0.1929, 0.3517, 0.2442, 0.3323,\n                      0.3718, 0.1559, 0.2805, 0.2836], dtype=torch.float64)),\n             ('6.8.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.9.convs.0.0.weight',\n              tensor([[[-0.0813],\n                       [ 0.0610],\n                       [-0.0926],\n                       ...,\n                       [-0.0010],\n                       [ 0.0468],\n                       [-0.0065]],\n              \n                      [[ 0.1631],\n                       [ 0.0335],\n                       [ 0.0903],\n                       ...,\n                       [ 0.1104],\n                       [ 0.0539],\n                       [-0.0513]],\n              \n                      [[ 0.0223],\n                       [-0.0326],\n                       [-0.0781],\n                       ...,\n                       [ 0.0177],\n                       [-0.1569],\n                       [ 0.0532]],\n              \n                      ...,\n              \n                      [[ 0.0231],\n                       [ 0.1380],\n                       [ 0.0566],\n                       ...,\n                       [ 0.0244],\n                       [-0.1035],\n                       [-0.0193]],\n              \n                      [[ 0.1010],\n                       [-0.0405],\n                       [ 0.0025],\n                       ...,\n                       [-0.0571],\n                       [-0.1015],\n                       [ 0.0298]],\n              \n                      [[-0.0005],\n                       [ 0.0264],\n                       [-0.0925],\n                       ...,\n                       [ 0.0210],\n                       [ 0.0282],\n                       [-0.0404]]], dtype=torch.float64)),\n             ('6.9.convs.0.1.weight',\n              tensor([0.9750, 0.9819, 0.9649, 0.9776, 0.9871, 0.9467, 0.9595, 0.9758, 1.0028,\n                      0.9632, 0.9893, 0.9389, 0.9785, 0.9899, 0.9649, 0.9732, 0.9734, 0.9575,\n                      0.9941, 0.9702, 0.9553, 0.9850, 0.9682, 0.9923, 0.9465, 0.9507, 0.9835,\n                      0.9816, 0.9771, 0.9428, 0.9717, 0.9623, 0.9523, 0.9815, 0.9632, 0.9720,\n                      0.9552, 0.9900, 0.9657, 0.9680, 0.9769, 0.9607, 0.9654, 0.9850, 0.9596,\n                      0.9854, 0.9849, 0.9691, 0.9443, 0.9693, 0.9721, 0.9748, 0.9836, 0.9763,\n                      0.9679, 0.9778, 0.9940, 0.9622, 0.9825, 0.9556, 0.9634, 0.9741, 0.9662,\n                      0.9424], dtype=torch.float64)),\n             ('6.9.convs.0.1.bias',\n              tensor([ 1.2720e-02, -3.1621e-03, -5.3963e-03, -4.0528e-03,  1.7812e-03,\n                      -2.4145e-02,  2.7870e-03, -3.8004e-03,  2.2681e-03,  5.0583e-03,\n                       1.5305e-02, -1.8052e-02,  1.2570e-02, -1.5111e-02, -2.7473e-03,\n                       1.8942e-03, -1.1458e-02, -1.1732e-02,  2.9528e-02,  1.1348e-03,\n                      -1.3661e-02,  1.0696e-02,  2.9996e-03,  9.0068e-03, -1.1412e-02,\n                      -8.1377e-03, -3.0630e-03,  9.3411e-04,  1.2722e-02, -1.8332e-03,\n                       3.0892e-02, -1.5897e-02, -1.5398e-02,  9.6534e-03, -2.6470e-03,\n                       7.5174e-03, -3.3340e-03,  8.7480e-03, -1.3130e-02, -3.0183e-03,\n                       1.4194e-02, -3.4733e-03,  3.5211e-03,  3.3736e-03, -6.8094e-03,\n                      -4.1734e-03,  1.6319e-02,  1.0342e-03,  5.2933e-03,  2.1836e-03,\n                      -4.6685e-03,  1.0572e-02,  8.4254e-03,  1.9179e-02, -1.4815e-02,\n                       3.7394e-05,  1.5185e-02, -3.2271e-03,  2.3928e-03,  4.0501e-03,\n                       1.9671e-02, -2.0330e-02, -1.9237e-02,  4.9478e-03],\n                     dtype=torch.float64)),\n             ('6.9.convs.0.1.running_mean',\n              tensor([-5.1299e-01,  2.1893e-01, -2.2575e-01, -6.0247e-01,  4.1847e-01,\n                       8.5130e-01,  3.8063e-01, -1.1130e-02,  9.5625e-01,  3.2814e-01,\n                       1.4986e-01, -4.3955e-01,  1.5870e-02,  3.6438e-01, -4.8804e-01,\n                       8.7743e-01, -3.6821e-01,  1.0809e+00,  6.3100e-01, -4.2783e-01,\n                       1.1584e-01, -6.1395e-01,  1.0540e-01, -2.3331e-01, -9.3521e-01,\n                       7.2648e-01,  1.0963e-01,  9.6573e-01, -2.1461e-02, -5.1821e-02,\n                      -4.2013e-01,  1.5057e-01, -1.4243e-01,  1.2127e-01, -1.1201e+00,\n                       5.7285e-01, -5.5514e-04, -3.9032e-01, -1.4426e-01,  4.6195e-01,\n                      -7.8567e-03,  6.7652e-01, -1.5185e+00,  4.2479e-03, -4.0399e-01,\n                      -6.5788e-02,  3.2118e-01, -2.3551e-03, -6.1577e-01, -1.7627e-01,\n                      -1.4676e-01, -7.0901e-01, -2.8145e-01,  5.9551e-01,  5.9078e-01,\n                      -6.4628e-02, -4.6498e-01,  1.3718e-01,  9.6977e-02,  3.1492e-01,\n                      -4.5557e-02,  7.8428e-01,  5.0170e-01, -5.4388e-01],\n                     dtype=torch.float64)),\n             ('6.9.convs.0.1.running_var',\n              tensor([0.2462, 0.3808, 0.2727, 0.2755, 0.1013, 0.9384, 0.2195, 0.1275, 0.1446,\n                      0.4254, 0.1599, 0.3240, 0.2067, 0.1295, 0.1214, 0.1466, 0.1249, 0.4835,\n                      0.1151, 0.1273, 0.2318, 0.2259, 0.1636, 0.0779, 0.4462, 0.5663, 0.1118,\n                      0.1338, 0.1290, 0.2601, 0.2451, 0.3338, 0.2074, 0.1195, 0.1043, 0.1824,\n                      0.3848, 0.2102, 0.2994, 0.5008, 0.1136, 0.7953, 0.1328, 0.1803, 0.1153,\n                      0.1446, 0.2042, 0.1558, 0.4887, 0.1309, 0.1366, 0.1614, 0.1149, 0.2081,\n                      0.7528, 0.1145, 0.1437, 0.4131, 0.3380, 0.3017, 0.2566, 0.1229, 0.1149,\n                      0.8034], dtype=torch.float64)),\n             ('6.9.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.9.convs.1.0.weight',\n              tensor([[[-0.0375, -0.0436,  0.1358,  0.0026, -0.0103],\n                       [ 0.1822,  0.0703, -0.1437, -0.0380,  0.0550],\n                       [ 0.0140, -0.0111, -0.0070, -0.1559,  0.0123],\n                       ...,\n                       [-0.1447,  0.1245,  0.0411, -0.0129, -0.1039],\n                       [ 0.0174, -0.0908,  0.0043, -0.1087, -0.1515],\n                       [-0.0010, -0.0775, -0.0219, -0.0696,  0.0306]],\n              \n                      [[-0.0341,  0.0068, -0.0217,  0.0647,  0.0235],\n                       [-0.0950, -0.1610,  0.0076, -0.0661, -0.0067],\n                       [ 0.1058,  0.0332,  0.0235,  0.1473, -0.0424],\n                       ...,\n                       [ 0.0376, -0.0129,  0.0148, -0.0103,  0.0428],\n                       [-0.1770,  0.0480, -0.0097,  0.0857, -0.0996],\n                       [ 0.1425,  0.0803,  0.0381,  0.1541, -0.0931]],\n              \n                      [[ 0.0214,  0.0125,  0.0488, -0.0231, -0.0332],\n                       [ 0.1249,  0.0729, -0.0125,  0.0653,  0.0047],\n                       [-0.0869, -0.1084, -0.0604, -0.0563, -0.0303],\n                       ...,\n                       [-0.0623, -0.0984,  0.1214, -0.0181,  0.0268],\n                       [-0.1094,  0.0629,  0.1208,  0.0964, -0.0058],\n                       [-0.0580, -0.0348,  0.1308,  0.0524,  0.0527]],\n              \n                      ...,\n              \n                      [[-0.0712,  0.0538, -0.0044, -0.0373,  0.1484],\n                       [-0.1403, -0.0338,  0.0162,  0.0637, -0.0987],\n                       [ 0.0461, -0.0691, -0.2055, -0.0315, -0.0023],\n                       ...,\n                       [-0.1200,  0.0239,  0.0774, -0.0476,  0.0003],\n                       [-0.0211, -0.1110, -0.1346, -0.0744, -0.0921],\n                       [ 0.0624,  0.0962,  0.0043,  0.1145, -0.0743]],\n              \n                      [[-0.0120,  0.0767, -0.0028,  0.0145,  0.0977],\n                       [-0.0431, -0.0102, -0.0652, -0.0951,  0.0675],\n                       [ 0.0216,  0.0194, -0.0389, -0.1032, -0.0460],\n                       ...,\n                       [ 0.0792, -0.1153, -0.0698,  0.0975,  0.0158],\n                       [-0.0884,  0.0936,  0.0910, -0.0802,  0.0101],\n                       [-0.0253, -0.0336,  0.0245, -0.0596, -0.0593]],\n              \n                      [[-0.0532,  0.0435,  0.2633, -0.0868,  0.1731],\n                       [ 0.0842, -0.0355,  0.0880,  0.1475,  0.1062],\n                       [ 0.0087,  0.1173,  0.0910, -0.1063, -0.0219],\n                       ...,\n                       [-0.0810, -0.0384,  0.0367, -0.0159,  0.1417],\n                       [ 0.0524,  0.0835, -0.0103,  0.1464,  0.0845],\n                       [ 0.0081, -0.0855, -0.0378,  0.0202,  0.0901]]], dtype=torch.float64)),\n             ('6.9.convs.1.1.weight',\n              tensor([1.0122, 0.9534, 0.9696, 0.9633, 0.9643, 1.0124, 0.9534, 0.9577, 0.9762,\n                      0.9636, 0.9512, 0.9230, 0.9639, 0.9538, 0.9679, 0.9504, 0.9591, 0.9583,\n                      0.9664, 0.9653, 0.9647, 0.9833, 0.9629, 0.9912, 0.9715, 0.9796, 0.9683,\n                      0.9589, 0.9363, 0.9612, 0.9594, 0.9842, 0.9726, 0.9626, 1.0199, 0.9679,\n                      0.9765, 0.9893, 0.9534, 0.9179, 0.9577, 0.9812, 0.9508, 0.9425, 0.9622,\n                      0.9914, 0.9875, 0.9605, 0.9697, 0.9573, 0.9798, 0.9693, 0.9878, 0.9776,\n                      0.9646, 0.9734, 0.9695, 0.9810, 0.9722, 0.9479, 0.9644, 0.9433, 0.9418,\n                      0.9432], dtype=torch.float64)),\n             ('6.9.convs.1.1.bias',\n              tensor([ 0.0243, -0.0026,  0.0020, -0.0055, -0.0125,  0.0327, -0.0025, -0.0050,\n                      -0.0023, -0.0125, -0.0225, -0.0294,  0.0046, -0.0092, -0.0133,  0.0023,\n                       0.0005, -0.0103,  0.0023,  0.0133, -0.0190,  0.0003, -0.0049, -0.0057,\n                      -0.0149,  0.0024, -0.0065, -0.0153, -0.0130,  0.0037, -0.0174,  0.0121,\n                       0.0083, -0.0075,  0.0121, -0.0063, -0.0003,  0.0060, -0.0161, -0.0155,\n                      -0.0109,  0.0043, -0.0284, -0.0300, -0.0262,  0.0230,  0.0070,  0.0077,\n                      -0.0011, -0.0060,  0.0124, -0.0075,  0.0320,  0.0162, -0.0057, -0.0250,\n                       0.0126,  0.0154,  0.0065, -0.0282, -0.0216, -0.0183, -0.0059, -0.0290],\n                     dtype=torch.float64)),\n             ('6.9.convs.1.1.running_mean',\n              tensor([-1.2514,  0.0662, -0.3021, -0.1990,  1.2269, -0.8138, -0.3655,  0.0439,\n                      -0.8457, -0.0487, -0.5501,  0.0947, -0.4014,  0.1619,  0.5045, -0.6021,\n                      -0.8322, -0.6092,  0.9667, -0.4734,  0.2212, -0.5115, -1.0419,  0.2626,\n                      -0.0119, -0.1979,  0.4004,  0.5910, -0.6113, -0.0663,  0.5426,  0.2087,\n                       0.6633,  0.0207, -0.2110, -0.2268,  0.7308, -0.5353,  0.1103, -0.3382,\n                       0.5863,  1.0467,  0.2675,  0.6656,  0.1332, -0.1556, -0.1738, -0.1929,\n                       0.6005, -0.4710,  0.2127, -0.2831, -0.2715, -0.7200, -0.0334,  0.7627,\n                      -0.8695, -0.5102, -0.2038,  0.2374,  0.3683, -1.1049, -0.4220, -0.1263],\n                     dtype=torch.float64)),\n             ('6.9.convs.1.1.running_var',\n              tensor([0.4951, 0.5551, 0.5161, 0.7929, 0.6730, 0.8803, 0.5287, 0.4668, 0.7212,\n                      0.4924, 0.8019, 0.7413, 1.0987, 0.7438, 0.4537, 0.8554, 0.6237, 0.6271,\n                      0.5643, 0.4603, 0.5157, 0.5985, 0.5596, 0.4932, 0.8332, 0.4350, 0.5210,\n                      0.6271, 0.5215, 0.7864, 0.7577, 0.4459, 0.5980, 0.7107, 0.4871, 0.4155,\n                      0.5383, 0.7093, 0.6683, 0.4401, 1.0233, 0.4873, 0.5053, 0.6209, 0.3728,\n                      0.4552, 0.5253, 0.4817, 0.6232, 0.6157, 0.7725, 0.5324, 0.7049, 0.5713,\n                      0.6358, 0.6494, 0.4572, 0.6735, 0.4575, 0.5501, 0.5756, 0.7872, 0.5334,\n                      0.9152], dtype=torch.float64)),\n             ('6.9.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.9.convs.2.0.weight',\n              tensor([[[ 0.0893],\n                       [-0.0455],\n                       [-0.2674],\n                       ...,\n                       [ 0.1167],\n                       [-0.0836],\n                       [ 0.2465]],\n              \n                      [[-0.2033],\n                       [ 0.0706],\n                       [-0.1168],\n                       ...,\n                       [-0.0581],\n                       [ 0.1263],\n                       [ 0.0072]],\n              \n                      [[-0.0705],\n                       [-0.0357],\n                       [ 0.1340],\n                       ...,\n                       [ 0.1086],\n                       [ 0.1340],\n                       [ 0.0703]],\n              \n                      ...,\n              \n                      [[ 0.0073],\n                       [-0.0165],\n                       [-0.1484],\n                       ...,\n                       [ 0.0422],\n                       [-0.0156],\n                       [ 0.0365]],\n              \n                      [[-0.0883],\n                       [ 0.0145],\n                       [ 0.0252],\n                       ...,\n                       [-0.0438],\n                       [ 0.0520],\n                       [-0.0764]],\n              \n                      [[-0.1101],\n                       [-0.0844],\n                       [-0.0323],\n                       ...,\n                       [ 0.0104],\n                       [-0.0811],\n                       [-0.0769]]], dtype=torch.float64)),\n             ('6.9.convs.2.1.weight',\n              tensor([ 3.8197e-02,  2.1366e-02,  2.4696e-02,  1.4561e-02, -6.2829e-03,\n                       2.0589e-02, -2.8215e-04,  6.6789e-03, -1.7766e-02, -1.9854e-02,\n                       3.2550e-03, -2.2405e-03,  8.2939e-03, -8.2569e-04, -8.4355e-04,\n                      -5.2118e-02,  5.4740e-03,  1.9636e-03, -9.1535e-03,  2.5672e-02,\n                      -5.5989e-03, -9.4478e-03,  1.5207e-03, -2.0959e-02,  1.0322e-02,\n                       1.7054e-04, -3.0756e-03, -1.1003e-02,  1.6626e-03,  1.2533e-02,\n                       4.0056e-02,  1.5763e-02, -1.0410e-02,  1.4234e-02, -2.7693e-02,\n                      -1.1018e-02, -2.2641e-02, -6.7160e-03, -1.2052e-02, -3.3082e-02,\n                       5.9991e-03, -8.8727e-03, -3.3118e-02, -3.2117e-03, -9.7912e-03,\n                       1.3251e-02,  2.3738e-02, -9.1586e-03,  2.3567e-03,  6.8963e-03,\n                       1.5196e-03,  3.2188e-02, -1.8743e-05,  1.8416e-02, -2.1405e-02,\n                       5.7661e-03, -4.9039e-03,  1.9656e-02,  3.9762e-03, -1.1368e-02,\n                       1.2981e-02, -1.8732e-03,  2.0916e-02, -6.4356e-03, -2.7787e-02,\n                      -8.9875e-03,  1.4702e-02,  2.1318e-02, -2.4436e-02,  1.4646e-02,\n                       5.4845e-03,  5.2684e-03,  1.6982e-02, -3.8205e-03,  2.0069e-02,\n                       1.4001e-02,  2.0501e-02,  1.8135e-02,  2.7525e-02,  1.4677e-02,\n                      -7.2911e-03, -6.9844e-03, -8.7730e-03, -4.4011e-03, -1.8420e-02,\n                      -2.7725e-02,  2.7036e-02,  4.7727e-04, -1.3584e-03, -2.1909e-02,\n                      -2.3168e-03, -1.7575e-03,  1.6877e-02, -2.5837e-03,  2.1309e-02,\n                       7.9868e-04,  4.7593e-03,  5.0303e-03,  1.9330e-02, -1.0573e-02,\n                       2.8600e-04,  1.3909e-02,  2.4698e-02, -6.4631e-03, -8.4863e-03,\n                       1.5554e-02,  6.1310e-03, -1.3418e-02,  1.1456e-02, -1.2268e-02,\n                      -1.1725e-02, -7.2832e-04, -1.7940e-02, -1.4059e-02,  1.5236e-02,\n                       1.4531e-02, -7.3030e-03,  1.3628e-02, -5.6375e-03,  5.0602e-03,\n                      -2.0684e-02, -1.5507e-03,  4.7530e-03, -8.6688e-03, -1.0095e-02,\n                       7.6345e-03,  2.4969e-03, -2.5301e-02,  1.5391e-02,  6.2170e-03,\n                       1.1334e-02,  8.4427e-04, -1.2570e-02,  1.1552e-02, -9.7551e-03,\n                       4.4813e-03,  4.0318e-02, -1.6385e-02,  1.3779e-02,  1.4663e-02,\n                      -5.1428e-04,  1.6617e-02, -9.6113e-03, -9.9553e-03,  1.1362e-02,\n                      -1.9588e-02, -6.3355e-03,  7.2053e-03, -2.0011e-02, -8.3248e-03,\n                      -2.6182e-02, -1.9902e-04, -1.1457e-02,  1.7781e-02, -2.1089e-03,\n                       1.3304e-02, -3.0273e-03, -2.2991e-02,  2.0670e-02, -1.5204e-02,\n                      -2.1731e-02,  8.4588e-03,  2.7016e-03,  5.1305e-04,  1.8516e-02,\n                       1.1654e-02, -6.0683e-03,  2.1588e-02,  1.3673e-02,  2.2667e-02,\n                      -5.0496e-03,  1.3705e-02, -2.6801e-02,  7.4720e-03,  1.9639e-03,\n                       1.5954e-02, -2.0386e-02,  4.7803e-02,  7.6350e-04,  9.5020e-03,\n                       3.2695e-03,  1.4055e-04,  4.9750e-03,  1.9632e-02,  2.1211e-02,\n                      -8.1133e-03,  7.4683e-03, -4.1438e-03,  8.7901e-03,  5.2431e-03,\n                      -2.1540e-03, -4.5825e-03, -2.8451e-02, -2.8668e-02,  2.0430e-02,\n                       2.1461e-02, -9.6153e-03, -2.3711e-02,  5.8847e-03, -6.9132e-03,\n                       5.2752e-03, -3.0356e-02,  1.9696e-02, -9.9085e-03,  1.4255e-02,\n                       5.4290e-03,  2.0562e-02,  1.9429e-02, -6.4988e-03,  1.4216e-02,\n                      -6.9774e-03, -1.3568e-02, -1.1343e-02, -1.4171e-02,  1.5999e-02,\n                       7.3574e-03, -6.1076e-03,  2.1894e-02,  6.7295e-03, -2.2721e-04,\n                      -1.0427e-02, -5.6908e-03,  6.9117e-03,  1.8961e-02,  4.8462e-04,\n                       7.7365e-04, -1.3075e-04,  1.1878e-02,  3.8245e-03, -1.2529e-02,\n                       4.3224e-03,  1.1561e-02,  4.1882e-02,  1.5538e-02,  1.4056e-02,\n                      -1.7800e-02, -1.2519e-02, -2.3626e-02, -1.4380e-02,  1.2683e-02,\n                      -1.3807e-02,  1.9819e-02, -2.5073e-02, -4.2987e-02, -1.3713e-02,\n                      -9.6242e-03,  1.1155e-02, -2.1724e-02,  1.1837e-02, -4.4349e-03,\n                      -2.6107e-02,  2.7170e-02,  9.4104e-03, -1.3384e-03,  2.2749e-02,\n                       2.3418e-03], dtype=torch.float64)),\n             ('6.9.convs.2.1.bias',\n              tensor([-6.4846e-04,  3.4670e-03,  1.3560e-02,  1.3903e-02,  1.0323e-03,\n                       1.3111e-02,  7.6078e-03, -7.1756e-04,  1.2451e-02,  1.4780e-02,\n                       1.3135e-02, -7.5430e-03,  8.1079e-03, -3.5415e-03,  1.1186e-02,\n                       4.0195e-03,  2.2127e-02, -3.6439e-03,  1.0206e-02, -2.1828e-03,\n                      -3.5464e-03,  1.6337e-03,  2.8847e-03,  5.6239e-03,  2.1583e-03,\n                      -1.6947e-02,  1.1932e-03,  6.8007e-03, -1.7143e-03, -3.1892e-03,\n                       3.3445e-03,  7.4800e-03, -5.6142e-03,  1.8470e-02,  8.8573e-03,\n                       1.6069e-02,  3.8610e-03,  2.0562e-02,  5.7403e-03,  1.5740e-02,\n                      -3.9430e-04,  2.0469e-02, -7.2633e-03,  7.7431e-05,  3.5858e-03,\n                      -9.0705e-03,  3.0999e-03,  2.8893e-03, -1.1129e-02,  9.1805e-03,\n                       1.0326e-02,  7.3620e-03,  7.6639e-03,  1.0123e-02,  4.9705e-03,\n                       2.0092e-02,  8.8805e-03,  1.8766e-03,  1.2297e-02,  8.3502e-04,\n                      -2.5419e-03,  9.3884e-04,  4.7181e-03,  8.7003e-03, -5.0107e-03,\n                       6.2617e-03, -1.1034e-02,  1.5183e-02,  2.7905e-03, -1.3341e-02,\n                       4.4583e-03,  2.7764e-03,  1.4734e-03, -6.8418e-03,  1.4786e-02,\n                       2.2719e-03,  4.4943e-03,  6.9237e-03,  4.1080e-03,  1.8831e-03,\n                       7.8287e-03, -6.3343e-03,  1.0328e-02,  4.7032e-03, -3.8044e-03,\n                       1.9094e-02, -8.4135e-04, -1.9934e-03,  1.7345e-02,  1.4599e-03,\n                       9.6969e-04,  8.9588e-03,  1.0819e-02, -8.3166e-04,  1.0169e-02,\n                      -1.5017e-02,  1.0828e-02,  1.9028e-03,  8.1641e-03, -1.2069e-03,\n                       1.9103e-02,  1.3743e-02,  4.5405e-03,  8.1596e-03,  2.8097e-03,\n                      -1.6397e-03, -1.5450e-03,  2.6037e-03,  5.3576e-03,  8.4291e-03,\n                      -1.0479e-02, -7.0350e-03,  5.6558e-03,  1.8411e-02,  1.1956e-02,\n                       5.3564e-03,  8.9365e-03,  2.3824e-03,  5.4456e-03, -1.6324e-02,\n                       1.5570e-03,  8.4389e-03, -7.0661e-04, -1.8132e-03, -5.9987e-03,\n                       9.4284e-03,  1.5256e-02,  6.3889e-03,  3.3287e-03,  1.7133e-02,\n                       1.0354e-02,  1.4330e-02,  1.3853e-02,  1.1783e-02,  1.6198e-02,\n                      -8.6506e-03,  1.5983e-02,  7.1688e-03,  1.3772e-02,  4.4455e-03,\n                       1.6668e-02, -5.3644e-03,  1.7795e-02,  4.4281e-03, -9.2293e-03,\n                       1.2964e-02, -6.2488e-04, -2.8342e-04,  1.2235e-02,  1.0201e-02,\n                       5.9463e-03,  1.2033e-02,  1.2914e-02,  1.2968e-02,  1.2481e-02,\n                       9.6396e-03,  3.2761e-04,  4.3209e-03, -1.3388e-03, -1.2766e-02,\n                       4.3126e-03, -3.1320e-03,  2.6008e-05,  9.4736e-03,  1.4805e-02,\n                      -2.8470e-03, -1.1368e-02,  1.2965e-02, -1.1121e-03,  1.8382e-02,\n                       4.5141e-03,  1.8434e-03,  1.2704e-02,  1.1463e-02, -1.3834e-02,\n                      -8.7677e-04, -7.2587e-04,  1.1072e-02,  2.4293e-03,  4.0718e-03,\n                      -5.8031e-03,  1.0492e-02, -6.6294e-03, -8.9262e-03,  1.9337e-02,\n                       7.2007e-03,  1.4884e-02,  9.1093e-03,  3.1240e-03,  7.0490e-03,\n                       6.8572e-03,  2.2262e-03,  1.0290e-02, -6.0214e-03,  4.4594e-03,\n                       5.3444e-03, -5.1600e-03,  1.0863e-02,  7.8465e-03,  1.6185e-02,\n                       1.2771e-03,  2.3475e-02,  2.1071e-02,  2.1209e-02,  2.6302e-03,\n                      -2.8398e-03,  8.8677e-03, -3.9001e-03,  6.8875e-03,  1.3522e-02,\n                       6.1550e-03,  1.1425e-02,  1.4341e-02,  7.3221e-03,  8.2503e-03,\n                      -3.2638e-04,  2.2783e-03, -1.3564e-03,  2.9843e-03, -1.4735e-03,\n                      -1.3981e-02,  1.2161e-03,  4.0684e-03,  1.8059e-02, -4.0838e-03,\n                       2.8558e-03, -3.7181e-03, -2.7040e-04, -1.4946e-02,  1.4309e-02,\n                       5.7225e-03, -2.0625e-03,  7.8892e-03,  5.3784e-03,  2.4442e-03,\n                       7.9535e-03,  6.6799e-03, -4.6101e-03,  1.2040e-02,  4.3402e-03,\n                       1.1283e-03,  4.2626e-04,  2.4149e-03,  8.8295e-03,  4.7386e-03,\n                       1.3292e-02,  4.6131e-03,  7.5871e-03, -8.0850e-04, -9.1783e-03,\n                       1.7131e-02,  2.1774e-02,  2.0271e-02,  1.4859e-02,  9.6975e-03,\n                       1.2369e-03], dtype=torch.float64)),\n             ('6.9.convs.2.1.running_mean',\n              tensor([-0.1147, -0.4197,  0.1856,  0.1600,  0.2017, -0.3548, -0.2849, -0.2420,\n                       0.1832, -0.7393, -0.0484,  0.0668, -0.3063, -0.1696,  0.4185,  1.4938,\n                       0.0752, -0.1952,  0.0146, -0.8348, -0.1308,  0.6076,  0.2876,  0.3286,\n                      -0.4414, -0.2555, -0.3208, -0.1436, -0.2482,  0.3056, -0.0332, -0.3530,\n                      -0.1061, -0.1616, -0.0986, -0.1400,  0.1554, -0.2614, -0.5994, -0.0546,\n                      -0.4695, -0.0484,  0.0255,  0.2898,  0.2685, -0.6784,  0.2800, -0.0976,\n                      -0.3457,  0.2126,  0.0305,  0.7658,  0.2623, -0.0713, -0.8933, -0.4809,\n                      -0.0042,  0.3441, -0.3661, -0.2123,  0.1557,  0.4125, -0.1666,  0.1306,\n                       0.5786,  0.1405, -0.0231,  0.0765, -0.0091, -0.1122,  0.2508, -0.1710,\n                      -0.1152, -0.0963, -0.4225,  0.5683,  0.2269,  0.2038,  0.7734, -0.3499,\n                       0.0233,  0.1448, -0.2664,  0.2740,  0.3847, -0.1142, -0.3360,  0.0627,\n                      -0.1295, -0.4552,  0.0774, -0.0260,  0.2801,  0.1809,  0.1028,  0.1019,\n                       0.0068, -0.3263,  0.0792, -0.0847,  0.2248,  0.5321,  0.2797,  0.1087,\n                       0.1056,  0.1422, -0.0532, -0.3065, -0.5281, -0.4906,  0.3444, -0.4464,\n                       0.5022,  0.2156,  0.4486, -0.5130,  0.2573,  0.5147, -0.2340,  0.1568,\n                      -0.2512, -0.4811, -0.3822,  0.7150,  0.0380, -0.0926,  0.1554, -0.2932,\n                      -0.0347, -0.0567,  0.2579,  0.2368, -0.3463, -0.0242,  0.2719,  0.2137,\n                       0.1343, -0.0277,  0.6522,  0.4034, -0.2241, -0.3542, -0.0213,  0.0394,\n                       0.1192, -0.0051, -0.2208,  0.9563,  0.2515, -0.2958,  0.3882,  0.2171,\n                      -0.2739, -0.4189,  0.3423,  0.6098, -0.1191,  0.3831,  0.1518, -0.5003,\n                       0.0916, -0.2091,  0.1989,  0.2209, -0.0519,  0.0627, -0.0144,  0.2527,\n                      -0.5587, -0.2902, -0.1265,  0.2108, -0.0807,  0.2127,  0.2084, -0.0287,\n                       0.2230, -0.2488,  0.0266,  0.0351,  0.8118, -0.0022,  0.3518,  0.0087,\n                       0.3701, -0.1938,  0.4315, -0.3034, -0.1270, -0.1790, -0.5028,  0.7335,\n                      -0.2608, -0.1508,  0.1336,  0.0768, -0.3157, -0.2619, -0.6927, -0.3791,\n                      -0.0610,  0.1268, -0.0597,  0.3434,  0.2909, -0.3056,  0.5169, -0.1156,\n                      -0.0429, -0.4485,  0.1017,  0.0873, -0.4607,  0.0906,  0.5384, -0.3130,\n                      -0.3855,  0.0149, -0.3241,  0.5847, -0.2137, -0.1886,  0.0791,  0.5524,\n                      -0.1036, -0.3656, -0.3034,  0.6169, -0.0711, -0.1529, -0.2413, -0.3578,\n                       0.0816, -0.1168, -0.4330, -0.2819,  0.0120, -0.3821, -0.2923,  0.5618,\n                      -0.1914,  0.3470,  0.3961,  0.2907, -0.0484,  0.0759,  0.2851,  0.1941,\n                       0.1031, -0.0488,  0.2944, -0.2256, -0.0739,  0.0652, -0.4319, -0.0753],\n                     dtype=torch.float64)),\n             ('6.9.convs.2.1.running_var',\n              tensor([0.4803, 0.5478, 0.4625, 0.3673, 0.1948, 0.2871, 0.1768, 0.3114, 0.3147,\n                      0.8863, 0.0980, 0.4286, 0.1232, 0.1722, 0.2081, 0.5771, 0.2073, 0.2113,\n                      0.1340, 0.4499, 0.2137, 0.4084, 0.2078, 0.3653, 0.4133, 0.1126, 0.2002,\n                      0.2677, 0.1279, 0.5691, 0.2992, 0.6103, 0.0756, 0.4039, 0.2903, 0.3548,\n                      0.3748, 0.2422, 0.5304, 0.5673, 0.5298, 0.1313, 0.3278, 0.3795, 0.3627,\n                      0.3433, 0.2928, 0.1844, 0.3451, 0.2010, 0.2011, 0.5306, 0.3434, 0.3450,\n                      0.4072, 0.1961, 0.4315, 0.5280, 0.4315, 0.4961, 0.1577, 0.1158, 0.3670,\n                      0.2104, 0.4688, 0.1069, 0.4705, 0.4134, 0.4165, 0.4189, 0.4089, 0.2667,\n                      0.1970, 0.4285, 0.5902, 0.3144, 0.6138, 0.2077, 0.4767, 0.1663, 0.1981,\n                      0.3499, 0.1911, 0.3684, 0.4142, 0.4183, 0.4339, 0.2023, 0.3758, 0.3068,\n                      0.3147, 0.1258, 0.2441, 0.1655, 0.3332, 0.2130, 0.4478, 0.3991, 0.4338,\n                      0.1957, 0.3035, 0.4672, 0.2368, 0.2352, 0.1689, 0.2376, 0.1583, 0.5390,\n                      0.2454, 0.2871, 0.1673, 0.4166, 0.4412, 0.3265, 0.4863, 0.4778, 0.4208,\n                      0.3350, 0.2198, 0.2302, 0.2356, 0.3902, 0.2601, 0.2968, 0.3177, 0.4056,\n                      0.1246, 0.2656, 0.2487, 0.4658, 0.2180, 0.2710, 0.3628, 0.1668, 0.2449,\n                      0.0676, 0.4741, 0.3067, 0.4366, 0.2359, 0.1120, 0.3539, 0.3944, 0.2258,\n                      0.3504, 0.4846, 0.1943, 0.4633, 0.1682, 0.4215, 0.4680, 0.1953, 0.2594,\n                      0.4176, 0.2188, 0.3408, 0.2014, 0.4109, 0.3926, 0.3819, 0.2703, 0.2993,\n                      0.1883, 0.1662, 0.4236, 0.3287, 0.4012, 0.3746, 0.3899, 0.4601, 0.4296,\n                      0.2782, 0.5423, 0.4095, 0.5457, 1.0451, 0.4015, 0.5590, 0.1655, 0.2209,\n                      0.4795, 0.1139, 0.2623, 0.3971, 0.3237, 0.5345, 0.3264, 0.1880, 0.3865,\n                      0.1408, 0.1883, 0.3963, 0.3412, 0.3708, 0.3337, 0.6031, 0.3492, 0.4676,\n                      0.2792, 0.4250, 0.1088, 0.5088, 0.4109, 0.2139, 0.2385, 0.2611, 0.2457,\n                      0.2573, 0.1701, 0.4551, 0.0689, 0.1759, 0.3959, 0.3574, 0.3201, 0.3698,\n                      0.5916, 0.3713, 0.3145, 0.3787, 0.3560, 0.1390, 0.1719, 0.4745, 0.3214,\n                      0.1735, 0.2497, 0.3693, 0.5153, 0.5044, 0.1635, 0.2772, 0.3693, 0.4279,\n                      0.4518, 0.7858, 0.1138, 0.4074, 0.5333, 0.3842, 0.4550, 0.3329, 0.6317,\n                      0.3377, 0.3532, 0.1406, 0.3594, 0.4929, 0.2524, 0.5136, 0.5394, 0.4202,\n                      0.2679, 0.2038, 0.2785, 0.3282], dtype=torch.float64)),\n             ('6.9.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.9.convpath.0.0.0.weight',\n              tensor([[[-0.0813],\n                       [ 0.0610],\n                       [-0.0926],\n                       ...,\n                       [-0.0010],\n                       [ 0.0468],\n                       [-0.0065]],\n              \n                      [[ 0.1631],\n                       [ 0.0335],\n                       [ 0.0903],\n                       ...,\n                       [ 0.1104],\n                       [ 0.0539],\n                       [-0.0513]],\n              \n                      [[ 0.0223],\n                       [-0.0326],\n                       [-0.0781],\n                       ...,\n                       [ 0.0177],\n                       [-0.1569],\n                       [ 0.0532]],\n              \n                      ...,\n              \n                      [[ 0.0231],\n                       [ 0.1380],\n                       [ 0.0566],\n                       ...,\n                       [ 0.0244],\n                       [-0.1035],\n                       [-0.0193]],\n              \n                      [[ 0.1010],\n                       [-0.0405],\n                       [ 0.0025],\n                       ...,\n                       [-0.0571],\n                       [-0.1015],\n                       [ 0.0298]],\n              \n                      [[-0.0005],\n                       [ 0.0264],\n                       [-0.0925],\n                       ...,\n                       [ 0.0210],\n                       [ 0.0282],\n                       [-0.0404]]], dtype=torch.float64)),\n             ('6.9.convpath.0.0.1.weight',\n              tensor([0.9750, 0.9819, 0.9649, 0.9776, 0.9871, 0.9467, 0.9595, 0.9758, 1.0028,\n                      0.9632, 0.9893, 0.9389, 0.9785, 0.9899, 0.9649, 0.9732, 0.9734, 0.9575,\n                      0.9941, 0.9702, 0.9553, 0.9850, 0.9682, 0.9923, 0.9465, 0.9507, 0.9835,\n                      0.9816, 0.9771, 0.9428, 0.9717, 0.9623, 0.9523, 0.9815, 0.9632, 0.9720,\n                      0.9552, 0.9900, 0.9657, 0.9680, 0.9769, 0.9607, 0.9654, 0.9850, 0.9596,\n                      0.9854, 0.9849, 0.9691, 0.9443, 0.9693, 0.9721, 0.9748, 0.9836, 0.9763,\n                      0.9679, 0.9778, 0.9940, 0.9622, 0.9825, 0.9556, 0.9634, 0.9741, 0.9662,\n                      0.9424], dtype=torch.float64)),\n             ('6.9.convpath.0.0.1.bias',\n              tensor([ 1.2720e-02, -3.1621e-03, -5.3963e-03, -4.0528e-03,  1.7812e-03,\n                      -2.4145e-02,  2.7870e-03, -3.8004e-03,  2.2681e-03,  5.0583e-03,\n                       1.5305e-02, -1.8052e-02,  1.2570e-02, -1.5111e-02, -2.7473e-03,\n                       1.8942e-03, -1.1458e-02, -1.1732e-02,  2.9528e-02,  1.1348e-03,\n                      -1.3661e-02,  1.0696e-02,  2.9996e-03,  9.0068e-03, -1.1412e-02,\n                      -8.1377e-03, -3.0630e-03,  9.3411e-04,  1.2722e-02, -1.8332e-03,\n                       3.0892e-02, -1.5897e-02, -1.5398e-02,  9.6534e-03, -2.6470e-03,\n                       7.5174e-03, -3.3340e-03,  8.7480e-03, -1.3130e-02, -3.0183e-03,\n                       1.4194e-02, -3.4733e-03,  3.5211e-03,  3.3736e-03, -6.8094e-03,\n                      -4.1734e-03,  1.6319e-02,  1.0342e-03,  5.2933e-03,  2.1836e-03,\n                      -4.6685e-03,  1.0572e-02,  8.4254e-03,  1.9179e-02, -1.4815e-02,\n                       3.7394e-05,  1.5185e-02, -3.2271e-03,  2.3928e-03,  4.0501e-03,\n                       1.9671e-02, -2.0330e-02, -1.9237e-02,  4.9478e-03],\n                     dtype=torch.float64)),\n             ('6.9.convpath.0.0.1.running_mean',\n              tensor([-5.1299e-01,  2.1893e-01, -2.2575e-01, -6.0247e-01,  4.1847e-01,\n                       8.5130e-01,  3.8063e-01, -1.1130e-02,  9.5625e-01,  3.2814e-01,\n                       1.4986e-01, -4.3955e-01,  1.5870e-02,  3.6438e-01, -4.8804e-01,\n                       8.7743e-01, -3.6821e-01,  1.0809e+00,  6.3100e-01, -4.2783e-01,\n                       1.1584e-01, -6.1395e-01,  1.0540e-01, -2.3331e-01, -9.3521e-01,\n                       7.2648e-01,  1.0963e-01,  9.6573e-01, -2.1461e-02, -5.1821e-02,\n                      -4.2013e-01,  1.5057e-01, -1.4243e-01,  1.2127e-01, -1.1201e+00,\n                       5.7285e-01, -5.5514e-04, -3.9032e-01, -1.4426e-01,  4.6195e-01,\n                      -7.8567e-03,  6.7652e-01, -1.5185e+00,  4.2479e-03, -4.0399e-01,\n                      -6.5788e-02,  3.2118e-01, -2.3551e-03, -6.1577e-01, -1.7627e-01,\n                      -1.4676e-01, -7.0901e-01, -2.8145e-01,  5.9551e-01,  5.9078e-01,\n                      -6.4628e-02, -4.6498e-01,  1.3718e-01,  9.6977e-02,  3.1492e-01,\n                      -4.5557e-02,  7.8428e-01,  5.0170e-01, -5.4388e-01],\n                     dtype=torch.float64)),\n             ('6.9.convpath.0.0.1.running_var',\n              tensor([0.2462, 0.3808, 0.2727, 0.2755, 0.1013, 0.9384, 0.2195, 0.1275, 0.1446,\n                      0.4254, 0.1599, 0.3240, 0.2067, 0.1295, 0.1214, 0.1466, 0.1249, 0.4835,\n                      0.1151, 0.1273, 0.2318, 0.2259, 0.1636, 0.0779, 0.4462, 0.5663, 0.1118,\n                      0.1338, 0.1290, 0.2601, 0.2451, 0.3338, 0.2074, 0.1195, 0.1043, 0.1824,\n                      0.3848, 0.2102, 0.2994, 0.5008, 0.1136, 0.7953, 0.1328, 0.1803, 0.1153,\n                      0.1446, 0.2042, 0.1558, 0.4887, 0.1309, 0.1366, 0.1614, 0.1149, 0.2081,\n                      0.7528, 0.1145, 0.1437, 0.4131, 0.3380, 0.3017, 0.2566, 0.1229, 0.1149,\n                      0.8034], dtype=torch.float64)),\n             ('6.9.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.9.convpath.0.1.0.weight',\n              tensor([[[-0.0375, -0.0436,  0.1358,  0.0026, -0.0103],\n                       [ 0.1822,  0.0703, -0.1437, -0.0380,  0.0550],\n                       [ 0.0140, -0.0111, -0.0070, -0.1559,  0.0123],\n                       ...,\n                       [-0.1447,  0.1245,  0.0411, -0.0129, -0.1039],\n                       [ 0.0174, -0.0908,  0.0043, -0.1087, -0.1515],\n                       [-0.0010, -0.0775, -0.0219, -0.0696,  0.0306]],\n              \n                      [[-0.0341,  0.0068, -0.0217,  0.0647,  0.0235],\n                       [-0.0950, -0.1610,  0.0076, -0.0661, -0.0067],\n                       [ 0.1058,  0.0332,  0.0235,  0.1473, -0.0424],\n                       ...,\n                       [ 0.0376, -0.0129,  0.0148, -0.0103,  0.0428],\n                       [-0.1770,  0.0480, -0.0097,  0.0857, -0.0996],\n                       [ 0.1425,  0.0803,  0.0381,  0.1541, -0.0931]],\n              \n                      [[ 0.0214,  0.0125,  0.0488, -0.0231, -0.0332],\n                       [ 0.1249,  0.0729, -0.0125,  0.0653,  0.0047],\n                       [-0.0869, -0.1084, -0.0604, -0.0563, -0.0303],\n                       ...,\n                       [-0.0623, -0.0984,  0.1214, -0.0181,  0.0268],\n                       [-0.1094,  0.0629,  0.1208,  0.0964, -0.0058],\n                       [-0.0580, -0.0348,  0.1308,  0.0524,  0.0527]],\n              \n                      ...,\n              \n                      [[-0.0712,  0.0538, -0.0044, -0.0373,  0.1484],\n                       [-0.1403, -0.0338,  0.0162,  0.0637, -0.0987],\n                       [ 0.0461, -0.0691, -0.2055, -0.0315, -0.0023],\n                       ...,\n                       [-0.1200,  0.0239,  0.0774, -0.0476,  0.0003],\n                       [-0.0211, -0.1110, -0.1346, -0.0744, -0.0921],\n                       [ 0.0624,  0.0962,  0.0043,  0.1145, -0.0743]],\n              \n                      [[-0.0120,  0.0767, -0.0028,  0.0145,  0.0977],\n                       [-0.0431, -0.0102, -0.0652, -0.0951,  0.0675],\n                       [ 0.0216,  0.0194, -0.0389, -0.1032, -0.0460],\n                       ...,\n                       [ 0.0792, -0.1153, -0.0698,  0.0975,  0.0158],\n                       [-0.0884,  0.0936,  0.0910, -0.0802,  0.0101],\n                       [-0.0253, -0.0336,  0.0245, -0.0596, -0.0593]],\n              \n                      [[-0.0532,  0.0435,  0.2633, -0.0868,  0.1731],\n                       [ 0.0842, -0.0355,  0.0880,  0.1475,  0.1062],\n                       [ 0.0087,  0.1173,  0.0910, -0.1063, -0.0219],\n                       ...,\n                       [-0.0810, -0.0384,  0.0367, -0.0159,  0.1417],\n                       [ 0.0524,  0.0835, -0.0103,  0.1464,  0.0845],\n                       [ 0.0081, -0.0855, -0.0378,  0.0202,  0.0901]]], dtype=torch.float64)),\n             ('6.9.convpath.0.1.1.weight',\n              tensor([1.0122, 0.9534, 0.9696, 0.9633, 0.9643, 1.0124, 0.9534, 0.9577, 0.9762,\n                      0.9636, 0.9512, 0.9230, 0.9639, 0.9538, 0.9679, 0.9504, 0.9591, 0.9583,\n                      0.9664, 0.9653, 0.9647, 0.9833, 0.9629, 0.9912, 0.9715, 0.9796, 0.9683,\n                      0.9589, 0.9363, 0.9612, 0.9594, 0.9842, 0.9726, 0.9626, 1.0199, 0.9679,\n                      0.9765, 0.9893, 0.9534, 0.9179, 0.9577, 0.9812, 0.9508, 0.9425, 0.9622,\n                      0.9914, 0.9875, 0.9605, 0.9697, 0.9573, 0.9798, 0.9693, 0.9878, 0.9776,\n                      0.9646, 0.9734, 0.9695, 0.9810, 0.9722, 0.9479, 0.9644, 0.9433, 0.9418,\n                      0.9432], dtype=torch.float64)),\n             ('6.9.convpath.0.1.1.bias',\n              tensor([ 0.0243, -0.0026,  0.0020, -0.0055, -0.0125,  0.0327, -0.0025, -0.0050,\n                      -0.0023, -0.0125, -0.0225, -0.0294,  0.0046, -0.0092, -0.0133,  0.0023,\n                       0.0005, -0.0103,  0.0023,  0.0133, -0.0190,  0.0003, -0.0049, -0.0057,\n                      -0.0149,  0.0024, -0.0065, -0.0153, -0.0130,  0.0037, -0.0174,  0.0121,\n                       0.0083, -0.0075,  0.0121, -0.0063, -0.0003,  0.0060, -0.0161, -0.0155,\n                      -0.0109,  0.0043, -0.0284, -0.0300, -0.0262,  0.0230,  0.0070,  0.0077,\n                      -0.0011, -0.0060,  0.0124, -0.0075,  0.0320,  0.0162, -0.0057, -0.0250,\n                       0.0126,  0.0154,  0.0065, -0.0282, -0.0216, -0.0183, -0.0059, -0.0290],\n                     dtype=torch.float64)),\n             ('6.9.convpath.0.1.1.running_mean',\n              tensor([-1.2514,  0.0662, -0.3021, -0.1990,  1.2269, -0.8138, -0.3655,  0.0439,\n                      -0.8457, -0.0487, -0.5501,  0.0947, -0.4014,  0.1619,  0.5045, -0.6021,\n                      -0.8322, -0.6092,  0.9667, -0.4734,  0.2212, -0.5115, -1.0419,  0.2626,\n                      -0.0119, -0.1979,  0.4004,  0.5910, -0.6113, -0.0663,  0.5426,  0.2087,\n                       0.6633,  0.0207, -0.2110, -0.2268,  0.7308, -0.5353,  0.1103, -0.3382,\n                       0.5863,  1.0467,  0.2675,  0.6656,  0.1332, -0.1556, -0.1738, -0.1929,\n                       0.6005, -0.4710,  0.2127, -0.2831, -0.2715, -0.7200, -0.0334,  0.7627,\n                      -0.8695, -0.5102, -0.2038,  0.2374,  0.3683, -1.1049, -0.4220, -0.1263],\n                     dtype=torch.float64)),\n             ('6.9.convpath.0.1.1.running_var',\n              tensor([0.4951, 0.5551, 0.5161, 0.7929, 0.6730, 0.8803, 0.5287, 0.4668, 0.7212,\n                      0.4924, 0.8019, 0.7413, 1.0987, 0.7438, 0.4537, 0.8554, 0.6237, 0.6271,\n                      0.5643, 0.4603, 0.5157, 0.5985, 0.5596, 0.4932, 0.8332, 0.4350, 0.5210,\n                      0.6271, 0.5215, 0.7864, 0.7577, 0.4459, 0.5980, 0.7107, 0.4871, 0.4155,\n                      0.5383, 0.7093, 0.6683, 0.4401, 1.0233, 0.4873, 0.5053, 0.6209, 0.3728,\n                      0.4552, 0.5253, 0.4817, 0.6232, 0.6157, 0.7725, 0.5324, 0.7049, 0.5713,\n                      0.6358, 0.6494, 0.4572, 0.6735, 0.4575, 0.5501, 0.5756, 0.7872, 0.5334,\n                      0.9152], dtype=torch.float64)),\n             ('6.9.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.9.convpath.0.2.0.weight',\n              tensor([[[ 0.0893],\n                       [-0.0455],\n                       [-0.2674],\n                       ...,\n                       [ 0.1167],\n                       [-0.0836],\n                       [ 0.2465]],\n              \n                      [[-0.2033],\n                       [ 0.0706],\n                       [-0.1168],\n                       ...,\n                       [-0.0581],\n                       [ 0.1263],\n                       [ 0.0072]],\n              \n                      [[-0.0705],\n                       [-0.0357],\n                       [ 0.1340],\n                       ...,\n                       [ 0.1086],\n                       [ 0.1340],\n                       [ 0.0703]],\n              \n                      ...,\n              \n                      [[ 0.0073],\n                       [-0.0165],\n                       [-0.1484],\n                       ...,\n                       [ 0.0422],\n                       [-0.0156],\n                       [ 0.0365]],\n              \n                      [[-0.0883],\n                       [ 0.0145],\n                       [ 0.0252],\n                       ...,\n                       [-0.0438],\n                       [ 0.0520],\n                       [-0.0764]],\n              \n                      [[-0.1101],\n                       [-0.0844],\n                       [-0.0323],\n                       ...,\n                       [ 0.0104],\n                       [-0.0811],\n                       [-0.0769]]], dtype=torch.float64)),\n             ('6.9.convpath.0.2.1.weight',\n              tensor([ 3.8197e-02,  2.1366e-02,  2.4696e-02,  1.4561e-02, -6.2829e-03,\n                       2.0589e-02, -2.8215e-04,  6.6789e-03, -1.7766e-02, -1.9854e-02,\n                       3.2550e-03, -2.2405e-03,  8.2939e-03, -8.2569e-04, -8.4355e-04,\n                      -5.2118e-02,  5.4740e-03,  1.9636e-03, -9.1535e-03,  2.5672e-02,\n                      -5.5989e-03, -9.4478e-03,  1.5207e-03, -2.0959e-02,  1.0322e-02,\n                       1.7054e-04, -3.0756e-03, -1.1003e-02,  1.6626e-03,  1.2533e-02,\n                       4.0056e-02,  1.5763e-02, -1.0410e-02,  1.4234e-02, -2.7693e-02,\n                      -1.1018e-02, -2.2641e-02, -6.7160e-03, -1.2052e-02, -3.3082e-02,\n                       5.9991e-03, -8.8727e-03, -3.3118e-02, -3.2117e-03, -9.7912e-03,\n                       1.3251e-02,  2.3738e-02, -9.1586e-03,  2.3567e-03,  6.8963e-03,\n                       1.5196e-03,  3.2188e-02, -1.8743e-05,  1.8416e-02, -2.1405e-02,\n                       5.7661e-03, -4.9039e-03,  1.9656e-02,  3.9762e-03, -1.1368e-02,\n                       1.2981e-02, -1.8732e-03,  2.0916e-02, -6.4356e-03, -2.7787e-02,\n                      -8.9875e-03,  1.4702e-02,  2.1318e-02, -2.4436e-02,  1.4646e-02,\n                       5.4845e-03,  5.2684e-03,  1.6982e-02, -3.8205e-03,  2.0069e-02,\n                       1.4001e-02,  2.0501e-02,  1.8135e-02,  2.7525e-02,  1.4677e-02,\n                      -7.2911e-03, -6.9844e-03, -8.7730e-03, -4.4011e-03, -1.8420e-02,\n                      -2.7725e-02,  2.7036e-02,  4.7727e-04, -1.3584e-03, -2.1909e-02,\n                      -2.3168e-03, -1.7575e-03,  1.6877e-02, -2.5837e-03,  2.1309e-02,\n                       7.9868e-04,  4.7593e-03,  5.0303e-03,  1.9330e-02, -1.0573e-02,\n                       2.8600e-04,  1.3909e-02,  2.4698e-02, -6.4631e-03, -8.4863e-03,\n                       1.5554e-02,  6.1310e-03, -1.3418e-02,  1.1456e-02, -1.2268e-02,\n                      -1.1725e-02, -7.2832e-04, -1.7940e-02, -1.4059e-02,  1.5236e-02,\n                       1.4531e-02, -7.3030e-03,  1.3628e-02, -5.6375e-03,  5.0602e-03,\n                      -2.0684e-02, -1.5507e-03,  4.7530e-03, -8.6688e-03, -1.0095e-02,\n                       7.6345e-03,  2.4969e-03, -2.5301e-02,  1.5391e-02,  6.2170e-03,\n                       1.1334e-02,  8.4427e-04, -1.2570e-02,  1.1552e-02, -9.7551e-03,\n                       4.4813e-03,  4.0318e-02, -1.6385e-02,  1.3779e-02,  1.4663e-02,\n                      -5.1428e-04,  1.6617e-02, -9.6113e-03, -9.9553e-03,  1.1362e-02,\n                      -1.9588e-02, -6.3355e-03,  7.2053e-03, -2.0011e-02, -8.3248e-03,\n                      -2.6182e-02, -1.9902e-04, -1.1457e-02,  1.7781e-02, -2.1089e-03,\n                       1.3304e-02, -3.0273e-03, -2.2991e-02,  2.0670e-02, -1.5204e-02,\n                      -2.1731e-02,  8.4588e-03,  2.7016e-03,  5.1305e-04,  1.8516e-02,\n                       1.1654e-02, -6.0683e-03,  2.1588e-02,  1.3673e-02,  2.2667e-02,\n                      -5.0496e-03,  1.3705e-02, -2.6801e-02,  7.4720e-03,  1.9639e-03,\n                       1.5954e-02, -2.0386e-02,  4.7803e-02,  7.6350e-04,  9.5020e-03,\n                       3.2695e-03,  1.4055e-04,  4.9750e-03,  1.9632e-02,  2.1211e-02,\n                      -8.1133e-03,  7.4683e-03, -4.1438e-03,  8.7901e-03,  5.2431e-03,\n                      -2.1540e-03, -4.5825e-03, -2.8451e-02, -2.8668e-02,  2.0430e-02,\n                       2.1461e-02, -9.6153e-03, -2.3711e-02,  5.8847e-03, -6.9132e-03,\n                       5.2752e-03, -3.0356e-02,  1.9696e-02, -9.9085e-03,  1.4255e-02,\n                       5.4290e-03,  2.0562e-02,  1.9429e-02, -6.4988e-03,  1.4216e-02,\n                      -6.9774e-03, -1.3568e-02, -1.1343e-02, -1.4171e-02,  1.5999e-02,\n                       7.3574e-03, -6.1076e-03,  2.1894e-02,  6.7295e-03, -2.2721e-04,\n                      -1.0427e-02, -5.6908e-03,  6.9117e-03,  1.8961e-02,  4.8462e-04,\n                       7.7365e-04, -1.3075e-04,  1.1878e-02,  3.8245e-03, -1.2529e-02,\n                       4.3224e-03,  1.1561e-02,  4.1882e-02,  1.5538e-02,  1.4056e-02,\n                      -1.7800e-02, -1.2519e-02, -2.3626e-02, -1.4380e-02,  1.2683e-02,\n                      -1.3807e-02,  1.9819e-02, -2.5073e-02, -4.2987e-02, -1.3713e-02,\n                      -9.6242e-03,  1.1155e-02, -2.1724e-02,  1.1837e-02, -4.4349e-03,\n                      -2.6107e-02,  2.7170e-02,  9.4104e-03, -1.3384e-03,  2.2749e-02,\n                       2.3418e-03], dtype=torch.float64)),\n             ('6.9.convpath.0.2.1.bias',\n              tensor([-6.4846e-04,  3.4670e-03,  1.3560e-02,  1.3903e-02,  1.0323e-03,\n                       1.3111e-02,  7.6078e-03, -7.1756e-04,  1.2451e-02,  1.4780e-02,\n                       1.3135e-02, -7.5430e-03,  8.1079e-03, -3.5415e-03,  1.1186e-02,\n                       4.0195e-03,  2.2127e-02, -3.6439e-03,  1.0206e-02, -2.1828e-03,\n                      -3.5464e-03,  1.6337e-03,  2.8847e-03,  5.6239e-03,  2.1583e-03,\n                      -1.6947e-02,  1.1932e-03,  6.8007e-03, -1.7143e-03, -3.1892e-03,\n                       3.3445e-03,  7.4800e-03, -5.6142e-03,  1.8470e-02,  8.8573e-03,\n                       1.6069e-02,  3.8610e-03,  2.0562e-02,  5.7403e-03,  1.5740e-02,\n                      -3.9430e-04,  2.0469e-02, -7.2633e-03,  7.7431e-05,  3.5858e-03,\n                      -9.0705e-03,  3.0999e-03,  2.8893e-03, -1.1129e-02,  9.1805e-03,\n                       1.0326e-02,  7.3620e-03,  7.6639e-03,  1.0123e-02,  4.9705e-03,\n                       2.0092e-02,  8.8805e-03,  1.8766e-03,  1.2297e-02,  8.3502e-04,\n                      -2.5419e-03,  9.3884e-04,  4.7181e-03,  8.7003e-03, -5.0107e-03,\n                       6.2617e-03, -1.1034e-02,  1.5183e-02,  2.7905e-03, -1.3341e-02,\n                       4.4583e-03,  2.7764e-03,  1.4734e-03, -6.8418e-03,  1.4786e-02,\n                       2.2719e-03,  4.4943e-03,  6.9237e-03,  4.1080e-03,  1.8831e-03,\n                       7.8287e-03, -6.3343e-03,  1.0328e-02,  4.7032e-03, -3.8044e-03,\n                       1.9094e-02, -8.4135e-04, -1.9934e-03,  1.7345e-02,  1.4599e-03,\n                       9.6969e-04,  8.9588e-03,  1.0819e-02, -8.3166e-04,  1.0169e-02,\n                      -1.5017e-02,  1.0828e-02,  1.9028e-03,  8.1641e-03, -1.2069e-03,\n                       1.9103e-02,  1.3743e-02,  4.5405e-03,  8.1596e-03,  2.8097e-03,\n                      -1.6397e-03, -1.5450e-03,  2.6037e-03,  5.3576e-03,  8.4291e-03,\n                      -1.0479e-02, -7.0350e-03,  5.6558e-03,  1.8411e-02,  1.1956e-02,\n                       5.3564e-03,  8.9365e-03,  2.3824e-03,  5.4456e-03, -1.6324e-02,\n                       1.5570e-03,  8.4389e-03, -7.0661e-04, -1.8132e-03, -5.9987e-03,\n                       9.4284e-03,  1.5256e-02,  6.3889e-03,  3.3287e-03,  1.7133e-02,\n                       1.0354e-02,  1.4330e-02,  1.3853e-02,  1.1783e-02,  1.6198e-02,\n                      -8.6506e-03,  1.5983e-02,  7.1688e-03,  1.3772e-02,  4.4455e-03,\n                       1.6668e-02, -5.3644e-03,  1.7795e-02,  4.4281e-03, -9.2293e-03,\n                       1.2964e-02, -6.2488e-04, -2.8342e-04,  1.2235e-02,  1.0201e-02,\n                       5.9463e-03,  1.2033e-02,  1.2914e-02,  1.2968e-02,  1.2481e-02,\n                       9.6396e-03,  3.2761e-04,  4.3209e-03, -1.3388e-03, -1.2766e-02,\n                       4.3126e-03, -3.1320e-03,  2.6008e-05,  9.4736e-03,  1.4805e-02,\n                      -2.8470e-03, -1.1368e-02,  1.2965e-02, -1.1121e-03,  1.8382e-02,\n                       4.5141e-03,  1.8434e-03,  1.2704e-02,  1.1463e-02, -1.3834e-02,\n                      -8.7677e-04, -7.2587e-04,  1.1072e-02,  2.4293e-03,  4.0718e-03,\n                      -5.8031e-03,  1.0492e-02, -6.6294e-03, -8.9262e-03,  1.9337e-02,\n                       7.2007e-03,  1.4884e-02,  9.1093e-03,  3.1240e-03,  7.0490e-03,\n                       6.8572e-03,  2.2262e-03,  1.0290e-02, -6.0214e-03,  4.4594e-03,\n                       5.3444e-03, -5.1600e-03,  1.0863e-02,  7.8465e-03,  1.6185e-02,\n                       1.2771e-03,  2.3475e-02,  2.1071e-02,  2.1209e-02,  2.6302e-03,\n                      -2.8398e-03,  8.8677e-03, -3.9001e-03,  6.8875e-03,  1.3522e-02,\n                       6.1550e-03,  1.1425e-02,  1.4341e-02,  7.3221e-03,  8.2503e-03,\n                      -3.2638e-04,  2.2783e-03, -1.3564e-03,  2.9843e-03, -1.4735e-03,\n                      -1.3981e-02,  1.2161e-03,  4.0684e-03,  1.8059e-02, -4.0838e-03,\n                       2.8558e-03, -3.7181e-03, -2.7040e-04, -1.4946e-02,  1.4309e-02,\n                       5.7225e-03, -2.0625e-03,  7.8892e-03,  5.3784e-03,  2.4442e-03,\n                       7.9535e-03,  6.6799e-03, -4.6101e-03,  1.2040e-02,  4.3402e-03,\n                       1.1283e-03,  4.2626e-04,  2.4149e-03,  8.8295e-03,  4.7386e-03,\n                       1.3292e-02,  4.6131e-03,  7.5871e-03, -8.0850e-04, -9.1783e-03,\n                       1.7131e-02,  2.1774e-02,  2.0271e-02,  1.4859e-02,  9.6975e-03,\n                       1.2369e-03], dtype=torch.float64)),\n             ('6.9.convpath.0.2.1.running_mean',\n              tensor([-0.1147, -0.4197,  0.1856,  0.1600,  0.2017, -0.3548, -0.2849, -0.2420,\n                       0.1832, -0.7393, -0.0484,  0.0668, -0.3063, -0.1696,  0.4185,  1.4938,\n                       0.0752, -0.1952,  0.0146, -0.8348, -0.1308,  0.6076,  0.2876,  0.3286,\n                      -0.4414, -0.2555, -0.3208, -0.1436, -0.2482,  0.3056, -0.0332, -0.3530,\n                      -0.1061, -0.1616, -0.0986, -0.1400,  0.1554, -0.2614, -0.5994, -0.0546,\n                      -0.4695, -0.0484,  0.0255,  0.2898,  0.2685, -0.6784,  0.2800, -0.0976,\n                      -0.3457,  0.2126,  0.0305,  0.7658,  0.2623, -0.0713, -0.8933, -0.4809,\n                      -0.0042,  0.3441, -0.3661, -0.2123,  0.1557,  0.4125, -0.1666,  0.1306,\n                       0.5786,  0.1405, -0.0231,  0.0765, -0.0091, -0.1122,  0.2508, -0.1710,\n                      -0.1152, -0.0963, -0.4225,  0.5683,  0.2269,  0.2038,  0.7734, -0.3499,\n                       0.0233,  0.1448, -0.2664,  0.2740,  0.3847, -0.1142, -0.3360,  0.0627,\n                      -0.1295, -0.4552,  0.0774, -0.0260,  0.2801,  0.1809,  0.1028,  0.1019,\n                       0.0068, -0.3263,  0.0792, -0.0847,  0.2248,  0.5321,  0.2797,  0.1087,\n                       0.1056,  0.1422, -0.0532, -0.3065, -0.5281, -0.4906,  0.3444, -0.4464,\n                       0.5022,  0.2156,  0.4486, -0.5130,  0.2573,  0.5147, -0.2340,  0.1568,\n                      -0.2512, -0.4811, -0.3822,  0.7150,  0.0380, -0.0926,  0.1554, -0.2932,\n                      -0.0347, -0.0567,  0.2579,  0.2368, -0.3463, -0.0242,  0.2719,  0.2137,\n                       0.1343, -0.0277,  0.6522,  0.4034, -0.2241, -0.3542, -0.0213,  0.0394,\n                       0.1192, -0.0051, -0.2208,  0.9563,  0.2515, -0.2958,  0.3882,  0.2171,\n                      -0.2739, -0.4189,  0.3423,  0.6098, -0.1191,  0.3831,  0.1518, -0.5003,\n                       0.0916, -0.2091,  0.1989,  0.2209, -0.0519,  0.0627, -0.0144,  0.2527,\n                      -0.5587, -0.2902, -0.1265,  0.2108, -0.0807,  0.2127,  0.2084, -0.0287,\n                       0.2230, -0.2488,  0.0266,  0.0351,  0.8118, -0.0022,  0.3518,  0.0087,\n                       0.3701, -0.1938,  0.4315, -0.3034, -0.1270, -0.1790, -0.5028,  0.7335,\n                      -0.2608, -0.1508,  0.1336,  0.0768, -0.3157, -0.2619, -0.6927, -0.3791,\n                      -0.0610,  0.1268, -0.0597,  0.3434,  0.2909, -0.3056,  0.5169, -0.1156,\n                      -0.0429, -0.4485,  0.1017,  0.0873, -0.4607,  0.0906,  0.5384, -0.3130,\n                      -0.3855,  0.0149, -0.3241,  0.5847, -0.2137, -0.1886,  0.0791,  0.5524,\n                      -0.1036, -0.3656, -0.3034,  0.6169, -0.0711, -0.1529, -0.2413, -0.3578,\n                       0.0816, -0.1168, -0.4330, -0.2819,  0.0120, -0.3821, -0.2923,  0.5618,\n                      -0.1914,  0.3470,  0.3961,  0.2907, -0.0484,  0.0759,  0.2851,  0.1941,\n                       0.1031, -0.0488,  0.2944, -0.2256, -0.0739,  0.0652, -0.4319, -0.0753],\n                     dtype=torch.float64)),\n             ('6.9.convpath.0.2.1.running_var',\n              tensor([0.4803, 0.5478, 0.4625, 0.3673, 0.1948, 0.2871, 0.1768, 0.3114, 0.3147,\n                      0.8863, 0.0980, 0.4286, 0.1232, 0.1722, 0.2081, 0.5771, 0.2073, 0.2113,\n                      0.1340, 0.4499, 0.2137, 0.4084, 0.2078, 0.3653, 0.4133, 0.1126, 0.2002,\n                      0.2677, 0.1279, 0.5691, 0.2992, 0.6103, 0.0756, 0.4039, 0.2903, 0.3548,\n                      0.3748, 0.2422, 0.5304, 0.5673, 0.5298, 0.1313, 0.3278, 0.3795, 0.3627,\n                      0.3433, 0.2928, 0.1844, 0.3451, 0.2010, 0.2011, 0.5306, 0.3434, 0.3450,\n                      0.4072, 0.1961, 0.4315, 0.5280, 0.4315, 0.4961, 0.1577, 0.1158, 0.3670,\n                      0.2104, 0.4688, 0.1069, 0.4705, 0.4134, 0.4165, 0.4189, 0.4089, 0.2667,\n                      0.1970, 0.4285, 0.5902, 0.3144, 0.6138, 0.2077, 0.4767, 0.1663, 0.1981,\n                      0.3499, 0.1911, 0.3684, 0.4142, 0.4183, 0.4339, 0.2023, 0.3758, 0.3068,\n                      0.3147, 0.1258, 0.2441, 0.1655, 0.3332, 0.2130, 0.4478, 0.3991, 0.4338,\n                      0.1957, 0.3035, 0.4672, 0.2368, 0.2352, 0.1689, 0.2376, 0.1583, 0.5390,\n                      0.2454, 0.2871, 0.1673, 0.4166, 0.4412, 0.3265, 0.4863, 0.4778, 0.4208,\n                      0.3350, 0.2198, 0.2302, 0.2356, 0.3902, 0.2601, 0.2968, 0.3177, 0.4056,\n                      0.1246, 0.2656, 0.2487, 0.4658, 0.2180, 0.2710, 0.3628, 0.1668, 0.2449,\n                      0.0676, 0.4741, 0.3067, 0.4366, 0.2359, 0.1120, 0.3539, 0.3944, 0.2258,\n                      0.3504, 0.4846, 0.1943, 0.4633, 0.1682, 0.4215, 0.4680, 0.1953, 0.2594,\n                      0.4176, 0.2188, 0.3408, 0.2014, 0.4109, 0.3926, 0.3819, 0.2703, 0.2993,\n                      0.1883, 0.1662, 0.4236, 0.3287, 0.4012, 0.3746, 0.3899, 0.4601, 0.4296,\n                      0.2782, 0.5423, 0.4095, 0.5457, 1.0451, 0.4015, 0.5590, 0.1655, 0.2209,\n                      0.4795, 0.1139, 0.2623, 0.3971, 0.3237, 0.5345, 0.3264, 0.1880, 0.3865,\n                      0.1408, 0.1883, 0.3963, 0.3412, 0.3708, 0.3337, 0.6031, 0.3492, 0.4676,\n                      0.2792, 0.4250, 0.1088, 0.5088, 0.4109, 0.2139, 0.2385, 0.2611, 0.2457,\n                      0.2573, 0.1701, 0.4551, 0.0689, 0.1759, 0.3959, 0.3574, 0.3201, 0.3698,\n                      0.5916, 0.3713, 0.3145, 0.3787, 0.3560, 0.1390, 0.1719, 0.4745, 0.3214,\n                      0.1735, 0.2497, 0.3693, 0.5153, 0.5044, 0.1635, 0.2772, 0.3693, 0.4279,\n                      0.4518, 0.7858, 0.1138, 0.4074, 0.5333, 0.3842, 0.4550, 0.3329, 0.6317,\n                      0.3377, 0.3532, 0.1406, 0.3594, 0.4929, 0.2524, 0.5136, 0.5394, 0.4202,\n                      0.2679, 0.2038, 0.2785, 0.3282], dtype=torch.float64)),\n             ('6.9.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.10.convs.0.0.weight',\n              tensor([[[ 5.3001e-02],\n                       [ 5.1272e-02],\n                       [-1.8943e-02],\n                       ...,\n                       [ 2.4716e-02],\n                       [ 2.8205e-02],\n                       [ 1.3569e-01]],\n              \n                      [[ 5.7943e-02],\n                       [-6.3280e-02],\n                       [ 1.6232e-02],\n                       ...,\n                       [ 5.2459e-02],\n                       [-6.3835e-02],\n                       [ 4.8409e-02]],\n              \n                      [[ 3.2850e-02],\n                       [-1.7670e-01],\n                       [ 2.1905e-02],\n                       ...,\n                       [ 4.4218e-02],\n                       [ 6.3894e-02],\n                       [-2.0578e-02]],\n              \n                      ...,\n              \n                      [[ 7.2022e-02],\n                       [ 1.4206e-02],\n                       [-5.0822e-02],\n                       ...,\n                       [ 3.2147e-02],\n                       [-1.8324e-02],\n                       [-1.6928e-02]],\n              \n                      [[ 8.7296e-02],\n                       [-4.3677e-02],\n                       [ 3.3087e-02],\n                       ...,\n                       [-8.9813e-02],\n                       [ 6.3145e-02],\n                       [-4.2425e-02]],\n              \n                      [[ 2.0281e-03],\n                       [-3.6634e-05],\n                       [ 1.7222e-01],\n                       ...,\n                       [-1.5494e-02],\n                       [ 8.0183e-02],\n                       [ 1.3786e-01]]], dtype=torch.float64)),\n             ('6.10.convs.0.1.weight',\n              tensor([0.9761, 0.9647, 0.9646, 0.9977, 1.0027, 0.9771, 0.9800, 0.9729, 0.9764,\n                      0.9411, 0.9793, 0.9648, 0.9732, 0.9549, 0.9648, 0.9778, 0.9948, 0.9920,\n                      0.9640, 0.9602, 0.9723, 0.9681, 0.9584, 1.0106, 0.9796, 0.9547, 1.0054,\n                      0.9699, 0.9842, 0.9972, 0.9735, 0.9792, 0.9563, 0.9732, 0.9663, 0.9644,\n                      0.9616, 0.9730, 0.9675, 0.9625, 0.9969, 0.9961, 0.9765, 0.9802, 0.9680,\n                      0.9787, 0.9896, 0.9960, 0.9961, 0.9659, 0.9677, 0.9514, 0.9971, 0.9549,\n                      0.9693, 0.9544, 0.9718, 0.9691, 0.9759, 0.9560, 0.9648, 0.9811, 0.9814,\n                      0.9558], dtype=torch.float64)),\n             ('6.10.convs.0.1.bias',\n              tensor([-0.0062, -0.0043, -0.0192,  0.0215,  0.0105,  0.0115,  0.0042, -0.0032,\n                       0.0220, -0.0178, -0.0044,  0.0153,  0.0239, -0.0038, -0.0082,  0.0243,\n                       0.0202,  0.0194,  0.0146, -0.0048,  0.0061, -0.0081, -0.0051,  0.0247,\n                       0.0074,  0.0132,  0.0277,  0.0038, -0.0004,  0.0364,  0.0012, -0.0044,\n                      -0.0061,  0.0169, -0.0103, -0.0108, -0.0137, -0.0135,  0.0239, -0.0124,\n                       0.0185,  0.0322,  0.0052,  0.0059,  0.0160,  0.0073,  0.0013,  0.0045,\n                       0.0278, -0.0109, -0.0147, -0.0044,  0.0156, -0.0091, -0.0028, -0.0025,\n                       0.0140,  0.0015, -0.0070, -0.0055,  0.0080,  0.0134, -0.0120, -0.0090],\n                     dtype=torch.float64)),\n             ('6.10.convs.0.1.running_mean',\n              tensor([ 0.0851,  0.1362,  1.1821, -0.1744, -0.0653, -0.4568, -0.1044,  1.5376,\n                      -0.6681,  1.5421,  0.2019,  0.6653, -1.2714, -0.1918, -0.2303, -0.1038,\n                      -0.6344, -0.6344,  0.7560, -0.8433,  0.2658,  0.5114, -0.2615,  0.1207,\n                       0.2419, -0.2890, -0.6004, -0.1606, -0.5961,  0.0796,  0.4721,  0.5530,\n                       0.2738, -0.4581,  0.2339,  0.5347, -0.0533, -0.6945,  0.1588, -0.5252,\n                      -0.6424, -0.2035,  0.0025, -0.1813, -0.2180, -0.0381, -0.5110,  0.0414,\n                      -0.8994, -0.0787,  0.5291,  0.0046, -0.4013, -0.3067,  0.4259, -0.2342,\n                       0.1026,  0.3998, -0.9588, -0.0718, -1.0658, -0.6128,  1.3851,  0.5635],\n                     dtype=torch.float64)),\n             ('6.10.convs.0.1.running_var',\n              tensor([0.2075, 0.1780, 0.3544, 0.2462, 0.1225, 0.1398, 0.1361, 1.5115, 0.1946,\n                      1.6075, 0.2783, 0.2215, 0.4317, 0.2211, 0.3148, 0.2696, 0.1128, 0.2005,\n                      0.2412, 0.4072, 0.1412, 0.8247, 0.5862, 0.1213, 0.2463, 0.4062, 0.1269,\n                      0.2243, 0.1076, 0.2449, 0.2198, 0.2023, 0.5002, 0.2317, 0.3742, 0.3920,\n                      0.2172, 0.1581, 0.0851, 0.1756, 0.1484, 0.1947, 0.1141, 0.3521, 0.2023,\n                      0.2105, 0.1509, 0.1691, 0.0952, 0.1439, 0.2637, 0.6856, 0.1059, 0.1499,\n                      0.2030, 0.0992, 0.2251, 0.2923, 0.4499, 0.2593, 0.4148, 0.2528, 0.5615,\n                      0.6002], dtype=torch.float64)),\n             ('6.10.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.10.convs.1.0.weight',\n              tensor([[[ 0.0826,  0.0750,  0.0228,  0.0698,  0.0649],\n                       [ 0.0153, -0.0929,  0.0216,  0.0377,  0.1532],\n                       [-0.0722, -0.0893, -0.1422,  0.0668, -0.1166],\n                       ...,\n                       [-0.1447, -0.0873,  0.0406,  0.0233,  0.0740],\n                       [ 0.0137, -0.0728,  0.0168, -0.0616, -0.0075],\n                       [-0.0269, -0.0355,  0.0754, -0.1133, -0.0195]],\n              \n                      [[-0.0596, -0.1007,  0.0120, -0.0124,  0.0380],\n                       [-0.0967,  0.0928,  0.0795,  0.0528,  0.0194],\n                       [ 0.0194, -0.0077, -0.0564, -0.0904, -0.1240],\n                       ...,\n                       [-0.0433, -0.0591, -0.1491,  0.0217,  0.0718],\n                       [-0.0213, -0.1208, -0.0256, -0.0895,  0.0479],\n                       [ 0.0402,  0.1456,  0.0895,  0.0109,  0.1030]],\n              \n                      [[ 0.0733, -0.0582, -0.0385,  0.0029,  0.0186],\n                       [ 0.0231,  0.0651,  0.0639,  0.1665,  0.0704],\n                       [ 0.0948, -0.0609, -0.1184, -0.0489,  0.0720],\n                       ...,\n                       [ 0.0088, -0.0404,  0.0280, -0.0296, -0.1209],\n                       [-0.0740,  0.0258, -0.0802, -0.0934,  0.0126],\n                       [-0.0336,  0.0618, -0.0700, -0.0925,  0.0064]],\n              \n                      ...,\n              \n                      [[-0.0528,  0.0317,  0.0551,  0.0407, -0.1539],\n                       [-0.0543,  0.0325,  0.0744,  0.0389,  0.1441],\n                       [-0.1047, -0.0849,  0.0807, -0.0975, -0.0493],\n                       ...,\n                       [ 0.1104, -0.0267, -0.0580, -0.0039, -0.1336],\n                       [ 0.0614,  0.0425,  0.0111, -0.0265,  0.1284],\n                       [ 0.0433,  0.0160, -0.0872,  0.1225, -0.0439]],\n              \n                      [[-0.0261, -0.0056, -0.0654, -0.0859,  0.0652],\n                       [-0.0291,  0.0285,  0.0541,  0.0416,  0.0197],\n                       [-0.1106, -0.2368, -0.0391,  0.0458,  0.1310],\n                       ...,\n                       [-0.1518,  0.0199, -0.1015, -0.0462,  0.0056],\n                       [ 0.0215,  0.0452,  0.0252,  0.0221, -0.0094],\n                       [-0.0929,  0.0013, -0.1021, -0.0710, -0.0472]],\n              \n                      [[ 0.0155,  0.0565,  0.0123,  0.0180, -0.1621],\n                       [ 0.0997,  0.0388, -0.0266, -0.0228,  0.0018],\n                       [-0.1008, -0.1550, -0.1184, -0.2444, -0.0671],\n                       ...,\n                       [ 0.0992, -0.1436,  0.0875, -0.0306,  0.1076],\n                       [-0.0567,  0.0806, -0.0124,  0.0722,  0.0503],\n                       [ 0.0919, -0.0561,  0.0182,  0.0457,  0.0400]]], dtype=torch.float64)),\n             ('6.10.convs.1.1.weight',\n              tensor([0.9843, 0.9771, 0.9389, 0.9296, 0.9613, 0.9532, 0.9630, 0.9553, 1.0097,\n                      0.9687, 0.9531, 0.9632, 0.9478, 0.9671, 0.9602, 0.9635, 0.9475, 0.9510,\n                      0.9420, 0.9615, 0.9554, 0.9806, 0.9963, 0.9300, 0.9560, 0.9829, 0.9949,\n                      0.9794, 0.9807, 0.9653, 0.9616, 0.9386, 0.9906, 0.9458, 0.9425, 0.9558,\n                      0.9591, 0.9932, 1.0054, 0.9593, 0.9550, 0.9495, 0.9477, 0.9575, 0.9782,\n                      0.9635, 0.9846, 0.9404, 0.9947, 0.9624, 0.9255, 0.9537, 0.9385, 0.9304,\n                      0.9719, 0.9792, 1.0084, 0.9497, 0.9683, 0.9727, 0.9633, 0.9756, 0.9931,\n                      0.9784], dtype=torch.float64)),\n             ('6.10.convs.1.1.bias',\n              tensor([ 0.0157, -0.0278, -0.0068, -0.0094, -0.0125, -0.0033, -0.0201, -0.0042,\n                      -0.0033, -0.0019,  0.0059, -0.0271, -0.0027, -0.0010, -0.0165, -0.0320,\n                      -0.0256, -0.0118, -0.0092,  0.0082, -0.0143,  0.0017,  0.0144, -0.0165,\n                      -0.0242, -0.0087,  0.0246, -0.0076,  0.0051, -0.0104, -0.0024, -0.0241,\n                       0.0030, -0.0071, -0.0205,  0.0134, -0.0302,  0.0043,  0.0242, -0.0137,\n                      -0.0159, -0.0104, -0.0250, -0.0340,  0.0002,  0.0073,  0.0042, -0.0267,\n                      -0.0129, -0.0010, -0.0269, -0.0039, -0.0198, -0.0181, -0.0052,  0.0024,\n                      -0.0061, -0.0087, -0.0110, -0.0023, -0.0061,  0.0011, -0.0065,  0.0144],\n                     dtype=torch.float64)),\n             ('6.10.convs.1.1.running_mean',\n              tensor([ 0.0187,  0.2259,  0.2150, -1.0941,  0.6182, -0.0773, -0.4612, -0.2403,\n                      -0.3761, -0.4489, -0.4950,  1.0450, -0.7571, -0.3510,  0.3584, -0.2392,\n                       0.3453,  0.3259,  0.5222, -0.4038, -0.8119, -0.7961,  0.4897, -1.0529,\n                      -0.4908,  0.3785, -0.0859, -0.5807, -0.7508, -0.5342, -0.4863,  0.3372,\n                       0.6826,  0.2338, -0.6086, -0.1205,  0.0786,  0.2197,  0.7343,  0.3162,\n                      -0.0494, -0.0666, -0.8932,  0.6783,  0.2522, -0.2925, -0.0483, -0.6740,\n                      -0.4905, -0.1910, -0.3267, -0.5483,  0.2979, -0.1600,  0.0428, -0.1494,\n                      -0.4107, -1.1245,  0.3102,  0.3486, -0.1278, -0.1558, -0.3634,  0.1078],\n                     dtype=torch.float64)),\n             ('6.10.convs.1.1.running_var',\n              tensor([0.5527, 0.3774, 0.7526, 0.8442, 0.7330, 0.5664, 0.7094, 0.5574, 0.5508,\n                      0.6127, 0.7145, 0.9200, 0.5266, 0.5878, 0.5787, 0.6866, 0.7206, 0.6839,\n                      2.1087, 0.5224, 0.7808, 0.8901, 0.6228, 0.7270, 0.6302, 0.5375, 0.5395,\n                      0.4998, 0.7418, 0.6076, 0.6234, 0.4750, 0.4875, 0.7924, 0.6141, 0.7703,\n                      0.5388, 0.4119, 0.4038, 0.5959, 0.5061, 0.6636, 0.5149, 0.8990, 0.4423,\n                      0.6233, 0.3774, 0.4376, 0.4759, 0.6566, 0.6653, 0.4274, 0.9510, 0.6285,\n                      0.6155, 0.4104, 0.4113, 0.6362, 0.9603, 0.4578, 0.4799, 0.3548, 0.5579,\n                      0.5769], dtype=torch.float64)),\n             ('6.10.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.10.convs.2.0.weight',\n              tensor([[[ 0.2122],\n                       [ 0.0268],\n                       [ 0.0150],\n                       ...,\n                       [ 0.0067],\n                       [-0.1124],\n                       [-0.2242]],\n              \n                      [[-0.1059],\n                       [ 0.0927],\n                       [-0.0035],\n                       ...,\n                       [-0.0038],\n                       [ 0.0482],\n                       [-0.3961]],\n              \n                      [[ 0.0258],\n                       [-0.0312],\n                       [-0.0507],\n                       ...,\n                       [ 0.0615],\n                       [ 0.0151],\n                       [-0.1351]],\n              \n                      ...,\n              \n                      [[ 0.2670],\n                       [-0.1374],\n                       [ 0.0363],\n                       ...,\n                       [-0.1588],\n                       [ 0.0924],\n                       [-0.0818]],\n              \n                      [[ 0.2567],\n                       [ 0.2478],\n                       [ 0.0953],\n                       ...,\n                       [-0.1857],\n                       [-0.2397],\n                       [-0.1418]],\n              \n                      [[ 0.0365],\n                       [ 0.0354],\n                       [ 0.1555],\n                       ...,\n                       [-0.0695],\n                       [ 0.0791],\n                       [-0.1659]]], dtype=torch.float64)),\n             ('6.10.convs.2.1.weight',\n              tensor([ 3.4072e-03, -1.2247e-02, -2.4161e-02, -2.7273e-04, -9.3331e-03,\n                       1.0570e-02,  1.4263e-02, -3.9445e-02, -7.2664e-03,  2.6008e-02,\n                      -2.1712e-02, -7.5450e-03,  2.0206e-02,  2.8890e-05,  2.0473e-02,\n                      -3.6217e-02, -3.1956e-02, -2.4624e-02,  3.3658e-03, -2.1315e-02,\n                       2.6538e-02,  1.5955e-02, -6.5937e-03, -2.1108e-02, -1.0326e-02,\n                      -2.0038e-02, -2.0217e-02, -7.3655e-03, -7.6255e-03, -8.6981e-03,\n                       1.8087e-02, -8.9053e-03, -1.3330e-02, -2.2761e-02, -1.3948e-02,\n                       2.0025e-02, -7.0666e-04, -2.4147e-02, -1.6121e-02, -1.5117e-02,\n                       1.0130e-02, -3.3159e-02,  1.8177e-02, -4.0222e-03,  2.6264e-02,\n                      -1.6140e-02, -6.5510e-03,  9.9583e-04, -4.0450e-03, -8.8346e-03,\n                       9.5506e-03, -5.2296e-03,  3.6607e-03,  1.4062e-02, -7.7209e-04,\n                      -1.4152e-02, -2.7755e-02,  8.0897e-03, -1.4775e-02, -1.0350e-02,\n                      -1.0600e-02,  8.8873e-03, -1.1732e-03,  7.1229e-03, -2.3113e-02,\n                      -3.1991e-02,  1.2511e-02,  1.8373e-02,  5.9849e-03, -1.0396e-02,\n                       7.9709e-03, -2.6618e-02, -4.4113e-03,  2.1236e-02,  1.3796e-02,\n                      -3.2869e-02,  6.6936e-03,  6.8765e-04,  1.4736e-02, -1.0892e-02,\n                      -1.1828e-02, -2.5184e-02, -1.4756e-02, -7.2027e-03,  9.2075e-03,\n                      -7.2813e-03,  5.3349e-03, -2.4958e-02, -1.2517e-02, -2.1349e-02,\n                       2.5620e-03, -6.9599e-05, -3.3621e-02,  8.3162e-03,  2.2684e-02,\n                       1.2405e-02,  3.3170e-03, -1.0054e-02,  1.6713e-04,  2.8225e-02,\n                       2.7370e-02, -8.6707e-03, -2.9238e-03,  1.2424e-02, -2.0158e-02,\n                      -2.8109e-02,  9.6405e-03,  8.8105e-03, -1.6848e-02,  2.3961e-02,\n                      -1.8228e-02,  9.2832e-03,  1.3457e-02,  3.6695e-02, -4.6360e-03,\n                      -1.4240e-02,  6.7069e-04, -3.4919e-02,  2.0982e-02,  2.6532e-04,\n                       3.9353e-03, -1.1445e-02, -2.8107e-03, -5.8135e-03, -2.9242e-02,\n                      -1.0877e-02,  1.9695e-02, -5.4900e-03, -7.4701e-03, -2.6370e-02,\n                      -3.9218e-03,  2.7932e-02,  8.1563e-03,  1.2044e-02, -4.4135e-03,\n                      -1.8723e-02, -1.0345e-02,  1.9427e-03,  4.3735e-02, -2.2981e-02,\n                      -2.1402e-02,  2.6798e-02,  3.0212e-02,  1.9308e-02,  7.0345e-04,\n                      -2.2224e-02,  9.0207e-03,  3.2886e-02,  1.1560e-02, -2.1491e-02,\n                       8.6478e-04,  2.4280e-02, -1.3888e-02, -3.6991e-02, -1.5033e-02,\n                      -1.9430e-02,  6.0777e-03,  4.9210e-03, -1.6575e-02,  6.4252e-03,\n                       1.5046e-02,  2.5336e-02, -9.5295e-03,  2.9799e-02,  3.8882e-02,\n                       1.4259e-02,  1.0982e-02,  9.2096e-03, -4.9746e-02,  2.9889e-02,\n                      -1.6953e-02,  4.4672e-03, -3.4920e-02,  4.1083e-03, -3.3216e-02,\n                       4.0766e-04,  5.9614e-02, -1.8276e-03,  2.1305e-02, -2.1283e-02,\n                      -1.1979e-02,  2.6840e-02, -5.3218e-03, -1.6319e-02, -3.6670e-02,\n                       1.0133e-02, -1.0708e-02, -3.5065e-02,  9.7089e-04,  1.1724e-02,\n                       1.7143e-02, -2.2267e-02,  6.4238e-03,  2.6369e-02,  1.6521e-02,\n                       1.0338e-03,  2.0108e-02,  2.5012e-02,  6.3948e-03, -1.8919e-02,\n                       7.6865e-04,  4.3738e-02, -6.6710e-03,  1.9074e-02,  4.0113e-02,\n                       4.2010e-03,  8.4241e-03, -2.2260e-02,  5.6589e-03, -1.2826e-02,\n                       3.4103e-02,  2.9219e-02,  1.6980e-03,  2.5113e-02, -7.7743e-03,\n                      -1.1834e-02,  3.1183e-03, -2.9594e-02,  2.3550e-02,  2.0443e-02,\n                      -1.3179e-02, -1.9991e-02, -7.1188e-04, -9.6507e-03,  1.3069e-02,\n                       2.0176e-02,  1.9741e-04,  1.1626e-04,  1.1369e-03, -1.0526e-02,\n                       4.1153e-03,  1.0016e-02,  1.0788e-02, -2.6078e-02,  2.0431e-02,\n                       1.8057e-02, -2.3363e-02, -6.2282e-03, -1.8878e-02, -1.2228e-02,\n                       2.3205e-02, -2.6446e-02, -1.3008e-02,  4.6080e-03,  1.8209e-02,\n                      -8.3547e-03,  1.7536e-02,  1.6987e-02, -5.0215e-03, -2.9718e-02,\n                       7.6276e-03, -5.4648e-03,  1.0720e-02, -2.5892e-02, -5.9801e-03,\n                      -3.2465e-03], dtype=torch.float64)),\n             ('6.10.convs.2.1.bias',\n              tensor([-2.4520e-03,  9.3828e-03,  1.1827e-02,  1.4305e-02,  5.7263e-04,\n                       9.9432e-03,  7.8757e-03, -6.7982e-04,  1.3137e-02,  1.5580e-02,\n                       1.3035e-02, -7.1952e-03,  9.3554e-03, -3.1480e-03,  1.1207e-02,\n                       2.7954e-03,  2.5311e-02, -1.9796e-03,  1.0127e-02, -7.7204e-04,\n                      -5.7045e-03,  1.2678e-03,  2.2362e-03,  6.0595e-03,  1.2055e-03,\n                      -1.5665e-02,  1.2548e-03,  6.4631e-03, -5.7722e-04, -4.4758e-03,\n                       3.3551e-03,  6.6531e-03, -5.1956e-03,  1.9016e-02,  7.6056e-03,\n                       1.6356e-02, -2.5679e-03,  2.3019e-02,  6.2591e-03,  1.3306e-02,\n                       7.7784e-04,  2.0809e-02, -8.5351e-03,  3.6030e-04,  3.9428e-03,\n                      -1.0247e-02,  6.6507e-03,  2.2572e-03, -1.1072e-02,  8.7657e-03,\n                       9.8873e-03,  5.1570e-03,  6.8206e-03,  1.0484e-02,  7.5549e-03,\n                       2.1297e-02,  9.4322e-03,  7.8660e-04,  1.2240e-02, -1.9337e-03,\n                      -4.0754e-03, -1.1740e-04,  6.7466e-03,  8.3507e-03, -4.8535e-03,\n                       6.3213e-03, -1.0384e-02,  1.5721e-02,  5.6857e-03, -1.3249e-02,\n                       8.8401e-03,  1.1107e-03,  1.6528e-03, -7.1821e-03,  1.4928e-02,\n                       5.1701e-04,  4.2543e-03,  6.3536e-03,  3.9085e-03,  4.4996e-03,\n                       6.4784e-03, -4.8751e-03,  1.0519e-02,  4.7066e-03, -4.2368e-03,\n                       1.9380e-02,  6.8053e-05, -6.0837e-03,  1.5958e-02,  9.5383e-04,\n                       1.2503e-03,  8.9366e-03,  1.1762e-02, -2.6870e-03,  1.0650e-02,\n                      -1.1184e-02,  1.1059e-02,  1.0312e-03,  1.8005e-02, -2.0933e-04,\n                       1.9040e-02,  1.3786e-02,  5.4997e-03,  8.4945e-03,  2.2343e-03,\n                      -8.4431e-04, -2.6019e-03,  2.7357e-03,  6.3142e-03,  8.2236e-03,\n                      -9.1302e-03, -5.8475e-03,  4.7060e-03,  1.8580e-02,  1.2242e-02,\n                       4.6164e-03,  1.1558e-02,  2.5087e-03,  5.3575e-03, -1.6675e-02,\n                       1.8842e-03,  8.4092e-03, -1.1372e-03, -2.8038e-03, -6.4122e-03,\n                       1.1889e-02,  1.3904e-02,  6.1809e-03,  4.4040e-03,  1.6077e-02,\n                       5.8161e-03,  1.4293e-02,  1.3822e-02,  1.0933e-02,  1.3112e-02,\n                      -1.1239e-02,  9.5890e-03,  5.7606e-03,  1.3627e-02,  1.5528e-03,\n                       1.6533e-02, -6.8476e-03,  1.7336e-02,  4.9267e-03, -6.3504e-03,\n                       1.4112e-02, -2.5164e-03,  5.0150e-04,  1.2105e-02,  9.7691e-03,\n                       5.1218e-03,  1.2296e-02,  9.9202e-03,  1.3127e-02,  1.2484e-02,\n                       9.8004e-03, -7.1805e-04,  4.3005e-03, -8.5380e-04, -1.4589e-02,\n                       4.6953e-03, -3.5371e-03, -1.5377e-04,  9.2811e-03,  1.6039e-02,\n                      -1.7357e-03, -1.2054e-02,  1.1148e-02, -1.6139e-04,  1.7936e-02,\n                       4.0661e-03,  2.1218e-03,  1.2853e-02,  1.2826e-02, -1.4234e-02,\n                       9.8502e-03,  7.6915e-04,  1.5784e-02,  2.4466e-03,  4.0880e-03,\n                      -5.2457e-03,  1.0351e-02, -6.2538e-03, -6.2423e-03,  1.9942e-02,\n                       7.2980e-03,  1.4964e-02,  9.5317e-03,  2.0691e-03,  7.2173e-03,\n                       5.8195e-03,  3.1460e-03,  8.2391e-03, -3.1033e-03,  3.8725e-03,\n                       6.2505e-03,  1.4530e-03,  5.7315e-03,  7.6802e-03,  1.5267e-02,\n                       2.2702e-03,  2.4098e-02,  2.1030e-02,  2.1161e-02,  5.8232e-03,\n                      -2.5579e-03,  7.4089e-03, -6.7027e-03,  5.9084e-03,  1.2503e-02,\n                       2.3454e-03,  1.1529e-02,  1.2954e-02,  7.5688e-03,  9.0912e-03,\n                       6.8166e-04,  1.3938e-03,  3.3354e-03,  4.0235e-03, -8.9321e-04,\n                      -1.1845e-02,  1.2893e-03,  3.7736e-03,  1.5616e-02, -2.7008e-03,\n                       3.7025e-03, -6.4905e-03,  2.1488e-05, -1.4322e-02,  1.4243e-02,\n                       5.2897e-03, -1.6429e-03,  1.0459e-02,  1.5137e-03,  2.0016e-03,\n                       9.3301e-03,  5.6510e-03, -3.1151e-03,  9.7082e-03,  4.6617e-03,\n                      -1.7597e-03,  1.3862e-03,  2.9500e-03,  4.4948e-03,  4.7447e-03,\n                       1.2681e-02,  4.0472e-03,  6.2626e-03, -1.4298e-03, -8.1937e-03,\n                       1.7483e-02,  2.0551e-02,  1.9907e-02,  1.4824e-02,  1.0463e-02,\n                       1.9561e-03], dtype=torch.float64)),\n             ('6.10.convs.2.1.running_mean',\n              tensor([ 5.6178e-01, -6.8782e-02,  2.0185e-01, -1.0731e+00,  2.1853e-01,\n                       1.0268e-01,  3.1078e-01,  7.5156e-01, -2.7289e-01,  6.0628e-01,\n                       5.3843e-01,  2.3213e-02, -3.6861e-01, -1.9925e-01,  7.4187e-01,\n                       5.7917e-01, -1.4652e-01,  4.5110e-01, -2.0102e-01, -2.4776e-02,\n                      -5.4560e-01, -3.4819e-01, -2.4555e-02,  8.4035e-01,  5.1256e-01,\n                      -2.5530e-02, -6.6425e-01,  1.7140e-01, -3.6024e-02, -4.1857e-02,\n                       6.1711e-01, -3.2143e-01, -1.0766e-02,  7.1144e-02,  8.3222e-02,\n                      -1.7820e-01, -1.9300e-01,  1.1062e-01,  8.8481e-01, -1.1790e+00,\n                      -7.5397e-01, -6.5807e-02, -3.5305e-01, -8.2003e-01,  1.2736e-01,\n                       1.2127e-01, -1.8146e-01, -9.0870e-02, -4.3714e-01, -6.1128e-01,\n                       2.4646e-01,  3.3453e-01,  1.2928e-01, -7.0750e-01,  4.4211e-01,\n                      -6.0625e-01,  5.1679e-01, -2.3441e-01, -8.2725e-01,  2.4390e-01,\n                      -2.5875e-01,  4.0395e-01, -6.4828e-01,  9.6058e-02,  2.0129e+00,\n                      -3.1218e-01,  1.8265e-02, -4.0407e-01,  6.6116e-03,  7.0741e-04,\n                       3.3268e-01, -1.2381e-01, -2.3007e-01,  7.7390e-02, -1.9671e-02,\n                      -8.2887e-01,  1.5198e-01, -3.0169e-01, -1.6719e-01,  3.0638e-01,\n                       3.4561e-01, -6.9595e-02, -3.3553e-01,  4.8904e-01, -1.6266e-01,\n                       2.3538e-01,  3.3497e-01, -5.4051e-01, -3.1362e-01, -1.3964e-01,\n                      -1.4191e-01,  9.0241e-03, -3.8299e-01, -3.7548e-01, -5.6345e-01,\n                      -5.6286e-01, -6.2053e-01,  2.7359e-01, -4.2809e-01, -3.7582e-02,\n                      -1.0939e-01, -2.4208e-01,  2.9761e-01,  2.6711e-01, -4.7773e-01,\n                      -4.7574e-01,  5.6905e-01,  3.7813e-01,  6.8381e-02,  2.9791e-01,\n                      -9.5990e-02,  5.5716e-01,  2.0655e-02,  1.3228e-02,  1.8174e-01,\n                       1.4467e+00, -3.6937e-01,  3.7790e-01, -2.4552e-01, -8.5553e-01,\n                       5.2369e-02, -4.4341e-01,  7.0195e-01, -1.3534e-01, -2.0126e-02,\n                       3.4482e-01,  4.0006e-01, -3.3399e-01, -2.5200e-02,  6.1621e-01,\n                       1.8634e-02, -1.0667e+00, -1.4345e-01,  2.9528e-01,  3.7303e-01,\n                      -5.7134e-01,  1.3169e-01, -5.8520e-02, -1.5251e-01, -4.0592e-01,\n                       5.2759e-01,  1.7364e-01,  8.3115e-01, -1.7131e-01, -2.2589e-01,\n                       1.2261e-01,  2.8909e-02,  6.1361e-01,  1.9334e-01,  6.4483e-02,\n                      -1.4849e-01,  4.2095e-02, -1.2642e-02, -6.3184e-01, -1.8436e-01,\n                       7.5699e-01, -2.7381e-01, -2.7729e-01,  7.4777e-01, -2.3450e-01,\n                       4.7544e-01, -3.8753e-01, -5.5739e-04,  8.7439e-03, -6.0848e-01,\n                       4.5884e-01, -6.8655e-01, -4.0494e-02,  5.8855e-01,  1.3876e-01,\n                      -3.4544e-01,  1.4734e-01, -4.9312e-01,  6.7195e-02, -7.8062e-02,\n                      -4.4475e-01,  2.0063e-01, -6.8710e-02, -4.9961e-01, -1.6415e-01,\n                      -1.1533e+00,  1.3045e-01,  2.3187e-01, -9.4491e-02,  9.5673e-02,\n                      -3.7021e-01,  6.2191e-01, -7.6247e-02, -2.7160e-02,  2.2064e-01,\n                      -1.4251e-01,  7.0665e-01,  4.8022e-01,  5.1456e-01,  5.9403e-02,\n                       9.6319e-02,  6.7817e-01,  7.5896e-01,  1.0440e-01, -8.2626e-01,\n                      -2.1037e-02, -2.5634e-01,  2.5498e-01,  4.9004e-01,  1.6474e-01,\n                      -4.2712e-03, -4.1767e-01, -2.6839e-02,  3.7826e-01, -3.4818e-01,\n                       3.7059e-01,  1.0642e-01, -6.6875e-02, -6.1889e-04, -1.1302e-01,\n                      -1.9289e-01,  1.4715e-01,  4.0603e-01, -1.5767e-01, -7.7226e-03,\n                      -1.9936e-01, -4.2945e-02, -3.8162e-01,  2.2403e-01, -4.3285e-01,\n                      -2.0797e-01,  4.9482e-01, -9.4220e-02,  6.4867e-01, -8.5883e-01,\n                       2.3201e-01, -3.9931e-01, -1.6298e-01, -4.6695e-01, -7.5557e-01,\n                      -1.3703e-01, -4.4461e-02, -4.4358e-01, -4.8746e-01, -2.0755e-02,\n                       5.6262e-01, -2.7123e-01,  1.9958e-01, -8.9495e-02, -3.4848e-01,\n                       8.0554e-01,  1.8498e-01, -5.2496e-01,  7.8764e-05,  2.1356e-01,\n                       9.6534e-02, -7.5191e-02, -1.7334e-01,  2.4495e-01,  3.2189e-01,\n                      -6.2282e-01], dtype=torch.float64)),\n             ('6.10.convs.2.1.running_var',\n              tensor([0.6414, 0.3865, 0.2646, 0.5096, 0.4047, 0.1970, 0.3226, 0.5637, 0.3440,\n                      0.3541, 0.4674, 0.3225, 0.1961, 0.1173, 0.5818, 0.5889, 0.4848, 0.4777,\n                      0.2309, 0.7209, 0.4128, 0.5210, 0.2913, 0.6647, 0.3132, 0.2866, 0.6578,\n                      0.5395, 0.2824, 0.1886, 0.4176, 0.3766, 0.2507, 0.3825, 0.4105, 0.3394,\n                      0.1934, 0.3391, 0.5375, 0.5433, 0.2968, 0.4990, 0.2610, 0.4648, 0.4129,\n                      0.3881, 0.2339, 0.0946, 0.4866, 0.3744, 0.2706, 0.3314, 0.2142, 0.2408,\n                      0.4084, 0.4188, 0.7038, 0.2284, 0.3762, 0.1916, 0.2609, 0.1654, 0.1990,\n                      0.1289, 0.8634, 0.3761, 0.2976, 0.2396, 0.1889, 0.4088, 0.3160, 0.1541,\n                      0.0417, 0.3735, 0.3887, 0.3390, 0.1843, 0.0834, 0.3020, 0.1834, 0.1979,\n                      0.3647, 0.3858, 0.3345, 0.2233, 0.3868, 0.1747, 0.4079, 0.3515, 0.2489,\n                      0.3010, 0.0881, 0.5005, 0.1223, 0.2784, 0.2946, 0.5440, 0.3266, 0.2057,\n                      0.2562, 0.5064, 0.3070, 0.1140, 0.1560, 0.2148, 0.3614, 0.4097, 0.3100,\n                      0.5722, 0.2523, 0.1679, 0.3997, 0.3828, 0.4530, 0.2136, 0.3676, 0.0991,\n                      0.6538, 0.4771, 0.4951, 0.2567, 0.3742, 0.1669, 0.3427, 0.3490, 0.4726,\n                      0.3186, 0.2675, 0.0856, 0.3531, 0.1977, 0.2559, 0.3485, 0.2448, 0.1307,\n                      0.3590, 0.4089, 0.3407, 0.4064, 0.3257, 0.3726, 0.2805, 0.4574, 0.5170,\n                      0.1330, 0.3319, 0.0519, 0.3706, 0.2655, 0.3802, 0.3535, 0.2284, 0.2750,\n                      0.3911, 0.3946, 0.4676, 0.1197, 0.3369, 0.4623, 0.1608, 0.1480, 0.3302,\n                      0.2723, 0.4390, 0.5125, 0.3372, 0.4923, 0.3396, 0.3069, 0.3190, 0.4701,\n                      0.1405, 0.4134, 0.1572, 0.4722, 0.3488, 0.3847, 0.0824, 0.5984, 0.3066,\n                      0.5788, 0.3256, 0.4023, 0.4478, 0.5611, 0.2623, 0.5534, 0.2696, 0.1722,\n                      0.3553, 0.2713, 0.4837, 0.2472, 0.5842, 0.4377, 0.2905, 0.4765, 0.7614,\n                      0.3932, 0.5070, 0.1500, 0.4627, 0.2270, 0.3273, 0.4728, 0.3960, 0.2141,\n                      0.2091, 0.3392, 0.5939, 0.1966, 0.3834, 0.0813, 0.3618, 0.0824, 0.1792,\n                      0.3296, 0.2856, 0.3791, 0.6279, 0.2755, 0.4400, 0.1532, 0.3508, 0.4913,\n                      0.4238, 0.4194, 0.2251, 0.4307, 0.3805, 0.2169, 0.5264, 0.4282, 0.4021,\n                      0.4860, 0.2623, 0.5181, 0.2361, 0.4318, 0.3855, 0.3994, 0.2376, 0.3360,\n                      0.1627, 0.3166, 0.1957, 0.2909, 0.5306, 0.0904, 0.4314, 0.3043, 0.3069,\n                      0.1932, 0.4822, 0.3189, 0.1674], dtype=torch.float64)),\n             ('6.10.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.10.convpath.0.0.0.weight',\n              tensor([[[ 5.3001e-02],\n                       [ 5.1272e-02],\n                       [-1.8943e-02],\n                       ...,\n                       [ 2.4716e-02],\n                       [ 2.8205e-02],\n                       [ 1.3569e-01]],\n              \n                      [[ 5.7943e-02],\n                       [-6.3280e-02],\n                       [ 1.6232e-02],\n                       ...,\n                       [ 5.2459e-02],\n                       [-6.3835e-02],\n                       [ 4.8409e-02]],\n              \n                      [[ 3.2850e-02],\n                       [-1.7670e-01],\n                       [ 2.1905e-02],\n                       ...,\n                       [ 4.4218e-02],\n                       [ 6.3894e-02],\n                       [-2.0578e-02]],\n              \n                      ...,\n              \n                      [[ 7.2022e-02],\n                       [ 1.4206e-02],\n                       [-5.0822e-02],\n                       ...,\n                       [ 3.2147e-02],\n                       [-1.8324e-02],\n                       [-1.6928e-02]],\n              \n                      [[ 8.7296e-02],\n                       [-4.3677e-02],\n                       [ 3.3087e-02],\n                       ...,\n                       [-8.9813e-02],\n                       [ 6.3145e-02],\n                       [-4.2425e-02]],\n              \n                      [[ 2.0281e-03],\n                       [-3.6634e-05],\n                       [ 1.7222e-01],\n                       ...,\n                       [-1.5494e-02],\n                       [ 8.0183e-02],\n                       [ 1.3786e-01]]], dtype=torch.float64)),\n             ('6.10.convpath.0.0.1.weight',\n              tensor([0.9761, 0.9647, 0.9646, 0.9977, 1.0027, 0.9771, 0.9800, 0.9729, 0.9764,\n                      0.9411, 0.9793, 0.9648, 0.9732, 0.9549, 0.9648, 0.9778, 0.9948, 0.9920,\n                      0.9640, 0.9602, 0.9723, 0.9681, 0.9584, 1.0106, 0.9796, 0.9547, 1.0054,\n                      0.9699, 0.9842, 0.9972, 0.9735, 0.9792, 0.9563, 0.9732, 0.9663, 0.9644,\n                      0.9616, 0.9730, 0.9675, 0.9625, 0.9969, 0.9961, 0.9765, 0.9802, 0.9680,\n                      0.9787, 0.9896, 0.9960, 0.9961, 0.9659, 0.9677, 0.9514, 0.9971, 0.9549,\n                      0.9693, 0.9544, 0.9718, 0.9691, 0.9759, 0.9560, 0.9648, 0.9811, 0.9814,\n                      0.9558], dtype=torch.float64)),\n             ('6.10.convpath.0.0.1.bias',\n              tensor([-0.0062, -0.0043, -0.0192,  0.0215,  0.0105,  0.0115,  0.0042, -0.0032,\n                       0.0220, -0.0178, -0.0044,  0.0153,  0.0239, -0.0038, -0.0082,  0.0243,\n                       0.0202,  0.0194,  0.0146, -0.0048,  0.0061, -0.0081, -0.0051,  0.0247,\n                       0.0074,  0.0132,  0.0277,  0.0038, -0.0004,  0.0364,  0.0012, -0.0044,\n                      -0.0061,  0.0169, -0.0103, -0.0108, -0.0137, -0.0135,  0.0239, -0.0124,\n                       0.0185,  0.0322,  0.0052,  0.0059,  0.0160,  0.0073,  0.0013,  0.0045,\n                       0.0278, -0.0109, -0.0147, -0.0044,  0.0156, -0.0091, -0.0028, -0.0025,\n                       0.0140,  0.0015, -0.0070, -0.0055,  0.0080,  0.0134, -0.0120, -0.0090],\n                     dtype=torch.float64)),\n             ('6.10.convpath.0.0.1.running_mean',\n              tensor([ 0.0851,  0.1362,  1.1821, -0.1744, -0.0653, -0.4568, -0.1044,  1.5376,\n                      -0.6681,  1.5421,  0.2019,  0.6653, -1.2714, -0.1918, -0.2303, -0.1038,\n                      -0.6344, -0.6344,  0.7560, -0.8433,  0.2658,  0.5114, -0.2615,  0.1207,\n                       0.2419, -0.2890, -0.6004, -0.1606, -0.5961,  0.0796,  0.4721,  0.5530,\n                       0.2738, -0.4581,  0.2339,  0.5347, -0.0533, -0.6945,  0.1588, -0.5252,\n                      -0.6424, -0.2035,  0.0025, -0.1813, -0.2180, -0.0381, -0.5110,  0.0414,\n                      -0.8994, -0.0787,  0.5291,  0.0046, -0.4013, -0.3067,  0.4259, -0.2342,\n                       0.1026,  0.3998, -0.9588, -0.0718, -1.0658, -0.6128,  1.3851,  0.5635],\n                     dtype=torch.float64)),\n             ('6.10.convpath.0.0.1.running_var',\n              tensor([0.2075, 0.1780, 0.3544, 0.2462, 0.1225, 0.1398, 0.1361, 1.5115, 0.1946,\n                      1.6075, 0.2783, 0.2215, 0.4317, 0.2211, 0.3148, 0.2696, 0.1128, 0.2005,\n                      0.2412, 0.4072, 0.1412, 0.8247, 0.5862, 0.1213, 0.2463, 0.4062, 0.1269,\n                      0.2243, 0.1076, 0.2449, 0.2198, 0.2023, 0.5002, 0.2317, 0.3742, 0.3920,\n                      0.2172, 0.1581, 0.0851, 0.1756, 0.1484, 0.1947, 0.1141, 0.3521, 0.2023,\n                      0.2105, 0.1509, 0.1691, 0.0952, 0.1439, 0.2637, 0.6856, 0.1059, 0.1499,\n                      0.2030, 0.0992, 0.2251, 0.2923, 0.4499, 0.2593, 0.4148, 0.2528, 0.5615,\n                      0.6002], dtype=torch.float64)),\n             ('6.10.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.10.convpath.0.1.0.weight',\n              tensor([[[ 0.0826,  0.0750,  0.0228,  0.0698,  0.0649],\n                       [ 0.0153, -0.0929,  0.0216,  0.0377,  0.1532],\n                       [-0.0722, -0.0893, -0.1422,  0.0668, -0.1166],\n                       ...,\n                       [-0.1447, -0.0873,  0.0406,  0.0233,  0.0740],\n                       [ 0.0137, -0.0728,  0.0168, -0.0616, -0.0075],\n                       [-0.0269, -0.0355,  0.0754, -0.1133, -0.0195]],\n              \n                      [[-0.0596, -0.1007,  0.0120, -0.0124,  0.0380],\n                       [-0.0967,  0.0928,  0.0795,  0.0528,  0.0194],\n                       [ 0.0194, -0.0077, -0.0564, -0.0904, -0.1240],\n                       ...,\n                       [-0.0433, -0.0591, -0.1491,  0.0217,  0.0718],\n                       [-0.0213, -0.1208, -0.0256, -0.0895,  0.0479],\n                       [ 0.0402,  0.1456,  0.0895,  0.0109,  0.1030]],\n              \n                      [[ 0.0733, -0.0582, -0.0385,  0.0029,  0.0186],\n                       [ 0.0231,  0.0651,  0.0639,  0.1665,  0.0704],\n                       [ 0.0948, -0.0609, -0.1184, -0.0489,  0.0720],\n                       ...,\n                       [ 0.0088, -0.0404,  0.0280, -0.0296, -0.1209],\n                       [-0.0740,  0.0258, -0.0802, -0.0934,  0.0126],\n                       [-0.0336,  0.0618, -0.0700, -0.0925,  0.0064]],\n              \n                      ...,\n              \n                      [[-0.0528,  0.0317,  0.0551,  0.0407, -0.1539],\n                       [-0.0543,  0.0325,  0.0744,  0.0389,  0.1441],\n                       [-0.1047, -0.0849,  0.0807, -0.0975, -0.0493],\n                       ...,\n                       [ 0.1104, -0.0267, -0.0580, -0.0039, -0.1336],\n                       [ 0.0614,  0.0425,  0.0111, -0.0265,  0.1284],\n                       [ 0.0433,  0.0160, -0.0872,  0.1225, -0.0439]],\n              \n                      [[-0.0261, -0.0056, -0.0654, -0.0859,  0.0652],\n                       [-0.0291,  0.0285,  0.0541,  0.0416,  0.0197],\n                       [-0.1106, -0.2368, -0.0391,  0.0458,  0.1310],\n                       ...,\n                       [-0.1518,  0.0199, -0.1015, -0.0462,  0.0056],\n                       [ 0.0215,  0.0452,  0.0252,  0.0221, -0.0094],\n                       [-0.0929,  0.0013, -0.1021, -0.0710, -0.0472]],\n              \n                      [[ 0.0155,  0.0565,  0.0123,  0.0180, -0.1621],\n                       [ 0.0997,  0.0388, -0.0266, -0.0228,  0.0018],\n                       [-0.1008, -0.1550, -0.1184, -0.2444, -0.0671],\n                       ...,\n                       [ 0.0992, -0.1436,  0.0875, -0.0306,  0.1076],\n                       [-0.0567,  0.0806, -0.0124,  0.0722,  0.0503],\n                       [ 0.0919, -0.0561,  0.0182,  0.0457,  0.0400]]], dtype=torch.float64)),\n             ('6.10.convpath.0.1.1.weight',\n              tensor([0.9843, 0.9771, 0.9389, 0.9296, 0.9613, 0.9532, 0.9630, 0.9553, 1.0097,\n                      0.9687, 0.9531, 0.9632, 0.9478, 0.9671, 0.9602, 0.9635, 0.9475, 0.9510,\n                      0.9420, 0.9615, 0.9554, 0.9806, 0.9963, 0.9300, 0.9560, 0.9829, 0.9949,\n                      0.9794, 0.9807, 0.9653, 0.9616, 0.9386, 0.9906, 0.9458, 0.9425, 0.9558,\n                      0.9591, 0.9932, 1.0054, 0.9593, 0.9550, 0.9495, 0.9477, 0.9575, 0.9782,\n                      0.9635, 0.9846, 0.9404, 0.9947, 0.9624, 0.9255, 0.9537, 0.9385, 0.9304,\n                      0.9719, 0.9792, 1.0084, 0.9497, 0.9683, 0.9727, 0.9633, 0.9756, 0.9931,\n                      0.9784], dtype=torch.float64)),\n             ('6.10.convpath.0.1.1.bias',\n              tensor([ 0.0157, -0.0278, -0.0068, -0.0094, -0.0125, -0.0033, -0.0201, -0.0042,\n                      -0.0033, -0.0019,  0.0059, -0.0271, -0.0027, -0.0010, -0.0165, -0.0320,\n                      -0.0256, -0.0118, -0.0092,  0.0082, -0.0143,  0.0017,  0.0144, -0.0165,\n                      -0.0242, -0.0087,  0.0246, -0.0076,  0.0051, -0.0104, -0.0024, -0.0241,\n                       0.0030, -0.0071, -0.0205,  0.0134, -0.0302,  0.0043,  0.0242, -0.0137,\n                      -0.0159, -0.0104, -0.0250, -0.0340,  0.0002,  0.0073,  0.0042, -0.0267,\n                      -0.0129, -0.0010, -0.0269, -0.0039, -0.0198, -0.0181, -0.0052,  0.0024,\n                      -0.0061, -0.0087, -0.0110, -0.0023, -0.0061,  0.0011, -0.0065,  0.0144],\n                     dtype=torch.float64)),\n             ('6.10.convpath.0.1.1.running_mean',\n              tensor([ 0.0187,  0.2259,  0.2150, -1.0941,  0.6182, -0.0773, -0.4612, -0.2403,\n                      -0.3761, -0.4489, -0.4950,  1.0450, -0.7571, -0.3510,  0.3584, -0.2392,\n                       0.3453,  0.3259,  0.5222, -0.4038, -0.8119, -0.7961,  0.4897, -1.0529,\n                      -0.4908,  0.3785, -0.0859, -0.5807, -0.7508, -0.5342, -0.4863,  0.3372,\n                       0.6826,  0.2338, -0.6086, -0.1205,  0.0786,  0.2197,  0.7343,  0.3162,\n                      -0.0494, -0.0666, -0.8932,  0.6783,  0.2522, -0.2925, -0.0483, -0.6740,\n                      -0.4905, -0.1910, -0.3267, -0.5483,  0.2979, -0.1600,  0.0428, -0.1494,\n                      -0.4107, -1.1245,  0.3102,  0.3486, -0.1278, -0.1558, -0.3634,  0.1078],\n                     dtype=torch.float64)),\n             ('6.10.convpath.0.1.1.running_var',\n              tensor([0.5527, 0.3774, 0.7526, 0.8442, 0.7330, 0.5664, 0.7094, 0.5574, 0.5508,\n                      0.6127, 0.7145, 0.9200, 0.5266, 0.5878, 0.5787, 0.6866, 0.7206, 0.6839,\n                      2.1087, 0.5224, 0.7808, 0.8901, 0.6228, 0.7270, 0.6302, 0.5375, 0.5395,\n                      0.4998, 0.7418, 0.6076, 0.6234, 0.4750, 0.4875, 0.7924, 0.6141, 0.7703,\n                      0.5388, 0.4119, 0.4038, 0.5959, 0.5061, 0.6636, 0.5149, 0.8990, 0.4423,\n                      0.6233, 0.3774, 0.4376, 0.4759, 0.6566, 0.6653, 0.4274, 0.9510, 0.6285,\n                      0.6155, 0.4104, 0.4113, 0.6362, 0.9603, 0.4578, 0.4799, 0.3548, 0.5579,\n                      0.5769], dtype=torch.float64)),\n             ('6.10.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.10.convpath.0.2.0.weight',\n              tensor([[[ 0.2122],\n                       [ 0.0268],\n                       [ 0.0150],\n                       ...,\n                       [ 0.0067],\n                       [-0.1124],\n                       [-0.2242]],\n              \n                      [[-0.1059],\n                       [ 0.0927],\n                       [-0.0035],\n                       ...,\n                       [-0.0038],\n                       [ 0.0482],\n                       [-0.3961]],\n              \n                      [[ 0.0258],\n                       [-0.0312],\n                       [-0.0507],\n                       ...,\n                       [ 0.0615],\n                       [ 0.0151],\n                       [-0.1351]],\n              \n                      ...,\n              \n                      [[ 0.2670],\n                       [-0.1374],\n                       [ 0.0363],\n                       ...,\n                       [-0.1588],\n                       [ 0.0924],\n                       [-0.0818]],\n              \n                      [[ 0.2567],\n                       [ 0.2478],\n                       [ 0.0953],\n                       ...,\n                       [-0.1857],\n                       [-0.2397],\n                       [-0.1418]],\n              \n                      [[ 0.0365],\n                       [ 0.0354],\n                       [ 0.1555],\n                       ...,\n                       [-0.0695],\n                       [ 0.0791],\n                       [-0.1659]]], dtype=torch.float64)),\n             ('6.10.convpath.0.2.1.weight',\n              tensor([ 3.4072e-03, -1.2247e-02, -2.4161e-02, -2.7273e-04, -9.3331e-03,\n                       1.0570e-02,  1.4263e-02, -3.9445e-02, -7.2664e-03,  2.6008e-02,\n                      -2.1712e-02, -7.5450e-03,  2.0206e-02,  2.8890e-05,  2.0473e-02,\n                      -3.6217e-02, -3.1956e-02, -2.4624e-02,  3.3658e-03, -2.1315e-02,\n                       2.6538e-02,  1.5955e-02, -6.5937e-03, -2.1108e-02, -1.0326e-02,\n                      -2.0038e-02, -2.0217e-02, -7.3655e-03, -7.6255e-03, -8.6981e-03,\n                       1.8087e-02, -8.9053e-03, -1.3330e-02, -2.2761e-02, -1.3948e-02,\n                       2.0025e-02, -7.0666e-04, -2.4147e-02, -1.6121e-02, -1.5117e-02,\n                       1.0130e-02, -3.3159e-02,  1.8177e-02, -4.0222e-03,  2.6264e-02,\n                      -1.6140e-02, -6.5510e-03,  9.9583e-04, -4.0450e-03, -8.8346e-03,\n                       9.5506e-03, -5.2296e-03,  3.6607e-03,  1.4062e-02, -7.7209e-04,\n                      -1.4152e-02, -2.7755e-02,  8.0897e-03, -1.4775e-02, -1.0350e-02,\n                      -1.0600e-02,  8.8873e-03, -1.1732e-03,  7.1229e-03, -2.3113e-02,\n                      -3.1991e-02,  1.2511e-02,  1.8373e-02,  5.9849e-03, -1.0396e-02,\n                       7.9709e-03, -2.6618e-02, -4.4113e-03,  2.1236e-02,  1.3796e-02,\n                      -3.2869e-02,  6.6936e-03,  6.8765e-04,  1.4736e-02, -1.0892e-02,\n                      -1.1828e-02, -2.5184e-02, -1.4756e-02, -7.2027e-03,  9.2075e-03,\n                      -7.2813e-03,  5.3349e-03, -2.4958e-02, -1.2517e-02, -2.1349e-02,\n                       2.5620e-03, -6.9599e-05, -3.3621e-02,  8.3162e-03,  2.2684e-02,\n                       1.2405e-02,  3.3170e-03, -1.0054e-02,  1.6713e-04,  2.8225e-02,\n                       2.7370e-02, -8.6707e-03, -2.9238e-03,  1.2424e-02, -2.0158e-02,\n                      -2.8109e-02,  9.6405e-03,  8.8105e-03, -1.6848e-02,  2.3961e-02,\n                      -1.8228e-02,  9.2832e-03,  1.3457e-02,  3.6695e-02, -4.6360e-03,\n                      -1.4240e-02,  6.7069e-04, -3.4919e-02,  2.0982e-02,  2.6532e-04,\n                       3.9353e-03, -1.1445e-02, -2.8107e-03, -5.8135e-03, -2.9242e-02,\n                      -1.0877e-02,  1.9695e-02, -5.4900e-03, -7.4701e-03, -2.6370e-02,\n                      -3.9218e-03,  2.7932e-02,  8.1563e-03,  1.2044e-02, -4.4135e-03,\n                      -1.8723e-02, -1.0345e-02,  1.9427e-03,  4.3735e-02, -2.2981e-02,\n                      -2.1402e-02,  2.6798e-02,  3.0212e-02,  1.9308e-02,  7.0345e-04,\n                      -2.2224e-02,  9.0207e-03,  3.2886e-02,  1.1560e-02, -2.1491e-02,\n                       8.6478e-04,  2.4280e-02, -1.3888e-02, -3.6991e-02, -1.5033e-02,\n                      -1.9430e-02,  6.0777e-03,  4.9210e-03, -1.6575e-02,  6.4252e-03,\n                       1.5046e-02,  2.5336e-02, -9.5295e-03,  2.9799e-02,  3.8882e-02,\n                       1.4259e-02,  1.0982e-02,  9.2096e-03, -4.9746e-02,  2.9889e-02,\n                      -1.6953e-02,  4.4672e-03, -3.4920e-02,  4.1083e-03, -3.3216e-02,\n                       4.0766e-04,  5.9614e-02, -1.8276e-03,  2.1305e-02, -2.1283e-02,\n                      -1.1979e-02,  2.6840e-02, -5.3218e-03, -1.6319e-02, -3.6670e-02,\n                       1.0133e-02, -1.0708e-02, -3.5065e-02,  9.7089e-04,  1.1724e-02,\n                       1.7143e-02, -2.2267e-02,  6.4238e-03,  2.6369e-02,  1.6521e-02,\n                       1.0338e-03,  2.0108e-02,  2.5012e-02,  6.3948e-03, -1.8919e-02,\n                       7.6865e-04,  4.3738e-02, -6.6710e-03,  1.9074e-02,  4.0113e-02,\n                       4.2010e-03,  8.4241e-03, -2.2260e-02,  5.6589e-03, -1.2826e-02,\n                       3.4103e-02,  2.9219e-02,  1.6980e-03,  2.5113e-02, -7.7743e-03,\n                      -1.1834e-02,  3.1183e-03, -2.9594e-02,  2.3550e-02,  2.0443e-02,\n                      -1.3179e-02, -1.9991e-02, -7.1188e-04, -9.6507e-03,  1.3069e-02,\n                       2.0176e-02,  1.9741e-04,  1.1626e-04,  1.1369e-03, -1.0526e-02,\n                       4.1153e-03,  1.0016e-02,  1.0788e-02, -2.6078e-02,  2.0431e-02,\n                       1.8057e-02, -2.3363e-02, -6.2282e-03, -1.8878e-02, -1.2228e-02,\n                       2.3205e-02, -2.6446e-02, -1.3008e-02,  4.6080e-03,  1.8209e-02,\n                      -8.3547e-03,  1.7536e-02,  1.6987e-02, -5.0215e-03, -2.9718e-02,\n                       7.6276e-03, -5.4648e-03,  1.0720e-02, -2.5892e-02, -5.9801e-03,\n                      -3.2465e-03], dtype=torch.float64)),\n             ('6.10.convpath.0.2.1.bias',\n              tensor([-2.4520e-03,  9.3828e-03,  1.1827e-02,  1.4305e-02,  5.7263e-04,\n                       9.9432e-03,  7.8757e-03, -6.7982e-04,  1.3137e-02,  1.5580e-02,\n                       1.3035e-02, -7.1952e-03,  9.3554e-03, -3.1480e-03,  1.1207e-02,\n                       2.7954e-03,  2.5311e-02, -1.9796e-03,  1.0127e-02, -7.7204e-04,\n                      -5.7045e-03,  1.2678e-03,  2.2362e-03,  6.0595e-03,  1.2055e-03,\n                      -1.5665e-02,  1.2548e-03,  6.4631e-03, -5.7722e-04, -4.4758e-03,\n                       3.3551e-03,  6.6531e-03, -5.1956e-03,  1.9016e-02,  7.6056e-03,\n                       1.6356e-02, -2.5679e-03,  2.3019e-02,  6.2591e-03,  1.3306e-02,\n                       7.7784e-04,  2.0809e-02, -8.5351e-03,  3.6030e-04,  3.9428e-03,\n                      -1.0247e-02,  6.6507e-03,  2.2572e-03, -1.1072e-02,  8.7657e-03,\n                       9.8873e-03,  5.1570e-03,  6.8206e-03,  1.0484e-02,  7.5549e-03,\n                       2.1297e-02,  9.4322e-03,  7.8660e-04,  1.2240e-02, -1.9337e-03,\n                      -4.0754e-03, -1.1740e-04,  6.7466e-03,  8.3507e-03, -4.8535e-03,\n                       6.3213e-03, -1.0384e-02,  1.5721e-02,  5.6857e-03, -1.3249e-02,\n                       8.8401e-03,  1.1107e-03,  1.6528e-03, -7.1821e-03,  1.4928e-02,\n                       5.1701e-04,  4.2543e-03,  6.3536e-03,  3.9085e-03,  4.4996e-03,\n                       6.4784e-03, -4.8751e-03,  1.0519e-02,  4.7066e-03, -4.2368e-03,\n                       1.9380e-02,  6.8053e-05, -6.0837e-03,  1.5958e-02,  9.5383e-04,\n                       1.2503e-03,  8.9366e-03,  1.1762e-02, -2.6870e-03,  1.0650e-02,\n                      -1.1184e-02,  1.1059e-02,  1.0312e-03,  1.8005e-02, -2.0933e-04,\n                       1.9040e-02,  1.3786e-02,  5.4997e-03,  8.4945e-03,  2.2343e-03,\n                      -8.4431e-04, -2.6019e-03,  2.7357e-03,  6.3142e-03,  8.2236e-03,\n                      -9.1302e-03, -5.8475e-03,  4.7060e-03,  1.8580e-02,  1.2242e-02,\n                       4.6164e-03,  1.1558e-02,  2.5087e-03,  5.3575e-03, -1.6675e-02,\n                       1.8842e-03,  8.4092e-03, -1.1372e-03, -2.8038e-03, -6.4122e-03,\n                       1.1889e-02,  1.3904e-02,  6.1809e-03,  4.4040e-03,  1.6077e-02,\n                       5.8161e-03,  1.4293e-02,  1.3822e-02,  1.0933e-02,  1.3112e-02,\n                      -1.1239e-02,  9.5890e-03,  5.7606e-03,  1.3627e-02,  1.5528e-03,\n                       1.6533e-02, -6.8476e-03,  1.7336e-02,  4.9267e-03, -6.3504e-03,\n                       1.4112e-02, -2.5164e-03,  5.0150e-04,  1.2105e-02,  9.7691e-03,\n                       5.1218e-03,  1.2296e-02,  9.9202e-03,  1.3127e-02,  1.2484e-02,\n                       9.8004e-03, -7.1805e-04,  4.3005e-03, -8.5380e-04, -1.4589e-02,\n                       4.6953e-03, -3.5371e-03, -1.5377e-04,  9.2811e-03,  1.6039e-02,\n                      -1.7357e-03, -1.2054e-02,  1.1148e-02, -1.6139e-04,  1.7936e-02,\n                       4.0661e-03,  2.1218e-03,  1.2853e-02,  1.2826e-02, -1.4234e-02,\n                       9.8502e-03,  7.6915e-04,  1.5784e-02,  2.4466e-03,  4.0880e-03,\n                      -5.2457e-03,  1.0351e-02, -6.2538e-03, -6.2423e-03,  1.9942e-02,\n                       7.2980e-03,  1.4964e-02,  9.5317e-03,  2.0691e-03,  7.2173e-03,\n                       5.8195e-03,  3.1460e-03,  8.2391e-03, -3.1033e-03,  3.8725e-03,\n                       6.2505e-03,  1.4530e-03,  5.7315e-03,  7.6802e-03,  1.5267e-02,\n                       2.2702e-03,  2.4098e-02,  2.1030e-02,  2.1161e-02,  5.8232e-03,\n                      -2.5579e-03,  7.4089e-03, -6.7027e-03,  5.9084e-03,  1.2503e-02,\n                       2.3454e-03,  1.1529e-02,  1.2954e-02,  7.5688e-03,  9.0912e-03,\n                       6.8166e-04,  1.3938e-03,  3.3354e-03,  4.0235e-03, -8.9321e-04,\n                      -1.1845e-02,  1.2893e-03,  3.7736e-03,  1.5616e-02, -2.7008e-03,\n                       3.7025e-03, -6.4905e-03,  2.1488e-05, -1.4322e-02,  1.4243e-02,\n                       5.2897e-03, -1.6429e-03,  1.0459e-02,  1.5137e-03,  2.0016e-03,\n                       9.3301e-03,  5.6510e-03, -3.1151e-03,  9.7082e-03,  4.6617e-03,\n                      -1.7597e-03,  1.3862e-03,  2.9500e-03,  4.4948e-03,  4.7447e-03,\n                       1.2681e-02,  4.0472e-03,  6.2626e-03, -1.4298e-03, -8.1937e-03,\n                       1.7483e-02,  2.0551e-02,  1.9907e-02,  1.4824e-02,  1.0463e-02,\n                       1.9561e-03], dtype=torch.float64)),\n             ('6.10.convpath.0.2.1.running_mean',\n              tensor([ 5.6178e-01, -6.8782e-02,  2.0185e-01, -1.0731e+00,  2.1853e-01,\n                       1.0268e-01,  3.1078e-01,  7.5156e-01, -2.7289e-01,  6.0628e-01,\n                       5.3843e-01,  2.3213e-02, -3.6861e-01, -1.9925e-01,  7.4187e-01,\n                       5.7917e-01, -1.4652e-01,  4.5110e-01, -2.0102e-01, -2.4776e-02,\n                      -5.4560e-01, -3.4819e-01, -2.4555e-02,  8.4035e-01,  5.1256e-01,\n                      -2.5530e-02, -6.6425e-01,  1.7140e-01, -3.6024e-02, -4.1857e-02,\n                       6.1711e-01, -3.2143e-01, -1.0766e-02,  7.1144e-02,  8.3222e-02,\n                      -1.7820e-01, -1.9300e-01,  1.1062e-01,  8.8481e-01, -1.1790e+00,\n                      -7.5397e-01, -6.5807e-02, -3.5305e-01, -8.2003e-01,  1.2736e-01,\n                       1.2127e-01, -1.8146e-01, -9.0870e-02, -4.3714e-01, -6.1128e-01,\n                       2.4646e-01,  3.3453e-01,  1.2928e-01, -7.0750e-01,  4.4211e-01,\n                      -6.0625e-01,  5.1679e-01, -2.3441e-01, -8.2725e-01,  2.4390e-01,\n                      -2.5875e-01,  4.0395e-01, -6.4828e-01,  9.6058e-02,  2.0129e+00,\n                      -3.1218e-01,  1.8265e-02, -4.0407e-01,  6.6116e-03,  7.0741e-04,\n                       3.3268e-01, -1.2381e-01, -2.3007e-01,  7.7390e-02, -1.9671e-02,\n                      -8.2887e-01,  1.5198e-01, -3.0169e-01, -1.6719e-01,  3.0638e-01,\n                       3.4561e-01, -6.9595e-02, -3.3553e-01,  4.8904e-01, -1.6266e-01,\n                       2.3538e-01,  3.3497e-01, -5.4051e-01, -3.1362e-01, -1.3964e-01,\n                      -1.4191e-01,  9.0241e-03, -3.8299e-01, -3.7548e-01, -5.6345e-01,\n                      -5.6286e-01, -6.2053e-01,  2.7359e-01, -4.2809e-01, -3.7582e-02,\n                      -1.0939e-01, -2.4208e-01,  2.9761e-01,  2.6711e-01, -4.7773e-01,\n                      -4.7574e-01,  5.6905e-01,  3.7813e-01,  6.8381e-02,  2.9791e-01,\n                      -9.5990e-02,  5.5716e-01,  2.0655e-02,  1.3228e-02,  1.8174e-01,\n                       1.4467e+00, -3.6937e-01,  3.7790e-01, -2.4552e-01, -8.5553e-01,\n                       5.2369e-02, -4.4341e-01,  7.0195e-01, -1.3534e-01, -2.0126e-02,\n                       3.4482e-01,  4.0006e-01, -3.3399e-01, -2.5200e-02,  6.1621e-01,\n                       1.8634e-02, -1.0667e+00, -1.4345e-01,  2.9528e-01,  3.7303e-01,\n                      -5.7134e-01,  1.3169e-01, -5.8520e-02, -1.5251e-01, -4.0592e-01,\n                       5.2759e-01,  1.7364e-01,  8.3115e-01, -1.7131e-01, -2.2589e-01,\n                       1.2261e-01,  2.8909e-02,  6.1361e-01,  1.9334e-01,  6.4483e-02,\n                      -1.4849e-01,  4.2095e-02, -1.2642e-02, -6.3184e-01, -1.8436e-01,\n                       7.5699e-01, -2.7381e-01, -2.7729e-01,  7.4777e-01, -2.3450e-01,\n                       4.7544e-01, -3.8753e-01, -5.5739e-04,  8.7439e-03, -6.0848e-01,\n                       4.5884e-01, -6.8655e-01, -4.0494e-02,  5.8855e-01,  1.3876e-01,\n                      -3.4544e-01,  1.4734e-01, -4.9312e-01,  6.7195e-02, -7.8062e-02,\n                      -4.4475e-01,  2.0063e-01, -6.8710e-02, -4.9961e-01, -1.6415e-01,\n                      -1.1533e+00,  1.3045e-01,  2.3187e-01, -9.4491e-02,  9.5673e-02,\n                      -3.7021e-01,  6.2191e-01, -7.6247e-02, -2.7160e-02,  2.2064e-01,\n                      -1.4251e-01,  7.0665e-01,  4.8022e-01,  5.1456e-01,  5.9403e-02,\n                       9.6319e-02,  6.7817e-01,  7.5896e-01,  1.0440e-01, -8.2626e-01,\n                      -2.1037e-02, -2.5634e-01,  2.5498e-01,  4.9004e-01,  1.6474e-01,\n                      -4.2712e-03, -4.1767e-01, -2.6839e-02,  3.7826e-01, -3.4818e-01,\n                       3.7059e-01,  1.0642e-01, -6.6875e-02, -6.1889e-04, -1.1302e-01,\n                      -1.9289e-01,  1.4715e-01,  4.0603e-01, -1.5767e-01, -7.7226e-03,\n                      -1.9936e-01, -4.2945e-02, -3.8162e-01,  2.2403e-01, -4.3285e-01,\n                      -2.0797e-01,  4.9482e-01, -9.4220e-02,  6.4867e-01, -8.5883e-01,\n                       2.3201e-01, -3.9931e-01, -1.6298e-01, -4.6695e-01, -7.5557e-01,\n                      -1.3703e-01, -4.4461e-02, -4.4358e-01, -4.8746e-01, -2.0755e-02,\n                       5.6262e-01, -2.7123e-01,  1.9958e-01, -8.9495e-02, -3.4848e-01,\n                       8.0554e-01,  1.8498e-01, -5.2496e-01,  7.8764e-05,  2.1356e-01,\n                       9.6534e-02, -7.5191e-02, -1.7334e-01,  2.4495e-01,  3.2189e-01,\n                      -6.2282e-01], dtype=torch.float64)),\n             ('6.10.convpath.0.2.1.running_var',\n              tensor([0.6414, 0.3865, 0.2646, 0.5096, 0.4047, 0.1970, 0.3226, 0.5637, 0.3440,\n                      0.3541, 0.4674, 0.3225, 0.1961, 0.1173, 0.5818, 0.5889, 0.4848, 0.4777,\n                      0.2309, 0.7209, 0.4128, 0.5210, 0.2913, 0.6647, 0.3132, 0.2866, 0.6578,\n                      0.5395, 0.2824, 0.1886, 0.4176, 0.3766, 0.2507, 0.3825, 0.4105, 0.3394,\n                      0.1934, 0.3391, 0.5375, 0.5433, 0.2968, 0.4990, 0.2610, 0.4648, 0.4129,\n                      0.3881, 0.2339, 0.0946, 0.4866, 0.3744, 0.2706, 0.3314, 0.2142, 0.2408,\n                      0.4084, 0.4188, 0.7038, 0.2284, 0.3762, 0.1916, 0.2609, 0.1654, 0.1990,\n                      0.1289, 0.8634, 0.3761, 0.2976, 0.2396, 0.1889, 0.4088, 0.3160, 0.1541,\n                      0.0417, 0.3735, 0.3887, 0.3390, 0.1843, 0.0834, 0.3020, 0.1834, 0.1979,\n                      0.3647, 0.3858, 0.3345, 0.2233, 0.3868, 0.1747, 0.4079, 0.3515, 0.2489,\n                      0.3010, 0.0881, 0.5005, 0.1223, 0.2784, 0.2946, 0.5440, 0.3266, 0.2057,\n                      0.2562, 0.5064, 0.3070, 0.1140, 0.1560, 0.2148, 0.3614, 0.4097, 0.3100,\n                      0.5722, 0.2523, 0.1679, 0.3997, 0.3828, 0.4530, 0.2136, 0.3676, 0.0991,\n                      0.6538, 0.4771, 0.4951, 0.2567, 0.3742, 0.1669, 0.3427, 0.3490, 0.4726,\n                      0.3186, 0.2675, 0.0856, 0.3531, 0.1977, 0.2559, 0.3485, 0.2448, 0.1307,\n                      0.3590, 0.4089, 0.3407, 0.4064, 0.3257, 0.3726, 0.2805, 0.4574, 0.5170,\n                      0.1330, 0.3319, 0.0519, 0.3706, 0.2655, 0.3802, 0.3535, 0.2284, 0.2750,\n                      0.3911, 0.3946, 0.4676, 0.1197, 0.3369, 0.4623, 0.1608, 0.1480, 0.3302,\n                      0.2723, 0.4390, 0.5125, 0.3372, 0.4923, 0.3396, 0.3069, 0.3190, 0.4701,\n                      0.1405, 0.4134, 0.1572, 0.4722, 0.3488, 0.3847, 0.0824, 0.5984, 0.3066,\n                      0.5788, 0.3256, 0.4023, 0.4478, 0.5611, 0.2623, 0.5534, 0.2696, 0.1722,\n                      0.3553, 0.2713, 0.4837, 0.2472, 0.5842, 0.4377, 0.2905, 0.4765, 0.7614,\n                      0.3932, 0.5070, 0.1500, 0.4627, 0.2270, 0.3273, 0.4728, 0.3960, 0.2141,\n                      0.2091, 0.3392, 0.5939, 0.1966, 0.3834, 0.0813, 0.3618, 0.0824, 0.1792,\n                      0.3296, 0.2856, 0.3791, 0.6279, 0.2755, 0.4400, 0.1532, 0.3508, 0.4913,\n                      0.4238, 0.4194, 0.2251, 0.4307, 0.3805, 0.2169, 0.5264, 0.4282, 0.4021,\n                      0.4860, 0.2623, 0.5181, 0.2361, 0.4318, 0.3855, 0.3994, 0.2376, 0.3360,\n                      0.1627, 0.3166, 0.1957, 0.2909, 0.5306, 0.0904, 0.4314, 0.3043, 0.3069,\n                      0.1932, 0.4822, 0.3189, 0.1674], dtype=torch.float64)),\n             ('6.10.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.11.convs.0.0.weight',\n              tensor([[[ 0.0154],\n                       [-0.0892],\n                       [-0.0168],\n                       ...,\n                       [ 0.0576],\n                       [-0.0533],\n                       [-0.0429]],\n              \n                      [[ 0.0828],\n                       [ 0.0308],\n                       [-0.1305],\n                       ...,\n                       [ 0.0635],\n                       [-0.0497],\n                       [ 0.0555]],\n              \n                      [[ 0.0704],\n                       [-0.0243],\n                       [ 0.0156],\n                       ...,\n                       [ 0.1265],\n                       [-0.0188],\n                       [-0.0606]],\n              \n                      ...,\n              \n                      [[-0.0218],\n                       [-0.0390],\n                       [ 0.2252],\n                       ...,\n                       [-0.0789],\n                       [-0.0200],\n                       [ 0.0347]],\n              \n                      [[ 0.1816],\n                       [-0.0967],\n                       [ 0.1080],\n                       ...,\n                       [-0.1956],\n                       [ 0.0873],\n                       [-0.0842]],\n              \n                      [[-0.0525],\n                       [ 0.2406],\n                       [-0.0742],\n                       ...,\n                       [ 0.0058],\n                       [-0.0531],\n                       [-0.1727]]], dtype=torch.float64)),\n             ('6.11.convs.0.1.weight',\n              tensor([0.9596, 0.9934, 0.9685, 0.9600, 0.9796, 0.9957, 0.9836, 0.9597, 0.9823,\n                      0.9913, 1.0027, 0.9769, 0.9645, 1.0102, 1.0212, 0.9701, 0.9957, 0.9628,\n                      0.9860, 0.9736, 0.9548, 0.9611, 0.9547, 0.9813, 0.9858, 0.9365, 0.9604,\n                      0.9404, 0.9735, 0.9664, 0.9631, 0.9603, 0.9786, 0.9689, 0.9417, 0.9934,\n                      0.9648, 0.9770, 0.9708, 0.9909, 0.9685, 0.9773, 0.9691, 0.9820, 0.9597,\n                      0.9574, 0.9955, 1.0087, 0.9527, 0.9812, 0.9746, 0.9523, 0.9837, 1.0006,\n                      0.9724, 0.9674, 0.9542, 0.9719, 0.9766, 0.9627, 0.9540, 0.9976, 0.9806,\n                      0.9635], dtype=torch.float64)),\n             ('6.11.convs.0.1.bias',\n              tensor([-0.0107,  0.0104, -0.0121, -0.0005,  0.0199,  0.0104, -0.0085, -0.0123,\n                      -0.0101,  0.0068,  0.0012,  0.0063, -0.0050,  0.0176,  0.0203,  0.0073,\n                       0.0096, -0.0027,  0.0075,  0.0069, -0.0050, -0.0132, -0.0021,  0.0021,\n                      -0.0044, -0.0118, -0.0145, -0.0015, -0.0029, -0.0021,  0.0017,  0.0052,\n                       0.0099,  0.0065, -0.0168, -0.0130, -0.0187, -0.0004, -0.0026,  0.0141,\n                       0.0053,  0.0042, -0.0060, -0.0028, -0.0035, -0.0080,  0.0356,  0.0225,\n                       0.0015,  0.0026,  0.0061,  0.0069,  0.0186,  0.0019, -0.0150, -0.0068,\n                      -0.0269,  0.0091, -0.0032,  0.0009, -0.0025,  0.0170,  0.0210, -0.0041],\n                     dtype=torch.float64)),\n             ('6.11.convs.0.1.running_mean',\n              tensor([ 0.4950, -0.2189,  0.5672,  0.2633,  0.1172,  0.0840, -0.6911,  0.2952,\n                      -0.2401, -0.0879,  0.8806,  0.0823, -0.4327,  0.2016, -0.1877, -0.5493,\n                       0.0455,  0.0628, -0.1649, -0.0487,  1.1227,  0.6757, -0.8174, -0.2393,\n                       0.6309, -1.7026, -0.5865, -0.4591, -0.0186,  0.0079, -0.9567,  0.1949,\n                      -0.3394,  0.3199, -0.0524, -0.7097, -0.2581, -0.3622,  0.2799, -1.1128,\n                      -0.6765, -0.7776, -0.4817,  0.0455, -0.6007, -1.1892, -0.5902,  0.2592,\n                      -0.6991, -0.4447, -0.3765, -0.2652, -0.3499,  0.1095, -0.2441,  0.8194,\n                       0.8722, -0.2361, -0.3028, -0.1793,  0.0786,  0.5229, -0.3110, -0.6732],\n                     dtype=torch.float64)),\n             ('6.11.convs.0.1.running_var',\n              tensor([0.6827, 0.1753, 0.4409, 0.5313, 0.1581, 0.2099, 0.1348, 0.1767, 0.1019,\n                      0.1488, 0.1245, 0.3008, 0.7290, 0.1824, 0.1648, 0.1633, 0.1624, 0.4288,\n                      0.2120, 0.1079, 0.3726, 0.1751, 0.5771, 0.1126, 0.3439, 0.3083, 0.9508,\n                      0.5869, 0.4247, 0.3686, 0.3968, 0.8334, 0.3589, 0.2149, 0.1824, 0.1025,\n                      0.1627, 0.8410, 0.1539, 0.2908, 0.1362, 0.1757, 0.2422, 0.2176, 0.1431,\n                      0.3602, 0.1249, 0.3043, 0.3525, 0.1683, 0.7416, 0.2500, 0.1035, 0.1107,\n                      0.4629, 0.2575, 0.3430, 0.2244, 0.1956, 0.2627, 0.3248, 0.1562, 0.1535,\n                      0.2104], dtype=torch.float64)),\n             ('6.11.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.11.convs.1.0.weight',\n              tensor([[[ 0.0854, -0.1115,  0.0910, -0.0257, -0.1021],\n                       [-0.0465, -0.0519,  0.0335, -0.0106, -0.0021],\n                       [-0.0080,  0.0325,  0.0157, -0.1898,  0.0446],\n                       ...,\n                       [ 0.0029,  0.0233, -0.1042,  0.0265,  0.0019],\n                       [ 0.1215,  0.0122,  0.0646, -0.0776,  0.0984],\n                       [ 0.0885,  0.0831,  0.0270,  0.0056, -0.0402]],\n              \n                      [[ 0.0468, -0.1644,  0.0471,  0.0381,  0.0812],\n                       [ 0.0161, -0.1158,  0.0210, -0.0087,  0.0875],\n                       [-0.0499, -0.1038, -0.0260, -0.0874,  0.0154],\n                       ...,\n                       [ 0.0164, -0.0409, -0.0774,  0.0090, -0.0478],\n                       [ 0.0613,  0.1101, -0.0117,  0.0719,  0.1147],\n                       [ 0.0128, -0.0990,  0.0429,  0.1194, -0.0578]],\n              \n                      [[ 0.0901,  0.1092, -0.0311,  0.0363,  0.0239],\n                       [-0.1044,  0.0044,  0.0184, -0.0521,  0.1046],\n                       [ 0.1063, -0.0056,  0.0597,  0.0506,  0.0896],\n                       ...,\n                       [ 0.0290,  0.0758,  0.0007,  0.0491,  0.0408],\n                       [-0.1737,  0.0390, -0.0331,  0.0662,  0.0338],\n                       [-0.0736,  0.0315,  0.0377,  0.0785,  0.1469]],\n              \n                      ...,\n              \n                      [[ 0.1238,  0.0901, -0.0040,  0.0505,  0.0639],\n                       [-0.1210, -0.0307,  0.0020, -0.1090, -0.1993],\n                       [-0.0245, -0.0638, -0.0814,  0.0127,  0.0632],\n                       ...,\n                       [ 0.0482,  0.1729,  0.0074,  0.0028,  0.1392],\n                       [ 0.0398, -0.0963, -0.0877, -0.0545, -0.0195],\n                       [-0.0831, -0.2894, -0.0571,  0.0226,  0.0425]],\n              \n                      [[-0.0260,  0.0724,  0.0384, -0.0503, -0.0473],\n                       [-0.0624, -0.0474, -0.0228, -0.0172, -0.1212],\n                       [ 0.0401,  0.0483,  0.0364, -0.0898,  0.0597],\n                       ...,\n                       [ 0.1320, -0.0026, -0.0678,  0.0190, -0.0085],\n                       [-0.0574,  0.0399, -0.0299, -0.0481,  0.0328],\n                       [ 0.0096, -0.0581, -0.0655, -0.1049,  0.0407]],\n              \n                      [[-0.0368, -0.0310, -0.0578, -0.0234, -0.0223],\n                       [ 0.0004,  0.0856,  0.0966, -0.0549,  0.0098],\n                       [ 0.0087, -0.1206,  0.0490, -0.0564, -0.0399],\n                       ...,\n                       [-0.1280, -0.0396, -0.1476, -0.0600,  0.0106],\n                       [-0.0606,  0.0986,  0.0973, -0.0027, -0.1676],\n                       [ 0.1519, -0.0333, -0.0685,  0.0084, -0.0105]]], dtype=torch.float64)),\n             ('6.11.convs.1.1.weight',\n              tensor([0.9912, 0.9629, 0.9698, 0.9828, 1.0111, 0.9667, 0.9593, 0.9920, 0.9381,\n                      0.9446, 1.0031, 0.9954, 0.9680, 0.9563, 0.9476, 0.9658, 0.9762, 0.9382,\n                      0.9707, 0.9592, 0.9647, 0.9743, 0.9415, 0.9884, 0.9507, 0.9862, 0.9512,\n                      0.9719, 0.9689, 0.9538, 0.9831, 0.9680, 0.9937, 0.9548, 0.9752, 0.9630,\n                      0.9558, 0.9569, 0.9749, 0.9653, 0.9823, 0.9545, 0.9534, 0.9778, 0.9631,\n                      0.9571, 0.9585, 0.9838, 0.9633, 0.9653, 0.9623, 0.9589, 0.9706, 0.9679,\n                      0.9853, 0.9307, 0.9720, 0.9967, 0.9524, 0.9583, 0.9553, 0.9541, 0.9374,\n                      1.0092], dtype=torch.float64)),\n             ('6.11.convs.1.1.bias',\n              tensor([-1.5748e-02,  1.0693e-02, -2.1226e-02, -5.4627e-03,  1.6458e-02,\n                      -1.9048e-02, -4.5592e-03,  7.3531e-04, -1.3906e-02, -1.9597e-02,\n                      -4.8206e-03,  2.0287e-02, -2.4424e-03, -6.8188e-03, -9.2368e-03,\n                      -2.7151e-02, -1.0754e-02, -1.7949e-03, -1.0875e-02, -2.2836e-02,\n                      -6.3336e-03, -1.4975e-02, -3.1525e-02,  6.8423e-03, -4.3383e-03,\n                      -1.5958e-02, -1.0923e-02, -9.1247e-03, -1.6129e-02, -1.1178e-03,\n                       1.4177e-02, -1.2853e-02,  8.0601e-03, -1.7442e-03,  4.6932e-03,\n                      -9.7305e-04,  1.4720e-02, -9.7800e-05,  1.3503e-02,  1.0583e-02,\n                       3.7720e-03, -6.8150e-03,  5.2426e-03,  6.2602e-04,  6.0060e-03,\n                       4.6512e-04, -2.3539e-03,  9.6639e-03, -2.6707e-04, -1.4188e-02,\n                      -5.7223e-03, -1.7490e-02, -7.8416e-03, -1.1736e-03,  1.8619e-03,\n                      -1.7604e-02,  1.0150e-02,  3.2062e-03, -3.0847e-03,  1.7742e-02,\n                      -3.0403e-03, -2.4040e-02, -9.9757e-03,  1.4866e-02],\n                     dtype=torch.float64)),\n             ('6.11.convs.1.1.running_mean',\n              tensor([-0.2740, -0.0949,  0.2010,  1.3845,  0.0017,  0.4114,  0.6638,  0.3778,\n                      -0.3055, -0.1998, -0.1844, -0.4237,  0.4950, -0.2737,  0.0268, -0.2468,\n                       0.2952, -0.5600,  1.0083, -0.6034, -0.4775,  0.2066, -0.0812, -0.1560,\n                      -0.2807,  0.6257,  0.2138,  0.1008, -0.3507, -0.7719, -0.8222,  0.6101,\n                       0.0232,  0.1421, -0.3567, -0.0102,  0.0177, -0.9428, -0.8388,  0.0723,\n                       0.2523, -0.2253,  0.4645, -0.1973, -0.8947,  0.2235, -0.7461, -0.4665,\n                      -0.0245,  0.3221, -0.1248,  0.2347, -0.5281, -0.6544,  0.1756, -0.7534,\n                      -0.3065,  0.1938, -0.4606, -0.3889,  0.2692, -0.6031, -0.5360, -0.5590],\n                     dtype=torch.float64)),\n             ('6.11.convs.1.1.running_var',\n              tensor([0.6629, 0.8150, 0.3461, 0.5726, 0.4242, 0.4047, 0.9175, 0.3921, 0.6273,\n                      0.6134, 0.5717, 0.6220, 0.4768, 0.3834, 0.5831, 0.5335, 0.4269, 0.8289,\n                      0.5826, 0.4038, 0.7147, 0.3588, 1.0183, 0.6034, 0.6989, 0.3481, 0.6373,\n                      0.4182, 0.4307, 0.5236, 0.4801, 0.5984, 0.4570, 0.5264, 0.4452, 0.4235,\n                      0.6046, 0.6539, 0.4712, 0.7682, 0.5044, 0.5716, 0.6081, 0.4782, 0.8307,\n                      0.9970, 0.5274, 0.5695, 0.6155, 0.5787, 0.5771, 0.5059, 0.9497, 0.4340,\n                      0.5326, 0.4216, 0.6013, 0.4343, 0.8269, 0.5728, 0.5538, 0.8755, 0.7744,\n                      0.5532], dtype=torch.float64)),\n             ('6.11.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.11.convs.2.0.weight',\n              tensor([[[ 0.1665],\n                       [ 0.0955],\n                       [ 0.2971],\n                       ...,\n                       [-0.0885],\n                       [-0.2512],\n                       [-0.0910]],\n              \n                      [[ 0.2374],\n                       [ 0.0014],\n                       [-0.1271],\n                       ...,\n                       [ 0.1418],\n                       [-0.3567],\n                       [ 0.1400]],\n              \n                      [[ 0.0375],\n                       [ 0.0116],\n                       [ 0.0495],\n                       ...,\n                       [ 0.0497],\n                       [ 0.2188],\n                       [ 0.0785]],\n              \n                      ...,\n              \n                      [[-0.1332],\n                       [-0.1648],\n                       [-0.1246],\n                       ...,\n                       [ 0.3083],\n                       [ 0.0573],\n                       [-0.0667]],\n              \n                      [[-0.1650],\n                       [ 0.1917],\n                       [ 0.1030],\n                       ...,\n                       [-0.1003],\n                       [ 0.0305],\n                       [-0.1145]],\n              \n                      [[-0.0817],\n                       [ 0.1569],\n                       [ 0.1196],\n                       ...,\n                       [ 0.0515],\n                       [-0.1735],\n                       [-0.1286]]], dtype=torch.float64)),\n             ('6.11.convs.2.1.weight',\n              tensor([ 0.0287,  0.0334,  0.0003,  0.0069,  0.0003,  0.0269, -0.0126,  0.0008,\n                       0.0410, -0.0042,  0.0524,  0.0249, -0.0093, -0.0112,  0.0034,  0.0486,\n                       0.0303,  0.0005,  0.0088,  0.0021, -0.0181, -0.0403, -0.0247, -0.0085,\n                       0.0031,  0.0022, -0.0243, -0.0029, -0.0147,  0.0153, -0.0089, -0.0280,\n                      -0.0057, -0.0098,  0.0081,  0.0091,  0.0104,  0.0160, -0.0080,  0.0301,\n                       0.0259,  0.0348, -0.0097,  0.0355,  0.0114,  0.0048,  0.0140, -0.0075,\n                       0.0151, -0.0277,  0.0091,  0.0064, -0.0121, -0.0130, -0.0239,  0.0113,\n                      -0.0240, -0.0116, -0.0012,  0.0005, -0.0155,  0.0324,  0.0057,  0.0258,\n                      -0.0352,  0.0194,  0.0159,  0.0366,  0.0391,  0.0181, -0.0033,  0.0135,\n                       0.0127, -0.0178, -0.0135, -0.0161, -0.0269, -0.0170,  0.0004,  0.0232,\n                       0.0059, -0.0210, -0.0348, -0.0047,  0.0156, -0.0118,  0.0206,  0.0009,\n                       0.0046, -0.0057,  0.0039, -0.0109, -0.0031,  0.0172,  0.0233, -0.0212,\n                       0.0053, -0.0141,  0.0219,  0.0223, -0.0026, -0.0323, -0.0151,  0.0139,\n                       0.0074, -0.0111,  0.0237, -0.0218,  0.0233, -0.0115,  0.0307, -0.0148,\n                      -0.0211, -0.0209, -0.0111,  0.0224, -0.0259,  0.0490,  0.0083, -0.0083,\n                       0.0043,  0.0356, -0.0058,  0.0014,  0.0199,  0.0105, -0.0235,  0.0087,\n                       0.0162, -0.0141, -0.0016,  0.0174, -0.0121, -0.0089,  0.0133,  0.0101,\n                       0.0228,  0.0002, -0.0016,  0.0056, -0.0135,  0.0209, -0.0235, -0.0100,\n                      -0.0020, -0.0221,  0.0342, -0.0215, -0.0015,  0.0139, -0.0310,  0.0325,\n                      -0.0290, -0.0249, -0.0173,  0.0232,  0.0103,  0.0168,  0.0160,  0.0059,\n                       0.0007,  0.0088,  0.0130, -0.0097,  0.0070,  0.0026, -0.0141, -0.0006,\n                      -0.0021, -0.0179,  0.0069, -0.0132,  0.0123,  0.0203, -0.0315, -0.0154,\n                      -0.0227, -0.0147,  0.0072,  0.0074, -0.0282,  0.0064,  0.0228,  0.0005,\n                       0.0122, -0.0074,  0.0015, -0.0156,  0.0205,  0.0072,  0.0245,  0.0050,\n                      -0.0392,  0.0133,  0.0159, -0.0459, -0.0314,  0.0025,  0.0024,  0.0180,\n                      -0.0067,  0.0284,  0.0295, -0.0149, -0.0010, -0.0365,  0.0099, -0.0068,\n                       0.0010,  0.0085, -0.0128, -0.0064,  0.0008,  0.0419, -0.0130, -0.0106,\n                      -0.0170,  0.0097, -0.0085, -0.0269, -0.0009, -0.0016, -0.0377,  0.0054,\n                      -0.0137,  0.0297, -0.0265,  0.0125, -0.0103,  0.0156,  0.0175,  0.0074,\n                       0.0199, -0.0169, -0.0022,  0.0262,  0.0093, -0.0014, -0.0037,  0.0275,\n                      -0.0198,  0.0008,  0.0179,  0.0190,  0.0307, -0.0277,  0.0148, -0.0138,\n                      -0.0060, -0.0239, -0.0031,  0.0268,  0.0181,  0.0372, -0.0300, -0.0233],\n                     dtype=torch.float64)),\n             ('6.11.convs.2.1.bias',\n              tensor([-3.9141e-04,  8.0634e-03,  1.0125e-02,  1.4286e-02,  1.3735e-03,\n                       5.3951e-03,  7.5824e-03, -6.3267e-04,  9.9568e-03,  1.2924e-02,\n                       1.3563e-02, -7.5017e-03,  8.4580e-03, -3.2558e-03,  9.9148e-03,\n                       1.8319e-03,  2.6651e-02, -5.1961e-04,  1.0177e-02, -5.0358e-04,\n                      -3.1162e-03,  1.1485e-03,  2.3449e-03,  5.7579e-03,  2.0148e-03,\n                      -1.6503e-02,  2.6855e-03,  3.9335e-03,  5.0946e-03, -2.4864e-03,\n                       4.5914e-04,  5.7783e-03, -5.6906e-03,  2.0783e-02,  6.2166e-03,\n                       1.6246e-02, -5.0117e-03,  1.8415e-02,  6.7536e-03,  1.2699e-02,\n                       1.5044e-03,  2.0635e-02, -1.0137e-02, -7.4635e-04,  3.4748e-03,\n                      -1.2583e-02,  1.1584e-02,  1.0432e-04, -1.1415e-02,  7.4176e-03,\n                       9.8773e-03,  4.2872e-03,  6.3857e-03,  1.1473e-02,  7.5385e-03,\n                       1.9569e-02,  9.6758e-03,  1.7637e-03,  1.2172e-02, -6.1527e-04,\n                       3.1739e-03,  3.6395e-03,  8.6972e-03,  8.2982e-03, -4.3376e-03,\n                       6.1956e-03, -1.0330e-02,  1.5533e-02,  5.4485e-03, -1.4536e-02,\n                       6.5557e-03,  2.1886e-03,  1.2654e-03, -7.3626e-03,  1.3961e-02,\n                       3.2203e-03,  3.8345e-03,  5.2962e-03,  3.5489e-03,  8.7098e-03,\n                       5.1441e-03, -5.6493e-03,  1.2580e-02,  4.9796e-03, -4.0797e-03,\n                       1.9536e-02, -6.4345e-04,  8.5748e-03,  1.5892e-02,  1.1218e-03,\n                       1.3201e-03,  8.9287e-03,  1.0843e-02, -4.6612e-03,  9.9995e-03,\n                      -1.3770e-02,  1.0499e-02,  1.1785e-03,  1.8498e-02, -3.4479e-03,\n                       1.8951e-02,  1.4431e-02,  5.9199e-03,  8.4126e-03,  1.7128e-04,\n                      -8.5813e-05, -2.8638e-03,  3.3997e-03,  8.3548e-03,  5.2371e-03,\n                      -1.2303e-02, -8.5048e-03,  5.5197e-03,  1.7341e-02,  1.2428e-02,\n                       5.6500e-03,  1.1565e-02,  2.2414e-03,  6.1242e-03, -1.6087e-02,\n                      -6.1538e-04,  8.0821e-03, -1.8215e-03, -2.8419e-03,  3.2766e-03,\n                       1.1355e-02,  1.1704e-02,  5.3001e-03,  5.8542e-03,  1.4611e-02,\n                       7.1493e-03,  6.6420e-03,  1.3843e-02,  7.1460e-03,  1.3853e-02,\n                      -1.1961e-02,  6.4787e-03,  4.9110e-03,  6.9287e-03,  1.0113e-03,\n                       1.4356e-02, -8.8628e-03,  1.5570e-02,  4.3827e-03, -7.6180e-03,\n                       1.5298e-02, -2.6279e-03, -7.0567e-04,  1.2226e-02,  1.0264e-02,\n                       5.6292e-03,  1.4108e-02,  9.7730e-03,  1.2464e-02,  1.3172e-02,\n                       1.0309e-02, -9.3897e-04,  4.8680e-03, -1.0985e-03, -9.7914e-03,\n                       1.8173e-03, -3.9861e-03, -2.5794e-03,  8.9996e-03,  1.4294e-02,\n                      -2.4580e-03, -1.2432e-02,  1.0035e-02,  7.1383e-03,  1.7669e-02,\n                       3.5820e-03,  2.6287e-03,  6.8362e-03,  1.2864e-02, -1.3407e-02,\n                       8.9756e-03,  1.5456e-03,  1.5476e-02,  1.1778e-03,  3.0518e-03,\n                      -6.6359e-03,  1.3613e-02, -3.8887e-03, -7.0535e-03,  1.3730e-02,\n                       7.4535e-03,  1.5217e-02,  1.0624e-02,  2.7994e-03,  7.9460e-03,\n                       6.4029e-03,  1.7332e-03,  8.2180e-03,  3.8802e-04,  2.9754e-03,\n                       5.1203e-03,  5.0671e-03,  4.8154e-03,  7.6486e-03,  1.4512e-02,\n                       6.9504e-04,  2.4737e-02,  1.9011e-02,  2.1740e-02,  1.2979e-02,\n                      -3.5348e-03,  8.7237e-03, -9.1532e-03,  7.2170e-03,  1.2567e-02,\n                       1.6782e-02,  1.0727e-02,  1.3058e-02,  4.3813e-03,  8.6895e-03,\n                      -9.6833e-04,  3.9261e-03,  1.7278e-02,  5.9452e-03,  2.4141e-03,\n                      -1.1391e-02,  2.5442e-03,  3.7994e-03,  1.5546e-02, -1.0604e-03,\n                       4.2490e-03, -7.7515e-03,  7.7381e-04, -1.4722e-02,  1.4590e-02,\n                       5.2157e-03, -4.1489e-03,  7.5514e-03,  6.9254e-03,  4.2418e-03,\n                       9.1679e-03,  4.0182e-03, -6.2320e-03,  1.0112e-02,  3.4802e-03,\n                      -3.5700e-03,  3.8317e-03,  1.0593e-03,  6.4606e-03,  4.8826e-03,\n                       1.2504e-02,  6.2789e-03,  3.8198e-03, -3.1651e-03, -7.3658e-03,\n                       1.7694e-02,  2.1122e-02,  2.0354e-02,  1.5853e-02,  8.8716e-03,\n                       2.8387e-03], dtype=torch.float64)),\n             ('6.11.convs.2.1.running_mean',\n              tensor([ 3.4907e-01,  1.0975e+00,  8.3447e-01,  5.2128e-01, -2.9051e-01,\n                       2.9902e-01, -1.3224e-01,  7.1919e-01,  5.2518e-01, -2.3102e-01,\n                      -4.8224e-01,  3.0748e-01,  1.5505e-01,  1.1025e-02, -3.3948e-01,\n                      -1.0461e-01, -5.2431e-01, -3.7457e-02, -9.3342e-02,  3.2749e-01,\n                       2.8768e-01,  7.4168e-01, -4.5377e-01,  3.5318e-01,  1.3855e-01,\n                      -8.1217e-02, -4.7301e-01,  1.3861e-01,  9.7304e-02,  3.5675e-01,\n                       2.9994e-01,  7.1146e-01, -2.0036e-01, -3.2643e-02, -5.1212e-02,\n                      -2.3895e-01, -2.6988e-01,  3.2192e-01,  4.5530e-02,  1.2316e+00,\n                      -6.6901e-01,  6.9515e-01,  2.5155e-01,  1.8132e-01, -7.5381e-01,\n                      -3.9510e-01, -4.4947e-01, -1.7423e-01,  1.7089e-01, -1.4083e-01,\n                      -3.6898e-01, -3.4458e-01, -1.3817e-01,  1.4257e-01, -4.3154e-04,\n                      -2.2697e-01,  5.6637e-01,  2.8352e-01,  1.9710e-01,  9.3985e-02,\n                      -1.2462e-01, -4.6928e-03, -1.4336e-01,  8.6031e-02,  7.3851e-01,\n                       1.3210e-01,  5.2813e-01, -8.1552e-01,  4.0679e-01,  1.2003e+00,\n                       1.3908e-01, -4.6754e-01, -7.2263e-02, -4.5304e-01,  5.0017e-01,\n                       1.3231e-01, -5.2738e-01, -2.5835e-01, -1.4379e-01, -9.5151e-03,\n                      -4.0354e-01, -3.2201e-01, -4.2015e-01,  4.0586e-02,  3.9121e-02,\n                      -1.2986e-01,  1.6395e-02,  4.7344e-01,  6.6087e-01, -3.1110e-01,\n                       7.2352e-01,  4.8726e-02, -1.2104e-01,  4.1115e-01,  4.5737e-02,\n                       5.1839e-01, -9.1699e-01, -7.8547e-02,  1.0196e-02,  4.4483e-01,\n                      -3.7035e-01,  2.8131e-01, -1.6556e-01, -3.7337e-01,  1.0925e-01,\n                      -5.0882e-02,  3.5042e-01, -7.5298e-01, -5.5560e-01,  2.7920e-01,\n                      -2.0436e-01,  1.5936e-01,  7.3897e-01, -2.0633e-01, -2.2686e-01,\n                      -3.3010e-01, -9.2319e-02, -7.6125e-01,  2.1368e-01, -1.4402e-01,\n                      -1.3299e-01, -1.5437e-02, -3.5225e-02,  3.9060e-01,  2.7066e-01,\n                       3.4418e-01,  3.1973e-01,  2.4917e-01,  2.8555e-01,  2.4531e-02,\n                      -3.0442e-01, -8.4320e-03,  1.4430e-01, -2.6868e-01,  2.7234e-02,\n                      -3.1994e-01,  9.4882e-02,  2.7606e-02,  4.5356e-02,  2.9554e-01,\n                      -3.2703e-01,  2.0529e-01, -2.2938e-01,  1.5854e-01,  1.1606e-01,\n                       1.0990e+00,  1.0217e-01, -6.3256e-01, -2.8041e-01, -5.9742e-01,\n                      -4.6316e-01, -4.9943e-01,  3.3065e-01,  4.1759e-01,  2.5410e-01,\n                       7.3505e-02, -1.9015e-01, -2.3267e-01, -7.0669e-01, -1.1676e-01,\n                       5.0032e-01, -6.5113e-01, -9.3694e-02,  7.6357e-02, -2.0035e-01,\n                      -6.4756e-01,  1.3382e+00, -1.3862e-01, -3.0377e-01,  2.7887e-01,\n                       4.9738e-03, -2.3537e-01,  5.8073e-02,  1.8501e-01,  2.2573e-01,\n                       1.9967e-01,  8.4538e-01, -1.5261e-01, -6.2222e-01, -4.3743e-01,\n                      -3.1208e-01,  9.1004e-02,  1.6211e-01, -1.5909e-02,  5.6480e-01,\n                       2.2774e-01, -1.2508e-01, -2.3965e-01, -1.3479e-01, -2.2823e-01,\n                       1.6182e-01, -3.9262e-01, -2.8745e-01, -1.6059e-01, -1.7430e-01,\n                      -5.6459e-01,  1.7784e-01, -1.0801e-01, -5.8403e-01,  2.1295e-02,\n                      -3.0989e-03,  6.8947e-02, -7.2755e-01,  8.0429e-01,  6.5535e-02,\n                      -3.8094e-01,  1.7630e-02,  6.5602e-02,  7.6656e-01, -9.7309e-01,\n                       6.1990e-01,  4.2762e-02,  8.4209e-02, -5.0984e-01,  1.3233e-01,\n                       5.0768e-01,  1.4121e-01,  1.1936e-01, -5.2422e-01,  1.9140e-01,\n                       6.9382e-02, -2.3407e-01, -2.3527e-01, -3.0487e-01,  2.8265e-01,\n                       2.2452e-01, -2.9291e-01,  3.9142e-01,  1.2703e-01,  8.0181e-01,\n                      -2.4266e-01, -2.5739e-01, -1.2371e-01, -7.5394e-02, -8.5431e-02,\n                       2.9134e-01,  6.2795e-02,  1.0810e-02, -5.1935e-01,  5.8161e-01,\n                      -5.7877e-02,  2.2322e-01, -5.8455e-01,  2.9310e-01,  6.1642e-01,\n                       3.3634e-01,  3.4446e-02, -5.2707e-02, -1.8586e-01,  4.7381e-01,\n                       2.4695e-01, -1.7676e-01,  1.9784e-01, -4.2809e-01, -1.3898e-01,\n                      -1.9006e-01], dtype=torch.float64)),\n             ('6.11.convs.2.1.running_var',\n              tensor([0.4041, 0.5088, 0.2466, 0.3358, 0.0859, 0.5084, 0.1815, 0.2342, 0.3926,\n                      0.4455, 0.3380, 0.3973, 0.3118, 0.3324, 0.3818, 0.5277, 0.4144, 0.2324,\n                      0.2750, 0.2488, 0.4377, 0.5214, 0.4501, 0.3516, 0.5036, 0.1696, 0.3078,\n                      0.0954, 0.1928, 0.3162, 0.3688, 0.3521, 0.1933, 0.2428, 0.2941, 0.4190,\n                      0.1252, 0.3590, 0.3396, 0.3514, 0.4784, 0.4142, 0.1818, 0.4453, 0.3781,\n                      0.4151, 0.2098, 0.2334, 0.3363, 0.3920, 0.3204, 0.3814, 0.3976, 0.2580,\n                      0.3838, 0.1142, 0.5447, 0.5769, 0.4246, 0.3364, 0.2043, 0.4817, 0.1496,\n                      0.3479, 0.3235, 0.3930, 0.5187, 0.4929, 0.3724, 0.7292, 0.1621, 0.2560,\n                      0.1837, 0.5179, 0.3210, 0.1549, 0.5898, 0.1526, 0.5336, 0.3186, 0.2536,\n                      0.4074, 0.5451, 0.2794, 0.3199, 0.3121, 0.2962, 0.1719, 0.2281, 0.2186,\n                      0.3387, 0.2662, 0.2532, 0.3475, 0.3452, 0.2794, 0.5138, 0.2463, 0.4809,\n                      0.3081, 0.3501, 0.4933, 0.2343, 0.2715, 0.2429, 0.2683, 0.4334, 0.7463,\n                      0.7225, 0.1995, 0.3021, 0.5213, 0.4687, 0.4247, 0.4333, 0.4714, 0.3188,\n                      0.3949, 0.2066, 0.2932, 0.1162, 0.4556, 0.3654, 0.0972, 0.3851, 0.3361,\n                      0.3994, 0.2667, 0.3424, 0.1899, 0.0627, 0.4577, 0.2910, 0.4304, 0.2704,\n                      0.2596, 0.3100, 0.1396, 0.1677, 0.2925, 0.2879, 0.1875, 0.4363, 0.2424,\n                      0.1326, 0.6246, 0.3400, 0.5680, 0.0618, 0.3628, 0.5246, 0.3419, 0.2571,\n                      0.5892, 0.4431, 0.4687, 0.1958, 0.3582, 0.3042, 0.0947, 0.2855, 0.3153,\n                      0.2800, 0.2818, 0.3723, 0.3595, 0.5450, 0.1248, 0.2607, 0.4605, 0.2021,\n                      0.1692, 0.3475, 0.2850, 0.4515, 0.6024, 0.3446, 0.3902, 0.2548, 0.2524,\n                      0.4572, 0.3328, 0.2283, 0.2228, 0.2460, 0.2907, 0.1223, 0.2900, 0.2742,\n                      0.0942, 0.3581, 0.1487, 0.3447, 0.5676, 0.3000, 0.5342, 0.3547, 0.2202,\n                      0.3219, 0.2116, 0.1768, 0.2955, 0.3635, 0.6483, 0.3323, 0.4829, 0.1149,\n                      0.0802, 0.2705, 0.4032, 0.1234, 0.1683, 0.1140, 0.4022, 0.2817, 0.2835,\n                      0.3301, 0.1958, 0.3088, 0.5258, 0.0648, 0.2727, 0.3238, 0.2582, 0.5038,\n                      0.2845, 0.2742, 0.1998, 0.3688, 0.4831, 0.4021, 0.3616, 0.3976, 0.4253,\n                      0.1921, 0.4696, 0.2922, 0.1325, 0.2844, 0.3660, 0.2176, 0.1321, 0.4654,\n                      0.2659, 0.4366, 0.2134, 0.2079, 0.4556, 0.0953, 0.4804, 0.2391, 0.4423,\n                      0.3008, 0.5873, 0.2853, 0.3567], dtype=torch.float64)),\n             ('6.11.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.11.convpath.0.0.0.weight',\n              tensor([[[ 0.0154],\n                       [-0.0892],\n                       [-0.0168],\n                       ...,\n                       [ 0.0576],\n                       [-0.0533],\n                       [-0.0429]],\n              \n                      [[ 0.0828],\n                       [ 0.0308],\n                       [-0.1305],\n                       ...,\n                       [ 0.0635],\n                       [-0.0497],\n                       [ 0.0555]],\n              \n                      [[ 0.0704],\n                       [-0.0243],\n                       [ 0.0156],\n                       ...,\n                       [ 0.1265],\n                       [-0.0188],\n                       [-0.0606]],\n              \n                      ...,\n              \n                      [[-0.0218],\n                       [-0.0390],\n                       [ 0.2252],\n                       ...,\n                       [-0.0789],\n                       [-0.0200],\n                       [ 0.0347]],\n              \n                      [[ 0.1816],\n                       [-0.0967],\n                       [ 0.1080],\n                       ...,\n                       [-0.1956],\n                       [ 0.0873],\n                       [-0.0842]],\n              \n                      [[-0.0525],\n                       [ 0.2406],\n                       [-0.0742],\n                       ...,\n                       [ 0.0058],\n                       [-0.0531],\n                       [-0.1727]]], dtype=torch.float64)),\n             ('6.11.convpath.0.0.1.weight',\n              tensor([0.9596, 0.9934, 0.9685, 0.9600, 0.9796, 0.9957, 0.9836, 0.9597, 0.9823,\n                      0.9913, 1.0027, 0.9769, 0.9645, 1.0102, 1.0212, 0.9701, 0.9957, 0.9628,\n                      0.9860, 0.9736, 0.9548, 0.9611, 0.9547, 0.9813, 0.9858, 0.9365, 0.9604,\n                      0.9404, 0.9735, 0.9664, 0.9631, 0.9603, 0.9786, 0.9689, 0.9417, 0.9934,\n                      0.9648, 0.9770, 0.9708, 0.9909, 0.9685, 0.9773, 0.9691, 0.9820, 0.9597,\n                      0.9574, 0.9955, 1.0087, 0.9527, 0.9812, 0.9746, 0.9523, 0.9837, 1.0006,\n                      0.9724, 0.9674, 0.9542, 0.9719, 0.9766, 0.9627, 0.9540, 0.9976, 0.9806,\n                      0.9635], dtype=torch.float64)),\n             ('6.11.convpath.0.0.1.bias',\n              tensor([-0.0107,  0.0104, -0.0121, -0.0005,  0.0199,  0.0104, -0.0085, -0.0123,\n                      -0.0101,  0.0068,  0.0012,  0.0063, -0.0050,  0.0176,  0.0203,  0.0073,\n                       0.0096, -0.0027,  0.0075,  0.0069, -0.0050, -0.0132, -0.0021,  0.0021,\n                      -0.0044, -0.0118, -0.0145, -0.0015, -0.0029, -0.0021,  0.0017,  0.0052,\n                       0.0099,  0.0065, -0.0168, -0.0130, -0.0187, -0.0004, -0.0026,  0.0141,\n                       0.0053,  0.0042, -0.0060, -0.0028, -0.0035, -0.0080,  0.0356,  0.0225,\n                       0.0015,  0.0026,  0.0061,  0.0069,  0.0186,  0.0019, -0.0150, -0.0068,\n                      -0.0269,  0.0091, -0.0032,  0.0009, -0.0025,  0.0170,  0.0210, -0.0041],\n                     dtype=torch.float64)),\n             ('6.11.convpath.0.0.1.running_mean',\n              tensor([ 0.4950, -0.2189,  0.5672,  0.2633,  0.1172,  0.0840, -0.6911,  0.2952,\n                      -0.2401, -0.0879,  0.8806,  0.0823, -0.4327,  0.2016, -0.1877, -0.5493,\n                       0.0455,  0.0628, -0.1649, -0.0487,  1.1227,  0.6757, -0.8174, -0.2393,\n                       0.6309, -1.7026, -0.5865, -0.4591, -0.0186,  0.0079, -0.9567,  0.1949,\n                      -0.3394,  0.3199, -0.0524, -0.7097, -0.2581, -0.3622,  0.2799, -1.1128,\n                      -0.6765, -0.7776, -0.4817,  0.0455, -0.6007, -1.1892, -0.5902,  0.2592,\n                      -0.6991, -0.4447, -0.3765, -0.2652, -0.3499,  0.1095, -0.2441,  0.8194,\n                       0.8722, -0.2361, -0.3028, -0.1793,  0.0786,  0.5229, -0.3110, -0.6732],\n                     dtype=torch.float64)),\n             ('6.11.convpath.0.0.1.running_var',\n              tensor([0.6827, 0.1753, 0.4409, 0.5313, 0.1581, 0.2099, 0.1348, 0.1767, 0.1019,\n                      0.1488, 0.1245, 0.3008, 0.7290, 0.1824, 0.1648, 0.1633, 0.1624, 0.4288,\n                      0.2120, 0.1079, 0.3726, 0.1751, 0.5771, 0.1126, 0.3439, 0.3083, 0.9508,\n                      0.5869, 0.4247, 0.3686, 0.3968, 0.8334, 0.3589, 0.2149, 0.1824, 0.1025,\n                      0.1627, 0.8410, 0.1539, 0.2908, 0.1362, 0.1757, 0.2422, 0.2176, 0.1431,\n                      0.3602, 0.1249, 0.3043, 0.3525, 0.1683, 0.7416, 0.2500, 0.1035, 0.1107,\n                      0.4629, 0.2575, 0.3430, 0.2244, 0.1956, 0.2627, 0.3248, 0.1562, 0.1535,\n                      0.2104], dtype=torch.float64)),\n             ('6.11.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.11.convpath.0.1.0.weight',\n              tensor([[[ 0.0854, -0.1115,  0.0910, -0.0257, -0.1021],\n                       [-0.0465, -0.0519,  0.0335, -0.0106, -0.0021],\n                       [-0.0080,  0.0325,  0.0157, -0.1898,  0.0446],\n                       ...,\n                       [ 0.0029,  0.0233, -0.1042,  0.0265,  0.0019],\n                       [ 0.1215,  0.0122,  0.0646, -0.0776,  0.0984],\n                       [ 0.0885,  0.0831,  0.0270,  0.0056, -0.0402]],\n              \n                      [[ 0.0468, -0.1644,  0.0471,  0.0381,  0.0812],\n                       [ 0.0161, -0.1158,  0.0210, -0.0087,  0.0875],\n                       [-0.0499, -0.1038, -0.0260, -0.0874,  0.0154],\n                       ...,\n                       [ 0.0164, -0.0409, -0.0774,  0.0090, -0.0478],\n                       [ 0.0613,  0.1101, -0.0117,  0.0719,  0.1147],\n                       [ 0.0128, -0.0990,  0.0429,  0.1194, -0.0578]],\n              \n                      [[ 0.0901,  0.1092, -0.0311,  0.0363,  0.0239],\n                       [-0.1044,  0.0044,  0.0184, -0.0521,  0.1046],\n                       [ 0.1063, -0.0056,  0.0597,  0.0506,  0.0896],\n                       ...,\n                       [ 0.0290,  0.0758,  0.0007,  0.0491,  0.0408],\n                       [-0.1737,  0.0390, -0.0331,  0.0662,  0.0338],\n                       [-0.0736,  0.0315,  0.0377,  0.0785,  0.1469]],\n              \n                      ...,\n              \n                      [[ 0.1238,  0.0901, -0.0040,  0.0505,  0.0639],\n                       [-0.1210, -0.0307,  0.0020, -0.1090, -0.1993],\n                       [-0.0245, -0.0638, -0.0814,  0.0127,  0.0632],\n                       ...,\n                       [ 0.0482,  0.1729,  0.0074,  0.0028,  0.1392],\n                       [ 0.0398, -0.0963, -0.0877, -0.0545, -0.0195],\n                       [-0.0831, -0.2894, -0.0571,  0.0226,  0.0425]],\n              \n                      [[-0.0260,  0.0724,  0.0384, -0.0503, -0.0473],\n                       [-0.0624, -0.0474, -0.0228, -0.0172, -0.1212],\n                       [ 0.0401,  0.0483,  0.0364, -0.0898,  0.0597],\n                       ...,\n                       [ 0.1320, -0.0026, -0.0678,  0.0190, -0.0085],\n                       [-0.0574,  0.0399, -0.0299, -0.0481,  0.0328],\n                       [ 0.0096, -0.0581, -0.0655, -0.1049,  0.0407]],\n              \n                      [[-0.0368, -0.0310, -0.0578, -0.0234, -0.0223],\n                       [ 0.0004,  0.0856,  0.0966, -0.0549,  0.0098],\n                       [ 0.0087, -0.1206,  0.0490, -0.0564, -0.0399],\n                       ...,\n                       [-0.1280, -0.0396, -0.1476, -0.0600,  0.0106],\n                       [-0.0606,  0.0986,  0.0973, -0.0027, -0.1676],\n                       [ 0.1519, -0.0333, -0.0685,  0.0084, -0.0105]]], dtype=torch.float64)),\n             ('6.11.convpath.0.1.1.weight',\n              tensor([0.9912, 0.9629, 0.9698, 0.9828, 1.0111, 0.9667, 0.9593, 0.9920, 0.9381,\n                      0.9446, 1.0031, 0.9954, 0.9680, 0.9563, 0.9476, 0.9658, 0.9762, 0.9382,\n                      0.9707, 0.9592, 0.9647, 0.9743, 0.9415, 0.9884, 0.9507, 0.9862, 0.9512,\n                      0.9719, 0.9689, 0.9538, 0.9831, 0.9680, 0.9937, 0.9548, 0.9752, 0.9630,\n                      0.9558, 0.9569, 0.9749, 0.9653, 0.9823, 0.9545, 0.9534, 0.9778, 0.9631,\n                      0.9571, 0.9585, 0.9838, 0.9633, 0.9653, 0.9623, 0.9589, 0.9706, 0.9679,\n                      0.9853, 0.9307, 0.9720, 0.9967, 0.9524, 0.9583, 0.9553, 0.9541, 0.9374,\n                      1.0092], dtype=torch.float64)),\n             ('6.11.convpath.0.1.1.bias',\n              tensor([-1.5748e-02,  1.0693e-02, -2.1226e-02, -5.4627e-03,  1.6458e-02,\n                      -1.9048e-02, -4.5592e-03,  7.3531e-04, -1.3906e-02, -1.9597e-02,\n                      -4.8206e-03,  2.0287e-02, -2.4424e-03, -6.8188e-03, -9.2368e-03,\n                      -2.7151e-02, -1.0754e-02, -1.7949e-03, -1.0875e-02, -2.2836e-02,\n                      -6.3336e-03, -1.4975e-02, -3.1525e-02,  6.8423e-03, -4.3383e-03,\n                      -1.5958e-02, -1.0923e-02, -9.1247e-03, -1.6129e-02, -1.1178e-03,\n                       1.4177e-02, -1.2853e-02,  8.0601e-03, -1.7442e-03,  4.6932e-03,\n                      -9.7305e-04,  1.4720e-02, -9.7800e-05,  1.3503e-02,  1.0583e-02,\n                       3.7720e-03, -6.8150e-03,  5.2426e-03,  6.2602e-04,  6.0060e-03,\n                       4.6512e-04, -2.3539e-03,  9.6639e-03, -2.6707e-04, -1.4188e-02,\n                      -5.7223e-03, -1.7490e-02, -7.8416e-03, -1.1736e-03,  1.8619e-03,\n                      -1.7604e-02,  1.0150e-02,  3.2062e-03, -3.0847e-03,  1.7742e-02,\n                      -3.0403e-03, -2.4040e-02, -9.9757e-03,  1.4866e-02],\n                     dtype=torch.float64)),\n             ('6.11.convpath.0.1.1.running_mean',\n              tensor([-0.2740, -0.0949,  0.2010,  1.3845,  0.0017,  0.4114,  0.6638,  0.3778,\n                      -0.3055, -0.1998, -0.1844, -0.4237,  0.4950, -0.2737,  0.0268, -0.2468,\n                       0.2952, -0.5600,  1.0083, -0.6034, -0.4775,  0.2066, -0.0812, -0.1560,\n                      -0.2807,  0.6257,  0.2138,  0.1008, -0.3507, -0.7719, -0.8222,  0.6101,\n                       0.0232,  0.1421, -0.3567, -0.0102,  0.0177, -0.9428, -0.8388,  0.0723,\n                       0.2523, -0.2253,  0.4645, -0.1973, -0.8947,  0.2235, -0.7461, -0.4665,\n                      -0.0245,  0.3221, -0.1248,  0.2347, -0.5281, -0.6544,  0.1756, -0.7534,\n                      -0.3065,  0.1938, -0.4606, -0.3889,  0.2692, -0.6031, -0.5360, -0.5590],\n                     dtype=torch.float64)),\n             ('6.11.convpath.0.1.1.running_var',\n              tensor([0.6629, 0.8150, 0.3461, 0.5726, 0.4242, 0.4047, 0.9175, 0.3921, 0.6273,\n                      0.6134, 0.5717, 0.6220, 0.4768, 0.3834, 0.5831, 0.5335, 0.4269, 0.8289,\n                      0.5826, 0.4038, 0.7147, 0.3588, 1.0183, 0.6034, 0.6989, 0.3481, 0.6373,\n                      0.4182, 0.4307, 0.5236, 0.4801, 0.5984, 0.4570, 0.5264, 0.4452, 0.4235,\n                      0.6046, 0.6539, 0.4712, 0.7682, 0.5044, 0.5716, 0.6081, 0.4782, 0.8307,\n                      0.9970, 0.5274, 0.5695, 0.6155, 0.5787, 0.5771, 0.5059, 0.9497, 0.4340,\n                      0.5326, 0.4216, 0.6013, 0.4343, 0.8269, 0.5728, 0.5538, 0.8755, 0.7744,\n                      0.5532], dtype=torch.float64)),\n             ('6.11.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.11.convpath.0.2.0.weight',\n              tensor([[[ 0.1665],\n                       [ 0.0955],\n                       [ 0.2971],\n                       ...,\n                       [-0.0885],\n                       [-0.2512],\n                       [-0.0910]],\n              \n                      [[ 0.2374],\n                       [ 0.0014],\n                       [-0.1271],\n                       ...,\n                       [ 0.1418],\n                       [-0.3567],\n                       [ 0.1400]],\n              \n                      [[ 0.0375],\n                       [ 0.0116],\n                       [ 0.0495],\n                       ...,\n                       [ 0.0497],\n                       [ 0.2188],\n                       [ 0.0785]],\n              \n                      ...,\n              \n                      [[-0.1332],\n                       [-0.1648],\n                       [-0.1246],\n                       ...,\n                       [ 0.3083],\n                       [ 0.0573],\n                       [-0.0667]],\n              \n                      [[-0.1650],\n                       [ 0.1917],\n                       [ 0.1030],\n                       ...,\n                       [-0.1003],\n                       [ 0.0305],\n                       [-0.1145]],\n              \n                      [[-0.0817],\n                       [ 0.1569],\n                       [ 0.1196],\n                       ...,\n                       [ 0.0515],\n                       [-0.1735],\n                       [-0.1286]]], dtype=torch.float64)),\n             ('6.11.convpath.0.2.1.weight',\n              tensor([ 0.0287,  0.0334,  0.0003,  0.0069,  0.0003,  0.0269, -0.0126,  0.0008,\n                       0.0410, -0.0042,  0.0524,  0.0249, -0.0093, -0.0112,  0.0034,  0.0486,\n                       0.0303,  0.0005,  0.0088,  0.0021, -0.0181, -0.0403, -0.0247, -0.0085,\n                       0.0031,  0.0022, -0.0243, -0.0029, -0.0147,  0.0153, -0.0089, -0.0280,\n                      -0.0057, -0.0098,  0.0081,  0.0091,  0.0104,  0.0160, -0.0080,  0.0301,\n                       0.0259,  0.0348, -0.0097,  0.0355,  0.0114,  0.0048,  0.0140, -0.0075,\n                       0.0151, -0.0277,  0.0091,  0.0064, -0.0121, -0.0130, -0.0239,  0.0113,\n                      -0.0240, -0.0116, -0.0012,  0.0005, -0.0155,  0.0324,  0.0057,  0.0258,\n                      -0.0352,  0.0194,  0.0159,  0.0366,  0.0391,  0.0181, -0.0033,  0.0135,\n                       0.0127, -0.0178, -0.0135, -0.0161, -0.0269, -0.0170,  0.0004,  0.0232,\n                       0.0059, -0.0210, -0.0348, -0.0047,  0.0156, -0.0118,  0.0206,  0.0009,\n                       0.0046, -0.0057,  0.0039, -0.0109, -0.0031,  0.0172,  0.0233, -0.0212,\n                       0.0053, -0.0141,  0.0219,  0.0223, -0.0026, -0.0323, -0.0151,  0.0139,\n                       0.0074, -0.0111,  0.0237, -0.0218,  0.0233, -0.0115,  0.0307, -0.0148,\n                      -0.0211, -0.0209, -0.0111,  0.0224, -0.0259,  0.0490,  0.0083, -0.0083,\n                       0.0043,  0.0356, -0.0058,  0.0014,  0.0199,  0.0105, -0.0235,  0.0087,\n                       0.0162, -0.0141, -0.0016,  0.0174, -0.0121, -0.0089,  0.0133,  0.0101,\n                       0.0228,  0.0002, -0.0016,  0.0056, -0.0135,  0.0209, -0.0235, -0.0100,\n                      -0.0020, -0.0221,  0.0342, -0.0215, -0.0015,  0.0139, -0.0310,  0.0325,\n                      -0.0290, -0.0249, -0.0173,  0.0232,  0.0103,  0.0168,  0.0160,  0.0059,\n                       0.0007,  0.0088,  0.0130, -0.0097,  0.0070,  0.0026, -0.0141, -0.0006,\n                      -0.0021, -0.0179,  0.0069, -0.0132,  0.0123,  0.0203, -0.0315, -0.0154,\n                      -0.0227, -0.0147,  0.0072,  0.0074, -0.0282,  0.0064,  0.0228,  0.0005,\n                       0.0122, -0.0074,  0.0015, -0.0156,  0.0205,  0.0072,  0.0245,  0.0050,\n                      -0.0392,  0.0133,  0.0159, -0.0459, -0.0314,  0.0025,  0.0024,  0.0180,\n                      -0.0067,  0.0284,  0.0295, -0.0149, -0.0010, -0.0365,  0.0099, -0.0068,\n                       0.0010,  0.0085, -0.0128, -0.0064,  0.0008,  0.0419, -0.0130, -0.0106,\n                      -0.0170,  0.0097, -0.0085, -0.0269, -0.0009, -0.0016, -0.0377,  0.0054,\n                      -0.0137,  0.0297, -0.0265,  0.0125, -0.0103,  0.0156,  0.0175,  0.0074,\n                       0.0199, -0.0169, -0.0022,  0.0262,  0.0093, -0.0014, -0.0037,  0.0275,\n                      -0.0198,  0.0008,  0.0179,  0.0190,  0.0307, -0.0277,  0.0148, -0.0138,\n                      -0.0060, -0.0239, -0.0031,  0.0268,  0.0181,  0.0372, -0.0300, -0.0233],\n                     dtype=torch.float64)),\n             ('6.11.convpath.0.2.1.bias',\n              tensor([-3.9141e-04,  8.0634e-03,  1.0125e-02,  1.4286e-02,  1.3735e-03,\n                       5.3951e-03,  7.5824e-03, -6.3267e-04,  9.9568e-03,  1.2924e-02,\n                       1.3563e-02, -7.5017e-03,  8.4580e-03, -3.2558e-03,  9.9148e-03,\n                       1.8319e-03,  2.6651e-02, -5.1961e-04,  1.0177e-02, -5.0358e-04,\n                      -3.1162e-03,  1.1485e-03,  2.3449e-03,  5.7579e-03,  2.0148e-03,\n                      -1.6503e-02,  2.6855e-03,  3.9335e-03,  5.0946e-03, -2.4864e-03,\n                       4.5914e-04,  5.7783e-03, -5.6906e-03,  2.0783e-02,  6.2166e-03,\n                       1.6246e-02, -5.0117e-03,  1.8415e-02,  6.7536e-03,  1.2699e-02,\n                       1.5044e-03,  2.0635e-02, -1.0137e-02, -7.4635e-04,  3.4748e-03,\n                      -1.2583e-02,  1.1584e-02,  1.0432e-04, -1.1415e-02,  7.4176e-03,\n                       9.8773e-03,  4.2872e-03,  6.3857e-03,  1.1473e-02,  7.5385e-03,\n                       1.9569e-02,  9.6758e-03,  1.7637e-03,  1.2172e-02, -6.1527e-04,\n                       3.1739e-03,  3.6395e-03,  8.6972e-03,  8.2982e-03, -4.3376e-03,\n                       6.1956e-03, -1.0330e-02,  1.5533e-02,  5.4485e-03, -1.4536e-02,\n                       6.5557e-03,  2.1886e-03,  1.2654e-03, -7.3626e-03,  1.3961e-02,\n                       3.2203e-03,  3.8345e-03,  5.2962e-03,  3.5489e-03,  8.7098e-03,\n                       5.1441e-03, -5.6493e-03,  1.2580e-02,  4.9796e-03, -4.0797e-03,\n                       1.9536e-02, -6.4345e-04,  8.5748e-03,  1.5892e-02,  1.1218e-03,\n                       1.3201e-03,  8.9287e-03,  1.0843e-02, -4.6612e-03,  9.9995e-03,\n                      -1.3770e-02,  1.0499e-02,  1.1785e-03,  1.8498e-02, -3.4479e-03,\n                       1.8951e-02,  1.4431e-02,  5.9199e-03,  8.4126e-03,  1.7128e-04,\n                      -8.5813e-05, -2.8638e-03,  3.3997e-03,  8.3548e-03,  5.2371e-03,\n                      -1.2303e-02, -8.5048e-03,  5.5197e-03,  1.7341e-02,  1.2428e-02,\n                       5.6500e-03,  1.1565e-02,  2.2414e-03,  6.1242e-03, -1.6087e-02,\n                      -6.1538e-04,  8.0821e-03, -1.8215e-03, -2.8419e-03,  3.2766e-03,\n                       1.1355e-02,  1.1704e-02,  5.3001e-03,  5.8542e-03,  1.4611e-02,\n                       7.1493e-03,  6.6420e-03,  1.3843e-02,  7.1460e-03,  1.3853e-02,\n                      -1.1961e-02,  6.4787e-03,  4.9110e-03,  6.9287e-03,  1.0113e-03,\n                       1.4356e-02, -8.8628e-03,  1.5570e-02,  4.3827e-03, -7.6180e-03,\n                       1.5298e-02, -2.6279e-03, -7.0567e-04,  1.2226e-02,  1.0264e-02,\n                       5.6292e-03,  1.4108e-02,  9.7730e-03,  1.2464e-02,  1.3172e-02,\n                       1.0309e-02, -9.3897e-04,  4.8680e-03, -1.0985e-03, -9.7914e-03,\n                       1.8173e-03, -3.9861e-03, -2.5794e-03,  8.9996e-03,  1.4294e-02,\n                      -2.4580e-03, -1.2432e-02,  1.0035e-02,  7.1383e-03,  1.7669e-02,\n                       3.5820e-03,  2.6287e-03,  6.8362e-03,  1.2864e-02, -1.3407e-02,\n                       8.9756e-03,  1.5456e-03,  1.5476e-02,  1.1778e-03,  3.0518e-03,\n                      -6.6359e-03,  1.3613e-02, -3.8887e-03, -7.0535e-03,  1.3730e-02,\n                       7.4535e-03,  1.5217e-02,  1.0624e-02,  2.7994e-03,  7.9460e-03,\n                       6.4029e-03,  1.7332e-03,  8.2180e-03,  3.8802e-04,  2.9754e-03,\n                       5.1203e-03,  5.0671e-03,  4.8154e-03,  7.6486e-03,  1.4512e-02,\n                       6.9504e-04,  2.4737e-02,  1.9011e-02,  2.1740e-02,  1.2979e-02,\n                      -3.5348e-03,  8.7237e-03, -9.1532e-03,  7.2170e-03,  1.2567e-02,\n                       1.6782e-02,  1.0727e-02,  1.3058e-02,  4.3813e-03,  8.6895e-03,\n                      -9.6833e-04,  3.9261e-03,  1.7278e-02,  5.9452e-03,  2.4141e-03,\n                      -1.1391e-02,  2.5442e-03,  3.7994e-03,  1.5546e-02, -1.0604e-03,\n                       4.2490e-03, -7.7515e-03,  7.7381e-04, -1.4722e-02,  1.4590e-02,\n                       5.2157e-03, -4.1489e-03,  7.5514e-03,  6.9254e-03,  4.2418e-03,\n                       9.1679e-03,  4.0182e-03, -6.2320e-03,  1.0112e-02,  3.4802e-03,\n                      -3.5700e-03,  3.8317e-03,  1.0593e-03,  6.4606e-03,  4.8826e-03,\n                       1.2504e-02,  6.2789e-03,  3.8198e-03, -3.1651e-03, -7.3658e-03,\n                       1.7694e-02,  2.1122e-02,  2.0354e-02,  1.5853e-02,  8.8716e-03,\n                       2.8387e-03], dtype=torch.float64)),\n             ('6.11.convpath.0.2.1.running_mean',\n              tensor([ 3.4907e-01,  1.0975e+00,  8.3447e-01,  5.2128e-01, -2.9051e-01,\n                       2.9902e-01, -1.3224e-01,  7.1919e-01,  5.2518e-01, -2.3102e-01,\n                      -4.8224e-01,  3.0748e-01,  1.5505e-01,  1.1025e-02, -3.3948e-01,\n                      -1.0461e-01, -5.2431e-01, -3.7457e-02, -9.3342e-02,  3.2749e-01,\n                       2.8768e-01,  7.4168e-01, -4.5377e-01,  3.5318e-01,  1.3855e-01,\n                      -8.1217e-02, -4.7301e-01,  1.3861e-01,  9.7304e-02,  3.5675e-01,\n                       2.9994e-01,  7.1146e-01, -2.0036e-01, -3.2643e-02, -5.1212e-02,\n                      -2.3895e-01, -2.6988e-01,  3.2192e-01,  4.5530e-02,  1.2316e+00,\n                      -6.6901e-01,  6.9515e-01,  2.5155e-01,  1.8132e-01, -7.5381e-01,\n                      -3.9510e-01, -4.4947e-01, -1.7423e-01,  1.7089e-01, -1.4083e-01,\n                      -3.6898e-01, -3.4458e-01, -1.3817e-01,  1.4257e-01, -4.3154e-04,\n                      -2.2697e-01,  5.6637e-01,  2.8352e-01,  1.9710e-01,  9.3985e-02,\n                      -1.2462e-01, -4.6928e-03, -1.4336e-01,  8.6031e-02,  7.3851e-01,\n                       1.3210e-01,  5.2813e-01, -8.1552e-01,  4.0679e-01,  1.2003e+00,\n                       1.3908e-01, -4.6754e-01, -7.2263e-02, -4.5304e-01,  5.0017e-01,\n                       1.3231e-01, -5.2738e-01, -2.5835e-01, -1.4379e-01, -9.5151e-03,\n                      -4.0354e-01, -3.2201e-01, -4.2015e-01,  4.0586e-02,  3.9121e-02,\n                      -1.2986e-01,  1.6395e-02,  4.7344e-01,  6.6087e-01, -3.1110e-01,\n                       7.2352e-01,  4.8726e-02, -1.2104e-01,  4.1115e-01,  4.5737e-02,\n                       5.1839e-01, -9.1699e-01, -7.8547e-02,  1.0196e-02,  4.4483e-01,\n                      -3.7035e-01,  2.8131e-01, -1.6556e-01, -3.7337e-01,  1.0925e-01,\n                      -5.0882e-02,  3.5042e-01, -7.5298e-01, -5.5560e-01,  2.7920e-01,\n                      -2.0436e-01,  1.5936e-01,  7.3897e-01, -2.0633e-01, -2.2686e-01,\n                      -3.3010e-01, -9.2319e-02, -7.6125e-01,  2.1368e-01, -1.4402e-01,\n                      -1.3299e-01, -1.5437e-02, -3.5225e-02,  3.9060e-01,  2.7066e-01,\n                       3.4418e-01,  3.1973e-01,  2.4917e-01,  2.8555e-01,  2.4531e-02,\n                      -3.0442e-01, -8.4320e-03,  1.4430e-01, -2.6868e-01,  2.7234e-02,\n                      -3.1994e-01,  9.4882e-02,  2.7606e-02,  4.5356e-02,  2.9554e-01,\n                      -3.2703e-01,  2.0529e-01, -2.2938e-01,  1.5854e-01,  1.1606e-01,\n                       1.0990e+00,  1.0217e-01, -6.3256e-01, -2.8041e-01, -5.9742e-01,\n                      -4.6316e-01, -4.9943e-01,  3.3065e-01,  4.1759e-01,  2.5410e-01,\n                       7.3505e-02, -1.9015e-01, -2.3267e-01, -7.0669e-01, -1.1676e-01,\n                       5.0032e-01, -6.5113e-01, -9.3694e-02,  7.6357e-02, -2.0035e-01,\n                      -6.4756e-01,  1.3382e+00, -1.3862e-01, -3.0377e-01,  2.7887e-01,\n                       4.9738e-03, -2.3537e-01,  5.8073e-02,  1.8501e-01,  2.2573e-01,\n                       1.9967e-01,  8.4538e-01, -1.5261e-01, -6.2222e-01, -4.3743e-01,\n                      -3.1208e-01,  9.1004e-02,  1.6211e-01, -1.5909e-02,  5.6480e-01,\n                       2.2774e-01, -1.2508e-01, -2.3965e-01, -1.3479e-01, -2.2823e-01,\n                       1.6182e-01, -3.9262e-01, -2.8745e-01, -1.6059e-01, -1.7430e-01,\n                      -5.6459e-01,  1.7784e-01, -1.0801e-01, -5.8403e-01,  2.1295e-02,\n                      -3.0989e-03,  6.8947e-02, -7.2755e-01,  8.0429e-01,  6.5535e-02,\n                      -3.8094e-01,  1.7630e-02,  6.5602e-02,  7.6656e-01, -9.7309e-01,\n                       6.1990e-01,  4.2762e-02,  8.4209e-02, -5.0984e-01,  1.3233e-01,\n                       5.0768e-01,  1.4121e-01,  1.1936e-01, -5.2422e-01,  1.9140e-01,\n                       6.9382e-02, -2.3407e-01, -2.3527e-01, -3.0487e-01,  2.8265e-01,\n                       2.2452e-01, -2.9291e-01,  3.9142e-01,  1.2703e-01,  8.0181e-01,\n                      -2.4266e-01, -2.5739e-01, -1.2371e-01, -7.5394e-02, -8.5431e-02,\n                       2.9134e-01,  6.2795e-02,  1.0810e-02, -5.1935e-01,  5.8161e-01,\n                      -5.7877e-02,  2.2322e-01, -5.8455e-01,  2.9310e-01,  6.1642e-01,\n                       3.3634e-01,  3.4446e-02, -5.2707e-02, -1.8586e-01,  4.7381e-01,\n                       2.4695e-01, -1.7676e-01,  1.9784e-01, -4.2809e-01, -1.3898e-01,\n                      -1.9006e-01], dtype=torch.float64)),\n             ('6.11.convpath.0.2.1.running_var',\n              tensor([0.4041, 0.5088, 0.2466, 0.3358, 0.0859, 0.5084, 0.1815, 0.2342, 0.3926,\n                      0.4455, 0.3380, 0.3973, 0.3118, 0.3324, 0.3818, 0.5277, 0.4144, 0.2324,\n                      0.2750, 0.2488, 0.4377, 0.5214, 0.4501, 0.3516, 0.5036, 0.1696, 0.3078,\n                      0.0954, 0.1928, 0.3162, 0.3688, 0.3521, 0.1933, 0.2428, 0.2941, 0.4190,\n                      0.1252, 0.3590, 0.3396, 0.3514, 0.4784, 0.4142, 0.1818, 0.4453, 0.3781,\n                      0.4151, 0.2098, 0.2334, 0.3363, 0.3920, 0.3204, 0.3814, 0.3976, 0.2580,\n                      0.3838, 0.1142, 0.5447, 0.5769, 0.4246, 0.3364, 0.2043, 0.4817, 0.1496,\n                      0.3479, 0.3235, 0.3930, 0.5187, 0.4929, 0.3724, 0.7292, 0.1621, 0.2560,\n                      0.1837, 0.5179, 0.3210, 0.1549, 0.5898, 0.1526, 0.5336, 0.3186, 0.2536,\n                      0.4074, 0.5451, 0.2794, 0.3199, 0.3121, 0.2962, 0.1719, 0.2281, 0.2186,\n                      0.3387, 0.2662, 0.2532, 0.3475, 0.3452, 0.2794, 0.5138, 0.2463, 0.4809,\n                      0.3081, 0.3501, 0.4933, 0.2343, 0.2715, 0.2429, 0.2683, 0.4334, 0.7463,\n                      0.7225, 0.1995, 0.3021, 0.5213, 0.4687, 0.4247, 0.4333, 0.4714, 0.3188,\n                      0.3949, 0.2066, 0.2932, 0.1162, 0.4556, 0.3654, 0.0972, 0.3851, 0.3361,\n                      0.3994, 0.2667, 0.3424, 0.1899, 0.0627, 0.4577, 0.2910, 0.4304, 0.2704,\n                      0.2596, 0.3100, 0.1396, 0.1677, 0.2925, 0.2879, 0.1875, 0.4363, 0.2424,\n                      0.1326, 0.6246, 0.3400, 0.5680, 0.0618, 0.3628, 0.5246, 0.3419, 0.2571,\n                      0.5892, 0.4431, 0.4687, 0.1958, 0.3582, 0.3042, 0.0947, 0.2855, 0.3153,\n                      0.2800, 0.2818, 0.3723, 0.3595, 0.5450, 0.1248, 0.2607, 0.4605, 0.2021,\n                      0.1692, 0.3475, 0.2850, 0.4515, 0.6024, 0.3446, 0.3902, 0.2548, 0.2524,\n                      0.4572, 0.3328, 0.2283, 0.2228, 0.2460, 0.2907, 0.1223, 0.2900, 0.2742,\n                      0.0942, 0.3581, 0.1487, 0.3447, 0.5676, 0.3000, 0.5342, 0.3547, 0.2202,\n                      0.3219, 0.2116, 0.1768, 0.2955, 0.3635, 0.6483, 0.3323, 0.4829, 0.1149,\n                      0.0802, 0.2705, 0.4032, 0.1234, 0.1683, 0.1140, 0.4022, 0.2817, 0.2835,\n                      0.3301, 0.1958, 0.3088, 0.5258, 0.0648, 0.2727, 0.3238, 0.2582, 0.5038,\n                      0.2845, 0.2742, 0.1998, 0.3688, 0.4831, 0.4021, 0.3616, 0.3976, 0.4253,\n                      0.1921, 0.4696, 0.2922, 0.1325, 0.2844, 0.3660, 0.2176, 0.1321, 0.4654,\n                      0.2659, 0.4366, 0.2134, 0.2079, 0.4556, 0.0953, 0.4804, 0.2391, 0.4423,\n                      0.3008, 0.5873, 0.2853, 0.3567], dtype=torch.float64)),\n             ('6.11.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.12.convs.0.0.weight',\n              tensor([[[-0.0688],\n                       [ 0.0173],\n                       [-0.0150],\n                       ...,\n                       [-0.1434],\n                       [ 0.0732],\n                       [ 0.0834]],\n              \n                      [[ 0.0636],\n                       [-0.0964],\n                       [ 0.0191],\n                       ...,\n                       [-0.0721],\n                       [-0.0149],\n                       [-0.0249]],\n              \n                      [[-0.0309],\n                       [ 0.0231],\n                       [ 0.0058],\n                       ...,\n                       [-0.0728],\n                       [-0.0469],\n                       [-0.0746]],\n              \n                      ...,\n              \n                      [[ 0.1119],\n                       [-0.0471],\n                       [-0.1694],\n                       ...,\n                       [-0.0081],\n                       [-0.0041],\n                       [-0.0197]],\n              \n                      [[ 0.1178],\n                       [-0.0608],\n                       [ 0.0560],\n                       ...,\n                       [ 0.0591],\n                       [ 0.0249],\n                       [-0.0473]],\n              \n                      [[ 0.1067],\n                       [-0.2160],\n                       [-0.1499],\n                       ...,\n                       [-0.0632],\n                       [-0.0009],\n                       [ 0.0064]]], dtype=torch.float64)),\n             ('6.12.convs.0.1.weight',\n              tensor([0.9793, 0.9858, 0.9421, 0.9929, 1.0062, 0.9816, 0.9431, 0.9761, 0.9678,\n                      0.9580, 1.0027, 0.9745, 0.9507, 0.9718, 0.9744, 0.9663, 0.9650, 0.9668,\n                      0.9697, 0.9661, 0.9674, 0.9912, 0.9772, 0.9834, 0.9990, 0.9591, 0.9882,\n                      0.9731, 0.9708, 0.9896, 0.9724, 0.9704, 0.9711, 0.9619, 0.9749, 0.9770,\n                      0.9645, 0.9659, 0.9779, 0.9818, 0.9747, 0.9940, 0.9899, 0.9682, 0.9827,\n                      0.9679, 0.9909, 0.9788, 0.9202, 0.9779, 0.9724, 1.0002, 0.9703, 0.9655,\n                      0.9570, 0.9803, 0.9931, 0.9642, 0.9822, 0.9646, 0.9927, 0.9654, 0.9393,\n                      0.9669], dtype=torch.float64)),\n             ('6.12.convs.0.1.bias',\n              tensor([ 0.0152,  0.0176, -0.0203,  0.0302,  0.0211,  0.0153, -0.0056, -0.0247,\n                       0.0118,  0.0003,  0.0345,  0.0169, -0.0162,  0.0091, -0.0164,  0.0181,\n                       0.0071, -0.0068,  0.0080,  0.0084, -0.0123,  0.0230, -0.0059, -0.0082,\n                       0.0090, -0.0118,  0.0114,  0.0118,  0.0090,  0.0077,  0.0141,  0.0111,\n                      -0.0120,  0.0012, -0.0092,  0.0153, -0.0187, -0.0139,  0.0082, -0.0021,\n                       0.0135,  0.0060, -0.0336, -0.0128,  0.0088,  0.0054,  0.0216,  0.0037,\n                      -0.0144,  0.0064,  0.0139,  0.0036, -0.0087, -0.0077, -0.0213,  0.0095,\n                       0.0204, -0.0097, -0.0041, -0.0139,  0.0306,  0.0203, -0.0260,  0.0081],\n                     dtype=torch.float64)),\n             ('6.12.convs.0.1.running_mean',\n              tensor([-0.5332, -0.6010,  0.4165, -1.0350,  0.4159,  0.2513, -0.0903, -0.1744,\n                      -0.2938, -0.0091, -0.0532, -0.0422,  0.8737, -1.1439,  1.3057,  0.1041,\n                       0.7279, -0.9889, -0.0745,  0.0590, -0.0455, -1.0139,  0.6245, -0.4647,\n                      -0.3633, -1.1606,  0.1107, -0.1427, -0.2794, -0.7135, -0.8088, -0.5740,\n                      -0.0075, -0.5612, -0.0704, -0.4165, -0.3024,  0.0695, -0.2785,  0.0186,\n                      -0.0033,  0.5229,  0.3831,  0.4827,  0.3439, -0.0287, -0.4526,  0.0159,\n                      -0.6273,  0.0887,  0.8727, -0.3394, -0.4260,  0.3998, -1.1015, -0.3104,\n                       0.1875, -0.3478, -0.3079,  0.0184, -0.3081, -0.6360,  0.8429,  0.1165],\n                     dtype=torch.float64)),\n             ('6.12.convs.0.1.running_var',\n              tensor([0.2153, 0.2243, 0.4917, 0.1777, 0.1228, 0.3646, 1.0509, 0.2096, 0.2503,\n                      0.1367, 0.3334, 0.2203, 0.6143, 0.4596, 0.2833, 0.2081, 0.5929, 0.1848,\n                      0.4142, 0.1655, 0.3030, 0.1831, 0.1373, 0.2344, 0.0993, 0.2555, 0.1468,\n                      0.3382, 0.1737, 0.1317, 0.5765, 0.3156, 0.2321, 0.2572, 0.2599, 0.1347,\n                      0.2165, 0.1822, 0.1422, 0.1964, 0.1127, 0.2739, 0.1030, 0.5523, 0.2264,\n                      0.4282, 0.1569, 0.3010, 1.2961, 0.1360, 0.8328, 0.1380, 0.6535, 0.4705,\n                      0.2673, 0.1179, 0.2291, 0.1956, 0.1638, 0.1472, 0.2305, 0.1769, 1.4008,\n                      0.1850], dtype=torch.float64)),\n             ('6.12.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.12.convs.1.0.weight',\n              tensor([[[-9.7982e-02, -1.2761e-02, -6.6099e-02,  1.1663e-01, -1.4064e-02],\n                       [-1.0251e-01, -9.8539e-02,  6.1466e-02, -6.2549e-02, -2.1574e-02],\n                       [ 5.7186e-02,  5.7956e-02, -1.0764e-01,  1.3726e-01,  3.5745e-02],\n                       ...,\n                       [-3.5507e-02, -9.2969e-02, -8.2163e-02,  1.8373e-01, -9.4310e-03],\n                       [-6.0465e-02, -1.8567e-02, -3.0952e-02,  1.6370e-01,  3.6034e-02],\n                       [ 3.0720e-02,  2.2004e-02,  3.6270e-03, -1.3350e-01,  1.2168e-01]],\n              \n                      [[ 1.3370e-02,  4.3619e-03,  7.7166e-02, -8.6199e-02, -9.9938e-02],\n                       [-1.4915e-02, -2.9636e-02, -1.7970e-01, -8.7397e-02, -2.9516e-02],\n                       [-9.9077e-02, -1.4389e-01,  1.3561e-01, -3.4435e-02, -4.0424e-02],\n                       ...,\n                       [ 5.3762e-02, -2.9169e-02,  8.3221e-02,  3.9154e-02,  7.6082e-02],\n                       [ 3.1914e-02,  1.0319e-01, -5.5373e-02, -6.3963e-02, -1.2396e-03],\n                       [-4.0058e-02, -4.1074e-02, -7.4671e-02,  4.1508e-02, -5.5732e-02]],\n              \n                      [[-7.8395e-02, -3.6643e-02,  2.1610e-02,  1.0661e-01, -4.0530e-02],\n                       [-2.0141e-02, -4.3800e-04,  5.9087e-02,  1.5981e-02,  6.0337e-02],\n                       [ 3.3762e-02, -2.0943e-02, -6.4002e-02,  1.2842e-02, -4.2015e-02],\n                       ...,\n                       [ 1.1113e-01, -4.2215e-02,  5.2007e-02,  1.4984e-02, -9.5229e-02],\n                       [-1.5339e-01,  1.8578e-02,  1.1406e-01,  2.6761e-02,  2.8678e-02],\n                       [-8.0011e-02, -5.3326e-02,  4.0838e-03,  2.2574e-02,  2.3392e-01]],\n              \n                      ...,\n              \n                      [[-6.9709e-03,  7.2196e-02, -1.6725e-02,  9.0950e-02,  1.3865e-01],\n                       [ 1.5826e-01,  8.4815e-03,  1.3853e-01, -7.0594e-03,  5.1524e-03],\n                       [-5.7565e-02, -3.9104e-02,  8.2913e-02, -2.1487e-02,  5.7015e-02],\n                       ...,\n                       [ 1.7257e-01,  5.1367e-02, -1.3975e-01,  1.0109e-01, -3.2802e-02],\n                       [-7.4708e-02, -5.9357e-02,  6.4704e-02, -2.3270e-02, -4.4137e-03],\n                       [-1.2323e-02,  5.4410e-02,  3.8502e-02, -2.7522e-02,  8.8798e-02]],\n              \n                      [[ 7.8709e-02,  3.9630e-02, -7.9865e-03,  5.0950e-02,  1.2268e-01],\n                       [-2.9876e-02,  6.3758e-04,  7.0092e-02, -8.2118e-02, -9.1391e-02],\n                       [ 7.6682e-02, -1.8632e-02,  4.7409e-02,  9.4682e-02,  9.3635e-02],\n                       ...,\n                       [ 8.5360e-02, -5.9873e-02,  1.0453e-01, -2.7172e-02, -3.1872e-03],\n                       [-7.2148e-03,  1.0446e-02,  5.0150e-02, -2.7209e-02,  1.9987e-03],\n                       [-1.0219e-01, -6.8400e-02,  2.4034e-02, -1.2183e-03,  7.0378e-03]],\n              \n                      [[ 7.5180e-03,  7.1001e-02, -1.2814e-01,  2.0146e-02, -6.5666e-02],\n                       [-1.1598e-01,  1.3663e-01,  1.8703e-01, -7.9319e-02, -2.5803e-02],\n                       [ 2.4860e-02,  2.9315e-03,  8.8203e-02, -8.3283e-03, -4.9884e-02],\n                       ...,\n                       [-5.8444e-05, -1.6208e-02, -4.2016e-02, -2.3293e-04, -5.8134e-02],\n                       [-3.1801e-02,  7.1128e-02,  4.9274e-02, -6.8835e-03,  6.1572e-02],\n                       [ 3.1043e-02, -3.2092e-02, -1.2546e-01,  6.0253e-03,  1.1994e-01]]],\n                     dtype=torch.float64)),\n             ('6.12.convs.1.1.weight',\n              tensor([0.9727, 0.9840, 0.9796, 0.9941, 0.9532, 0.9603, 0.9452, 0.9722, 0.9417,\n                      0.9682, 0.9613, 0.9770, 0.9584, 0.9599, 0.9627, 0.9902, 1.0144, 0.9612,\n                      0.9503, 0.9543, 0.9639, 0.9526, 0.9711, 0.9664, 0.9383, 0.9562, 0.9569,\n                      0.9619, 0.9755, 0.9605, 0.9621, 1.0033, 0.9588, 0.9698, 0.9776, 0.9520,\n                      0.9810, 0.9803, 0.9994, 0.9801, 0.9548, 0.9874, 0.9612, 0.9967, 0.9625,\n                      0.9882, 0.9556, 0.9615, 0.9689, 0.9437, 1.0050, 0.9610, 0.9465, 0.9830,\n                      0.9372, 0.9765, 0.9470, 0.9552, 0.9649, 0.9725, 0.9534, 0.9733, 0.9731,\n                      0.9774], dtype=torch.float64)),\n             ('6.12.convs.1.1.bias',\n              tensor([-0.0153,  0.0058,  0.0003, -0.0060,  0.0036, -0.0165, -0.0073,  0.0012,\n                      -0.0087, -0.0165, -0.0252,  0.0165, -0.0342,  0.0058,  0.0005, -0.0091,\n                       0.0293, -0.0177, -0.0143, -0.0212, -0.0146, -0.0334,  0.0051, -0.0251,\n                      -0.0109, -0.0313, -0.0217, -0.0116, -0.0025, -0.0087, -0.0085,  0.0123,\n                      -0.0101,  0.0026, -0.0030,  0.0107,  0.0129, -0.0006, -0.0061, -0.0005,\n                      -0.0163,  0.0128, -0.0111,  0.0302,  0.0068,  0.0010, -0.0077, -0.0036,\n                      -0.0173, -0.0139, -0.0076, -0.0533, -0.0227,  0.0029, -0.0203, -0.0022,\n                      -0.0113, -0.0313, -0.0190,  0.0043, -0.0230, -0.0135,  0.0009,  0.0093],\n                     dtype=torch.float64)),\n             ('6.12.convs.1.1.running_mean',\n              tensor([ 1.2463,  0.2691,  0.2006,  0.6099, -0.7010,  0.2026, -0.2258, -0.0429,\n                      -0.0074,  0.5334, -0.4643, -0.2287,  0.0568, -0.5103, -0.3855,  0.0943,\n                      -0.5141,  0.0113, -0.5586, -0.1022,  0.2446,  0.2875, -0.5562,  0.6388,\n                       0.1918,  0.2068,  0.2429, -0.6888, -0.0700,  0.5268,  0.2255,  0.4996,\n                      -0.3366, -1.1653, -0.0834, -0.5605,  0.3329, -0.0566,  0.1109,  0.3425,\n                      -0.1902, -0.0698, -0.2286, -0.8737, -0.0582, -0.0644, -1.3233,  0.0579,\n                       0.5339,  0.2005,  0.1695,  0.4966,  0.4083, -0.6585, -0.4888,  0.0511,\n                      -0.1164,  0.6424,  0.5446, -0.3016, -0.2471,  0.7757,  0.4093, -0.6232],\n                     dtype=torch.float64)),\n             ('6.12.convs.1.1.running_var',\n              tensor([0.7758, 0.5843, 0.5248, 0.4503, 0.6307, 0.4795, 0.3695, 0.4656, 0.4163,\n                      0.6106, 0.7637, 0.4951, 0.4428, 1.0930, 0.5325, 0.5584, 0.5000, 0.5542,\n                      0.4828, 0.6982, 0.6061, 0.5412, 0.6219, 0.4847, 0.7456, 0.5069, 0.4489,\n                      0.4655, 0.4122, 0.4522, 0.6073, 0.4349, 0.6295, 0.4845, 1.1838, 0.6203,\n                      0.5063, 0.4700, 0.4704, 0.3182, 0.5585, 0.4173, 0.4882, 0.8518, 0.3987,\n                      0.6489, 0.5742, 0.4507, 0.7601, 0.4160, 0.5150, 0.7346, 0.6092, 0.6886,\n                      1.1726, 0.4357, 0.6276, 0.7141, 0.6504, 0.4412, 0.5721, 0.4725, 0.6901,\n                      0.3921], dtype=torch.float64)),\n             ('6.12.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.12.convs.2.0.weight',\n              tensor([[[ 4.2645e-02],\n                       [-4.4919e-02],\n                       [ 9.1611e-02],\n                       ...,\n                       [ 1.8184e-01],\n                       [ 4.4987e-02],\n                       [-7.1846e-02]],\n              \n                      [[-5.2676e-02],\n                       [-3.0656e-02],\n                       [-9.9997e-02],\n                       ...,\n                       [-2.5832e-03],\n                       [ 2.9083e-01],\n                       [-9.7800e-02]],\n              \n                      [[ 5.0634e-02],\n                       [ 4.2759e-02],\n                       [ 1.7114e-01],\n                       ...,\n                       [-2.1405e-04],\n                       [ 1.3658e-01],\n                       [ 8.1322e-02]],\n              \n                      ...,\n              \n                      [[-1.6691e-01],\n                       [ 2.2944e-01],\n                       [ 9.7645e-04],\n                       ...,\n                       [ 6.8186e-02],\n                       [-1.1157e-01],\n                       [ 5.7341e-02]],\n              \n                      [[ 3.2393e-02],\n                       [-6.8236e-02],\n                       [ 1.1008e-01],\n                       ...,\n                       [ 3.1608e-02],\n                       [-1.3980e-01],\n                       [ 8.9334e-02]],\n              \n                      [[-2.2162e-02],\n                       [-1.0166e-02],\n                       [ 2.3773e-01],\n                       ...,\n                       [-4.0543e-02],\n                       [-1.6363e-01],\n                       [ 1.0111e-01]]], dtype=torch.float64)),\n             ('6.12.convs.2.1.weight',\n              tensor([ 4.3333e-03, -3.2985e-02,  3.9914e-03, -2.6680e-04,  1.3390e-02,\n                       5.7171e-03,  2.5363e-02,  1.4338e-02, -2.0090e-02, -2.2176e-03,\n                       9.1880e-03, -3.7147e-02,  1.0612e-02, -1.9335e-03, -5.7457e-03,\n                       1.7238e-02,  2.5920e-02,  7.0679e-03,  1.3227e-02,  2.9495e-02,\n                      -7.9638e-03,  1.7731e-02,  4.5621e-03,  1.3678e-02,  5.9185e-03,\n                       1.7896e-02,  9.2414e-03,  1.3525e-02,  1.6675e-02, -2.6282e-02,\n                       3.5259e-05,  1.6538e-02, -1.3696e-02,  1.9330e-02,  2.7159e-02,\n                       2.2065e-02,  1.1225e-02,  1.0586e-02, -2.6503e-02, -4.3072e-02,\n                       2.3337e-03, -3.3425e-02, -3.1829e-02,  2.3749e-03, -7.8579e-03,\n                      -1.0979e-02,  5.4345e-03,  6.3433e-03, -5.2358e-02,  1.4357e-02,\n                       1.2711e-02,  1.3936e-03,  1.0062e-02, -1.7712e-02, -8.6028e-03,\n                      -2.2248e-02, -7.1339e-03, -7.2612e-03,  2.3742e-03,  1.2199e-02,\n                       4.7175e-03, -9.7278e-03,  7.1659e-03,  1.6170e-03,  6.4444e-03,\n                       1.0993e-02,  7.1212e-03, -2.1645e-02,  2.4415e-03,  1.7752e-02,\n                       4.2838e-03,  1.2279e-02,  7.4552e-03, -2.1457e-02,  7.0103e-03,\n                       1.2902e-02,  2.3184e-02,  9.0124e-03, -1.0797e-03,  1.6717e-02,\n                       7.3032e-03, -1.2958e-02,  8.5208e-03, -1.1383e-02, -5.2576e-03,\n                       5.8323e-03, -3.4887e-03,  3.4044e-02, -1.6613e-02, -2.3611e-03,\n                      -1.4635e-02, -2.7882e-02, -1.0064e-02,  1.1715e-02,  1.7560e-02,\n                       2.7311e-03, -2.3777e-02, -2.2234e-02, -5.5099e-03,  1.1357e-02,\n                       2.5698e-02, -3.9072e-03,  2.1077e-02, -3.5788e-02, -1.9684e-02,\n                       1.4666e-02, -8.2681e-03,  2.3861e-02,  2.6581e-02, -1.3678e-02,\n                      -1.5686e-02, -1.1667e-02,  3.5243e-03,  1.1915e-02,  3.7788e-02,\n                       1.4163e-02,  9.0875e-03,  1.8285e-02,  1.9371e-02, -1.9560e-02,\n                       2.2672e-02,  5.7491e-03, -2.3855e-02,  1.8731e-02, -6.7731e-04,\n                      -3.1417e-02,  1.0569e-02, -2.8762e-03,  9.5676e-03,  1.5725e-02,\n                       5.6691e-03, -1.2855e-03,  1.9320e-02,  1.3017e-02, -2.3978e-02,\n                       2.2088e-02, -3.0879e-02,  1.8831e-02,  2.7621e-03,  1.7204e-02,\n                       7.7387e-03, -2.0760e-03,  2.5390e-02,  7.3766e-03,  1.0156e-02,\n                      -1.2003e-02,  1.5718e-02,  3.8513e-03, -1.8115e-02, -2.7875e-02,\n                      -7.2305e-03, -2.0790e-02,  7.2825e-03, -2.8709e-02, -3.7876e-02,\n                      -6.8566e-03,  9.1621e-03,  1.5685e-02, -1.7024e-02, -1.2376e-03,\n                      -2.0125e-02, -8.5298e-03, -2.8956e-03,  2.0038e-02, -1.8752e-02,\n                      -1.1455e-02,  6.8390e-03,  5.1941e-03, -8.6517e-03,  1.8406e-02,\n                      -1.0333e-02,  5.1810e-03,  1.0007e-02,  2.0577e-02, -2.2655e-02,\n                       3.7010e-03, -5.8759e-03,  8.3018e-03, -8.6059e-03,  1.1485e-02,\n                      -5.3462e-04,  1.8886e-02,  1.2490e-03,  7.4949e-03, -2.2191e-03,\n                       6.7708e-03, -1.6585e-02,  1.2357e-02, -1.1070e-02, -1.4082e-02,\n                       7.6563e-04, -9.5342e-03, -4.0074e-02, -4.3340e-02, -2.0792e-02,\n                      -1.1328e-02,  3.4753e-02,  5.3701e-03, -2.5156e-02, -1.3349e-02,\n                      -5.8134e-03, -3.2724e-02, -2.4255e-02,  1.5011e-02,  1.6584e-02,\n                       1.1896e-02,  3.8396e-03,  1.0835e-02,  3.9661e-03, -1.9407e-02,\n                      -7.8115e-03, -3.0624e-02,  4.0959e-02,  2.6369e-02, -1.7248e-02,\n                      -2.3680e-04, -1.4952e-02,  1.7921e-02, -2.8126e-02, -3.4492e-02,\n                       1.4971e-02, -2.0886e-02, -5.4711e-03,  1.1128e-02, -2.2040e-02,\n                      -8.8091e-03,  3.3865e-03, -3.1624e-03, -2.1064e-02, -2.5997e-02,\n                      -6.1313e-03,  5.7078e-03,  2.3235e-02,  3.4079e-03, -8.3955e-03,\n                      -1.7391e-02,  9.7061e-04,  2.1430e-02, -1.3030e-02, -3.8849e-02,\n                      -2.2701e-03,  2.1835e-02,  1.6006e-02,  5.3944e-03,  2.2795e-02,\n                       8.8596e-03, -9.8455e-03, -1.0179e-02, -2.1849e-02,  2.8151e-02,\n                       2.9802e-02,  1.9166e-02, -2.7278e-02, -5.1191e-03, -8.8329e-03,\n                       6.1739e-03], dtype=torch.float64)),\n             ('6.12.convs.2.1.bias',\n              tensor([-2.5600e-04,  1.7020e-02,  1.0045e-02,  1.4077e-02,  2.1968e-03,\n                       7.5821e-03,  7.3552e-03, -6.8334e-04,  7.3275e-03,  1.4333e-02,\n                       1.5833e-02, -5.8730e-03,  8.1243e-03, -4.2887e-03,  9.5703e-03,\n                       2.4902e-04,  2.4685e-02, -9.6970e-04,  9.9541e-03, -3.2593e-03,\n                      -3.8560e-03,  4.8604e-04,  4.7689e-03,  6.7267e-03,  5.6186e-03,\n                      -1.6607e-02,  5.4133e-03,  6.2940e-03,  2.9117e-03, -1.7983e-03,\n                       1.7642e-03,  6.9711e-03, -1.2844e-03,  2.0768e-02,  5.8349e-03,\n                       1.6876e-02, -4.8159e-03,  1.8574e-02,  6.5640e-03,  1.2572e-02,\n                       7.8595e-04,  1.9110e-02, -9.6012e-03, -1.6159e-03,  7.9766e-03,\n                      -1.2446e-02,  1.4124e-02, -9.4082e-04, -1.2313e-02,  7.6576e-03,\n                       8.6440e-03,  4.1945e-03,  8.4791e-03,  1.3316e-02,  2.9959e-03,\n                       1.8845e-02,  9.5597e-03,  1.3199e-03,  1.2198e-02, -2.2303e-03,\n                       1.1571e-03,  1.5151e-03,  9.3999e-03,  9.4843e-03, -4.6687e-03,\n                       3.7606e-03, -1.0555e-02,  1.6097e-02, -5.9984e-04, -1.4805e-02,\n                       7.0054e-03,  3.3655e-03,  4.3141e-05, -7.8689e-03,  1.3777e-02,\n                       8.5932e-03,  2.4855e-03,  1.0963e-03,  3.4996e-03,  1.4961e-02,\n                       5.9398e-03, -6.7026e-03,  1.0933e-02,  5.1164e-03, -2.6523e-03,\n                       1.6488e-02,  1.1068e-03,  1.0784e-02,  1.5853e-02,  2.2014e-03,\n                       1.2374e-03,  9.3275e-03,  1.0455e-02,  9.5208e-04,  9.8636e-03,\n                      -1.4447e-02,  1.0779e-02,  6.5399e-03,  2.0659e-02,  3.8402e-03,\n                       1.8976e-02,  1.5091e-02,  5.1299e-03,  7.7587e-03, -2.0852e-03,\n                      -7.5260e-04, -4.1723e-03,  8.7620e-03,  9.1412e-03,  4.5257e-03,\n                      -1.3500e-02, -8.3322e-03,  5.3216e-03,  2.0198e-02,  1.4477e-02,\n                       5.0377e-03,  1.1875e-02,  3.9472e-03,  6.6442e-03, -1.4596e-02,\n                       3.3788e-04,  9.5697e-03, -8.3387e-04, -2.2317e-03,  2.4434e-04,\n                       1.1601e-02,  9.2506e-03,  5.2181e-03,  5.9043e-03,  1.3239e-02,\n                       7.2757e-03,  7.3823e-03,  1.3766e-02,  4.6326e-03,  1.6891e-02,\n                      -1.0387e-02,  8.0736e-03,  3.3363e-03,  6.1905e-03,  9.3296e-04,\n                       1.2954e-02, -8.0869e-03,  1.7141e-02,  3.9806e-03, -7.8536e-03,\n                       1.5639e-02,  4.1875e-03,  2.0371e-03,  1.2778e-02,  8.8516e-03,\n                       1.4130e-02,  1.6991e-02,  5.4017e-03,  1.2235e-02,  1.3049e-02,\n                       5.2551e-03, -1.4156e-03,  3.4166e-03, -3.7861e-04, -1.1388e-02,\n                       4.2257e-03, -4.9475e-03, -2.5110e-03,  1.0504e-02,  1.3990e-02,\n                      -2.6560e-03, -1.2329e-02,  1.0394e-02,  7.3265e-03,  2.1756e-02,\n                       1.8259e-03,  1.0314e-03,  5.3184e-03,  1.4547e-02, -1.3551e-02,\n                       1.0348e-02,  1.5567e-03,  1.5888e-02,  8.0573e-04,  4.9805e-03,\n                      -6.0100e-03,  1.3268e-02, -5.1664e-03, -8.5644e-03,  1.1752e-02,\n                       7.6632e-03,  1.5471e-02,  1.0756e-02,  4.7474e-03,  6.8514e-03,\n                       5.8507e-03,  3.1228e-03,  9.7273e-03,  1.4821e-04,  1.7491e-03,\n                       7.2844e-03,  1.6729e-02,  3.4953e-03,  7.5682e-03,  1.4828e-02,\n                      -9.7120e-04,  2.5077e-02,  1.7338e-02,  1.9577e-02,  1.4727e-02,\n                      -1.4192e-03,  7.4099e-03, -9.1286e-03,  6.5704e-03,  1.2738e-02,\n                       8.5957e-03,  1.0890e-02,  1.2723e-02,  1.5806e-03,  1.0670e-02,\n                       1.1850e-03,  5.3435e-03,  2.1925e-02,  5.9399e-03,  2.2693e-03,\n                      -5.3717e-03,  9.6136e-04,  2.1991e-03,  1.5042e-02,  2.2005e-03,\n                       3.8303e-03, -7.5251e-03, -5.3439e-04, -1.1964e-02,  1.4300e-02,\n                       5.6032e-03, -3.6194e-03,  5.8316e-03,  1.2587e-02,  1.0643e-03,\n                       8.0725e-03,  3.8096e-03,  5.2157e-03,  9.9200e-03,  1.0016e-02,\n                      -3.7368e-03,  3.2172e-03, -1.8096e-03,  1.4063e-02, -7.9539e-04,\n                       1.2141e-02,  4.6286e-03,  3.8485e-03, -1.0175e-02, -8.1536e-03,\n                       1.7679e-02,  2.4662e-02,  2.0427e-02,  1.7683e-02,  5.7350e-03,\n                       3.6259e-03], dtype=torch.float64)),\n             ('6.12.convs.2.1.running_mean',\n              tensor([ 1.4753e-01, -3.0601e-01,  5.1817e-01,  4.1692e-01, -4.3183e-01,\n                      -2.1904e-01, -2.0195e-01, -1.0384e-01, -6.5060e-01, -4.7379e-01,\n                       3.0915e-01, -2.8250e-01,  1.3103e-02, -3.4402e-03, -4.5476e-01,\n                       1.6426e-01, -4.3117e-01,  2.3470e-01,  1.2453e-01,  3.6012e-01,\n                      -1.4442e-01,  2.0722e-01,  1.7161e-01, -1.7708e-01, -4.3544e-01,\n                       2.2440e-01,  4.2157e-01,  5.0408e-01,  6.6446e-01,  2.3939e-01,\n                      -2.4536e-01, -6.4491e-01,  1.4516e-01, -2.6177e-01, -1.2848e-01,\n                       2.8047e-01, -4.7213e-01, -9.6812e-01, -1.9556e-03, -6.3206e-02,\n                      -3.8405e-01,  4.8359e-01,  8.2157e-01,  4.5880e-01,  4.5355e-01,\n                       4.2089e-01,  1.7443e-01,  2.1376e-01,  1.6487e-01, -4.9049e-01,\n                      -4.9801e-02, -1.4256e-01, -4.4200e-01,  1.3034e+00, -1.2064e+00,\n                       3.4899e-01,  8.4597e-01,  1.8325e-02, -9.6387e-01,  7.0111e-01,\n                       1.5948e-01,  2.0721e-01, -2.2218e-01, -1.7130e-01, -6.9824e-01,\n                       5.5967e-01,  5.5855e-02, -1.8150e-01, -9.3013e-01,  4.4247e-01,\n                      -1.1931e-01,  1.4947e-01, -2.2282e-01, -3.4601e-01, -1.3687e-01,\n                       5.2105e-02, -1.7660e-01, -6.7380e-01, -3.3463e-01, -8.6035e-02,\n                      -8.7581e-01,  3.2253e-01,  6.0354e-01,  6.4281e-01, -5.8594e-01,\n                      -5.3835e-01,  5.0381e-01,  6.1174e-01, -9.1578e-02,  4.5787e-02,\n                       7.8894e-02, -9.1025e-02, -6.4429e-01, -4.3106e-01, -5.7191e-01,\n                      -8.9322e-02, -5.4603e-01, -4.1528e-01,  2.1133e-01,  5.2052e-02,\n                      -5.5254e-01, -5.7469e-01,  1.6737e-01, -2.3617e-01, -2.6254e-01,\n                      -2.5764e-01, -4.3746e-01, -2.9873e-01, -6.1210e-01,  4.8055e-01,\n                       7.1081e-02, -7.8498e-01,  6.4950e-01, -4.2057e-01,  7.0114e-01,\n                      -9.7119e-02, -4.1169e-01, -9.8688e-02, -7.0832e-01,  3.3856e-01,\n                      -3.6173e-01, -3.0683e-01, -1.9966e-01,  8.7885e-01, -2.1811e-01,\n                       5.9722e-02, -3.0662e-01, -4.1434e-01, -6.2363e-01, -1.1739e-01,\n                      -4.0327e-02,  1.1750e-03, -8.5319e-01, -2.4438e-01,  7.5235e-01,\n                      -3.8232e-01,  1.3725e-01,  6.2136e-01,  6.7773e-01,  7.9686e-01,\n                      -8.3322e-02, -1.3326e-01,  2.4364e-01, -4.5360e-01,  8.0759e-01,\n                      -1.2880e-01,  1.7840e-01,  1.4535e-01,  7.0434e-02,  3.1018e-01,\n                       3.5097e-01, -6.4020e-01, -2.7085e-01,  6.3063e-01,  1.3747e-01,\n                      -2.2307e-01,  3.2277e-01,  3.8238e-01,  4.0447e-01,  6.1100e-02,\n                      -8.0286e-01,  1.0218e-01,  1.7010e-01, -5.4063e-03,  7.2750e-01,\n                      -4.8741e-01, -7.0680e-04,  4.0081e-01,  1.7672e-02,  8.6178e-01,\n                      -3.6781e-01,  3.9942e-01, -1.1741e-01,  7.9297e-01, -5.2318e-01,\n                      -4.5091e-01,  1.5177e-01,  1.5965e-01,  6.4706e-02,  2.3996e-01,\n                       1.7680e-01, -1.5895e-01,  2.6762e-01,  4.7472e-01,  3.6022e-01,\n                      -7.2934e-01,  7.0720e-01, -6.1017e-01,  3.5189e-01, -9.7853e-03,\n                      -1.9449e-01,  8.0933e-01, -1.0425e-01,  3.6561e-01,  6.2799e-01,\n                       4.4417e-01, -1.0560e-01, -2.8244e-01,  1.2358e-01,  1.9057e-01,\n                      -3.2314e-01,  2.2405e-01,  3.5805e-01, -6.9201e-01, -1.2915e-01,\n                       3.6469e-01, -3.0913e-02,  1.6540e-01,  1.2815e-01,  9.2675e-02,\n                       6.8621e-02,  1.2617e-01, -3.3290e-01,  4.9898e-01,  3.1051e-02,\n                       3.3834e-01, -5.5665e-01,  3.8894e-01,  6.5896e-01,  2.3898e-01,\n                       1.7422e-02,  3.5232e-01, -1.4835e-01,  3.9643e-01,  5.5990e-02,\n                      -8.2668e-01, -5.3417e-01, -5.6419e-02, -4.0678e-01, -3.7904e-01,\n                      -4.4497e-01, -4.3355e-02,  4.0113e-01, -3.3066e-01, -3.6132e-01,\n                       2.4055e-01, -4.7341e-01,  2.8538e-01, -8.2936e-01,  1.6485e-01,\n                      -5.5315e-01,  1.9013e-01, -6.6564e-01,  4.4754e-01, -4.4832e-01,\n                       2.9771e-02, -3.3644e-01, -5.9301e-01,  5.8840e-02,  3.8288e-02,\n                       5.1611e-02, -2.7410e-01, -8.6876e-02,  2.9932e-01,  2.2284e-01,\n                       2.3446e-01], dtype=torch.float64)),\n             ('6.12.convs.2.1.running_var',\n              tensor([0.3350, 0.4503, 0.3777, 0.2177, 0.3207, 0.1474, 0.4416, 0.1513, 0.2863,\n                      0.2286, 0.2043, 0.3801, 0.1718, 0.2988, 0.5335, 0.5760, 0.4489, 0.3237,\n                      0.2729, 0.5978, 0.2859, 0.3018, 0.4265, 0.2910, 0.2641, 0.2614, 0.3065,\n                      0.5153, 0.4380, 0.4443, 0.2279, 0.2849, 0.1423, 0.5226, 0.4146, 0.4074,\n                      0.2059, 0.3746, 0.3234, 0.4652, 0.3472, 0.3741, 0.3484, 0.4082, 0.3783,\n                      0.5932, 0.3533, 0.2218, 0.6305, 0.3294, 0.2853, 0.2677, 0.2416, 0.5568,\n                      0.3251, 0.3260, 0.3530, 0.6326, 0.5305, 0.3249, 0.1226, 0.2612, 0.2000,\n                      0.2177, 0.4144, 0.1071, 0.1756, 0.4027, 0.3514, 0.3843, 0.4361, 0.3753,\n                      0.1187, 0.5673, 0.5123, 0.1927, 0.5193, 0.4015, 0.3666, 0.1315, 0.3815,\n                      0.3982, 0.3193, 0.4592, 0.2200, 0.3698, 0.1644, 0.3850, 0.6212, 0.1188,\n                      0.4956, 0.5812, 0.5067, 0.3136, 0.5115, 0.1096, 0.5300, 0.2123, 0.0905,\n                      0.2473, 0.4239, 0.2464, 0.4142, 0.4949, 0.2562, 0.3198, 0.3961, 0.3760,\n                      0.4912, 0.3838, 0.2860, 0.5370, 0.2939, 0.3092, 0.4675, 0.4980, 0.4219,\n                      0.5931, 0.6321, 0.3104, 0.1622, 0.2184, 0.4998, 0.4400, 0.1929, 0.4879,\n                      0.2311, 0.1799, 0.2539, 0.4469, 0.0249, 0.1327, 0.4234, 0.1463, 0.4570,\n                      0.2362, 0.3333, 0.2238, 0.3357, 0.4647, 0.2632, 0.2340, 0.4119, 0.1367,\n                      0.2742, 0.3951, 0.3601, 0.5575, 0.2958, 0.5227, 0.3917, 0.3341, 0.2593,\n                      0.7426, 0.3549, 0.2147, 0.2287, 0.2589, 0.7083, 0.0556, 0.4847, 0.1636,\n                      0.1447, 0.4965, 0.4337, 0.3081, 0.4970, 0.3441, 0.3585, 0.4207, 0.1982,\n                      0.1102, 0.2390, 0.4796, 0.3769, 0.4840, 0.2099, 0.2077, 0.3524, 0.1851,\n                      0.2189, 0.3197, 0.3173, 0.3261, 0.1426, 0.3154, 0.2969, 0.2029, 0.6535,\n                      0.3368, 0.1074, 0.3799, 0.2907, 0.4698, 0.4837, 0.2754, 0.5035, 0.3669,\n                      0.4373, 0.4542, 0.2091, 0.6810, 0.3802, 0.3311, 0.3434, 0.3487, 0.1582,\n                      0.0636, 0.0855, 0.5924, 0.0801, 0.3918, 0.3443, 0.4168, 0.3292, 0.1314,\n                      0.6064, 0.3128, 0.3684, 0.5052, 0.3849, 0.4695, 0.0811, 0.3297, 0.4834,\n                      0.3965, 0.2263, 0.2799, 0.3948, 0.5244, 0.2479, 0.1348, 0.4891, 0.1633,\n                      0.2855, 0.6305, 0.3246, 0.2866, 0.6562, 0.3896, 0.3554, 0.3373, 0.3958,\n                      0.3256, 0.2976, 0.3648, 0.4963, 0.3051, 0.2849, 0.3910, 0.3885, 0.5122,\n                      0.2935, 0.1862, 0.2973, 0.2718], dtype=torch.float64)),\n             ('6.12.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.12.convpath.0.0.0.weight',\n              tensor([[[-0.0688],\n                       [ 0.0173],\n                       [-0.0150],\n                       ...,\n                       [-0.1434],\n                       [ 0.0732],\n                       [ 0.0834]],\n              \n                      [[ 0.0636],\n                       [-0.0964],\n                       [ 0.0191],\n                       ...,\n                       [-0.0721],\n                       [-0.0149],\n                       [-0.0249]],\n              \n                      [[-0.0309],\n                       [ 0.0231],\n                       [ 0.0058],\n                       ...,\n                       [-0.0728],\n                       [-0.0469],\n                       [-0.0746]],\n              \n                      ...,\n              \n                      [[ 0.1119],\n                       [-0.0471],\n                       [-0.1694],\n                       ...,\n                       [-0.0081],\n                       [-0.0041],\n                       [-0.0197]],\n              \n                      [[ 0.1178],\n                       [-0.0608],\n                       [ 0.0560],\n                       ...,\n                       [ 0.0591],\n                       [ 0.0249],\n                       [-0.0473]],\n              \n                      [[ 0.1067],\n                       [-0.2160],\n                       [-0.1499],\n                       ...,\n                       [-0.0632],\n                       [-0.0009],\n                       [ 0.0064]]], dtype=torch.float64)),\n             ('6.12.convpath.0.0.1.weight',\n              tensor([0.9793, 0.9858, 0.9421, 0.9929, 1.0062, 0.9816, 0.9431, 0.9761, 0.9678,\n                      0.9580, 1.0027, 0.9745, 0.9507, 0.9718, 0.9744, 0.9663, 0.9650, 0.9668,\n                      0.9697, 0.9661, 0.9674, 0.9912, 0.9772, 0.9834, 0.9990, 0.9591, 0.9882,\n                      0.9731, 0.9708, 0.9896, 0.9724, 0.9704, 0.9711, 0.9619, 0.9749, 0.9770,\n                      0.9645, 0.9659, 0.9779, 0.9818, 0.9747, 0.9940, 0.9899, 0.9682, 0.9827,\n                      0.9679, 0.9909, 0.9788, 0.9202, 0.9779, 0.9724, 1.0002, 0.9703, 0.9655,\n                      0.9570, 0.9803, 0.9931, 0.9642, 0.9822, 0.9646, 0.9927, 0.9654, 0.9393,\n                      0.9669], dtype=torch.float64)),\n             ('6.12.convpath.0.0.1.bias',\n              tensor([ 0.0152,  0.0176, -0.0203,  0.0302,  0.0211,  0.0153, -0.0056, -0.0247,\n                       0.0118,  0.0003,  0.0345,  0.0169, -0.0162,  0.0091, -0.0164,  0.0181,\n                       0.0071, -0.0068,  0.0080,  0.0084, -0.0123,  0.0230, -0.0059, -0.0082,\n                       0.0090, -0.0118,  0.0114,  0.0118,  0.0090,  0.0077,  0.0141,  0.0111,\n                      -0.0120,  0.0012, -0.0092,  0.0153, -0.0187, -0.0139,  0.0082, -0.0021,\n                       0.0135,  0.0060, -0.0336, -0.0128,  0.0088,  0.0054,  0.0216,  0.0037,\n                      -0.0144,  0.0064,  0.0139,  0.0036, -0.0087, -0.0077, -0.0213,  0.0095,\n                       0.0204, -0.0097, -0.0041, -0.0139,  0.0306,  0.0203, -0.0260,  0.0081],\n                     dtype=torch.float64)),\n             ('6.12.convpath.0.0.1.running_mean',\n              tensor([-0.5332, -0.6010,  0.4165, -1.0350,  0.4159,  0.2513, -0.0903, -0.1744,\n                      -0.2938, -0.0091, -0.0532, -0.0422,  0.8737, -1.1439,  1.3057,  0.1041,\n                       0.7279, -0.9889, -0.0745,  0.0590, -0.0455, -1.0139,  0.6245, -0.4647,\n                      -0.3633, -1.1606,  0.1107, -0.1427, -0.2794, -0.7135, -0.8088, -0.5740,\n                      -0.0075, -0.5612, -0.0704, -0.4165, -0.3024,  0.0695, -0.2785,  0.0186,\n                      -0.0033,  0.5229,  0.3831,  0.4827,  0.3439, -0.0287, -0.4526,  0.0159,\n                      -0.6273,  0.0887,  0.8727, -0.3394, -0.4260,  0.3998, -1.1015, -0.3104,\n                       0.1875, -0.3478, -0.3079,  0.0184, -0.3081, -0.6360,  0.8429,  0.1165],\n                     dtype=torch.float64)),\n             ('6.12.convpath.0.0.1.running_var',\n              tensor([0.2153, 0.2243, 0.4917, 0.1777, 0.1228, 0.3646, 1.0509, 0.2096, 0.2503,\n                      0.1367, 0.3334, 0.2203, 0.6143, 0.4596, 0.2833, 0.2081, 0.5929, 0.1848,\n                      0.4142, 0.1655, 0.3030, 0.1831, 0.1373, 0.2344, 0.0993, 0.2555, 0.1468,\n                      0.3382, 0.1737, 0.1317, 0.5765, 0.3156, 0.2321, 0.2572, 0.2599, 0.1347,\n                      0.2165, 0.1822, 0.1422, 0.1964, 0.1127, 0.2739, 0.1030, 0.5523, 0.2264,\n                      0.4282, 0.1569, 0.3010, 1.2961, 0.1360, 0.8328, 0.1380, 0.6535, 0.4705,\n                      0.2673, 0.1179, 0.2291, 0.1956, 0.1638, 0.1472, 0.2305, 0.1769, 1.4008,\n                      0.1850], dtype=torch.float64)),\n             ('6.12.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.12.convpath.0.1.0.weight',\n              tensor([[[-9.7982e-02, -1.2761e-02, -6.6099e-02,  1.1663e-01, -1.4064e-02],\n                       [-1.0251e-01, -9.8539e-02,  6.1466e-02, -6.2549e-02, -2.1574e-02],\n                       [ 5.7186e-02,  5.7956e-02, -1.0764e-01,  1.3726e-01,  3.5745e-02],\n                       ...,\n                       [-3.5507e-02, -9.2969e-02, -8.2163e-02,  1.8373e-01, -9.4310e-03],\n                       [-6.0465e-02, -1.8567e-02, -3.0952e-02,  1.6370e-01,  3.6034e-02],\n                       [ 3.0720e-02,  2.2004e-02,  3.6270e-03, -1.3350e-01,  1.2168e-01]],\n              \n                      [[ 1.3370e-02,  4.3619e-03,  7.7166e-02, -8.6199e-02, -9.9938e-02],\n                       [-1.4915e-02, -2.9636e-02, -1.7970e-01, -8.7397e-02, -2.9516e-02],\n                       [-9.9077e-02, -1.4389e-01,  1.3561e-01, -3.4435e-02, -4.0424e-02],\n                       ...,\n                       [ 5.3762e-02, -2.9169e-02,  8.3221e-02,  3.9154e-02,  7.6082e-02],\n                       [ 3.1914e-02,  1.0319e-01, -5.5373e-02, -6.3963e-02, -1.2396e-03],\n                       [-4.0058e-02, -4.1074e-02, -7.4671e-02,  4.1508e-02, -5.5732e-02]],\n              \n                      [[-7.8395e-02, -3.6643e-02,  2.1610e-02,  1.0661e-01, -4.0530e-02],\n                       [-2.0141e-02, -4.3800e-04,  5.9087e-02,  1.5981e-02,  6.0337e-02],\n                       [ 3.3762e-02, -2.0943e-02, -6.4002e-02,  1.2842e-02, -4.2015e-02],\n                       ...,\n                       [ 1.1113e-01, -4.2215e-02,  5.2007e-02,  1.4984e-02, -9.5229e-02],\n                       [-1.5339e-01,  1.8578e-02,  1.1406e-01,  2.6761e-02,  2.8678e-02],\n                       [-8.0011e-02, -5.3326e-02,  4.0838e-03,  2.2574e-02,  2.3392e-01]],\n              \n                      ...,\n              \n                      [[-6.9709e-03,  7.2196e-02, -1.6725e-02,  9.0950e-02,  1.3865e-01],\n                       [ 1.5826e-01,  8.4815e-03,  1.3853e-01, -7.0594e-03,  5.1524e-03],\n                       [-5.7565e-02, -3.9104e-02,  8.2913e-02, -2.1487e-02,  5.7015e-02],\n                       ...,\n                       [ 1.7257e-01,  5.1367e-02, -1.3975e-01,  1.0109e-01, -3.2802e-02],\n                       [-7.4708e-02, -5.9357e-02,  6.4704e-02, -2.3270e-02, -4.4137e-03],\n                       [-1.2323e-02,  5.4410e-02,  3.8502e-02, -2.7522e-02,  8.8798e-02]],\n              \n                      [[ 7.8709e-02,  3.9630e-02, -7.9865e-03,  5.0950e-02,  1.2268e-01],\n                       [-2.9876e-02,  6.3758e-04,  7.0092e-02, -8.2118e-02, -9.1391e-02],\n                       [ 7.6682e-02, -1.8632e-02,  4.7409e-02,  9.4682e-02,  9.3635e-02],\n                       ...,\n                       [ 8.5360e-02, -5.9873e-02,  1.0453e-01, -2.7172e-02, -3.1872e-03],\n                       [-7.2148e-03,  1.0446e-02,  5.0150e-02, -2.7209e-02,  1.9987e-03],\n                       [-1.0219e-01, -6.8400e-02,  2.4034e-02, -1.2183e-03,  7.0378e-03]],\n              \n                      [[ 7.5180e-03,  7.1001e-02, -1.2814e-01,  2.0146e-02, -6.5666e-02],\n                       [-1.1598e-01,  1.3663e-01,  1.8703e-01, -7.9319e-02, -2.5803e-02],\n                       [ 2.4860e-02,  2.9315e-03,  8.8203e-02, -8.3283e-03, -4.9884e-02],\n                       ...,\n                       [-5.8444e-05, -1.6208e-02, -4.2016e-02, -2.3293e-04, -5.8134e-02],\n                       [-3.1801e-02,  7.1128e-02,  4.9274e-02, -6.8835e-03,  6.1572e-02],\n                       [ 3.1043e-02, -3.2092e-02, -1.2546e-01,  6.0253e-03,  1.1994e-01]]],\n                     dtype=torch.float64)),\n             ('6.12.convpath.0.1.1.weight',\n              tensor([0.9727, 0.9840, 0.9796, 0.9941, 0.9532, 0.9603, 0.9452, 0.9722, 0.9417,\n                      0.9682, 0.9613, 0.9770, 0.9584, 0.9599, 0.9627, 0.9902, 1.0144, 0.9612,\n                      0.9503, 0.9543, 0.9639, 0.9526, 0.9711, 0.9664, 0.9383, 0.9562, 0.9569,\n                      0.9619, 0.9755, 0.9605, 0.9621, 1.0033, 0.9588, 0.9698, 0.9776, 0.9520,\n                      0.9810, 0.9803, 0.9994, 0.9801, 0.9548, 0.9874, 0.9612, 0.9967, 0.9625,\n                      0.9882, 0.9556, 0.9615, 0.9689, 0.9437, 1.0050, 0.9610, 0.9465, 0.9830,\n                      0.9372, 0.9765, 0.9470, 0.9552, 0.9649, 0.9725, 0.9534, 0.9733, 0.9731,\n                      0.9774], dtype=torch.float64)),\n             ('6.12.convpath.0.1.1.bias',\n              tensor([-0.0153,  0.0058,  0.0003, -0.0060,  0.0036, -0.0165, -0.0073,  0.0012,\n                      -0.0087, -0.0165, -0.0252,  0.0165, -0.0342,  0.0058,  0.0005, -0.0091,\n                       0.0293, -0.0177, -0.0143, -0.0212, -0.0146, -0.0334,  0.0051, -0.0251,\n                      -0.0109, -0.0313, -0.0217, -0.0116, -0.0025, -0.0087, -0.0085,  0.0123,\n                      -0.0101,  0.0026, -0.0030,  0.0107,  0.0129, -0.0006, -0.0061, -0.0005,\n                      -0.0163,  0.0128, -0.0111,  0.0302,  0.0068,  0.0010, -0.0077, -0.0036,\n                      -0.0173, -0.0139, -0.0076, -0.0533, -0.0227,  0.0029, -0.0203, -0.0022,\n                      -0.0113, -0.0313, -0.0190,  0.0043, -0.0230, -0.0135,  0.0009,  0.0093],\n                     dtype=torch.float64)),\n             ('6.12.convpath.0.1.1.running_mean',\n              tensor([ 1.2463,  0.2691,  0.2006,  0.6099, -0.7010,  0.2026, -0.2258, -0.0429,\n                      -0.0074,  0.5334, -0.4643, -0.2287,  0.0568, -0.5103, -0.3855,  0.0943,\n                      -0.5141,  0.0113, -0.5586, -0.1022,  0.2446,  0.2875, -0.5562,  0.6388,\n                       0.1918,  0.2068,  0.2429, -0.6888, -0.0700,  0.5268,  0.2255,  0.4996,\n                      -0.3366, -1.1653, -0.0834, -0.5605,  0.3329, -0.0566,  0.1109,  0.3425,\n                      -0.1902, -0.0698, -0.2286, -0.8737, -0.0582, -0.0644, -1.3233,  0.0579,\n                       0.5339,  0.2005,  0.1695,  0.4966,  0.4083, -0.6585, -0.4888,  0.0511,\n                      -0.1164,  0.6424,  0.5446, -0.3016, -0.2471,  0.7757,  0.4093, -0.6232],\n                     dtype=torch.float64)),\n             ('6.12.convpath.0.1.1.running_var',\n              tensor([0.7758, 0.5843, 0.5248, 0.4503, 0.6307, 0.4795, 0.3695, 0.4656, 0.4163,\n                      0.6106, 0.7637, 0.4951, 0.4428, 1.0930, 0.5325, 0.5584, 0.5000, 0.5542,\n                      0.4828, 0.6982, 0.6061, 0.5412, 0.6219, 0.4847, 0.7456, 0.5069, 0.4489,\n                      0.4655, 0.4122, 0.4522, 0.6073, 0.4349, 0.6295, 0.4845, 1.1838, 0.6203,\n                      0.5063, 0.4700, 0.4704, 0.3182, 0.5585, 0.4173, 0.4882, 0.8518, 0.3987,\n                      0.6489, 0.5742, 0.4507, 0.7601, 0.4160, 0.5150, 0.7346, 0.6092, 0.6886,\n                      1.1726, 0.4357, 0.6276, 0.7141, 0.6504, 0.4412, 0.5721, 0.4725, 0.6901,\n                      0.3921], dtype=torch.float64)),\n             ('6.12.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.12.convpath.0.2.0.weight',\n              tensor([[[ 4.2645e-02],\n                       [-4.4919e-02],\n                       [ 9.1611e-02],\n                       ...,\n                       [ 1.8184e-01],\n                       [ 4.4987e-02],\n                       [-7.1846e-02]],\n              \n                      [[-5.2676e-02],\n                       [-3.0656e-02],\n                       [-9.9997e-02],\n                       ...,\n                       [-2.5832e-03],\n                       [ 2.9083e-01],\n                       [-9.7800e-02]],\n              \n                      [[ 5.0634e-02],\n                       [ 4.2759e-02],\n                       [ 1.7114e-01],\n                       ...,\n                       [-2.1405e-04],\n                       [ 1.3658e-01],\n                       [ 8.1322e-02]],\n              \n                      ...,\n              \n                      [[-1.6691e-01],\n                       [ 2.2944e-01],\n                       [ 9.7645e-04],\n                       ...,\n                       [ 6.8186e-02],\n                       [-1.1157e-01],\n                       [ 5.7341e-02]],\n              \n                      [[ 3.2393e-02],\n                       [-6.8236e-02],\n                       [ 1.1008e-01],\n                       ...,\n                       [ 3.1608e-02],\n                       [-1.3980e-01],\n                       [ 8.9334e-02]],\n              \n                      [[-2.2162e-02],\n                       [-1.0166e-02],\n                       [ 2.3773e-01],\n                       ...,\n                       [-4.0543e-02],\n                       [-1.6363e-01],\n                       [ 1.0111e-01]]], dtype=torch.float64)),\n             ('6.12.convpath.0.2.1.weight',\n              tensor([ 4.3333e-03, -3.2985e-02,  3.9914e-03, -2.6680e-04,  1.3390e-02,\n                       5.7171e-03,  2.5363e-02,  1.4338e-02, -2.0090e-02, -2.2176e-03,\n                       9.1880e-03, -3.7147e-02,  1.0612e-02, -1.9335e-03, -5.7457e-03,\n                       1.7238e-02,  2.5920e-02,  7.0679e-03,  1.3227e-02,  2.9495e-02,\n                      -7.9638e-03,  1.7731e-02,  4.5621e-03,  1.3678e-02,  5.9185e-03,\n                       1.7896e-02,  9.2414e-03,  1.3525e-02,  1.6675e-02, -2.6282e-02,\n                       3.5259e-05,  1.6538e-02, -1.3696e-02,  1.9330e-02,  2.7159e-02,\n                       2.2065e-02,  1.1225e-02,  1.0586e-02, -2.6503e-02, -4.3072e-02,\n                       2.3337e-03, -3.3425e-02, -3.1829e-02,  2.3749e-03, -7.8579e-03,\n                      -1.0979e-02,  5.4345e-03,  6.3433e-03, -5.2358e-02,  1.4357e-02,\n                       1.2711e-02,  1.3936e-03,  1.0062e-02, -1.7712e-02, -8.6028e-03,\n                      -2.2248e-02, -7.1339e-03, -7.2612e-03,  2.3742e-03,  1.2199e-02,\n                       4.7175e-03, -9.7278e-03,  7.1659e-03,  1.6170e-03,  6.4444e-03,\n                       1.0993e-02,  7.1212e-03, -2.1645e-02,  2.4415e-03,  1.7752e-02,\n                       4.2838e-03,  1.2279e-02,  7.4552e-03, -2.1457e-02,  7.0103e-03,\n                       1.2902e-02,  2.3184e-02,  9.0124e-03, -1.0797e-03,  1.6717e-02,\n                       7.3032e-03, -1.2958e-02,  8.5208e-03, -1.1383e-02, -5.2576e-03,\n                       5.8323e-03, -3.4887e-03,  3.4044e-02, -1.6613e-02, -2.3611e-03,\n                      -1.4635e-02, -2.7882e-02, -1.0064e-02,  1.1715e-02,  1.7560e-02,\n                       2.7311e-03, -2.3777e-02, -2.2234e-02, -5.5099e-03,  1.1357e-02,\n                       2.5698e-02, -3.9072e-03,  2.1077e-02, -3.5788e-02, -1.9684e-02,\n                       1.4666e-02, -8.2681e-03,  2.3861e-02,  2.6581e-02, -1.3678e-02,\n                      -1.5686e-02, -1.1667e-02,  3.5243e-03,  1.1915e-02,  3.7788e-02,\n                       1.4163e-02,  9.0875e-03,  1.8285e-02,  1.9371e-02, -1.9560e-02,\n                       2.2672e-02,  5.7491e-03, -2.3855e-02,  1.8731e-02, -6.7731e-04,\n                      -3.1417e-02,  1.0569e-02, -2.8762e-03,  9.5676e-03,  1.5725e-02,\n                       5.6691e-03, -1.2855e-03,  1.9320e-02,  1.3017e-02, -2.3978e-02,\n                       2.2088e-02, -3.0879e-02,  1.8831e-02,  2.7621e-03,  1.7204e-02,\n                       7.7387e-03, -2.0760e-03,  2.5390e-02,  7.3766e-03,  1.0156e-02,\n                      -1.2003e-02,  1.5718e-02,  3.8513e-03, -1.8115e-02, -2.7875e-02,\n                      -7.2305e-03, -2.0790e-02,  7.2825e-03, -2.8709e-02, -3.7876e-02,\n                      -6.8566e-03,  9.1621e-03,  1.5685e-02, -1.7024e-02, -1.2376e-03,\n                      -2.0125e-02, -8.5298e-03, -2.8956e-03,  2.0038e-02, -1.8752e-02,\n                      -1.1455e-02,  6.8390e-03,  5.1941e-03, -8.6517e-03,  1.8406e-02,\n                      -1.0333e-02,  5.1810e-03,  1.0007e-02,  2.0577e-02, -2.2655e-02,\n                       3.7010e-03, -5.8759e-03,  8.3018e-03, -8.6059e-03,  1.1485e-02,\n                      -5.3462e-04,  1.8886e-02,  1.2490e-03,  7.4949e-03, -2.2191e-03,\n                       6.7708e-03, -1.6585e-02,  1.2357e-02, -1.1070e-02, -1.4082e-02,\n                       7.6563e-04, -9.5342e-03, -4.0074e-02, -4.3340e-02, -2.0792e-02,\n                      -1.1328e-02,  3.4753e-02,  5.3701e-03, -2.5156e-02, -1.3349e-02,\n                      -5.8134e-03, -3.2724e-02, -2.4255e-02,  1.5011e-02,  1.6584e-02,\n                       1.1896e-02,  3.8396e-03,  1.0835e-02,  3.9661e-03, -1.9407e-02,\n                      -7.8115e-03, -3.0624e-02,  4.0959e-02,  2.6369e-02, -1.7248e-02,\n                      -2.3680e-04, -1.4952e-02,  1.7921e-02, -2.8126e-02, -3.4492e-02,\n                       1.4971e-02, -2.0886e-02, -5.4711e-03,  1.1128e-02, -2.2040e-02,\n                      -8.8091e-03,  3.3865e-03, -3.1624e-03, -2.1064e-02, -2.5997e-02,\n                      -6.1313e-03,  5.7078e-03,  2.3235e-02,  3.4079e-03, -8.3955e-03,\n                      -1.7391e-02,  9.7061e-04,  2.1430e-02, -1.3030e-02, -3.8849e-02,\n                      -2.2701e-03,  2.1835e-02,  1.6006e-02,  5.3944e-03,  2.2795e-02,\n                       8.8596e-03, -9.8455e-03, -1.0179e-02, -2.1849e-02,  2.8151e-02,\n                       2.9802e-02,  1.9166e-02, -2.7278e-02, -5.1191e-03, -8.8329e-03,\n                       6.1739e-03], dtype=torch.float64)),\n             ('6.12.convpath.0.2.1.bias',\n              tensor([-2.5600e-04,  1.7020e-02,  1.0045e-02,  1.4077e-02,  2.1968e-03,\n                       7.5821e-03,  7.3552e-03, -6.8334e-04,  7.3275e-03,  1.4333e-02,\n                       1.5833e-02, -5.8730e-03,  8.1243e-03, -4.2887e-03,  9.5703e-03,\n                       2.4902e-04,  2.4685e-02, -9.6970e-04,  9.9541e-03, -3.2593e-03,\n                      -3.8560e-03,  4.8604e-04,  4.7689e-03,  6.7267e-03,  5.6186e-03,\n                      -1.6607e-02,  5.4133e-03,  6.2940e-03,  2.9117e-03, -1.7983e-03,\n                       1.7642e-03,  6.9711e-03, -1.2844e-03,  2.0768e-02,  5.8349e-03,\n                       1.6876e-02, -4.8159e-03,  1.8574e-02,  6.5640e-03,  1.2572e-02,\n                       7.8595e-04,  1.9110e-02, -9.6012e-03, -1.6159e-03,  7.9766e-03,\n                      -1.2446e-02,  1.4124e-02, -9.4082e-04, -1.2313e-02,  7.6576e-03,\n                       8.6440e-03,  4.1945e-03,  8.4791e-03,  1.3316e-02,  2.9959e-03,\n                       1.8845e-02,  9.5597e-03,  1.3199e-03,  1.2198e-02, -2.2303e-03,\n                       1.1571e-03,  1.5151e-03,  9.3999e-03,  9.4843e-03, -4.6687e-03,\n                       3.7606e-03, -1.0555e-02,  1.6097e-02, -5.9984e-04, -1.4805e-02,\n                       7.0054e-03,  3.3655e-03,  4.3141e-05, -7.8689e-03,  1.3777e-02,\n                       8.5932e-03,  2.4855e-03,  1.0963e-03,  3.4996e-03,  1.4961e-02,\n                       5.9398e-03, -6.7026e-03,  1.0933e-02,  5.1164e-03, -2.6523e-03,\n                       1.6488e-02,  1.1068e-03,  1.0784e-02,  1.5853e-02,  2.2014e-03,\n                       1.2374e-03,  9.3275e-03,  1.0455e-02,  9.5208e-04,  9.8636e-03,\n                      -1.4447e-02,  1.0779e-02,  6.5399e-03,  2.0659e-02,  3.8402e-03,\n                       1.8976e-02,  1.5091e-02,  5.1299e-03,  7.7587e-03, -2.0852e-03,\n                      -7.5260e-04, -4.1723e-03,  8.7620e-03,  9.1412e-03,  4.5257e-03,\n                      -1.3500e-02, -8.3322e-03,  5.3216e-03,  2.0198e-02,  1.4477e-02,\n                       5.0377e-03,  1.1875e-02,  3.9472e-03,  6.6442e-03, -1.4596e-02,\n                       3.3788e-04,  9.5697e-03, -8.3387e-04, -2.2317e-03,  2.4434e-04,\n                       1.1601e-02,  9.2506e-03,  5.2181e-03,  5.9043e-03,  1.3239e-02,\n                       7.2757e-03,  7.3823e-03,  1.3766e-02,  4.6326e-03,  1.6891e-02,\n                      -1.0387e-02,  8.0736e-03,  3.3363e-03,  6.1905e-03,  9.3296e-04,\n                       1.2954e-02, -8.0869e-03,  1.7141e-02,  3.9806e-03, -7.8536e-03,\n                       1.5639e-02,  4.1875e-03,  2.0371e-03,  1.2778e-02,  8.8516e-03,\n                       1.4130e-02,  1.6991e-02,  5.4017e-03,  1.2235e-02,  1.3049e-02,\n                       5.2551e-03, -1.4156e-03,  3.4166e-03, -3.7861e-04, -1.1388e-02,\n                       4.2257e-03, -4.9475e-03, -2.5110e-03,  1.0504e-02,  1.3990e-02,\n                      -2.6560e-03, -1.2329e-02,  1.0394e-02,  7.3265e-03,  2.1756e-02,\n                       1.8259e-03,  1.0314e-03,  5.3184e-03,  1.4547e-02, -1.3551e-02,\n                       1.0348e-02,  1.5567e-03,  1.5888e-02,  8.0573e-04,  4.9805e-03,\n                      -6.0100e-03,  1.3268e-02, -5.1664e-03, -8.5644e-03,  1.1752e-02,\n                       7.6632e-03,  1.5471e-02,  1.0756e-02,  4.7474e-03,  6.8514e-03,\n                       5.8507e-03,  3.1228e-03,  9.7273e-03,  1.4821e-04,  1.7491e-03,\n                       7.2844e-03,  1.6729e-02,  3.4953e-03,  7.5682e-03,  1.4828e-02,\n                      -9.7120e-04,  2.5077e-02,  1.7338e-02,  1.9577e-02,  1.4727e-02,\n                      -1.4192e-03,  7.4099e-03, -9.1286e-03,  6.5704e-03,  1.2738e-02,\n                       8.5957e-03,  1.0890e-02,  1.2723e-02,  1.5806e-03,  1.0670e-02,\n                       1.1850e-03,  5.3435e-03,  2.1925e-02,  5.9399e-03,  2.2693e-03,\n                      -5.3717e-03,  9.6136e-04,  2.1991e-03,  1.5042e-02,  2.2005e-03,\n                       3.8303e-03, -7.5251e-03, -5.3439e-04, -1.1964e-02,  1.4300e-02,\n                       5.6032e-03, -3.6194e-03,  5.8316e-03,  1.2587e-02,  1.0643e-03,\n                       8.0725e-03,  3.8096e-03,  5.2157e-03,  9.9200e-03,  1.0016e-02,\n                      -3.7368e-03,  3.2172e-03, -1.8096e-03,  1.4063e-02, -7.9539e-04,\n                       1.2141e-02,  4.6286e-03,  3.8485e-03, -1.0175e-02, -8.1536e-03,\n                       1.7679e-02,  2.4662e-02,  2.0427e-02,  1.7683e-02,  5.7350e-03,\n                       3.6259e-03], dtype=torch.float64)),\n             ('6.12.convpath.0.2.1.running_mean',\n              tensor([ 1.4753e-01, -3.0601e-01,  5.1817e-01,  4.1692e-01, -4.3183e-01,\n                      -2.1904e-01, -2.0195e-01, -1.0384e-01, -6.5060e-01, -4.7379e-01,\n                       3.0915e-01, -2.8250e-01,  1.3103e-02, -3.4402e-03, -4.5476e-01,\n                       1.6426e-01, -4.3117e-01,  2.3470e-01,  1.2453e-01,  3.6012e-01,\n                      -1.4442e-01,  2.0722e-01,  1.7161e-01, -1.7708e-01, -4.3544e-01,\n                       2.2440e-01,  4.2157e-01,  5.0408e-01,  6.6446e-01,  2.3939e-01,\n                      -2.4536e-01, -6.4491e-01,  1.4516e-01, -2.6177e-01, -1.2848e-01,\n                       2.8047e-01, -4.7213e-01, -9.6812e-01, -1.9556e-03, -6.3206e-02,\n                      -3.8405e-01,  4.8359e-01,  8.2157e-01,  4.5880e-01,  4.5355e-01,\n                       4.2089e-01,  1.7443e-01,  2.1376e-01,  1.6487e-01, -4.9049e-01,\n                      -4.9801e-02, -1.4256e-01, -4.4200e-01,  1.3034e+00, -1.2064e+00,\n                       3.4899e-01,  8.4597e-01,  1.8325e-02, -9.6387e-01,  7.0111e-01,\n                       1.5948e-01,  2.0721e-01, -2.2218e-01, -1.7130e-01, -6.9824e-01,\n                       5.5967e-01,  5.5855e-02, -1.8150e-01, -9.3013e-01,  4.4247e-01,\n                      -1.1931e-01,  1.4947e-01, -2.2282e-01, -3.4601e-01, -1.3687e-01,\n                       5.2105e-02, -1.7660e-01, -6.7380e-01, -3.3463e-01, -8.6035e-02,\n                      -8.7581e-01,  3.2253e-01,  6.0354e-01,  6.4281e-01, -5.8594e-01,\n                      -5.3835e-01,  5.0381e-01,  6.1174e-01, -9.1578e-02,  4.5787e-02,\n                       7.8894e-02, -9.1025e-02, -6.4429e-01, -4.3106e-01, -5.7191e-01,\n                      -8.9322e-02, -5.4603e-01, -4.1528e-01,  2.1133e-01,  5.2052e-02,\n                      -5.5254e-01, -5.7469e-01,  1.6737e-01, -2.3617e-01, -2.6254e-01,\n                      -2.5764e-01, -4.3746e-01, -2.9873e-01, -6.1210e-01,  4.8055e-01,\n                       7.1081e-02, -7.8498e-01,  6.4950e-01, -4.2057e-01,  7.0114e-01,\n                      -9.7119e-02, -4.1169e-01, -9.8688e-02, -7.0832e-01,  3.3856e-01,\n                      -3.6173e-01, -3.0683e-01, -1.9966e-01,  8.7885e-01, -2.1811e-01,\n                       5.9722e-02, -3.0662e-01, -4.1434e-01, -6.2363e-01, -1.1739e-01,\n                      -4.0327e-02,  1.1750e-03, -8.5319e-01, -2.4438e-01,  7.5235e-01,\n                      -3.8232e-01,  1.3725e-01,  6.2136e-01,  6.7773e-01,  7.9686e-01,\n                      -8.3322e-02, -1.3326e-01,  2.4364e-01, -4.5360e-01,  8.0759e-01,\n                      -1.2880e-01,  1.7840e-01,  1.4535e-01,  7.0434e-02,  3.1018e-01,\n                       3.5097e-01, -6.4020e-01, -2.7085e-01,  6.3063e-01,  1.3747e-01,\n                      -2.2307e-01,  3.2277e-01,  3.8238e-01,  4.0447e-01,  6.1100e-02,\n                      -8.0286e-01,  1.0218e-01,  1.7010e-01, -5.4063e-03,  7.2750e-01,\n                      -4.8741e-01, -7.0680e-04,  4.0081e-01,  1.7672e-02,  8.6178e-01,\n                      -3.6781e-01,  3.9942e-01, -1.1741e-01,  7.9297e-01, -5.2318e-01,\n                      -4.5091e-01,  1.5177e-01,  1.5965e-01,  6.4706e-02,  2.3996e-01,\n                       1.7680e-01, -1.5895e-01,  2.6762e-01,  4.7472e-01,  3.6022e-01,\n                      -7.2934e-01,  7.0720e-01, -6.1017e-01,  3.5189e-01, -9.7853e-03,\n                      -1.9449e-01,  8.0933e-01, -1.0425e-01,  3.6561e-01,  6.2799e-01,\n                       4.4417e-01, -1.0560e-01, -2.8244e-01,  1.2358e-01,  1.9057e-01,\n                      -3.2314e-01,  2.2405e-01,  3.5805e-01, -6.9201e-01, -1.2915e-01,\n                       3.6469e-01, -3.0913e-02,  1.6540e-01,  1.2815e-01,  9.2675e-02,\n                       6.8621e-02,  1.2617e-01, -3.3290e-01,  4.9898e-01,  3.1051e-02,\n                       3.3834e-01, -5.5665e-01,  3.8894e-01,  6.5896e-01,  2.3898e-01,\n                       1.7422e-02,  3.5232e-01, -1.4835e-01,  3.9643e-01,  5.5990e-02,\n                      -8.2668e-01, -5.3417e-01, -5.6419e-02, -4.0678e-01, -3.7904e-01,\n                      -4.4497e-01, -4.3355e-02,  4.0113e-01, -3.3066e-01, -3.6132e-01,\n                       2.4055e-01, -4.7341e-01,  2.8538e-01, -8.2936e-01,  1.6485e-01,\n                      -5.5315e-01,  1.9013e-01, -6.6564e-01,  4.4754e-01, -4.4832e-01,\n                       2.9771e-02, -3.3644e-01, -5.9301e-01,  5.8840e-02,  3.8288e-02,\n                       5.1611e-02, -2.7410e-01, -8.6876e-02,  2.9932e-01,  2.2284e-01,\n                       2.3446e-01], dtype=torch.float64)),\n             ('6.12.convpath.0.2.1.running_var',\n              tensor([0.3350, 0.4503, 0.3777, 0.2177, 0.3207, 0.1474, 0.4416, 0.1513, 0.2863,\n                      0.2286, 0.2043, 0.3801, 0.1718, 0.2988, 0.5335, 0.5760, 0.4489, 0.3237,\n                      0.2729, 0.5978, 0.2859, 0.3018, 0.4265, 0.2910, 0.2641, 0.2614, 0.3065,\n                      0.5153, 0.4380, 0.4443, 0.2279, 0.2849, 0.1423, 0.5226, 0.4146, 0.4074,\n                      0.2059, 0.3746, 0.3234, 0.4652, 0.3472, 0.3741, 0.3484, 0.4082, 0.3783,\n                      0.5932, 0.3533, 0.2218, 0.6305, 0.3294, 0.2853, 0.2677, 0.2416, 0.5568,\n                      0.3251, 0.3260, 0.3530, 0.6326, 0.5305, 0.3249, 0.1226, 0.2612, 0.2000,\n                      0.2177, 0.4144, 0.1071, 0.1756, 0.4027, 0.3514, 0.3843, 0.4361, 0.3753,\n                      0.1187, 0.5673, 0.5123, 0.1927, 0.5193, 0.4015, 0.3666, 0.1315, 0.3815,\n                      0.3982, 0.3193, 0.4592, 0.2200, 0.3698, 0.1644, 0.3850, 0.6212, 0.1188,\n                      0.4956, 0.5812, 0.5067, 0.3136, 0.5115, 0.1096, 0.5300, 0.2123, 0.0905,\n                      0.2473, 0.4239, 0.2464, 0.4142, 0.4949, 0.2562, 0.3198, 0.3961, 0.3760,\n                      0.4912, 0.3838, 0.2860, 0.5370, 0.2939, 0.3092, 0.4675, 0.4980, 0.4219,\n                      0.5931, 0.6321, 0.3104, 0.1622, 0.2184, 0.4998, 0.4400, 0.1929, 0.4879,\n                      0.2311, 0.1799, 0.2539, 0.4469, 0.0249, 0.1327, 0.4234, 0.1463, 0.4570,\n                      0.2362, 0.3333, 0.2238, 0.3357, 0.4647, 0.2632, 0.2340, 0.4119, 0.1367,\n                      0.2742, 0.3951, 0.3601, 0.5575, 0.2958, 0.5227, 0.3917, 0.3341, 0.2593,\n                      0.7426, 0.3549, 0.2147, 0.2287, 0.2589, 0.7083, 0.0556, 0.4847, 0.1636,\n                      0.1447, 0.4965, 0.4337, 0.3081, 0.4970, 0.3441, 0.3585, 0.4207, 0.1982,\n                      0.1102, 0.2390, 0.4796, 0.3769, 0.4840, 0.2099, 0.2077, 0.3524, 0.1851,\n                      0.2189, 0.3197, 0.3173, 0.3261, 0.1426, 0.3154, 0.2969, 0.2029, 0.6535,\n                      0.3368, 0.1074, 0.3799, 0.2907, 0.4698, 0.4837, 0.2754, 0.5035, 0.3669,\n                      0.4373, 0.4542, 0.2091, 0.6810, 0.3802, 0.3311, 0.3434, 0.3487, 0.1582,\n                      0.0636, 0.0855, 0.5924, 0.0801, 0.3918, 0.3443, 0.4168, 0.3292, 0.1314,\n                      0.6064, 0.3128, 0.3684, 0.5052, 0.3849, 0.4695, 0.0811, 0.3297, 0.4834,\n                      0.3965, 0.2263, 0.2799, 0.3948, 0.5244, 0.2479, 0.1348, 0.4891, 0.1633,\n                      0.2855, 0.6305, 0.3246, 0.2866, 0.6562, 0.3896, 0.3554, 0.3373, 0.3958,\n                      0.3256, 0.2976, 0.3648, 0.4963, 0.3051, 0.2849, 0.3910, 0.3885, 0.5122,\n                      0.2935, 0.1862, 0.2973, 0.2718], dtype=torch.float64)),\n             ('6.12.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.13.convs.0.0.weight',\n              tensor([[[-0.0171],\n                       [ 0.0466],\n                       [ 0.0559],\n                       ...,\n                       [-0.0358],\n                       [-0.0417],\n                       [-0.0885]],\n              \n                      [[-0.0490],\n                       [-0.0320],\n                       [-0.0085],\n                       ...,\n                       [-0.0381],\n                       [-0.0539],\n                       [ 0.0024]],\n              \n                      [[ 0.0459],\n                       [ 0.0733],\n                       [-0.0337],\n                       ...,\n                       [ 0.0959],\n                       [ 0.0054],\n                       [-0.0658]],\n              \n                      ...,\n              \n                      [[ 0.0207],\n                       [ 0.0258],\n                       [ 0.0256],\n                       ...,\n                       [-0.0267],\n                       [ 0.1061],\n                       [ 0.0363]],\n              \n                      [[ 0.0286],\n                       [-0.1582],\n                       [ 0.0615],\n                       ...,\n                       [ 0.1192],\n                       [ 0.0957],\n                       [ 0.1393]],\n              \n                      [[-0.0808],\n                       [-0.0834],\n                       [ 0.0938],\n                       ...,\n                       [ 0.1318],\n                       [-0.0147],\n                       [-0.0764]]], dtype=torch.float64)),\n             ('6.13.convs.0.1.weight',\n              tensor([0.9778, 0.9821, 0.9600, 0.9657, 0.9603, 0.9639, 0.9758, 0.9548, 0.9760,\n                      0.9659, 0.9573, 0.9684, 0.9999, 0.9296, 0.9633, 0.9526, 0.9379, 0.9738,\n                      0.9416, 0.9574, 0.9881, 0.9777, 0.9599, 0.9635, 0.9565, 0.9750, 0.9682,\n                      0.9410, 0.9330, 0.9437, 0.9698, 0.9792, 0.9644, 0.9665, 0.9439, 1.0003,\n                      0.9691, 0.9729, 0.9612, 0.9771, 0.9661, 0.9811, 0.9842, 0.9632, 0.9750,\n                      0.9571, 0.9783, 0.9752, 0.9870, 0.9574, 0.9505, 0.9511, 0.9727, 0.9432,\n                      0.9730, 0.9982, 0.9549, 0.9979, 1.0022, 0.9893, 0.9596, 0.9346, 0.9622,\n                      0.9766], dtype=torch.float64)),\n             ('6.13.convs.0.1.bias',\n              tensor([ 0.0017,  0.0037, -0.0169, -0.0129, -0.0200,  0.0030,  0.0041, -0.0009,\n                       0.0016,  0.0157,  0.0027, -0.0061,  0.0372,  0.0020,  0.0021,  0.0108,\n                      -0.0081,  0.0119, -0.0060,  0.0144,  0.0098, -0.0071,  0.0046,  0.0078,\n                      -0.0094,  0.0070, -0.0050,  0.0135, -0.0263,  0.0029,  0.0089,  0.0019,\n                      -0.0067, -0.0186,  0.0013,  0.0226,  0.0009,  0.0122, -0.0149,  0.0019,\n                       0.0058, -0.0046,  0.0151, -0.0163,  0.0019, -0.0048,  0.0099,  0.0123,\n                       0.0095, -0.0013, -0.0208, -0.0251, -0.0023, -0.0028,  0.0127,  0.0119,\n                       0.0157,  0.0219,  0.0140, -0.0046, -0.0129,  0.0052, -0.0041,  0.0150],\n                     dtype=torch.float64)),\n             ('6.13.convs.0.1.running_mean',\n              tensor([-0.5705,  0.1955,  1.6724,  0.8388,  1.2055, -0.0280, -0.4704,  0.6609,\n                      -0.2674, -0.5305, -0.1330,  0.4741, -0.4546, -0.9844, -0.3226, -0.0108,\n                      -1.2653,  0.5629, -0.6295, -0.3457, -0.1934,  1.4640, -1.0251,  1.1369,\n                       0.5671,  0.1600,  0.2716, -0.5820, -0.3679, -0.2190, -0.5219, -0.7149,\n                       0.1950, -0.0680, -0.2078, -0.2351,  1.7980, -0.1021,  1.3794,  0.0544,\n                       0.3415,  0.3088,  0.4475,  0.6645,  0.0172, -0.6267, -0.1309,  0.3605,\n                       0.1949,  0.5779,  0.6670,  0.8631,  0.5621,  1.3369, -0.2124, -0.8789,\n                      -1.3022,  0.4782, -0.7564, -0.8544,  1.3024, -1.1875,  0.4247, -0.0363],\n                     dtype=torch.float64)),\n             ('6.13.convs.0.1.running_var',\n              tensor([0.0818, 0.1604, 1.6647, 0.5731, 0.6027, 0.1323, 0.2977, 0.4069, 0.1752,\n                      0.2945, 0.3839, 0.1466, 0.1137, 1.0702, 0.2503, 0.5533, 0.1713, 0.3160,\n                      0.5696, 0.2020, 0.2139, 0.3312, 0.1362, 1.3043, 0.2385, 0.3023, 0.1823,\n                      0.7287, 0.3828, 0.0757, 0.1310, 0.2247, 0.3231, 0.0993, 0.4513, 0.0856,\n                      0.3543, 0.1920, 0.5381, 0.1433, 0.2449, 0.1507, 0.1008, 0.1254, 0.7459,\n                      0.4307, 0.1503, 0.1286, 0.1770, 0.4843, 0.7279, 0.5958, 0.6142, 0.0990,\n                      0.1254, 0.1339, 0.7094, 0.1357, 0.2193, 0.1044, 1.1201, 0.8450, 0.4090,\n                      0.1854], dtype=torch.float64)),\n             ('6.13.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.13.convs.1.0.weight',\n              tensor([[[-1.4548e-01, -6.0081e-02, -2.7059e-02, -5.8420e-02,  2.5364e-02],\n                       [ 2.4933e-02, -4.2873e-02, -2.8073e-02, -6.9013e-02, -2.7364e-02],\n                       [-2.0948e-02,  6.9798e-03,  5.8242e-02, -1.1626e-01,  1.7592e-02],\n                       ...,\n                       [ 5.0084e-02, -5.4315e-02, -3.6414e-02, -1.2853e-02, -3.6543e-02],\n                       [ 5.2874e-02,  4.9857e-02,  6.9492e-02, -9.5053e-02, -2.7161e-02],\n                       [-1.1644e-01,  7.5752e-02,  3.1112e-02, -2.8855e-02, -3.9235e-02]],\n              \n                      [[-1.5654e-01,  7.3430e-03, -2.7421e-02,  7.1822e-02, -4.6880e-02],\n                       [-8.4769e-02, -2.9939e-02,  7.7032e-03,  3.3473e-02,  1.1162e-01],\n                       [-3.8761e-02, -9.5768e-02,  1.2726e-02, -6.8003e-02,  6.0147e-02],\n                       ...,\n                       [-8.0171e-02, -1.6173e-01, -6.2211e-02, -1.6270e-01,  7.1253e-02],\n                       [-2.1825e-02,  4.6477e-02, -2.1266e-02, -5.8885e-02, -9.6070e-03],\n                       [-8.2920e-03,  4.0409e-02,  4.4635e-02,  4.7182e-02, -1.3776e-01]],\n              \n                      [[-5.0762e-02,  3.9749e-02,  5.7687e-02, -7.9778e-02, -3.2109e-02],\n                       [-8.0852e-02, -7.0447e-02,  5.1158e-02, -4.8903e-03,  6.0413e-02],\n                       [ 1.6301e-02, -1.1975e-01, -2.5601e-02, -3.5559e-02,  3.0498e-04],\n                       ...,\n                       [ 1.2384e-01,  2.9540e-02, -4.9960e-02, -8.3949e-02, -9.0407e-02],\n                       [-8.0676e-02, -1.7478e-01,  4.2582e-02, -1.2974e-01, -5.7886e-02],\n                       [-1.0883e-01,  6.2665e-04,  7.7072e-02,  1.6236e-02,  6.3000e-02]],\n              \n                      ...,\n              \n                      [[ 6.4901e-02, -7.1595e-03,  9.8509e-02, -3.6420e-03, -5.6746e-02],\n                       [ 1.3131e-01, -4.7154e-02, -9.7348e-02,  4.0171e-02, -1.2041e-01],\n                       [ 5.6126e-02, -3.8203e-02,  1.3718e-01,  3.8906e-02,  7.1897e-02],\n                       ...,\n                       [ 1.7149e-02,  7.3543e-03,  3.8296e-02, -7.9906e-02,  1.7509e-02],\n                       [ 1.1866e-01, -1.4766e-01, -1.2177e-03, -1.7202e-01, -1.1195e-01],\n                       [-8.4962e-02, -1.2995e-02,  9.3062e-03, -1.6297e-01, -3.8770e-02]],\n              \n                      [[-7.1619e-02, -2.0431e-02,  8.3252e-02, -6.2487e-02,  1.8180e-01],\n                       [-7.8980e-02, -7.6899e-03,  4.5549e-02, -2.9508e-02,  8.4784e-02],\n                       [-1.5468e-01, -1.3886e-01,  1.3574e-02,  5.2715e-02,  2.7708e-05],\n                       ...,\n                       [-1.3815e-01, -4.8067e-03, -1.5901e-02, -8.3183e-02,  6.4381e-04],\n                       [ 3.1024e-02, -8.5193e-02, -1.8651e-01,  2.4245e-02, -2.1807e-01],\n                       [-3.1928e-03, -1.5661e-01,  6.4474e-02,  1.0194e-01, -6.7360e-02]],\n              \n                      [[-1.6357e-01, -4.4661e-02, -6.1795e-02, -2.6217e-03,  3.1399e-02],\n                       [-9.2542e-02,  9.8082e-02, -6.0010e-02, -8.8338e-04,  9.7368e-02],\n                       [ 8.3721e-02, -4.6371e-02, -2.2987e-02,  1.2923e-01,  4.2175e-02],\n                       ...,\n                       [-9.6165e-02, -7.7653e-03,  4.7100e-02,  5.1517e-02,  8.0729e-02],\n                       [-6.2907e-02, -7.5381e-02, -3.0818e-02, -1.3653e-01, -1.0445e-01],\n                       [ 4.0789e-02, -3.4180e-02,  1.0727e-01,  8.4954e-03, -5.6275e-02]]],\n                     dtype=torch.float64)),\n             ('6.13.convs.1.1.weight',\n              tensor([1.0010, 0.9663, 0.9698, 0.9487, 0.9567, 0.9623, 0.9531, 0.9555, 1.0001,\n                      0.9614, 0.9682, 0.9626, 0.9687, 0.9748, 0.9658, 0.9486, 0.9752, 0.9647,\n                      0.9664, 0.9792, 0.9473, 0.9789, 0.9607, 0.9629, 0.9802, 0.9722, 0.9204,\n                      0.9789, 0.9597, 0.9574, 0.9555, 0.9855, 0.9867, 0.9601, 0.9418, 0.9706,\n                      0.9722, 0.9618, 0.9627, 0.9632, 0.9581, 0.9444, 0.9952, 0.9689, 0.9705,\n                      0.9611, 0.9497, 0.9741, 0.9600, 0.9498, 0.9465, 0.9610, 0.9757, 0.9530,\n                      0.9395, 0.9721, 0.9714, 0.9642, 0.9593, 0.9576, 0.9628, 0.9479, 0.9767,\n                      0.9489], dtype=torch.float64)),\n             ('6.13.convs.1.1.bias',\n              tensor([ 2.2191e-02, -1.9797e-02, -5.4914e-04,  6.8388e-03, -1.9183e-02,\n                       6.5534e-03,  3.3478e-04,  1.4414e-03,  3.4087e-02, -7.5099e-03,\n                       1.4579e-02, -1.7031e-02, -3.5580e-03,  1.1472e-02,  1.6541e-02,\n                      -1.4898e-03,  4.9320e-04,  4.0031e-07, -4.0037e-03, -2.7737e-03,\n                      -5.5625e-04,  1.0401e-03, -9.9758e-03, -4.4800e-03,  1.1606e-03,\n                      -1.2184e-02, -1.1498e-02, -4.0597e-03, -1.0666e-02,  3.0479e-03,\n                       1.6056e-02,  1.1323e-02,  1.9979e-02,  9.4837e-03, -1.3558e-02,\n                       1.0922e-02, -4.2005e-03,  8.2197e-03, -4.7835e-03, -1.7147e-02,\n                      -1.3034e-02,  1.3582e-02,  9.4440e-03,  4.0566e-03, -1.8755e-03,\n                      -4.8153e-03,  2.9140e-03,  1.2538e-02, -1.2239e-02,  4.8748e-04,\n                      -8.2226e-03,  7.3608e-04, -6.7241e-03, -2.4716e-02, -1.5144e-02,\n                      -2.8047e-03, -8.1725e-03,  2.3615e-02, -1.1297e-02, -7.4358e-03,\n                      -7.1439e-03, -3.8513e-03,  1.4019e-04, -1.6053e-03],\n                     dtype=torch.float64)),\n             ('6.13.convs.1.1.running_mean',\n              tensor([-4.3767e-01, -3.5169e-01, -4.8482e-01, -7.9885e-01,  2.0882e-01,\n                      -4.9010e-01,  5.3561e-01, -3.3310e-02, -7.4366e-01,  2.5952e-01,\n                      -2.7686e-01,  2.8710e-01,  3.3390e-01, -6.2427e-01,  9.5532e-02,\n                       5.8640e-02,  7.5632e-03, -7.6850e-01, -5.2135e-01, -1.9176e-04,\n                      -9.2832e-01, -7.3453e-02,  8.8578e-01,  5.2217e-01, -5.3165e-01,\n                       2.7525e-01, -7.3558e-01,  3.2225e-01,  3.1069e-01, -3.3549e-01,\n                       2.9882e-02,  2.6587e-01, -7.0607e-01, -1.2120e-01, -1.0605e-01,\n                      -1.8391e-01, -2.1154e-01, -8.2011e-01, -3.0112e-02,  3.0164e-01,\n                       1.3161e-01, -9.5813e-01, -3.3909e-02, -6.9102e-01,  4.5450e-01,\n                      -3.1132e-01,  2.5933e-01, -2.2675e-01, -1.7857e-02,  6.1876e-02,\n                      -7.1365e-01, -5.5025e-01, -4.6579e-01,  1.0815e-01, -4.2908e-01,\n                       2.9207e-01,  3.3943e-01, -8.4226e-01,  3.5619e-02,  1.6953e-02,\n                       2.0708e-01, -8.7690e-01,  9.4395e-02,  1.0529e-01],\n                     dtype=torch.float64)),\n             ('6.13.convs.1.1.running_var',\n              tensor([0.5844, 0.9954, 0.5082, 0.9178, 0.6175, 0.6581, 0.4834, 1.1521, 0.5605,\n                      0.5491, 0.5730, 0.5612, 0.7454, 0.7830, 0.6046, 0.5962, 0.6327, 0.6858,\n                      0.6639, 0.3449, 0.6112, 0.4824, 0.7322, 0.6266, 0.7572, 0.3791, 0.6467,\n                      0.4990, 0.8153, 1.2824, 0.5141, 0.5516, 0.6154, 0.5150, 0.6305, 0.7988,\n                      0.5225, 0.7691, 0.4227, 0.5030, 0.3966, 0.9883, 0.5631, 0.9327, 0.6956,\n                      0.5729, 0.5655, 0.7164, 0.8374, 0.5203, 0.8330, 0.5797, 0.4854, 0.9130,\n                      0.6093, 0.5595, 0.7818, 0.7221, 0.5959, 0.9039, 0.5992, 0.6503, 0.4518,\n                      1.0118], dtype=torch.float64)),\n             ('6.13.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.13.convs.2.0.weight',\n              tensor([[[ 0.0519],\n                       [-0.0516],\n                       [-0.1350],\n                       ...,\n                       [-0.0462],\n                       [-0.1625],\n                       [ 0.0618]],\n              \n                      [[ 0.0452],\n                       [ 0.1068],\n                       [-0.2067],\n                       ...,\n                       [ 0.0367],\n                       [-0.0881],\n                       [-0.0796]],\n              \n                      [[-0.0415],\n                       [-0.1307],\n                       [ 0.0260],\n                       ...,\n                       [-0.0423],\n                       [ 0.0027],\n                       [ 0.0026]],\n              \n                      ...,\n              \n                      [[ 0.0579],\n                       [ 0.0510],\n                       [-0.0494],\n                       ...,\n                       [ 0.0419],\n                       [-0.0481],\n                       [ 0.1872]],\n              \n                      [[ 0.1596],\n                       [ 0.0068],\n                       [ 0.0626],\n                       ...,\n                       [-0.0255],\n                       [-0.0219],\n                       [ 0.0025]],\n              \n                      [[ 0.0219],\n                       [ 0.2924],\n                       [-0.2022],\n                       ...,\n                       [-0.0019],\n                       [-0.2145],\n                       [-0.0057]]], dtype=torch.float64)),\n             ('6.13.convs.2.1.weight',\n              tensor([ 9.0264e-04, -1.8442e-03,  7.8081e-03, -2.7761e-03, -2.3762e-03,\n                      -8.1073e-03, -9.2309e-03,  2.8186e-02,  3.0679e-05,  9.4049e-03,\n                      -3.0244e-02, -2.4950e-02, -1.3176e-02, -1.0886e-02,  1.5435e-02,\n                       2.3951e-02, -1.7138e-02, -1.2674e-03, -1.2846e-02, -4.8328e-04,\n                      -2.0524e-02,  1.9178e-02, -1.6388e-03,  1.7316e-03, -3.2421e-02,\n                       8.7399e-03, -3.2143e-02, -3.4827e-03, -2.7582e-02,  1.6249e-02,\n                      -2.0744e-02, -2.0761e-02, -2.8662e-03, -8.5422e-03, -5.9387e-03,\n                       1.6644e-02, -9.6083e-03,  1.5628e-02,  3.1499e-05, -3.2163e-03,\n                      -5.6035e-03,  1.2028e-02,  1.2773e-02, -1.2157e-02, -1.5288e-03,\n                      -3.0308e-03, -3.1764e-02, -1.2567e-02,  5.2686e-03,  5.2975e-03,\n                      -1.6833e-02,  3.8504e-03,  3.8320e-03,  1.9051e-03,  1.4378e-02,\n                       5.9967e-02,  2.4584e-02, -2.5146e-03, -1.7227e-03,  5.1612e-03,\n                      -8.1995e-03, -4.4886e-03, -3.2472e-02,  1.5959e-02, -3.2776e-02,\n                      -1.1816e-02, -6.9172e-03,  1.5806e-02,  2.2582e-02,  1.6673e-02,\n                       4.1314e-03,  4.6527e-03, -4.7516e-03,  9.5212e-03,  2.8346e-02,\n                       5.4278e-03,  4.9834e-03, -1.4716e-02,  2.2329e-02, -9.3704e-03,\n                       7.0517e-03,  1.0359e-02, -1.0477e-02, -3.1556e-03,  9.0022e-03,\n                       6.4094e-03, -7.8552e-03,  2.1836e-02,  4.8672e-05,  7.7626e-03,\n                      -2.5395e-03,  7.4278e-03,  1.3625e-02, -1.7499e-02,  2.1558e-02,\n                      -1.3903e-02, -7.9741e-03, -1.7599e-02, -7.7283e-04,  1.6247e-02,\n                       1.6919e-02, -1.2140e-02,  1.5336e-03, -1.3440e-02, -7.5494e-03,\n                      -2.3736e-02,  1.9984e-02,  8.0849e-03, -2.5506e-02,  2.3528e-03,\n                       2.7488e-03, -6.5428e-03,  2.6358e-02, -2.2948e-02,  1.0978e-02,\n                       1.5734e-02, -2.4465e-02,  1.1182e-02, -3.5343e-02, -1.3823e-02,\n                       1.2170e-02,  1.1022e-02, -3.0964e-03,  2.3041e-03,  2.1905e-02,\n                      -3.2901e-02,  1.0712e-02, -1.5463e-02,  1.3127e-02, -2.6933e-03,\n                      -2.0616e-03, -1.6855e-02,  1.6730e-02,  1.6052e-02, -8.3106e-03,\n                       1.1990e-02,  2.8264e-03,  5.3277e-03, -1.7021e-02, -8.6031e-03,\n                       2.9925e-02,  2.5197e-02,  1.8990e-02,  1.5761e-02,  1.0350e-02,\n                       1.3884e-02, -1.0856e-02,  1.0129e-02, -1.4048e-02, -9.6497e-03,\n                      -1.1583e-02, -3.8121e-03, -1.8518e-02,  2.0526e-02,  5.1410e-04,\n                       1.4138e-02, -2.2857e-02,  2.1986e-03,  1.1884e-02,  1.4280e-02,\n                      -2.9263e-03,  7.9252e-03,  2.9437e-02, -1.5536e-03, -2.7173e-02,\n                       1.6297e-02, -3.9052e-02, -1.6970e-02,  9.1741e-03, -3.7511e-02,\n                       1.2486e-04,  5.7046e-03, -6.8798e-04, -6.2910e-03, -5.5737e-03,\n                      -5.6677e-03,  1.9926e-02,  3.1230e-02,  2.1947e-03,  2.4191e-02,\n                       9.4773e-03, -4.3795e-03, -8.4010e-03, -1.6261e-02,  1.1966e-02,\n                       7.0355e-03,  1.3800e-03, -5.4656e-03,  1.7027e-02, -4.1955e-04,\n                      -2.9646e-03,  2.9417e-02, -8.1331e-03,  1.9180e-02, -3.2995e-02,\n                      -3.5414e-03,  1.7536e-02,  4.7590e-03,  6.3905e-04,  2.0163e-02,\n                      -3.0102e-04, -2.3761e-02,  1.1434e-03, -3.2357e-02, -1.8739e-02,\n                      -1.3880e-02,  2.3332e-03,  9.9259e-03,  1.8760e-02, -1.9919e-02,\n                       2.1322e-02, -6.3412e-04, -4.3835e-02, -1.5551e-02,  1.5436e-02,\n                       9.7790e-03, -1.4621e-03, -6.9060e-04, -2.4824e-02, -9.8609e-03,\n                      -1.8598e-02,  1.6646e-02,  1.0271e-02,  9.2319e-03,  9.4591e-03,\n                      -2.9256e-03,  1.5250e-02, -9.6402e-03,  1.7530e-02,  2.1543e-02,\n                       4.0701e-03, -5.1803e-03, -1.5343e-04, -2.2187e-02,  3.4696e-03,\n                       1.0980e-02,  6.4323e-03, -7.4039e-03,  7.9961e-03,  1.4056e-02,\n                       1.5447e-03,  4.7254e-03,  1.4236e-03,  9.7185e-04, -9.4150e-04,\n                       4.7475e-04, -7.1570e-03,  2.3596e-02, -4.5919e-03, -4.2937e-02,\n                       3.7873e-02, -3.0164e-02,  2.3760e-03, -7.3786e-03,  5.2193e-04,\n                       3.3035e-02], dtype=torch.float64)),\n             ('6.13.convs.2.1.bias',\n              tensor([ 8.1188e-06,  9.3859e-03,  9.2961e-03,  1.4093e-02,  3.5178e-03,\n                       9.6883e-03,  7.1956e-03, -7.1808e-04,  1.4511e-02,  1.5965e-02,\n                       1.5775e-02, -6.2965e-03,  5.5444e-03, -5.1574e-03,  8.0633e-03,\n                       2.3873e-03,  2.4227e-02, -1.1772e-03,  9.9406e-03, -3.3031e-03,\n                      -4.7985e-03,  5.2502e-04,  5.1964e-03,  6.5902e-03,  5.0445e-03,\n                      -1.7085e-02,  3.8389e-03,  7.7876e-03,  1.4593e-02, -7.1374e-03,\n                       9.1926e-04,  7.3146e-03, -3.2220e-03,  2.0801e-02,  3.6378e-03,\n                       1.5466e-02, -2.5558e-03,  1.7172e-02,  1.1054e-02,  1.1730e-02,\n                       2.0702e-03,  1.7164e-02, -1.2344e-02, -1.8373e-03,  6.9630e-03,\n                      -1.2725e-02,  1.4439e-02,  6.2896e-03, -1.2343e-02,  1.8317e-03,\n                       8.3281e-03,  4.1248e-03,  7.4451e-03,  1.7264e-02,  3.7784e-03,\n                       1.9088e-02,  8.8985e-03,  1.3304e-03,  1.2174e-02, -2.9547e-03,\n                      -7.5268e-04,  5.1524e-04,  9.4787e-03,  8.5604e-03, -5.8265e-03,\n                       2.8080e-03, -1.0708e-02,  1.4742e-02, -2.0457e-03, -1.4956e-02,\n                       7.2167e-03,  3.1540e-03, -7.0523e-04, -8.0911e-03,  1.3436e-02,\n                       6.0556e-03,  2.2118e-04, -1.1355e-03,  2.8094e-03,  1.4773e-02,\n                       5.2919e-03, -8.2789e-03,  1.0413e-02,  4.1866e-03, -3.4977e-03,\n                       1.6590e-02, -2.9025e-04,  1.3983e-02,  1.4462e-02,  3.9924e-04,\n                       2.7518e-04,  1.0580e-02,  1.0004e-02,  2.8441e-03,  1.1647e-02,\n                      -8.7508e-03,  1.2464e-02, -1.5488e-03,  2.0702e-02,  6.4013e-03,\n                       1.8810e-02,  1.5998e-02,  3.6197e-03,  1.1261e-02, -5.3379e-04,\n                       5.4579e-04, -6.2880e-03,  1.1352e-02,  8.2945e-03,  2.7038e-03,\n                      -1.3244e-02, -9.2793e-03,  4.5037e-03,  1.9861e-02,  1.4106e-02,\n                       5.9143e-03,  9.8287e-03,  2.6533e-03,  6.5537e-03, -1.3839e-02,\n                      -1.7607e-04,  9.6864e-03,  1.1683e-03, -4.9378e-04,  1.1176e-02,\n                       9.9491e-03,  6.9958e-03,  5.2945e-03,  4.9082e-03,  1.2865e-02,\n                       6.7311e-03,  5.8107e-03,  1.3728e-02,  5.4030e-03,  8.8502e-03,\n                      -1.2701e-02,  1.4475e-02,  3.7615e-03,  6.0663e-03, -2.8962e-03,\n                       1.3033e-02, -1.2167e-02,  1.6747e-02,  2.1833e-03, -4.9723e-03,\n                       1.6532e-02,  5.4126e-03, -8.0455e-04,  1.2399e-02,  8.4627e-03,\n                       1.1890e-02,  1.4772e-02,  6.2747e-03,  1.2290e-02,  1.0989e-02,\n                       4.7254e-03, -1.6241e-03,  6.4660e-03,  8.0668e-04, -1.2979e-02,\n                       2.4385e-03,  4.7222e-04, -2.2378e-03,  7.5218e-03,  1.2945e-02,\n                      -3.2596e-03, -1.3042e-02,  9.7880e-03,  7.3170e-03,  2.1177e-02,\n                       1.6999e-03,  1.4970e-03,  5.4934e-03,  1.4688e-02, -1.3014e-02,\n                       1.0316e-02,  1.0022e-03,  1.5179e-02,  1.3242e-03,  5.8099e-03,\n                      -5.9191e-03,  1.1417e-02, -7.0672e-03, -8.8494e-03,  1.2337e-02,\n                       8.0209e-03,  1.4096e-02,  9.3819e-03,  6.4982e-03,  8.1123e-03,\n                       5.9088e-03,  4.9292e-03,  6.0037e-03,  1.1428e-03,  1.6777e-03,\n                       9.8802e-03,  1.1496e-02,  2.6247e-03,  5.1550e-03,  1.4937e-02,\n                      -7.0068e-04,  2.2734e-02,  1.8110e-02,  2.0024e-02,  1.8069e-02,\n                      -1.7547e-03,  9.1308e-03, -1.1559e-02,  6.6428e-03,  1.2718e-02,\n                       9.3185e-03,  1.0902e-02,  1.1870e-02,  6.6168e-03,  8.5487e-03,\n                       1.9172e-03,  4.8528e-03,  1.6108e-02,  4.3948e-03,  4.4651e-03,\n                       8.3401e-03, -3.7677e-04,  2.5471e-03,  1.5156e-02,  7.8935e-04,\n                       7.2086e-03, -6.9722e-03, -1.5534e-03,  2.0729e-02,  1.6517e-02,\n                       3.2275e-03, -4.2153e-03,  4.9803e-03,  1.2740e-02, -3.3138e-04,\n                       7.5377e-03,  2.5846e-03,  6.6910e-03,  7.0040e-03,  7.5547e-03,\n                      -3.4200e-03, -2.2858e-04, -2.1586e-03,  1.2933e-02,  1.1062e-03,\n                       9.3007e-03,  3.5708e-03,  3.5857e-03, -1.2534e-02, -1.0333e-02,\n                       2.0282e-02,  2.4897e-02,  1.8509e-02,  1.7617e-02,  2.8039e-03,\n                       4.0916e-03], dtype=torch.float64)),\n             ('6.13.convs.2.1.running_mean',\n              tensor([-7.5019e-02,  3.4987e-01,  5.9603e-02,  8.1202e-02, -1.1371e-01,\n                      -7.7833e-01,  9.6499e-03, -2.9537e-01,  1.8077e-01, -3.9717e-01,\n                      -3.3094e-01, -7.1698e-01,  2.3992e-01,  5.0273e-01, -5.2787e-01,\n                      -6.5982e-01,  9.3607e-01, -8.7359e-02,  9.0010e-01,  9.3877e-02,\n                      -1.6932e-01,  9.0360e-02, -9.9249e-02, -6.9108e-03,  8.3004e-01,\n                       6.0121e-02, -1.3261e+00, -1.8313e-02, -4.5757e-02,  6.3813e-01,\n                       4.9511e-01,  8.0187e-03,  8.1358e-02,  4.8489e-01, -1.3992e-01,\n                      -1.6722e-01,  7.6294e-02, -7.6344e-01, -7.3700e-02, -1.1355e-01,\n                      -1.2237e-01, -1.0308e-01,  5.9181e-02, -2.6961e-01,  2.2003e-01,\n                       2.6055e-01, -3.6410e-01, -2.1450e-01,  2.2604e-01, -8.8875e-01,\n                       5.7539e-02, -5.1677e-01, -2.5665e-01, -1.2461e-01,  4.6009e-01,\n                       3.9679e-01,  6.3269e-03,  5.4402e-01, -2.0966e-01,  1.3705e-01,\n                       3.2988e-01,  1.1380e-01,  1.1383e-01, -1.4972e-01,  8.5433e-01,\n                      -1.4535e-01,  7.6311e-01,  4.3342e-01, -1.4459e-01, -3.4254e-01,\n                       3.7322e-01,  1.1451e-01,  1.8938e-02, -3.2956e-01,  5.5660e-01,\n                       3.1419e-01,  5.7530e-01,  2.8784e-01,  2.6796e-01, -2.4315e-01,\n                       1.6871e-01,  5.2095e-01, -6.4603e-02,  1.7638e-01, -2.3244e-02,\n                      -1.4593e-01, -2.1309e-01,  4.0366e-02,  2.4277e-01,  2.6452e-02,\n                       5.0399e-01,  3.4196e-01, -2.4411e-01, -2.0873e-01, -5.7462e-01,\n                      -4.7988e-01,  6.9530e-02, -1.7714e-02,  7.2791e-02, -3.0984e-01,\n                      -1.7332e-01,  3.1703e-01,  1.1177e-01,  1.2807e-01, -6.9931e-02,\n                       5.6725e-02, -3.4908e-01,  6.5505e-02,  4.4137e-02,  2.5664e-02,\n                      -2.5894e-01, -8.1149e-01, -6.4786e-02,  5.8094e-01,  7.8395e-01,\n                      -1.9563e-01,  6.9253e-01, -2.9486e-01,  5.1291e-01, -1.7648e-01,\n                       3.8404e-01, -1.0654e-01,  7.5491e-01,  6.1168e-01, -8.2250e-02,\n                       7.5600e-01,  3.6907e-02, -7.2429e-01,  5.5753e-02,  3.1528e-01,\n                       2.7916e-02,  5.2273e-01,  1.6702e-01, -1.6596e-01, -5.4292e-01,\n                       3.7348e-02, -2.7012e-01, -2.1488e-01, -2.6215e-01,  1.0019e-01,\n                      -8.9256e-02,  5.9688e-01,  2.9512e-02,  5.7577e-01,  1.9496e-01,\n                      -5.4371e-01,  1.7891e-01,  6.8517e-01, -3.1385e-03, -1.7543e-01,\n                       1.1274e+00, -5.4757e-01, -9.9244e-02, -9.0421e-01, -1.2888e-01,\n                      -4.9647e-02, -3.8015e-01, -4.3676e-02, -1.0141e+00,  5.3824e-01,\n                       1.0095e-01, -1.7301e-01, -4.7507e-01,  8.7340e-02, -1.1037e-01,\n                      -8.2543e-02,  5.7178e-01,  7.4243e-01,  6.5475e-02, -5.4299e-01,\n                      -3.8479e-01, -8.5238e-02, -3.1859e-01,  1.0898e-01,  5.4049e-01,\n                       1.7061e-01, -5.6904e-01,  8.1368e-01,  4.2633e-01,  1.9510e-01,\n                       3.2089e-01, -4.7030e-02,  7.4617e-01,  6.3243e-02, -5.7487e-01,\n                       8.0976e-01,  1.1849e-01, -6.2483e-02, -2.1943e-01,  1.2972e-01,\n                       3.4769e-01, -5.3095e-01,  3.8545e-01, -2.5792e-01, -1.4042e-01,\n                      -1.0570e-01,  5.8450e-01,  3.7729e-01, -2.4488e-02,  1.3505e-01,\n                      -1.2183e-01,  2.8761e-01,  9.3975e-02,  2.1007e-01,  6.3286e-01,\n                      -3.8089e-01, -1.1797e-01,  1.0107e-01,  4.0529e-01,  3.0759e-01,\n                      -3.4575e-01, -2.7904e-01,  3.3144e-01, -4.7041e-01,  5.5349e-01,\n                       6.7930e-02, -6.5247e-01,  1.8468e-01,  2.3026e-01,  4.0175e-01,\n                       1.2029e-01, -2.3509e-02, -1.5128e-01,  3.0389e-01, -1.0787e+00,\n                       2.6493e-02, -9.9319e-02,  1.3627e-01,  3.4217e-01, -6.0922e-02,\n                       1.4853e-01, -2.6796e-01,  4.9524e-01,  9.0733e-03,  1.1409e+00,\n                      -7.1447e-01,  5.6601e-01,  8.3615e-02,  1.0717e-01,  2.1248e-01,\n                       3.2406e-01, -7.4458e-04,  3.4014e-01, -3.7291e-01, -1.6408e-01,\n                       1.9066e-01, -9.5002e-02,  3.4987e-01,  3.5461e-01, -2.6118e-01,\n                       6.2780e-01, -2.4201e-01,  2.3080e-02, -3.1261e-01, -5.9843e-01,\n                       1.7681e-01], dtype=torch.float64)),\n             ('6.13.convs.2.1.running_var',\n              tensor([0.1536, 0.2526, 0.1511, 0.2511, 0.2982, 0.3210, 0.2114, 0.5696, 0.0901,\n                      0.2710, 0.4634, 0.4321, 0.1473, 0.3153, 0.4919, 0.6123, 0.4843, 0.3401,\n                      0.4215, 0.1164, 0.2652, 0.3813, 0.2031, 0.1666, 0.4511, 0.2075, 0.5621,\n                      0.2148, 0.3406, 0.5812, 0.4709, 0.4462, 0.0663, 0.3420, 0.2454, 0.4558,\n                      0.2551, 0.2538, 0.1319, 0.3669, 0.2590, 0.5202, 0.1347, 0.5678, 0.1658,\n                      0.5348, 0.3214, 0.4045, 0.3782, 0.5084, 0.2031, 0.1789, 0.3317, 0.0860,\n                      0.4606, 0.4749, 0.2358, 0.2683, 0.3019, 0.3028, 0.3255, 0.3277, 0.4021,\n                      0.3263, 0.3896, 0.3078, 0.3474, 0.4168, 0.2530, 0.3054, 0.2655, 0.2228,\n                      0.1088, 0.2799, 0.3252, 0.1581, 0.3246, 0.2236, 0.7597, 0.1997, 0.2203,\n                      0.3031, 0.2264, 0.3281, 0.2517, 0.2378, 0.3133, 0.4601, 0.1710, 0.0975,\n                      0.3552, 0.3794, 0.3567, 0.2366, 0.5293, 0.3795, 0.3077, 0.3444, 0.0891,\n                      0.1874, 0.4629, 0.2626, 0.1731, 0.2658, 0.3726, 0.1938, 0.3924, 0.2572,\n                      0.3402, 0.1147, 0.1044, 0.4150, 0.7442, 0.6369, 0.3626, 0.3018, 0.1828,\n                      0.4511, 0.3111, 0.5339, 0.2339, 0.2904, 0.3212, 0.3015, 0.3399, 0.5196,\n                      0.3016, 0.4960, 0.1627, 0.3944, 0.1657, 0.3784, 0.3674, 0.3704, 0.3215,\n                      0.2961, 0.1313, 0.2123, 0.4623, 0.0674, 0.3962, 0.3077, 0.2827, 0.2510,\n                      0.2552, 0.3658, 0.1488, 0.8561, 0.0708, 0.1752, 0.5940, 0.2354, 0.4294,\n                      0.5432, 0.1488, 0.2960, 0.4411, 0.0382, 0.2632, 0.1905, 0.0710, 0.3291,\n                      0.7065, 0.1959, 0.5945, 0.3937, 0.5396, 0.5225, 0.2965, 0.6626, 0.2037,\n                      0.1978, 0.1210, 0.0971, 0.2508, 0.4386, 0.4017, 0.4591, 0.2582, 0.3537,\n                      0.3709, 0.0706, 0.3354, 0.2644, 0.2031, 0.2498, 0.2811, 0.1916, 0.3416,\n                      0.1263, 0.2080, 0.4597, 0.4795, 0.5773, 0.2210, 0.2660, 0.2898, 0.2305,\n                      0.3363, 0.4138, 0.0894, 0.5179, 0.2106, 0.3454, 0.3467, 0.5171, 0.0867,\n                      0.1828, 0.2965, 0.4883, 0.2400, 0.3124, 0.2895, 0.3011, 0.2705, 0.2590,\n                      0.4832, 0.0652, 0.3223, 0.3409, 0.3071, 0.2273, 0.2194, 0.4172, 0.6200,\n                      0.2172, 0.1388, 0.3155, 0.4567, 0.3574, 0.3897, 0.2648, 0.2852, 0.2987,\n                      0.4094, 0.6144, 0.3524, 0.2888, 0.3500, 0.2851, 0.3374, 0.0615, 0.3102,\n                      0.2253, 0.1165, 0.1647, 0.1981, 0.4118, 0.0795, 0.4155, 0.2973, 0.3202,\n                      0.1046, 0.2627, 0.2383, 0.3887], dtype=torch.float64)),\n             ('6.13.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.13.convpath.0.0.0.weight',\n              tensor([[[-0.0171],\n                       [ 0.0466],\n                       [ 0.0559],\n                       ...,\n                       [-0.0358],\n                       [-0.0417],\n                       [-0.0885]],\n              \n                      [[-0.0490],\n                       [-0.0320],\n                       [-0.0085],\n                       ...,\n                       [-0.0381],\n                       [-0.0539],\n                       [ 0.0024]],\n              \n                      [[ 0.0459],\n                       [ 0.0733],\n                       [-0.0337],\n                       ...,\n                       [ 0.0959],\n                       [ 0.0054],\n                       [-0.0658]],\n              \n                      ...,\n              \n                      [[ 0.0207],\n                       [ 0.0258],\n                       [ 0.0256],\n                       ...,\n                       [-0.0267],\n                       [ 0.1061],\n                       [ 0.0363]],\n              \n                      [[ 0.0286],\n                       [-0.1582],\n                       [ 0.0615],\n                       ...,\n                       [ 0.1192],\n                       [ 0.0957],\n                       [ 0.1393]],\n              \n                      [[-0.0808],\n                       [-0.0834],\n                       [ 0.0938],\n                       ...,\n                       [ 0.1318],\n                       [-0.0147],\n                       [-0.0764]]], dtype=torch.float64)),\n             ('6.13.convpath.0.0.1.weight',\n              tensor([0.9778, 0.9821, 0.9600, 0.9657, 0.9603, 0.9639, 0.9758, 0.9548, 0.9760,\n                      0.9659, 0.9573, 0.9684, 0.9999, 0.9296, 0.9633, 0.9526, 0.9379, 0.9738,\n                      0.9416, 0.9574, 0.9881, 0.9777, 0.9599, 0.9635, 0.9565, 0.9750, 0.9682,\n                      0.9410, 0.9330, 0.9437, 0.9698, 0.9792, 0.9644, 0.9665, 0.9439, 1.0003,\n                      0.9691, 0.9729, 0.9612, 0.9771, 0.9661, 0.9811, 0.9842, 0.9632, 0.9750,\n                      0.9571, 0.9783, 0.9752, 0.9870, 0.9574, 0.9505, 0.9511, 0.9727, 0.9432,\n                      0.9730, 0.9982, 0.9549, 0.9979, 1.0022, 0.9893, 0.9596, 0.9346, 0.9622,\n                      0.9766], dtype=torch.float64)),\n             ('6.13.convpath.0.0.1.bias',\n              tensor([ 0.0017,  0.0037, -0.0169, -0.0129, -0.0200,  0.0030,  0.0041, -0.0009,\n                       0.0016,  0.0157,  0.0027, -0.0061,  0.0372,  0.0020,  0.0021,  0.0108,\n                      -0.0081,  0.0119, -0.0060,  0.0144,  0.0098, -0.0071,  0.0046,  0.0078,\n                      -0.0094,  0.0070, -0.0050,  0.0135, -0.0263,  0.0029,  0.0089,  0.0019,\n                      -0.0067, -0.0186,  0.0013,  0.0226,  0.0009,  0.0122, -0.0149,  0.0019,\n                       0.0058, -0.0046,  0.0151, -0.0163,  0.0019, -0.0048,  0.0099,  0.0123,\n                       0.0095, -0.0013, -0.0208, -0.0251, -0.0023, -0.0028,  0.0127,  0.0119,\n                       0.0157,  0.0219,  0.0140, -0.0046, -0.0129,  0.0052, -0.0041,  0.0150],\n                     dtype=torch.float64)),\n             ('6.13.convpath.0.0.1.running_mean',\n              tensor([-0.5705,  0.1955,  1.6724,  0.8388,  1.2055, -0.0280, -0.4704,  0.6609,\n                      -0.2674, -0.5305, -0.1330,  0.4741, -0.4546, -0.9844, -0.3226, -0.0108,\n                      -1.2653,  0.5629, -0.6295, -0.3457, -0.1934,  1.4640, -1.0251,  1.1369,\n                       0.5671,  0.1600,  0.2716, -0.5820, -0.3679, -0.2190, -0.5219, -0.7149,\n                       0.1950, -0.0680, -0.2078, -0.2351,  1.7980, -0.1021,  1.3794,  0.0544,\n                       0.3415,  0.3088,  0.4475,  0.6645,  0.0172, -0.6267, -0.1309,  0.3605,\n                       0.1949,  0.5779,  0.6670,  0.8631,  0.5621,  1.3369, -0.2124, -0.8789,\n                      -1.3022,  0.4782, -0.7564, -0.8544,  1.3024, -1.1875,  0.4247, -0.0363],\n                     dtype=torch.float64)),\n             ('6.13.convpath.0.0.1.running_var',\n              tensor([0.0818, 0.1604, 1.6647, 0.5731, 0.6027, 0.1323, 0.2977, 0.4069, 0.1752,\n                      0.2945, 0.3839, 0.1466, 0.1137, 1.0702, 0.2503, 0.5533, 0.1713, 0.3160,\n                      0.5696, 0.2020, 0.2139, 0.3312, 0.1362, 1.3043, 0.2385, 0.3023, 0.1823,\n                      0.7287, 0.3828, 0.0757, 0.1310, 0.2247, 0.3231, 0.0993, 0.4513, 0.0856,\n                      0.3543, 0.1920, 0.5381, 0.1433, 0.2449, 0.1507, 0.1008, 0.1254, 0.7459,\n                      0.4307, 0.1503, 0.1286, 0.1770, 0.4843, 0.7279, 0.5958, 0.6142, 0.0990,\n                      0.1254, 0.1339, 0.7094, 0.1357, 0.2193, 0.1044, 1.1201, 0.8450, 0.4090,\n                      0.1854], dtype=torch.float64)),\n             ('6.13.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.13.convpath.0.1.0.weight',\n              tensor([[[-1.4548e-01, -6.0081e-02, -2.7059e-02, -5.8420e-02,  2.5364e-02],\n                       [ 2.4933e-02, -4.2873e-02, -2.8073e-02, -6.9013e-02, -2.7364e-02],\n                       [-2.0948e-02,  6.9798e-03,  5.8242e-02, -1.1626e-01,  1.7592e-02],\n                       ...,\n                       [ 5.0084e-02, -5.4315e-02, -3.6414e-02, -1.2853e-02, -3.6543e-02],\n                       [ 5.2874e-02,  4.9857e-02,  6.9492e-02, -9.5053e-02, -2.7161e-02],\n                       [-1.1644e-01,  7.5752e-02,  3.1112e-02, -2.8855e-02, -3.9235e-02]],\n              \n                      [[-1.5654e-01,  7.3430e-03, -2.7421e-02,  7.1822e-02, -4.6880e-02],\n                       [-8.4769e-02, -2.9939e-02,  7.7032e-03,  3.3473e-02,  1.1162e-01],\n                       [-3.8761e-02, -9.5768e-02,  1.2726e-02, -6.8003e-02,  6.0147e-02],\n                       ...,\n                       [-8.0171e-02, -1.6173e-01, -6.2211e-02, -1.6270e-01,  7.1253e-02],\n                       [-2.1825e-02,  4.6477e-02, -2.1266e-02, -5.8885e-02, -9.6070e-03],\n                       [-8.2920e-03,  4.0409e-02,  4.4635e-02,  4.7182e-02, -1.3776e-01]],\n              \n                      [[-5.0762e-02,  3.9749e-02,  5.7687e-02, -7.9778e-02, -3.2109e-02],\n                       [-8.0852e-02, -7.0447e-02,  5.1158e-02, -4.8903e-03,  6.0413e-02],\n                       [ 1.6301e-02, -1.1975e-01, -2.5601e-02, -3.5559e-02,  3.0498e-04],\n                       ...,\n                       [ 1.2384e-01,  2.9540e-02, -4.9960e-02, -8.3949e-02, -9.0407e-02],\n                       [-8.0676e-02, -1.7478e-01,  4.2582e-02, -1.2974e-01, -5.7886e-02],\n                       [-1.0883e-01,  6.2665e-04,  7.7072e-02,  1.6236e-02,  6.3000e-02]],\n              \n                      ...,\n              \n                      [[ 6.4901e-02, -7.1595e-03,  9.8509e-02, -3.6420e-03, -5.6746e-02],\n                       [ 1.3131e-01, -4.7154e-02, -9.7348e-02,  4.0171e-02, -1.2041e-01],\n                       [ 5.6126e-02, -3.8203e-02,  1.3718e-01,  3.8906e-02,  7.1897e-02],\n                       ...,\n                       [ 1.7149e-02,  7.3543e-03,  3.8296e-02, -7.9906e-02,  1.7509e-02],\n                       [ 1.1866e-01, -1.4766e-01, -1.2177e-03, -1.7202e-01, -1.1195e-01],\n                       [-8.4962e-02, -1.2995e-02,  9.3062e-03, -1.6297e-01, -3.8770e-02]],\n              \n                      [[-7.1619e-02, -2.0431e-02,  8.3252e-02, -6.2487e-02,  1.8180e-01],\n                       [-7.8980e-02, -7.6899e-03,  4.5549e-02, -2.9508e-02,  8.4784e-02],\n                       [-1.5468e-01, -1.3886e-01,  1.3574e-02,  5.2715e-02,  2.7708e-05],\n                       ...,\n                       [-1.3815e-01, -4.8067e-03, -1.5901e-02, -8.3183e-02,  6.4381e-04],\n                       [ 3.1024e-02, -8.5193e-02, -1.8651e-01,  2.4245e-02, -2.1807e-01],\n                       [-3.1928e-03, -1.5661e-01,  6.4474e-02,  1.0194e-01, -6.7360e-02]],\n              \n                      [[-1.6357e-01, -4.4661e-02, -6.1795e-02, -2.6217e-03,  3.1399e-02],\n                       [-9.2542e-02,  9.8082e-02, -6.0010e-02, -8.8338e-04,  9.7368e-02],\n                       [ 8.3721e-02, -4.6371e-02, -2.2987e-02,  1.2923e-01,  4.2175e-02],\n                       ...,\n                       [-9.6165e-02, -7.7653e-03,  4.7100e-02,  5.1517e-02,  8.0729e-02],\n                       [-6.2907e-02, -7.5381e-02, -3.0818e-02, -1.3653e-01, -1.0445e-01],\n                       [ 4.0789e-02, -3.4180e-02,  1.0727e-01,  8.4954e-03, -5.6275e-02]]],\n                     dtype=torch.float64)),\n             ('6.13.convpath.0.1.1.weight',\n              tensor([1.0010, 0.9663, 0.9698, 0.9487, 0.9567, 0.9623, 0.9531, 0.9555, 1.0001,\n                      0.9614, 0.9682, 0.9626, 0.9687, 0.9748, 0.9658, 0.9486, 0.9752, 0.9647,\n                      0.9664, 0.9792, 0.9473, 0.9789, 0.9607, 0.9629, 0.9802, 0.9722, 0.9204,\n                      0.9789, 0.9597, 0.9574, 0.9555, 0.9855, 0.9867, 0.9601, 0.9418, 0.9706,\n                      0.9722, 0.9618, 0.9627, 0.9632, 0.9581, 0.9444, 0.9952, 0.9689, 0.9705,\n                      0.9611, 0.9497, 0.9741, 0.9600, 0.9498, 0.9465, 0.9610, 0.9757, 0.9530,\n                      0.9395, 0.9721, 0.9714, 0.9642, 0.9593, 0.9576, 0.9628, 0.9479, 0.9767,\n                      0.9489], dtype=torch.float64)),\n             ('6.13.convpath.0.1.1.bias',\n              tensor([ 2.2191e-02, -1.9797e-02, -5.4914e-04,  6.8388e-03, -1.9183e-02,\n                       6.5534e-03,  3.3478e-04,  1.4414e-03,  3.4087e-02, -7.5099e-03,\n                       1.4579e-02, -1.7031e-02, -3.5580e-03,  1.1472e-02,  1.6541e-02,\n                      -1.4898e-03,  4.9320e-04,  4.0031e-07, -4.0037e-03, -2.7737e-03,\n                      -5.5625e-04,  1.0401e-03, -9.9758e-03, -4.4800e-03,  1.1606e-03,\n                      -1.2184e-02, -1.1498e-02, -4.0597e-03, -1.0666e-02,  3.0479e-03,\n                       1.6056e-02,  1.1323e-02,  1.9979e-02,  9.4837e-03, -1.3558e-02,\n                       1.0922e-02, -4.2005e-03,  8.2197e-03, -4.7835e-03, -1.7147e-02,\n                      -1.3034e-02,  1.3582e-02,  9.4440e-03,  4.0566e-03, -1.8755e-03,\n                      -4.8153e-03,  2.9140e-03,  1.2538e-02, -1.2239e-02,  4.8748e-04,\n                      -8.2226e-03,  7.3608e-04, -6.7241e-03, -2.4716e-02, -1.5144e-02,\n                      -2.8047e-03, -8.1725e-03,  2.3615e-02, -1.1297e-02, -7.4358e-03,\n                      -7.1439e-03, -3.8513e-03,  1.4019e-04, -1.6053e-03],\n                     dtype=torch.float64)),\n             ('6.13.convpath.0.1.1.running_mean',\n              tensor([-4.3767e-01, -3.5169e-01, -4.8482e-01, -7.9885e-01,  2.0882e-01,\n                      -4.9010e-01,  5.3561e-01, -3.3310e-02, -7.4366e-01,  2.5952e-01,\n                      -2.7686e-01,  2.8710e-01,  3.3390e-01, -6.2427e-01,  9.5532e-02,\n                       5.8640e-02,  7.5632e-03, -7.6850e-01, -5.2135e-01, -1.9176e-04,\n                      -9.2832e-01, -7.3453e-02,  8.8578e-01,  5.2217e-01, -5.3165e-01,\n                       2.7525e-01, -7.3558e-01,  3.2225e-01,  3.1069e-01, -3.3549e-01,\n                       2.9882e-02,  2.6587e-01, -7.0607e-01, -1.2120e-01, -1.0605e-01,\n                      -1.8391e-01, -2.1154e-01, -8.2011e-01, -3.0112e-02,  3.0164e-01,\n                       1.3161e-01, -9.5813e-01, -3.3909e-02, -6.9102e-01,  4.5450e-01,\n                      -3.1132e-01,  2.5933e-01, -2.2675e-01, -1.7857e-02,  6.1876e-02,\n                      -7.1365e-01, -5.5025e-01, -4.6579e-01,  1.0815e-01, -4.2908e-01,\n                       2.9207e-01,  3.3943e-01, -8.4226e-01,  3.5619e-02,  1.6953e-02,\n                       2.0708e-01, -8.7690e-01,  9.4395e-02,  1.0529e-01],\n                     dtype=torch.float64)),\n             ('6.13.convpath.0.1.1.running_var',\n              tensor([0.5844, 0.9954, 0.5082, 0.9178, 0.6175, 0.6581, 0.4834, 1.1521, 0.5605,\n                      0.5491, 0.5730, 0.5612, 0.7454, 0.7830, 0.6046, 0.5962, 0.6327, 0.6858,\n                      0.6639, 0.3449, 0.6112, 0.4824, 0.7322, 0.6266, 0.7572, 0.3791, 0.6467,\n                      0.4990, 0.8153, 1.2824, 0.5141, 0.5516, 0.6154, 0.5150, 0.6305, 0.7988,\n                      0.5225, 0.7691, 0.4227, 0.5030, 0.3966, 0.9883, 0.5631, 0.9327, 0.6956,\n                      0.5729, 0.5655, 0.7164, 0.8374, 0.5203, 0.8330, 0.5797, 0.4854, 0.9130,\n                      0.6093, 0.5595, 0.7818, 0.7221, 0.5959, 0.9039, 0.5992, 0.6503, 0.4518,\n                      1.0118], dtype=torch.float64)),\n             ('6.13.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.13.convpath.0.2.0.weight',\n              tensor([[[ 0.0519],\n                       [-0.0516],\n                       [-0.1350],\n                       ...,\n                       [-0.0462],\n                       [-0.1625],\n                       [ 0.0618]],\n              \n                      [[ 0.0452],\n                       [ 0.1068],\n                       [-0.2067],\n                       ...,\n                       [ 0.0367],\n                       [-0.0881],\n                       [-0.0796]],\n              \n                      [[-0.0415],\n                       [-0.1307],\n                       [ 0.0260],\n                       ...,\n                       [-0.0423],\n                       [ 0.0027],\n                       [ 0.0026]],\n              \n                      ...,\n              \n                      [[ 0.0579],\n                       [ 0.0510],\n                       [-0.0494],\n                       ...,\n                       [ 0.0419],\n                       [-0.0481],\n                       [ 0.1872]],\n              \n                      [[ 0.1596],\n                       [ 0.0068],\n                       [ 0.0626],\n                       ...,\n                       [-0.0255],\n                       [-0.0219],\n                       [ 0.0025]],\n              \n                      [[ 0.0219],\n                       [ 0.2924],\n                       [-0.2022],\n                       ...,\n                       [-0.0019],\n                       [-0.2145],\n                       [-0.0057]]], dtype=torch.float64)),\n             ('6.13.convpath.0.2.1.weight',\n              tensor([ 9.0264e-04, -1.8442e-03,  7.8081e-03, -2.7761e-03, -2.3762e-03,\n                      -8.1073e-03, -9.2309e-03,  2.8186e-02,  3.0679e-05,  9.4049e-03,\n                      -3.0244e-02, -2.4950e-02, -1.3176e-02, -1.0886e-02,  1.5435e-02,\n                       2.3951e-02, -1.7138e-02, -1.2674e-03, -1.2846e-02, -4.8328e-04,\n                      -2.0524e-02,  1.9178e-02, -1.6388e-03,  1.7316e-03, -3.2421e-02,\n                       8.7399e-03, -3.2143e-02, -3.4827e-03, -2.7582e-02,  1.6249e-02,\n                      -2.0744e-02, -2.0761e-02, -2.8662e-03, -8.5422e-03, -5.9387e-03,\n                       1.6644e-02, -9.6083e-03,  1.5628e-02,  3.1499e-05, -3.2163e-03,\n                      -5.6035e-03,  1.2028e-02,  1.2773e-02, -1.2157e-02, -1.5288e-03,\n                      -3.0308e-03, -3.1764e-02, -1.2567e-02,  5.2686e-03,  5.2975e-03,\n                      -1.6833e-02,  3.8504e-03,  3.8320e-03,  1.9051e-03,  1.4378e-02,\n                       5.9967e-02,  2.4584e-02, -2.5146e-03, -1.7227e-03,  5.1612e-03,\n                      -8.1995e-03, -4.4886e-03, -3.2472e-02,  1.5959e-02, -3.2776e-02,\n                      -1.1816e-02, -6.9172e-03,  1.5806e-02,  2.2582e-02,  1.6673e-02,\n                       4.1314e-03,  4.6527e-03, -4.7516e-03,  9.5212e-03,  2.8346e-02,\n                       5.4278e-03,  4.9834e-03, -1.4716e-02,  2.2329e-02, -9.3704e-03,\n                       7.0517e-03,  1.0359e-02, -1.0477e-02, -3.1556e-03,  9.0022e-03,\n                       6.4094e-03, -7.8552e-03,  2.1836e-02,  4.8672e-05,  7.7626e-03,\n                      -2.5395e-03,  7.4278e-03,  1.3625e-02, -1.7499e-02,  2.1558e-02,\n                      -1.3903e-02, -7.9741e-03, -1.7599e-02, -7.7283e-04,  1.6247e-02,\n                       1.6919e-02, -1.2140e-02,  1.5336e-03, -1.3440e-02, -7.5494e-03,\n                      -2.3736e-02,  1.9984e-02,  8.0849e-03, -2.5506e-02,  2.3528e-03,\n                       2.7488e-03, -6.5428e-03,  2.6358e-02, -2.2948e-02,  1.0978e-02,\n                       1.5734e-02, -2.4465e-02,  1.1182e-02, -3.5343e-02, -1.3823e-02,\n                       1.2170e-02,  1.1022e-02, -3.0964e-03,  2.3041e-03,  2.1905e-02,\n                      -3.2901e-02,  1.0712e-02, -1.5463e-02,  1.3127e-02, -2.6933e-03,\n                      -2.0616e-03, -1.6855e-02,  1.6730e-02,  1.6052e-02, -8.3106e-03,\n                       1.1990e-02,  2.8264e-03,  5.3277e-03, -1.7021e-02, -8.6031e-03,\n                       2.9925e-02,  2.5197e-02,  1.8990e-02,  1.5761e-02,  1.0350e-02,\n                       1.3884e-02, -1.0856e-02,  1.0129e-02, -1.4048e-02, -9.6497e-03,\n                      -1.1583e-02, -3.8121e-03, -1.8518e-02,  2.0526e-02,  5.1410e-04,\n                       1.4138e-02, -2.2857e-02,  2.1986e-03,  1.1884e-02,  1.4280e-02,\n                      -2.9263e-03,  7.9252e-03,  2.9437e-02, -1.5536e-03, -2.7173e-02,\n                       1.6297e-02, -3.9052e-02, -1.6970e-02,  9.1741e-03, -3.7511e-02,\n                       1.2486e-04,  5.7046e-03, -6.8798e-04, -6.2910e-03, -5.5737e-03,\n                      -5.6677e-03,  1.9926e-02,  3.1230e-02,  2.1947e-03,  2.4191e-02,\n                       9.4773e-03, -4.3795e-03, -8.4010e-03, -1.6261e-02,  1.1966e-02,\n                       7.0355e-03,  1.3800e-03, -5.4656e-03,  1.7027e-02, -4.1955e-04,\n                      -2.9646e-03,  2.9417e-02, -8.1331e-03,  1.9180e-02, -3.2995e-02,\n                      -3.5414e-03,  1.7536e-02,  4.7590e-03,  6.3905e-04,  2.0163e-02,\n                      -3.0102e-04, -2.3761e-02,  1.1434e-03, -3.2357e-02, -1.8739e-02,\n                      -1.3880e-02,  2.3332e-03,  9.9259e-03,  1.8760e-02, -1.9919e-02,\n                       2.1322e-02, -6.3412e-04, -4.3835e-02, -1.5551e-02,  1.5436e-02,\n                       9.7790e-03, -1.4621e-03, -6.9060e-04, -2.4824e-02, -9.8609e-03,\n                      -1.8598e-02,  1.6646e-02,  1.0271e-02,  9.2319e-03,  9.4591e-03,\n                      -2.9256e-03,  1.5250e-02, -9.6402e-03,  1.7530e-02,  2.1543e-02,\n                       4.0701e-03, -5.1803e-03, -1.5343e-04, -2.2187e-02,  3.4696e-03,\n                       1.0980e-02,  6.4323e-03, -7.4039e-03,  7.9961e-03,  1.4056e-02,\n                       1.5447e-03,  4.7254e-03,  1.4236e-03,  9.7185e-04, -9.4150e-04,\n                       4.7475e-04, -7.1570e-03,  2.3596e-02, -4.5919e-03, -4.2937e-02,\n                       3.7873e-02, -3.0164e-02,  2.3760e-03, -7.3786e-03,  5.2193e-04,\n                       3.3035e-02], dtype=torch.float64)),\n             ('6.13.convpath.0.2.1.bias',\n              tensor([ 8.1188e-06,  9.3859e-03,  9.2961e-03,  1.4093e-02,  3.5178e-03,\n                       9.6883e-03,  7.1956e-03, -7.1808e-04,  1.4511e-02,  1.5965e-02,\n                       1.5775e-02, -6.2965e-03,  5.5444e-03, -5.1574e-03,  8.0633e-03,\n                       2.3873e-03,  2.4227e-02, -1.1772e-03,  9.9406e-03, -3.3031e-03,\n                      -4.7985e-03,  5.2502e-04,  5.1964e-03,  6.5902e-03,  5.0445e-03,\n                      -1.7085e-02,  3.8389e-03,  7.7876e-03,  1.4593e-02, -7.1374e-03,\n                       9.1926e-04,  7.3146e-03, -3.2220e-03,  2.0801e-02,  3.6378e-03,\n                       1.5466e-02, -2.5558e-03,  1.7172e-02,  1.1054e-02,  1.1730e-02,\n                       2.0702e-03,  1.7164e-02, -1.2344e-02, -1.8373e-03,  6.9630e-03,\n                      -1.2725e-02,  1.4439e-02,  6.2896e-03, -1.2343e-02,  1.8317e-03,\n                       8.3281e-03,  4.1248e-03,  7.4451e-03,  1.7264e-02,  3.7784e-03,\n                       1.9088e-02,  8.8985e-03,  1.3304e-03,  1.2174e-02, -2.9547e-03,\n                      -7.5268e-04,  5.1524e-04,  9.4787e-03,  8.5604e-03, -5.8265e-03,\n                       2.8080e-03, -1.0708e-02,  1.4742e-02, -2.0457e-03, -1.4956e-02,\n                       7.2167e-03,  3.1540e-03, -7.0523e-04, -8.0911e-03,  1.3436e-02,\n                       6.0556e-03,  2.2118e-04, -1.1355e-03,  2.8094e-03,  1.4773e-02,\n                       5.2919e-03, -8.2789e-03,  1.0413e-02,  4.1866e-03, -3.4977e-03,\n                       1.6590e-02, -2.9025e-04,  1.3983e-02,  1.4462e-02,  3.9924e-04,\n                       2.7518e-04,  1.0580e-02,  1.0004e-02,  2.8441e-03,  1.1647e-02,\n                      -8.7508e-03,  1.2464e-02, -1.5488e-03,  2.0702e-02,  6.4013e-03,\n                       1.8810e-02,  1.5998e-02,  3.6197e-03,  1.1261e-02, -5.3379e-04,\n                       5.4579e-04, -6.2880e-03,  1.1352e-02,  8.2945e-03,  2.7038e-03,\n                      -1.3244e-02, -9.2793e-03,  4.5037e-03,  1.9861e-02,  1.4106e-02,\n                       5.9143e-03,  9.8287e-03,  2.6533e-03,  6.5537e-03, -1.3839e-02,\n                      -1.7607e-04,  9.6864e-03,  1.1683e-03, -4.9378e-04,  1.1176e-02,\n                       9.9491e-03,  6.9958e-03,  5.2945e-03,  4.9082e-03,  1.2865e-02,\n                       6.7311e-03,  5.8107e-03,  1.3728e-02,  5.4030e-03,  8.8502e-03,\n                      -1.2701e-02,  1.4475e-02,  3.7615e-03,  6.0663e-03, -2.8962e-03,\n                       1.3033e-02, -1.2167e-02,  1.6747e-02,  2.1833e-03, -4.9723e-03,\n                       1.6532e-02,  5.4126e-03, -8.0455e-04,  1.2399e-02,  8.4627e-03,\n                       1.1890e-02,  1.4772e-02,  6.2747e-03,  1.2290e-02,  1.0989e-02,\n                       4.7254e-03, -1.6241e-03,  6.4660e-03,  8.0668e-04, -1.2979e-02,\n                       2.4385e-03,  4.7222e-04, -2.2378e-03,  7.5218e-03,  1.2945e-02,\n                      -3.2596e-03, -1.3042e-02,  9.7880e-03,  7.3170e-03,  2.1177e-02,\n                       1.6999e-03,  1.4970e-03,  5.4934e-03,  1.4688e-02, -1.3014e-02,\n                       1.0316e-02,  1.0022e-03,  1.5179e-02,  1.3242e-03,  5.8099e-03,\n                      -5.9191e-03,  1.1417e-02, -7.0672e-03, -8.8494e-03,  1.2337e-02,\n                       8.0209e-03,  1.4096e-02,  9.3819e-03,  6.4982e-03,  8.1123e-03,\n                       5.9088e-03,  4.9292e-03,  6.0037e-03,  1.1428e-03,  1.6777e-03,\n                       9.8802e-03,  1.1496e-02,  2.6247e-03,  5.1550e-03,  1.4937e-02,\n                      -7.0068e-04,  2.2734e-02,  1.8110e-02,  2.0024e-02,  1.8069e-02,\n                      -1.7547e-03,  9.1308e-03, -1.1559e-02,  6.6428e-03,  1.2718e-02,\n                       9.3185e-03,  1.0902e-02,  1.1870e-02,  6.6168e-03,  8.5487e-03,\n                       1.9172e-03,  4.8528e-03,  1.6108e-02,  4.3948e-03,  4.4651e-03,\n                       8.3401e-03, -3.7677e-04,  2.5471e-03,  1.5156e-02,  7.8935e-04,\n                       7.2086e-03, -6.9722e-03, -1.5534e-03,  2.0729e-02,  1.6517e-02,\n                       3.2275e-03, -4.2153e-03,  4.9803e-03,  1.2740e-02, -3.3138e-04,\n                       7.5377e-03,  2.5846e-03,  6.6910e-03,  7.0040e-03,  7.5547e-03,\n                      -3.4200e-03, -2.2858e-04, -2.1586e-03,  1.2933e-02,  1.1062e-03,\n                       9.3007e-03,  3.5708e-03,  3.5857e-03, -1.2534e-02, -1.0333e-02,\n                       2.0282e-02,  2.4897e-02,  1.8509e-02,  1.7617e-02,  2.8039e-03,\n                       4.0916e-03], dtype=torch.float64)),\n             ('6.13.convpath.0.2.1.running_mean',\n              tensor([-7.5019e-02,  3.4987e-01,  5.9603e-02,  8.1202e-02, -1.1371e-01,\n                      -7.7833e-01,  9.6499e-03, -2.9537e-01,  1.8077e-01, -3.9717e-01,\n                      -3.3094e-01, -7.1698e-01,  2.3992e-01,  5.0273e-01, -5.2787e-01,\n                      -6.5982e-01,  9.3607e-01, -8.7359e-02,  9.0010e-01,  9.3877e-02,\n                      -1.6932e-01,  9.0360e-02, -9.9249e-02, -6.9108e-03,  8.3004e-01,\n                       6.0121e-02, -1.3261e+00, -1.8313e-02, -4.5757e-02,  6.3813e-01,\n                       4.9511e-01,  8.0187e-03,  8.1358e-02,  4.8489e-01, -1.3992e-01,\n                      -1.6722e-01,  7.6294e-02, -7.6344e-01, -7.3700e-02, -1.1355e-01,\n                      -1.2237e-01, -1.0308e-01,  5.9181e-02, -2.6961e-01,  2.2003e-01,\n                       2.6055e-01, -3.6410e-01, -2.1450e-01,  2.2604e-01, -8.8875e-01,\n                       5.7539e-02, -5.1677e-01, -2.5665e-01, -1.2461e-01,  4.6009e-01,\n                       3.9679e-01,  6.3269e-03,  5.4402e-01, -2.0966e-01,  1.3705e-01,\n                       3.2988e-01,  1.1380e-01,  1.1383e-01, -1.4972e-01,  8.5433e-01,\n                      -1.4535e-01,  7.6311e-01,  4.3342e-01, -1.4459e-01, -3.4254e-01,\n                       3.7322e-01,  1.1451e-01,  1.8938e-02, -3.2956e-01,  5.5660e-01,\n                       3.1419e-01,  5.7530e-01,  2.8784e-01,  2.6796e-01, -2.4315e-01,\n                       1.6871e-01,  5.2095e-01, -6.4603e-02,  1.7638e-01, -2.3244e-02,\n                      -1.4593e-01, -2.1309e-01,  4.0366e-02,  2.4277e-01,  2.6452e-02,\n                       5.0399e-01,  3.4196e-01, -2.4411e-01, -2.0873e-01, -5.7462e-01,\n                      -4.7988e-01,  6.9530e-02, -1.7714e-02,  7.2791e-02, -3.0984e-01,\n                      -1.7332e-01,  3.1703e-01,  1.1177e-01,  1.2807e-01, -6.9931e-02,\n                       5.6725e-02, -3.4908e-01,  6.5505e-02,  4.4137e-02,  2.5664e-02,\n                      -2.5894e-01, -8.1149e-01, -6.4786e-02,  5.8094e-01,  7.8395e-01,\n                      -1.9563e-01,  6.9253e-01, -2.9486e-01,  5.1291e-01, -1.7648e-01,\n                       3.8404e-01, -1.0654e-01,  7.5491e-01,  6.1168e-01, -8.2250e-02,\n                       7.5600e-01,  3.6907e-02, -7.2429e-01,  5.5753e-02,  3.1528e-01,\n                       2.7916e-02,  5.2273e-01,  1.6702e-01, -1.6596e-01, -5.4292e-01,\n                       3.7348e-02, -2.7012e-01, -2.1488e-01, -2.6215e-01,  1.0019e-01,\n                      -8.9256e-02,  5.9688e-01,  2.9512e-02,  5.7577e-01,  1.9496e-01,\n                      -5.4371e-01,  1.7891e-01,  6.8517e-01, -3.1385e-03, -1.7543e-01,\n                       1.1274e+00, -5.4757e-01, -9.9244e-02, -9.0421e-01, -1.2888e-01,\n                      -4.9647e-02, -3.8015e-01, -4.3676e-02, -1.0141e+00,  5.3824e-01,\n                       1.0095e-01, -1.7301e-01, -4.7507e-01,  8.7340e-02, -1.1037e-01,\n                      -8.2543e-02,  5.7178e-01,  7.4243e-01,  6.5475e-02, -5.4299e-01,\n                      -3.8479e-01, -8.5238e-02, -3.1859e-01,  1.0898e-01,  5.4049e-01,\n                       1.7061e-01, -5.6904e-01,  8.1368e-01,  4.2633e-01,  1.9510e-01,\n                       3.2089e-01, -4.7030e-02,  7.4617e-01,  6.3243e-02, -5.7487e-01,\n                       8.0976e-01,  1.1849e-01, -6.2483e-02, -2.1943e-01,  1.2972e-01,\n                       3.4769e-01, -5.3095e-01,  3.8545e-01, -2.5792e-01, -1.4042e-01,\n                      -1.0570e-01,  5.8450e-01,  3.7729e-01, -2.4488e-02,  1.3505e-01,\n                      -1.2183e-01,  2.8761e-01,  9.3975e-02,  2.1007e-01,  6.3286e-01,\n                      -3.8089e-01, -1.1797e-01,  1.0107e-01,  4.0529e-01,  3.0759e-01,\n                      -3.4575e-01, -2.7904e-01,  3.3144e-01, -4.7041e-01,  5.5349e-01,\n                       6.7930e-02, -6.5247e-01,  1.8468e-01,  2.3026e-01,  4.0175e-01,\n                       1.2029e-01, -2.3509e-02, -1.5128e-01,  3.0389e-01, -1.0787e+00,\n                       2.6493e-02, -9.9319e-02,  1.3627e-01,  3.4217e-01, -6.0922e-02,\n                       1.4853e-01, -2.6796e-01,  4.9524e-01,  9.0733e-03,  1.1409e+00,\n                      -7.1447e-01,  5.6601e-01,  8.3615e-02,  1.0717e-01,  2.1248e-01,\n                       3.2406e-01, -7.4458e-04,  3.4014e-01, -3.7291e-01, -1.6408e-01,\n                       1.9066e-01, -9.5002e-02,  3.4987e-01,  3.5461e-01, -2.6118e-01,\n                       6.2780e-01, -2.4201e-01,  2.3080e-02, -3.1261e-01, -5.9843e-01,\n                       1.7681e-01], dtype=torch.float64)),\n             ('6.13.convpath.0.2.1.running_var',\n              tensor([0.1536, 0.2526, 0.1511, 0.2511, 0.2982, 0.3210, 0.2114, 0.5696, 0.0901,\n                      0.2710, 0.4634, 0.4321, 0.1473, 0.3153, 0.4919, 0.6123, 0.4843, 0.3401,\n                      0.4215, 0.1164, 0.2652, 0.3813, 0.2031, 0.1666, 0.4511, 0.2075, 0.5621,\n                      0.2148, 0.3406, 0.5812, 0.4709, 0.4462, 0.0663, 0.3420, 0.2454, 0.4558,\n                      0.2551, 0.2538, 0.1319, 0.3669, 0.2590, 0.5202, 0.1347, 0.5678, 0.1658,\n                      0.5348, 0.3214, 0.4045, 0.3782, 0.5084, 0.2031, 0.1789, 0.3317, 0.0860,\n                      0.4606, 0.4749, 0.2358, 0.2683, 0.3019, 0.3028, 0.3255, 0.3277, 0.4021,\n                      0.3263, 0.3896, 0.3078, 0.3474, 0.4168, 0.2530, 0.3054, 0.2655, 0.2228,\n                      0.1088, 0.2799, 0.3252, 0.1581, 0.3246, 0.2236, 0.7597, 0.1997, 0.2203,\n                      0.3031, 0.2264, 0.3281, 0.2517, 0.2378, 0.3133, 0.4601, 0.1710, 0.0975,\n                      0.3552, 0.3794, 0.3567, 0.2366, 0.5293, 0.3795, 0.3077, 0.3444, 0.0891,\n                      0.1874, 0.4629, 0.2626, 0.1731, 0.2658, 0.3726, 0.1938, 0.3924, 0.2572,\n                      0.3402, 0.1147, 0.1044, 0.4150, 0.7442, 0.6369, 0.3626, 0.3018, 0.1828,\n                      0.4511, 0.3111, 0.5339, 0.2339, 0.2904, 0.3212, 0.3015, 0.3399, 0.5196,\n                      0.3016, 0.4960, 0.1627, 0.3944, 0.1657, 0.3784, 0.3674, 0.3704, 0.3215,\n                      0.2961, 0.1313, 0.2123, 0.4623, 0.0674, 0.3962, 0.3077, 0.2827, 0.2510,\n                      0.2552, 0.3658, 0.1488, 0.8561, 0.0708, 0.1752, 0.5940, 0.2354, 0.4294,\n                      0.5432, 0.1488, 0.2960, 0.4411, 0.0382, 0.2632, 0.1905, 0.0710, 0.3291,\n                      0.7065, 0.1959, 0.5945, 0.3937, 0.5396, 0.5225, 0.2965, 0.6626, 0.2037,\n                      0.1978, 0.1210, 0.0971, 0.2508, 0.4386, 0.4017, 0.4591, 0.2582, 0.3537,\n                      0.3709, 0.0706, 0.3354, 0.2644, 0.2031, 0.2498, 0.2811, 0.1916, 0.3416,\n                      0.1263, 0.2080, 0.4597, 0.4795, 0.5773, 0.2210, 0.2660, 0.2898, 0.2305,\n                      0.3363, 0.4138, 0.0894, 0.5179, 0.2106, 0.3454, 0.3467, 0.5171, 0.0867,\n                      0.1828, 0.2965, 0.4883, 0.2400, 0.3124, 0.2895, 0.3011, 0.2705, 0.2590,\n                      0.4832, 0.0652, 0.3223, 0.3409, 0.3071, 0.2273, 0.2194, 0.4172, 0.6200,\n                      0.2172, 0.1388, 0.3155, 0.4567, 0.3574, 0.3897, 0.2648, 0.2852, 0.2987,\n                      0.4094, 0.6144, 0.3524, 0.2888, 0.3500, 0.2851, 0.3374, 0.0615, 0.3102,\n                      0.2253, 0.1165, 0.1647, 0.1981, 0.4118, 0.0795, 0.4155, 0.2973, 0.3202,\n                      0.1046, 0.2627, 0.2383, 0.3887], dtype=torch.float64)),\n             ('6.13.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.14.convs.0.0.weight',\n              tensor([[[ 7.6561e-02],\n                       [-1.5895e-02],\n                       [ 4.6714e-03],\n                       ...,\n                       [ 7.2812e-02],\n                       [-4.8927e-02],\n                       [ 3.2493e-02]],\n              \n                      [[ 4.4624e-02],\n                       [ 5.0613e-02],\n                       [ 4.2176e-02],\n                       ...,\n                       [-1.4014e-01],\n                       [-6.9230e-03],\n                       [-5.6085e-02]],\n              \n                      [[ 1.2783e-01],\n                       [ 8.1154e-03],\n                       [ 3.1433e-02],\n                       ...,\n                       [-1.7322e-01],\n                       [ 1.1900e-01],\n                       [-6.8969e-02]],\n              \n                      ...,\n              \n                      [[-1.6158e-02],\n                       [-1.1034e-02],\n                       [-3.3664e-02],\n                       ...,\n                       [-1.9662e-02],\n                       [ 4.7206e-02],\n                       [ 3.1625e-03]],\n              \n                      [[-5.6436e-02],\n                       [-8.1698e-02],\n                       [ 7.1369e-02],\n                       ...,\n                       [-1.7726e-01],\n                       [-9.1429e-02],\n                       [ 3.2624e-02]],\n              \n                      [[-6.5344e-02],\n                       [ 1.0106e-02],\n                       [-1.5147e-02],\n                       ...,\n                       [ 1.0679e-04],\n                       [ 5.1660e-02],\n                       [ 8.7525e-03]]], dtype=torch.float64)),\n             ('6.14.convs.0.1.weight',\n              tensor([0.9525, 0.9719, 0.9757, 0.9917, 0.9495, 0.9690, 0.9585, 0.9789, 0.9811,\n                      0.9651, 0.9550, 0.9889, 0.9799, 0.9561, 0.9831, 0.9410, 0.9689, 0.9640,\n                      0.9759, 0.9656, 0.9825, 0.9566, 0.9243, 0.9800, 0.9463, 0.9699, 0.9652,\n                      0.9994, 0.9620, 0.9709, 0.9481, 0.9862, 0.9583, 0.9638, 0.9481, 0.9662,\n                      0.9901, 0.9453, 0.9737, 0.9776, 0.9759, 0.9536, 0.9683, 0.9756, 0.9553,\n                      0.9489, 0.9587, 0.9524, 0.9730, 0.9627, 0.9534, 0.9626, 0.9703, 0.9718,\n                      0.9527, 0.9480, 0.9544, 0.9452, 0.9480, 0.9887, 0.9504, 0.9842, 0.9855,\n                      0.9604], dtype=torch.float64)),\n             ('6.14.convs.0.1.bias',\n              tensor([-1.4633e-02,  3.6452e-03,  2.0481e-02, -1.3261e-03, -2.3015e-02,\n                       2.3452e-02,  7.9624e-03,  2.9815e-02,  1.2440e-02,  5.1935e-03,\n                      -4.2705e-03,  1.5624e-02,  1.1480e-02, -1.2509e-02,  1.7098e-02,\n                      -1.4460e-03, -9.4927e-03, -8.7487e-04, -1.0514e-02,  9.4479e-03,\n                       1.7121e-02, -1.1738e-02, -8.5928e-03,  2.8503e-02,  1.0380e-02,\n                      -5.1002e-03,  1.3708e-02,  1.9667e-02, -1.7578e-02,  2.0791e-02,\n                      -2.2950e-02,  2.1195e-02, -1.1251e-02, -1.2482e-03, -5.9303e-03,\n                       6.1032e-04,  2.0373e-02,  8.4859e-03,  1.6992e-03, -2.0250e-02,\n                       2.9656e-02,  4.4756e-03,  5.3999e-03, -5.7733e-03, -9.2714e-03,\n                      -3.1791e-03,  9.3408e-03, -1.1724e-02,  6.2458e-03,  1.8660e-02,\n                       3.5461e-03,  1.0799e-02,  7.1723e-03,  3.1934e-03, -5.3938e-04,\n                       1.2567e-02,  8.5068e-04, -2.5023e-02,  9.1758e-03,  1.7066e-02,\n                      -3.0497e-02,  1.2168e-02,  1.9033e-02, -2.2422e-05],\n                     dtype=torch.float64)),\n             ('6.14.convs.0.1.running_mean',\n              tensor([ 0.2129,  0.2392, -1.1709, -0.6569,  0.6296,  0.4536,  0.7904, -0.3640,\n                      -0.4672,  0.1389, -0.8530, -0.1185, -0.3664, -1.0939, -0.2134, -1.0852,\n                       0.5117, -0.8136,  1.6629,  0.2476,  1.2363,  0.6140, -0.6228, -0.2199,\n                      -0.3268,  0.9550, -0.1406, -0.4663,  0.1587,  0.0172,  1.3006, -0.3817,\n                      -0.4664,  0.7236,  0.5750, -0.4993, -0.0993, -0.8862, -0.1513,  0.3100,\n                      -1.2171, -0.6683,  0.8378,  0.4937, -0.3231,  0.1375, -0.4551, -0.1724,\n                       0.4359, -0.8960, -1.3968, -1.1370, -0.2018,  0.9186,  0.7014, -0.6626,\n                      -0.4704, -0.6797, -0.0240, -0.3629,  0.6358,  0.0805, -0.3016,  0.0126],\n                     dtype=torch.float64)),\n             ('6.14.convs.0.1.running_var',\n              tensor([0.3306, 0.1077, 0.4177, 0.1389, 0.1597, 0.5041, 1.3595, 0.2186, 0.3781,\n                      0.3793, 0.1629, 0.1123, 0.2050, 0.1850, 0.3898, 0.5976, 0.4065, 0.1767,\n                      1.5156, 0.1501, 0.6881, 0.3413, 1.1223, 0.1513, 0.3041, 0.3005, 0.2007,\n                      0.1332, 0.3814, 0.2054, 0.7908, 0.1311, 0.1745, 0.1647, 1.3914, 0.1646,\n                      0.1488, 0.6938, 0.1662, 0.2469, 0.6444, 0.3518, 0.4422, 0.9674, 0.2048,\n                      0.3099, 0.1459, 0.1890, 0.2512, 0.5993, 1.0015, 0.2166, 0.2218, 0.8162,\n                      0.1848, 0.2734, 0.5868, 0.1937, 0.2838, 0.1613, 0.2925, 0.1126, 0.1627,\n                      0.6123], dtype=torch.float64)),\n             ('6.14.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.14.convs.1.0.weight',\n              tensor([[[ 0.0965,  0.0027,  0.0158, -0.0907,  0.1548],\n                       [-0.1032, -0.1144,  0.1827, -0.0500,  0.0275],\n                       [ 0.0792, -0.0748,  0.0143,  0.1289, -0.0517],\n                       ...,\n                       [ 0.0877,  0.1365,  0.0455,  0.0590,  0.0972],\n                       [-0.0907,  0.0410,  0.0856, -0.0269,  0.0983],\n                       [-0.0064, -0.1133, -0.0145,  0.0535, -0.0013]],\n              \n                      [[-0.1529,  0.1502, -0.1088, -0.0776,  0.0183],\n                       [ 0.0415, -0.0496, -0.1053,  0.0872,  0.0415],\n                       [ 0.1552,  0.1142, -0.1063,  0.0355, -0.0559],\n                       ...,\n                       [ 0.0871, -0.0404,  0.0049,  0.0624,  0.1225],\n                       [-0.0818, -0.0193,  0.0717,  0.0115,  0.0944],\n                       [ 0.0333, -0.0930,  0.0634,  0.0037,  0.0116]],\n              \n                      [[ 0.0925,  0.1481, -0.0174, -0.0291, -0.0894],\n                       [-0.0645, -0.0116,  0.0274, -0.1454, -0.0338],\n                       [ 0.0035,  0.0285, -0.0951,  0.0514,  0.0578],\n                       ...,\n                       [ 0.0320, -0.0762,  0.0013, -0.0643, -0.0345],\n                       [ 0.0373,  0.0079,  0.0203,  0.0493,  0.1449],\n                       [-0.0203, -0.0421,  0.1473,  0.0083, -0.1305]],\n              \n                      ...,\n              \n                      [[-0.0161, -0.0244, -0.1655, -0.0218,  0.1213],\n                       [-0.2903,  0.0705, -0.0137,  0.0375,  0.0728],\n                       [ 0.0028, -0.0110,  0.0097, -0.0485,  0.0141],\n                       ...,\n                       [-0.0646,  0.0741, -0.0873,  0.0861,  0.1458],\n                       [ 0.1155, -0.0252, -0.0417,  0.1304,  0.1073],\n                       [-0.0664,  0.0150, -0.0763,  0.0077,  0.0668]],\n              \n                      [[ 0.0353,  0.0042,  0.0699,  0.0042,  0.0006],\n                       [ 0.1006, -0.0051,  0.0168, -0.0949,  0.1144],\n                       [ 0.1709, -0.1775, -0.0006,  0.0008,  0.1779],\n                       ...,\n                       [-0.0090, -0.0200,  0.0384, -0.0250,  0.1623],\n                       [ 0.1357, -0.0239,  0.1576, -0.0031, -0.1411],\n                       [-0.1240, -0.0836, -0.0531, -0.0615, -0.0977]],\n              \n                      [[-0.0844, -0.1113, -0.0198, -0.0386, -0.1010],\n                       [-0.1122,  0.0376, -0.0720,  0.0822, -0.1421],\n                       [ 0.0275, -0.0589, -0.0085,  0.1507, -0.0030],\n                       ...,\n                       [-0.0825,  0.0495,  0.0048, -0.0400,  0.0203],\n                       [ 0.0429,  0.0005, -0.0535,  0.0248, -0.0261],\n                       [ 0.0547, -0.0310, -0.1147,  0.0737,  0.0346]]], dtype=torch.float64)),\n             ('6.14.convs.1.1.weight',\n              tensor([0.9698, 0.9703, 0.9649, 0.9486, 0.9362, 0.9595, 0.9669, 0.9414, 0.9611,\n                      0.9591, 0.9633, 0.9446, 0.9731, 0.9700, 0.9653, 0.9492, 0.9558, 0.9626,\n                      0.9676, 0.9507, 0.9657, 0.9799, 0.9484, 0.9752, 0.9727, 0.9715, 0.9593,\n                      0.9408, 0.9555, 0.9812, 0.9544, 0.9627, 0.9817, 0.9610, 0.9597, 0.9737,\n                      0.9680, 0.9588, 0.9682, 0.9636, 0.9483, 0.9568, 0.9483, 0.9734, 0.9330,\n                      0.9484, 0.9605, 0.9615, 0.9313, 0.9628, 0.9450, 0.9455, 0.9838, 0.9681,\n                      0.9748, 0.9480, 0.9543, 0.9572, 0.9508, 0.9481, 0.9556, 0.9635, 0.9715,\n                      0.9456], dtype=torch.float64)),\n             ('6.14.convs.1.1.bias',\n              tensor([-6.7622e-03, -6.6768e-03,  1.4336e-02, -2.0384e-03, -1.9962e-03,\n                      -1.9036e-02, -4.1224e-04,  4.3166e-03,  1.1551e-02,  1.2141e-02,\n                       1.3844e-02, -1.1620e-02, -2.3727e-03,  1.0230e-02, -1.4533e-02,\n                      -6.0496e-03,  2.7096e-03,  2.5620e-04,  2.4661e-03, -1.7885e-03,\n                      -6.3180e-03, -2.3844e-03,  6.6566e-03, -1.2616e-02,  1.7306e-03,\n                      -2.3083e-03,  1.5006e-02, -8.1094e-03, -1.4035e-02, -6.7148e-04,\n                      -1.0172e-02, -1.9230e-03, -1.5971e-03, -3.3683e-03, -1.2528e-02,\n                       2.6604e-02,  6.1867e-03, -1.7183e-02,  9.1226e-03,  2.6066e-03,\n                      -4.0264e-02, -2.2759e-02, -9.1506e-03,  1.8505e-02, -2.4043e-03,\n                      -8.5184e-03, -8.6515e-03,  1.6169e-02, -2.6693e-02, -6.8134e-05,\n                       3.5488e-03, -4.8545e-03, -7.9838e-03,  2.5749e-03,  4.9354e-03,\n                       2.1841e-03,  3.3992e-03, -4.5390e-03, -1.2006e-02,  8.6400e-03,\n                      -9.1348e-04, -4.6363e-04, -5.5802e-03, -2.2655e-02],\n                     dtype=torch.float64)),\n             ('6.14.convs.1.1.running_mean',\n              tensor([ 2.1063e-01, -2.1963e-01,  2.9270e-01, -6.6521e-01, -6.5460e-01,\n                      -1.7141e-01, -3.9080e-01, -3.6882e-01,  1.6433e-01, -5.3185e-01,\n                      -3.2825e-01, -5.7722e-01,  9.5513e-02, -8.1703e-02, -8.0854e-01,\n                      -9.2183e-01, -1.0972e-01,  1.0362e+00, -8.0875e-01,  4.9838e-01,\n                      -3.1681e-01,  2.8013e-01,  1.7551e-01,  3.7642e-01, -7.6371e-01,\n                      -6.6375e-02,  1.9549e-01,  3.7953e-01, -1.0003e-01,  5.0503e-01,\n                       5.6529e-01,  4.9146e-01,  7.4374e-01, -3.5891e-01, -4.1658e-01,\n                      -2.9461e-01, -3.1656e-01,  5.1993e-01,  4.5903e-01,  9.1721e-01,\n                       7.4038e-01,  3.5792e-01,  1.7909e-01, -7.2803e-01, -6.5921e-01,\n                      -4.2045e-02,  5.5385e-01, -9.6556e-01,  1.9092e-01,  2.0352e-02,\n                       2.8835e-01, -2.1176e-01, -7.5625e-01,  4.1450e-01,  6.4818e-01,\n                      -2.6404e-01,  9.9570e-02,  2.7974e-01, -6.7690e-01, -3.7404e-02,\n                       1.9910e-01, -5.8474e-01,  9.5688e-04, -4.9329e-01],\n                     dtype=torch.float64)),\n             ('6.14.convs.1.1.running_var',\n              tensor([0.4177, 0.4526, 0.3627, 0.5962, 0.6910, 0.3260, 0.4654, 0.4809, 0.5906,\n                      0.9024, 0.3876, 0.5065, 0.4418, 0.6332, 0.4221, 0.3128, 0.6325, 0.4747,\n                      0.3829, 0.5612, 0.4202, 0.3599, 0.4299, 0.3656, 0.4964, 0.8745, 0.4172,\n                      0.5539, 0.3451, 0.4637, 0.6000, 0.5498, 0.6517, 0.3863, 0.6199, 0.5757,\n                      0.4259, 1.6924, 0.3543, 0.4730, 0.6826, 0.5410, 0.6369, 0.4739, 0.3790,\n                      0.4693, 0.4901, 0.3365, 0.6446, 0.5219, 0.4454, 0.5427, 0.4177, 0.4721,\n                      0.4679, 0.6169, 0.6664, 0.3397, 0.5956, 0.3822, 1.1353, 0.6155, 0.2851,\n                      0.4379], dtype=torch.float64)),\n             ('6.14.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.14.convs.2.0.weight',\n              tensor([[[-0.1885],\n                       [ 0.0270],\n                       [ 0.2305],\n                       ...,\n                       [-0.1859],\n                       [-0.0906],\n                       [ 0.0640]],\n              \n                      [[-0.0146],\n                       [-0.1211],\n                       [ 0.0129],\n                       ...,\n                       [-0.0304],\n                       [ 0.0527],\n                       [-0.0866]],\n              \n                      [[-0.0934],\n                       [ 0.0120],\n                       [ 0.1071],\n                       ...,\n                       [-0.0665],\n                       [ 0.0911],\n                       [ 0.0802]],\n              \n                      ...,\n              \n                      [[-0.0100],\n                       [-0.2365],\n                       [-0.0050],\n                       ...,\n                       [-0.0709],\n                       [ 0.2043],\n                       [-0.0051]],\n              \n                      [[-0.1404],\n                       [-0.1385],\n                       [ 0.1909],\n                       ...,\n                       [ 0.1743],\n                       [-0.1109],\n                       [-0.1718]],\n              \n                      [[ 0.2084],\n                       [-0.1079],\n                       [-0.0063],\n                       ...,\n                       [ 0.0191],\n                       [ 0.1082],\n                       [-0.0130]]], dtype=torch.float64)),\n             ('6.14.convs.2.1.weight',\n              tensor([ 1.5736e-02, -7.2876e-03, -3.4539e-03,  7.4461e-03, -7.2907e-03,\n                       2.1321e-02,  1.5802e-02, -1.6684e-03,  2.2476e-02,  7.5699e-03,\n                      -1.2772e-02, -2.3367e-02,  2.1775e-02, -3.0274e-03,  2.0812e-03,\n                      -3.9827e-02,  1.0222e-02,  1.7974e-02, -2.8318e-02,  5.3611e-03,\n                      -1.4073e-02,  4.9689e-04,  1.3865e-02,  3.4198e-03, -1.9289e-02,\n                       4.3788e-03,  1.5074e-02, -8.6650e-04, -7.5729e-03,  4.1597e-03,\n                       1.8546e-02,  2.6312e-02,  8.4122e-03, -1.2805e-02,  2.3715e-03,\n                       2.2518e-02,  1.6254e-02,  1.8126e-03, -9.4583e-03,  2.7529e-02,\n                       2.1536e-02, -2.7798e-03,  6.9601e-03,  2.6775e-02, -1.0081e-02,\n                      -9.4782e-03,  2.9958e-02,  1.2145e-02, -1.7918e-02,  1.4826e-03,\n                       3.8331e-02, -1.7387e-02, -2.7409e-03,  9.5228e-03, -7.2281e-03,\n                       2.1282e-02, -6.6992e-03, -2.1436e-02,  1.6560e-02, -9.9812e-03,\n                      -6.4283e-03, -1.7930e-02,  8.5809e-06,  3.0234e-03,  3.3746e-02,\n                      -3.1131e-02, -1.2737e-02,  1.6249e-02, -1.7992e-02, -6.7936e-04,\n                       5.2887e-03,  1.7849e-02, -5.3674e-03,  2.5484e-02, -1.9273e-02,\n                       6.9146e-03,  5.3136e-03,  3.6484e-03,  2.0866e-02, -9.0841e-03,\n                      -7.9872e-03,  2.5644e-02,  3.5399e-02, -1.2316e-02,  1.7186e-02,\n                      -3.0739e-03,  2.9126e-02,  3.1144e-03,  7.7750e-03,  1.1417e-02,\n                      -1.1424e-02,  8.1994e-03, -6.1575e-05, -1.0525e-02,  4.2314e-03,\n                      -4.0809e-03,  1.0297e-02, -1.2589e-03,  1.9965e-02,  2.1586e-02,\n                      -2.9409e-03, -7.9447e-03,  1.6797e-02, -1.2828e-02, -1.6365e-02,\n                      -2.4021e-02, -3.3813e-02, -1.0140e-02, -1.3431e-02, -6.6214e-04,\n                       8.8033e-03, -2.2674e-03,  6.8517e-03, -2.1693e-02, -9.7868e-03,\n                       1.4110e-02,  1.3607e-02,  2.0425e-02, -2.1966e-02,  1.1143e-02,\n                       1.4850e-02,  1.1744e-02,  3.7157e-03,  2.5422e-02,  5.4570e-03,\n                      -2.3700e-03, -1.8784e-02, -1.7062e-02, -1.2266e-02,  1.4217e-02,\n                       6.8295e-03,  6.8180e-03, -1.3141e-02,  9.4746e-03, -9.8198e-03,\n                       9.8451e-03,  7.6225e-03, -7.9840e-04,  6.0248e-03, -1.2513e-02,\n                      -4.5429e-03,  1.9239e-03, -2.4311e-02,  5.9705e-03,  2.2080e-02,\n                       2.4998e-02,  1.4509e-02, -9.4550e-03,  3.1931e-02,  1.7518e-02,\n                       2.3306e-03, -3.3995e-02,  1.5254e-02,  2.3105e-02, -1.6452e-02,\n                       1.1688e-02, -1.0264e-02,  1.1572e-02, -2.1778e-02, -1.6071e-04,\n                      -1.4199e-02, -6.9624e-03, -1.3369e-02,  1.0611e-02, -3.2145e-02,\n                      -4.6487e-03,  1.1036e-02,  3.0410e-03,  4.7614e-03, -1.4272e-02,\n                      -3.7738e-02,  2.9097e-03,  2.1413e-02, -2.5720e-03, -9.5727e-03,\n                      -1.5675e-02, -2.1848e-02,  3.1626e-03,  3.4785e-02, -1.8398e-02,\n                      -3.2209e-02, -7.6526e-03, -2.0189e-02,  2.0382e-02, -1.6469e-02,\n                      -2.0120e-02, -6.0278e-04, -1.6347e-02, -1.2308e-02, -1.3368e-02,\n                       3.0702e-03,  6.7696e-03,  1.3789e-02,  7.5802e-03,  4.4226e-03,\n                       1.7069e-02,  5.1781e-03, -7.5791e-03, -2.8421e-02,  2.6106e-02,\n                      -2.1857e-02, -3.6030e-02, -4.0933e-03,  1.5411e-02,  3.3685e-02,\n                       1.0099e-02,  1.0357e-02, -6.4655e-03, -1.5033e-02, -3.0701e-03,\n                       4.3711e-03, -2.1394e-02,  1.1476e-02, -1.3979e-03,  1.2544e-02,\n                       1.3505e-03, -2.9370e-02, -6.9009e-03,  2.7346e-02,  1.4169e-03,\n                      -4.2313e-04,  3.2365e-03,  2.7603e-02, -1.4010e-02,  2.6882e-02,\n                      -3.7576e-03, -5.2766e-03, -9.5697e-03, -5.0745e-03, -1.4550e-02,\n                      -2.6532e-02, -2.4705e-02,  4.0987e-03,  3.1217e-02, -1.4942e-02,\n                      -7.1709e-03, -2.2050e-02, -4.2713e-03,  9.8033e-03, -1.9234e-02,\n                      -7.4559e-03, -1.4143e-02, -3.5966e-03, -9.9090e-03, -7.8588e-03,\n                       1.7008e-03, -2.7607e-03,  2.8645e-02,  4.9021e-03, -2.2649e-02,\n                      -1.9762e-03,  2.4631e-03, -2.3914e-02,  5.2466e-03,  1.7005e-02,\n                       1.8338e-02], dtype=torch.float64)),\n             ('6.14.convs.2.1.bias',\n              tensor([ 5.8337e-04,  8.7161e-03,  9.7822e-03,  1.4136e-02,  3.7749e-03,\n                       9.4440e-03,  6.9385e-03, -2.0490e-03,  1.3700e-02,  1.5831e-02,\n                       1.2665e-02, -6.8320e-03,  3.3390e-03, -5.0369e-03,  8.7464e-03,\n                       3.8034e-03,  2.5515e-02,  6.2206e-04,  9.5942e-03, -3.3557e-03,\n                      -6.7202e-03,  1.6262e-04,  5.0797e-03,  5.9981e-03,  7.7227e-03,\n                      -1.7456e-02,  1.3811e-03,  1.1715e-02,  9.7634e-03, -9.4234e-03,\n                      -2.5349e-03,  7.7975e-03, -1.6893e-03,  2.1533e-02,  3.4766e-03,\n                       1.5701e-02, -2.4168e-03,  1.5000e-02,  1.1390e-02,  1.1915e-02,\n                       1.8040e-03,  1.2340e-02, -1.0227e-02, -1.4714e-03,  6.8795e-03,\n                      -1.4375e-02,  1.4249e-02,  3.1333e-03, -1.3396e-02,  1.6570e-03,\n                       9.8685e-03,  3.8613e-03,  7.1221e-03,  1.7412e-02,  2.9498e-03,\n                       1.5352e-02,  9.4217e-03,  1.1719e-03,  1.2148e-02, -1.8754e-03,\n                       4.1562e-03, -2.5491e-03,  5.6550e-03,  8.8902e-03, -5.8815e-03,\n                       4.8627e-03, -1.0043e-02,  1.4669e-02,  1.3239e-02, -1.5225e-02,\n                       7.4269e-03,  3.0531e-03, -5.4918e-04, -8.1785e-03,  1.4100e-02,\n                       5.6879e-03, -1.5054e-04, -2.8871e-03,  2.1115e-03,  1.9573e-02,\n                       4.9192e-03, -9.7291e-03,  8.5289e-03,  4.1062e-03, -5.3416e-03,\n                       1.6770e-02,  8.9935e-04,  1.1899e-02,  1.4619e-02,  1.0834e-04,\n                       5.2395e-04,  1.0381e-02,  9.7955e-03, -8.5737e-05,  9.6237e-03,\n                      -8.5457e-03,  1.1372e-02,  4.9466e-03,  2.0507e-02,  8.5325e-03,\n                       2.2761e-02,  1.4413e-02,  4.6015e-03,  8.8327e-03,  1.6484e-03,\n                       2.6931e-03, -8.0282e-03,  8.6644e-03,  7.8472e-03,  4.6853e-03,\n                      -1.2644e-02, -9.6816e-03,  2.9948e-03,  2.0802e-02,  1.5601e-02,\n                       5.9147e-03,  5.1458e-03,  3.9814e-03,  5.4950e-03, -1.2381e-02,\n                       5.6668e-04,  1.1955e-02,  4.0694e-03,  5.7698e-04,  2.1172e-02,\n                       9.4442e-03,  6.8089e-03,  3.9312e-03,  8.8342e-03,  1.2765e-02,\n                       6.5112e-03,  5.3796e-03,  1.3433e-02,  5.1025e-03,  7.8809e-03,\n                      -1.4009e-02,  1.4142e-02,  3.3423e-03,  6.3470e-03, -1.4682e-03,\n                       1.3080e-02,  5.4408e-03,  1.6634e-02,  2.3801e-03, -7.3193e-03,\n                       1.2420e-02,  5.1028e-03, -1.0865e-04,  1.2648e-02,  8.4206e-03,\n                       7.8787e-03,  1.0547e-02,  5.6378e-03,  1.1991e-02,  1.2066e-02,\n                       3.8934e-03, -4.7506e-04,  9.3844e-03, -1.1138e-03, -1.0792e-02,\n                       5.2280e-03,  1.6871e-03, -3.5828e-03,  6.0369e-03,  1.2640e-02,\n                      -3.7089e-03, -1.3168e-02,  6.5984e-03,  6.6375e-03,  2.0516e-02,\n                       1.1960e-03, -1.4555e-04,  5.8167e-03,  1.4624e-02, -1.3613e-02,\n                       1.1293e-02,  3.2295e-03,  1.8230e-02,  1.6713e-03,  8.2045e-03,\n                      -3.3450e-04,  1.1495e-02, -6.2043e-03, -9.0849e-03,  1.2302e-02,\n                       8.0910e-03,  1.3837e-02,  1.0073e-02,  8.9927e-03,  8.0492e-03,\n                       6.4389e-03,  7.2144e-03,  6.1394e-03,  4.4872e-03, -1.7703e-03,\n                       1.0190e-02,  7.4669e-03,  2.2370e-03,  5.1278e-03,  1.1924e-02,\n                      -1.2104e-03,  2.3817e-02,  1.8197e-02,  1.8632e-02,  1.3702e-02,\n                      -1.2401e-03,  8.7114e-03, -1.0098e-02,  5.9039e-03,  1.3382e-02,\n                       4.3429e-03,  1.0475e-02,  3.8276e-03,  7.8336e-03,  7.9269e-03,\n                       3.9322e-03,  6.3476e-03,  1.6844e-02,  4.5460e-03,  4.3071e-03,\n                       1.5390e-02,  1.3315e-03,  2.0788e-03,  1.4203e-02,  2.2957e-03,\n                       6.7605e-03, -8.9227e-03, -2.0635e-03,  2.8109e-02,  1.7326e-02,\n                       2.8677e-03, -3.4123e-03,  9.7750e-03,  1.1292e-02,  2.0729e-03,\n                       9.3608e-03,  2.9421e-03,  1.3558e-02,  5.4997e-03,  7.3573e-03,\n                       2.0913e-03, -1.1360e-04, -2.1136e-03,  1.1646e-02,  2.4487e-03,\n                       7.4126e-03,  5.5638e-03,  4.9860e-03, -1.3606e-02, -1.1076e-02,\n                       2.1211e-02,  2.3833e-02,  1.8569e-02,  1.7618e-02,  2.3303e-03,\n                       3.9070e-03], dtype=torch.float64)),\n             ('6.14.convs.2.1.running_mean',\n              tensor([ 5.0026e-01,  9.3141e-02, -2.1251e-01,  7.3323e-01, -1.8499e-01,\n                      -4.0980e-01,  1.2514e-01, -1.4934e-01,  1.9726e-01,  1.0485e-01,\n                       2.5828e-01, -7.3974e-02, -2.1603e-01, -1.3170e-01, -3.0867e-01,\n                       4.3427e-01,  2.8073e-01,  1.5739e-01,  4.8902e-01, -2.1588e-01,\n                       8.9053e-02, -5.7797e-01,  7.6504e-01, -3.5310e-02,  6.9145e-01,\n                       4.4874e-01,  1.3136e-01,  7.8434e-02,  5.1857e-01, -1.8248e-01,\n                       3.4175e-01,  2.8422e-01,  1.8412e-02, -1.6209e-01, -4.4365e-01,\n                       8.4120e-02, -3.8192e-01, -1.6505e-01, -4.2522e-02,  1.7304e-01,\n                      -7.4047e-01, -1.6742e-01, -1.1923e-01, -5.9140e-01, -1.1016e+00,\n                       4.9109e-01,  5.0325e-01, -1.2081e-02,  2.4890e-01,  7.0643e-02,\n                       2.4532e-01, -8.6393e-02,  9.8280e-02, -2.6729e-01, -2.1211e-01,\n                       3.5975e-01,  8.5683e-02,  4.3402e-01,  2.8010e-01, -2.9853e-01,\n                       6.1529e-02, -9.9139e-02,  1.0229e-01,  3.1469e-01, -5.2147e-01,\n                      -6.9906e-03, -1.9800e-01,  7.6698e-02,  6.1234e-02, -1.2762e+00,\n                      -1.9253e-01, -4.1760e-01, -1.3152e-01, -4.3664e-01,  7.6436e-01,\n                       3.4946e-01, -4.4820e-01,  4.7770e-01,  2.0864e-02,  4.7338e-02,\n                       2.9022e-01, -2.2126e-01, -4.7634e-01,  1.5849e-01,  1.0436e-01,\n                      -8.9968e-02,  4.5607e-02,  2.8470e-01, -1.7707e-01, -1.2997e-01,\n                      -1.0082e+00,  2.5810e-01,  2.5660e-01,  2.5079e-01, -2.5922e-01,\n                      -1.2112e-01, -4.0944e-01, -1.3710e-01,  1.6557e-01, -4.5737e-01,\n                      -6.8667e-01, -4.4445e-01,  1.4642e-01,  2.1788e-01, -1.4625e-01,\n                      -3.7751e-01, -4.6903e-01,  5.5947e-02,  3.8867e-01, -1.6644e-01,\n                       1.4560e-01, -2.4786e-01,  1.0550e-01,  3.7704e-01, -4.2315e-01,\n                      -5.7592e-01, -7.8602e-01, -2.8560e-01,  8.0650e-01, -4.8573e-01,\n                       1.6206e-01, -2.9149e-01, -6.0742e-02,  4.8892e-01, -3.8435e-02,\n                       3.1146e-01, -3.5359e-01,  1.6058e-01,  3.4355e-01, -4.3201e-02,\n                       4.3305e-01,  3.2971e-01,  9.0624e-01,  3.6702e-01, -3.1481e-01,\n                       3.0116e-01, -8.4463e-03, -5.2434e-02, -3.1924e-01, -1.8818e-01,\n                      -1.3858e-02, -1.0314e-02, -9.2277e-01, -8.2794e-02, -7.0564e-02,\n                      -4.8139e-01,  2.4116e-01, -4.7562e-01,  1.7412e-01,  5.9401e-01,\n                       2.7586e-01, -2.6760e-02, -4.4510e-01, -4.8671e-01, -2.7432e-01,\n                      -2.1863e-01,  1.5691e-01, -2.3646e-01, -9.0933e-02, -3.8486e-01,\n                      -3.2732e-01,  4.2269e-01,  3.9178e-01,  5.2351e-02,  7.1855e-03,\n                       4.2797e-01, -1.2154e+00, -3.6851e-01, -5.9731e-02,  1.2184e-01,\n                       4.3613e-01,  5.0065e-01,  9.4921e-01, -7.7080e-01, -1.0948e-01,\n                      -3.6581e-01,  8.3944e-01,  3.3255e-01, -3.9562e-01, -5.1363e-01,\n                      -7.6535e-01, -2.2918e-01, -7.8139e-02,  1.6849e-01,  6.7955e-01,\n                       9.9292e-01,  4.4483e-01, -2.8233e-01,  3.2044e-01,  2.5445e-01,\n                      -2.1611e-01, -5.3334e-02,  8.7077e-01,  1.1670e-01,  2.2550e-01,\n                       9.0622e-02,  4.5673e-01,  1.8207e-01,  4.9145e-01,  2.3715e-01,\n                       4.5510e-01, -4.6668e-02,  1.5837e-01, -3.9190e-01,  1.7196e-01,\n                       8.7218e-01,  8.0817e-02, -2.9992e-01, -6.6255e-01,  5.9850e-02,\n                      -3.1378e-02, -7.1788e-01,  4.2144e-01,  4.7466e-01, -2.2126e-01,\n                       7.9035e-02,  1.4773e-02, -2.4681e-01, -2.1436e-02,  1.0557e-01,\n                       3.3052e-01, -2.9865e-01,  4.3637e-01, -4.8127e-01, -5.3196e-01,\n                      -1.0230e-01, -2.1043e-01,  4.1143e-02, -9.9736e-02, -2.4837e-01,\n                      -2.5516e-01,  2.7657e-01, -1.2699e-01,  1.7097e-01,  4.5303e-02,\n                      -7.3056e-01,  1.2212e-01, -5.1471e-02,  3.1733e-01, -2.7648e-02,\n                       1.9847e-01, -2.8087e-01,  1.3055e-01, -3.4334e-01, -7.2076e-04,\n                       2.7705e-01,  1.5380e-02,  5.0412e-01,  8.5264e-01,  1.5978e-01,\n                       2.0322e-01,  9.0154e-02,  3.0661e-01, -2.7637e-01,  1.2074e-03,\n                       2.6530e-01], dtype=torch.float64)),\n             ('6.14.convs.2.1.running_var',\n              tensor([0.3715, 0.2850, 0.3478, 0.6129, 0.3449, 0.3169, 0.2080, 0.2719, 0.3345,\n                      0.3922, 0.2698, 0.4366, 0.1643, 0.2938, 0.4986, 0.4152, 0.4012, 0.3607,\n                      0.3374, 0.3843, 0.5034, 0.3836, 0.2638, 0.2955, 0.4505, 0.1834, 0.6964,\n                      0.0738, 0.1925, 0.4188, 0.3754, 0.2805, 0.2274, 0.3307, 0.0808, 0.3544,\n                      0.1543, 0.1195, 0.2069, 0.5901, 0.3454, 0.3223, 0.1130, 0.3981, 0.4202,\n                      0.3063, 0.3851, 0.3600, 0.6541, 0.2812, 0.3708, 0.3684, 0.2055, 0.2753,\n                      0.5789, 0.4541, 0.2016, 0.6917, 0.3962, 0.3877, 0.2105, 0.3840, 0.2467,\n                      0.0974, 0.3916, 0.4618, 0.3229, 0.3511, 0.2895, 0.5606, 0.3120, 0.2043,\n                      0.1807, 0.2994, 0.6415, 0.0809, 0.3251, 0.2179, 0.4529, 0.1188, 0.1767,\n                      0.5147, 0.4899, 0.4587, 0.3688, 0.2789, 0.2846, 0.3584, 0.5212, 0.1543,\n                      0.5261, 0.0725, 0.1197, 0.5237, 0.1523, 0.1955, 0.5306, 0.0943, 0.2411,\n                      0.3187, 0.3282, 0.3035, 0.3690, 0.1920, 0.1522, 0.3096, 0.5753, 0.3035,\n                      0.3711, 0.0669, 0.2502, 0.1947, 0.2682, 0.2303, 0.4490, 0.6046, 0.3999,\n                      0.2405, 0.5596, 0.5948, 0.3013, 0.3441, 0.2598, 0.3294, 0.1480, 0.4248,\n                      0.3442, 0.2619, 0.2029, 0.3976, 0.1121, 0.2037, 0.3916, 0.3200, 0.3491,\n                      0.1539, 0.2194, 0.1420, 0.1775, 0.2977, 0.2182, 0.2346, 0.3621, 0.1361,\n                      0.1920, 0.3043, 0.1175, 0.3965, 0.1517, 0.4139, 0.2431, 0.2734, 0.3780,\n                      0.4685, 0.4891, 0.5140, 0.3274, 0.2088, 0.2440, 0.1464, 0.3099, 0.1424,\n                      0.3065, 0.1068, 0.4195, 0.2866, 0.3903, 0.1936, 0.3266, 0.4546, 0.3739,\n                      0.0965, 0.4264, 0.2683, 0.3809, 0.5158, 0.3613, 0.1242, 0.4777, 0.2961,\n                      0.5248, 0.1413, 0.3295, 0.2300, 0.5278, 0.4805, 0.3406, 0.2826, 0.3727,\n                      0.2331, 0.2419, 0.3833, 0.4922, 0.3249, 0.3030, 0.2729, 0.3098, 0.3590,\n                      0.4502, 0.5565, 0.4356, 0.3420, 0.1291, 0.4557, 0.3998, 0.3618, 0.2300,\n                      0.0615, 0.3368, 0.4447, 0.0690, 0.4648, 0.3062, 0.2253, 0.1868, 0.1201,\n                      0.5601, 0.2608, 0.3905, 0.2948, 0.1460, 0.0878, 0.3208, 0.3119, 0.4130,\n                      0.2110, 0.2469, 0.1339, 0.2769, 0.7031, 0.5923, 0.4617, 0.1750, 0.2574,\n                      0.1978, 0.3139, 0.2984, 0.1729, 0.4170, 0.2989, 0.1676, 0.1521, 0.3499,\n                      0.2030, 0.3443, 0.1467, 0.1355, 0.3351, 0.3515, 0.4910, 0.2412, 0.4063,\n                      0.4572, 0.3446, 0.2855, 0.3754], dtype=torch.float64)),\n             ('6.14.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.14.convpath.0.0.0.weight',\n              tensor([[[ 7.6561e-02],\n                       [-1.5895e-02],\n                       [ 4.6714e-03],\n                       ...,\n                       [ 7.2812e-02],\n                       [-4.8927e-02],\n                       [ 3.2493e-02]],\n              \n                      [[ 4.4624e-02],\n                       [ 5.0613e-02],\n                       [ 4.2176e-02],\n                       ...,\n                       [-1.4014e-01],\n                       [-6.9230e-03],\n                       [-5.6085e-02]],\n              \n                      [[ 1.2783e-01],\n                       [ 8.1154e-03],\n                       [ 3.1433e-02],\n                       ...,\n                       [-1.7322e-01],\n                       [ 1.1900e-01],\n                       [-6.8969e-02]],\n              \n                      ...,\n              \n                      [[-1.6158e-02],\n                       [-1.1034e-02],\n                       [-3.3664e-02],\n                       ...,\n                       [-1.9662e-02],\n                       [ 4.7206e-02],\n                       [ 3.1625e-03]],\n              \n                      [[-5.6436e-02],\n                       [-8.1698e-02],\n                       [ 7.1369e-02],\n                       ...,\n                       [-1.7726e-01],\n                       [-9.1429e-02],\n                       [ 3.2624e-02]],\n              \n                      [[-6.5344e-02],\n                       [ 1.0106e-02],\n                       [-1.5147e-02],\n                       ...,\n                       [ 1.0679e-04],\n                       [ 5.1660e-02],\n                       [ 8.7525e-03]]], dtype=torch.float64)),\n             ('6.14.convpath.0.0.1.weight',\n              tensor([0.9525, 0.9719, 0.9757, 0.9917, 0.9495, 0.9690, 0.9585, 0.9789, 0.9811,\n                      0.9651, 0.9550, 0.9889, 0.9799, 0.9561, 0.9831, 0.9410, 0.9689, 0.9640,\n                      0.9759, 0.9656, 0.9825, 0.9566, 0.9243, 0.9800, 0.9463, 0.9699, 0.9652,\n                      0.9994, 0.9620, 0.9709, 0.9481, 0.9862, 0.9583, 0.9638, 0.9481, 0.9662,\n                      0.9901, 0.9453, 0.9737, 0.9776, 0.9759, 0.9536, 0.9683, 0.9756, 0.9553,\n                      0.9489, 0.9587, 0.9524, 0.9730, 0.9627, 0.9534, 0.9626, 0.9703, 0.9718,\n                      0.9527, 0.9480, 0.9544, 0.9452, 0.9480, 0.9887, 0.9504, 0.9842, 0.9855,\n                      0.9604], dtype=torch.float64)),\n             ('6.14.convpath.0.0.1.bias',\n              tensor([-1.4633e-02,  3.6452e-03,  2.0481e-02, -1.3261e-03, -2.3015e-02,\n                       2.3452e-02,  7.9624e-03,  2.9815e-02,  1.2440e-02,  5.1935e-03,\n                      -4.2705e-03,  1.5624e-02,  1.1480e-02, -1.2509e-02,  1.7098e-02,\n                      -1.4460e-03, -9.4927e-03, -8.7487e-04, -1.0514e-02,  9.4479e-03,\n                       1.7121e-02, -1.1738e-02, -8.5928e-03,  2.8503e-02,  1.0380e-02,\n                      -5.1002e-03,  1.3708e-02,  1.9667e-02, -1.7578e-02,  2.0791e-02,\n                      -2.2950e-02,  2.1195e-02, -1.1251e-02, -1.2482e-03, -5.9303e-03,\n                       6.1032e-04,  2.0373e-02,  8.4859e-03,  1.6992e-03, -2.0250e-02,\n                       2.9656e-02,  4.4756e-03,  5.3999e-03, -5.7733e-03, -9.2714e-03,\n                      -3.1791e-03,  9.3408e-03, -1.1724e-02,  6.2458e-03,  1.8660e-02,\n                       3.5461e-03,  1.0799e-02,  7.1723e-03,  3.1934e-03, -5.3938e-04,\n                       1.2567e-02,  8.5068e-04, -2.5023e-02,  9.1758e-03,  1.7066e-02,\n                      -3.0497e-02,  1.2168e-02,  1.9033e-02, -2.2422e-05],\n                     dtype=torch.float64)),\n             ('6.14.convpath.0.0.1.running_mean',\n              tensor([ 0.2129,  0.2392, -1.1709, -0.6569,  0.6296,  0.4536,  0.7904, -0.3640,\n                      -0.4672,  0.1389, -0.8530, -0.1185, -0.3664, -1.0939, -0.2134, -1.0852,\n                       0.5117, -0.8136,  1.6629,  0.2476,  1.2363,  0.6140, -0.6228, -0.2199,\n                      -0.3268,  0.9550, -0.1406, -0.4663,  0.1587,  0.0172,  1.3006, -0.3817,\n                      -0.4664,  0.7236,  0.5750, -0.4993, -0.0993, -0.8862, -0.1513,  0.3100,\n                      -1.2171, -0.6683,  0.8378,  0.4937, -0.3231,  0.1375, -0.4551, -0.1724,\n                       0.4359, -0.8960, -1.3968, -1.1370, -0.2018,  0.9186,  0.7014, -0.6626,\n                      -0.4704, -0.6797, -0.0240, -0.3629,  0.6358,  0.0805, -0.3016,  0.0126],\n                     dtype=torch.float64)),\n             ('6.14.convpath.0.0.1.running_var',\n              tensor([0.3306, 0.1077, 0.4177, 0.1389, 0.1597, 0.5041, 1.3595, 0.2186, 0.3781,\n                      0.3793, 0.1629, 0.1123, 0.2050, 0.1850, 0.3898, 0.5976, 0.4065, 0.1767,\n                      1.5156, 0.1501, 0.6881, 0.3413, 1.1223, 0.1513, 0.3041, 0.3005, 0.2007,\n                      0.1332, 0.3814, 0.2054, 0.7908, 0.1311, 0.1745, 0.1647, 1.3914, 0.1646,\n                      0.1488, 0.6938, 0.1662, 0.2469, 0.6444, 0.3518, 0.4422, 0.9674, 0.2048,\n                      0.3099, 0.1459, 0.1890, 0.2512, 0.5993, 1.0015, 0.2166, 0.2218, 0.8162,\n                      0.1848, 0.2734, 0.5868, 0.1937, 0.2838, 0.1613, 0.2925, 0.1126, 0.1627,\n                      0.6123], dtype=torch.float64)),\n             ('6.14.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.14.convpath.0.1.0.weight',\n              tensor([[[ 0.0965,  0.0027,  0.0158, -0.0907,  0.1548],\n                       [-0.1032, -0.1144,  0.1827, -0.0500,  0.0275],\n                       [ 0.0792, -0.0748,  0.0143,  0.1289, -0.0517],\n                       ...,\n                       [ 0.0877,  0.1365,  0.0455,  0.0590,  0.0972],\n                       [-0.0907,  0.0410,  0.0856, -0.0269,  0.0983],\n                       [-0.0064, -0.1133, -0.0145,  0.0535, -0.0013]],\n              \n                      [[-0.1529,  0.1502, -0.1088, -0.0776,  0.0183],\n                       [ 0.0415, -0.0496, -0.1053,  0.0872,  0.0415],\n                       [ 0.1552,  0.1142, -0.1063,  0.0355, -0.0559],\n                       ...,\n                       [ 0.0871, -0.0404,  0.0049,  0.0624,  0.1225],\n                       [-0.0818, -0.0193,  0.0717,  0.0115,  0.0944],\n                       [ 0.0333, -0.0930,  0.0634,  0.0037,  0.0116]],\n              \n                      [[ 0.0925,  0.1481, -0.0174, -0.0291, -0.0894],\n                       [-0.0645, -0.0116,  0.0274, -0.1454, -0.0338],\n                       [ 0.0035,  0.0285, -0.0951,  0.0514,  0.0578],\n                       ...,\n                       [ 0.0320, -0.0762,  0.0013, -0.0643, -0.0345],\n                       [ 0.0373,  0.0079,  0.0203,  0.0493,  0.1449],\n                       [-0.0203, -0.0421,  0.1473,  0.0083, -0.1305]],\n              \n                      ...,\n              \n                      [[-0.0161, -0.0244, -0.1655, -0.0218,  0.1213],\n                       [-0.2903,  0.0705, -0.0137,  0.0375,  0.0728],\n                       [ 0.0028, -0.0110,  0.0097, -0.0485,  0.0141],\n                       ...,\n                       [-0.0646,  0.0741, -0.0873,  0.0861,  0.1458],\n                       [ 0.1155, -0.0252, -0.0417,  0.1304,  0.1073],\n                       [-0.0664,  0.0150, -0.0763,  0.0077,  0.0668]],\n              \n                      [[ 0.0353,  0.0042,  0.0699,  0.0042,  0.0006],\n                       [ 0.1006, -0.0051,  0.0168, -0.0949,  0.1144],\n                       [ 0.1709, -0.1775, -0.0006,  0.0008,  0.1779],\n                       ...,\n                       [-0.0090, -0.0200,  0.0384, -0.0250,  0.1623],\n                       [ 0.1357, -0.0239,  0.1576, -0.0031, -0.1411],\n                       [-0.1240, -0.0836, -0.0531, -0.0615, -0.0977]],\n              \n                      [[-0.0844, -0.1113, -0.0198, -0.0386, -0.1010],\n                       [-0.1122,  0.0376, -0.0720,  0.0822, -0.1421],\n                       [ 0.0275, -0.0589, -0.0085,  0.1507, -0.0030],\n                       ...,\n                       [-0.0825,  0.0495,  0.0048, -0.0400,  0.0203],\n                       [ 0.0429,  0.0005, -0.0535,  0.0248, -0.0261],\n                       [ 0.0547, -0.0310, -0.1147,  0.0737,  0.0346]]], dtype=torch.float64)),\n             ('6.14.convpath.0.1.1.weight',\n              tensor([0.9698, 0.9703, 0.9649, 0.9486, 0.9362, 0.9595, 0.9669, 0.9414, 0.9611,\n                      0.9591, 0.9633, 0.9446, 0.9731, 0.9700, 0.9653, 0.9492, 0.9558, 0.9626,\n                      0.9676, 0.9507, 0.9657, 0.9799, 0.9484, 0.9752, 0.9727, 0.9715, 0.9593,\n                      0.9408, 0.9555, 0.9812, 0.9544, 0.9627, 0.9817, 0.9610, 0.9597, 0.9737,\n                      0.9680, 0.9588, 0.9682, 0.9636, 0.9483, 0.9568, 0.9483, 0.9734, 0.9330,\n                      0.9484, 0.9605, 0.9615, 0.9313, 0.9628, 0.9450, 0.9455, 0.9838, 0.9681,\n                      0.9748, 0.9480, 0.9543, 0.9572, 0.9508, 0.9481, 0.9556, 0.9635, 0.9715,\n                      0.9456], dtype=torch.float64)),\n             ('6.14.convpath.0.1.1.bias',\n              tensor([-6.7622e-03, -6.6768e-03,  1.4336e-02, -2.0384e-03, -1.9962e-03,\n                      -1.9036e-02, -4.1224e-04,  4.3166e-03,  1.1551e-02,  1.2141e-02,\n                       1.3844e-02, -1.1620e-02, -2.3727e-03,  1.0230e-02, -1.4533e-02,\n                      -6.0496e-03,  2.7096e-03,  2.5620e-04,  2.4661e-03, -1.7885e-03,\n                      -6.3180e-03, -2.3844e-03,  6.6566e-03, -1.2616e-02,  1.7306e-03,\n                      -2.3083e-03,  1.5006e-02, -8.1094e-03, -1.4035e-02, -6.7148e-04,\n                      -1.0172e-02, -1.9230e-03, -1.5971e-03, -3.3683e-03, -1.2528e-02,\n                       2.6604e-02,  6.1867e-03, -1.7183e-02,  9.1226e-03,  2.6066e-03,\n                      -4.0264e-02, -2.2759e-02, -9.1506e-03,  1.8505e-02, -2.4043e-03,\n                      -8.5184e-03, -8.6515e-03,  1.6169e-02, -2.6693e-02, -6.8134e-05,\n                       3.5488e-03, -4.8545e-03, -7.9838e-03,  2.5749e-03,  4.9354e-03,\n                       2.1841e-03,  3.3992e-03, -4.5390e-03, -1.2006e-02,  8.6400e-03,\n                      -9.1348e-04, -4.6363e-04, -5.5802e-03, -2.2655e-02],\n                     dtype=torch.float64)),\n             ('6.14.convpath.0.1.1.running_mean',\n              tensor([ 2.1063e-01, -2.1963e-01,  2.9270e-01, -6.6521e-01, -6.5460e-01,\n                      -1.7141e-01, -3.9080e-01, -3.6882e-01,  1.6433e-01, -5.3185e-01,\n                      -3.2825e-01, -5.7722e-01,  9.5513e-02, -8.1703e-02, -8.0854e-01,\n                      -9.2183e-01, -1.0972e-01,  1.0362e+00, -8.0875e-01,  4.9838e-01,\n                      -3.1681e-01,  2.8013e-01,  1.7551e-01,  3.7642e-01, -7.6371e-01,\n                      -6.6375e-02,  1.9549e-01,  3.7953e-01, -1.0003e-01,  5.0503e-01,\n                       5.6529e-01,  4.9146e-01,  7.4374e-01, -3.5891e-01, -4.1658e-01,\n                      -2.9461e-01, -3.1656e-01,  5.1993e-01,  4.5903e-01,  9.1721e-01,\n                       7.4038e-01,  3.5792e-01,  1.7909e-01, -7.2803e-01, -6.5921e-01,\n                      -4.2045e-02,  5.5385e-01, -9.6556e-01,  1.9092e-01,  2.0352e-02,\n                       2.8835e-01, -2.1176e-01, -7.5625e-01,  4.1450e-01,  6.4818e-01,\n                      -2.6404e-01,  9.9570e-02,  2.7974e-01, -6.7690e-01, -3.7404e-02,\n                       1.9910e-01, -5.8474e-01,  9.5688e-04, -4.9329e-01],\n                     dtype=torch.float64)),\n             ('6.14.convpath.0.1.1.running_var',\n              tensor([0.4177, 0.4526, 0.3627, 0.5962, 0.6910, 0.3260, 0.4654, 0.4809, 0.5906,\n                      0.9024, 0.3876, 0.5065, 0.4418, 0.6332, 0.4221, 0.3128, 0.6325, 0.4747,\n                      0.3829, 0.5612, 0.4202, 0.3599, 0.4299, 0.3656, 0.4964, 0.8745, 0.4172,\n                      0.5539, 0.3451, 0.4637, 0.6000, 0.5498, 0.6517, 0.3863, 0.6199, 0.5757,\n                      0.4259, 1.6924, 0.3543, 0.4730, 0.6826, 0.5410, 0.6369, 0.4739, 0.3790,\n                      0.4693, 0.4901, 0.3365, 0.6446, 0.5219, 0.4454, 0.5427, 0.4177, 0.4721,\n                      0.4679, 0.6169, 0.6664, 0.3397, 0.5956, 0.3822, 1.1353, 0.6155, 0.2851,\n                      0.4379], dtype=torch.float64)),\n             ('6.14.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.14.convpath.0.2.0.weight',\n              tensor([[[-0.1885],\n                       [ 0.0270],\n                       [ 0.2305],\n                       ...,\n                       [-0.1859],\n                       [-0.0906],\n                       [ 0.0640]],\n              \n                      [[-0.0146],\n                       [-0.1211],\n                       [ 0.0129],\n                       ...,\n                       [-0.0304],\n                       [ 0.0527],\n                       [-0.0866]],\n              \n                      [[-0.0934],\n                       [ 0.0120],\n                       [ 0.1071],\n                       ...,\n                       [-0.0665],\n                       [ 0.0911],\n                       [ 0.0802]],\n              \n                      ...,\n              \n                      [[-0.0100],\n                       [-0.2365],\n                       [-0.0050],\n                       ...,\n                       [-0.0709],\n                       [ 0.2043],\n                       [-0.0051]],\n              \n                      [[-0.1404],\n                       [-0.1385],\n                       [ 0.1909],\n                       ...,\n                       [ 0.1743],\n                       [-0.1109],\n                       [-0.1718]],\n              \n                      [[ 0.2084],\n                       [-0.1079],\n                       [-0.0063],\n                       ...,\n                       [ 0.0191],\n                       [ 0.1082],\n                       [-0.0130]]], dtype=torch.float64)),\n             ('6.14.convpath.0.2.1.weight',\n              tensor([ 1.5736e-02, -7.2876e-03, -3.4539e-03,  7.4461e-03, -7.2907e-03,\n                       2.1321e-02,  1.5802e-02, -1.6684e-03,  2.2476e-02,  7.5699e-03,\n                      -1.2772e-02, -2.3367e-02,  2.1775e-02, -3.0274e-03,  2.0812e-03,\n                      -3.9827e-02,  1.0222e-02,  1.7974e-02, -2.8318e-02,  5.3611e-03,\n                      -1.4073e-02,  4.9689e-04,  1.3865e-02,  3.4198e-03, -1.9289e-02,\n                       4.3788e-03,  1.5074e-02, -8.6650e-04, -7.5729e-03,  4.1597e-03,\n                       1.8546e-02,  2.6312e-02,  8.4122e-03, -1.2805e-02,  2.3715e-03,\n                       2.2518e-02,  1.6254e-02,  1.8126e-03, -9.4583e-03,  2.7529e-02,\n                       2.1536e-02, -2.7798e-03,  6.9601e-03,  2.6775e-02, -1.0081e-02,\n                      -9.4782e-03,  2.9958e-02,  1.2145e-02, -1.7918e-02,  1.4826e-03,\n                       3.8331e-02, -1.7387e-02, -2.7409e-03,  9.5228e-03, -7.2281e-03,\n                       2.1282e-02, -6.6992e-03, -2.1436e-02,  1.6560e-02, -9.9812e-03,\n                      -6.4283e-03, -1.7930e-02,  8.5809e-06,  3.0234e-03,  3.3746e-02,\n                      -3.1131e-02, -1.2737e-02,  1.6249e-02, -1.7992e-02, -6.7936e-04,\n                       5.2887e-03,  1.7849e-02, -5.3674e-03,  2.5484e-02, -1.9273e-02,\n                       6.9146e-03,  5.3136e-03,  3.6484e-03,  2.0866e-02, -9.0841e-03,\n                      -7.9872e-03,  2.5644e-02,  3.5399e-02, -1.2316e-02,  1.7186e-02,\n                      -3.0739e-03,  2.9126e-02,  3.1144e-03,  7.7750e-03,  1.1417e-02,\n                      -1.1424e-02,  8.1994e-03, -6.1575e-05, -1.0525e-02,  4.2314e-03,\n                      -4.0809e-03,  1.0297e-02, -1.2589e-03,  1.9965e-02,  2.1586e-02,\n                      -2.9409e-03, -7.9447e-03,  1.6797e-02, -1.2828e-02, -1.6365e-02,\n                      -2.4021e-02, -3.3813e-02, -1.0140e-02, -1.3431e-02, -6.6214e-04,\n                       8.8033e-03, -2.2674e-03,  6.8517e-03, -2.1693e-02, -9.7868e-03,\n                       1.4110e-02,  1.3607e-02,  2.0425e-02, -2.1966e-02,  1.1143e-02,\n                       1.4850e-02,  1.1744e-02,  3.7157e-03,  2.5422e-02,  5.4570e-03,\n                      -2.3700e-03, -1.8784e-02, -1.7062e-02, -1.2266e-02,  1.4217e-02,\n                       6.8295e-03,  6.8180e-03, -1.3141e-02,  9.4746e-03, -9.8198e-03,\n                       9.8451e-03,  7.6225e-03, -7.9840e-04,  6.0248e-03, -1.2513e-02,\n                      -4.5429e-03,  1.9239e-03, -2.4311e-02,  5.9705e-03,  2.2080e-02,\n                       2.4998e-02,  1.4509e-02, -9.4550e-03,  3.1931e-02,  1.7518e-02,\n                       2.3306e-03, -3.3995e-02,  1.5254e-02,  2.3105e-02, -1.6452e-02,\n                       1.1688e-02, -1.0264e-02,  1.1572e-02, -2.1778e-02, -1.6071e-04,\n                      -1.4199e-02, -6.9624e-03, -1.3369e-02,  1.0611e-02, -3.2145e-02,\n                      -4.6487e-03,  1.1036e-02,  3.0410e-03,  4.7614e-03, -1.4272e-02,\n                      -3.7738e-02,  2.9097e-03,  2.1413e-02, -2.5720e-03, -9.5727e-03,\n                      -1.5675e-02, -2.1848e-02,  3.1626e-03,  3.4785e-02, -1.8398e-02,\n                      -3.2209e-02, -7.6526e-03, -2.0189e-02,  2.0382e-02, -1.6469e-02,\n                      -2.0120e-02, -6.0278e-04, -1.6347e-02, -1.2308e-02, -1.3368e-02,\n                       3.0702e-03,  6.7696e-03,  1.3789e-02,  7.5802e-03,  4.4226e-03,\n                       1.7069e-02,  5.1781e-03, -7.5791e-03, -2.8421e-02,  2.6106e-02,\n                      -2.1857e-02, -3.6030e-02, -4.0933e-03,  1.5411e-02,  3.3685e-02,\n                       1.0099e-02,  1.0357e-02, -6.4655e-03, -1.5033e-02, -3.0701e-03,\n                       4.3711e-03, -2.1394e-02,  1.1476e-02, -1.3979e-03,  1.2544e-02,\n                       1.3505e-03, -2.9370e-02, -6.9009e-03,  2.7346e-02,  1.4169e-03,\n                      -4.2313e-04,  3.2365e-03,  2.7603e-02, -1.4010e-02,  2.6882e-02,\n                      -3.7576e-03, -5.2766e-03, -9.5697e-03, -5.0745e-03, -1.4550e-02,\n                      -2.6532e-02, -2.4705e-02,  4.0987e-03,  3.1217e-02, -1.4942e-02,\n                      -7.1709e-03, -2.2050e-02, -4.2713e-03,  9.8033e-03, -1.9234e-02,\n                      -7.4559e-03, -1.4143e-02, -3.5966e-03, -9.9090e-03, -7.8588e-03,\n                       1.7008e-03, -2.7607e-03,  2.8645e-02,  4.9021e-03, -2.2649e-02,\n                      -1.9762e-03,  2.4631e-03, -2.3914e-02,  5.2466e-03,  1.7005e-02,\n                       1.8338e-02], dtype=torch.float64)),\n             ('6.14.convpath.0.2.1.bias',\n              tensor([ 5.8337e-04,  8.7161e-03,  9.7822e-03,  1.4136e-02,  3.7749e-03,\n                       9.4440e-03,  6.9385e-03, -2.0490e-03,  1.3700e-02,  1.5831e-02,\n                       1.2665e-02, -6.8320e-03,  3.3390e-03, -5.0369e-03,  8.7464e-03,\n                       3.8034e-03,  2.5515e-02,  6.2206e-04,  9.5942e-03, -3.3557e-03,\n                      -6.7202e-03,  1.6262e-04,  5.0797e-03,  5.9981e-03,  7.7227e-03,\n                      -1.7456e-02,  1.3811e-03,  1.1715e-02,  9.7634e-03, -9.4234e-03,\n                      -2.5349e-03,  7.7975e-03, -1.6893e-03,  2.1533e-02,  3.4766e-03,\n                       1.5701e-02, -2.4168e-03,  1.5000e-02,  1.1390e-02,  1.1915e-02,\n                       1.8040e-03,  1.2340e-02, -1.0227e-02, -1.4714e-03,  6.8795e-03,\n                      -1.4375e-02,  1.4249e-02,  3.1333e-03, -1.3396e-02,  1.6570e-03,\n                       9.8685e-03,  3.8613e-03,  7.1221e-03,  1.7412e-02,  2.9498e-03,\n                       1.5352e-02,  9.4217e-03,  1.1719e-03,  1.2148e-02, -1.8754e-03,\n                       4.1562e-03, -2.5491e-03,  5.6550e-03,  8.8902e-03, -5.8815e-03,\n                       4.8627e-03, -1.0043e-02,  1.4669e-02,  1.3239e-02, -1.5225e-02,\n                       7.4269e-03,  3.0531e-03, -5.4918e-04, -8.1785e-03,  1.4100e-02,\n                       5.6879e-03, -1.5054e-04, -2.8871e-03,  2.1115e-03,  1.9573e-02,\n                       4.9192e-03, -9.7291e-03,  8.5289e-03,  4.1062e-03, -5.3416e-03,\n                       1.6770e-02,  8.9935e-04,  1.1899e-02,  1.4619e-02,  1.0834e-04,\n                       5.2395e-04,  1.0381e-02,  9.7955e-03, -8.5737e-05,  9.6237e-03,\n                      -8.5457e-03,  1.1372e-02,  4.9466e-03,  2.0507e-02,  8.5325e-03,\n                       2.2761e-02,  1.4413e-02,  4.6015e-03,  8.8327e-03,  1.6484e-03,\n                       2.6931e-03, -8.0282e-03,  8.6644e-03,  7.8472e-03,  4.6853e-03,\n                      -1.2644e-02, -9.6816e-03,  2.9948e-03,  2.0802e-02,  1.5601e-02,\n                       5.9147e-03,  5.1458e-03,  3.9814e-03,  5.4950e-03, -1.2381e-02,\n                       5.6668e-04,  1.1955e-02,  4.0694e-03,  5.7698e-04,  2.1172e-02,\n                       9.4442e-03,  6.8089e-03,  3.9312e-03,  8.8342e-03,  1.2765e-02,\n                       6.5112e-03,  5.3796e-03,  1.3433e-02,  5.1025e-03,  7.8809e-03,\n                      -1.4009e-02,  1.4142e-02,  3.3423e-03,  6.3470e-03, -1.4682e-03,\n                       1.3080e-02,  5.4408e-03,  1.6634e-02,  2.3801e-03, -7.3193e-03,\n                       1.2420e-02,  5.1028e-03, -1.0865e-04,  1.2648e-02,  8.4206e-03,\n                       7.8787e-03,  1.0547e-02,  5.6378e-03,  1.1991e-02,  1.2066e-02,\n                       3.8934e-03, -4.7506e-04,  9.3844e-03, -1.1138e-03, -1.0792e-02,\n                       5.2280e-03,  1.6871e-03, -3.5828e-03,  6.0369e-03,  1.2640e-02,\n                      -3.7089e-03, -1.3168e-02,  6.5984e-03,  6.6375e-03,  2.0516e-02,\n                       1.1960e-03, -1.4555e-04,  5.8167e-03,  1.4624e-02, -1.3613e-02,\n                       1.1293e-02,  3.2295e-03,  1.8230e-02,  1.6713e-03,  8.2045e-03,\n                      -3.3450e-04,  1.1495e-02, -6.2043e-03, -9.0849e-03,  1.2302e-02,\n                       8.0910e-03,  1.3837e-02,  1.0073e-02,  8.9927e-03,  8.0492e-03,\n                       6.4389e-03,  7.2144e-03,  6.1394e-03,  4.4872e-03, -1.7703e-03,\n                       1.0190e-02,  7.4669e-03,  2.2370e-03,  5.1278e-03,  1.1924e-02,\n                      -1.2104e-03,  2.3817e-02,  1.8197e-02,  1.8632e-02,  1.3702e-02,\n                      -1.2401e-03,  8.7114e-03, -1.0098e-02,  5.9039e-03,  1.3382e-02,\n                       4.3429e-03,  1.0475e-02,  3.8276e-03,  7.8336e-03,  7.9269e-03,\n                       3.9322e-03,  6.3476e-03,  1.6844e-02,  4.5460e-03,  4.3071e-03,\n                       1.5390e-02,  1.3315e-03,  2.0788e-03,  1.4203e-02,  2.2957e-03,\n                       6.7605e-03, -8.9227e-03, -2.0635e-03,  2.8109e-02,  1.7326e-02,\n                       2.8677e-03, -3.4123e-03,  9.7750e-03,  1.1292e-02,  2.0729e-03,\n                       9.3608e-03,  2.9421e-03,  1.3558e-02,  5.4997e-03,  7.3573e-03,\n                       2.0913e-03, -1.1360e-04, -2.1136e-03,  1.1646e-02,  2.4487e-03,\n                       7.4126e-03,  5.5638e-03,  4.9860e-03, -1.3606e-02, -1.1076e-02,\n                       2.1211e-02,  2.3833e-02,  1.8569e-02,  1.7618e-02,  2.3303e-03,\n                       3.9070e-03], dtype=torch.float64)),\n             ('6.14.convpath.0.2.1.running_mean',\n              tensor([ 5.0026e-01,  9.3141e-02, -2.1251e-01,  7.3323e-01, -1.8499e-01,\n                      -4.0980e-01,  1.2514e-01, -1.4934e-01,  1.9726e-01,  1.0485e-01,\n                       2.5828e-01, -7.3974e-02, -2.1603e-01, -1.3170e-01, -3.0867e-01,\n                       4.3427e-01,  2.8073e-01,  1.5739e-01,  4.8902e-01, -2.1588e-01,\n                       8.9053e-02, -5.7797e-01,  7.6504e-01, -3.5310e-02,  6.9145e-01,\n                       4.4874e-01,  1.3136e-01,  7.8434e-02,  5.1857e-01, -1.8248e-01,\n                       3.4175e-01,  2.8422e-01,  1.8412e-02, -1.6209e-01, -4.4365e-01,\n                       8.4120e-02, -3.8192e-01, -1.6505e-01, -4.2522e-02,  1.7304e-01,\n                      -7.4047e-01, -1.6742e-01, -1.1923e-01, -5.9140e-01, -1.1016e+00,\n                       4.9109e-01,  5.0325e-01, -1.2081e-02,  2.4890e-01,  7.0643e-02,\n                       2.4532e-01, -8.6393e-02,  9.8280e-02, -2.6729e-01, -2.1211e-01,\n                       3.5975e-01,  8.5683e-02,  4.3402e-01,  2.8010e-01, -2.9853e-01,\n                       6.1529e-02, -9.9139e-02,  1.0229e-01,  3.1469e-01, -5.2147e-01,\n                      -6.9906e-03, -1.9800e-01,  7.6698e-02,  6.1234e-02, -1.2762e+00,\n                      -1.9253e-01, -4.1760e-01, -1.3152e-01, -4.3664e-01,  7.6436e-01,\n                       3.4946e-01, -4.4820e-01,  4.7770e-01,  2.0864e-02,  4.7338e-02,\n                       2.9022e-01, -2.2126e-01, -4.7634e-01,  1.5849e-01,  1.0436e-01,\n                      -8.9968e-02,  4.5607e-02,  2.8470e-01, -1.7707e-01, -1.2997e-01,\n                      -1.0082e+00,  2.5810e-01,  2.5660e-01,  2.5079e-01, -2.5922e-01,\n                      -1.2112e-01, -4.0944e-01, -1.3710e-01,  1.6557e-01, -4.5737e-01,\n                      -6.8667e-01, -4.4445e-01,  1.4642e-01,  2.1788e-01, -1.4625e-01,\n                      -3.7751e-01, -4.6903e-01,  5.5947e-02,  3.8867e-01, -1.6644e-01,\n                       1.4560e-01, -2.4786e-01,  1.0550e-01,  3.7704e-01, -4.2315e-01,\n                      -5.7592e-01, -7.8602e-01, -2.8560e-01,  8.0650e-01, -4.8573e-01,\n                       1.6206e-01, -2.9149e-01, -6.0742e-02,  4.8892e-01, -3.8435e-02,\n                       3.1146e-01, -3.5359e-01,  1.6058e-01,  3.4355e-01, -4.3201e-02,\n                       4.3305e-01,  3.2971e-01,  9.0624e-01,  3.6702e-01, -3.1481e-01,\n                       3.0116e-01, -8.4463e-03, -5.2434e-02, -3.1924e-01, -1.8818e-01,\n                      -1.3858e-02, -1.0314e-02, -9.2277e-01, -8.2794e-02, -7.0564e-02,\n                      -4.8139e-01,  2.4116e-01, -4.7562e-01,  1.7412e-01,  5.9401e-01,\n                       2.7586e-01, -2.6760e-02, -4.4510e-01, -4.8671e-01, -2.7432e-01,\n                      -2.1863e-01,  1.5691e-01, -2.3646e-01, -9.0933e-02, -3.8486e-01,\n                      -3.2732e-01,  4.2269e-01,  3.9178e-01,  5.2351e-02,  7.1855e-03,\n                       4.2797e-01, -1.2154e+00, -3.6851e-01, -5.9731e-02,  1.2184e-01,\n                       4.3613e-01,  5.0065e-01,  9.4921e-01, -7.7080e-01, -1.0948e-01,\n                      -3.6581e-01,  8.3944e-01,  3.3255e-01, -3.9562e-01, -5.1363e-01,\n                      -7.6535e-01, -2.2918e-01, -7.8139e-02,  1.6849e-01,  6.7955e-01,\n                       9.9292e-01,  4.4483e-01, -2.8233e-01,  3.2044e-01,  2.5445e-01,\n                      -2.1611e-01, -5.3334e-02,  8.7077e-01,  1.1670e-01,  2.2550e-01,\n                       9.0622e-02,  4.5673e-01,  1.8207e-01,  4.9145e-01,  2.3715e-01,\n                       4.5510e-01, -4.6668e-02,  1.5837e-01, -3.9190e-01,  1.7196e-01,\n                       8.7218e-01,  8.0817e-02, -2.9992e-01, -6.6255e-01,  5.9850e-02,\n                      -3.1378e-02, -7.1788e-01,  4.2144e-01,  4.7466e-01, -2.2126e-01,\n                       7.9035e-02,  1.4773e-02, -2.4681e-01, -2.1436e-02,  1.0557e-01,\n                       3.3052e-01, -2.9865e-01,  4.3637e-01, -4.8127e-01, -5.3196e-01,\n                      -1.0230e-01, -2.1043e-01,  4.1143e-02, -9.9736e-02, -2.4837e-01,\n                      -2.5516e-01,  2.7657e-01, -1.2699e-01,  1.7097e-01,  4.5303e-02,\n                      -7.3056e-01,  1.2212e-01, -5.1471e-02,  3.1733e-01, -2.7648e-02,\n                       1.9847e-01, -2.8087e-01,  1.3055e-01, -3.4334e-01, -7.2076e-04,\n                       2.7705e-01,  1.5380e-02,  5.0412e-01,  8.5264e-01,  1.5978e-01,\n                       2.0322e-01,  9.0154e-02,  3.0661e-01, -2.7637e-01,  1.2074e-03,\n                       2.6530e-01], dtype=torch.float64)),\n             ('6.14.convpath.0.2.1.running_var',\n              tensor([0.3715, 0.2850, 0.3478, 0.6129, 0.3449, 0.3169, 0.2080, 0.2719, 0.3345,\n                      0.3922, 0.2698, 0.4366, 0.1643, 0.2938, 0.4986, 0.4152, 0.4012, 0.3607,\n                      0.3374, 0.3843, 0.5034, 0.3836, 0.2638, 0.2955, 0.4505, 0.1834, 0.6964,\n                      0.0738, 0.1925, 0.4188, 0.3754, 0.2805, 0.2274, 0.3307, 0.0808, 0.3544,\n                      0.1543, 0.1195, 0.2069, 0.5901, 0.3454, 0.3223, 0.1130, 0.3981, 0.4202,\n                      0.3063, 0.3851, 0.3600, 0.6541, 0.2812, 0.3708, 0.3684, 0.2055, 0.2753,\n                      0.5789, 0.4541, 0.2016, 0.6917, 0.3962, 0.3877, 0.2105, 0.3840, 0.2467,\n                      0.0974, 0.3916, 0.4618, 0.3229, 0.3511, 0.2895, 0.5606, 0.3120, 0.2043,\n                      0.1807, 0.2994, 0.6415, 0.0809, 0.3251, 0.2179, 0.4529, 0.1188, 0.1767,\n                      0.5147, 0.4899, 0.4587, 0.3688, 0.2789, 0.2846, 0.3584, 0.5212, 0.1543,\n                      0.5261, 0.0725, 0.1197, 0.5237, 0.1523, 0.1955, 0.5306, 0.0943, 0.2411,\n                      0.3187, 0.3282, 0.3035, 0.3690, 0.1920, 0.1522, 0.3096, 0.5753, 0.3035,\n                      0.3711, 0.0669, 0.2502, 0.1947, 0.2682, 0.2303, 0.4490, 0.6046, 0.3999,\n                      0.2405, 0.5596, 0.5948, 0.3013, 0.3441, 0.2598, 0.3294, 0.1480, 0.4248,\n                      0.3442, 0.2619, 0.2029, 0.3976, 0.1121, 0.2037, 0.3916, 0.3200, 0.3491,\n                      0.1539, 0.2194, 0.1420, 0.1775, 0.2977, 0.2182, 0.2346, 0.3621, 0.1361,\n                      0.1920, 0.3043, 0.1175, 0.3965, 0.1517, 0.4139, 0.2431, 0.2734, 0.3780,\n                      0.4685, 0.4891, 0.5140, 0.3274, 0.2088, 0.2440, 0.1464, 0.3099, 0.1424,\n                      0.3065, 0.1068, 0.4195, 0.2866, 0.3903, 0.1936, 0.3266, 0.4546, 0.3739,\n                      0.0965, 0.4264, 0.2683, 0.3809, 0.5158, 0.3613, 0.1242, 0.4777, 0.2961,\n                      0.5248, 0.1413, 0.3295, 0.2300, 0.5278, 0.4805, 0.3406, 0.2826, 0.3727,\n                      0.2331, 0.2419, 0.3833, 0.4922, 0.3249, 0.3030, 0.2729, 0.3098, 0.3590,\n                      0.4502, 0.5565, 0.4356, 0.3420, 0.1291, 0.4557, 0.3998, 0.3618, 0.2300,\n                      0.0615, 0.3368, 0.4447, 0.0690, 0.4648, 0.3062, 0.2253, 0.1868, 0.1201,\n                      0.5601, 0.2608, 0.3905, 0.2948, 0.1460, 0.0878, 0.3208, 0.3119, 0.4130,\n                      0.2110, 0.2469, 0.1339, 0.2769, 0.7031, 0.5923, 0.4617, 0.1750, 0.2574,\n                      0.1978, 0.3139, 0.2984, 0.1729, 0.4170, 0.2989, 0.1676, 0.1521, 0.3499,\n                      0.2030, 0.3443, 0.1467, 0.1355, 0.3351, 0.3515, 0.4910, 0.2412, 0.4063,\n                      0.4572, 0.3446, 0.2855, 0.3754], dtype=torch.float64)),\n             ('6.14.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.15.convs.0.0.weight',\n              tensor([[[-0.0541],\n                       [-0.0288],\n                       [ 0.0700],\n                       ...,\n                       [-0.1937],\n                       [-0.0201],\n                       [-0.0638]],\n              \n                      [[-0.0419],\n                       [ 0.0127],\n                       [ 0.1278],\n                       ...,\n                       [-0.0330],\n                       [ 0.0121],\n                       [-0.1421]],\n              \n                      [[ 0.0452],\n                       [ 0.0520],\n                       [-0.0199],\n                       ...,\n                       [-0.0458],\n                       [-0.0698],\n                       [-0.1104]],\n              \n                      ...,\n              \n                      [[ 0.0225],\n                       [-0.1383],\n                       [-0.1002],\n                       ...,\n                       [-0.1351],\n                       [-0.0041],\n                       [ 0.0609]],\n              \n                      [[ 0.0742],\n                       [ 0.0229],\n                       [ 0.0301],\n                       ...,\n                       [-0.0782],\n                       [ 0.0675],\n                       [-0.0669]],\n              \n                      [[ 0.0992],\n                       [ 0.0533],\n                       [ 0.1041],\n                       ...,\n                       [ 0.0658],\n                       [ 0.0627],\n                       [ 0.0502]]], dtype=torch.float64)),\n             ('6.15.convs.0.1.weight',\n              tensor([0.9463, 0.9705, 0.9827, 0.9735, 0.9734, 0.9728, 0.9625, 0.9430, 0.9935,\n                      0.9951, 0.9725, 0.9666, 0.9745, 0.9771, 0.9533, 0.9805, 0.9636, 0.9474,\n                      0.9691, 0.9935, 0.9748, 0.9666, 1.0127, 0.9508, 0.9485, 0.9879, 0.9835,\n                      0.9156, 0.9648, 0.9741, 0.9820, 0.9494, 0.9557, 1.0001, 0.9531, 0.9736,\n                      0.9869, 0.9828, 0.9850, 0.9783, 0.9518, 0.9873, 0.9819, 0.9675, 0.9766,\n                      0.9632, 0.9973, 0.9751, 0.9473, 0.9826, 0.9513, 0.9514, 0.9841, 0.9834,\n                      0.9695, 0.9585, 0.9733, 0.9740, 0.9532, 0.9602, 0.9690, 0.9257, 0.9629,\n                      0.9733], dtype=torch.float64)),\n             ('6.15.convs.0.1.bias',\n              tensor([-2.1911e-02,  2.2383e-02,  5.1651e-03,  4.6313e-03,  6.6057e-03,\n                      -2.0082e-02, -1.1793e-02, -1.8412e-03,  1.6916e-02, -2.5712e-03,\n                       6.5386e-03,  1.1808e-02, -2.4849e-03, -6.6839e-03, -3.4937e-03,\n                       1.8632e-02,  6.6344e-03, -3.6308e-03, -1.3727e-03,  6.9857e-03,\n                       7.5670e-04, -3.2121e-03,  3.2562e-02, -2.6373e-03, -1.4681e-02,\n                       1.4497e-02, -5.8505e-03, -1.8250e-02,  4.7206e-03, -8.6974e-05,\n                      -1.2655e-02, -2.7792e-02, -1.1447e-02,  1.8565e-02, -1.0512e-02,\n                       1.0934e-02,  1.2045e-03,  1.5368e-02,  1.3512e-02,  2.0219e-02,\n                      -1.3205e-02, -9.7965e-03,  2.5704e-02,  1.3520e-02, -4.9599e-03,\n                       5.2376e-03,  2.1400e-02, -2.1097e-03, -6.7256e-03,  1.2010e-02,\n                      -1.4655e-02, -7.3916e-03,  1.4205e-02,  1.0389e-02, -6.4587e-03,\n                       5.1018e-03, -6.5240e-03, -1.3284e-02, -7.4626e-03, -1.3694e-02,\n                      -9.1392e-04, -2.2744e-02,  3.3859e-03,  2.5712e-05],\n                     dtype=torch.float64)),\n             ('6.15.convs.0.1.running_mean',\n              tensor([-0.3664, -0.6768, -0.8207, -0.3930, -0.3286,  0.9531, -1.3503, -0.2966,\n                      -0.1421,  0.4222,  0.1947,  0.4024, -0.3859,  0.9844, -0.4524, -0.2657,\n                       0.4571, -0.4074,  0.0493,  0.2227, -0.5151, -0.2222, -1.1664, -0.5592,\n                      -1.1289, -0.5731,  0.2532, -1.3125, -0.6064, -0.1724, -0.5534,  0.3572,\n                       0.0241,  0.4629, -0.3359, -0.1692,  0.5204, -0.4762,  0.1248,  0.1715,\n                      -0.4837, -0.1730, -0.5014, -0.2952, -0.4773,  0.9244,  0.2181, -0.2514,\n                      -0.7051, -0.5596,  0.6210, -1.0957, -0.1398, -0.7159,  0.4442,  0.0800,\n                      -0.7100,  0.2565,  0.3326,  0.3973,  0.2485, -0.1736,  0.8007,  0.5940],\n                     dtype=torch.float64)),\n             ('6.15.convs.0.1.running_var',\n              tensor([0.6134, 0.4527, 0.1750, 0.2008, 0.1813, 0.3022, 0.3942, 0.4855, 0.1967,\n                      0.1443, 0.1512, 0.1315, 0.2069, 0.7281, 0.3426, 0.3440, 0.5554, 0.5919,\n                      0.1539, 0.1948, 0.1116, 0.4094, 0.2235, 0.4364, 0.8588, 0.4760, 0.4412,\n                      0.7581, 0.1895, 0.1007, 0.1305, 0.1993, 0.1518, 0.1238, 0.4263, 0.1462,\n                      0.2099, 0.2160, 0.2551, 0.5796, 0.6776, 0.2586, 0.1278, 0.4879, 0.1715,\n                      1.1504, 0.2099, 0.2651, 0.4664, 0.1136, 0.1952, 0.4565, 0.1458, 0.3117,\n                      0.1826, 0.2265, 0.3653, 0.2073, 0.3343, 0.3065, 0.5733, 0.2401, 0.1906,\n                      0.1774], dtype=torch.float64)),\n             ('6.15.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.15.convs.1.0.weight',\n              tensor([[[ 0.0365, -0.0088, -0.1596,  0.0008, -0.0102],\n                       [-0.0652, -0.1257, -0.1465,  0.0406,  0.0022],\n                       [ 0.0661, -0.1009, -0.0582,  0.1363, -0.0557],\n                       ...,\n                       [ 0.0702, -0.0138,  0.1363,  0.0524, -0.0036],\n                       [ 0.0407, -0.0791, -0.0375, -0.1090,  0.0930],\n                       [ 0.0861,  0.0422,  0.0104,  0.1234, -0.0203]],\n              \n                      [[-0.0119,  0.0614,  0.0369, -0.0738,  0.0594],\n                       [ 0.0173, -0.1537,  0.0102, -0.0114, -0.0138],\n                       [ 0.0485, -0.0777,  0.0055, -0.1281, -0.0553],\n                       ...,\n                       [ 0.0245, -0.0312, -0.0310, -0.0294, -0.1041],\n                       [ 0.0184,  0.0267, -0.1629, -0.0523, -0.1395],\n                       [ 0.0182,  0.0307,  0.1425,  0.0949,  0.0388]],\n              \n                      [[-0.0205,  0.1368, -0.2226, -0.0908, -0.0523],\n                       [-0.0882,  0.0452, -0.0129, -0.1099, -0.1264],\n                       [-0.0164, -0.1916,  0.0304,  0.1287, -0.0046],\n                       ...,\n                       [ 0.0938,  0.0962,  0.0884,  0.0203, -0.0352],\n                       [-0.0056,  0.0036,  0.0159, -0.0188,  0.0613],\n                       [ 0.0737,  0.0036,  0.0486, -0.0992,  0.0282]],\n              \n                      ...,\n              \n                      [[-0.0712,  0.0641,  0.0567, -0.0712,  0.0029],\n                       [-0.1085, -0.0066,  0.0666, -0.0095, -0.0585],\n                       [ 0.0104, -0.0419, -0.0818, -0.0713, -0.0852],\n                       ...,\n                       [ 0.0641,  0.0020,  0.0349,  0.0906, -0.0563],\n                       [ 0.1625, -0.1216,  0.0388, -0.0475, -0.0682],\n                       [-0.0170, -0.0096, -0.0879,  0.1046,  0.0212]],\n              \n                      [[-0.0677, -0.0203,  0.0128, -0.0203, -0.0028],\n                       [ 0.0286, -0.0496, -0.0099,  0.0382, -0.0120],\n                       [-0.0052, -0.1719,  0.0473, -0.0082,  0.1848],\n                       ...,\n                       [ 0.0184, -0.0383, -0.0863, -0.0073, -0.0374],\n                       [-0.2072, -0.2095,  0.0337, -0.0184,  0.0535],\n                       [ 0.0658,  0.1133,  0.0735, -0.0796, -0.0046]],\n              \n                      [[-0.0344,  0.0512,  0.0384, -0.0591,  0.1539],\n                       [ 0.0795,  0.0118,  0.0088,  0.0292,  0.0554],\n                       [ 0.0160, -0.0637, -0.0667,  0.0548,  0.0072],\n                       ...,\n                       [ 0.0268,  0.0009,  0.1383,  0.1455, -0.0215],\n                       [ 0.0083,  0.0437,  0.0833,  0.1238,  0.1306],\n                       [ 0.0299,  0.0419, -0.1319, -0.0439, -0.1120]]], dtype=torch.float64)),\n             ('6.15.convs.1.1.weight',\n              tensor([0.9293, 0.9985, 0.9525, 0.9769, 0.9566, 0.9610, 0.9652, 0.9372, 0.9724,\n                      0.9845, 0.9571, 1.0179, 0.9806, 0.9775, 0.9529, 0.9436, 0.9670, 0.9697,\n                      0.9621, 0.9779, 0.9677, 0.9781, 0.9603, 0.8998, 0.9333, 0.9519, 0.9178,\n                      0.9528, 0.9570, 0.9582, 0.9627, 0.9513, 0.9925, 0.9657, 0.9548, 0.9501,\n                      0.9575, 0.9530, 0.9602, 0.9973, 0.9731, 0.9719, 0.9949, 0.9624, 0.9561,\n                      0.9645, 0.9727, 0.9714, 0.9595, 0.9599, 0.9526, 0.9489, 0.9593, 0.9786,\n                      0.9750, 0.9718, 0.9794, 0.9654, 0.9524, 0.9885, 1.0028, 1.0046, 0.9717,\n                      0.9736], dtype=torch.float64)),\n             ('6.15.convs.1.1.bias',\n              tensor([-0.0056, -0.0137, -0.0162, -0.0156,  0.0018, -0.0066, -0.0092, -0.0143,\n                       0.0084,  0.0077,  0.0018, -0.0311, -0.0056, -0.0167, -0.0356, -0.0016,\n                      -0.0016,  0.0144, -0.0267,  0.0193, -0.0125, -0.0004, -0.0091, -0.0364,\n                      -0.0158, -0.0052, -0.0180, -0.0223, -0.0190, -0.0251,  0.0003, -0.0091,\n                      -0.0283, -0.0065, -0.0084,  0.0037, -0.0008, -0.0073, -0.0030,  0.0245,\n                      -0.0058,  0.0051,  0.0126,  0.0042, -0.0203, -0.0140, -0.0095, -0.0211,\n                      -0.0095, -0.0175,  0.0018, -0.0202,  0.0109, -0.0067,  0.0025,  0.0030,\n                       0.0012,  0.0073, -0.0057, -0.0082, -0.0007,  0.0230, -0.0018, -0.0029],\n                     dtype=torch.float64)),\n             ('6.15.convs.1.1.running_mean',\n              tensor([-0.3485, -0.2754, -0.3150,  0.7041, -0.3306, -0.2593, -0.2418, -0.2294,\n                      -0.2694,  0.1487, -0.5379, -0.1990,  0.6688,  0.5622,  0.2482, -0.8124,\n                       0.1933, -0.8719,  0.3852, -0.1066, -0.7692, -0.1053,  0.1267, -0.6182,\n                      -0.4634, -0.6459, -0.5931, -0.9057, -0.2623, -0.0419, -0.7965, -1.1764,\n                       0.6690, -0.5609, -1.1999,  0.7370,  0.4391,  0.3725, -0.6687, -0.6831,\n                      -0.4745,  0.2714, -0.6251, -0.5994,  0.7184,  0.8468, -0.9091,  0.1424,\n                      -0.2948, -0.5900, -0.1343,  0.7723, -0.1976,  0.7360,  0.1816, -0.0813,\n                      -0.5161,  0.0181, -0.5071,  0.6816, -0.4056, -0.2278,  0.6237,  0.3408],\n                     dtype=torch.float64)),\n             ('6.15.convs.1.1.running_var',\n              tensor([0.5408, 0.4678, 0.3464, 0.4533, 0.5386, 0.4097, 0.3803, 1.0948, 0.6647,\n                      0.3112, 0.4504, 0.5255, 0.6277, 0.5079, 0.3101, 0.6061, 0.4881, 0.5388,\n                      0.7805, 0.5783, 0.5154, 0.3350, 0.4275, 0.5500, 0.5687, 0.6771, 0.5446,\n                      0.3741, 1.0552, 0.7730, 0.7270, 0.3843, 0.4254, 0.5863, 0.7281, 0.5104,\n                      0.4715, 0.6462, 0.5404, 0.3935, 0.5149, 0.4131, 0.3629, 0.5706, 0.5875,\n                      0.6909, 0.3766, 0.6369, 0.4133, 0.4357, 0.7915, 0.6372, 0.5983, 0.3493,\n                      0.5035, 0.3689, 0.4628, 0.5193, 0.5091, 0.5171, 0.5984, 0.4025, 0.5612,\n                      0.4365], dtype=torch.float64)),\n             ('6.15.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.15.convs.2.0.weight',\n              tensor([[[-0.0897],\n                       [-0.1421],\n                       [ 0.1287],\n                       ...,\n                       [-0.0959],\n                       [-0.1251],\n                       [-0.0776]],\n              \n                      [[-0.1253],\n                       [-0.3135],\n                       [-0.2487],\n                       ...,\n                       [ 0.1479],\n                       [ 0.0657],\n                       [ 0.0065]],\n              \n                      [[ 0.0369],\n                       [ 0.0230],\n                       [-0.0845],\n                       ...,\n                       [-0.0645],\n                       [-0.0878],\n                       [ 0.0084]],\n              \n                      ...,\n              \n                      [[-0.0673],\n                       [-0.2753],\n                       [-0.0797],\n                       ...,\n                       [-0.0663],\n                       [-0.1305],\n                       [ 0.0428]],\n              \n                      [[-0.0404],\n                       [ 0.0839],\n                       [-0.1159],\n                       ...,\n                       [-0.1294],\n                       [-0.1473],\n                       [-0.0257]],\n              \n                      [[ 0.1763],\n                       [-0.0708],\n                       [-0.0577],\n                       ...,\n                       [-0.1063],\n                       [-0.0006],\n                       [ 0.3006]]], dtype=torch.float64)),\n             ('6.15.convs.2.1.weight',\n              tensor([-0.0249,  0.0140, -0.0065,  0.0115,  0.0256, -0.0141, -0.0022, -0.0149,\n                       0.0270, -0.0325, -0.0224, -0.0188,  0.0037,  0.0032,  0.0046,  0.0106,\n                      -0.0319, -0.0150, -0.0239,  0.0130,  0.0007,  0.0354,  0.0016,  0.0135,\n                       0.0155,  0.0138, -0.0055,  0.0217,  0.0025,  0.0058, -0.0119,  0.0448,\n                       0.0142, -0.0015, -0.0243, -0.0055,  0.0140, -0.0039,  0.0188,  0.0153,\n                      -0.0169, -0.0318,  0.0164,  0.0158,  0.0029,  0.0058, -0.0263, -0.0170,\n                      -0.0227, -0.0005, -0.0022, -0.0131, -0.0243,  0.0169, -0.0191, -0.0075,\n                       0.0222,  0.0351,  0.0319, -0.0058,  0.0219,  0.0063,  0.0038,  0.0167,\n                      -0.0055, -0.0154, -0.0192,  0.0062,  0.0056, -0.0003,  0.0114,  0.0125,\n                       0.0135, -0.0228,  0.0080,  0.0320,  0.0063, -0.0154,  0.0096, -0.0113,\n                      -0.0092,  0.0029, -0.0295,  0.0043, -0.0276,  0.0096, -0.0223, -0.0308,\n                       0.0180, -0.0039, -0.0104,  0.0199, -0.0047, -0.0178,  0.0176, -0.0034,\n                      -0.0215,  0.0181, -0.0151,  0.0345, -0.0041,  0.0359,  0.0157, -0.0140,\n                       0.0125, -0.0121,  0.0002, -0.0089, -0.0094, -0.0208,  0.0080,  0.0037,\n                       0.0210,  0.0128, -0.0087, -0.0102,  0.0242,  0.0065,  0.0032, -0.0386,\n                      -0.0088, -0.0065,  0.0151, -0.0222, -0.0017, -0.0064,  0.0110, -0.0112,\n                       0.0063, -0.0271,  0.0086, -0.0020, -0.0129, -0.0010,  0.0140,  0.0120,\n                      -0.0174, -0.0088,  0.0145, -0.0205,  0.0046,  0.0001,  0.0071, -0.0042,\n                       0.0022,  0.0201,  0.0144,  0.0388, -0.0506,  0.0305,  0.0003, -0.0058,\n                      -0.0096, -0.0240,  0.0118,  0.0150, -0.0150, -0.0209, -0.0054, -0.0235,\n                      -0.0026,  0.0057,  0.0150,  0.0018,  0.0173,  0.0070, -0.0243, -0.0077,\n                      -0.0044, -0.0329,  0.0102,  0.0091,  0.0278, -0.0221, -0.0059,  0.0115,\n                       0.0090,  0.0031,  0.0034,  0.0159,  0.0082, -0.0019, -0.0132,  0.0138,\n                      -0.0231,  0.0018,  0.0130,  0.0088,  0.0016,  0.0075,  0.0292,  0.0051,\n                       0.0375, -0.0377, -0.0221,  0.0290, -0.0299, -0.0303,  0.0174,  0.0158,\n                      -0.0089,  0.0134,  0.0216, -0.0089, -0.0136,  0.0288, -0.0084, -0.0134,\n                      -0.0028, -0.0287, -0.0182,  0.0088, -0.0187, -0.0222, -0.0147,  0.0103,\n                      -0.0262,  0.0051,  0.0047, -0.0100, -0.0178, -0.0211,  0.0063,  0.0312,\n                       0.0265, -0.0155, -0.0080,  0.0046,  0.0303, -0.0058, -0.0230, -0.0090,\n                       0.0345,  0.0335, -0.0023,  0.0038,  0.0067, -0.0219, -0.0071,  0.0081,\n                      -0.0322,  0.0172, -0.0079,  0.0036,  0.0051, -0.0186, -0.0153, -0.0081,\n                       0.0013,  0.0095, -0.0081, -0.0126,  0.0202,  0.0238,  0.0236,  0.0189],\n                     dtype=torch.float64)),\n             ('6.15.convs.2.1.bias',\n              tensor([ 0.0008,  0.0093,  0.0093,  0.0141,  0.0030,  0.0087,  0.0060, -0.0031,\n                       0.0111,  0.0154,  0.0130, -0.0087,  0.0039, -0.0056,  0.0086,  0.0043,\n                       0.0255,  0.0006,  0.0120, -0.0029, -0.0110,  0.0014,  0.0086,  0.0058,\n                       0.0107, -0.0204,  0.0076,  0.0134,  0.0099, -0.0081, -0.0047,  0.0090,\n                      -0.0024,  0.0217,  0.0040,  0.0110, -0.0025,  0.0108,  0.0110,  0.0079,\n                       0.0024,  0.0121, -0.0141, -0.0031,  0.0070, -0.0152,  0.0169,  0.0016,\n                      -0.0139,  0.0004,  0.0121,  0.0038,  0.0048,  0.0183,  0.0018,  0.0130,\n                       0.0099,  0.0011,  0.0123, -0.0034,  0.0053, -0.0003,  0.0049,  0.0088,\n                      -0.0063,  0.0026, -0.0102,  0.0128,  0.0141, -0.0152,  0.0071, -0.0017,\n                      -0.0012, -0.0073,  0.0138,  0.0077, -0.0007,  0.0005,  0.0022,  0.0168,\n                       0.0048, -0.0086,  0.0113,  0.0034, -0.0030,  0.0167,  0.0007,  0.0127,\n                       0.0152, -0.0005,  0.0003,  0.0118,  0.0100, -0.0040,  0.0113, -0.0075,\n                       0.0116,  0.0063,  0.0205,  0.0099,  0.0230,  0.0145,  0.0037,  0.0075,\n                       0.0034,  0.0008, -0.0077,  0.0055,  0.0072,  0.0048, -0.0095, -0.0098,\n                       0.0025,  0.0235,  0.0156,  0.0061,  0.0052,  0.0052,  0.0055, -0.0040,\n                      -0.0002,  0.0121,  0.0052,  0.0037,  0.0215,  0.0091,  0.0066,  0.0043,\n                       0.0096,  0.0139,  0.0064,  0.0051,  0.0123,  0.0036,  0.0061, -0.0160,\n                       0.0132,  0.0035,  0.0059,  0.0033,  0.0136,  0.0075,  0.0166,  0.0022,\n                      -0.0055,  0.0105,  0.0042, -0.0026,  0.0128,  0.0069,  0.0078,  0.0112,\n                       0.0030,  0.0120,  0.0126,  0.0034,  0.0002,  0.0094, -0.0004, -0.0057,\n                       0.0051,  0.0118, -0.0029,  0.0061,  0.0117, -0.0042, -0.0164,  0.0060,\n                       0.0069,  0.0194, -0.0007, -0.0008,  0.0088,  0.0136, -0.0118,  0.0118,\n                       0.0005,  0.0184,  0.0054,  0.0087,  0.0005,  0.0110, -0.0035, -0.0095,\n                       0.0112,  0.0067,  0.0138,  0.0103,  0.0086,  0.0080,  0.0071,  0.0049,\n                       0.0052,  0.0049, -0.0004,  0.0111,  0.0096,  0.0021,  0.0058,  0.0216,\n                      -0.0007,  0.0236,  0.0181,  0.0164,  0.0169,  0.0032,  0.0085, -0.0135,\n                       0.0038,  0.0130,  0.0044,  0.0116,  0.0020,  0.0079,  0.0085,  0.0052,\n                       0.0073,  0.0164,  0.0027,  0.0030,  0.0157,  0.0002,  0.0046,  0.0144,\n                       0.0050,  0.0062, -0.0065, -0.0032,  0.0289,  0.0196,  0.0004,  0.0019,\n                       0.0091,  0.0115,  0.0016,  0.0093,  0.0019,  0.0123,  0.0051,  0.0098,\n                       0.0006, -0.0034, -0.0023,  0.0133,  0.0060,  0.0075,  0.0052,  0.0024,\n                      -0.0118, -0.0090,  0.0211,  0.0241,  0.0167,  0.0176,  0.0009,  0.0020],\n                     dtype=torch.float64)),\n             ('6.15.convs.2.1.running_mean',\n              tensor([ 1.0479e-01,  1.8677e-01, -3.5391e-01, -1.7504e-01, -6.7980e-01,\n                      -1.6289e-02,  2.5559e-01, -1.1582e-01, -1.2931e-02, -2.2876e-01,\n                       1.8573e-01, -1.0069e-01, -1.8811e-01,  8.6703e-04, -4.0426e-01,\n                      -1.3337e-01,  2.9601e-01, -5.1322e-01,  2.3288e-01, -1.9224e-01,\n                      -1.5222e-01, -6.3568e-02, -1.1412e-01, -4.3768e-01,  2.6221e-01,\n                      -1.7339e-01,  2.1424e-01,  3.5728e-01,  4.0704e-01,  1.9737e-01,\n                      -2.4685e-01,  8.9206e-02, -1.5409e-01, -1.6658e-01, -4.5586e-01,\n                      -1.2754e-01, -1.8894e-01,  1.5415e-01, -2.8832e-01,  8.3452e-02,\n                       2.9798e-01, -4.9729e-01, -2.2228e-01,  1.9003e-01,  2.1117e-03,\n                       6.8536e-01, -2.2233e-01, -2.2881e-01, -1.2354e-01, -2.3497e-01,\n                       5.9885e-02, -3.7618e-01,  2.6879e-01, -3.5419e-01,  2.7170e-01,\n                      -3.4546e-01, -9.3643e-01, -3.1858e-01,  1.9661e-01, -7.5543e-01,\n                      -5.0649e-01, -1.0024e-01, -1.2122e-02, -2.4440e-01, -3.8876e-01,\n                      -1.6764e-03, -6.4166e-01, -3.8463e-01,  3.6953e-01,  3.0495e-01,\n                       3.5121e-01, -1.4471e-01, -1.0449e-02, -6.8700e-01, -2.8979e-01,\n                      -4.8481e-01, -3.1703e-01,  5.2793e-01,  7.9635e-01, -2.1931e-01,\n                       3.9055e-01, -1.4431e-01,  9.5028e-01, -3.1821e-01, -2.5749e-01,\n                      -5.8180e-01,  5.4855e-01, -9.3870e-01,  3.8442e-01, -2.9656e-01,\n                      -6.9393e-01,  6.4734e-01, -3.1124e-01, -1.2238e-01, -3.8310e-01,\n                      -2.5708e-01,  1.7398e-01,  3.0630e-02, -7.3252e-01,  1.5129e-01,\n                       5.0478e-01, -8.0460e-02,  2.2963e-01,  7.1013e-02,  5.1687e-01,\n                      -2.7485e-01,  2.6014e-02, -4.2407e-01, -1.3121e-01, -2.7005e-01,\n                      -2.9262e-01,  7.4822e-02, -9.6785e-01,  4.5174e-01, -9.1099e-02,\n                       7.0045e-01, -4.8365e-01, -1.9028e-01, -1.7435e-01,  6.0641e-01,\n                      -1.3054e-01,  7.0349e-01,  6.2479e-02, -4.5685e-01,  3.0731e-01,\n                      -2.2747e-01,  1.1041e-01, -3.2144e-03, -1.8292e-01,  6.9356e-01,\n                       2.0157e-01,  8.7339e-02, -4.4246e-01, -2.3561e-01, -4.6846e-01,\n                      -1.0735e-01, -2.7825e-01,  1.1165e-02,  2.7746e-01, -7.2893e-01,\n                      -1.7397e-02,  4.8868e-01,  6.2146e-02,  1.4681e-01,  8.7959e-03,\n                      -7.0782e-01, -2.0533e-01,  4.4275e-01, -3.5407e-01,  1.3771e-01,\n                       1.9552e-01,  1.1500e-02, -3.2183e-01,  7.1869e-01,  2.0491e-02,\n                      -3.1756e-01,  6.3591e-01,  1.0389e-01,  8.8295e-02, -2.1867e-01,\n                      -5.8845e-01, -1.4317e-01, -6.5038e-02,  2.9326e-02, -5.1279e-01,\n                       5.4331e-01,  5.1955e-01, -2.2634e-02, -4.6085e-02,  2.0497e-01,\n                       2.2110e-01, -1.2189e-01,  2.1803e-01,  3.4218e-02, -2.7513e-01,\n                       1.5140e-01,  4.1626e-02,  1.1159e-01,  3.2007e-01, -5.2300e-01,\n                       2.4906e-01, -5.9964e-01,  3.9300e-01,  5.1744e-01,  5.7434e-01,\n                      -1.7518e-01, -2.8018e-01, -3.4586e-01,  2.0095e-02,  2.0409e-02,\n                       2.3337e-01, -1.8359e-01,  1.7274e-01, -7.7483e-01, -7.7451e-02,\n                       3.2532e-01, -8.2276e-01, -6.1814e-02, -4.9117e-02, -6.3873e-01,\n                      -2.1534e-01,  3.2278e-02, -4.7700e-01,  3.8683e-01, -6.6096e-02,\n                       1.9187e-01,  2.9021e-01,  1.0910e-02, -7.2273e-02,  5.3995e-01,\n                      -1.1949e-01, -7.4782e-01,  3.5793e-02,  4.3922e-01, -5.0333e-01,\n                      -2.0267e-01,  9.5468e-02, -4.5315e-03, -5.3939e-01, -3.2830e-01,\n                      -8.3010e-01, -4.8634e-01,  1.8608e-02,  1.7785e-01, -4.8933e-01,\n                       2.8294e-01, -9.9302e-02,  1.1578e-01, -5.2607e-01, -7.7552e-01,\n                       1.6543e-01, -1.7001e-01, -4.1742e-01,  4.8436e-01, -2.3778e-01,\n                       3.1478e-01,  2.0144e-01,  2.1662e-01, -9.1818e-01, -6.9275e-02,\n                       2.2825e-01, -1.1320e-01,  2.6199e-01, -1.6639e-02, -3.1166e-02,\n                      -1.4135e-01, -2.1073e-01, -4.1948e-01,  2.0640e-01, -4.4599e-01,\n                       9.0185e-01,  5.9018e-01, -2.7295e-01, -1.9527e-01, -4.0795e-01,\n                       1.8765e-01], dtype=torch.float64)),\n             ('6.15.convs.2.1.running_var',\n              tensor([0.3135, 0.3781, 0.1736, 0.3603, 0.4590, 0.5072, 0.1257, 0.4336, 0.2330,\n                      0.4114, 0.2835, 0.4340, 0.0949, 0.1575, 0.3950, 0.2456, 0.2902, 0.3000,\n                      0.2790, 0.4455, 0.1980, 0.5252, 0.3532, 0.3930, 0.4254, 0.2121, 0.3774,\n                      0.3274, 0.2840, 0.3836, 0.7551, 0.3911, 0.1550, 0.3059, 0.5672, 0.3948,\n                      0.3652, 0.2074, 0.4422, 0.3415, 0.2113, 0.3504, 0.3131, 0.4447, 0.3633,\n                      0.3820, 0.4223, 0.3368, 0.5318, 0.4337, 0.1178, 0.3670, 0.3754, 0.4140,\n                      0.3801, 0.3197, 0.5504, 0.4567, 0.4693, 0.2123, 0.3096, 0.2895, 0.2178,\n                      0.3126, 0.3632, 0.2206, 0.4002, 0.1966, 0.1738, 0.4091, 0.2828, 0.3404,\n                      0.2327, 0.6510, 0.2811, 0.2819, 0.2291, 0.4534, 0.4709, 0.1609, 0.3142,\n                      0.2755, 0.3894, 0.5698, 0.3086, 0.3690, 0.6925, 0.4212, 0.3391, 0.2701,\n                      0.5574, 0.2751, 0.2864, 0.4911, 0.2465, 0.2322, 0.5320, 0.2430, 0.4115,\n                      0.2584, 0.2798, 0.4306, 0.3511, 0.2572, 0.3124, 0.2414, 0.3444, 0.6826,\n                      0.4306, 0.3720, 0.2076, 0.3348, 0.6123, 0.3995, 0.2375, 0.4530, 0.3811,\n                      0.1410, 0.1294, 0.3727, 0.1302, 0.3509, 0.3208, 0.3497, 0.0804, 0.2702,\n                      0.2695, 0.5138, 0.1046, 0.4247, 0.1918, 0.3231, 0.5364, 0.1916, 0.1685,\n                      0.1591, 0.1758, 0.3813, 0.4704, 0.4362, 0.1025, 0.2494, 0.4240, 0.1669,\n                      0.1152, 0.3842, 0.2001, 0.4396, 0.3914, 0.3538, 0.2552, 0.3404, 0.5096,\n                      0.7207, 0.4262, 0.2094, 0.2314, 0.2303, 0.3435, 0.3477, 0.1860, 0.1319,\n                      0.3631, 0.4989, 0.6070, 0.3542, 0.3878, 0.0841, 0.4020, 0.5578, 0.2265,\n                      0.1435, 0.4680, 0.3120, 0.4217, 0.3852, 0.2484, 0.1407, 0.3949, 0.5614,\n                      0.2795, 0.2495, 0.5103, 0.3847, 0.3899, 0.2983, 0.3305, 0.2930, 0.1935,\n                      0.3251, 0.5286, 0.3981, 0.3502, 0.2924, 0.3298, 0.3093, 0.2672, 0.3031,\n                      0.3339, 0.4020, 0.3489, 0.3213, 0.3566, 0.3139, 0.6308, 0.6544, 0.1406,\n                      0.1098, 0.1602, 0.3394, 0.1359, 0.3483, 0.2814, 0.2717, 0.2663, 0.2063,\n                      0.3771, 0.0309, 0.1363, 0.4361, 0.3120, 0.3508, 0.1236, 0.3520, 0.6128,\n                      0.4074, 0.1826, 0.1285, 0.5723, 0.3298, 0.1600, 0.2964, 0.4572, 0.3846,\n                      0.2573, 0.2025, 0.3171, 0.1765, 0.5909, 0.2828, 0.4280, 0.1850, 0.7586,\n                      0.1593, 0.1209, 0.3152, 0.2796, 0.4446, 0.1909, 0.3149, 0.4554, 0.6545,\n                      0.4658, 0.2942, 0.3452, 0.3046], dtype=torch.float64)),\n             ('6.15.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.15.convpath.0.0.0.weight',\n              tensor([[[-0.0541],\n                       [-0.0288],\n                       [ 0.0700],\n                       ...,\n                       [-0.1937],\n                       [-0.0201],\n                       [-0.0638]],\n              \n                      [[-0.0419],\n                       [ 0.0127],\n                       [ 0.1278],\n                       ...,\n                       [-0.0330],\n                       [ 0.0121],\n                       [-0.1421]],\n              \n                      [[ 0.0452],\n                       [ 0.0520],\n                       [-0.0199],\n                       ...,\n                       [-0.0458],\n                       [-0.0698],\n                       [-0.1104]],\n              \n                      ...,\n              \n                      [[ 0.0225],\n                       [-0.1383],\n                       [-0.1002],\n                       ...,\n                       [-0.1351],\n                       [-0.0041],\n                       [ 0.0609]],\n              \n                      [[ 0.0742],\n                       [ 0.0229],\n                       [ 0.0301],\n                       ...,\n                       [-0.0782],\n                       [ 0.0675],\n                       [-0.0669]],\n              \n                      [[ 0.0992],\n                       [ 0.0533],\n                       [ 0.1041],\n                       ...,\n                       [ 0.0658],\n                       [ 0.0627],\n                       [ 0.0502]]], dtype=torch.float64)),\n             ('6.15.convpath.0.0.1.weight',\n              tensor([0.9463, 0.9705, 0.9827, 0.9735, 0.9734, 0.9728, 0.9625, 0.9430, 0.9935,\n                      0.9951, 0.9725, 0.9666, 0.9745, 0.9771, 0.9533, 0.9805, 0.9636, 0.9474,\n                      0.9691, 0.9935, 0.9748, 0.9666, 1.0127, 0.9508, 0.9485, 0.9879, 0.9835,\n                      0.9156, 0.9648, 0.9741, 0.9820, 0.9494, 0.9557, 1.0001, 0.9531, 0.9736,\n                      0.9869, 0.9828, 0.9850, 0.9783, 0.9518, 0.9873, 0.9819, 0.9675, 0.9766,\n                      0.9632, 0.9973, 0.9751, 0.9473, 0.9826, 0.9513, 0.9514, 0.9841, 0.9834,\n                      0.9695, 0.9585, 0.9733, 0.9740, 0.9532, 0.9602, 0.9690, 0.9257, 0.9629,\n                      0.9733], dtype=torch.float64)),\n             ('6.15.convpath.0.0.1.bias',\n              tensor([-2.1911e-02,  2.2383e-02,  5.1651e-03,  4.6313e-03,  6.6057e-03,\n                      -2.0082e-02, -1.1793e-02, -1.8412e-03,  1.6916e-02, -2.5712e-03,\n                       6.5386e-03,  1.1808e-02, -2.4849e-03, -6.6839e-03, -3.4937e-03,\n                       1.8632e-02,  6.6344e-03, -3.6308e-03, -1.3727e-03,  6.9857e-03,\n                       7.5670e-04, -3.2121e-03,  3.2562e-02, -2.6373e-03, -1.4681e-02,\n                       1.4497e-02, -5.8505e-03, -1.8250e-02,  4.7206e-03, -8.6974e-05,\n                      -1.2655e-02, -2.7792e-02, -1.1447e-02,  1.8565e-02, -1.0512e-02,\n                       1.0934e-02,  1.2045e-03,  1.5368e-02,  1.3512e-02,  2.0219e-02,\n                      -1.3205e-02, -9.7965e-03,  2.5704e-02,  1.3520e-02, -4.9599e-03,\n                       5.2376e-03,  2.1400e-02, -2.1097e-03, -6.7256e-03,  1.2010e-02,\n                      -1.4655e-02, -7.3916e-03,  1.4205e-02,  1.0389e-02, -6.4587e-03,\n                       5.1018e-03, -6.5240e-03, -1.3284e-02, -7.4626e-03, -1.3694e-02,\n                      -9.1392e-04, -2.2744e-02,  3.3859e-03,  2.5712e-05],\n                     dtype=torch.float64)),\n             ('6.15.convpath.0.0.1.running_mean',\n              tensor([-0.3664, -0.6768, -0.8207, -0.3930, -0.3286,  0.9531, -1.3503, -0.2966,\n                      -0.1421,  0.4222,  0.1947,  0.4024, -0.3859,  0.9844, -0.4524, -0.2657,\n                       0.4571, -0.4074,  0.0493,  0.2227, -0.5151, -0.2222, -1.1664, -0.5592,\n                      -1.1289, -0.5731,  0.2532, -1.3125, -0.6064, -0.1724, -0.5534,  0.3572,\n                       0.0241,  0.4629, -0.3359, -0.1692,  0.5204, -0.4762,  0.1248,  0.1715,\n                      -0.4837, -0.1730, -0.5014, -0.2952, -0.4773,  0.9244,  0.2181, -0.2514,\n                      -0.7051, -0.5596,  0.6210, -1.0957, -0.1398, -0.7159,  0.4442,  0.0800,\n                      -0.7100,  0.2565,  0.3326,  0.3973,  0.2485, -0.1736,  0.8007,  0.5940],\n                     dtype=torch.float64)),\n             ('6.15.convpath.0.0.1.running_var',\n              tensor([0.6134, 0.4527, 0.1750, 0.2008, 0.1813, 0.3022, 0.3942, 0.4855, 0.1967,\n                      0.1443, 0.1512, 0.1315, 0.2069, 0.7281, 0.3426, 0.3440, 0.5554, 0.5919,\n                      0.1539, 0.1948, 0.1116, 0.4094, 0.2235, 0.4364, 0.8588, 0.4760, 0.4412,\n                      0.7581, 0.1895, 0.1007, 0.1305, 0.1993, 0.1518, 0.1238, 0.4263, 0.1462,\n                      0.2099, 0.2160, 0.2551, 0.5796, 0.6776, 0.2586, 0.1278, 0.4879, 0.1715,\n                      1.1504, 0.2099, 0.2651, 0.4664, 0.1136, 0.1952, 0.4565, 0.1458, 0.3117,\n                      0.1826, 0.2265, 0.3653, 0.2073, 0.3343, 0.3065, 0.5733, 0.2401, 0.1906,\n                      0.1774], dtype=torch.float64)),\n             ('6.15.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.15.convpath.0.1.0.weight',\n              tensor([[[ 0.0365, -0.0088, -0.1596,  0.0008, -0.0102],\n                       [-0.0652, -0.1257, -0.1465,  0.0406,  0.0022],\n                       [ 0.0661, -0.1009, -0.0582,  0.1363, -0.0557],\n                       ...,\n                       [ 0.0702, -0.0138,  0.1363,  0.0524, -0.0036],\n                       [ 0.0407, -0.0791, -0.0375, -0.1090,  0.0930],\n                       [ 0.0861,  0.0422,  0.0104,  0.1234, -0.0203]],\n              \n                      [[-0.0119,  0.0614,  0.0369, -0.0738,  0.0594],\n                       [ 0.0173, -0.1537,  0.0102, -0.0114, -0.0138],\n                       [ 0.0485, -0.0777,  0.0055, -0.1281, -0.0553],\n                       ...,\n                       [ 0.0245, -0.0312, -0.0310, -0.0294, -0.1041],\n                       [ 0.0184,  0.0267, -0.1629, -0.0523, -0.1395],\n                       [ 0.0182,  0.0307,  0.1425,  0.0949,  0.0388]],\n              \n                      [[-0.0205,  0.1368, -0.2226, -0.0908, -0.0523],\n                       [-0.0882,  0.0452, -0.0129, -0.1099, -0.1264],\n                       [-0.0164, -0.1916,  0.0304,  0.1287, -0.0046],\n                       ...,\n                       [ 0.0938,  0.0962,  0.0884,  0.0203, -0.0352],\n                       [-0.0056,  0.0036,  0.0159, -0.0188,  0.0613],\n                       [ 0.0737,  0.0036,  0.0486, -0.0992,  0.0282]],\n              \n                      ...,\n              \n                      [[-0.0712,  0.0641,  0.0567, -0.0712,  0.0029],\n                       [-0.1085, -0.0066,  0.0666, -0.0095, -0.0585],\n                       [ 0.0104, -0.0419, -0.0818, -0.0713, -0.0852],\n                       ...,\n                       [ 0.0641,  0.0020,  0.0349,  0.0906, -0.0563],\n                       [ 0.1625, -0.1216,  0.0388, -0.0475, -0.0682],\n                       [-0.0170, -0.0096, -0.0879,  0.1046,  0.0212]],\n              \n                      [[-0.0677, -0.0203,  0.0128, -0.0203, -0.0028],\n                       [ 0.0286, -0.0496, -0.0099,  0.0382, -0.0120],\n                       [-0.0052, -0.1719,  0.0473, -0.0082,  0.1848],\n                       ...,\n                       [ 0.0184, -0.0383, -0.0863, -0.0073, -0.0374],\n                       [-0.2072, -0.2095,  0.0337, -0.0184,  0.0535],\n                       [ 0.0658,  0.1133,  0.0735, -0.0796, -0.0046]],\n              \n                      [[-0.0344,  0.0512,  0.0384, -0.0591,  0.1539],\n                       [ 0.0795,  0.0118,  0.0088,  0.0292,  0.0554],\n                       [ 0.0160, -0.0637, -0.0667,  0.0548,  0.0072],\n                       ...,\n                       [ 0.0268,  0.0009,  0.1383,  0.1455, -0.0215],\n                       [ 0.0083,  0.0437,  0.0833,  0.1238,  0.1306],\n                       [ 0.0299,  0.0419, -0.1319, -0.0439, -0.1120]]], dtype=torch.float64)),\n             ('6.15.convpath.0.1.1.weight',\n              tensor([0.9293, 0.9985, 0.9525, 0.9769, 0.9566, 0.9610, 0.9652, 0.9372, 0.9724,\n                      0.9845, 0.9571, 1.0179, 0.9806, 0.9775, 0.9529, 0.9436, 0.9670, 0.9697,\n                      0.9621, 0.9779, 0.9677, 0.9781, 0.9603, 0.8998, 0.9333, 0.9519, 0.9178,\n                      0.9528, 0.9570, 0.9582, 0.9627, 0.9513, 0.9925, 0.9657, 0.9548, 0.9501,\n                      0.9575, 0.9530, 0.9602, 0.9973, 0.9731, 0.9719, 0.9949, 0.9624, 0.9561,\n                      0.9645, 0.9727, 0.9714, 0.9595, 0.9599, 0.9526, 0.9489, 0.9593, 0.9786,\n                      0.9750, 0.9718, 0.9794, 0.9654, 0.9524, 0.9885, 1.0028, 1.0046, 0.9717,\n                      0.9736], dtype=torch.float64)),\n             ('6.15.convpath.0.1.1.bias',\n              tensor([-0.0056, -0.0137, -0.0162, -0.0156,  0.0018, -0.0066, -0.0092, -0.0143,\n                       0.0084,  0.0077,  0.0018, -0.0311, -0.0056, -0.0167, -0.0356, -0.0016,\n                      -0.0016,  0.0144, -0.0267,  0.0193, -0.0125, -0.0004, -0.0091, -0.0364,\n                      -0.0158, -0.0052, -0.0180, -0.0223, -0.0190, -0.0251,  0.0003, -0.0091,\n                      -0.0283, -0.0065, -0.0084,  0.0037, -0.0008, -0.0073, -0.0030,  0.0245,\n                      -0.0058,  0.0051,  0.0126,  0.0042, -0.0203, -0.0140, -0.0095, -0.0211,\n                      -0.0095, -0.0175,  0.0018, -0.0202,  0.0109, -0.0067,  0.0025,  0.0030,\n                       0.0012,  0.0073, -0.0057, -0.0082, -0.0007,  0.0230, -0.0018, -0.0029],\n                     dtype=torch.float64)),\n             ('6.15.convpath.0.1.1.running_mean',\n              tensor([-0.3485, -0.2754, -0.3150,  0.7041, -0.3306, -0.2593, -0.2418, -0.2294,\n                      -0.2694,  0.1487, -0.5379, -0.1990,  0.6688,  0.5622,  0.2482, -0.8124,\n                       0.1933, -0.8719,  0.3852, -0.1066, -0.7692, -0.1053,  0.1267, -0.6182,\n                      -0.4634, -0.6459, -0.5931, -0.9057, -0.2623, -0.0419, -0.7965, -1.1764,\n                       0.6690, -0.5609, -1.1999,  0.7370,  0.4391,  0.3725, -0.6687, -0.6831,\n                      -0.4745,  0.2714, -0.6251, -0.5994,  0.7184,  0.8468, -0.9091,  0.1424,\n                      -0.2948, -0.5900, -0.1343,  0.7723, -0.1976,  0.7360,  0.1816, -0.0813,\n                      -0.5161,  0.0181, -0.5071,  0.6816, -0.4056, -0.2278,  0.6237,  0.3408],\n                     dtype=torch.float64)),\n             ('6.15.convpath.0.1.1.running_var',\n              tensor([0.5408, 0.4678, 0.3464, 0.4533, 0.5386, 0.4097, 0.3803, 1.0948, 0.6647,\n                      0.3112, 0.4504, 0.5255, 0.6277, 0.5079, 0.3101, 0.6061, 0.4881, 0.5388,\n                      0.7805, 0.5783, 0.5154, 0.3350, 0.4275, 0.5500, 0.5687, 0.6771, 0.5446,\n                      0.3741, 1.0552, 0.7730, 0.7270, 0.3843, 0.4254, 0.5863, 0.7281, 0.5104,\n                      0.4715, 0.6462, 0.5404, 0.3935, 0.5149, 0.4131, 0.3629, 0.5706, 0.5875,\n                      0.6909, 0.3766, 0.6369, 0.4133, 0.4357, 0.7915, 0.6372, 0.5983, 0.3493,\n                      0.5035, 0.3689, 0.4628, 0.5193, 0.5091, 0.5171, 0.5984, 0.4025, 0.5612,\n                      0.4365], dtype=torch.float64)),\n             ('6.15.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.15.convpath.0.2.0.weight',\n              tensor([[[-0.0897],\n                       [-0.1421],\n                       [ 0.1287],\n                       ...,\n                       [-0.0959],\n                       [-0.1251],\n                       [-0.0776]],\n              \n                      [[-0.1253],\n                       [-0.3135],\n                       [-0.2487],\n                       ...,\n                       [ 0.1479],\n                       [ 0.0657],\n                       [ 0.0065]],\n              \n                      [[ 0.0369],\n                       [ 0.0230],\n                       [-0.0845],\n                       ...,\n                       [-0.0645],\n                       [-0.0878],\n                       [ 0.0084]],\n              \n                      ...,\n              \n                      [[-0.0673],\n                       [-0.2753],\n                       [-0.0797],\n                       ...,\n                       [-0.0663],\n                       [-0.1305],\n                       [ 0.0428]],\n              \n                      [[-0.0404],\n                       [ 0.0839],\n                       [-0.1159],\n                       ...,\n                       [-0.1294],\n                       [-0.1473],\n                       [-0.0257]],\n              \n                      [[ 0.1763],\n                       [-0.0708],\n                       [-0.0577],\n                       ...,\n                       [-0.1063],\n                       [-0.0006],\n                       [ 0.3006]]], dtype=torch.float64)),\n             ('6.15.convpath.0.2.1.weight',\n              tensor([-0.0249,  0.0140, -0.0065,  0.0115,  0.0256, -0.0141, -0.0022, -0.0149,\n                       0.0270, -0.0325, -0.0224, -0.0188,  0.0037,  0.0032,  0.0046,  0.0106,\n                      -0.0319, -0.0150, -0.0239,  0.0130,  0.0007,  0.0354,  0.0016,  0.0135,\n                       0.0155,  0.0138, -0.0055,  0.0217,  0.0025,  0.0058, -0.0119,  0.0448,\n                       0.0142, -0.0015, -0.0243, -0.0055,  0.0140, -0.0039,  0.0188,  0.0153,\n                      -0.0169, -0.0318,  0.0164,  0.0158,  0.0029,  0.0058, -0.0263, -0.0170,\n                      -0.0227, -0.0005, -0.0022, -0.0131, -0.0243,  0.0169, -0.0191, -0.0075,\n                       0.0222,  0.0351,  0.0319, -0.0058,  0.0219,  0.0063,  0.0038,  0.0167,\n                      -0.0055, -0.0154, -0.0192,  0.0062,  0.0056, -0.0003,  0.0114,  0.0125,\n                       0.0135, -0.0228,  0.0080,  0.0320,  0.0063, -0.0154,  0.0096, -0.0113,\n                      -0.0092,  0.0029, -0.0295,  0.0043, -0.0276,  0.0096, -0.0223, -0.0308,\n                       0.0180, -0.0039, -0.0104,  0.0199, -0.0047, -0.0178,  0.0176, -0.0034,\n                      -0.0215,  0.0181, -0.0151,  0.0345, -0.0041,  0.0359,  0.0157, -0.0140,\n                       0.0125, -0.0121,  0.0002, -0.0089, -0.0094, -0.0208,  0.0080,  0.0037,\n                       0.0210,  0.0128, -0.0087, -0.0102,  0.0242,  0.0065,  0.0032, -0.0386,\n                      -0.0088, -0.0065,  0.0151, -0.0222, -0.0017, -0.0064,  0.0110, -0.0112,\n                       0.0063, -0.0271,  0.0086, -0.0020, -0.0129, -0.0010,  0.0140,  0.0120,\n                      -0.0174, -0.0088,  0.0145, -0.0205,  0.0046,  0.0001,  0.0071, -0.0042,\n                       0.0022,  0.0201,  0.0144,  0.0388, -0.0506,  0.0305,  0.0003, -0.0058,\n                      -0.0096, -0.0240,  0.0118,  0.0150, -0.0150, -0.0209, -0.0054, -0.0235,\n                      -0.0026,  0.0057,  0.0150,  0.0018,  0.0173,  0.0070, -0.0243, -0.0077,\n                      -0.0044, -0.0329,  0.0102,  0.0091,  0.0278, -0.0221, -0.0059,  0.0115,\n                       0.0090,  0.0031,  0.0034,  0.0159,  0.0082, -0.0019, -0.0132,  0.0138,\n                      -0.0231,  0.0018,  0.0130,  0.0088,  0.0016,  0.0075,  0.0292,  0.0051,\n                       0.0375, -0.0377, -0.0221,  0.0290, -0.0299, -0.0303,  0.0174,  0.0158,\n                      -0.0089,  0.0134,  0.0216, -0.0089, -0.0136,  0.0288, -0.0084, -0.0134,\n                      -0.0028, -0.0287, -0.0182,  0.0088, -0.0187, -0.0222, -0.0147,  0.0103,\n                      -0.0262,  0.0051,  0.0047, -0.0100, -0.0178, -0.0211,  0.0063,  0.0312,\n                       0.0265, -0.0155, -0.0080,  0.0046,  0.0303, -0.0058, -0.0230, -0.0090,\n                       0.0345,  0.0335, -0.0023,  0.0038,  0.0067, -0.0219, -0.0071,  0.0081,\n                      -0.0322,  0.0172, -0.0079,  0.0036,  0.0051, -0.0186, -0.0153, -0.0081,\n                       0.0013,  0.0095, -0.0081, -0.0126,  0.0202,  0.0238,  0.0236,  0.0189],\n                     dtype=torch.float64)),\n             ('6.15.convpath.0.2.1.bias',\n              tensor([ 0.0008,  0.0093,  0.0093,  0.0141,  0.0030,  0.0087,  0.0060, -0.0031,\n                       0.0111,  0.0154,  0.0130, -0.0087,  0.0039, -0.0056,  0.0086,  0.0043,\n                       0.0255,  0.0006,  0.0120, -0.0029, -0.0110,  0.0014,  0.0086,  0.0058,\n                       0.0107, -0.0204,  0.0076,  0.0134,  0.0099, -0.0081, -0.0047,  0.0090,\n                      -0.0024,  0.0217,  0.0040,  0.0110, -0.0025,  0.0108,  0.0110,  0.0079,\n                       0.0024,  0.0121, -0.0141, -0.0031,  0.0070, -0.0152,  0.0169,  0.0016,\n                      -0.0139,  0.0004,  0.0121,  0.0038,  0.0048,  0.0183,  0.0018,  0.0130,\n                       0.0099,  0.0011,  0.0123, -0.0034,  0.0053, -0.0003,  0.0049,  0.0088,\n                      -0.0063,  0.0026, -0.0102,  0.0128,  0.0141, -0.0152,  0.0071, -0.0017,\n                      -0.0012, -0.0073,  0.0138,  0.0077, -0.0007,  0.0005,  0.0022,  0.0168,\n                       0.0048, -0.0086,  0.0113,  0.0034, -0.0030,  0.0167,  0.0007,  0.0127,\n                       0.0152, -0.0005,  0.0003,  0.0118,  0.0100, -0.0040,  0.0113, -0.0075,\n                       0.0116,  0.0063,  0.0205,  0.0099,  0.0230,  0.0145,  0.0037,  0.0075,\n                       0.0034,  0.0008, -0.0077,  0.0055,  0.0072,  0.0048, -0.0095, -0.0098,\n                       0.0025,  0.0235,  0.0156,  0.0061,  0.0052,  0.0052,  0.0055, -0.0040,\n                      -0.0002,  0.0121,  0.0052,  0.0037,  0.0215,  0.0091,  0.0066,  0.0043,\n                       0.0096,  0.0139,  0.0064,  0.0051,  0.0123,  0.0036,  0.0061, -0.0160,\n                       0.0132,  0.0035,  0.0059,  0.0033,  0.0136,  0.0075,  0.0166,  0.0022,\n                      -0.0055,  0.0105,  0.0042, -0.0026,  0.0128,  0.0069,  0.0078,  0.0112,\n                       0.0030,  0.0120,  0.0126,  0.0034,  0.0002,  0.0094, -0.0004, -0.0057,\n                       0.0051,  0.0118, -0.0029,  0.0061,  0.0117, -0.0042, -0.0164,  0.0060,\n                       0.0069,  0.0194, -0.0007, -0.0008,  0.0088,  0.0136, -0.0118,  0.0118,\n                       0.0005,  0.0184,  0.0054,  0.0087,  0.0005,  0.0110, -0.0035, -0.0095,\n                       0.0112,  0.0067,  0.0138,  0.0103,  0.0086,  0.0080,  0.0071,  0.0049,\n                       0.0052,  0.0049, -0.0004,  0.0111,  0.0096,  0.0021,  0.0058,  0.0216,\n                      -0.0007,  0.0236,  0.0181,  0.0164,  0.0169,  0.0032,  0.0085, -0.0135,\n                       0.0038,  0.0130,  0.0044,  0.0116,  0.0020,  0.0079,  0.0085,  0.0052,\n                       0.0073,  0.0164,  0.0027,  0.0030,  0.0157,  0.0002,  0.0046,  0.0144,\n                       0.0050,  0.0062, -0.0065, -0.0032,  0.0289,  0.0196,  0.0004,  0.0019,\n                       0.0091,  0.0115,  0.0016,  0.0093,  0.0019,  0.0123,  0.0051,  0.0098,\n                       0.0006, -0.0034, -0.0023,  0.0133,  0.0060,  0.0075,  0.0052,  0.0024,\n                      -0.0118, -0.0090,  0.0211,  0.0241,  0.0167,  0.0176,  0.0009,  0.0020],\n                     dtype=torch.float64)),\n             ('6.15.convpath.0.2.1.running_mean',\n              tensor([ 1.0479e-01,  1.8677e-01, -3.5391e-01, -1.7504e-01, -6.7980e-01,\n                      -1.6289e-02,  2.5559e-01, -1.1582e-01, -1.2931e-02, -2.2876e-01,\n                       1.8573e-01, -1.0069e-01, -1.8811e-01,  8.6703e-04, -4.0426e-01,\n                      -1.3337e-01,  2.9601e-01, -5.1322e-01,  2.3288e-01, -1.9224e-01,\n                      -1.5222e-01, -6.3568e-02, -1.1412e-01, -4.3768e-01,  2.6221e-01,\n                      -1.7339e-01,  2.1424e-01,  3.5728e-01,  4.0704e-01,  1.9737e-01,\n                      -2.4685e-01,  8.9206e-02, -1.5409e-01, -1.6658e-01, -4.5586e-01,\n                      -1.2754e-01, -1.8894e-01,  1.5415e-01, -2.8832e-01,  8.3452e-02,\n                       2.9798e-01, -4.9729e-01, -2.2228e-01,  1.9003e-01,  2.1117e-03,\n                       6.8536e-01, -2.2233e-01, -2.2881e-01, -1.2354e-01, -2.3497e-01,\n                       5.9885e-02, -3.7618e-01,  2.6879e-01, -3.5419e-01,  2.7170e-01,\n                      -3.4546e-01, -9.3643e-01, -3.1858e-01,  1.9661e-01, -7.5543e-01,\n                      -5.0649e-01, -1.0024e-01, -1.2122e-02, -2.4440e-01, -3.8876e-01,\n                      -1.6764e-03, -6.4166e-01, -3.8463e-01,  3.6953e-01,  3.0495e-01,\n                       3.5121e-01, -1.4471e-01, -1.0449e-02, -6.8700e-01, -2.8979e-01,\n                      -4.8481e-01, -3.1703e-01,  5.2793e-01,  7.9635e-01, -2.1931e-01,\n                       3.9055e-01, -1.4431e-01,  9.5028e-01, -3.1821e-01, -2.5749e-01,\n                      -5.8180e-01,  5.4855e-01, -9.3870e-01,  3.8442e-01, -2.9656e-01,\n                      -6.9393e-01,  6.4734e-01, -3.1124e-01, -1.2238e-01, -3.8310e-01,\n                      -2.5708e-01,  1.7398e-01,  3.0630e-02, -7.3252e-01,  1.5129e-01,\n                       5.0478e-01, -8.0460e-02,  2.2963e-01,  7.1013e-02,  5.1687e-01,\n                      -2.7485e-01,  2.6014e-02, -4.2407e-01, -1.3121e-01, -2.7005e-01,\n                      -2.9262e-01,  7.4822e-02, -9.6785e-01,  4.5174e-01, -9.1099e-02,\n                       7.0045e-01, -4.8365e-01, -1.9028e-01, -1.7435e-01,  6.0641e-01,\n                      -1.3054e-01,  7.0349e-01,  6.2479e-02, -4.5685e-01,  3.0731e-01,\n                      -2.2747e-01,  1.1041e-01, -3.2144e-03, -1.8292e-01,  6.9356e-01,\n                       2.0157e-01,  8.7339e-02, -4.4246e-01, -2.3561e-01, -4.6846e-01,\n                      -1.0735e-01, -2.7825e-01,  1.1165e-02,  2.7746e-01, -7.2893e-01,\n                      -1.7397e-02,  4.8868e-01,  6.2146e-02,  1.4681e-01,  8.7959e-03,\n                      -7.0782e-01, -2.0533e-01,  4.4275e-01, -3.5407e-01,  1.3771e-01,\n                       1.9552e-01,  1.1500e-02, -3.2183e-01,  7.1869e-01,  2.0491e-02,\n                      -3.1756e-01,  6.3591e-01,  1.0389e-01,  8.8295e-02, -2.1867e-01,\n                      -5.8845e-01, -1.4317e-01, -6.5038e-02,  2.9326e-02, -5.1279e-01,\n                       5.4331e-01,  5.1955e-01, -2.2634e-02, -4.6085e-02,  2.0497e-01,\n                       2.2110e-01, -1.2189e-01,  2.1803e-01,  3.4218e-02, -2.7513e-01,\n                       1.5140e-01,  4.1626e-02,  1.1159e-01,  3.2007e-01, -5.2300e-01,\n                       2.4906e-01, -5.9964e-01,  3.9300e-01,  5.1744e-01,  5.7434e-01,\n                      -1.7518e-01, -2.8018e-01, -3.4586e-01,  2.0095e-02,  2.0409e-02,\n                       2.3337e-01, -1.8359e-01,  1.7274e-01, -7.7483e-01, -7.7451e-02,\n                       3.2532e-01, -8.2276e-01, -6.1814e-02, -4.9117e-02, -6.3873e-01,\n                      -2.1534e-01,  3.2278e-02, -4.7700e-01,  3.8683e-01, -6.6096e-02,\n                       1.9187e-01,  2.9021e-01,  1.0910e-02, -7.2273e-02,  5.3995e-01,\n                      -1.1949e-01, -7.4782e-01,  3.5793e-02,  4.3922e-01, -5.0333e-01,\n                      -2.0267e-01,  9.5468e-02, -4.5315e-03, -5.3939e-01, -3.2830e-01,\n                      -8.3010e-01, -4.8634e-01,  1.8608e-02,  1.7785e-01, -4.8933e-01,\n                       2.8294e-01, -9.9302e-02,  1.1578e-01, -5.2607e-01, -7.7552e-01,\n                       1.6543e-01, -1.7001e-01, -4.1742e-01,  4.8436e-01, -2.3778e-01,\n                       3.1478e-01,  2.0144e-01,  2.1662e-01, -9.1818e-01, -6.9275e-02,\n                       2.2825e-01, -1.1320e-01,  2.6199e-01, -1.6639e-02, -3.1166e-02,\n                      -1.4135e-01, -2.1073e-01, -4.1948e-01,  2.0640e-01, -4.4599e-01,\n                       9.0185e-01,  5.9018e-01, -2.7295e-01, -1.9527e-01, -4.0795e-01,\n                       1.8765e-01], dtype=torch.float64)),\n             ('6.15.convpath.0.2.1.running_var',\n              tensor([0.3135, 0.3781, 0.1736, 0.3603, 0.4590, 0.5072, 0.1257, 0.4336, 0.2330,\n                      0.4114, 0.2835, 0.4340, 0.0949, 0.1575, 0.3950, 0.2456, 0.2902, 0.3000,\n                      0.2790, 0.4455, 0.1980, 0.5252, 0.3532, 0.3930, 0.4254, 0.2121, 0.3774,\n                      0.3274, 0.2840, 0.3836, 0.7551, 0.3911, 0.1550, 0.3059, 0.5672, 0.3948,\n                      0.3652, 0.2074, 0.4422, 0.3415, 0.2113, 0.3504, 0.3131, 0.4447, 0.3633,\n                      0.3820, 0.4223, 0.3368, 0.5318, 0.4337, 0.1178, 0.3670, 0.3754, 0.4140,\n                      0.3801, 0.3197, 0.5504, 0.4567, 0.4693, 0.2123, 0.3096, 0.2895, 0.2178,\n                      0.3126, 0.3632, 0.2206, 0.4002, 0.1966, 0.1738, 0.4091, 0.2828, 0.3404,\n                      0.2327, 0.6510, 0.2811, 0.2819, 0.2291, 0.4534, 0.4709, 0.1609, 0.3142,\n                      0.2755, 0.3894, 0.5698, 0.3086, 0.3690, 0.6925, 0.4212, 0.3391, 0.2701,\n                      0.5574, 0.2751, 0.2864, 0.4911, 0.2465, 0.2322, 0.5320, 0.2430, 0.4115,\n                      0.2584, 0.2798, 0.4306, 0.3511, 0.2572, 0.3124, 0.2414, 0.3444, 0.6826,\n                      0.4306, 0.3720, 0.2076, 0.3348, 0.6123, 0.3995, 0.2375, 0.4530, 0.3811,\n                      0.1410, 0.1294, 0.3727, 0.1302, 0.3509, 0.3208, 0.3497, 0.0804, 0.2702,\n                      0.2695, 0.5138, 0.1046, 0.4247, 0.1918, 0.3231, 0.5364, 0.1916, 0.1685,\n                      0.1591, 0.1758, 0.3813, 0.4704, 0.4362, 0.1025, 0.2494, 0.4240, 0.1669,\n                      0.1152, 0.3842, 0.2001, 0.4396, 0.3914, 0.3538, 0.2552, 0.3404, 0.5096,\n                      0.7207, 0.4262, 0.2094, 0.2314, 0.2303, 0.3435, 0.3477, 0.1860, 0.1319,\n                      0.3631, 0.4989, 0.6070, 0.3542, 0.3878, 0.0841, 0.4020, 0.5578, 0.2265,\n                      0.1435, 0.4680, 0.3120, 0.4217, 0.3852, 0.2484, 0.1407, 0.3949, 0.5614,\n                      0.2795, 0.2495, 0.5103, 0.3847, 0.3899, 0.2983, 0.3305, 0.2930, 0.1935,\n                      0.3251, 0.5286, 0.3981, 0.3502, 0.2924, 0.3298, 0.3093, 0.2672, 0.3031,\n                      0.3339, 0.4020, 0.3489, 0.3213, 0.3566, 0.3139, 0.6308, 0.6544, 0.1406,\n                      0.1098, 0.1602, 0.3394, 0.1359, 0.3483, 0.2814, 0.2717, 0.2663, 0.2063,\n                      0.3771, 0.0309, 0.1363, 0.4361, 0.3120, 0.3508, 0.1236, 0.3520, 0.6128,\n                      0.4074, 0.1826, 0.1285, 0.5723, 0.3298, 0.1600, 0.2964, 0.4572, 0.3846,\n                      0.2573, 0.2025, 0.3171, 0.1765, 0.5909, 0.2828, 0.4280, 0.1850, 0.7586,\n                      0.1593, 0.1209, 0.3152, 0.2796, 0.4446, 0.1909, 0.3149, 0.4554, 0.6545,\n                      0.4658, 0.2942, 0.3452, 0.3046], dtype=torch.float64)),\n             ('6.15.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.16.convs.0.0.weight',\n              tensor([[[-0.0849],\n                       [ 0.0370],\n                       [ 0.0660],\n                       ...,\n                       [ 0.0349],\n                       [ 0.0190],\n                       [ 0.0572]],\n              \n                      [[ 0.1340],\n                       [-0.0127],\n                       [-0.1204],\n                       ...,\n                       [ 0.0607],\n                       [ 0.0385],\n                       [ 0.0542]],\n              \n                      [[-0.0033],\n                       [ 0.0583],\n                       [ 0.0407],\n                       ...,\n                       [-0.0902],\n                       [-0.1398],\n                       [-0.0860]],\n              \n                      ...,\n              \n                      [[-0.1042],\n                       [-0.1574],\n                       [-0.0387],\n                       ...,\n                       [ 0.0432],\n                       [ 0.0390],\n                       [ 0.0041]],\n              \n                      [[ 0.0076],\n                       [ 0.0651],\n                       [-0.0265],\n                       ...,\n                       [ 0.1583],\n                       [ 0.1733],\n                       [ 0.0527]],\n              \n                      [[ 0.1249],\n                       [-0.0949],\n                       [-0.0671],\n                       ...,\n                       [-0.1007],\n                       [-0.0337],\n                       [-0.0539]]], dtype=torch.float64)),\n             ('6.16.convs.0.1.weight',\n              tensor([1.0204, 0.9983, 0.9722, 0.9709, 0.9496, 0.9767, 0.9625, 0.9766, 0.9750,\n                      1.0028, 0.9789, 0.9604, 0.9579, 0.9582, 0.9726, 0.9695, 0.9591, 0.9919,\n                      0.9730, 0.9733, 0.9822, 0.9740, 0.9776, 0.9634, 0.9870, 0.9621, 0.9761,\n                      0.9525, 0.9793, 0.9947, 0.9793, 0.9809, 1.0071, 0.9582, 0.9795, 0.9642,\n                      0.9817, 0.9942, 0.9596, 0.9613, 0.9832, 0.9603, 0.9715, 0.9670, 0.9693,\n                      0.9862, 0.9944, 0.9899, 0.9428, 0.9702, 1.0020, 0.9859, 0.9851, 0.9738,\n                      0.9715, 0.9766, 0.9613, 0.9507, 0.9693, 0.9697, 0.9631, 0.9612, 0.9928,\n                      0.9599], dtype=torch.float64)),\n             ('6.16.convs.0.1.bias',\n              tensor([ 3.7872e-02,  1.7528e-02,  9.4606e-04,  6.7585e-03, -9.2415e-03,\n                       7.4245e-03,  3.3601e-03, -5.3582e-03,  8.7345e-03,  1.9513e-02,\n                      -9.6278e-04, -1.5136e-02, -5.4815e-03, -1.4322e-02,  3.6464e-03,\n                       8.7829e-03, -4.4805e-03,  2.0636e-02, -3.5340e-03, -8.0657e-03,\n                       1.6374e-02, -4.2637e-03,  6.8740e-03,  4.2311e-04,  6.6076e-04,\n                      -4.9033e-03,  1.1023e-02, -1.3583e-02,  1.1037e-02,  6.1770e-03,\n                       8.7457e-03,  9.7177e-03,  1.3991e-02,  1.2460e-02,  4.3055e-04,\n                       1.4306e-02,  1.7489e-02, -8.1642e-05,  2.2225e-03,  1.2362e-03,\n                      -5.1253e-03, -1.2712e-02,  1.0149e-02, -1.7798e-03,  3.5995e-03,\n                       9.3915e-03,  1.9896e-02,  1.2670e-02, -3.2209e-02, -3.8582e-03,\n                       3.0761e-02,  9.0579e-03,  2.9330e-02,  1.1309e-02,  3.7868e-03,\n                      -2.3350e-03,  3.4725e-03, -3.8650e-03,  3.3181e-03, -6.6589e-04,\n                      -5.7606e-03,  1.2657e-03,  1.0486e-02, -1.4904e-02],\n                     dtype=torch.float64)),\n             ('6.16.convs.0.1.running_mean',\n              tensor([ 0.2091, -0.3048, -1.1237,  1.1509,  0.7080, -0.8807, -0.1687, -0.8891,\n                      -0.9276,  0.6444,  0.3535,  0.6074,  1.7552,  0.6510,  0.1953, -0.8793,\n                      -0.4890, -0.5889, -0.0730, -0.5934, -0.1562, -0.1691, -0.0669, -0.3359,\n                      -0.3484,  0.2112,  0.7949,  0.6647,  0.8641,  0.3263, -0.4912,  0.1529,\n                      -0.0412, -1.2238,  0.2319, -0.7661, -0.0840, -0.1459, -0.0771,  0.6293,\n                       0.3002,  0.2458, -0.4420,  0.4570, -1.0461,  0.1204, -1.3301, -0.3564,\n                      -0.0401,  1.1795,  0.2219, -0.0931, -0.0042, -0.3307,  0.3959,  0.6692,\n                      -0.8969,  0.4309,  0.4061, -1.0083, -0.9263, -0.9333, -0.3082, -0.1359],\n                     dtype=torch.float64)),\n             ('6.16.convs.0.1.running_var',\n              tensor([0.1525, 0.1737, 0.1394, 0.2540, 0.4210, 0.1965, 0.2169, 0.2674, 0.1344,\n                      0.0966, 0.1535, 0.2333, 1.5348, 1.0286, 0.2110, 0.1943, 0.2559, 0.1814,\n                      0.1055, 0.1294, 0.2185, 0.1433, 0.1353, 0.1014, 0.1175, 0.1602, 0.1496,\n                      0.1953, 0.1265, 0.2047, 0.1056, 0.3393, 0.1275, 1.1701, 0.1572, 0.1764,\n                      0.5158, 0.3284, 0.1791, 1.6581, 0.2850, 0.2629, 0.3453, 0.1870, 0.7823,\n                      0.4712, 0.2041, 0.1751, 0.1437, 0.4975, 0.1308, 0.1125, 0.1751, 0.1249,\n                      0.9092, 0.1291, 0.3944, 0.4786, 0.3618, 0.1770, 0.2023, 0.3866, 0.1370,\n                      0.6383], dtype=torch.float64)),\n             ('6.16.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.16.convs.1.0.weight',\n              tensor([[[-0.0495, -0.0257,  0.0729, -0.0628,  0.0664],\n                       [ 0.0872,  0.0761, -0.1176, -0.0915, -0.0315],\n                       [ 0.0615,  0.0835, -0.0732,  0.0728,  0.0103],\n                       ...,\n                       [-0.0311, -0.0073, -0.0252, -0.0855,  0.1494],\n                       [-0.0005, -0.0151,  0.1097,  0.0150, -0.0251],\n                       [-0.0480,  0.1253,  0.0874, -0.0400, -0.0724]],\n              \n                      [[ 0.0125,  0.0584,  0.2318,  0.0178,  0.1433],\n                       [ 0.0839, -0.0259, -0.0564,  0.0386, -0.0003],\n                       [ 0.1535,  0.0124, -0.0149,  0.1117, -0.0777],\n                       ...,\n                       [-0.0654, -0.0153, -0.0812,  0.0630, -0.1094],\n                       [-0.0259,  0.0435,  0.0299,  0.0790, -0.1026],\n                       [ 0.0499, -0.0335,  0.0372, -0.0486, -0.0005]],\n              \n                      [[ 0.0953,  0.0963,  0.0318,  0.0819, -0.0382],\n                       [-0.1328,  0.0064, -0.0100,  0.0602,  0.0263],\n                       [-0.1218, -0.0080, -0.0063, -0.0373,  0.0640],\n                       ...,\n                       [ 0.0971,  0.0049, -0.0025, -0.0477, -0.0630],\n                       [-0.0736, -0.2161, -0.0748,  0.0991,  0.0707],\n                       [ 0.0634, -0.0100,  0.0149,  0.0701, -0.0062]],\n              \n                      ...,\n              \n                      [[-0.1141,  0.0655,  0.0645,  0.0988, -0.0535],\n                       [ 0.0189,  0.0011,  0.0627,  0.0571, -0.0065],\n                       [-0.0256, -0.0695,  0.0029, -0.0065, -0.0278],\n                       ...,\n                       [ 0.0783, -0.0260,  0.0638,  0.0338,  0.0096],\n                       [ 0.0115,  0.0455,  0.0435,  0.0109, -0.0641],\n                       [ 0.0210, -0.0198,  0.0508,  0.0690, -0.0831]],\n              \n                      [[-0.0371, -0.0980, -0.1335, -0.0326,  0.1524],\n                       [-0.0761, -0.0580, -0.0129, -0.0514, -0.0040],\n                       [-0.1499, -0.0150, -0.0092, -0.1002, -0.1156],\n                       ...,\n                       [-0.1336, -0.0441,  0.0788,  0.0535,  0.0330],\n                       [ 0.0216, -0.1529,  0.0017,  0.1496,  0.0180],\n                       [ 0.0853, -0.0043, -0.0247,  0.0088,  0.0530]],\n              \n                      [[ 0.0390, -0.0798,  0.0299,  0.0353,  0.0489],\n                       [ 0.0220, -0.1562, -0.0673, -0.1119,  0.1118],\n                       [ 0.0406, -0.0420,  0.0609,  0.1055, -0.0913],\n                       ...,\n                       [-0.1312, -0.0054,  0.0705, -0.0770,  0.0593],\n                       [-0.0046, -0.0738,  0.1191,  0.0335,  0.0504],\n                       [-0.0950,  0.1289,  0.0746,  0.0174, -0.0401]]], dtype=torch.float64)),\n             ('6.16.convs.1.1.weight',\n              tensor([0.9521, 0.9663, 0.9419, 0.9671, 1.0194, 0.9439, 0.9950, 0.9539, 0.9640,\n                      0.9785, 0.9245, 0.9682, 0.9661, 0.9759, 0.9984, 0.9626, 0.9533, 0.9649,\n                      0.9754, 0.9531, 0.9816, 0.9421, 1.0038, 0.9764, 0.9616, 0.9579, 0.9554,\n                      0.9736, 0.9662, 0.9372, 0.9691, 0.9603, 0.9606, 0.9221, 0.9600, 0.9773,\n                      0.9938, 0.9632, 1.0066, 0.9742, 0.9760, 0.9704, 1.0337, 0.9769, 0.9782,\n                      0.9478, 0.9541, 0.9743, 0.9941, 0.9371, 0.9572, 0.9273, 1.0007, 0.9460,\n                      0.9810, 0.9513, 0.9822, 0.9660, 0.9393, 0.9559, 0.9687, 0.9425, 0.9770,\n                      0.9621], dtype=torch.float64)),\n             ('6.16.convs.1.1.bias',\n              tensor([-0.0354,  0.0144, -0.0082, -0.0069,  0.0244, -0.0049,  0.0041, -0.0045,\n                      -0.0102, -0.0095, -0.0307,  0.0032,  0.0032,  0.0102, -0.0125, -0.0081,\n                      -0.0010, -0.0095, -0.0050, -0.0092,  0.0172,  0.0005, -0.0234,  0.0026,\n                      -0.0236, -0.0175,  0.0005, -0.0204,  0.0004, -0.0250,  0.0141, -0.0213,\n                       0.0062, -0.0177,  0.0106,  0.0018,  0.0005, -0.0092,  0.0218, -0.0095,\n                       0.0106,  0.0002,  0.0192, -0.0051, -0.0242, -0.0034, -0.0052,  0.0131,\n                       0.0257, -0.0280, -0.0126, -0.0361,  0.0197, -0.0236,  0.0092, -0.0268,\n                      -0.0272, -0.0179, -0.0069, -0.0019, -0.0130, -0.0106,  0.0071, -0.0072],\n                     dtype=torch.float64)),\n             ('6.16.convs.1.1.running_mean',\n              tensor([ 0.3796, -0.3983, -0.7651, -0.0324,  0.3357,  0.0143,  0.0337, -0.5383,\n                       0.0723, -0.3463,  0.5091,  0.3380,  0.0919, -0.0493, -0.2716, -0.0137,\n                      -0.0227,  0.4798, -0.4945,  0.1577, -0.4114, -0.4955, -0.0542, -0.2214,\n                      -0.1997,  0.4557, -0.4343, -0.0194, -1.2919, -0.1384,  0.5426,  0.7191,\n                       0.2690, -1.1025, -0.2469, -0.0124,  0.4420, -0.0629, -0.0067,  0.3446,\n                       0.0428, -0.7081,  0.0539,  0.6643,  0.3667, -0.6925, -0.0742, -0.0649,\n                       0.0947, -0.4319,  0.2873,  0.3959, -0.1346,  0.0755, -0.7097, -0.0335,\n                       0.9937, -0.1613,  0.0135, -0.5595,  0.4577, -0.3138, -0.9171, -0.2414],\n                     dtype=torch.float64)),\n             ('6.16.convs.1.1.running_var',\n              tensor([0.5643, 0.6416, 0.9706, 0.5738, 0.5148, 0.5681, 0.6402, 0.6911, 0.5865,\n                      0.4405, 0.6877, 0.5318, 0.6561, 0.7423, 0.5779, 0.4612, 0.6561, 0.5076,\n                      0.6750, 0.9432, 0.4387, 0.8454, 0.7202, 0.3461, 0.5043, 0.4775, 0.5518,\n                      0.6444, 0.8404, 0.5568, 0.5134, 0.4892, 0.4832, 0.6589, 1.0680, 0.5413,\n                      0.4567, 0.7856, 0.4941, 0.6084, 0.5559, 0.5024, 0.6621, 0.5626, 0.3897,\n                      0.6590, 0.5006, 0.8367, 0.4844, 0.7295, 1.0898, 0.5473, 0.7793, 0.5465,\n                      0.4796, 0.7566, 0.5572, 0.6338, 0.5360, 0.9785, 0.7664, 1.0578, 0.5516,\n                      0.6342], dtype=torch.float64)),\n             ('6.16.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.16.convs.2.0.weight',\n              tensor([[[ 0.0930],\n                       [ 0.0412],\n                       [-0.0414],\n                       ...,\n                       [ 0.0876],\n                       [-0.0330],\n                       [-0.0239]],\n              \n                      [[ 0.0033],\n                       [ 0.1032],\n                       [ 0.0673],\n                       ...,\n                       [-0.0214],\n                       [ 0.0200],\n                       [-0.0275]],\n              \n                      [[ 0.0295],\n                       [-0.0573],\n                       [ 0.1216],\n                       ...,\n                       [ 0.0039],\n                       [ 0.0025],\n                       [-0.3180]],\n              \n                      ...,\n              \n                      [[-0.1113],\n                       [-0.4144],\n                       [-0.0549],\n                       ...,\n                       [ 0.2064],\n                       [ 0.2598],\n                       [ 0.0462]],\n              \n                      [[ 0.0325],\n                       [-0.0147],\n                       [ 0.0393],\n                       ...,\n                       [-0.0517],\n                       [ 0.0677],\n                       [-0.0752]],\n              \n                      [[ 0.0882],\n                       [ 0.0162],\n                       [ 0.1092],\n                       ...,\n                       [ 0.1672],\n                       [ 0.0101],\n                       [ 0.0132]]], dtype=torch.float64)),\n             ('6.16.convs.2.1.weight',\n              tensor([-4.2887e-03,  5.3547e-03,  2.8098e-02, -4.1148e-02,  8.9659e-03,\n                       1.4052e-02,  1.7672e-02, -1.5002e-02,  2.2406e-02,  1.4576e-02,\n                       1.8012e-02,  1.5807e-02,  8.0291e-03,  2.1013e-02, -3.6874e-02,\n                       3.1353e-02, -2.3360e-02,  1.6778e-02, -1.3213e-02,  2.6153e-02,\n                       1.6228e-02,  4.0400e-02, -2.8806e-03,  9.2256e-03, -1.0633e-02,\n                      -1.7746e-02, -3.0937e-04, -2.2479e-02, -9.0966e-03,  1.6908e-02,\n                       1.0458e-02,  3.0138e-02,  1.4046e-03,  4.1998e-02, -8.7236e-03,\n                      -3.0711e-02,  5.2909e-03, -1.8230e-03,  3.3795e-02, -2.7628e-02,\n                      -3.0381e-02, -8.2002e-03, -8.7711e-03,  2.1332e-02,  2.7518e-03,\n                       2.8232e-03,  1.2952e-02, -1.8517e-02, -1.1196e-04,  3.3431e-03,\n                       3.9941e-03,  2.9208e-02,  1.6043e-02,  1.7105e-02, -3.2334e-03,\n                       1.2888e-03, -1.2872e-02,  4.3753e-02,  3.0307e-02,  2.2347e-03,\n                       1.3201e-02,  1.2301e-02, -4.7794e-03, -6.8303e-03, -1.6982e-02,\n                      -7.4266e-03, -2.1852e-02,  2.3630e-02, -1.6068e-02, -6.8652e-03,\n                      -1.6146e-02, -2.3270e-02,  3.4155e-03,  7.5641e-03, -4.4102e-02,\n                       7.8778e-03, -3.1041e-02, -8.7155e-03, -3.3446e-02, -1.2616e-02,\n                      -1.3742e-02,  1.7855e-03,  9.3243e-03,  2.0487e-02, -8.5238e-03,\n                       4.2211e-02, -4.9792e-03,  1.0958e-02,  1.9776e-02,  3.1619e-04,\n                      -5.9298e-03, -1.3137e-02,  2.5259e-02, -2.8567e-02, -4.5968e-03,\n                       1.3717e-02,  1.4659e-02,  1.9317e-02,  4.4472e-03,  1.0376e-02,\n                       8.2648e-03, -3.5143e-02, -2.3706e-02, -1.9286e-03, -1.1590e-02,\n                      -2.5200e-02, -9.1530e-03, -9.3763e-03, -3.7565e-02,  2.7193e-03,\n                      -2.4676e-02, -1.6890e-02, -2.7430e-02,  9.2596e-03, -2.7572e-02,\n                       1.5723e-02, -6.4210e-03,  1.3429e-02,  1.3513e-02, -7.3940e-03,\n                      -7.8988e-03, -1.3452e-02, -1.7926e-02, -3.2606e-02, -1.9435e-02,\n                       4.6131e-04, -1.0693e-02, -1.7958e-02, -2.9680e-02,  1.3550e-02,\n                      -6.2280e-03,  7.3637e-03, -2.6189e-02,  9.6368e-03, -4.1867e-03,\n                       2.0588e-03, -3.4247e-02,  1.5086e-02,  2.2798e-02,  5.0421e-06,\n                       2.2978e-02,  1.0273e-02,  2.1271e-02, -5.8057e-03, -5.8482e-03,\n                       1.0571e-02,  1.5283e-02,  2.4695e-02, -1.4543e-02,  1.6483e-02,\n                       3.1754e-03, -7.9288e-03,  1.1269e-02, -2.2481e-02, -1.2273e-02,\n                      -4.5980e-03, -1.9678e-02, -1.4204e-02, -1.3493e-02, -2.5066e-02,\n                       4.3385e-03, -6.1403e-03,  1.4905e-02, -7.7507e-04,  2.5668e-02,\n                       9.5060e-03, -1.1172e-02, -1.9561e-02,  2.6481e-02, -4.9491e-02,\n                       7.9912e-03, -7.5990e-03,  6.6821e-03,  1.3816e-02,  2.3499e-02,\n                      -2.6853e-03,  1.5853e-02,  3.8100e-02, -1.3817e-02,  1.1213e-02,\n                      -1.1415e-02,  1.6445e-02, -9.3296e-03,  1.3714e-02,  6.2017e-03,\n                      -1.7782e-02,  3.5762e-02, -2.9937e-02, -2.7340e-03, -1.9184e-02,\n                       5.8794e-05,  1.2618e-02, -6.5432e-03, -2.5166e-02, -2.2505e-02,\n                       1.5141e-02,  2.1169e-02, -1.0039e-02, -4.4835e-03,  2.2034e-02,\n                       1.0826e-03,  9.1657e-03,  8.5009e-03, -1.1663e-02, -8.6444e-03,\n                       1.0814e-02,  2.4179e-03, -1.3879e-02,  6.6626e-03, -3.1775e-02,\n                      -1.1022e-03,  1.3412e-02,  1.0795e-02,  1.0487e-02,  8.4371e-03,\n                       1.0807e-02, -7.4968e-03, -1.3240e-02, -1.0706e-02, -2.7411e-02,\n                      -1.4444e-02, -2.9956e-02,  1.0542e-02, -4.6799e-03,  9.1211e-03,\n                      -1.8913e-02, -2.4750e-03,  4.2870e-03, -1.7951e-02, -1.7830e-02,\n                      -1.9307e-02,  3.8218e-03, -8.0723e-03,  1.3052e-02,  1.8856e-02,\n                       2.1231e-02,  1.7566e-03,  8.4203e-03, -2.1740e-03,  7.3546e-03,\n                       4.1479e-02,  8.6095e-03, -3.2123e-02,  6.4610e-03, -3.0998e-02,\n                       3.0812e-02, -1.4489e-02,  2.4966e-02,  1.9497e-03, -3.1294e-02,\n                      -1.2307e-02, -6.4975e-03, -3.1969e-03,  1.2752e-02, -6.7522e-03,\n                      -6.9401e-03], dtype=torch.float64)),\n             ('6.16.convs.2.1.bias',\n              tensor([ 1.3239e-04,  5.9952e-03,  9.3251e-03,  1.4057e-02, -4.1340e-04,\n                       5.8669e-03,  5.9947e-03, -3.6517e-03,  1.1120e-02,  1.6620e-02,\n                       1.4444e-02, -7.4460e-03,  3.9039e-03, -7.1543e-03,  8.7027e-03,\n                       4.4965e-03,  2.6014e-02,  9.9015e-04,  1.2080e-02, -2.5601e-04,\n                      -1.0805e-02,  2.4438e-03,  8.3434e-03,  6.9587e-03,  9.6617e-03,\n                      -2.1555e-02,  6.7647e-03,  1.2255e-02,  1.2894e-02, -4.9601e-03,\n                      -3.4266e-03,  1.0724e-02,  4.4924e-03,  2.1441e-02,  8.8721e-03,\n                       1.1025e-02, -6.1305e-03,  1.0371e-02,  2.1027e-02,  6.2433e-03,\n                       2.8081e-03,  7.2477e-03, -6.6896e-03, -4.0474e-03,  7.3500e-03,\n                      -1.6637e-02,  1.6194e-02,  1.0437e-02, -1.3652e-02, -4.1064e-04,\n                       1.1147e-02,  2.7983e-03,  3.6667e-03,  2.0729e-02,  3.1084e-04,\n                       1.3225e-02,  1.0156e-02,  2.6511e-03,  1.2527e-02, -4.0934e-03,\n                      -4.0890e-04,  1.0625e-03,  8.7474e-03,  9.1291e-03, -7.7499e-03,\n                       1.9510e-04, -7.9020e-03,  1.2744e-02,  1.5976e-02, -1.4377e-02,\n                       7.3737e-03, -2.4469e-03, -7.3329e-04, -7.4612e-03,  1.3656e-02,\n                       8.3042e-03,  2.3329e-04,  9.6921e-03,  2.4927e-04,  1.7013e-02,\n                       4.6550e-03, -7.8937e-03,  1.3986e-02,  3.6012e-03, -5.0575e-03,\n                       1.7210e-02, -8.2577e-04,  1.0912e-02,  1.3911e-02, -1.0697e-03,\n                       7.5105e-04,  1.1527e-02,  1.0212e-02,  1.4002e-02,  8.1182e-03,\n                      -6.0427e-03,  1.4571e-02,  5.6991e-03,  1.9976e-02,  9.0048e-03,\n                       2.3133e-02,  1.6251e-02,  6.4168e-03,  1.2667e-02,  6.1930e-03,\n                       3.4247e-03, -7.1713e-03,  1.1359e-02,  7.3542e-03,  6.2848e-03,\n                       1.1315e-03, -9.3433e-03,  1.5573e-03,  2.1615e-02,  1.5572e-02,\n                       5.5938e-03,  5.6072e-03,  4.2924e-03,  4.6647e-03, -5.7760e-03,\n                      -2.4097e-04,  1.1999e-02,  4.8271e-03,  4.6796e-03,  2.1520e-02,\n                       8.2732e-03,  6.0123e-03,  5.5142e-03,  8.7275e-03,  1.5135e-02,\n                       6.5944e-03,  5.8353e-03,  1.4577e-02,  2.2841e-03,  5.9913e-03,\n                      -1.6714e-02,  1.5067e-02,  3.3433e-03,  5.1037e-03,  8.2408e-03,\n                       1.3740e-02,  7.8210e-03,  1.5095e-02,  3.5819e-03, -8.0414e-03,\n                       9.6777e-03,  8.8312e-03, -2.1516e-03,  5.8577e-03,  4.2446e-03,\n                       7.9761e-03,  1.0870e-02,  5.4885e-03,  1.1858e-02,  1.4177e-02,\n                       3.3224e-03, -3.9424e-04,  5.9704e-03, -1.0368e-03, -7.0068e-04,\n                       4.7409e-03,  9.2333e-03, -2.8326e-03,  6.1248e-03,  1.0726e-02,\n                      -4.6764e-03, -1.4223e-02,  5.3103e-03,  6.3637e-03,  1.7889e-02,\n                       4.1875e-03, -1.0991e-03,  9.7235e-03,  1.4793e-02, -1.3577e-02,\n                       1.2898e-02,  1.8470e-03,  1.8432e-02,  2.6971e-03,  6.9354e-03,\n                       3.2598e-04,  1.0614e-02, -3.0122e-03, -8.6167e-03,  1.0016e-02,\n                       7.2768e-03,  1.3332e-02,  1.0278e-02,  8.3826e-03,  8.0632e-03,\n                       6.1904e-03,  5.0412e-03,  6.2193e-03,  1.2392e-03, -1.3277e-03,\n                       1.0656e-02,  1.0794e-02,  1.8575e-03,  6.0470e-03,  1.5418e-02,\n                      -2.1556e-03,  2.2473e-02,  1.6429e-02,  1.6354e-02,  1.7115e-02,\n                       1.5950e-03,  8.7438e-03, -1.2510e-02,  4.0747e-03,  9.9341e-03,\n                       9.7133e-03,  1.1614e-02, -7.8708e-04,  7.6011e-03,  6.0641e-03,\n                       7.1787e-03,  2.5677e-03,  1.6120e-02,  2.7974e-03,  1.7038e-03,\n                       1.2634e-02,  3.3191e-03,  3.7477e-03,  1.3246e-02,  8.3140e-03,\n                       6.1698e-03, -8.1395e-03, -1.6029e-03,  2.8262e-02,  1.9504e-02,\n                       4.4171e-03,  5.8607e-04,  6.3725e-03,  1.2017e-02,  7.5251e-04,\n                       1.0322e-02,  1.3695e-05,  1.4474e-02,  4.4732e-03,  1.3578e-02,\n                      -9.4972e-04,  7.3473e-03, -3.1719e-03,  1.3425e-02,  7.1577e-03,\n                       8.9096e-03,  4.7802e-03,  2.0985e-03, -1.1745e-02, -9.2216e-03,\n                       1.8780e-02,  2.2160e-02,  1.4048e-02,  1.7082e-02,  3.3521e-03,\n                       1.1426e-03], dtype=torch.float64)),\n             ('6.16.convs.2.1.running_mean',\n              tensor([ 6.1306e-01, -6.2078e-03, -1.8435e-01,  6.5953e-02,  1.9692e-02,\n                       6.8546e-01,  4.8946e-01,  4.5521e-01,  1.0915e-01,  2.0139e-01,\n                      -1.1507e-01, -1.9916e-01,  1.0243e-01,  2.0044e-01,  7.8897e-03,\n                      -1.1108e+00,  3.9688e-01,  1.3976e-01,  3.9393e-01, -2.2625e-01,\n                       2.1822e-01, -7.7434e-01,  3.6786e-02, -7.0005e-01,  8.0393e-02,\n                       2.4291e-01, -2.2736e-01, -1.3886e-01,  3.3794e-01,  5.1980e-01,\n                      -4.9370e-01, -2.7451e-01, -1.1982e-01,  4.4666e-01,  1.9052e-01,\n                      -2.3208e-01, -2.6255e-02,  6.3425e-01, -6.0396e-02, -1.0914e-01,\n                       3.8388e-01, -1.2205e-01,  2.3332e-01,  5.0189e-01,  1.4234e-01,\n                       5.5909e-02, -1.9562e-01, -4.9734e-01,  1.0565e+00,  6.2301e-01,\n                       1.2532e-01,  2.3393e-01, -3.9227e-01,  1.1734e-01, -4.2162e-04,\n                      -8.7809e-01, -2.9131e-01,  1.2416e-01, -9.1970e-02, -4.9564e-02,\n                      -5.9136e-02, -1.5892e-01,  3.1150e-01,  3.0159e-01,  8.7612e-01,\n                      -3.6963e-01,  6.2932e-01, -2.7327e-01, -1.5035e-01,  6.2895e-01,\n                      -8.6141e-01,  2.2655e-01,  6.6538e-02, -3.6014e-01,  4.1273e-01,\n                       9.6808e-02, -5.0759e-02,  3.4167e-01,  3.7929e-02,  5.1091e-01,\n                      -2.6523e-01,  3.4326e-01, -2.5974e-02,  3.8641e-01,  1.7151e-01,\n                      -6.7585e-02, -7.5243e-01, -7.6153e-02,  4.0592e-01,  2.8271e-01,\n                      -3.0570e-01, -6.0099e-01,  2.9698e-01, -3.2425e-01,  2.1180e-01,\n                       8.7377e-03, -5.2692e-01, -5.1686e-01,  4.1962e-02,  2.2891e-01,\n                      -8.2175e-01, -1.0140e+00,  1.9329e-01, -2.7158e-01, -2.8176e-01,\n                      -8.4360e-02, -7.1051e-01, -8.5633e-01,  5.0236e-01,  1.4016e-01,\n                       2.2585e-01, -5.8610e-01, -2.1127e-02,  4.5338e-01, -4.3334e-01,\n                      -4.8692e-02,  2.3909e-01, -9.4583e-01,  3.4418e-01,  3.8721e-01,\n                      -2.0788e-01,  9.4788e-02,  6.5160e-01, -1.3896e-01, -3.3092e-01,\n                       5.7804e-01,  1.5541e-01, -4.3961e-02,  4.8244e-01, -3.2292e-01,\n                       6.1213e-02, -2.8619e-01, -6.0153e-01, -2.5566e-01, -1.8018e-01,\n                      -2.5891e-01,  4.9818e-02,  3.5354e-01, -3.6644e-02,  2.4181e-01,\n                      -1.9632e-01,  9.1498e-01,  1.2314e-01,  5.2392e-01, -1.4135e-01,\n                      -2.3385e-01,  3.5498e-01,  2.6323e-01,  1.3812e-01,  4.2290e-01,\n                       1.3710e-01,  1.4288e+00,  1.6401e-01,  6.4494e-01, -4.8343e-01,\n                      -2.2728e-01, -1.3081e-01,  1.9859e-01,  5.1851e-01,  1.7820e-01,\n                       6.8328e-02, -2.1686e-01, -1.3230e-01,  1.6343e-01, -2.3534e-01,\n                       8.2609e-01,  6.6073e-01, -6.2572e-01, -8.0333e-01, -1.3264e-01,\n                       5.9903e-01, -3.0722e-02,  3.3766e-01,  5.1450e-02,  5.1100e-01,\n                       4.3058e-01, -5.0604e-01, -3.3865e-01, -2.2567e-01, -1.7736e-01,\n                      -1.4153e-02,  3.4312e-01,  1.0110e+00,  1.6017e-01, -2.2221e-01,\n                      -1.6938e-01, -5.8114e-01, -5.0691e-01,  3.6252e-01,  3.0749e-02,\n                      -1.3048e-01, -5.6993e-01, -3.5579e-01, -3.9806e-01, -8.5054e-01,\n                       9.7509e-03,  8.1117e-02, -4.4937e-01,  6.6542e-01,  4.4782e-01,\n                      -2.6690e-02,  1.2220e-01,  2.6535e-01, -7.1831e-01,  7.6122e-02,\n                      -2.0710e-01,  1.3585e-02, -1.8125e-01, -9.8350e-02,  4.3923e-01,\n                       4.4509e-01, -1.0687e-01,  3.3277e-01,  5.9799e-01,  7.0560e-01,\n                      -5.7123e-02,  6.0254e-02, -9.3929e-02,  2.2802e-01, -4.0039e-02,\n                       1.5842e-02, -8.7733e-01,  6.4256e-02, -7.1610e-02, -3.6014e-01,\n                      -1.9152e-01, -7.4374e-01,  2.2500e-02,  6.1319e-02, -3.0701e-01,\n                      -2.2476e-01,  5.4270e-02,  4.3336e-01, -4.5984e-01,  4.4515e-02,\n                       3.7807e-01,  1.5538e-01,  6.2516e-01,  1.8614e-01,  3.7799e-01,\n                       6.4289e-01,  8.5381e-01,  3.7553e-01, -3.1792e-01,  5.8097e-01,\n                      -8.7172e-02, -3.8625e-02, -5.6988e-02,  3.7833e-02,  2.4193e-01,\n                      -2.4288e-01,  4.2301e-01, -2.2027e-01, -3.0302e-01,  1.0070e-01,\n                       9.8010e-01], dtype=torch.float64)),\n             ('6.16.convs.2.1.running_var',\n              tensor([0.3133, 0.1922, 0.3422, 0.4176, 0.3093, 0.2284, 0.3108, 0.5188, 0.2302,\n                      0.4271, 0.2768, 0.3147, 0.0466, 0.4343, 0.4955, 0.4783, 0.2291, 0.4844,\n                      0.1740, 0.5771, 0.2095, 0.3850, 0.1939, 0.3683, 0.3818, 0.2451, 0.1651,\n                      0.3108, 0.1634, 0.3742, 0.4722, 0.7049, 0.0644, 0.4734, 0.2857, 0.3992,\n                      0.3182, 0.2040, 0.3829, 0.2944, 0.6267, 0.3199, 0.3212, 0.5727, 0.2603,\n                      0.1812, 0.7401, 0.2705, 0.3074, 0.3129, 0.1301, 0.4902, 0.2484, 0.2459,\n                      0.2344, 0.4069, 0.6537, 0.4933, 0.5320, 0.1483, 0.2342, 0.1491, 0.1204,\n                      0.3233, 0.6566, 0.4202, 0.4079, 0.3538, 0.2616, 0.4105, 0.7248, 0.3265,\n                      0.0663, 0.4411, 0.5530, 0.0937, 0.4070, 0.3388, 0.4188, 0.3898, 0.5769,\n                      0.1645, 0.3725, 0.4534, 0.1581, 0.5219, 0.2435, 0.4300, 0.5928, 0.3090,\n                      0.2796, 0.3137, 0.3389, 0.3986, 0.3343, 0.2211, 0.4333, 0.5383, 0.1850,\n                      0.1930, 0.4125, 0.5704, 0.3220, 0.2697, 0.4498, 0.5880, 0.4425, 0.4711,\n                      0.5014, 0.1203, 0.3135, 0.3679, 0.3669, 0.2458, 0.5322, 0.5680, 0.1994,\n                      0.2871, 0.2653, 0.4116, 0.2745, 0.4457, 0.5028, 0.4277, 0.2836, 0.4855,\n                      0.1778, 0.2352, 0.4457, 0.4371, 0.0583, 0.3205, 0.6673, 0.1172, 0.2534,\n                      0.0734, 0.4079, 0.3415, 0.5969, 0.1359, 0.3046, 0.3069, 0.3308, 0.2062,\n                      0.2927, 0.5014, 0.1463, 0.5133, 0.1067, 0.7088, 0.2917, 0.3569, 0.3563,\n                      0.4550, 0.4520, 0.1508, 0.3734, 0.1910, 0.4831, 0.3506, 0.2492, 0.1979,\n                      0.5237, 0.1145, 0.5266, 0.4935, 0.4422, 0.2838, 0.3637, 0.4010, 0.1738,\n                      0.0760, 0.1718, 0.2479, 0.5964, 0.2508, 0.4666, 0.3105, 0.2718, 0.3246,\n                      0.2973, 0.2534, 0.4928, 0.4504, 0.2600, 0.4325, 0.3286, 0.2124, 0.2420,\n                      0.6731, 0.2501, 0.2855, 0.3022, 0.5669, 0.3630, 0.4219, 0.4059, 0.2435,\n                      0.2839, 0.4457, 0.1439, 0.3331, 0.3270, 0.3455, 0.1955, 0.6198, 0.0509,\n                      0.0718, 0.0685, 0.4660, 0.0890, 0.3144, 0.3449, 0.3180, 0.1373, 0.1355,\n                      0.3570, 0.1986, 0.3384, 0.5744, 0.2798, 0.3902, 0.1597, 0.1455, 0.3579,\n                      0.6040, 0.2347, 0.1471, 0.6010, 0.3557, 0.2532, 0.2359, 0.3658, 0.5241,\n                      0.3923, 0.4290, 0.1312, 0.3150, 0.1041, 0.3859, 0.4342, 0.2519, 0.3787,\n                      0.2352, 0.4382, 0.4002, 0.4378, 0.4208, 0.0396, 0.5058, 0.2718, 0.4559,\n                      0.0972, 0.4081, 0.1595, 0.3917], dtype=torch.float64)),\n             ('6.16.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.16.convpath.0.0.0.weight',\n              tensor([[[-0.0849],\n                       [ 0.0370],\n                       [ 0.0660],\n                       ...,\n                       [ 0.0349],\n                       [ 0.0190],\n                       [ 0.0572]],\n              \n                      [[ 0.1340],\n                       [-0.0127],\n                       [-0.1204],\n                       ...,\n                       [ 0.0607],\n                       [ 0.0385],\n                       [ 0.0542]],\n              \n                      [[-0.0033],\n                       [ 0.0583],\n                       [ 0.0407],\n                       ...,\n                       [-0.0902],\n                       [-0.1398],\n                       [-0.0860]],\n              \n                      ...,\n              \n                      [[-0.1042],\n                       [-0.1574],\n                       [-0.0387],\n                       ...,\n                       [ 0.0432],\n                       [ 0.0390],\n                       [ 0.0041]],\n              \n                      [[ 0.0076],\n                       [ 0.0651],\n                       [-0.0265],\n                       ...,\n                       [ 0.1583],\n                       [ 0.1733],\n                       [ 0.0527]],\n              \n                      [[ 0.1249],\n                       [-0.0949],\n                       [-0.0671],\n                       ...,\n                       [-0.1007],\n                       [-0.0337],\n                       [-0.0539]]], dtype=torch.float64)),\n             ('6.16.convpath.0.0.1.weight',\n              tensor([1.0204, 0.9983, 0.9722, 0.9709, 0.9496, 0.9767, 0.9625, 0.9766, 0.9750,\n                      1.0028, 0.9789, 0.9604, 0.9579, 0.9582, 0.9726, 0.9695, 0.9591, 0.9919,\n                      0.9730, 0.9733, 0.9822, 0.9740, 0.9776, 0.9634, 0.9870, 0.9621, 0.9761,\n                      0.9525, 0.9793, 0.9947, 0.9793, 0.9809, 1.0071, 0.9582, 0.9795, 0.9642,\n                      0.9817, 0.9942, 0.9596, 0.9613, 0.9832, 0.9603, 0.9715, 0.9670, 0.9693,\n                      0.9862, 0.9944, 0.9899, 0.9428, 0.9702, 1.0020, 0.9859, 0.9851, 0.9738,\n                      0.9715, 0.9766, 0.9613, 0.9507, 0.9693, 0.9697, 0.9631, 0.9612, 0.9928,\n                      0.9599], dtype=torch.float64)),\n             ('6.16.convpath.0.0.1.bias',\n              tensor([ 3.7872e-02,  1.7528e-02,  9.4606e-04,  6.7585e-03, -9.2415e-03,\n                       7.4245e-03,  3.3601e-03, -5.3582e-03,  8.7345e-03,  1.9513e-02,\n                      -9.6278e-04, -1.5136e-02, -5.4815e-03, -1.4322e-02,  3.6464e-03,\n                       8.7829e-03, -4.4805e-03,  2.0636e-02, -3.5340e-03, -8.0657e-03,\n                       1.6374e-02, -4.2637e-03,  6.8740e-03,  4.2311e-04,  6.6076e-04,\n                      -4.9033e-03,  1.1023e-02, -1.3583e-02,  1.1037e-02,  6.1770e-03,\n                       8.7457e-03,  9.7177e-03,  1.3991e-02,  1.2460e-02,  4.3055e-04,\n                       1.4306e-02,  1.7489e-02, -8.1642e-05,  2.2225e-03,  1.2362e-03,\n                      -5.1253e-03, -1.2712e-02,  1.0149e-02, -1.7798e-03,  3.5995e-03,\n                       9.3915e-03,  1.9896e-02,  1.2670e-02, -3.2209e-02, -3.8582e-03,\n                       3.0761e-02,  9.0579e-03,  2.9330e-02,  1.1309e-02,  3.7868e-03,\n                      -2.3350e-03,  3.4725e-03, -3.8650e-03,  3.3181e-03, -6.6589e-04,\n                      -5.7606e-03,  1.2657e-03,  1.0486e-02, -1.4904e-02],\n                     dtype=torch.float64)),\n             ('6.16.convpath.0.0.1.running_mean',\n              tensor([ 0.2091, -0.3048, -1.1237,  1.1509,  0.7080, -0.8807, -0.1687, -0.8891,\n                      -0.9276,  0.6444,  0.3535,  0.6074,  1.7552,  0.6510,  0.1953, -0.8793,\n                      -0.4890, -0.5889, -0.0730, -0.5934, -0.1562, -0.1691, -0.0669, -0.3359,\n                      -0.3484,  0.2112,  0.7949,  0.6647,  0.8641,  0.3263, -0.4912,  0.1529,\n                      -0.0412, -1.2238,  0.2319, -0.7661, -0.0840, -0.1459, -0.0771,  0.6293,\n                       0.3002,  0.2458, -0.4420,  0.4570, -1.0461,  0.1204, -1.3301, -0.3564,\n                      -0.0401,  1.1795,  0.2219, -0.0931, -0.0042, -0.3307,  0.3959,  0.6692,\n                      -0.8969,  0.4309,  0.4061, -1.0083, -0.9263, -0.9333, -0.3082, -0.1359],\n                     dtype=torch.float64)),\n             ('6.16.convpath.0.0.1.running_var',\n              tensor([0.1525, 0.1737, 0.1394, 0.2540, 0.4210, 0.1965, 0.2169, 0.2674, 0.1344,\n                      0.0966, 0.1535, 0.2333, 1.5348, 1.0286, 0.2110, 0.1943, 0.2559, 0.1814,\n                      0.1055, 0.1294, 0.2185, 0.1433, 0.1353, 0.1014, 0.1175, 0.1602, 0.1496,\n                      0.1953, 0.1265, 0.2047, 0.1056, 0.3393, 0.1275, 1.1701, 0.1572, 0.1764,\n                      0.5158, 0.3284, 0.1791, 1.6581, 0.2850, 0.2629, 0.3453, 0.1870, 0.7823,\n                      0.4712, 0.2041, 0.1751, 0.1437, 0.4975, 0.1308, 0.1125, 0.1751, 0.1249,\n                      0.9092, 0.1291, 0.3944, 0.4786, 0.3618, 0.1770, 0.2023, 0.3866, 0.1370,\n                      0.6383], dtype=torch.float64)),\n             ('6.16.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.16.convpath.0.1.0.weight',\n              tensor([[[-0.0495, -0.0257,  0.0729, -0.0628,  0.0664],\n                       [ 0.0872,  0.0761, -0.1176, -0.0915, -0.0315],\n                       [ 0.0615,  0.0835, -0.0732,  0.0728,  0.0103],\n                       ...,\n                       [-0.0311, -0.0073, -0.0252, -0.0855,  0.1494],\n                       [-0.0005, -0.0151,  0.1097,  0.0150, -0.0251],\n                       [-0.0480,  0.1253,  0.0874, -0.0400, -0.0724]],\n              \n                      [[ 0.0125,  0.0584,  0.2318,  0.0178,  0.1433],\n                       [ 0.0839, -0.0259, -0.0564,  0.0386, -0.0003],\n                       [ 0.1535,  0.0124, -0.0149,  0.1117, -0.0777],\n                       ...,\n                       [-0.0654, -0.0153, -0.0812,  0.0630, -0.1094],\n                       [-0.0259,  0.0435,  0.0299,  0.0790, -0.1026],\n                       [ 0.0499, -0.0335,  0.0372, -0.0486, -0.0005]],\n              \n                      [[ 0.0953,  0.0963,  0.0318,  0.0819, -0.0382],\n                       [-0.1328,  0.0064, -0.0100,  0.0602,  0.0263],\n                       [-0.1218, -0.0080, -0.0063, -0.0373,  0.0640],\n                       ...,\n                       [ 0.0971,  0.0049, -0.0025, -0.0477, -0.0630],\n                       [-0.0736, -0.2161, -0.0748,  0.0991,  0.0707],\n                       [ 0.0634, -0.0100,  0.0149,  0.0701, -0.0062]],\n              \n                      ...,\n              \n                      [[-0.1141,  0.0655,  0.0645,  0.0988, -0.0535],\n                       [ 0.0189,  0.0011,  0.0627,  0.0571, -0.0065],\n                       [-0.0256, -0.0695,  0.0029, -0.0065, -0.0278],\n                       ...,\n                       [ 0.0783, -0.0260,  0.0638,  0.0338,  0.0096],\n                       [ 0.0115,  0.0455,  0.0435,  0.0109, -0.0641],\n                       [ 0.0210, -0.0198,  0.0508,  0.0690, -0.0831]],\n              \n                      [[-0.0371, -0.0980, -0.1335, -0.0326,  0.1524],\n                       [-0.0761, -0.0580, -0.0129, -0.0514, -0.0040],\n                       [-0.1499, -0.0150, -0.0092, -0.1002, -0.1156],\n                       ...,\n                       [-0.1336, -0.0441,  0.0788,  0.0535,  0.0330],\n                       [ 0.0216, -0.1529,  0.0017,  0.1496,  0.0180],\n                       [ 0.0853, -0.0043, -0.0247,  0.0088,  0.0530]],\n              \n                      [[ 0.0390, -0.0798,  0.0299,  0.0353,  0.0489],\n                       [ 0.0220, -0.1562, -0.0673, -0.1119,  0.1118],\n                       [ 0.0406, -0.0420,  0.0609,  0.1055, -0.0913],\n                       ...,\n                       [-0.1312, -0.0054,  0.0705, -0.0770,  0.0593],\n                       [-0.0046, -0.0738,  0.1191,  0.0335,  0.0504],\n                       [-0.0950,  0.1289,  0.0746,  0.0174, -0.0401]]], dtype=torch.float64)),\n             ('6.16.convpath.0.1.1.weight',\n              tensor([0.9521, 0.9663, 0.9419, 0.9671, 1.0194, 0.9439, 0.9950, 0.9539, 0.9640,\n                      0.9785, 0.9245, 0.9682, 0.9661, 0.9759, 0.9984, 0.9626, 0.9533, 0.9649,\n                      0.9754, 0.9531, 0.9816, 0.9421, 1.0038, 0.9764, 0.9616, 0.9579, 0.9554,\n                      0.9736, 0.9662, 0.9372, 0.9691, 0.9603, 0.9606, 0.9221, 0.9600, 0.9773,\n                      0.9938, 0.9632, 1.0066, 0.9742, 0.9760, 0.9704, 1.0337, 0.9769, 0.9782,\n                      0.9478, 0.9541, 0.9743, 0.9941, 0.9371, 0.9572, 0.9273, 1.0007, 0.9460,\n                      0.9810, 0.9513, 0.9822, 0.9660, 0.9393, 0.9559, 0.9687, 0.9425, 0.9770,\n                      0.9621], dtype=torch.float64)),\n             ('6.16.convpath.0.1.1.bias',\n              tensor([-0.0354,  0.0144, -0.0082, -0.0069,  0.0244, -0.0049,  0.0041, -0.0045,\n                      -0.0102, -0.0095, -0.0307,  0.0032,  0.0032,  0.0102, -0.0125, -0.0081,\n                      -0.0010, -0.0095, -0.0050, -0.0092,  0.0172,  0.0005, -0.0234,  0.0026,\n                      -0.0236, -0.0175,  0.0005, -0.0204,  0.0004, -0.0250,  0.0141, -0.0213,\n                       0.0062, -0.0177,  0.0106,  0.0018,  0.0005, -0.0092,  0.0218, -0.0095,\n                       0.0106,  0.0002,  0.0192, -0.0051, -0.0242, -0.0034, -0.0052,  0.0131,\n                       0.0257, -0.0280, -0.0126, -0.0361,  0.0197, -0.0236,  0.0092, -0.0268,\n                      -0.0272, -0.0179, -0.0069, -0.0019, -0.0130, -0.0106,  0.0071, -0.0072],\n                     dtype=torch.float64)),\n             ('6.16.convpath.0.1.1.running_mean',\n              tensor([ 0.3796, -0.3983, -0.7651, -0.0324,  0.3357,  0.0143,  0.0337, -0.5383,\n                       0.0723, -0.3463,  0.5091,  0.3380,  0.0919, -0.0493, -0.2716, -0.0137,\n                      -0.0227,  0.4798, -0.4945,  0.1577, -0.4114, -0.4955, -0.0542, -0.2214,\n                      -0.1997,  0.4557, -0.4343, -0.0194, -1.2919, -0.1384,  0.5426,  0.7191,\n                       0.2690, -1.1025, -0.2469, -0.0124,  0.4420, -0.0629, -0.0067,  0.3446,\n                       0.0428, -0.7081,  0.0539,  0.6643,  0.3667, -0.6925, -0.0742, -0.0649,\n                       0.0947, -0.4319,  0.2873,  0.3959, -0.1346,  0.0755, -0.7097, -0.0335,\n                       0.9937, -0.1613,  0.0135, -0.5595,  0.4577, -0.3138, -0.9171, -0.2414],\n                     dtype=torch.float64)),\n             ('6.16.convpath.0.1.1.running_var',\n              tensor([0.5643, 0.6416, 0.9706, 0.5738, 0.5148, 0.5681, 0.6402, 0.6911, 0.5865,\n                      0.4405, 0.6877, 0.5318, 0.6561, 0.7423, 0.5779, 0.4612, 0.6561, 0.5076,\n                      0.6750, 0.9432, 0.4387, 0.8454, 0.7202, 0.3461, 0.5043, 0.4775, 0.5518,\n                      0.6444, 0.8404, 0.5568, 0.5134, 0.4892, 0.4832, 0.6589, 1.0680, 0.5413,\n                      0.4567, 0.7856, 0.4941, 0.6084, 0.5559, 0.5024, 0.6621, 0.5626, 0.3897,\n                      0.6590, 0.5006, 0.8367, 0.4844, 0.7295, 1.0898, 0.5473, 0.7793, 0.5465,\n                      0.4796, 0.7566, 0.5572, 0.6338, 0.5360, 0.9785, 0.7664, 1.0578, 0.5516,\n                      0.6342], dtype=torch.float64)),\n             ('6.16.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.16.convpath.0.2.0.weight',\n              tensor([[[ 0.0930],\n                       [ 0.0412],\n                       [-0.0414],\n                       ...,\n                       [ 0.0876],\n                       [-0.0330],\n                       [-0.0239]],\n              \n                      [[ 0.0033],\n                       [ 0.1032],\n                       [ 0.0673],\n                       ...,\n                       [-0.0214],\n                       [ 0.0200],\n                       [-0.0275]],\n              \n                      [[ 0.0295],\n                       [-0.0573],\n                       [ 0.1216],\n                       ...,\n                       [ 0.0039],\n                       [ 0.0025],\n                       [-0.3180]],\n              \n                      ...,\n              \n                      [[-0.1113],\n                       [-0.4144],\n                       [-0.0549],\n                       ...,\n                       [ 0.2064],\n                       [ 0.2598],\n                       [ 0.0462]],\n              \n                      [[ 0.0325],\n                       [-0.0147],\n                       [ 0.0393],\n                       ...,\n                       [-0.0517],\n                       [ 0.0677],\n                       [-0.0752]],\n              \n                      [[ 0.0882],\n                       [ 0.0162],\n                       [ 0.1092],\n                       ...,\n                       [ 0.1672],\n                       [ 0.0101],\n                       [ 0.0132]]], dtype=torch.float64)),\n             ('6.16.convpath.0.2.1.weight',\n              tensor([-4.2887e-03,  5.3547e-03,  2.8098e-02, -4.1148e-02,  8.9659e-03,\n                       1.4052e-02,  1.7672e-02, -1.5002e-02,  2.2406e-02,  1.4576e-02,\n                       1.8012e-02,  1.5807e-02,  8.0291e-03,  2.1013e-02, -3.6874e-02,\n                       3.1353e-02, -2.3360e-02,  1.6778e-02, -1.3213e-02,  2.6153e-02,\n                       1.6228e-02,  4.0400e-02, -2.8806e-03,  9.2256e-03, -1.0633e-02,\n                      -1.7746e-02, -3.0937e-04, -2.2479e-02, -9.0966e-03,  1.6908e-02,\n                       1.0458e-02,  3.0138e-02,  1.4046e-03,  4.1998e-02, -8.7236e-03,\n                      -3.0711e-02,  5.2909e-03, -1.8230e-03,  3.3795e-02, -2.7628e-02,\n                      -3.0381e-02, -8.2002e-03, -8.7711e-03,  2.1332e-02,  2.7518e-03,\n                       2.8232e-03,  1.2952e-02, -1.8517e-02, -1.1196e-04,  3.3431e-03,\n                       3.9941e-03,  2.9208e-02,  1.6043e-02,  1.7105e-02, -3.2334e-03,\n                       1.2888e-03, -1.2872e-02,  4.3753e-02,  3.0307e-02,  2.2347e-03,\n                       1.3201e-02,  1.2301e-02, -4.7794e-03, -6.8303e-03, -1.6982e-02,\n                      -7.4266e-03, -2.1852e-02,  2.3630e-02, -1.6068e-02, -6.8652e-03,\n                      -1.6146e-02, -2.3270e-02,  3.4155e-03,  7.5641e-03, -4.4102e-02,\n                       7.8778e-03, -3.1041e-02, -8.7155e-03, -3.3446e-02, -1.2616e-02,\n                      -1.3742e-02,  1.7855e-03,  9.3243e-03,  2.0487e-02, -8.5238e-03,\n                       4.2211e-02, -4.9792e-03,  1.0958e-02,  1.9776e-02,  3.1619e-04,\n                      -5.9298e-03, -1.3137e-02,  2.5259e-02, -2.8567e-02, -4.5968e-03,\n                       1.3717e-02,  1.4659e-02,  1.9317e-02,  4.4472e-03,  1.0376e-02,\n                       8.2648e-03, -3.5143e-02, -2.3706e-02, -1.9286e-03, -1.1590e-02,\n                      -2.5200e-02, -9.1530e-03, -9.3763e-03, -3.7565e-02,  2.7193e-03,\n                      -2.4676e-02, -1.6890e-02, -2.7430e-02,  9.2596e-03, -2.7572e-02,\n                       1.5723e-02, -6.4210e-03,  1.3429e-02,  1.3513e-02, -7.3940e-03,\n                      -7.8988e-03, -1.3452e-02, -1.7926e-02, -3.2606e-02, -1.9435e-02,\n                       4.6131e-04, -1.0693e-02, -1.7958e-02, -2.9680e-02,  1.3550e-02,\n                      -6.2280e-03,  7.3637e-03, -2.6189e-02,  9.6368e-03, -4.1867e-03,\n                       2.0588e-03, -3.4247e-02,  1.5086e-02,  2.2798e-02,  5.0421e-06,\n                       2.2978e-02,  1.0273e-02,  2.1271e-02, -5.8057e-03, -5.8482e-03,\n                       1.0571e-02,  1.5283e-02,  2.4695e-02, -1.4543e-02,  1.6483e-02,\n                       3.1754e-03, -7.9288e-03,  1.1269e-02, -2.2481e-02, -1.2273e-02,\n                      -4.5980e-03, -1.9678e-02, -1.4204e-02, -1.3493e-02, -2.5066e-02,\n                       4.3385e-03, -6.1403e-03,  1.4905e-02, -7.7507e-04,  2.5668e-02,\n                       9.5060e-03, -1.1172e-02, -1.9561e-02,  2.6481e-02, -4.9491e-02,\n                       7.9912e-03, -7.5990e-03,  6.6821e-03,  1.3816e-02,  2.3499e-02,\n                      -2.6853e-03,  1.5853e-02,  3.8100e-02, -1.3817e-02,  1.1213e-02,\n                      -1.1415e-02,  1.6445e-02, -9.3296e-03,  1.3714e-02,  6.2017e-03,\n                      -1.7782e-02,  3.5762e-02, -2.9937e-02, -2.7340e-03, -1.9184e-02,\n                       5.8794e-05,  1.2618e-02, -6.5432e-03, -2.5166e-02, -2.2505e-02,\n                       1.5141e-02,  2.1169e-02, -1.0039e-02, -4.4835e-03,  2.2034e-02,\n                       1.0826e-03,  9.1657e-03,  8.5009e-03, -1.1663e-02, -8.6444e-03,\n                       1.0814e-02,  2.4179e-03, -1.3879e-02,  6.6626e-03, -3.1775e-02,\n                      -1.1022e-03,  1.3412e-02,  1.0795e-02,  1.0487e-02,  8.4371e-03,\n                       1.0807e-02, -7.4968e-03, -1.3240e-02, -1.0706e-02, -2.7411e-02,\n                      -1.4444e-02, -2.9956e-02,  1.0542e-02, -4.6799e-03,  9.1211e-03,\n                      -1.8913e-02, -2.4750e-03,  4.2870e-03, -1.7951e-02, -1.7830e-02,\n                      -1.9307e-02,  3.8218e-03, -8.0723e-03,  1.3052e-02,  1.8856e-02,\n                       2.1231e-02,  1.7566e-03,  8.4203e-03, -2.1740e-03,  7.3546e-03,\n                       4.1479e-02,  8.6095e-03, -3.2123e-02,  6.4610e-03, -3.0998e-02,\n                       3.0812e-02, -1.4489e-02,  2.4966e-02,  1.9497e-03, -3.1294e-02,\n                      -1.2307e-02, -6.4975e-03, -3.1969e-03,  1.2752e-02, -6.7522e-03,\n                      -6.9401e-03], dtype=torch.float64)),\n             ('6.16.convpath.0.2.1.bias',\n              tensor([ 1.3239e-04,  5.9952e-03,  9.3251e-03,  1.4057e-02, -4.1340e-04,\n                       5.8669e-03,  5.9947e-03, -3.6517e-03,  1.1120e-02,  1.6620e-02,\n                       1.4444e-02, -7.4460e-03,  3.9039e-03, -7.1543e-03,  8.7027e-03,\n                       4.4965e-03,  2.6014e-02,  9.9015e-04,  1.2080e-02, -2.5601e-04,\n                      -1.0805e-02,  2.4438e-03,  8.3434e-03,  6.9587e-03,  9.6617e-03,\n                      -2.1555e-02,  6.7647e-03,  1.2255e-02,  1.2894e-02, -4.9601e-03,\n                      -3.4266e-03,  1.0724e-02,  4.4924e-03,  2.1441e-02,  8.8721e-03,\n                       1.1025e-02, -6.1305e-03,  1.0371e-02,  2.1027e-02,  6.2433e-03,\n                       2.8081e-03,  7.2477e-03, -6.6896e-03, -4.0474e-03,  7.3500e-03,\n                      -1.6637e-02,  1.6194e-02,  1.0437e-02, -1.3652e-02, -4.1064e-04,\n                       1.1147e-02,  2.7983e-03,  3.6667e-03,  2.0729e-02,  3.1084e-04,\n                       1.3225e-02,  1.0156e-02,  2.6511e-03,  1.2527e-02, -4.0934e-03,\n                      -4.0890e-04,  1.0625e-03,  8.7474e-03,  9.1291e-03, -7.7499e-03,\n                       1.9510e-04, -7.9020e-03,  1.2744e-02,  1.5976e-02, -1.4377e-02,\n                       7.3737e-03, -2.4469e-03, -7.3329e-04, -7.4612e-03,  1.3656e-02,\n                       8.3042e-03,  2.3329e-04,  9.6921e-03,  2.4927e-04,  1.7013e-02,\n                       4.6550e-03, -7.8937e-03,  1.3986e-02,  3.6012e-03, -5.0575e-03,\n                       1.7210e-02, -8.2577e-04,  1.0912e-02,  1.3911e-02, -1.0697e-03,\n                       7.5105e-04,  1.1527e-02,  1.0212e-02,  1.4002e-02,  8.1182e-03,\n                      -6.0427e-03,  1.4571e-02,  5.6991e-03,  1.9976e-02,  9.0048e-03,\n                       2.3133e-02,  1.6251e-02,  6.4168e-03,  1.2667e-02,  6.1930e-03,\n                       3.4247e-03, -7.1713e-03,  1.1359e-02,  7.3542e-03,  6.2848e-03,\n                       1.1315e-03, -9.3433e-03,  1.5573e-03,  2.1615e-02,  1.5572e-02,\n                       5.5938e-03,  5.6072e-03,  4.2924e-03,  4.6647e-03, -5.7760e-03,\n                      -2.4097e-04,  1.1999e-02,  4.8271e-03,  4.6796e-03,  2.1520e-02,\n                       8.2732e-03,  6.0123e-03,  5.5142e-03,  8.7275e-03,  1.5135e-02,\n                       6.5944e-03,  5.8353e-03,  1.4577e-02,  2.2841e-03,  5.9913e-03,\n                      -1.6714e-02,  1.5067e-02,  3.3433e-03,  5.1037e-03,  8.2408e-03,\n                       1.3740e-02,  7.8210e-03,  1.5095e-02,  3.5819e-03, -8.0414e-03,\n                       9.6777e-03,  8.8312e-03, -2.1516e-03,  5.8577e-03,  4.2446e-03,\n                       7.9761e-03,  1.0870e-02,  5.4885e-03,  1.1858e-02,  1.4177e-02,\n                       3.3224e-03, -3.9424e-04,  5.9704e-03, -1.0368e-03, -7.0068e-04,\n                       4.7409e-03,  9.2333e-03, -2.8326e-03,  6.1248e-03,  1.0726e-02,\n                      -4.6764e-03, -1.4223e-02,  5.3103e-03,  6.3637e-03,  1.7889e-02,\n                       4.1875e-03, -1.0991e-03,  9.7235e-03,  1.4793e-02, -1.3577e-02,\n                       1.2898e-02,  1.8470e-03,  1.8432e-02,  2.6971e-03,  6.9354e-03,\n                       3.2598e-04,  1.0614e-02, -3.0122e-03, -8.6167e-03,  1.0016e-02,\n                       7.2768e-03,  1.3332e-02,  1.0278e-02,  8.3826e-03,  8.0632e-03,\n                       6.1904e-03,  5.0412e-03,  6.2193e-03,  1.2392e-03, -1.3277e-03,\n                       1.0656e-02,  1.0794e-02,  1.8575e-03,  6.0470e-03,  1.5418e-02,\n                      -2.1556e-03,  2.2473e-02,  1.6429e-02,  1.6354e-02,  1.7115e-02,\n                       1.5950e-03,  8.7438e-03, -1.2510e-02,  4.0747e-03,  9.9341e-03,\n                       9.7133e-03,  1.1614e-02, -7.8708e-04,  7.6011e-03,  6.0641e-03,\n                       7.1787e-03,  2.5677e-03,  1.6120e-02,  2.7974e-03,  1.7038e-03,\n                       1.2634e-02,  3.3191e-03,  3.7477e-03,  1.3246e-02,  8.3140e-03,\n                       6.1698e-03, -8.1395e-03, -1.6029e-03,  2.8262e-02,  1.9504e-02,\n                       4.4171e-03,  5.8607e-04,  6.3725e-03,  1.2017e-02,  7.5251e-04,\n                       1.0322e-02,  1.3695e-05,  1.4474e-02,  4.4732e-03,  1.3578e-02,\n                      -9.4972e-04,  7.3473e-03, -3.1719e-03,  1.3425e-02,  7.1577e-03,\n                       8.9096e-03,  4.7802e-03,  2.0985e-03, -1.1745e-02, -9.2216e-03,\n                       1.8780e-02,  2.2160e-02,  1.4048e-02,  1.7082e-02,  3.3521e-03,\n                       1.1426e-03], dtype=torch.float64)),\n             ('6.16.convpath.0.2.1.running_mean',\n              tensor([ 6.1306e-01, -6.2078e-03, -1.8435e-01,  6.5953e-02,  1.9692e-02,\n                       6.8546e-01,  4.8946e-01,  4.5521e-01,  1.0915e-01,  2.0139e-01,\n                      -1.1507e-01, -1.9916e-01,  1.0243e-01,  2.0044e-01,  7.8897e-03,\n                      -1.1108e+00,  3.9688e-01,  1.3976e-01,  3.9393e-01, -2.2625e-01,\n                       2.1822e-01, -7.7434e-01,  3.6786e-02, -7.0005e-01,  8.0393e-02,\n                       2.4291e-01, -2.2736e-01, -1.3886e-01,  3.3794e-01,  5.1980e-01,\n                      -4.9370e-01, -2.7451e-01, -1.1982e-01,  4.4666e-01,  1.9052e-01,\n                      -2.3208e-01, -2.6255e-02,  6.3425e-01, -6.0396e-02, -1.0914e-01,\n                       3.8388e-01, -1.2205e-01,  2.3332e-01,  5.0189e-01,  1.4234e-01,\n                       5.5909e-02, -1.9562e-01, -4.9734e-01,  1.0565e+00,  6.2301e-01,\n                       1.2532e-01,  2.3393e-01, -3.9227e-01,  1.1734e-01, -4.2162e-04,\n                      -8.7809e-01, -2.9131e-01,  1.2416e-01, -9.1970e-02, -4.9564e-02,\n                      -5.9136e-02, -1.5892e-01,  3.1150e-01,  3.0159e-01,  8.7612e-01,\n                      -3.6963e-01,  6.2932e-01, -2.7327e-01, -1.5035e-01,  6.2895e-01,\n                      -8.6141e-01,  2.2655e-01,  6.6538e-02, -3.6014e-01,  4.1273e-01,\n                       9.6808e-02, -5.0759e-02,  3.4167e-01,  3.7929e-02,  5.1091e-01,\n                      -2.6523e-01,  3.4326e-01, -2.5974e-02,  3.8641e-01,  1.7151e-01,\n                      -6.7585e-02, -7.5243e-01, -7.6153e-02,  4.0592e-01,  2.8271e-01,\n                      -3.0570e-01, -6.0099e-01,  2.9698e-01, -3.2425e-01,  2.1180e-01,\n                       8.7377e-03, -5.2692e-01, -5.1686e-01,  4.1962e-02,  2.2891e-01,\n                      -8.2175e-01, -1.0140e+00,  1.9329e-01, -2.7158e-01, -2.8176e-01,\n                      -8.4360e-02, -7.1051e-01, -8.5633e-01,  5.0236e-01,  1.4016e-01,\n                       2.2585e-01, -5.8610e-01, -2.1127e-02,  4.5338e-01, -4.3334e-01,\n                      -4.8692e-02,  2.3909e-01, -9.4583e-01,  3.4418e-01,  3.8721e-01,\n                      -2.0788e-01,  9.4788e-02,  6.5160e-01, -1.3896e-01, -3.3092e-01,\n                       5.7804e-01,  1.5541e-01, -4.3961e-02,  4.8244e-01, -3.2292e-01,\n                       6.1213e-02, -2.8619e-01, -6.0153e-01, -2.5566e-01, -1.8018e-01,\n                      -2.5891e-01,  4.9818e-02,  3.5354e-01, -3.6644e-02,  2.4181e-01,\n                      -1.9632e-01,  9.1498e-01,  1.2314e-01,  5.2392e-01, -1.4135e-01,\n                      -2.3385e-01,  3.5498e-01,  2.6323e-01,  1.3812e-01,  4.2290e-01,\n                       1.3710e-01,  1.4288e+00,  1.6401e-01,  6.4494e-01, -4.8343e-01,\n                      -2.2728e-01, -1.3081e-01,  1.9859e-01,  5.1851e-01,  1.7820e-01,\n                       6.8328e-02, -2.1686e-01, -1.3230e-01,  1.6343e-01, -2.3534e-01,\n                       8.2609e-01,  6.6073e-01, -6.2572e-01, -8.0333e-01, -1.3264e-01,\n                       5.9903e-01, -3.0722e-02,  3.3766e-01,  5.1450e-02,  5.1100e-01,\n                       4.3058e-01, -5.0604e-01, -3.3865e-01, -2.2567e-01, -1.7736e-01,\n                      -1.4153e-02,  3.4312e-01,  1.0110e+00,  1.6017e-01, -2.2221e-01,\n                      -1.6938e-01, -5.8114e-01, -5.0691e-01,  3.6252e-01,  3.0749e-02,\n                      -1.3048e-01, -5.6993e-01, -3.5579e-01, -3.9806e-01, -8.5054e-01,\n                       9.7509e-03,  8.1117e-02, -4.4937e-01,  6.6542e-01,  4.4782e-01,\n                      -2.6690e-02,  1.2220e-01,  2.6535e-01, -7.1831e-01,  7.6122e-02,\n                      -2.0710e-01,  1.3585e-02, -1.8125e-01, -9.8350e-02,  4.3923e-01,\n                       4.4509e-01, -1.0687e-01,  3.3277e-01,  5.9799e-01,  7.0560e-01,\n                      -5.7123e-02,  6.0254e-02, -9.3929e-02,  2.2802e-01, -4.0039e-02,\n                       1.5842e-02, -8.7733e-01,  6.4256e-02, -7.1610e-02, -3.6014e-01,\n                      -1.9152e-01, -7.4374e-01,  2.2500e-02,  6.1319e-02, -3.0701e-01,\n                      -2.2476e-01,  5.4270e-02,  4.3336e-01, -4.5984e-01,  4.4515e-02,\n                       3.7807e-01,  1.5538e-01,  6.2516e-01,  1.8614e-01,  3.7799e-01,\n                       6.4289e-01,  8.5381e-01,  3.7553e-01, -3.1792e-01,  5.8097e-01,\n                      -8.7172e-02, -3.8625e-02, -5.6988e-02,  3.7833e-02,  2.4193e-01,\n                      -2.4288e-01,  4.2301e-01, -2.2027e-01, -3.0302e-01,  1.0070e-01,\n                       9.8010e-01], dtype=torch.float64)),\n             ('6.16.convpath.0.2.1.running_var',\n              tensor([0.3133, 0.1922, 0.3422, 0.4176, 0.3093, 0.2284, 0.3108, 0.5188, 0.2302,\n                      0.4271, 0.2768, 0.3147, 0.0466, 0.4343, 0.4955, 0.4783, 0.2291, 0.4844,\n                      0.1740, 0.5771, 0.2095, 0.3850, 0.1939, 0.3683, 0.3818, 0.2451, 0.1651,\n                      0.3108, 0.1634, 0.3742, 0.4722, 0.7049, 0.0644, 0.4734, 0.2857, 0.3992,\n                      0.3182, 0.2040, 0.3829, 0.2944, 0.6267, 0.3199, 0.3212, 0.5727, 0.2603,\n                      0.1812, 0.7401, 0.2705, 0.3074, 0.3129, 0.1301, 0.4902, 0.2484, 0.2459,\n                      0.2344, 0.4069, 0.6537, 0.4933, 0.5320, 0.1483, 0.2342, 0.1491, 0.1204,\n                      0.3233, 0.6566, 0.4202, 0.4079, 0.3538, 0.2616, 0.4105, 0.7248, 0.3265,\n                      0.0663, 0.4411, 0.5530, 0.0937, 0.4070, 0.3388, 0.4188, 0.3898, 0.5769,\n                      0.1645, 0.3725, 0.4534, 0.1581, 0.5219, 0.2435, 0.4300, 0.5928, 0.3090,\n                      0.2796, 0.3137, 0.3389, 0.3986, 0.3343, 0.2211, 0.4333, 0.5383, 0.1850,\n                      0.1930, 0.4125, 0.5704, 0.3220, 0.2697, 0.4498, 0.5880, 0.4425, 0.4711,\n                      0.5014, 0.1203, 0.3135, 0.3679, 0.3669, 0.2458, 0.5322, 0.5680, 0.1994,\n                      0.2871, 0.2653, 0.4116, 0.2745, 0.4457, 0.5028, 0.4277, 0.2836, 0.4855,\n                      0.1778, 0.2352, 0.4457, 0.4371, 0.0583, 0.3205, 0.6673, 0.1172, 0.2534,\n                      0.0734, 0.4079, 0.3415, 0.5969, 0.1359, 0.3046, 0.3069, 0.3308, 0.2062,\n                      0.2927, 0.5014, 0.1463, 0.5133, 0.1067, 0.7088, 0.2917, 0.3569, 0.3563,\n                      0.4550, 0.4520, 0.1508, 0.3734, 0.1910, 0.4831, 0.3506, 0.2492, 0.1979,\n                      0.5237, 0.1145, 0.5266, 0.4935, 0.4422, 0.2838, 0.3637, 0.4010, 0.1738,\n                      0.0760, 0.1718, 0.2479, 0.5964, 0.2508, 0.4666, 0.3105, 0.2718, 0.3246,\n                      0.2973, 0.2534, 0.4928, 0.4504, 0.2600, 0.4325, 0.3286, 0.2124, 0.2420,\n                      0.6731, 0.2501, 0.2855, 0.3022, 0.5669, 0.3630, 0.4219, 0.4059, 0.2435,\n                      0.2839, 0.4457, 0.1439, 0.3331, 0.3270, 0.3455, 0.1955, 0.6198, 0.0509,\n                      0.0718, 0.0685, 0.4660, 0.0890, 0.3144, 0.3449, 0.3180, 0.1373, 0.1355,\n                      0.3570, 0.1986, 0.3384, 0.5744, 0.2798, 0.3902, 0.1597, 0.1455, 0.3579,\n                      0.6040, 0.2347, 0.1471, 0.6010, 0.3557, 0.2532, 0.2359, 0.3658, 0.5241,\n                      0.3923, 0.4290, 0.1312, 0.3150, 0.1041, 0.3859, 0.4342, 0.2519, 0.3787,\n                      0.2352, 0.4382, 0.4002, 0.4378, 0.4208, 0.0396, 0.5058, 0.2718, 0.4559,\n                      0.0972, 0.4081, 0.1595, 0.3917], dtype=torch.float64)),\n             ('6.16.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.17.convs.0.0.weight',\n              tensor([[[ 0.1011],\n                       [ 0.1910],\n                       [-0.0038],\n                       ...,\n                       [-0.1547],\n                       [ 0.0677],\n                       [-0.0680]],\n              \n                      [[-0.0171],\n                       [-0.0157],\n                       [-0.1286],\n                       ...,\n                       [-0.0976],\n                       [-0.0246],\n                       [-0.1203]],\n              \n                      [[-0.0841],\n                       [ 0.0101],\n                       [-0.0634],\n                       ...,\n                       [-0.0668],\n                       [-0.1459],\n                       [ 0.0700]],\n              \n                      ...,\n              \n                      [[ 0.0079],\n                       [-0.0362],\n                       [-0.0751],\n                       ...,\n                       [ 0.1131],\n                       [ 0.0727],\n                       [ 0.0293]],\n              \n                      [[ 0.0453],\n                       [-0.0168],\n                       [ 0.1205],\n                       ...,\n                       [ 0.0348],\n                       [ 0.0182],\n                       [ 0.0405]],\n              \n                      [[-0.0843],\n                       [-0.0257],\n                       [-0.0705],\n                       ...,\n                       [-0.0185],\n                       [-0.0186],\n                       [ 0.0884]]], dtype=torch.float64)),\n             ('6.17.convs.0.1.weight',\n              tensor([0.9546, 0.9901, 0.9658, 1.0060, 0.9663, 0.9994, 0.9632, 0.9947, 0.9562,\n                      0.9514, 0.9837, 0.9780, 0.9789, 0.9608, 0.9545, 0.9662, 0.9640, 0.9949,\n                      0.9597, 0.9776, 0.9839, 0.9756, 0.9557, 0.9577, 0.9561, 0.9956, 0.9636,\n                      0.9498, 0.9728, 0.9772, 0.9605, 0.9446, 0.9576, 0.9761, 0.9658, 0.9944,\n                      0.9678, 0.9601, 0.9873, 0.9531, 0.9494, 0.9700, 0.9756, 0.9400, 0.9635,\n                      0.9587, 0.9886, 0.9748, 0.9529, 0.9753, 0.9938, 0.9957, 0.9687, 0.9733,\n                      0.9631, 0.9728, 0.9541, 0.9469, 0.9842, 0.9612, 0.9629, 0.9861, 0.9751,\n                      0.9540], dtype=torch.float64)),\n             ('6.17.convs.0.1.bias',\n              tensor([-0.0119,  0.0167,  0.0088,  0.0083, -0.0066,  0.0169,  0.0153,  0.0202,\n                      -0.0178, -0.0057, -0.0153, -0.0096, -0.0063, -0.0047, -0.0076, -0.0140,\n                      -0.0260,  0.0103, -0.0008,  0.0121,  0.0059,  0.0247, -0.0302, -0.0155,\n                       0.0100,  0.0182, -0.0056, -0.0007,  0.0111, -0.0046, -0.0095,  0.0017,\n                      -0.0116,  0.0141, -0.0087,  0.0118, -0.0053,  0.0011,  0.0161,  0.0005,\n                       0.0074, -0.0099, -0.0048, -0.0056,  0.0019,  0.0019,  0.0142, -0.0085,\n                       0.0110,  0.0326,  0.0053, -0.0033,  0.0119,  0.0063, -0.0008,  0.0123,\n                      -0.0266, -0.0235,  0.0039, -0.0100,  0.0134,  0.0103,  0.0019, -0.0110],\n                     dtype=torch.float64)),\n             ('6.17.convs.0.1.running_mean',\n              tensor([ 0.0431,  0.3416,  1.1659, -0.4379,  0.9825, -0.2735, -0.5742, -0.0839,\n                      -0.3975, -0.4308, -0.6213, -0.0291, -0.5786, -0.0193,  0.0833,  0.5728,\n                       0.9937,  0.2995, -0.6744, -0.9051, -0.9441, -0.6111, -1.3306,  0.1646,\n                      -0.2059,  0.2093,  0.1936, -0.9058,  0.0300, -0.9388,  0.2495, -0.7662,\n                       0.2187,  0.1358,  0.6306,  0.8113, -0.0563,  0.2728,  0.1240, -0.1015,\n                       0.7224,  0.8565,  0.2912, -1.0717, -0.0315, -1.0396,  1.1022, -0.4631,\n                      -0.0057, -0.4879, -1.1238,  0.4833, -0.2824,  0.8825,  0.5286,  0.2315,\n                       0.2808,  0.3639, -0.7991, -0.0864, -0.4335, -0.7895,  0.2155,  0.2494],\n                     dtype=torch.float64)),\n             ('6.17.convs.0.1.running_var',\n              tensor([0.2662, 0.1606, 0.9427, 0.0978, 0.5794, 0.1695, 0.1603, 0.0982, 0.2000,\n                      0.2465, 0.1052, 0.1230, 0.1076, 0.1245, 0.2364, 0.1655, 0.1708, 0.1950,\n                      0.2093, 0.5119, 0.1396, 0.0962, 0.3256, 0.2245, 0.1506, 0.1173, 0.4474,\n                      0.3014, 0.2194, 0.6246, 0.2335, 1.0946, 0.3558, 0.1441, 0.1674, 0.1553,\n                      0.1965, 0.2472, 0.2358, 0.2846, 0.1663, 0.1888, 0.1784, 0.8368, 0.8129,\n                      0.8493, 0.1019, 0.1602, 0.2671, 0.2183, 0.1491, 0.1671, 0.4543, 0.1669,\n                      0.2251, 0.1110, 0.8243, 0.6660, 0.1390, 0.1291, 0.3830, 0.1056, 0.2283,\n                      0.1395], dtype=torch.float64)),\n             ('6.17.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.17.convs.1.0.weight',\n              tensor([[[-2.7650e-03, -8.7907e-02, -8.0904e-02, -8.8151e-02, -1.7358e-01],\n                       [ 3.8751e-02,  4.9101e-02,  1.7389e-02,  5.8484e-02,  1.2000e-02],\n                       [ 3.6215e-02, -8.3917e-02,  5.0440e-03, -5.5940e-02, -8.0683e-02],\n                       ...,\n                       [-8.1097e-02,  3.3157e-02,  9.5237e-02,  5.3807e-02,  5.8816e-02],\n                       [ 3.3692e-02, -4.0109e-02, -1.3064e-02,  7.8080e-02,  6.4626e-03],\n                       [ 1.3472e-01, -3.6794e-02, -3.2681e-02, -1.5583e-01,  4.1795e-02]],\n              \n                      [[ 9.0043e-02, -7.6573e-02, -2.1841e-02,  4.0454e-02, -4.0627e-02],\n                       [ 3.3711e-02,  1.2113e-01,  6.4196e-02, -4.7071e-03,  4.9153e-02],\n                       [ 4.9101e-02,  1.2570e-02,  2.0064e-02,  5.2496e-03, -5.9189e-02],\n                       ...,\n                       [ 6.4913e-02, -2.8510e-02, -2.2203e-02,  6.4161e-02, -5.8795e-02],\n                       [-5.3323e-02, -4.5986e-02,  1.5897e-01,  8.1368e-02,  6.4010e-02],\n                       [ 2.4161e-02, -6.6179e-02,  7.9401e-02, -7.1610e-02,  1.6790e-02]],\n              \n                      [[ 7.4899e-02,  6.3762e-02,  4.4013e-03,  1.8360e-01, -6.2220e-02],\n                       [-1.0947e-02, -6.7096e-03,  4.6106e-02, -6.3463e-02, -3.3193e-02],\n                       [-1.7243e-03,  1.0452e-01, -3.1891e-02, -1.4179e-02, -9.9657e-02],\n                       ...,\n                       [-2.6831e-02, -1.2870e-01, -7.2081e-02, -3.5437e-02, -5.7481e-02],\n                       [ 1.1444e-01,  5.0991e-02,  4.5252e-02,  8.1723e-02,  1.4126e-02],\n                       [-6.1653e-02,  1.5755e-04,  1.5366e-01, -2.0145e-02,  1.3626e-02]],\n              \n                      ...,\n              \n                      [[ 5.0871e-02, -1.5253e-01,  3.7321e-02,  1.5114e-02, -9.8919e-02],\n                       [-1.8270e-02, -8.8611e-02, -6.2199e-02, -3.5088e-02,  6.9235e-02],\n                       [ 1.8439e-01, -1.8785e-01,  9.3109e-02,  8.7847e-02,  1.6660e-01],\n                       ...,\n                       [ 9.6717e-02,  8.4309e-02,  7.3325e-04,  7.0540e-02,  4.7752e-02],\n                       [-2.3678e-02, -1.1943e-02,  5.0881e-02,  6.2254e-02, -3.7987e-02],\n                       [ 1.6986e-02,  2.3752e-02,  4.9315e-02,  6.3301e-02,  6.4597e-02]],\n              \n                      [[-2.8797e-02,  1.5723e-01,  5.9449e-02, -2.4509e-02,  3.9729e-02],\n                       [-2.0425e-02,  2.8752e-03,  1.4395e-01,  6.1944e-02,  5.5884e-02],\n                       [-7.8054e-02,  4.7143e-02, -1.1606e-01,  5.0965e-03, -3.9009e-02],\n                       ...,\n                       [ 7.2926e-03,  1.7506e-01, -1.8480e-03,  7.1178e-02, -1.8200e-02],\n                       [-1.0687e-01,  1.0052e-01, -6.2718e-02, -3.4395e-02, -9.4569e-02],\n                       [ 5.6353e-02,  5.1006e-02, -3.9454e-02, -7.6750e-02, -8.2791e-02]],\n              \n                      [[-1.2018e-02,  6.7915e-02, -8.0359e-03, -1.8727e-02, -6.7394e-02],\n                       [-5.7579e-02,  9.2954e-03, -9.1481e-02, -2.4134e-02, -5.3126e-03],\n                       [ 2.4703e-02, -7.7651e-02, -1.4564e-01, -2.7633e-02,  5.8622e-02],\n                       ...,\n                       [ 4.3366e-02,  9.1384e-02, -6.0102e-02, -6.7411e-02,  5.9397e-02],\n                       [ 6.2592e-02,  5.1124e-02,  7.2105e-02,  1.7691e-01, -1.6832e-01],\n                       [-2.4049e-03,  4.1401e-02,  7.8244e-02, -9.5568e-02,  2.4983e-02]]],\n                     dtype=torch.float64)),\n             ('6.17.convs.1.1.weight',\n              tensor([0.9490, 0.9780, 0.9574, 0.9939, 0.9676, 0.9685, 0.9727, 0.9774, 0.9398,\n                      0.9683, 0.9597, 0.9828, 0.9244, 0.9300, 0.9817, 0.9983, 0.9407, 0.9416,\n                      0.9459, 0.9723, 0.9887, 0.9688, 0.9466, 0.9652, 0.9725, 0.9727, 0.9774,\n                      0.9574, 0.9645, 0.9305, 0.9633, 0.9482, 0.9567, 0.9594, 0.9607, 0.9601,\n                      0.9735, 0.9529, 0.9600, 0.9547, 0.9749, 0.9565, 0.9697, 0.9553, 0.9678,\n                      0.9492, 1.0010, 0.9589, 0.9757, 0.9713, 0.9897, 0.9772, 0.9593, 1.0072,\n                      0.9574, 0.9697, 0.9534, 0.9765, 0.9794, 0.9620, 0.9813, 0.9826, 0.9359,\n                      0.9683], dtype=torch.float64)),\n             ('6.17.convs.1.1.bias',\n              tensor([-0.0059,  0.0153, -0.0273,  0.0134,  0.0020,  0.0073, -0.0014, -0.0193,\n                      -0.0195, -0.0210, -0.0007, -0.0241, -0.0092, -0.0293,  0.0136, -0.0335,\n                      -0.0134, -0.0135, -0.0083, -0.0078,  0.0016, -0.0152, -0.0043, -0.0290,\n                      -0.0024,  0.0032, -0.0137,  0.0006, -0.0026, -0.0082, -0.0061, -0.0051,\n                      -0.0238, -0.0061, -0.0049, -0.0108,  0.0136, -0.0154, -0.0134, -0.0098,\n                       0.0134, -0.0236,  0.0085, -0.0122,  0.0093, -0.0199,  0.0123, -0.0056,\n                      -0.0313,  0.0074, -0.0245, -0.0017,  0.0080,  0.0105, -0.0094,  0.0024,\n                      -0.0106, -0.0018, -0.0098, -0.0083,  0.0004, -0.0059, -0.0045,  0.0082],\n                     dtype=torch.float64)),\n             ('6.17.convs.1.1.running_mean',\n              tensor([ 0.1076,  0.0531,  0.3838, -0.4194,  0.2765,  1.0686,  0.4875,  0.9236,\n                       0.1217,  0.7606, -0.9840,  0.9500, -0.4870, -0.3049,  0.5356,  1.5241,\n                      -0.0368, -0.8052, -0.0407, -0.0346, -0.6509,  0.1868, -0.5836,  0.5512,\n                       0.3642, -0.4180,  0.5873,  0.3476,  0.5529, -0.1865,  0.2539, -0.6929,\n                      -0.4648,  0.5983, -0.1700, -0.2726, -0.1861,  0.2151,  0.2371, -0.2833,\n                      -0.0923,  0.2916, -0.4289, -1.1124, -0.8487,  0.0323, -0.3319,  0.6912,\n                       0.9337,  0.3910,  0.8991,  0.0033,  1.0178,  0.3381, -1.1239,  0.2089,\n                       0.6657, -0.8024,  1.2301, -0.1110, -0.1906, -0.4709,  0.1098, -0.1694],\n                     dtype=torch.float64)),\n             ('6.17.convs.1.1.running_var',\n              tensor([0.5253, 0.6203, 0.6087, 0.3960, 0.2999, 0.4142, 0.5388, 0.5990, 0.6290,\n                      0.5431, 0.7907, 0.4143, 0.4195, 0.4786, 0.3714, 0.5621, 0.4939, 0.4016,\n                      0.5699, 0.5559, 0.5137, 0.5611, 0.5967, 0.7345, 0.4974, 0.4699, 0.6522,\n                      0.4545, 0.4128, 0.5330, 0.5432, 0.6835, 0.4363, 0.8313, 0.4695, 0.8678,\n                      0.4816, 0.3829, 0.7665, 0.5329, 0.4250, 1.1877, 0.4461, 0.5738, 0.5738,\n                      0.4175, 0.4046, 0.4687, 0.3871, 0.5521, 0.6238, 0.4324, 0.5601, 0.4125,\n                      0.5125, 0.6241, 0.5805, 0.5618, 0.3811, 0.5905, 0.6000, 0.4785, 0.5265,\n                      0.3171], dtype=torch.float64)),\n             ('6.17.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.17.convs.2.0.weight',\n              tensor([[[-0.0794],\n                       [-0.1554],\n                       [ 0.1495],\n                       ...,\n                       [ 0.1434],\n                       [-0.0471],\n                       [-0.1191]],\n              \n                      [[ 0.0439],\n                       [ 0.0580],\n                       [-0.0277],\n                       ...,\n                       [-0.1035],\n                       [-0.0186],\n                       [-0.1371]],\n              \n                      [[ 0.0437],\n                       [-0.0252],\n                       [ 0.0775],\n                       ...,\n                       [ 0.1078],\n                       [ 0.2906],\n                       [-0.0108]],\n              \n                      ...,\n              \n                      [[-0.0177],\n                       [-0.1471],\n                       [ 0.0080],\n                       ...,\n                       [-0.0669],\n                       [ 0.0281],\n                       [-0.3486]],\n              \n                      [[-0.1739],\n                       [ 0.2456],\n                       [-0.1407],\n                       ...,\n                       [ 0.0558],\n                       [-0.1788],\n                       [ 0.0984]],\n              \n                      [[-0.1239],\n                       [-0.1243],\n                       [ 0.0225],\n                       ...,\n                       [-0.0854],\n                       [-0.1869],\n                       [ 0.0199]]], dtype=torch.float64)),\n             ('6.17.convs.2.1.weight',\n              tensor([ 0.0045,  0.0041, -0.0233,  0.0119,  0.0216, -0.0186,  0.0135, -0.0435,\n                       0.0137,  0.0382, -0.0151,  0.0052, -0.0125, -0.0150, -0.0153,  0.0216,\n                      -0.0262,  0.0083,  0.0091, -0.0370, -0.0102, -0.0245,  0.0087, -0.0046,\n                       0.0291,  0.0240,  0.0230, -0.0279,  0.0274,  0.0013,  0.0226,  0.0087,\n                       0.0147, -0.0231, -0.0045,  0.0025, -0.0028, -0.0222, -0.0135,  0.0266,\n                       0.0113,  0.0007,  0.0258, -0.0053,  0.0051, -0.0173, -0.0004, -0.0130,\n                      -0.0150, -0.0130, -0.0232,  0.0059, -0.0045,  0.0100, -0.0163,  0.0428,\n                       0.0133, -0.0004, -0.0009,  0.0105,  0.0072, -0.0039, -0.0133,  0.0011,\n                      -0.0349, -0.0419,  0.0073,  0.0144,  0.0186,  0.0272, -0.0201, -0.0132,\n                      -0.0191, -0.0073, -0.0010, -0.0238, -0.0139, -0.0123, -0.0195, -0.0244,\n                      -0.0068,  0.0110, -0.0179,  0.0168,  0.0218, -0.0199,  0.0165, -0.0164,\n                       0.0058, -0.0064, -0.0163,  0.0019,  0.0396, -0.0007, -0.0215,  0.0076,\n                      -0.0004,  0.0111, -0.0291, -0.0323,  0.0423, -0.0094,  0.0344,  0.0076,\n                      -0.0301,  0.0032,  0.0256,  0.0029, -0.0495, -0.0139,  0.0022,  0.0087,\n                       0.0089, -0.0109,  0.0030,  0.0174,  0.0048,  0.0168, -0.0151, -0.0104,\n                      -0.0007, -0.0208,  0.0175, -0.0113, -0.0355,  0.0031,  0.0363, -0.0085,\n                      -0.0009,  0.0151,  0.0120, -0.0446,  0.0325,  0.0078, -0.0035,  0.0156,\n                       0.0295, -0.0103,  0.0229,  0.0157, -0.0066,  0.0062, -0.0012,  0.0025,\n                      -0.0159,  0.0192, -0.0056, -0.0278, -0.0042,  0.0019, -0.0159,  0.0007,\n                      -0.0339,  0.0181, -0.0011, -0.0128, -0.0080,  0.0027, -0.0100, -0.0229,\n                       0.0100,  0.0020,  0.0079,  0.0152,  0.0299,  0.0030,  0.0277,  0.0017,\n                      -0.0342, -0.0192,  0.0107, -0.0099,  0.0032,  0.0070,  0.0262,  0.0313,\n                       0.0048, -0.0215, -0.0190,  0.0052,  0.0057, -0.0039,  0.0073,  0.0062,\n                      -0.0301, -0.0257, -0.0250, -0.0010, -0.0320,  0.0150, -0.0213, -0.0154,\n                       0.0179,  0.0004,  0.0121, -0.0026,  0.0176,  0.0256, -0.0055,  0.0062,\n                       0.0135, -0.0113, -0.0226,  0.0230,  0.0061,  0.0081,  0.0147,  0.0050,\n                       0.0138, -0.0072,  0.0056, -0.0111, -0.0146, -0.0244, -0.0157,  0.0225,\n                      -0.0080, -0.0289, -0.0022, -0.0338,  0.0064, -0.0354,  0.0154,  0.0002,\n                      -0.0001,  0.0075,  0.0323, -0.0307, -0.0070,  0.0077,  0.0133,  0.0108,\n                       0.0132,  0.0105, -0.0028,  0.0381,  0.0076,  0.0011, -0.0230, -0.0130,\n                      -0.0158, -0.0173,  0.0144,  0.0095, -0.0140, -0.0332,  0.0263, -0.0204,\n                      -0.0078, -0.0084,  0.0388,  0.0386,  0.0169,  0.0194, -0.0512, -0.0069],\n                     dtype=torch.float64)),\n             ('6.17.convs.2.1.bias',\n              tensor([-4.5486e-05,  6.0256e-03,  9.3203e-03,  1.4539e-02,  1.3087e-03,\n                       5.6782e-03,  6.0570e-03, -7.3542e-04,  5.3249e-04,  1.6577e-02,\n                       1.6396e-02, -7.3291e-03,  2.5514e-03, -5.6310e-03,  5.6751e-03,\n                       4.0660e-03,  2.7858e-02,  5.8710e-04,  1.1688e-02, -4.9836e-03,\n                      -1.0568e-02,  1.6861e-03,  8.4686e-03,  4.6090e-03,  9.6537e-03,\n                      -1.7670e-02,  6.8723e-03,  5.2994e-03,  1.3304e-02, -5.5060e-03,\n                      -1.8059e-03,  1.1647e-02,  3.5535e-03,  1.7987e-02,  1.0142e-02,\n                       1.3516e-02,  2.3112e-04,  1.1144e-02,  9.6727e-03,  6.7899e-03,\n                       3.8965e-03,  2.2842e-03, -7.8735e-03, -4.6794e-03,  7.4168e-03,\n                      -1.7873e-02,  1.2272e-02,  5.5425e-03, -1.3350e-02, -1.4436e-05,\n                       1.1693e-02,  3.4187e-03,  5.9580e-03,  1.9528e-02, -4.5441e-04,\n                       1.1899e-02,  1.0841e-02,  5.4668e-03,  6.3329e-03, -5.1205e-03,\n                      -5.9168e-04,  1.8611e-03,  9.1517e-03,  8.8308e-03, -1.0028e-02,\n                      -1.5754e-04, -4.1114e-03,  1.5066e-02,  1.7317e-02, -1.6164e-02,\n                       7.3855e-03, -3.8283e-03, -1.0748e-03, -7.6576e-03,  1.3662e-02,\n                       7.4842e-03,  1.6951e-03,  1.8237e-02, -3.9403e-04,  1.3537e-02,\n                       4.5510e-03, -7.9282e-03,  2.0848e-02,  3.6059e-03, -7.7019e-03,\n                       1.8586e-02, -1.7934e-03,  8.4113e-03,  1.2737e-02, -4.3181e-04,\n                       1.4576e-03,  1.2780e-02,  1.0248e-02, -6.6179e-03,  6.4495e-03,\n                      -4.8571e-03,  1.5484e-02,  5.4774e-03,  2.0043e-02,  8.2383e-03,\n                       2.3438e-02,  1.5568e-02,  6.3293e-03,  1.3777e-02,  1.1332e-02,\n                       2.2643e-03, -9.1796e-03,  1.0896e-02,  6.0323e-03,  6.4556e-03,\n                      -2.8244e-04, -6.4253e-03,  2.2538e-03,  2.2485e-02,  1.7934e-02,\n                       5.1690e-03,  5.2958e-03,  3.3799e-03,  2.8632e-03, -3.2200e-03,\n                       3.1456e-03,  1.0977e-02,  3.3900e-03,  4.1344e-03,  1.9959e-02,\n                       8.3535e-03,  5.1631e-03,  4.9004e-03,  3.8810e-03,  1.4662e-02,\n                       8.1672e-03,  7.7800e-03,  1.3100e-02,  1.4073e-03,  6.0063e-03,\n                      -1.8018e-02,  1.3580e-02,  3.9374e-03,  5.4135e-03,  8.2910e-03,\n                       1.5792e-02,  1.1208e-02,  1.1902e-02,  1.8086e-03, -8.0435e-03,\n                       9.0699e-03,  6.0981e-03, -3.1861e-03,  4.7604e-03,  2.9878e-03,\n                       7.9735e-03,  9.9461e-03,  6.9924e-03,  1.1382e-02,  1.4283e-02,\n                       3.0344e-03, -6.7065e-04,  4.5958e-03,  4.1192e-03, -1.5040e-03,\n                       5.6651e-03,  8.7652e-03, -1.8505e-03,  6.6854e-03,  1.1015e-02,\n                      -5.3422e-03, -9.5780e-03,  5.3796e-03,  5.8183e-03,  1.1702e-02,\n                       1.1239e-02, -2.5882e-03,  1.0441e-02,  1.5723e-02, -1.3589e-02,\n                       1.2948e-02, -1.0222e-04,  1.8138e-02,  2.3002e-03,  2.1699e-03,\n                      -7.3694e-04,  9.1046e-03, -1.9512e-03, -7.9285e-03,  9.8535e-03,\n                       7.0501e-03,  1.0547e-02,  8.7334e-03,  8.2931e-03,  3.7524e-03,\n                       6.6465e-03,  6.2764e-03,  6.8081e-03,  9.5316e-03,  5.7852e-03,\n                       9.4402e-03,  1.0103e-02,  4.6320e-04,  5.7802e-03,  1.2478e-02,\n                      -5.4578e-04,  2.2199e-02,  1.4904e-02,  1.6152e-02,  1.7721e-02,\n                       4.9351e-03,  8.8235e-03, -1.0745e-02,  3.7662e-03,  7.8666e-03,\n                       8.1069e-03,  9.6116e-03, -3.1557e-03,  9.1075e-03,  6.4481e-03,\n                       7.6962e-03,  1.7362e-03,  1.5496e-02,  2.2152e-03,  1.3356e-03,\n                       1.5570e-02,  8.1333e-03,  5.5015e-03,  1.3156e-02,  8.4536e-03,\n                       4.8096e-03, -4.3397e-03, -3.1354e-03,  2.4866e-02,  1.8989e-02,\n                       4.7648e-03, -2.2109e-04,  8.2660e-03,  6.3731e-03, -7.4253e-04,\n                       8.6815e-03, -2.2512e-03,  1.4911e-02,  4.3540e-03,  1.4208e-02,\n                       1.3251e-04,  2.7282e-03, -6.1565e-03,  1.2093e-02,  1.4628e-03,\n                       1.0310e-02,  6.6734e-03,  4.5486e-04, -1.6654e-02, -9.6438e-03,\n                       1.8525e-02,  2.3138e-02,  1.1708e-02,  1.7715e-02,  4.1041e-03,\n                       2.3974e-03], dtype=torch.float64)),\n             ('6.17.convs.2.1.running_mean',\n              tensor([ 3.7024e-01,  2.0199e-01, -5.8932e-01, -2.9456e-01, -1.5762e-02,\n                      -5.4308e-01,  2.4270e-01,  6.8195e-01,  1.6808e-01,  1.8157e-01,\n                      -3.1067e-02, -9.1627e-02,  3.3589e-01,  4.3754e-01,  4.4139e-01,\n                      -4.1747e-01, -6.2627e-01, -3.7111e-01, -3.3084e-03,  4.4530e-01,\n                       1.8779e-01,  3.8325e-01,  5.7041e-01, -2.0387e-01, -4.7382e-01,\n                      -4.3674e-03,  6.2565e-01,  4.0120e-01,  4.0990e-01, -1.0849e-01,\n                      -1.3312e-01,  3.0331e-01,  2.9492e-01,  9.3740e-01, -1.1587e-01,\n                      -3.0130e-01,  3.9192e-01,  3.5150e-01,  2.3179e-01,  4.3525e-02,\n                      -2.9420e-02, -1.8285e-01, -3.0051e-01, -3.1498e-01,  5.9791e-01,\n                       1.9901e-01,  4.5652e-01, -2.9374e-01,  2.0447e-01,  3.7247e-01,\n                       3.6691e-01, -5.0435e-03, -6.8386e-02, -6.0224e-01, -6.4418e-02,\n                       6.7236e-01, -4.6991e-01,  5.7562e-02, -4.7838e-01, -2.9798e-02,\n                       5.0790e-01, -1.7083e-01,  1.2350e-01, -2.8500e-01,  3.9261e-01,\n                       1.4347e-01, -6.2737e-04, -3.0265e-02,  2.3465e-01,  5.5923e-01,\n                      -5.0849e-01,  2.7459e-02,  1.4260e-01,  1.4072e-01,  4.1721e-01,\n                       5.4835e-02,  6.4167e-01,  3.9489e-01, -5.6341e-01, -4.1856e-01,\n                       5.1450e-01, -1.0079e-01,  7.9869e-02, -3.7211e-01,  1.3429e-01,\n                      -6.5351e-01, -2.6659e-01, -5.0698e-01,  2.3678e-01, -2.6831e-01,\n                      -3.9020e-01, -2.2874e-02,  8.1380e-02,  1.4259e-01,  8.5290e-01,\n                       5.9297e-01, -5.8248e-01,  6.3449e-01, -8.1682e-01, -7.3134e-02,\n                      -5.8580e-01,  2.9379e-01,  1.1317e-01,  1.6616e-01, -3.8099e-01,\n                       3.2084e-01,  1.3036e-01,  4.1928e-01,  5.3826e-01,  7.2245e-01,\n                       3.9075e-02,  8.0109e-01,  1.2795e-02,  3.6939e-01,  2.6068e-01,\n                      -5.8114e-01,  3.8999e-01, -1.6727e-01,  2.0008e-01, -2.2343e-01,\n                       1.2692e-01, -4.4147e-01,  2.9411e-01, -7.3177e-01,  4.8792e-01,\n                       9.3940e-01,  1.3152e-01, -9.1903e-02,  7.7173e-02, -6.1913e-01,\n                       2.6078e-01,  5.7101e-01,  1.2481e-01, -1.6686e-02, -4.2232e-02,\n                       1.3614e-01, -4.2237e-01,  8.9904e-02,  3.6924e-01,  1.7907e-01,\n                      -2.4065e-01,  3.2218e-01, -3.4991e-01,  2.2324e-01,  2.2254e-01,\n                       5.1009e-01, -2.6143e-01, -8.9272e-01, -2.4157e-02, -4.4340e-01,\n                      -1.0770e-01,  1.8312e-01, -3.8298e-01, -8.0961e-02, -7.4842e-02,\n                      -1.9189e-01, -5.0744e-01, -1.4356e-01, -1.1591e-01, -4.2615e-01,\n                      -2.3919e-01, -2.5695e-01, -1.2306e-01, -2.6789e-01, -6.3123e-01,\n                       1.3136e-04, -9.0787e-01, -3.6040e-01,  3.2891e-01, -2.7260e-01,\n                      -7.6605e-02, -4.5037e-01, -2.3511e-01, -4.7999e-01, -1.3458e-02,\n                       3.7782e-01,  6.3541e-02,  2.3703e-02,  4.6335e-01,  7.8672e-02,\n                      -4.3246e-01,  7.9925e-01, -5.4128e-01,  5.2813e-01, -3.3250e-01,\n                       4.3922e-01, -1.1671e-01,  1.8851e-01,  2.4798e-01,  5.2746e-01,\n                       1.6409e-02,  7.2987e-01, -3.0908e-01,  4.6262e-02,  9.6338e-01,\n                       8.1525e-01,  1.5216e-01, -2.1230e-01,  2.7901e-01,  1.9349e-01,\n                      -2.9105e-01,  5.3078e-01,  1.5774e-01, -2.0463e-01,  2.1300e-01,\n                       5.6954e-01,  4.3563e-01,  1.1149e-01,  2.7809e-01, -1.7339e-01,\n                      -2.7596e-01, -1.0872e+00, -9.6208e-02, -1.6955e-01, -5.7735e-01,\n                       3.3802e-01,  3.4071e-01,  1.5794e-02, -6.2159e-02,  5.0687e-01,\n                       3.1973e-01,  2.7486e-02,  9.7964e-02, -1.7091e-02, -9.1394e-01,\n                      -5.5152e-02, -1.1772e-01,  1.1513e-01, -2.2522e-01, -2.2518e-01,\n                       8.7394e-02, -3.6991e-01, -7.9692e-01, -2.0979e-01, -5.6866e-02,\n                      -1.2670e-01, -1.0352e-01, -3.9386e-01, -1.9357e-01,  4.3411e-01,\n                      -4.9134e-01, -7.3731e-02,  3.5982e-01, -1.7892e-01,  2.2660e-01,\n                       5.9985e-01, -8.4993e-02, -1.5441e-01,  2.1440e-01,  4.4953e-01,\n                       1.5204e-01, -8.1264e-01, -7.8709e-02, -6.6976e-01,  2.3725e-01,\n                      -4.3351e-01], dtype=torch.float64)),\n             ('6.17.convs.2.1.running_var',\n              tensor([0.4834, 0.2445, 0.4250, 0.4389, 0.2160, 0.4665, 0.4324, 0.6194, 0.3131,\n                      0.5174, 0.3143, 0.2008, 0.2788, 0.5726, 0.2613, 0.5530, 0.3823, 0.3396,\n                      0.3076, 0.5625, 0.1679, 0.5683, 0.3463, 0.3091, 0.4258, 0.2476, 0.3051,\n                      0.4082, 0.4261, 0.1978, 0.7196, 0.2739, 0.2767, 0.4441, 0.3076, 0.3342,\n                      0.0811, 0.2860, 0.2839, 0.4172, 0.3195, 0.1690, 0.1475, 0.4127, 0.3228,\n                      0.5583, 0.2369, 0.1649, 0.3827, 0.2620, 0.5234, 0.4196, 0.3438, 0.2099,\n                      0.4946, 0.4881, 0.5881, 0.3282, 0.6560, 0.1514, 0.1317, 0.1007, 0.1751,\n                      0.1825, 0.2969, 0.3156, 0.3539, 0.3036, 0.2313, 0.6777, 0.3586, 0.3528,\n                      0.1945, 0.4021, 0.4117, 0.3253, 0.4511, 0.3565, 0.4871, 0.3781, 0.3168,\n                      0.4729, 0.2951, 0.4289, 0.5328, 0.6612, 0.3624, 0.4502, 0.2456, 0.2601,\n                      0.5935, 0.1553, 0.4542, 0.2070, 0.3745, 0.4115, 0.3708, 0.1990, 0.4252,\n                      0.3363, 0.5051, 0.3461, 0.4251, 0.1150, 0.4776, 0.0926, 0.4658, 0.6165,\n                      0.3205, 0.3335, 0.1285, 0.5038, 0.4889, 0.5185, 0.3024, 0.4351, 0.5167,\n                      0.4952, 0.3016, 0.3540, 0.1233, 0.3830, 0.3595, 0.4158, 0.3526, 0.3903,\n                      0.3123, 0.2241, 0.0856, 0.4551, 0.3894, 0.3268, 0.3814, 0.0969, 0.3195,\n                      0.3051, 0.2632, 0.3055, 0.3501, 0.3030, 0.2753, 0.2809, 0.2193, 0.0746,\n                      0.1382, 0.8117, 0.0877, 0.5908, 0.0776, 0.2687, 0.6965, 0.2212, 0.4589,\n                      0.4283, 0.1816, 0.3318, 0.4388, 0.0761, 0.2122, 0.2887, 0.3384, 0.3440,\n                      0.2722, 0.2363, 0.5354, 0.4137, 0.3240, 0.1577, 0.4402, 0.4709, 0.0716,\n                      0.2064, 0.2588, 0.1717, 0.3567, 0.4416, 0.1605, 0.3168, 0.2784, 0.1911,\n                      0.4119, 0.1748, 0.4294, 0.3043, 0.2657, 0.5145, 0.4997, 0.1051, 0.5464,\n                      0.3533, 0.4112, 0.3274, 0.3064, 0.5507, 0.3906, 0.3060, 0.5791, 0.3679,\n                      0.2572, 0.3905, 0.1842, 0.2337, 0.5736, 0.6057, 0.2915, 0.3813, 0.3652,\n                      0.0254, 0.2391, 0.3461, 0.0871, 0.3246, 0.2150, 0.5893, 0.3394, 0.4176,\n                      0.4271, 0.3352, 0.0980, 0.5630, 0.2918, 0.2940, 0.2407, 0.2996, 0.6469,\n                      0.3469, 0.4700, 0.3163, 0.5411, 0.4300, 0.2391, 0.4199, 0.6520, 0.2476,\n                      0.1674, 0.3415, 0.1240, 0.0780, 0.4357, 0.1243, 0.2961, 0.2322, 0.7925,\n                      0.1487, 0.2004, 0.3188, 0.5123, 0.4813, 0.2167, 0.4056, 0.5035, 0.5278,\n                      0.3785, 0.3716, 0.3405, 0.3593], dtype=torch.float64)),\n             ('6.17.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.17.convpath.0.0.0.weight',\n              tensor([[[ 0.1011],\n                       [ 0.1910],\n                       [-0.0038],\n                       ...,\n                       [-0.1547],\n                       [ 0.0677],\n                       [-0.0680]],\n              \n                      [[-0.0171],\n                       [-0.0157],\n                       [-0.1286],\n                       ...,\n                       [-0.0976],\n                       [-0.0246],\n                       [-0.1203]],\n              \n                      [[-0.0841],\n                       [ 0.0101],\n                       [-0.0634],\n                       ...,\n                       [-0.0668],\n                       [-0.1459],\n                       [ 0.0700]],\n              \n                      ...,\n              \n                      [[ 0.0079],\n                       [-0.0362],\n                       [-0.0751],\n                       ...,\n                       [ 0.1131],\n                       [ 0.0727],\n                       [ 0.0293]],\n              \n                      [[ 0.0453],\n                       [-0.0168],\n                       [ 0.1205],\n                       ...,\n                       [ 0.0348],\n                       [ 0.0182],\n                       [ 0.0405]],\n              \n                      [[-0.0843],\n                       [-0.0257],\n                       [-0.0705],\n                       ...,\n                       [-0.0185],\n                       [-0.0186],\n                       [ 0.0884]]], dtype=torch.float64)),\n             ('6.17.convpath.0.0.1.weight',\n              tensor([0.9546, 0.9901, 0.9658, 1.0060, 0.9663, 0.9994, 0.9632, 0.9947, 0.9562,\n                      0.9514, 0.9837, 0.9780, 0.9789, 0.9608, 0.9545, 0.9662, 0.9640, 0.9949,\n                      0.9597, 0.9776, 0.9839, 0.9756, 0.9557, 0.9577, 0.9561, 0.9956, 0.9636,\n                      0.9498, 0.9728, 0.9772, 0.9605, 0.9446, 0.9576, 0.9761, 0.9658, 0.9944,\n                      0.9678, 0.9601, 0.9873, 0.9531, 0.9494, 0.9700, 0.9756, 0.9400, 0.9635,\n                      0.9587, 0.9886, 0.9748, 0.9529, 0.9753, 0.9938, 0.9957, 0.9687, 0.9733,\n                      0.9631, 0.9728, 0.9541, 0.9469, 0.9842, 0.9612, 0.9629, 0.9861, 0.9751,\n                      0.9540], dtype=torch.float64)),\n             ('6.17.convpath.0.0.1.bias',\n              tensor([-0.0119,  0.0167,  0.0088,  0.0083, -0.0066,  0.0169,  0.0153,  0.0202,\n                      -0.0178, -0.0057, -0.0153, -0.0096, -0.0063, -0.0047, -0.0076, -0.0140,\n                      -0.0260,  0.0103, -0.0008,  0.0121,  0.0059,  0.0247, -0.0302, -0.0155,\n                       0.0100,  0.0182, -0.0056, -0.0007,  0.0111, -0.0046, -0.0095,  0.0017,\n                      -0.0116,  0.0141, -0.0087,  0.0118, -0.0053,  0.0011,  0.0161,  0.0005,\n                       0.0074, -0.0099, -0.0048, -0.0056,  0.0019,  0.0019,  0.0142, -0.0085,\n                       0.0110,  0.0326,  0.0053, -0.0033,  0.0119,  0.0063, -0.0008,  0.0123,\n                      -0.0266, -0.0235,  0.0039, -0.0100,  0.0134,  0.0103,  0.0019, -0.0110],\n                     dtype=torch.float64)),\n             ('6.17.convpath.0.0.1.running_mean',\n              tensor([ 0.0431,  0.3416,  1.1659, -0.4379,  0.9825, -0.2735, -0.5742, -0.0839,\n                      -0.3975, -0.4308, -0.6213, -0.0291, -0.5786, -0.0193,  0.0833,  0.5728,\n                       0.9937,  0.2995, -0.6744, -0.9051, -0.9441, -0.6111, -1.3306,  0.1646,\n                      -0.2059,  0.2093,  0.1936, -0.9058,  0.0300, -0.9388,  0.2495, -0.7662,\n                       0.2187,  0.1358,  0.6306,  0.8113, -0.0563,  0.2728,  0.1240, -0.1015,\n                       0.7224,  0.8565,  0.2912, -1.0717, -0.0315, -1.0396,  1.1022, -0.4631,\n                      -0.0057, -0.4879, -1.1238,  0.4833, -0.2824,  0.8825,  0.5286,  0.2315,\n                       0.2808,  0.3639, -0.7991, -0.0864, -0.4335, -0.7895,  0.2155,  0.2494],\n                     dtype=torch.float64)),\n             ('6.17.convpath.0.0.1.running_var',\n              tensor([0.2662, 0.1606, 0.9427, 0.0978, 0.5794, 0.1695, 0.1603, 0.0982, 0.2000,\n                      0.2465, 0.1052, 0.1230, 0.1076, 0.1245, 0.2364, 0.1655, 0.1708, 0.1950,\n                      0.2093, 0.5119, 0.1396, 0.0962, 0.3256, 0.2245, 0.1506, 0.1173, 0.4474,\n                      0.3014, 0.2194, 0.6246, 0.2335, 1.0946, 0.3558, 0.1441, 0.1674, 0.1553,\n                      0.1965, 0.2472, 0.2358, 0.2846, 0.1663, 0.1888, 0.1784, 0.8368, 0.8129,\n                      0.8493, 0.1019, 0.1602, 0.2671, 0.2183, 0.1491, 0.1671, 0.4543, 0.1669,\n                      0.2251, 0.1110, 0.8243, 0.6660, 0.1390, 0.1291, 0.3830, 0.1056, 0.2283,\n                      0.1395], dtype=torch.float64)),\n             ('6.17.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.17.convpath.0.1.0.weight',\n              tensor([[[-2.7650e-03, -8.7907e-02, -8.0904e-02, -8.8151e-02, -1.7358e-01],\n                       [ 3.8751e-02,  4.9101e-02,  1.7389e-02,  5.8484e-02,  1.2000e-02],\n                       [ 3.6215e-02, -8.3917e-02,  5.0440e-03, -5.5940e-02, -8.0683e-02],\n                       ...,\n                       [-8.1097e-02,  3.3157e-02,  9.5237e-02,  5.3807e-02,  5.8816e-02],\n                       [ 3.3692e-02, -4.0109e-02, -1.3064e-02,  7.8080e-02,  6.4626e-03],\n                       [ 1.3472e-01, -3.6794e-02, -3.2681e-02, -1.5583e-01,  4.1795e-02]],\n              \n                      [[ 9.0043e-02, -7.6573e-02, -2.1841e-02,  4.0454e-02, -4.0627e-02],\n                       [ 3.3711e-02,  1.2113e-01,  6.4196e-02, -4.7071e-03,  4.9153e-02],\n                       [ 4.9101e-02,  1.2570e-02,  2.0064e-02,  5.2496e-03, -5.9189e-02],\n                       ...,\n                       [ 6.4913e-02, -2.8510e-02, -2.2203e-02,  6.4161e-02, -5.8795e-02],\n                       [-5.3323e-02, -4.5986e-02,  1.5897e-01,  8.1368e-02,  6.4010e-02],\n                       [ 2.4161e-02, -6.6179e-02,  7.9401e-02, -7.1610e-02,  1.6790e-02]],\n              \n                      [[ 7.4899e-02,  6.3762e-02,  4.4013e-03,  1.8360e-01, -6.2220e-02],\n                       [-1.0947e-02, -6.7096e-03,  4.6106e-02, -6.3463e-02, -3.3193e-02],\n                       [-1.7243e-03,  1.0452e-01, -3.1891e-02, -1.4179e-02, -9.9657e-02],\n                       ...,\n                       [-2.6831e-02, -1.2870e-01, -7.2081e-02, -3.5437e-02, -5.7481e-02],\n                       [ 1.1444e-01,  5.0991e-02,  4.5252e-02,  8.1723e-02,  1.4126e-02],\n                       [-6.1653e-02,  1.5755e-04,  1.5366e-01, -2.0145e-02,  1.3626e-02]],\n              \n                      ...,\n              \n                      [[ 5.0871e-02, -1.5253e-01,  3.7321e-02,  1.5114e-02, -9.8919e-02],\n                       [-1.8270e-02, -8.8611e-02, -6.2199e-02, -3.5088e-02,  6.9235e-02],\n                       [ 1.8439e-01, -1.8785e-01,  9.3109e-02,  8.7847e-02,  1.6660e-01],\n                       ...,\n                       [ 9.6717e-02,  8.4309e-02,  7.3325e-04,  7.0540e-02,  4.7752e-02],\n                       [-2.3678e-02, -1.1943e-02,  5.0881e-02,  6.2254e-02, -3.7987e-02],\n                       [ 1.6986e-02,  2.3752e-02,  4.9315e-02,  6.3301e-02,  6.4597e-02]],\n              \n                      [[-2.8797e-02,  1.5723e-01,  5.9449e-02, -2.4509e-02,  3.9729e-02],\n                       [-2.0425e-02,  2.8752e-03,  1.4395e-01,  6.1944e-02,  5.5884e-02],\n                       [-7.8054e-02,  4.7143e-02, -1.1606e-01,  5.0965e-03, -3.9009e-02],\n                       ...,\n                       [ 7.2926e-03,  1.7506e-01, -1.8480e-03,  7.1178e-02, -1.8200e-02],\n                       [-1.0687e-01,  1.0052e-01, -6.2718e-02, -3.4395e-02, -9.4569e-02],\n                       [ 5.6353e-02,  5.1006e-02, -3.9454e-02, -7.6750e-02, -8.2791e-02]],\n              \n                      [[-1.2018e-02,  6.7915e-02, -8.0359e-03, -1.8727e-02, -6.7394e-02],\n                       [-5.7579e-02,  9.2954e-03, -9.1481e-02, -2.4134e-02, -5.3126e-03],\n                       [ 2.4703e-02, -7.7651e-02, -1.4564e-01, -2.7633e-02,  5.8622e-02],\n                       ...,\n                       [ 4.3366e-02,  9.1384e-02, -6.0102e-02, -6.7411e-02,  5.9397e-02],\n                       [ 6.2592e-02,  5.1124e-02,  7.2105e-02,  1.7691e-01, -1.6832e-01],\n                       [-2.4049e-03,  4.1401e-02,  7.8244e-02, -9.5568e-02,  2.4983e-02]]],\n                     dtype=torch.float64)),\n             ('6.17.convpath.0.1.1.weight',\n              tensor([0.9490, 0.9780, 0.9574, 0.9939, 0.9676, 0.9685, 0.9727, 0.9774, 0.9398,\n                      0.9683, 0.9597, 0.9828, 0.9244, 0.9300, 0.9817, 0.9983, 0.9407, 0.9416,\n                      0.9459, 0.9723, 0.9887, 0.9688, 0.9466, 0.9652, 0.9725, 0.9727, 0.9774,\n                      0.9574, 0.9645, 0.9305, 0.9633, 0.9482, 0.9567, 0.9594, 0.9607, 0.9601,\n                      0.9735, 0.9529, 0.9600, 0.9547, 0.9749, 0.9565, 0.9697, 0.9553, 0.9678,\n                      0.9492, 1.0010, 0.9589, 0.9757, 0.9713, 0.9897, 0.9772, 0.9593, 1.0072,\n                      0.9574, 0.9697, 0.9534, 0.9765, 0.9794, 0.9620, 0.9813, 0.9826, 0.9359,\n                      0.9683], dtype=torch.float64)),\n             ('6.17.convpath.0.1.1.bias',\n              tensor([-0.0059,  0.0153, -0.0273,  0.0134,  0.0020,  0.0073, -0.0014, -0.0193,\n                      -0.0195, -0.0210, -0.0007, -0.0241, -0.0092, -0.0293,  0.0136, -0.0335,\n                      -0.0134, -0.0135, -0.0083, -0.0078,  0.0016, -0.0152, -0.0043, -0.0290,\n                      -0.0024,  0.0032, -0.0137,  0.0006, -0.0026, -0.0082, -0.0061, -0.0051,\n                      -0.0238, -0.0061, -0.0049, -0.0108,  0.0136, -0.0154, -0.0134, -0.0098,\n                       0.0134, -0.0236,  0.0085, -0.0122,  0.0093, -0.0199,  0.0123, -0.0056,\n                      -0.0313,  0.0074, -0.0245, -0.0017,  0.0080,  0.0105, -0.0094,  0.0024,\n                      -0.0106, -0.0018, -0.0098, -0.0083,  0.0004, -0.0059, -0.0045,  0.0082],\n                     dtype=torch.float64)),\n             ('6.17.convpath.0.1.1.running_mean',\n              tensor([ 0.1076,  0.0531,  0.3838, -0.4194,  0.2765,  1.0686,  0.4875,  0.9236,\n                       0.1217,  0.7606, -0.9840,  0.9500, -0.4870, -0.3049,  0.5356,  1.5241,\n                      -0.0368, -0.8052, -0.0407, -0.0346, -0.6509,  0.1868, -0.5836,  0.5512,\n                       0.3642, -0.4180,  0.5873,  0.3476,  0.5529, -0.1865,  0.2539, -0.6929,\n                      -0.4648,  0.5983, -0.1700, -0.2726, -0.1861,  0.2151,  0.2371, -0.2833,\n                      -0.0923,  0.2916, -0.4289, -1.1124, -0.8487,  0.0323, -0.3319,  0.6912,\n                       0.9337,  0.3910,  0.8991,  0.0033,  1.0178,  0.3381, -1.1239,  0.2089,\n                       0.6657, -0.8024,  1.2301, -0.1110, -0.1906, -0.4709,  0.1098, -0.1694],\n                     dtype=torch.float64)),\n             ('6.17.convpath.0.1.1.running_var',\n              tensor([0.5253, 0.6203, 0.6087, 0.3960, 0.2999, 0.4142, 0.5388, 0.5990, 0.6290,\n                      0.5431, 0.7907, 0.4143, 0.4195, 0.4786, 0.3714, 0.5621, 0.4939, 0.4016,\n                      0.5699, 0.5559, 0.5137, 0.5611, 0.5967, 0.7345, 0.4974, 0.4699, 0.6522,\n                      0.4545, 0.4128, 0.5330, 0.5432, 0.6835, 0.4363, 0.8313, 0.4695, 0.8678,\n                      0.4816, 0.3829, 0.7665, 0.5329, 0.4250, 1.1877, 0.4461, 0.5738, 0.5738,\n                      0.4175, 0.4046, 0.4687, 0.3871, 0.5521, 0.6238, 0.4324, 0.5601, 0.4125,\n                      0.5125, 0.6241, 0.5805, 0.5618, 0.3811, 0.5905, 0.6000, 0.4785, 0.5265,\n                      0.3171], dtype=torch.float64)),\n             ('6.17.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.17.convpath.0.2.0.weight',\n              tensor([[[-0.0794],\n                       [-0.1554],\n                       [ 0.1495],\n                       ...,\n                       [ 0.1434],\n                       [-0.0471],\n                       [-0.1191]],\n              \n                      [[ 0.0439],\n                       [ 0.0580],\n                       [-0.0277],\n                       ...,\n                       [-0.1035],\n                       [-0.0186],\n                       [-0.1371]],\n              \n                      [[ 0.0437],\n                       [-0.0252],\n                       [ 0.0775],\n                       ...,\n                       [ 0.1078],\n                       [ 0.2906],\n                       [-0.0108]],\n              \n                      ...,\n              \n                      [[-0.0177],\n                       [-0.1471],\n                       [ 0.0080],\n                       ...,\n                       [-0.0669],\n                       [ 0.0281],\n                       [-0.3486]],\n              \n                      [[-0.1739],\n                       [ 0.2456],\n                       [-0.1407],\n                       ...,\n                       [ 0.0558],\n                       [-0.1788],\n                       [ 0.0984]],\n              \n                      [[-0.1239],\n                       [-0.1243],\n                       [ 0.0225],\n                       ...,\n                       [-0.0854],\n                       [-0.1869],\n                       [ 0.0199]]], dtype=torch.float64)),\n             ('6.17.convpath.0.2.1.weight',\n              tensor([ 0.0045,  0.0041, -0.0233,  0.0119,  0.0216, -0.0186,  0.0135, -0.0435,\n                       0.0137,  0.0382, -0.0151,  0.0052, -0.0125, -0.0150, -0.0153,  0.0216,\n                      -0.0262,  0.0083,  0.0091, -0.0370, -0.0102, -0.0245,  0.0087, -0.0046,\n                       0.0291,  0.0240,  0.0230, -0.0279,  0.0274,  0.0013,  0.0226,  0.0087,\n                       0.0147, -0.0231, -0.0045,  0.0025, -0.0028, -0.0222, -0.0135,  0.0266,\n                       0.0113,  0.0007,  0.0258, -0.0053,  0.0051, -0.0173, -0.0004, -0.0130,\n                      -0.0150, -0.0130, -0.0232,  0.0059, -0.0045,  0.0100, -0.0163,  0.0428,\n                       0.0133, -0.0004, -0.0009,  0.0105,  0.0072, -0.0039, -0.0133,  0.0011,\n                      -0.0349, -0.0419,  0.0073,  0.0144,  0.0186,  0.0272, -0.0201, -0.0132,\n                      -0.0191, -0.0073, -0.0010, -0.0238, -0.0139, -0.0123, -0.0195, -0.0244,\n                      -0.0068,  0.0110, -0.0179,  0.0168,  0.0218, -0.0199,  0.0165, -0.0164,\n                       0.0058, -0.0064, -0.0163,  0.0019,  0.0396, -0.0007, -0.0215,  0.0076,\n                      -0.0004,  0.0111, -0.0291, -0.0323,  0.0423, -0.0094,  0.0344,  0.0076,\n                      -0.0301,  0.0032,  0.0256,  0.0029, -0.0495, -0.0139,  0.0022,  0.0087,\n                       0.0089, -0.0109,  0.0030,  0.0174,  0.0048,  0.0168, -0.0151, -0.0104,\n                      -0.0007, -0.0208,  0.0175, -0.0113, -0.0355,  0.0031,  0.0363, -0.0085,\n                      -0.0009,  0.0151,  0.0120, -0.0446,  0.0325,  0.0078, -0.0035,  0.0156,\n                       0.0295, -0.0103,  0.0229,  0.0157, -0.0066,  0.0062, -0.0012,  0.0025,\n                      -0.0159,  0.0192, -0.0056, -0.0278, -0.0042,  0.0019, -0.0159,  0.0007,\n                      -0.0339,  0.0181, -0.0011, -0.0128, -0.0080,  0.0027, -0.0100, -0.0229,\n                       0.0100,  0.0020,  0.0079,  0.0152,  0.0299,  0.0030,  0.0277,  0.0017,\n                      -0.0342, -0.0192,  0.0107, -0.0099,  0.0032,  0.0070,  0.0262,  0.0313,\n                       0.0048, -0.0215, -0.0190,  0.0052,  0.0057, -0.0039,  0.0073,  0.0062,\n                      -0.0301, -0.0257, -0.0250, -0.0010, -0.0320,  0.0150, -0.0213, -0.0154,\n                       0.0179,  0.0004,  0.0121, -0.0026,  0.0176,  0.0256, -0.0055,  0.0062,\n                       0.0135, -0.0113, -0.0226,  0.0230,  0.0061,  0.0081,  0.0147,  0.0050,\n                       0.0138, -0.0072,  0.0056, -0.0111, -0.0146, -0.0244, -0.0157,  0.0225,\n                      -0.0080, -0.0289, -0.0022, -0.0338,  0.0064, -0.0354,  0.0154,  0.0002,\n                      -0.0001,  0.0075,  0.0323, -0.0307, -0.0070,  0.0077,  0.0133,  0.0108,\n                       0.0132,  0.0105, -0.0028,  0.0381,  0.0076,  0.0011, -0.0230, -0.0130,\n                      -0.0158, -0.0173,  0.0144,  0.0095, -0.0140, -0.0332,  0.0263, -0.0204,\n                      -0.0078, -0.0084,  0.0388,  0.0386,  0.0169,  0.0194, -0.0512, -0.0069],\n                     dtype=torch.float64)),\n             ('6.17.convpath.0.2.1.bias',\n              tensor([-4.5486e-05,  6.0256e-03,  9.3203e-03,  1.4539e-02,  1.3087e-03,\n                       5.6782e-03,  6.0570e-03, -7.3542e-04,  5.3249e-04,  1.6577e-02,\n                       1.6396e-02, -7.3291e-03,  2.5514e-03, -5.6310e-03,  5.6751e-03,\n                       4.0660e-03,  2.7858e-02,  5.8710e-04,  1.1688e-02, -4.9836e-03,\n                      -1.0568e-02,  1.6861e-03,  8.4686e-03,  4.6090e-03,  9.6537e-03,\n                      -1.7670e-02,  6.8723e-03,  5.2994e-03,  1.3304e-02, -5.5060e-03,\n                      -1.8059e-03,  1.1647e-02,  3.5535e-03,  1.7987e-02,  1.0142e-02,\n                       1.3516e-02,  2.3112e-04,  1.1144e-02,  9.6727e-03,  6.7899e-03,\n                       3.8965e-03,  2.2842e-03, -7.8735e-03, -4.6794e-03,  7.4168e-03,\n                      -1.7873e-02,  1.2272e-02,  5.5425e-03, -1.3350e-02, -1.4436e-05,\n                       1.1693e-02,  3.4187e-03,  5.9580e-03,  1.9528e-02, -4.5441e-04,\n                       1.1899e-02,  1.0841e-02,  5.4668e-03,  6.3329e-03, -5.1205e-03,\n                      -5.9168e-04,  1.8611e-03,  9.1517e-03,  8.8308e-03, -1.0028e-02,\n                      -1.5754e-04, -4.1114e-03,  1.5066e-02,  1.7317e-02, -1.6164e-02,\n                       7.3855e-03, -3.8283e-03, -1.0748e-03, -7.6576e-03,  1.3662e-02,\n                       7.4842e-03,  1.6951e-03,  1.8237e-02, -3.9403e-04,  1.3537e-02,\n                       4.5510e-03, -7.9282e-03,  2.0848e-02,  3.6059e-03, -7.7019e-03,\n                       1.8586e-02, -1.7934e-03,  8.4113e-03,  1.2737e-02, -4.3181e-04,\n                       1.4576e-03,  1.2780e-02,  1.0248e-02, -6.6179e-03,  6.4495e-03,\n                      -4.8571e-03,  1.5484e-02,  5.4774e-03,  2.0043e-02,  8.2383e-03,\n                       2.3438e-02,  1.5568e-02,  6.3293e-03,  1.3777e-02,  1.1332e-02,\n                       2.2643e-03, -9.1796e-03,  1.0896e-02,  6.0323e-03,  6.4556e-03,\n                      -2.8244e-04, -6.4253e-03,  2.2538e-03,  2.2485e-02,  1.7934e-02,\n                       5.1690e-03,  5.2958e-03,  3.3799e-03,  2.8632e-03, -3.2200e-03,\n                       3.1456e-03,  1.0977e-02,  3.3900e-03,  4.1344e-03,  1.9959e-02,\n                       8.3535e-03,  5.1631e-03,  4.9004e-03,  3.8810e-03,  1.4662e-02,\n                       8.1672e-03,  7.7800e-03,  1.3100e-02,  1.4073e-03,  6.0063e-03,\n                      -1.8018e-02,  1.3580e-02,  3.9374e-03,  5.4135e-03,  8.2910e-03,\n                       1.5792e-02,  1.1208e-02,  1.1902e-02,  1.8086e-03, -8.0435e-03,\n                       9.0699e-03,  6.0981e-03, -3.1861e-03,  4.7604e-03,  2.9878e-03,\n                       7.9735e-03,  9.9461e-03,  6.9924e-03,  1.1382e-02,  1.4283e-02,\n                       3.0344e-03, -6.7065e-04,  4.5958e-03,  4.1192e-03, -1.5040e-03,\n                       5.6651e-03,  8.7652e-03, -1.8505e-03,  6.6854e-03,  1.1015e-02,\n                      -5.3422e-03, -9.5780e-03,  5.3796e-03,  5.8183e-03,  1.1702e-02,\n                       1.1239e-02, -2.5882e-03,  1.0441e-02,  1.5723e-02, -1.3589e-02,\n                       1.2948e-02, -1.0222e-04,  1.8138e-02,  2.3002e-03,  2.1699e-03,\n                      -7.3694e-04,  9.1046e-03, -1.9512e-03, -7.9285e-03,  9.8535e-03,\n                       7.0501e-03,  1.0547e-02,  8.7334e-03,  8.2931e-03,  3.7524e-03,\n                       6.6465e-03,  6.2764e-03,  6.8081e-03,  9.5316e-03,  5.7852e-03,\n                       9.4402e-03,  1.0103e-02,  4.6320e-04,  5.7802e-03,  1.2478e-02,\n                      -5.4578e-04,  2.2199e-02,  1.4904e-02,  1.6152e-02,  1.7721e-02,\n                       4.9351e-03,  8.8235e-03, -1.0745e-02,  3.7662e-03,  7.8666e-03,\n                       8.1069e-03,  9.6116e-03, -3.1557e-03,  9.1075e-03,  6.4481e-03,\n                       7.6962e-03,  1.7362e-03,  1.5496e-02,  2.2152e-03,  1.3356e-03,\n                       1.5570e-02,  8.1333e-03,  5.5015e-03,  1.3156e-02,  8.4536e-03,\n                       4.8096e-03, -4.3397e-03, -3.1354e-03,  2.4866e-02,  1.8989e-02,\n                       4.7648e-03, -2.2109e-04,  8.2660e-03,  6.3731e-03, -7.4253e-04,\n                       8.6815e-03, -2.2512e-03,  1.4911e-02,  4.3540e-03,  1.4208e-02,\n                       1.3251e-04,  2.7282e-03, -6.1565e-03,  1.2093e-02,  1.4628e-03,\n                       1.0310e-02,  6.6734e-03,  4.5486e-04, -1.6654e-02, -9.6438e-03,\n                       1.8525e-02,  2.3138e-02,  1.1708e-02,  1.7715e-02,  4.1041e-03,\n                       2.3974e-03], dtype=torch.float64)),\n             ('6.17.convpath.0.2.1.running_mean',\n              tensor([ 3.7024e-01,  2.0199e-01, -5.8932e-01, -2.9456e-01, -1.5762e-02,\n                      -5.4308e-01,  2.4270e-01,  6.8195e-01,  1.6808e-01,  1.8157e-01,\n                      -3.1067e-02, -9.1627e-02,  3.3589e-01,  4.3754e-01,  4.4139e-01,\n                      -4.1747e-01, -6.2627e-01, -3.7111e-01, -3.3084e-03,  4.4530e-01,\n                       1.8779e-01,  3.8325e-01,  5.7041e-01, -2.0387e-01, -4.7382e-01,\n                      -4.3674e-03,  6.2565e-01,  4.0120e-01,  4.0990e-01, -1.0849e-01,\n                      -1.3312e-01,  3.0331e-01,  2.9492e-01,  9.3740e-01, -1.1587e-01,\n                      -3.0130e-01,  3.9192e-01,  3.5150e-01,  2.3179e-01,  4.3525e-02,\n                      -2.9420e-02, -1.8285e-01, -3.0051e-01, -3.1498e-01,  5.9791e-01,\n                       1.9901e-01,  4.5652e-01, -2.9374e-01,  2.0447e-01,  3.7247e-01,\n                       3.6691e-01, -5.0435e-03, -6.8386e-02, -6.0224e-01, -6.4418e-02,\n                       6.7236e-01, -4.6991e-01,  5.7562e-02, -4.7838e-01, -2.9798e-02,\n                       5.0790e-01, -1.7083e-01,  1.2350e-01, -2.8500e-01,  3.9261e-01,\n                       1.4347e-01, -6.2737e-04, -3.0265e-02,  2.3465e-01,  5.5923e-01,\n                      -5.0849e-01,  2.7459e-02,  1.4260e-01,  1.4072e-01,  4.1721e-01,\n                       5.4835e-02,  6.4167e-01,  3.9489e-01, -5.6341e-01, -4.1856e-01,\n                       5.1450e-01, -1.0079e-01,  7.9869e-02, -3.7211e-01,  1.3429e-01,\n                      -6.5351e-01, -2.6659e-01, -5.0698e-01,  2.3678e-01, -2.6831e-01,\n                      -3.9020e-01, -2.2874e-02,  8.1380e-02,  1.4259e-01,  8.5290e-01,\n                       5.9297e-01, -5.8248e-01,  6.3449e-01, -8.1682e-01, -7.3134e-02,\n                      -5.8580e-01,  2.9379e-01,  1.1317e-01,  1.6616e-01, -3.8099e-01,\n                       3.2084e-01,  1.3036e-01,  4.1928e-01,  5.3826e-01,  7.2245e-01,\n                       3.9075e-02,  8.0109e-01,  1.2795e-02,  3.6939e-01,  2.6068e-01,\n                      -5.8114e-01,  3.8999e-01, -1.6727e-01,  2.0008e-01, -2.2343e-01,\n                       1.2692e-01, -4.4147e-01,  2.9411e-01, -7.3177e-01,  4.8792e-01,\n                       9.3940e-01,  1.3152e-01, -9.1903e-02,  7.7173e-02, -6.1913e-01,\n                       2.6078e-01,  5.7101e-01,  1.2481e-01, -1.6686e-02, -4.2232e-02,\n                       1.3614e-01, -4.2237e-01,  8.9904e-02,  3.6924e-01,  1.7907e-01,\n                      -2.4065e-01,  3.2218e-01, -3.4991e-01,  2.2324e-01,  2.2254e-01,\n                       5.1009e-01, -2.6143e-01, -8.9272e-01, -2.4157e-02, -4.4340e-01,\n                      -1.0770e-01,  1.8312e-01, -3.8298e-01, -8.0961e-02, -7.4842e-02,\n                      -1.9189e-01, -5.0744e-01, -1.4356e-01, -1.1591e-01, -4.2615e-01,\n                      -2.3919e-01, -2.5695e-01, -1.2306e-01, -2.6789e-01, -6.3123e-01,\n                       1.3136e-04, -9.0787e-01, -3.6040e-01,  3.2891e-01, -2.7260e-01,\n                      -7.6605e-02, -4.5037e-01, -2.3511e-01, -4.7999e-01, -1.3458e-02,\n                       3.7782e-01,  6.3541e-02,  2.3703e-02,  4.6335e-01,  7.8672e-02,\n                      -4.3246e-01,  7.9925e-01, -5.4128e-01,  5.2813e-01, -3.3250e-01,\n                       4.3922e-01, -1.1671e-01,  1.8851e-01,  2.4798e-01,  5.2746e-01,\n                       1.6409e-02,  7.2987e-01, -3.0908e-01,  4.6262e-02,  9.6338e-01,\n                       8.1525e-01,  1.5216e-01, -2.1230e-01,  2.7901e-01,  1.9349e-01,\n                      -2.9105e-01,  5.3078e-01,  1.5774e-01, -2.0463e-01,  2.1300e-01,\n                       5.6954e-01,  4.3563e-01,  1.1149e-01,  2.7809e-01, -1.7339e-01,\n                      -2.7596e-01, -1.0872e+00, -9.6208e-02, -1.6955e-01, -5.7735e-01,\n                       3.3802e-01,  3.4071e-01,  1.5794e-02, -6.2159e-02,  5.0687e-01,\n                       3.1973e-01,  2.7486e-02,  9.7964e-02, -1.7091e-02, -9.1394e-01,\n                      -5.5152e-02, -1.1772e-01,  1.1513e-01, -2.2522e-01, -2.2518e-01,\n                       8.7394e-02, -3.6991e-01, -7.9692e-01, -2.0979e-01, -5.6866e-02,\n                      -1.2670e-01, -1.0352e-01, -3.9386e-01, -1.9357e-01,  4.3411e-01,\n                      -4.9134e-01, -7.3731e-02,  3.5982e-01, -1.7892e-01,  2.2660e-01,\n                       5.9985e-01, -8.4993e-02, -1.5441e-01,  2.1440e-01,  4.4953e-01,\n                       1.5204e-01, -8.1264e-01, -7.8709e-02, -6.6976e-01,  2.3725e-01,\n                      -4.3351e-01], dtype=torch.float64)),\n             ('6.17.convpath.0.2.1.running_var',\n              tensor([0.4834, 0.2445, 0.4250, 0.4389, 0.2160, 0.4665, 0.4324, 0.6194, 0.3131,\n                      0.5174, 0.3143, 0.2008, 0.2788, 0.5726, 0.2613, 0.5530, 0.3823, 0.3396,\n                      0.3076, 0.5625, 0.1679, 0.5683, 0.3463, 0.3091, 0.4258, 0.2476, 0.3051,\n                      0.4082, 0.4261, 0.1978, 0.7196, 0.2739, 0.2767, 0.4441, 0.3076, 0.3342,\n                      0.0811, 0.2860, 0.2839, 0.4172, 0.3195, 0.1690, 0.1475, 0.4127, 0.3228,\n                      0.5583, 0.2369, 0.1649, 0.3827, 0.2620, 0.5234, 0.4196, 0.3438, 0.2099,\n                      0.4946, 0.4881, 0.5881, 0.3282, 0.6560, 0.1514, 0.1317, 0.1007, 0.1751,\n                      0.1825, 0.2969, 0.3156, 0.3539, 0.3036, 0.2313, 0.6777, 0.3586, 0.3528,\n                      0.1945, 0.4021, 0.4117, 0.3253, 0.4511, 0.3565, 0.4871, 0.3781, 0.3168,\n                      0.4729, 0.2951, 0.4289, 0.5328, 0.6612, 0.3624, 0.4502, 0.2456, 0.2601,\n                      0.5935, 0.1553, 0.4542, 0.2070, 0.3745, 0.4115, 0.3708, 0.1990, 0.4252,\n                      0.3363, 0.5051, 0.3461, 0.4251, 0.1150, 0.4776, 0.0926, 0.4658, 0.6165,\n                      0.3205, 0.3335, 0.1285, 0.5038, 0.4889, 0.5185, 0.3024, 0.4351, 0.5167,\n                      0.4952, 0.3016, 0.3540, 0.1233, 0.3830, 0.3595, 0.4158, 0.3526, 0.3903,\n                      0.3123, 0.2241, 0.0856, 0.4551, 0.3894, 0.3268, 0.3814, 0.0969, 0.3195,\n                      0.3051, 0.2632, 0.3055, 0.3501, 0.3030, 0.2753, 0.2809, 0.2193, 0.0746,\n                      0.1382, 0.8117, 0.0877, 0.5908, 0.0776, 0.2687, 0.6965, 0.2212, 0.4589,\n                      0.4283, 0.1816, 0.3318, 0.4388, 0.0761, 0.2122, 0.2887, 0.3384, 0.3440,\n                      0.2722, 0.2363, 0.5354, 0.4137, 0.3240, 0.1577, 0.4402, 0.4709, 0.0716,\n                      0.2064, 0.2588, 0.1717, 0.3567, 0.4416, 0.1605, 0.3168, 0.2784, 0.1911,\n                      0.4119, 0.1748, 0.4294, 0.3043, 0.2657, 0.5145, 0.4997, 0.1051, 0.5464,\n                      0.3533, 0.4112, 0.3274, 0.3064, 0.5507, 0.3906, 0.3060, 0.5791, 0.3679,\n                      0.2572, 0.3905, 0.1842, 0.2337, 0.5736, 0.6057, 0.2915, 0.3813, 0.3652,\n                      0.0254, 0.2391, 0.3461, 0.0871, 0.3246, 0.2150, 0.5893, 0.3394, 0.4176,\n                      0.4271, 0.3352, 0.0980, 0.5630, 0.2918, 0.2940, 0.2407, 0.2996, 0.6469,\n                      0.3469, 0.4700, 0.3163, 0.5411, 0.4300, 0.2391, 0.4199, 0.6520, 0.2476,\n                      0.1674, 0.3415, 0.1240, 0.0780, 0.4357, 0.1243, 0.2961, 0.2322, 0.7925,\n                      0.1487, 0.2004, 0.3188, 0.5123, 0.4813, 0.2167, 0.4056, 0.5035, 0.5278,\n                      0.3785, 0.3716, 0.3405, 0.3593], dtype=torch.float64)),\n             ('6.17.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.18.convs.0.0.weight',\n              tensor([[[ 0.0326],\n                       [ 0.0622],\n                       [ 0.0897],\n                       ...,\n                       [-0.0259],\n                       [-0.0473],\n                       [ 0.0863]],\n              \n                      [[-0.0303],\n                       [ 0.0579],\n                       [ 0.1164],\n                       ...,\n                       [-0.0343],\n                       [ 0.1348],\n                       [-0.0078]],\n              \n                      [[ 0.0598],\n                       [-0.0100],\n                       [-0.0197],\n                       ...,\n                       [-0.0651],\n                       [-0.1132],\n                       [ 0.1284]],\n              \n                      ...,\n              \n                      [[-0.0994],\n                       [ 0.0243],\n                       [ 0.1443],\n                       ...,\n                       [ 0.0282],\n                       [-0.0606],\n                       [-0.1937]],\n              \n                      [[-0.1157],\n                       [-0.0695],\n                       [-0.1269],\n                       ...,\n                       [-0.0351],\n                       [-0.0380],\n                       [-0.1206]],\n              \n                      [[ 0.0463],\n                       [-0.1051],\n                       [-0.0652],\n                       ...,\n                       [ 0.0918],\n                       [ 0.0303],\n                       [-0.0258]]], dtype=torch.float64)),\n             ('6.18.convs.0.1.weight',\n              tensor([0.9693, 0.9608, 0.9642, 0.9795, 0.9707, 0.9424, 0.9496, 0.9757, 0.9618,\n                      0.9657, 0.9909, 0.9712, 0.9703, 1.0110, 0.9739, 0.9758, 1.0145, 1.0055,\n                      0.9801, 0.9795, 0.9615, 0.9495, 0.9829, 0.9818, 0.9797, 0.9531, 0.9648,\n                      0.9743, 0.9750, 0.9641, 0.9683, 0.9765, 0.9545, 0.9727, 0.9750, 0.9799,\n                      0.9506, 0.9660, 1.0045, 0.9571, 0.9782, 0.9508, 0.9647, 0.9892, 0.9497,\n                      0.9494, 0.9932, 0.9814, 0.9639, 0.9801, 0.9612, 0.9717, 0.9696, 0.9683,\n                      0.9565, 0.9687, 0.9876, 0.9492, 0.9585, 0.9565, 0.9756, 0.9652, 0.9740,\n                      0.9550], dtype=torch.float64)),\n             ('6.18.convs.0.1.bias',\n              tensor([ 1.4644e-03, -9.3553e-03, -7.7696e-03,  1.2056e-02, -1.9368e-02,\n                       7.0443e-03, -1.3395e-02, -1.1643e-02, -9.5395e-03, -1.2194e-02,\n                       1.9161e-02,  5.6341e-04, -1.1159e-02,  2.4839e-02, -8.1317e-03,\n                      -1.6184e-03,  1.6074e-02, -8.2810e-03, -8.4647e-03,  7.7671e-03,\n                       2.2326e-04, -2.0229e-05,  9.8568e-03,  1.6711e-02,  2.7004e-02,\n                       1.4573e-02, -8.6591e-03, -2.2268e-02, -7.2342e-03, -8.6033e-03,\n                      -2.5289e-03, -6.3978e-03, -5.2394e-03,  2.8941e-03,  1.4332e-02,\n                       1.8374e-02,  1.1981e-03, -4.3097e-04,  3.2194e-02, -1.2187e-02,\n                       2.1108e-02, -8.5860e-03,  4.1466e-03,  1.5354e-02, -6.8866e-03,\n                       1.4691e-02,  1.4348e-02,  2.2744e-04, -1.6536e-02,  9.2811e-03,\n                      -4.6270e-03,  4.7947e-03,  6.3936e-03, -1.7480e-02, -1.0078e-02,\n                       1.9818e-02,  1.7869e-02,  3.7228e-03, -9.5491e-03, -9.0658e-03,\n                       1.5320e-02, -2.9019e-03,  1.6277e-03, -6.0902e-03],\n                     dtype=torch.float64)),\n             ('6.18.convs.0.1.running_mean',\n              tensor([ 0.7911,  1.0856, -0.1271,  0.4413,  1.3026, -0.8317, -0.7399, -1.2779,\n                       0.0735,  1.1619,  0.6248, -0.2560, -0.3489,  0.1403,  0.2621, -0.7375,\n                       0.0212, -0.5844,  0.2094,  0.1336, -0.1608, -1.3917,  0.0524,  0.1382,\n                      -0.8523,  0.3752, -0.5548,  0.7559,  1.2574, -0.0529,  0.7082, -0.5641,\n                      -1.4012, -0.4222, -1.2143,  0.2030, -0.1999, -1.3190, -0.2920,  0.1989,\n                      -0.1171,  0.1261,  0.4280, -1.1588,  0.6451, -0.6450, -0.5804,  0.1390,\n                      -0.3991, -0.2114, -0.0702, -0.0440,  0.2758, -0.0428, -0.8534, -1.0308,\n                       0.0107,  0.4808,  0.2333,  0.2953,  0.2533,  0.1044,  1.3181,  0.2374],\n                     dtype=torch.float64)),\n             ('6.18.convs.0.1.running_var',\n              tensor([0.1505, 0.9159, 0.3126, 0.2280, 0.2127, 0.4216, 0.1253, 0.1659, 0.1205,\n                      1.0745, 0.1182, 0.2970, 0.1873, 0.1414, 0.2570, 0.2836, 0.0983, 0.1541,\n                      0.1687, 0.1334, 0.1676, 0.5300, 0.2283, 0.2158, 0.1906, 0.1985, 0.2586,\n                      0.4634, 0.1213, 0.1751, 0.3176, 0.3535, 0.2251, 0.1867, 0.4454, 0.1679,\n                      0.1419, 0.1268, 0.1468, 0.1245, 0.1410, 0.2251, 0.1988, 0.1568, 0.2570,\n                      0.7680, 0.2041, 0.1606, 0.1948, 0.1312, 0.1316, 0.1588, 0.2987, 0.2048,\n                      0.2823, 0.1957, 0.1769, 0.1863, 0.1024, 0.1098, 0.1037, 0.2023, 0.1028,\n                      0.1515], dtype=torch.float64)),\n             ('6.18.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.18.convs.1.0.weight',\n              tensor([[[-0.0699, -0.0065,  0.0287,  0.0297,  0.0957],\n                       [ 0.0765, -0.1905,  0.1309,  0.1234, -0.0747],\n                       [-0.0673, -0.0923, -0.1309, -0.0678, -0.0278],\n                       ...,\n                       [-0.0820,  0.0623, -0.0270,  0.0348,  0.0489],\n                       [-0.1027,  0.0825,  0.0055,  0.0275,  0.0665],\n                       [ 0.1255, -0.1047, -0.0907, -0.0772, -0.0879]],\n              \n                      [[ 0.0024,  0.0277,  0.0817, -0.0020,  0.0155],\n                       [-0.0345,  0.0154, -0.0585,  0.0028,  0.1844],\n                       [ 0.0749, -0.0277,  0.0359,  0.0443, -0.0576],\n                       ...,\n                       [ 0.0352,  0.0201, -0.0416, -0.1004,  0.0328],\n                       [-0.0307, -0.0453, -0.0767, -0.0677, -0.0190],\n                       [ 0.0831,  0.0273,  0.0701,  0.0060, -0.1484]],\n              \n                      [[ 0.1036,  0.0110, -0.0590, -0.0081, -0.0507],\n                       [ 0.0192,  0.1049, -0.0535, -0.0701,  0.1101],\n                       [ 0.0387,  0.0267,  0.1388, -0.0512, -0.0071],\n                       ...,\n                       [-0.0349, -0.1413, -0.0051,  0.0827,  0.0311],\n                       [-0.1081,  0.0131, -0.0557,  0.0370, -0.1276],\n                       [-0.1572,  0.0660,  0.0661,  0.0362, -0.0224]],\n              \n                      ...,\n              \n                      [[ 0.0082,  0.0575, -0.0559,  0.0069, -0.0443],\n                       [ 0.0223,  0.1566, -0.0250, -0.0507, -0.0568],\n                       [ 0.0224, -0.0563, -0.0884,  0.1039,  0.0485],\n                       ...,\n                       [ 0.0514, -0.0394,  0.0670,  0.0471, -0.0902],\n                       [-0.1240, -0.0415,  0.1104, -0.0603, -0.0023],\n                       [-0.1577, -0.0558, -0.1134, -0.0116, -0.0240]],\n              \n                      [[ 0.0725,  0.0531, -0.0406, -0.0116,  0.0553],\n                       [ 0.0502, -0.0395,  0.0592,  0.0314,  0.1352],\n                       [-0.0075, -0.0009,  0.1412,  0.2115,  0.0184],\n                       ...,\n                       [ 0.0462,  0.0162, -0.1095, -0.0886,  0.1991],\n                       [-0.0826, -0.0101, -0.0229,  0.0448,  0.1285],\n                       [ 0.0721,  0.0141,  0.0232,  0.0370,  0.0098]],\n              \n                      [[-0.1181, -0.0504, -0.0034,  0.0041,  0.0623],\n                       [-0.1397, -0.0815,  0.0469, -0.0488, -0.1109],\n                       [ 0.0548,  0.0719, -0.1314, -0.1144, -0.0111],\n                       ...,\n                       [ 0.0296, -0.0649,  0.0560,  0.1466, -0.0326],\n                       [-0.0958,  0.0471,  0.0475,  0.0230, -0.0047],\n                       [ 0.0281, -0.0935,  0.0127, -0.0664,  0.0094]]], dtype=torch.float64)),\n             ('6.18.convs.1.1.weight',\n              tensor([0.9610, 0.9796, 0.9399, 0.9772, 0.9852, 0.9276, 0.9653, 0.9428, 0.9817,\n                      0.9708, 0.9792, 0.9787, 0.9495, 0.9730, 0.9661, 0.9821, 0.9755, 0.9922,\n                      0.9722, 0.9525, 0.9702, 0.9589, 0.9802, 0.9466, 0.9428, 0.9781, 0.9721,\n                      0.9552, 0.9784, 0.9666, 0.9656, 0.9536, 0.9580, 0.9861, 0.9820, 0.9272,\n                      0.9512, 0.9577, 0.9557, 0.9499, 0.9775, 0.9682, 0.9534, 0.9523, 0.9661,\n                      0.9558, 0.9686, 0.9579, 0.9607, 0.9707, 0.9890, 0.9573, 0.9552, 0.9642,\n                      0.9554, 0.9669, 0.9755, 0.9673, 0.9896, 0.9975, 0.9615, 0.9542, 0.9897,\n                      0.9682], dtype=torch.float64)),\n             ('6.18.convs.1.1.bias',\n              tensor([-0.0083,  0.0096, -0.0079, -0.0098,  0.0079, -0.0072, -0.0049, -0.0050,\n                       0.0128,  0.0003, -0.0059,  0.0048,  0.0007, -0.0159, -0.0177,  0.0013,\n                      -0.0036, -0.0074,  0.0013, -0.0037, -0.0008, -0.0225, -0.0277, -0.0147,\n                      -0.0052,  0.0068, -0.0047, -0.0051,  0.0010,  0.0037, -0.0112, -0.0296,\n                      -0.0108, -0.0085, -0.0104, -0.0267, -0.0272, -0.0071, -0.0062, -0.0133,\n                       0.0093, -0.0065,  0.0006, -0.0245, -0.0201,  0.0038,  0.0084, -0.0220,\n                       0.0094,  0.0113,  0.0176, -0.0176, -0.0246,  0.0101, -0.0076, -0.0283,\n                      -0.0062, -0.0346,  0.0031,  0.0148,  0.0105, -0.0175, -0.0025, -0.0077],\n                     dtype=torch.float64)),\n             ('6.18.convs.1.1.running_mean',\n              tensor([-0.2456,  0.3734, -0.3205, -0.4581, -0.0111, -0.2860,  0.5471,  0.0383,\n                       0.2086,  0.3688,  0.0716, -1.3562, -0.2441, -0.5892, -0.0978, -0.3246,\n                      -0.0569,  0.6194, -0.3676,  0.0369, -0.5219, -0.1303, -0.4742, -0.6607,\n                      -0.5371, -0.4513, -0.6930, -0.6633,  0.6716, -0.4953, -0.2153, -0.4817,\n                      -0.8008, -0.4875,  0.2456, -0.1912,  0.2986,  0.3066,  0.2862, -0.1004,\n                      -0.4656, -0.0087, -0.6817, -0.5223,  0.5085, -0.4211, -1.0567,  0.3645,\n                      -0.7002,  0.0866,  0.1141,  0.3119,  0.9414,  1.3299, -0.1979, -0.3982,\n                       0.5804,  0.2144, -0.5156,  0.3599, -0.9109, -0.1137, -0.2019, -0.5339],\n                     dtype=torch.float64)),\n             ('6.18.convs.1.1.running_var',\n              tensor([0.5257, 0.6336, 0.4815, 0.7168, 0.8632, 0.7030, 0.3303, 0.4625, 0.4001,\n                      0.4910, 0.4410, 0.8068, 0.7808, 0.4280, 0.5905, 0.6657, 0.6357, 0.4209,\n                      0.5663, 0.4526, 0.4523, 0.4809, 0.3738, 0.4723, 0.6604, 0.4958, 0.6646,\n                      0.5248, 0.6344, 0.5742, 0.4544, 0.5549, 0.6469, 0.4479, 0.4748, 0.5404,\n                      0.6669, 0.6506, 0.3404, 0.4634, 0.6312, 0.6308, 0.7208, 0.6500, 0.4138,\n                      0.6190, 0.5990, 0.6618, 0.5618, 0.5002, 0.5534, 0.4077, 0.4548, 0.7171,\n                      0.6190, 0.5977, 0.7583, 0.8713, 0.5393, 0.5285, 0.5386, 0.5539, 0.5991,\n                      0.5065], dtype=torch.float64)),\n             ('6.18.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.18.convs.2.0.weight',\n              tensor([[[-0.0606],\n                       [-0.0881],\n                       [ 0.1923],\n                       ...,\n                       [ 0.0470],\n                       [ 0.0801],\n                       [ 0.0749]],\n              \n                      [[ 0.0503],\n                       [-0.0712],\n                       [ 0.0044],\n                       ...,\n                       [ 0.0589],\n                       [-0.0123],\n                       [-0.0054]],\n              \n                      [[-0.1691],\n                       [-0.0244],\n                       [-0.0830],\n                       ...,\n                       [-0.1529],\n                       [ 0.0536],\n                       [-0.1610]],\n              \n                      ...,\n              \n                      [[-0.2000],\n                       [-0.0557],\n                       [-0.1459],\n                       ...,\n                       [ 0.0996],\n                       [ 0.1150],\n                       [ 0.0637]],\n              \n                      [[-0.1319],\n                       [ 0.0597],\n                       [-0.0909],\n                       ...,\n                       [ 0.0110],\n                       [-0.2066],\n                       [-0.1393]],\n              \n                      [[ 0.0124],\n                       [-0.0879],\n                       [-0.0872],\n                       ...,\n                       [ 0.1538],\n                       [ 0.1130],\n                       [-0.0020]]], dtype=torch.float64)),\n             ('6.18.convs.2.1.weight',\n              tensor([ 1.9600e-02,  1.2067e-02,  1.7449e-02,  3.0706e-03,  5.4469e-03,\n                      -8.3460e-03, -5.6302e-03, -1.6789e-02,  8.8008e-03, -7.9497e-03,\n                      -1.0700e-02,  5.5923e-03,  5.7849e-03,  8.3630e-03,  5.8248e-03,\n                       1.3987e-02, -5.2145e-02, -1.1648e-02,  6.8550e-03,  9.1247e-03,\n                      -1.2569e-02,  9.2128e-04,  2.4236e-02,  1.2678e-02,  1.3325e-02,\n                       1.8923e-02, -2.2389e-02,  6.4395e-03, -1.1526e-02,  2.3172e-02,\n                      -9.6461e-03,  3.0464e-02,  1.7222e-02, -1.8433e-02, -6.9785e-02,\n                       1.6874e-02,  1.7926e-02,  4.8753e-03,  1.7527e-03, -1.1408e-03,\n                      -1.1214e-02,  2.8707e-02, -5.8988e-03,  7.0184e-03,  6.1359e-03,\n                       2.9272e-02, -2.9838e-02, -5.2065e-03, -3.5785e-02, -2.0929e-02,\n                      -3.0276e-02, -1.2769e-02, -2.1736e-02, -1.5033e-03,  1.2660e-02,\n                       1.0708e-02, -1.4412e-02,  8.9157e-04, -5.7865e-03,  5.8098e-03,\n                       3.6804e-03,  1.4412e-02,  1.5876e-03, -4.7275e-02, -2.5694e-02,\n                      -1.0761e-02, -5.0806e-03, -3.4255e-02,  9.4502e-03, -2.0274e-02,\n                       8.4346e-03,  7.2065e-03, -7.8735e-03, -1.9829e-02,  9.2813e-03,\n                       1.0792e-02, -2.7873e-02, -2.4430e-02, -1.9158e-02, -1.2250e-02,\n                       1.4809e-02,  2.2369e-02,  5.0336e-03, -8.5300e-03, -3.0914e-02,\n                      -1.9050e-03,  1.6162e-02,  1.3694e-02, -7.0497e-03, -2.9154e-02,\n                       3.1416e-02,  1.2979e-02, -1.2714e-02,  8.5382e-03,  1.8068e-03,\n                      -1.9883e-02, -1.8492e-02,  5.3051e-03,  2.5011e-02,  1.6844e-02,\n                       2.9109e-04,  1.8003e-02, -7.7917e-03,  4.0893e-02,  1.1443e-02,\n                       2.2266e-02, -3.1417e-03,  1.2431e-02, -7.0870e-04,  6.6558e-03,\n                       9.8892e-03,  1.3473e-02, -9.8680e-03,  9.2901e-03,  2.2994e-02,\n                      -2.0649e-02, -6.9128e-03,  3.0918e-02,  5.5584e-03,  3.1578e-02,\n                      -1.2305e-02, -1.8649e-02,  1.4175e-02,  4.2901e-03,  9.4881e-03,\n                       5.1201e-02, -8.8319e-03,  5.7289e-03,  9.9962e-04,  8.0820e-03,\n                      -5.2919e-03,  9.1284e-03, -2.6513e-02,  1.9012e-03, -1.2204e-02,\n                      -1.2970e-02, -6.1749e-03, -1.0992e-02, -1.8732e-02, -2.2937e-02,\n                       1.3254e-02,  4.8321e-03,  2.4983e-02, -5.8679e-04,  1.7433e-02,\n                       2.0568e-02, -2.8096e-03, -8.8333e-03, -1.1907e-02,  2.9226e-03,\n                      -9.4637e-03, -1.2581e-02, -4.3402e-03,  8.8420e-03, -1.9088e-03,\n                      -1.3332e-02,  8.2638e-03,  3.7064e-03, -1.5463e-02,  9.1711e-04,\n                      -3.7246e-03,  1.4282e-02,  3.9456e-03,  2.1891e-02, -2.5818e-02,\n                       5.5600e-03, -5.9263e-03, -1.9170e-02, -1.2410e-02,  2.7370e-02,\n                      -7.9121e-03, -4.9170e-03, -8.5817e-03, -8.0854e-03,  1.7443e-02,\n                      -3.9178e-02,  9.8698e-03, -1.2641e-02, -1.6787e-02,  7.4793e-03,\n                      -2.9841e-02,  2.5893e-02, -2.2694e-02,  1.1599e-02,  8.6739e-03,\n                       1.8298e-02,  3.7548e-03, -1.4132e-02,  1.1466e-02, -1.3387e-02,\n                      -7.1240e-03, -4.8281e-02, -1.1828e-03, -2.2117e-02,  3.6535e-02,\n                      -1.1665e-02,  1.3719e-02,  2.7388e-02,  1.1115e-02,  1.5647e-02,\n                      -1.2775e-02, -2.8299e-02,  3.1611e-02, -1.0292e-02, -3.7667e-03,\n                       8.0773e-03,  2.2250e-02, -2.3351e-02,  1.9374e-02, -8.7631e-03,\n                       2.9280e-03,  8.4645e-03, -1.0909e-02,  1.0227e-02,  9.9291e-03,\n                      -1.2464e-02,  1.0244e-02,  1.1889e-02, -7.5968e-03,  2.0103e-02,\n                       7.5045e-05, -1.3698e-02, -4.7202e-04,  2.7508e-03, -2.3327e-02,\n                       1.1899e-02,  4.9536e-03, -1.3317e-03,  2.8445e-02,  9.0946e-04,\n                      -1.1273e-02, -7.9019e-03,  1.5172e-02, -1.6721e-02, -4.3719e-03,\n                       4.0167e-02, -4.9451e-03, -4.9652e-02,  2.6526e-03,  1.9213e-02,\n                      -1.4157e-02,  1.5956e-02,  1.3411e-02, -4.6567e-03, -2.0045e-03,\n                      -1.0787e-02,  1.5407e-02, -1.8295e-02, -5.5819e-03, -1.9157e-02,\n                      -2.0630e-02, -2.4605e-02,  1.3807e-02, -2.6926e-02,  7.4194e-03,\n                       1.0944e-02], dtype=torch.float64)),\n             ('6.18.convs.2.1.bias',\n              tensor([ 0.0042,  0.0061,  0.0042,  0.0152, -0.0022,  0.0079,  0.0044,  0.0012,\n                       0.0024,  0.0071,  0.0163, -0.0078,  0.0055, -0.0058,  0.0023,  0.0058,\n                       0.0274,  0.0042,  0.0115, -0.0032, -0.0079,  0.0016,  0.0076,  0.0049,\n                       0.0177, -0.0193,  0.0057,  0.0111,  0.0110, -0.0054, -0.0049,  0.0132,\n                       0.0089,  0.0155,  0.0101,  0.0138, -0.0045,  0.0092,  0.0149,  0.0005,\n                       0.0092,  0.0026, -0.0089, -0.0060,  0.0077, -0.0166,  0.0113,  0.0036,\n                      -0.0128,  0.0002,  0.0113,  0.0042,  0.0055,  0.0207,  0.0006,  0.0126,\n                       0.0102,  0.0052,  0.0052, -0.0034,  0.0015,  0.0006,  0.0134,  0.0081,\n                      -0.0112,  0.0023, -0.0058,  0.0142,  0.0187, -0.0149,  0.0085,  0.0024,\n                      -0.0007, -0.0079,  0.0131,  0.0038,  0.0039,  0.0182,  0.0011,  0.0097,\n                       0.0032, -0.0087,  0.0189,  0.0027, -0.0082,  0.0214, -0.0020,  0.0122,\n                       0.0124,  0.0002,  0.0017,  0.0132,  0.0098, -0.0075,  0.0046, -0.0064,\n                       0.0148,  0.0043,  0.0197,  0.0066,  0.0245,  0.0170,  0.0013,  0.0146,\n                       0.0066,  0.0017,  0.0049,  0.0108,  0.0057,  0.0079,  0.0033, -0.0050,\n                       0.0058,  0.0225,  0.0179,  0.0026,  0.0047,  0.0027,  0.0008, -0.0030,\n                      -0.0002,  0.0125,  0.0034,  0.0016,  0.0180,  0.0081,  0.0108,  0.0046,\n                       0.0029,  0.0134,  0.0072,  0.0065,  0.0088,  0.0019,  0.0059, -0.0133,\n                       0.0102,  0.0049,  0.0081,  0.0076,  0.0157,  0.0134,  0.0093,  0.0018,\n                      -0.0081,  0.0087,  0.0055,  0.0066,  0.0055,  0.0013,  0.0102,  0.0084,\n                       0.0044,  0.0108,  0.0140,  0.0030, -0.0019,  0.0045,  0.0042,  0.0008,\n                       0.0052,  0.0081, -0.0002,  0.0065,  0.0107, -0.0053, -0.0110,  0.0047,\n                       0.0105,  0.0114,  0.0147, -0.0022,  0.0125,  0.0150, -0.0156,  0.0129,\n                      -0.0026,  0.0130, -0.0024,  0.0036, -0.0003,  0.0110, -0.0039, -0.0065,\n                       0.0089,  0.0078,  0.0110,  0.0087,  0.0011,  0.0071,  0.0034,  0.0096,\n                       0.0050,  0.0076,  0.0124,  0.0099,  0.0092, -0.0012,  0.0056,  0.0104,\n                      -0.0004,  0.0210,  0.0141,  0.0169,  0.0148,  0.0054,  0.0074, -0.0062,\n                       0.0040,  0.0070,  0.0066,  0.0100, -0.0041,  0.0133,  0.0066,  0.0058,\n                       0.0010,  0.0162,  0.0007, -0.0013,  0.0180,  0.0101,  0.0028,  0.0134,\n                       0.0119,  0.0051, -0.0071, -0.0041,  0.0254,  0.0183,  0.0028, -0.0007,\n                       0.0064,  0.0058, -0.0020,  0.0064, -0.0035,  0.0153,  0.0021,  0.0149,\n                      -0.0031,  0.0025, -0.0076,  0.0132,  0.0007,  0.0024,  0.0070,  0.0023,\n                      -0.0211, -0.0112,  0.0185,  0.0165,  0.0095,  0.0175,  0.0033,  0.0019],\n                     dtype=torch.float64)),\n             ('6.18.convs.2.1.running_mean',\n              tensor([ 7.7297e-01, -1.0550e-01,  1.0763e-01, -8.0681e-02, -9.9735e-04,\n                      -5.5130e-01, -1.6592e-02,  4.4639e-01, -9.7016e-02,  7.2733e-01,\n                      -2.3602e-01,  2.8331e-01,  2.1040e-02,  1.0536e-01, -4.3713e-01,\n                      -2.6298e-02, -1.9619e-01,  4.0163e-01, -5.6093e-01, -6.9598e-01,\n                      -7.6822e-02, -2.1407e-01,  1.9279e-01,  2.5199e-01, -3.2156e-01,\n                      -2.6858e-01,  7.4786e-02, -1.7502e-01, -4.1488e-01,  5.4379e-01,\n                       1.3537e+00, -6.4823e-01,  2.1594e-01,  2.3014e-01,  6.8409e-01,\n                      -8.3925e-01, -6.7568e-02, -3.7324e-01,  1.0105e-01,  2.3012e-01,\n                       2.2100e-01, -1.4756e-01,  1.4439e-01,  1.9787e-01, -7.0692e-01,\n                       6.3368e-03, -8.6856e-01, -3.2146e-01,  9.9722e-02,  5.7602e-01,\n                      -2.4114e-02, -5.5874e-01,  2.5370e-01,  2.3945e-01,  3.3417e-01,\n                       5.6123e-01,  4.1261e-01,  4.2150e-01, -7.7494e-02,  1.9512e-01,\n                       5.8126e-01,  1.2466e-01,  2.5612e-01, -1.8675e-01, -1.2655e-01,\n                      -6.2670e-02,  9.1066e-04, -2.4185e-01,  2.5471e-01, -8.5520e-02,\n                       9.6745e-01,  5.2680e-01,  3.3554e-01,  6.5724e-01, -1.2188e+00,\n                      -4.0781e-01,  5.0810e-01, -1.3068e-01, -7.6112e-01, -8.2694e-02,\n                      -6.8665e-01,  8.7213e-01, -4.6975e-02,  5.0169e-02, -3.0235e-01,\n                      -2.1147e-01, -3.2663e-01,  7.5809e-01, -4.5827e-01,  5.9889e-01,\n                      -8.6986e-02, -1.3586e-01,  4.1223e-01, -4.1404e-01, -2.1901e-01,\n                      -5.6238e-01,  2.8949e-02, -7.9281e-03, -6.4932e-01, -1.4727e-01,\n                       2.7748e-03, -3.5938e-01, -6.4176e-01, -8.0207e-01,  3.4256e-01,\n                       2.6874e-01,  8.5718e-02,  2.8744e-01,  2.1488e-01,  2.3778e-01,\n                       2.4563e-01, -1.2899e-02,  2.1048e-01, -6.7537e-01,  5.3172e-01,\n                       4.1443e-01,  5.7816e-01, -6.9320e-01,  3.6026e-01, -8.7836e-02,\n                      -2.5065e-01, -6.7196e-01,  3.5993e-01,  2.1463e-01,  1.3988e-01,\n                      -5.8351e-01, -8.5797e-02,  5.1361e-01, -1.8977e-02, -5.0259e-01,\n                      -4.4895e-02, -2.2994e-01, -1.1669e-01, -2.6686e-01, -3.1314e-01,\n                       3.3971e-02, -7.3420e-03,  1.2434e-01, -1.6070e-01, -2.2562e-01,\n                      -5.2357e-01,  6.4218e-02,  7.5142e-01,  2.4942e-01,  3.3641e-01,\n                       3.8522e-01,  9.3835e-02, -5.6183e-01,  2.3336e-02,  2.6558e-01,\n                      -2.6176e-01,  4.8150e-01, -2.3535e-01, -1.3355e-01,  4.3214e-01,\n                       2.5568e-01,  3.6074e-01, -4.4321e-02,  4.5100e-01, -8.1580e-03,\n                       4.0667e-01,  2.5507e-01, -1.8878e-01, -4.5634e-01, -1.9376e-03,\n                       9.7773e-02,  2.1771e-01,  2.2567e-01, -1.2761e-01, -2.6499e-01,\n                       8.0108e-02, -1.2826e-01, -9.4114e-02,  1.5773e-01, -3.6830e-01,\n                      -5.2824e-01, -2.8120e-01, -3.6948e-01,  3.3065e-01, -7.7955e-01,\n                      -1.0149e-01,  2.3654e-01,  4.3488e-01,  2.7248e-01,  2.8639e-01,\n                      -1.1094e-01, -1.0786e-01, -2.1823e-03,  9.2183e-01,  3.8103e-01,\n                      -2.2365e-01,  2.5584e-01, -4.3678e-01, -1.0737e-01,  6.7606e-01,\n                       5.4486e-03, -1.6769e-01, -3.6260e-01,  1.3729e-01, -1.3350e-01,\n                      -3.2611e-01, -5.8568e-01,  4.0421e-01,  4.4531e-01, -9.5040e-02,\n                       4.4474e-01,  3.6696e-01,  1.9211e-01,  3.7226e-01,  1.6134e-01,\n                       1.6496e-01,  6.3573e-02,  2.5671e-01,  2.2514e-01,  6.9041e-02,\n                      -1.1368e-01,  2.3480e-01, -1.1725e-01,  2.5873e-02, -2.5599e-01,\n                      -3.7109e-01,  4.5825e-01, -1.2619e-01,  9.3730e-01,  2.0248e-01,\n                      -7.6791e-02,  3.0305e-01,  5.9686e-02,  5.7985e-01, -3.8884e-01,\n                      -6.5739e-02, -7.1770e-01, -3.0932e-01, -4.2560e-01,  1.6907e-01,\n                      -7.4240e-02,  1.8930e-01,  6.1338e-01, -1.4488e-01,  3.2112e-01,\n                      -4.2869e-01,  9.2409e-02,  4.0495e-01, -1.3100e-02,  1.2595e-01,\n                       1.3171e-01,  5.4219e-01,  6.6487e-02, -3.5884e-01, -2.3615e-01,\n                       2.6037e-01, -1.7370e-01, -3.6932e-01,  3.9731e-01, -4.1626e-01,\n                       4.2828e-01], dtype=torch.float64)),\n             ('6.18.convs.2.1.running_var',\n              tensor([0.5027, 0.2789, 0.2474, 0.3024, 0.4673, 0.1978, 0.1944, 0.3229, 0.1606,\n                      0.4020, 0.2890, 0.2050, 0.0731, 0.1802, 0.5074, 0.3439, 0.4591, 0.3183,\n                      0.1334, 0.6073, 0.1882, 0.2437, 0.4098, 0.2736, 0.3000, 0.3634, 0.3360,\n                      0.1636, 0.2182, 0.2939, 0.6119, 0.5169, 0.2103, 0.3892, 0.5651, 0.5459,\n                      0.1788, 0.2224, 0.1095, 0.3436, 0.6027, 0.2180, 0.1874, 0.4948, 0.2203,\n                      0.4113, 0.4821, 0.1087, 0.4726, 0.3603, 0.3598, 0.4120, 0.5232, 0.0719,\n                      0.6229, 0.3412, 0.4377, 0.2467, 0.3156, 0.1675, 0.1592, 0.2451, 0.1242,\n                      0.4417, 0.4087, 0.3856, 0.2379, 0.5252, 0.2825, 0.5343, 0.5386, 0.2684,\n                      0.1666, 0.5099, 0.4004, 0.2264, 0.4568, 0.3038, 0.5604, 0.1957, 0.4106,\n                      0.6138, 0.3222, 0.3476, 0.5642, 0.2987, 0.3263, 0.4100, 0.2053, 0.1932,\n                      0.6016, 0.5876, 0.2311, 0.1737, 0.2841, 0.3007, 0.5892, 0.1242, 0.3034,\n                      0.4184, 0.5513, 0.5158, 0.2246, 0.6594, 0.4737, 0.3662, 0.2929, 0.3533,\n                      0.2992, 0.1654, 0.1407, 0.2628, 0.3091, 0.3792, 0.4222, 0.5051, 0.3909,\n                      0.5063, 0.2592, 0.5521, 0.4681, 0.4270, 0.3317, 0.1596, 0.2421, 0.3292,\n                      0.1958, 0.2536, 0.2545, 0.2768, 0.3246, 0.2735, 0.3756, 0.0863, 0.2476,\n                      0.1280, 0.0569, 0.3442, 0.3355, 0.4602, 0.4584, 0.0830, 0.3024, 0.1507,\n                      0.3132, 0.4159, 0.0791, 0.4559, 0.0806, 0.3913, 0.3916, 0.2991, 0.2003,\n                      0.4046, 0.2692, 0.1813, 0.2487, 0.1460, 0.4957, 0.1389, 0.1198, 0.2473,\n                      0.2776, 0.3304, 0.4821, 0.3365, 0.6486, 0.3036, 0.3833, 0.4677, 0.0951,\n                      0.0989, 0.2398, 0.2202, 0.7901, 0.5209, 0.3599, 0.2472, 0.3224, 0.2672,\n                      0.8757, 0.4342, 0.4727, 0.3744, 0.1521, 0.4479, 0.2096, 0.3283, 0.4618,\n                      0.1377, 0.2535, 0.5651, 0.2063, 0.6375, 0.4324, 0.3621, 0.3044, 0.3737,\n                      0.2715, 0.2355, 0.2862, 0.5097, 0.5200, 0.4040, 0.2693, 0.2242, 0.3296,\n                      0.2772, 0.2923, 0.3419, 0.0776, 0.3295, 0.2575, 0.2453, 0.1361, 0.4140,\n                      0.2965, 0.2613, 0.2432, 0.4271, 0.1075, 0.5608, 0.1242, 0.3460, 0.6001,\n                      0.2329, 0.2246, 0.2389, 0.8850, 0.5230, 0.1118, 0.3299, 0.2798, 0.4547,\n                      0.2506, 0.3151, 0.1293, 0.3373, 0.2370, 0.3779, 0.4788, 0.2138, 0.5492,\n                      0.3443, 0.0747, 0.2048, 0.3871, 0.4093, 0.1205, 0.7260, 0.5135, 0.3473,\n                      0.2989, 0.2890, 0.2596, 0.3594], dtype=torch.float64)),\n             ('6.18.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.18.convpath.0.0.0.weight',\n              tensor([[[ 0.0326],\n                       [ 0.0622],\n                       [ 0.0897],\n                       ...,\n                       [-0.0259],\n                       [-0.0473],\n                       [ 0.0863]],\n              \n                      [[-0.0303],\n                       [ 0.0579],\n                       [ 0.1164],\n                       ...,\n                       [-0.0343],\n                       [ 0.1348],\n                       [-0.0078]],\n              \n                      [[ 0.0598],\n                       [-0.0100],\n                       [-0.0197],\n                       ...,\n                       [-0.0651],\n                       [-0.1132],\n                       [ 0.1284]],\n              \n                      ...,\n              \n                      [[-0.0994],\n                       [ 0.0243],\n                       [ 0.1443],\n                       ...,\n                       [ 0.0282],\n                       [-0.0606],\n                       [-0.1937]],\n              \n                      [[-0.1157],\n                       [-0.0695],\n                       [-0.1269],\n                       ...,\n                       [-0.0351],\n                       [-0.0380],\n                       [-0.1206]],\n              \n                      [[ 0.0463],\n                       [-0.1051],\n                       [-0.0652],\n                       ...,\n                       [ 0.0918],\n                       [ 0.0303],\n                       [-0.0258]]], dtype=torch.float64)),\n             ('6.18.convpath.0.0.1.weight',\n              tensor([0.9693, 0.9608, 0.9642, 0.9795, 0.9707, 0.9424, 0.9496, 0.9757, 0.9618,\n                      0.9657, 0.9909, 0.9712, 0.9703, 1.0110, 0.9739, 0.9758, 1.0145, 1.0055,\n                      0.9801, 0.9795, 0.9615, 0.9495, 0.9829, 0.9818, 0.9797, 0.9531, 0.9648,\n                      0.9743, 0.9750, 0.9641, 0.9683, 0.9765, 0.9545, 0.9727, 0.9750, 0.9799,\n                      0.9506, 0.9660, 1.0045, 0.9571, 0.9782, 0.9508, 0.9647, 0.9892, 0.9497,\n                      0.9494, 0.9932, 0.9814, 0.9639, 0.9801, 0.9612, 0.9717, 0.9696, 0.9683,\n                      0.9565, 0.9687, 0.9876, 0.9492, 0.9585, 0.9565, 0.9756, 0.9652, 0.9740,\n                      0.9550], dtype=torch.float64)),\n             ('6.18.convpath.0.0.1.bias',\n              tensor([ 1.4644e-03, -9.3553e-03, -7.7696e-03,  1.2056e-02, -1.9368e-02,\n                       7.0443e-03, -1.3395e-02, -1.1643e-02, -9.5395e-03, -1.2194e-02,\n                       1.9161e-02,  5.6341e-04, -1.1159e-02,  2.4839e-02, -8.1317e-03,\n                      -1.6184e-03,  1.6074e-02, -8.2810e-03, -8.4647e-03,  7.7671e-03,\n                       2.2326e-04, -2.0229e-05,  9.8568e-03,  1.6711e-02,  2.7004e-02,\n                       1.4573e-02, -8.6591e-03, -2.2268e-02, -7.2342e-03, -8.6033e-03,\n                      -2.5289e-03, -6.3978e-03, -5.2394e-03,  2.8941e-03,  1.4332e-02,\n                       1.8374e-02,  1.1981e-03, -4.3097e-04,  3.2194e-02, -1.2187e-02,\n                       2.1108e-02, -8.5860e-03,  4.1466e-03,  1.5354e-02, -6.8866e-03,\n                       1.4691e-02,  1.4348e-02,  2.2744e-04, -1.6536e-02,  9.2811e-03,\n                      -4.6270e-03,  4.7947e-03,  6.3936e-03, -1.7480e-02, -1.0078e-02,\n                       1.9818e-02,  1.7869e-02,  3.7228e-03, -9.5491e-03, -9.0658e-03,\n                       1.5320e-02, -2.9019e-03,  1.6277e-03, -6.0902e-03],\n                     dtype=torch.float64)),\n             ('6.18.convpath.0.0.1.running_mean',\n              tensor([ 0.7911,  1.0856, -0.1271,  0.4413,  1.3026, -0.8317, -0.7399, -1.2779,\n                       0.0735,  1.1619,  0.6248, -0.2560, -0.3489,  0.1403,  0.2621, -0.7375,\n                       0.0212, -0.5844,  0.2094,  0.1336, -0.1608, -1.3917,  0.0524,  0.1382,\n                      -0.8523,  0.3752, -0.5548,  0.7559,  1.2574, -0.0529,  0.7082, -0.5641,\n                      -1.4012, -0.4222, -1.2143,  0.2030, -0.1999, -1.3190, -0.2920,  0.1989,\n                      -0.1171,  0.1261,  0.4280, -1.1588,  0.6451, -0.6450, -0.5804,  0.1390,\n                      -0.3991, -0.2114, -0.0702, -0.0440,  0.2758, -0.0428, -0.8534, -1.0308,\n                       0.0107,  0.4808,  0.2333,  0.2953,  0.2533,  0.1044,  1.3181,  0.2374],\n                     dtype=torch.float64)),\n             ('6.18.convpath.0.0.1.running_var',\n              tensor([0.1505, 0.9159, 0.3126, 0.2280, 0.2127, 0.4216, 0.1253, 0.1659, 0.1205,\n                      1.0745, 0.1182, 0.2970, 0.1873, 0.1414, 0.2570, 0.2836, 0.0983, 0.1541,\n                      0.1687, 0.1334, 0.1676, 0.5300, 0.2283, 0.2158, 0.1906, 0.1985, 0.2586,\n                      0.4634, 0.1213, 0.1751, 0.3176, 0.3535, 0.2251, 0.1867, 0.4454, 0.1679,\n                      0.1419, 0.1268, 0.1468, 0.1245, 0.1410, 0.2251, 0.1988, 0.1568, 0.2570,\n                      0.7680, 0.2041, 0.1606, 0.1948, 0.1312, 0.1316, 0.1588, 0.2987, 0.2048,\n                      0.2823, 0.1957, 0.1769, 0.1863, 0.1024, 0.1098, 0.1037, 0.2023, 0.1028,\n                      0.1515], dtype=torch.float64)),\n             ('6.18.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.18.convpath.0.1.0.weight',\n              tensor([[[-0.0699, -0.0065,  0.0287,  0.0297,  0.0957],\n                       [ 0.0765, -0.1905,  0.1309,  0.1234, -0.0747],\n                       [-0.0673, -0.0923, -0.1309, -0.0678, -0.0278],\n                       ...,\n                       [-0.0820,  0.0623, -0.0270,  0.0348,  0.0489],\n                       [-0.1027,  0.0825,  0.0055,  0.0275,  0.0665],\n                       [ 0.1255, -0.1047, -0.0907, -0.0772, -0.0879]],\n              \n                      [[ 0.0024,  0.0277,  0.0817, -0.0020,  0.0155],\n                       [-0.0345,  0.0154, -0.0585,  0.0028,  0.1844],\n                       [ 0.0749, -0.0277,  0.0359,  0.0443, -0.0576],\n                       ...,\n                       [ 0.0352,  0.0201, -0.0416, -0.1004,  0.0328],\n                       [-0.0307, -0.0453, -0.0767, -0.0677, -0.0190],\n                       [ 0.0831,  0.0273,  0.0701,  0.0060, -0.1484]],\n              \n                      [[ 0.1036,  0.0110, -0.0590, -0.0081, -0.0507],\n                       [ 0.0192,  0.1049, -0.0535, -0.0701,  0.1101],\n                       [ 0.0387,  0.0267,  0.1388, -0.0512, -0.0071],\n                       ...,\n                       [-0.0349, -0.1413, -0.0051,  0.0827,  0.0311],\n                       [-0.1081,  0.0131, -0.0557,  0.0370, -0.1276],\n                       [-0.1572,  0.0660,  0.0661,  0.0362, -0.0224]],\n              \n                      ...,\n              \n                      [[ 0.0082,  0.0575, -0.0559,  0.0069, -0.0443],\n                       [ 0.0223,  0.1566, -0.0250, -0.0507, -0.0568],\n                       [ 0.0224, -0.0563, -0.0884,  0.1039,  0.0485],\n                       ...,\n                       [ 0.0514, -0.0394,  0.0670,  0.0471, -0.0902],\n                       [-0.1240, -0.0415,  0.1104, -0.0603, -0.0023],\n                       [-0.1577, -0.0558, -0.1134, -0.0116, -0.0240]],\n              \n                      [[ 0.0725,  0.0531, -0.0406, -0.0116,  0.0553],\n                       [ 0.0502, -0.0395,  0.0592,  0.0314,  0.1352],\n                       [-0.0075, -0.0009,  0.1412,  0.2115,  0.0184],\n                       ...,\n                       [ 0.0462,  0.0162, -0.1095, -0.0886,  0.1991],\n                       [-0.0826, -0.0101, -0.0229,  0.0448,  0.1285],\n                       [ 0.0721,  0.0141,  0.0232,  0.0370,  0.0098]],\n              \n                      [[-0.1181, -0.0504, -0.0034,  0.0041,  0.0623],\n                       [-0.1397, -0.0815,  0.0469, -0.0488, -0.1109],\n                       [ 0.0548,  0.0719, -0.1314, -0.1144, -0.0111],\n                       ...,\n                       [ 0.0296, -0.0649,  0.0560,  0.1466, -0.0326],\n                       [-0.0958,  0.0471,  0.0475,  0.0230, -0.0047],\n                       [ 0.0281, -0.0935,  0.0127, -0.0664,  0.0094]]], dtype=torch.float64)),\n             ('6.18.convpath.0.1.1.weight',\n              tensor([0.9610, 0.9796, 0.9399, 0.9772, 0.9852, 0.9276, 0.9653, 0.9428, 0.9817,\n                      0.9708, 0.9792, 0.9787, 0.9495, 0.9730, 0.9661, 0.9821, 0.9755, 0.9922,\n                      0.9722, 0.9525, 0.9702, 0.9589, 0.9802, 0.9466, 0.9428, 0.9781, 0.9721,\n                      0.9552, 0.9784, 0.9666, 0.9656, 0.9536, 0.9580, 0.9861, 0.9820, 0.9272,\n                      0.9512, 0.9577, 0.9557, 0.9499, 0.9775, 0.9682, 0.9534, 0.9523, 0.9661,\n                      0.9558, 0.9686, 0.9579, 0.9607, 0.9707, 0.9890, 0.9573, 0.9552, 0.9642,\n                      0.9554, 0.9669, 0.9755, 0.9673, 0.9896, 0.9975, 0.9615, 0.9542, 0.9897,\n                      0.9682], dtype=torch.float64)),\n             ('6.18.convpath.0.1.1.bias',\n              tensor([-0.0083,  0.0096, -0.0079, -0.0098,  0.0079, -0.0072, -0.0049, -0.0050,\n                       0.0128,  0.0003, -0.0059,  0.0048,  0.0007, -0.0159, -0.0177,  0.0013,\n                      -0.0036, -0.0074,  0.0013, -0.0037, -0.0008, -0.0225, -0.0277, -0.0147,\n                      -0.0052,  0.0068, -0.0047, -0.0051,  0.0010,  0.0037, -0.0112, -0.0296,\n                      -0.0108, -0.0085, -0.0104, -0.0267, -0.0272, -0.0071, -0.0062, -0.0133,\n                       0.0093, -0.0065,  0.0006, -0.0245, -0.0201,  0.0038,  0.0084, -0.0220,\n                       0.0094,  0.0113,  0.0176, -0.0176, -0.0246,  0.0101, -0.0076, -0.0283,\n                      -0.0062, -0.0346,  0.0031,  0.0148,  0.0105, -0.0175, -0.0025, -0.0077],\n                     dtype=torch.float64)),\n             ('6.18.convpath.0.1.1.running_mean',\n              tensor([-0.2456,  0.3734, -0.3205, -0.4581, -0.0111, -0.2860,  0.5471,  0.0383,\n                       0.2086,  0.3688,  0.0716, -1.3562, -0.2441, -0.5892, -0.0978, -0.3246,\n                      -0.0569,  0.6194, -0.3676,  0.0369, -0.5219, -0.1303, -0.4742, -0.6607,\n                      -0.5371, -0.4513, -0.6930, -0.6633,  0.6716, -0.4953, -0.2153, -0.4817,\n                      -0.8008, -0.4875,  0.2456, -0.1912,  0.2986,  0.3066,  0.2862, -0.1004,\n                      -0.4656, -0.0087, -0.6817, -0.5223,  0.5085, -0.4211, -1.0567,  0.3645,\n                      -0.7002,  0.0866,  0.1141,  0.3119,  0.9414,  1.3299, -0.1979, -0.3982,\n                       0.5804,  0.2144, -0.5156,  0.3599, -0.9109, -0.1137, -0.2019, -0.5339],\n                     dtype=torch.float64)),\n             ('6.18.convpath.0.1.1.running_var',\n              tensor([0.5257, 0.6336, 0.4815, 0.7168, 0.8632, 0.7030, 0.3303, 0.4625, 0.4001,\n                      0.4910, 0.4410, 0.8068, 0.7808, 0.4280, 0.5905, 0.6657, 0.6357, 0.4209,\n                      0.5663, 0.4526, 0.4523, 0.4809, 0.3738, 0.4723, 0.6604, 0.4958, 0.6646,\n                      0.5248, 0.6344, 0.5742, 0.4544, 0.5549, 0.6469, 0.4479, 0.4748, 0.5404,\n                      0.6669, 0.6506, 0.3404, 0.4634, 0.6312, 0.6308, 0.7208, 0.6500, 0.4138,\n                      0.6190, 0.5990, 0.6618, 0.5618, 0.5002, 0.5534, 0.4077, 0.4548, 0.7171,\n                      0.6190, 0.5977, 0.7583, 0.8713, 0.5393, 0.5285, 0.5386, 0.5539, 0.5991,\n                      0.5065], dtype=torch.float64)),\n             ('6.18.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.18.convpath.0.2.0.weight',\n              tensor([[[-0.0606],\n                       [-0.0881],\n                       [ 0.1923],\n                       ...,\n                       [ 0.0470],\n                       [ 0.0801],\n                       [ 0.0749]],\n              \n                      [[ 0.0503],\n                       [-0.0712],\n                       [ 0.0044],\n                       ...,\n                       [ 0.0589],\n                       [-0.0123],\n                       [-0.0054]],\n              \n                      [[-0.1691],\n                       [-0.0244],\n                       [-0.0830],\n                       ...,\n                       [-0.1529],\n                       [ 0.0536],\n                       [-0.1610]],\n              \n                      ...,\n              \n                      [[-0.2000],\n                       [-0.0557],\n                       [-0.1459],\n                       ...,\n                       [ 0.0996],\n                       [ 0.1150],\n                       [ 0.0637]],\n              \n                      [[-0.1319],\n                       [ 0.0597],\n                       [-0.0909],\n                       ...,\n                       [ 0.0110],\n                       [-0.2066],\n                       [-0.1393]],\n              \n                      [[ 0.0124],\n                       [-0.0879],\n                       [-0.0872],\n                       ...,\n                       [ 0.1538],\n                       [ 0.1130],\n                       [-0.0020]]], dtype=torch.float64)),\n             ('6.18.convpath.0.2.1.weight',\n              tensor([ 1.9600e-02,  1.2067e-02,  1.7449e-02,  3.0706e-03,  5.4469e-03,\n                      -8.3460e-03, -5.6302e-03, -1.6789e-02,  8.8008e-03, -7.9497e-03,\n                      -1.0700e-02,  5.5923e-03,  5.7849e-03,  8.3630e-03,  5.8248e-03,\n                       1.3987e-02, -5.2145e-02, -1.1648e-02,  6.8550e-03,  9.1247e-03,\n                      -1.2569e-02,  9.2128e-04,  2.4236e-02,  1.2678e-02,  1.3325e-02,\n                       1.8923e-02, -2.2389e-02,  6.4395e-03, -1.1526e-02,  2.3172e-02,\n                      -9.6461e-03,  3.0464e-02,  1.7222e-02, -1.8433e-02, -6.9785e-02,\n                       1.6874e-02,  1.7926e-02,  4.8753e-03,  1.7527e-03, -1.1408e-03,\n                      -1.1214e-02,  2.8707e-02, -5.8988e-03,  7.0184e-03,  6.1359e-03,\n                       2.9272e-02, -2.9838e-02, -5.2065e-03, -3.5785e-02, -2.0929e-02,\n                      -3.0276e-02, -1.2769e-02, -2.1736e-02, -1.5033e-03,  1.2660e-02,\n                       1.0708e-02, -1.4412e-02,  8.9157e-04, -5.7865e-03,  5.8098e-03,\n                       3.6804e-03,  1.4412e-02,  1.5876e-03, -4.7275e-02, -2.5694e-02,\n                      -1.0761e-02, -5.0806e-03, -3.4255e-02,  9.4502e-03, -2.0274e-02,\n                       8.4346e-03,  7.2065e-03, -7.8735e-03, -1.9829e-02,  9.2813e-03,\n                       1.0792e-02, -2.7873e-02, -2.4430e-02, -1.9158e-02, -1.2250e-02,\n                       1.4809e-02,  2.2369e-02,  5.0336e-03, -8.5300e-03, -3.0914e-02,\n                      -1.9050e-03,  1.6162e-02,  1.3694e-02, -7.0497e-03, -2.9154e-02,\n                       3.1416e-02,  1.2979e-02, -1.2714e-02,  8.5382e-03,  1.8068e-03,\n                      -1.9883e-02, -1.8492e-02,  5.3051e-03,  2.5011e-02,  1.6844e-02,\n                       2.9109e-04,  1.8003e-02, -7.7917e-03,  4.0893e-02,  1.1443e-02,\n                       2.2266e-02, -3.1417e-03,  1.2431e-02, -7.0870e-04,  6.6558e-03,\n                       9.8892e-03,  1.3473e-02, -9.8680e-03,  9.2901e-03,  2.2994e-02,\n                      -2.0649e-02, -6.9128e-03,  3.0918e-02,  5.5584e-03,  3.1578e-02,\n                      -1.2305e-02, -1.8649e-02,  1.4175e-02,  4.2901e-03,  9.4881e-03,\n                       5.1201e-02, -8.8319e-03,  5.7289e-03,  9.9962e-04,  8.0820e-03,\n                      -5.2919e-03,  9.1284e-03, -2.6513e-02,  1.9012e-03, -1.2204e-02,\n                      -1.2970e-02, -6.1749e-03, -1.0992e-02, -1.8732e-02, -2.2937e-02,\n                       1.3254e-02,  4.8321e-03,  2.4983e-02, -5.8679e-04,  1.7433e-02,\n                       2.0568e-02, -2.8096e-03, -8.8333e-03, -1.1907e-02,  2.9226e-03,\n                      -9.4637e-03, -1.2581e-02, -4.3402e-03,  8.8420e-03, -1.9088e-03,\n                      -1.3332e-02,  8.2638e-03,  3.7064e-03, -1.5463e-02,  9.1711e-04,\n                      -3.7246e-03,  1.4282e-02,  3.9456e-03,  2.1891e-02, -2.5818e-02,\n                       5.5600e-03, -5.9263e-03, -1.9170e-02, -1.2410e-02,  2.7370e-02,\n                      -7.9121e-03, -4.9170e-03, -8.5817e-03, -8.0854e-03,  1.7443e-02,\n                      -3.9178e-02,  9.8698e-03, -1.2641e-02, -1.6787e-02,  7.4793e-03,\n                      -2.9841e-02,  2.5893e-02, -2.2694e-02,  1.1599e-02,  8.6739e-03,\n                       1.8298e-02,  3.7548e-03, -1.4132e-02,  1.1466e-02, -1.3387e-02,\n                      -7.1240e-03, -4.8281e-02, -1.1828e-03, -2.2117e-02,  3.6535e-02,\n                      -1.1665e-02,  1.3719e-02,  2.7388e-02,  1.1115e-02,  1.5647e-02,\n                      -1.2775e-02, -2.8299e-02,  3.1611e-02, -1.0292e-02, -3.7667e-03,\n                       8.0773e-03,  2.2250e-02, -2.3351e-02,  1.9374e-02, -8.7631e-03,\n                       2.9280e-03,  8.4645e-03, -1.0909e-02,  1.0227e-02,  9.9291e-03,\n                      -1.2464e-02,  1.0244e-02,  1.1889e-02, -7.5968e-03,  2.0103e-02,\n                       7.5045e-05, -1.3698e-02, -4.7202e-04,  2.7508e-03, -2.3327e-02,\n                       1.1899e-02,  4.9536e-03, -1.3317e-03,  2.8445e-02,  9.0946e-04,\n                      -1.1273e-02, -7.9019e-03,  1.5172e-02, -1.6721e-02, -4.3719e-03,\n                       4.0167e-02, -4.9451e-03, -4.9652e-02,  2.6526e-03,  1.9213e-02,\n                      -1.4157e-02,  1.5956e-02,  1.3411e-02, -4.6567e-03, -2.0045e-03,\n                      -1.0787e-02,  1.5407e-02, -1.8295e-02, -5.5819e-03, -1.9157e-02,\n                      -2.0630e-02, -2.4605e-02,  1.3807e-02, -2.6926e-02,  7.4194e-03,\n                       1.0944e-02], dtype=torch.float64)),\n             ('6.18.convpath.0.2.1.bias',\n              tensor([ 0.0042,  0.0061,  0.0042,  0.0152, -0.0022,  0.0079,  0.0044,  0.0012,\n                       0.0024,  0.0071,  0.0163, -0.0078,  0.0055, -0.0058,  0.0023,  0.0058,\n                       0.0274,  0.0042,  0.0115, -0.0032, -0.0079,  0.0016,  0.0076,  0.0049,\n                       0.0177, -0.0193,  0.0057,  0.0111,  0.0110, -0.0054, -0.0049,  0.0132,\n                       0.0089,  0.0155,  0.0101,  0.0138, -0.0045,  0.0092,  0.0149,  0.0005,\n                       0.0092,  0.0026, -0.0089, -0.0060,  0.0077, -0.0166,  0.0113,  0.0036,\n                      -0.0128,  0.0002,  0.0113,  0.0042,  0.0055,  0.0207,  0.0006,  0.0126,\n                       0.0102,  0.0052,  0.0052, -0.0034,  0.0015,  0.0006,  0.0134,  0.0081,\n                      -0.0112,  0.0023, -0.0058,  0.0142,  0.0187, -0.0149,  0.0085,  0.0024,\n                      -0.0007, -0.0079,  0.0131,  0.0038,  0.0039,  0.0182,  0.0011,  0.0097,\n                       0.0032, -0.0087,  0.0189,  0.0027, -0.0082,  0.0214, -0.0020,  0.0122,\n                       0.0124,  0.0002,  0.0017,  0.0132,  0.0098, -0.0075,  0.0046, -0.0064,\n                       0.0148,  0.0043,  0.0197,  0.0066,  0.0245,  0.0170,  0.0013,  0.0146,\n                       0.0066,  0.0017,  0.0049,  0.0108,  0.0057,  0.0079,  0.0033, -0.0050,\n                       0.0058,  0.0225,  0.0179,  0.0026,  0.0047,  0.0027,  0.0008, -0.0030,\n                      -0.0002,  0.0125,  0.0034,  0.0016,  0.0180,  0.0081,  0.0108,  0.0046,\n                       0.0029,  0.0134,  0.0072,  0.0065,  0.0088,  0.0019,  0.0059, -0.0133,\n                       0.0102,  0.0049,  0.0081,  0.0076,  0.0157,  0.0134,  0.0093,  0.0018,\n                      -0.0081,  0.0087,  0.0055,  0.0066,  0.0055,  0.0013,  0.0102,  0.0084,\n                       0.0044,  0.0108,  0.0140,  0.0030, -0.0019,  0.0045,  0.0042,  0.0008,\n                       0.0052,  0.0081, -0.0002,  0.0065,  0.0107, -0.0053, -0.0110,  0.0047,\n                       0.0105,  0.0114,  0.0147, -0.0022,  0.0125,  0.0150, -0.0156,  0.0129,\n                      -0.0026,  0.0130, -0.0024,  0.0036, -0.0003,  0.0110, -0.0039, -0.0065,\n                       0.0089,  0.0078,  0.0110,  0.0087,  0.0011,  0.0071,  0.0034,  0.0096,\n                       0.0050,  0.0076,  0.0124,  0.0099,  0.0092, -0.0012,  0.0056,  0.0104,\n                      -0.0004,  0.0210,  0.0141,  0.0169,  0.0148,  0.0054,  0.0074, -0.0062,\n                       0.0040,  0.0070,  0.0066,  0.0100, -0.0041,  0.0133,  0.0066,  0.0058,\n                       0.0010,  0.0162,  0.0007, -0.0013,  0.0180,  0.0101,  0.0028,  0.0134,\n                       0.0119,  0.0051, -0.0071, -0.0041,  0.0254,  0.0183,  0.0028, -0.0007,\n                       0.0064,  0.0058, -0.0020,  0.0064, -0.0035,  0.0153,  0.0021,  0.0149,\n                      -0.0031,  0.0025, -0.0076,  0.0132,  0.0007,  0.0024,  0.0070,  0.0023,\n                      -0.0211, -0.0112,  0.0185,  0.0165,  0.0095,  0.0175,  0.0033,  0.0019],\n                     dtype=torch.float64)),\n             ('6.18.convpath.0.2.1.running_mean',\n              tensor([ 7.7297e-01, -1.0550e-01,  1.0763e-01, -8.0681e-02, -9.9735e-04,\n                      -5.5130e-01, -1.6592e-02,  4.4639e-01, -9.7016e-02,  7.2733e-01,\n                      -2.3602e-01,  2.8331e-01,  2.1040e-02,  1.0536e-01, -4.3713e-01,\n                      -2.6298e-02, -1.9619e-01,  4.0163e-01, -5.6093e-01, -6.9598e-01,\n                      -7.6822e-02, -2.1407e-01,  1.9279e-01,  2.5199e-01, -3.2156e-01,\n                      -2.6858e-01,  7.4786e-02, -1.7502e-01, -4.1488e-01,  5.4379e-01,\n                       1.3537e+00, -6.4823e-01,  2.1594e-01,  2.3014e-01,  6.8409e-01,\n                      -8.3925e-01, -6.7568e-02, -3.7324e-01,  1.0105e-01,  2.3012e-01,\n                       2.2100e-01, -1.4756e-01,  1.4439e-01,  1.9787e-01, -7.0692e-01,\n                       6.3368e-03, -8.6856e-01, -3.2146e-01,  9.9722e-02,  5.7602e-01,\n                      -2.4114e-02, -5.5874e-01,  2.5370e-01,  2.3945e-01,  3.3417e-01,\n                       5.6123e-01,  4.1261e-01,  4.2150e-01, -7.7494e-02,  1.9512e-01,\n                       5.8126e-01,  1.2466e-01,  2.5612e-01, -1.8675e-01, -1.2655e-01,\n                      -6.2670e-02,  9.1066e-04, -2.4185e-01,  2.5471e-01, -8.5520e-02,\n                       9.6745e-01,  5.2680e-01,  3.3554e-01,  6.5724e-01, -1.2188e+00,\n                      -4.0781e-01,  5.0810e-01, -1.3068e-01, -7.6112e-01, -8.2694e-02,\n                      -6.8665e-01,  8.7213e-01, -4.6975e-02,  5.0169e-02, -3.0235e-01,\n                      -2.1147e-01, -3.2663e-01,  7.5809e-01, -4.5827e-01,  5.9889e-01,\n                      -8.6986e-02, -1.3586e-01,  4.1223e-01, -4.1404e-01, -2.1901e-01,\n                      -5.6238e-01,  2.8949e-02, -7.9281e-03, -6.4932e-01, -1.4727e-01,\n                       2.7748e-03, -3.5938e-01, -6.4176e-01, -8.0207e-01,  3.4256e-01,\n                       2.6874e-01,  8.5718e-02,  2.8744e-01,  2.1488e-01,  2.3778e-01,\n                       2.4563e-01, -1.2899e-02,  2.1048e-01, -6.7537e-01,  5.3172e-01,\n                       4.1443e-01,  5.7816e-01, -6.9320e-01,  3.6026e-01, -8.7836e-02,\n                      -2.5065e-01, -6.7196e-01,  3.5993e-01,  2.1463e-01,  1.3988e-01,\n                      -5.8351e-01, -8.5797e-02,  5.1361e-01, -1.8977e-02, -5.0259e-01,\n                      -4.4895e-02, -2.2994e-01, -1.1669e-01, -2.6686e-01, -3.1314e-01,\n                       3.3971e-02, -7.3420e-03,  1.2434e-01, -1.6070e-01, -2.2562e-01,\n                      -5.2357e-01,  6.4218e-02,  7.5142e-01,  2.4942e-01,  3.3641e-01,\n                       3.8522e-01,  9.3835e-02, -5.6183e-01,  2.3336e-02,  2.6558e-01,\n                      -2.6176e-01,  4.8150e-01, -2.3535e-01, -1.3355e-01,  4.3214e-01,\n                       2.5568e-01,  3.6074e-01, -4.4321e-02,  4.5100e-01, -8.1580e-03,\n                       4.0667e-01,  2.5507e-01, -1.8878e-01, -4.5634e-01, -1.9376e-03,\n                       9.7773e-02,  2.1771e-01,  2.2567e-01, -1.2761e-01, -2.6499e-01,\n                       8.0108e-02, -1.2826e-01, -9.4114e-02,  1.5773e-01, -3.6830e-01,\n                      -5.2824e-01, -2.8120e-01, -3.6948e-01,  3.3065e-01, -7.7955e-01,\n                      -1.0149e-01,  2.3654e-01,  4.3488e-01,  2.7248e-01,  2.8639e-01,\n                      -1.1094e-01, -1.0786e-01, -2.1823e-03,  9.2183e-01,  3.8103e-01,\n                      -2.2365e-01,  2.5584e-01, -4.3678e-01, -1.0737e-01,  6.7606e-01,\n                       5.4486e-03, -1.6769e-01, -3.6260e-01,  1.3729e-01, -1.3350e-01,\n                      -3.2611e-01, -5.8568e-01,  4.0421e-01,  4.4531e-01, -9.5040e-02,\n                       4.4474e-01,  3.6696e-01,  1.9211e-01,  3.7226e-01,  1.6134e-01,\n                       1.6496e-01,  6.3573e-02,  2.5671e-01,  2.2514e-01,  6.9041e-02,\n                      -1.1368e-01,  2.3480e-01, -1.1725e-01,  2.5873e-02, -2.5599e-01,\n                      -3.7109e-01,  4.5825e-01, -1.2619e-01,  9.3730e-01,  2.0248e-01,\n                      -7.6791e-02,  3.0305e-01,  5.9686e-02,  5.7985e-01, -3.8884e-01,\n                      -6.5739e-02, -7.1770e-01, -3.0932e-01, -4.2560e-01,  1.6907e-01,\n                      -7.4240e-02,  1.8930e-01,  6.1338e-01, -1.4488e-01,  3.2112e-01,\n                      -4.2869e-01,  9.2409e-02,  4.0495e-01, -1.3100e-02,  1.2595e-01,\n                       1.3171e-01,  5.4219e-01,  6.6487e-02, -3.5884e-01, -2.3615e-01,\n                       2.6037e-01, -1.7370e-01, -3.6932e-01,  3.9731e-01, -4.1626e-01,\n                       4.2828e-01], dtype=torch.float64)),\n             ('6.18.convpath.0.2.1.running_var',\n              tensor([0.5027, 0.2789, 0.2474, 0.3024, 0.4673, 0.1978, 0.1944, 0.3229, 0.1606,\n                      0.4020, 0.2890, 0.2050, 0.0731, 0.1802, 0.5074, 0.3439, 0.4591, 0.3183,\n                      0.1334, 0.6073, 0.1882, 0.2437, 0.4098, 0.2736, 0.3000, 0.3634, 0.3360,\n                      0.1636, 0.2182, 0.2939, 0.6119, 0.5169, 0.2103, 0.3892, 0.5651, 0.5459,\n                      0.1788, 0.2224, 0.1095, 0.3436, 0.6027, 0.2180, 0.1874, 0.4948, 0.2203,\n                      0.4113, 0.4821, 0.1087, 0.4726, 0.3603, 0.3598, 0.4120, 0.5232, 0.0719,\n                      0.6229, 0.3412, 0.4377, 0.2467, 0.3156, 0.1675, 0.1592, 0.2451, 0.1242,\n                      0.4417, 0.4087, 0.3856, 0.2379, 0.5252, 0.2825, 0.5343, 0.5386, 0.2684,\n                      0.1666, 0.5099, 0.4004, 0.2264, 0.4568, 0.3038, 0.5604, 0.1957, 0.4106,\n                      0.6138, 0.3222, 0.3476, 0.5642, 0.2987, 0.3263, 0.4100, 0.2053, 0.1932,\n                      0.6016, 0.5876, 0.2311, 0.1737, 0.2841, 0.3007, 0.5892, 0.1242, 0.3034,\n                      0.4184, 0.5513, 0.5158, 0.2246, 0.6594, 0.4737, 0.3662, 0.2929, 0.3533,\n                      0.2992, 0.1654, 0.1407, 0.2628, 0.3091, 0.3792, 0.4222, 0.5051, 0.3909,\n                      0.5063, 0.2592, 0.5521, 0.4681, 0.4270, 0.3317, 0.1596, 0.2421, 0.3292,\n                      0.1958, 0.2536, 0.2545, 0.2768, 0.3246, 0.2735, 0.3756, 0.0863, 0.2476,\n                      0.1280, 0.0569, 0.3442, 0.3355, 0.4602, 0.4584, 0.0830, 0.3024, 0.1507,\n                      0.3132, 0.4159, 0.0791, 0.4559, 0.0806, 0.3913, 0.3916, 0.2991, 0.2003,\n                      0.4046, 0.2692, 0.1813, 0.2487, 0.1460, 0.4957, 0.1389, 0.1198, 0.2473,\n                      0.2776, 0.3304, 0.4821, 0.3365, 0.6486, 0.3036, 0.3833, 0.4677, 0.0951,\n                      0.0989, 0.2398, 0.2202, 0.7901, 0.5209, 0.3599, 0.2472, 0.3224, 0.2672,\n                      0.8757, 0.4342, 0.4727, 0.3744, 0.1521, 0.4479, 0.2096, 0.3283, 0.4618,\n                      0.1377, 0.2535, 0.5651, 0.2063, 0.6375, 0.4324, 0.3621, 0.3044, 0.3737,\n                      0.2715, 0.2355, 0.2862, 0.5097, 0.5200, 0.4040, 0.2693, 0.2242, 0.3296,\n                      0.2772, 0.2923, 0.3419, 0.0776, 0.3295, 0.2575, 0.2453, 0.1361, 0.4140,\n                      0.2965, 0.2613, 0.2432, 0.4271, 0.1075, 0.5608, 0.1242, 0.3460, 0.6001,\n                      0.2329, 0.2246, 0.2389, 0.8850, 0.5230, 0.1118, 0.3299, 0.2798, 0.4547,\n                      0.2506, 0.3151, 0.1293, 0.3373, 0.2370, 0.3779, 0.4788, 0.2138, 0.5492,\n                      0.3443, 0.0747, 0.2048, 0.3871, 0.4093, 0.1205, 0.7260, 0.5135, 0.3473,\n                      0.2989, 0.2890, 0.2596, 0.3594], dtype=torch.float64)),\n             ('6.18.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.19.convs.0.0.weight',\n              tensor([[[-0.0309],\n                       [ 0.0352],\n                       [-0.0062],\n                       ...,\n                       [ 0.0164],\n                       [-0.1095],\n                       [ 0.1249]],\n              \n                      [[ 0.0469],\n                       [-0.0528],\n                       [-0.0574],\n                       ...,\n                       [-0.0871],\n                       [ 0.0535],\n                       [-0.0431]],\n              \n                      [[-0.0536],\n                       [ 0.1097],\n                       [ 0.0267],\n                       ...,\n                       [ 0.1238],\n                       [-0.1016],\n                       [-0.0073]],\n              \n                      ...,\n              \n                      [[-0.1524],\n                       [-0.1054],\n                       [ 0.0396],\n                       ...,\n                       [-0.0170],\n                       [-0.0055],\n                       [-0.0294]],\n              \n                      [[-0.0636],\n                       [ 0.0465],\n                       [-0.1090],\n                       ...,\n                       [-0.0072],\n                       [ 0.0397],\n                       [-0.0325]],\n              \n                      [[ 0.1725],\n                       [ 0.1143],\n                       [ 0.0235],\n                       ...,\n                       [-0.0319],\n                       [ 0.0712],\n                       [ 0.0875]]], dtype=torch.float64)),\n             ('6.19.convs.0.1.weight',\n              tensor([0.9465, 0.9673, 0.9610, 0.9982, 0.9627, 0.9206, 0.9613, 0.9774, 0.9680,\n                      0.9548, 0.9687, 0.9728, 0.9534, 0.9651, 0.9637, 0.9550, 0.9873, 0.9821,\n                      0.9950, 0.9775, 0.9508, 0.9539, 0.9569, 0.9602, 0.9906, 0.9584, 0.9734,\n                      0.9563, 0.9670, 0.9598, 0.9677, 0.9615, 0.9995, 0.9924, 0.9926, 0.9774,\n                      0.9630, 0.9691, 0.9840, 0.9736, 0.9810, 0.9847, 0.9664, 0.9729, 0.9663,\n                      0.9759, 0.9888, 0.9898, 0.9786, 0.9691, 0.9576, 0.9848, 0.9614, 0.9877,\n                      0.9785, 1.0056, 0.9587, 0.9637, 0.9717, 0.9649, 0.9715, 0.9830, 0.9343,\n                      0.9689], dtype=torch.float64)),\n             ('6.19.convs.0.1.bias',\n              tensor([ 0.0004,  0.0010,  0.0090,  0.0118, -0.0161, -0.0230,  0.0081,  0.0007,\n                      -0.0011, -0.0010, -0.0007,  0.0052, -0.0120, -0.0151,  0.0100, -0.0061,\n                       0.0027, -0.0112,  0.0109, -0.0109, -0.0046, -0.0194, -0.0048, -0.0098,\n                       0.0251,  0.0005, -0.0126,  0.0074,  0.0064, -0.0065,  0.0087, -0.0048,\n                       0.0267,  0.0263,  0.0099,  0.0038,  0.0168,  0.0078,  0.0081,  0.0054,\n                       0.0019,  0.0193, -0.0142,  0.0120, -0.0155,  0.0095,  0.0080,  0.0065,\n                       0.0028, -0.0186, -0.0022,  0.0122, -0.0067, -0.0053, -0.0004,  0.0218,\n                       0.0016,  0.0023,  0.0117, -0.0185,  0.0077,  0.0066,  0.0057, -0.0242],\n                     dtype=torch.float64)),\n             ('6.19.convs.0.1.running_mean',\n              tensor([-0.0352,  0.1269,  1.0086, -0.5691,  0.4288,  0.1688,  0.6714,  0.3483,\n                       1.6770, -0.5643,  0.3108,  0.5974,  0.1055,  0.6841,  0.4968,  1.0746,\n                       0.4248, -0.1263,  0.0488,  1.3591,  0.1826,  0.4513, -0.2599, -0.1598,\n                      -0.3771,  0.4301,  0.3143, -0.1347,  1.0426,  0.4396, -0.5129,  0.8051,\n                      -0.5000, -0.0382, -0.4156,  0.1962, -0.5401, -0.5085,  0.0811,  0.8767,\n                       0.5280,  0.4389, -0.1381,  0.2047,  0.2205,  0.3668, -0.7498, -0.9375,\n                       0.2150,  0.7657, -0.0034,  0.6661, -0.1777,  0.1903, -1.2948,  0.3198,\n                       0.3274, -0.1673, -0.3854,  0.8866,  0.0911, -0.0436, -1.5243, -0.7568],\n                     dtype=torch.float64)),\n             ('6.19.convs.0.1.running_var',\n              tensor([0.6753, 0.6099, 0.1485, 0.1127, 0.4499, 0.1259, 0.3177, 0.1275, 0.3582,\n                      0.1177, 0.1491, 0.1335, 0.1072, 0.1845, 0.3260, 0.5314, 0.1514, 0.1063,\n                      0.1642, 0.6159, 0.2689, 0.0986, 0.2813, 0.1059, 0.2782, 0.4126, 0.2184,\n                      0.3942, 0.3670, 0.6785, 0.2573, 0.6176, 0.1335, 0.2136, 0.1746, 0.1991,\n                      0.2718, 0.2110, 0.0934, 0.3661, 0.3891, 0.1652, 0.1269, 0.1293, 0.1617,\n                      0.5399, 0.2253, 0.1296, 0.4586, 0.1804, 0.7872, 0.2141, 0.2740, 0.1984,\n                      0.1814, 0.1486, 0.2788, 0.1341, 0.1227, 0.2549, 0.4101, 0.1312, 0.5740,\n                      0.1581], dtype=torch.float64)),\n             ('6.19.convs.0.1.num_batches_tracked', tensor(11419)),\n             ('6.19.convs.1.0.weight',\n              tensor([[[ 0.1165, -0.1736,  0.0306, -0.0704, -0.0433],\n                       [ 0.0334, -0.0367, -0.0195,  0.0504, -0.1455],\n                       [ 0.1327,  0.0585, -0.0744,  0.0926,  0.0495],\n                       ...,\n                       [-0.0434,  0.1077, -0.0595,  0.0033,  0.0543],\n                       [-0.0087,  0.1416, -0.0783,  0.0033, -0.0156],\n                       [ 0.0259,  0.0772, -0.0559,  0.0033, -0.0133]],\n              \n                      [[-0.0969, -0.1059, -0.1564, -0.0751, -0.1244],\n                       [-0.1024, -0.0131, -0.1156,  0.0490, -0.0207],\n                       [ 0.0746,  0.0309, -0.0064,  0.0696, -0.0899],\n                       ...,\n                       [ 0.0702, -0.0677,  0.0464, -0.0528,  0.0621],\n                       [-0.1095,  0.0752,  0.0498, -0.0710, -0.0553],\n                       [ 0.0399,  0.1017, -0.1137,  0.1110, -0.0143]],\n              \n                      [[ 0.0486,  0.1574, -0.0219, -0.0175,  0.0295],\n                       [-0.0751, -0.2239,  0.0829,  0.0138,  0.0032],\n                       [ 0.0452, -0.0014, -0.0441, -0.1438, -0.0019],\n                       ...,\n                       [-0.0967, -0.0573,  0.0150, -0.1774,  0.0102],\n                       [-0.1442,  0.1391,  0.0036,  0.0125, -0.0165],\n                       [ 0.0196, -0.0220,  0.0362,  0.0105,  0.0080]],\n              \n                      ...,\n              \n                      [[ 0.0459, -0.0270,  0.0123, -0.0173, -0.0490],\n                       [-0.0014, -0.0581, -0.0340,  0.0084, -0.1285],\n                       [ 0.0311,  0.0581,  0.0909,  0.0502, -0.0235],\n                       ...,\n                       [-0.0576, -0.0291, -0.1795, -0.0349,  0.1208],\n                       [-0.0633, -0.0917,  0.0608,  0.0222,  0.1170],\n                       [ 0.0178, -0.0665, -0.0138,  0.1873,  0.0839]],\n              \n                      [[-0.0355, -0.0649,  0.0332, -0.0104, -0.0937],\n                       [ 0.0547,  0.0169,  0.0314,  0.0078, -0.0403],\n                       [ 0.0762, -0.0570, -0.0565, -0.0390,  0.0486],\n                       ...,\n                       [-0.0129,  0.0333, -0.0114, -0.0347, -0.0766],\n                       [-0.0408,  0.0754, -0.0126,  0.0182, -0.0775],\n                       [-0.0025,  0.0352,  0.1216,  0.1075, -0.1832]],\n              \n                      [[ 0.0954,  0.0212, -0.0932,  0.0348, -0.1242],\n                       [-0.0298, -0.0097, -0.0489,  0.1128, -0.0180],\n                       [ 0.0729,  0.0294, -0.0500, -0.0591,  0.0400],\n                       ...,\n                       [-0.1481,  0.0661,  0.0523, -0.0160,  0.0190],\n                       [ 0.0876,  0.0092,  0.0145, -0.0134, -0.1215],\n                       [ 0.0388,  0.1000,  0.1322, -0.0559,  0.1115]]], dtype=torch.float64)),\n             ('6.19.convs.1.1.weight',\n              tensor([0.9854, 0.9772, 0.9586, 0.9698, 0.9546, 0.9785, 0.9591, 0.9452, 0.9358,\n                      0.9381, 0.9514, 0.9844, 0.9680, 0.9707, 0.9283, 0.9679, 0.9576, 0.9826,\n                      0.9592, 0.9798, 0.9548, 0.9960, 0.9639, 0.9595, 0.9699, 0.9628, 0.9560,\n                      0.9582, 0.9932, 1.0024, 0.9836, 0.9702, 0.9626, 0.9779, 0.9211, 0.9636,\n                      0.9846, 0.9447, 0.9561, 0.9486, 0.9418, 0.9346, 0.9613, 0.9692, 1.0056,\n                      0.9570, 0.9559, 0.9564, 0.9965, 0.9589, 0.9799, 0.9652, 0.9894, 0.9469,\n                      0.9864, 0.9511, 0.9373, 0.9645, 0.9467, 0.9789, 0.9695, 0.9466, 0.9587,\n                      0.9868], dtype=torch.float64)),\n             ('6.19.convs.1.1.bias',\n              tensor([ 0.0189,  0.0067,  0.0051,  0.0044, -0.0194,  0.0132, -0.0118, -0.0287,\n                       0.0040,  0.0007, -0.0265, -0.0091, -0.0233,  0.0129, -0.0266,  0.0060,\n                      -0.0025,  0.0012, -0.0061, -0.0023, -0.0109, -0.0014,  0.0093,  0.0049,\n                       0.0071, -0.0071, -0.0114,  0.0026,  0.0002,  0.0190, -0.0305, -0.0072,\n                       0.0082, -0.0015, -0.0130,  0.0010,  0.0272, -0.0126, -0.0106, -0.0003,\n                      -0.0254, -0.0387, -0.0120,  0.0103, -0.0037, -0.0085,  0.0028,  0.0035,\n                       0.0182, -0.0046,  0.0323,  0.0015,  0.0018, -0.0021,  0.0128, -0.0015,\n                      -0.0285, -0.0041, -0.0327,  0.0104, -0.0117, -0.0086, -0.0268,  0.0189],\n                     dtype=torch.float64)),\n             ('6.19.convs.1.1.running_mean',\n              tensor([-0.5928,  0.4752, -0.6233,  0.0427,  0.3794,  0.6618,  0.1289, -0.1337,\n                      -0.7683, -0.7071,  0.7596, -0.4342,  0.4187, -0.3059,  0.1674,  0.4107,\n                       0.4373, -0.1382,  0.1947, -0.5036,  0.3961,  0.3380, -0.1310, -0.2714,\n                      -0.4456, -0.8531, -0.3238, -0.4221,  0.5841,  0.6657, -0.3842,  0.5015,\n                      -0.5533,  1.1292, -0.6113,  0.5296, -0.1887,  0.7650, -0.2793, -1.5744,\n                      -0.5374, -0.0544,  0.1547, -0.3493,  0.2678,  0.5066, -0.3600, -0.5852,\n                      -0.1266,  0.0696, -0.8083,  0.3702, -0.2838, -0.8286,  0.3888, -0.6621,\n                      -0.4211, -0.0509, -0.2778, -0.2576,  0.3087,  0.1847, -0.5284, -0.0500],\n                     dtype=torch.float64)),\n             ('6.19.convs.1.1.running_var',\n              tensor([1.0307, 0.5464, 0.4976, 0.5659, 0.7815, 0.3228, 0.8903, 0.7220, 0.6383,\n                      0.6007, 0.5564, 0.4324, 0.6375, 0.4143, 0.6234, 0.5191, 0.7773, 0.5040,\n                      0.7775, 0.7485, 0.6540, 0.6999, 0.7966, 0.7159, 0.8776, 0.5601, 0.6416,\n                      0.6073, 0.5239, 0.7212, 1.3477, 1.1656, 1.2305, 0.6658, 0.8735, 0.6730,\n                      0.3857, 0.5948, 0.8603, 0.9221, 0.7339, 0.5856, 0.4816, 0.4837, 0.6153,\n                      0.7093, 0.8636, 0.9905, 0.5833, 0.6152, 0.6400, 0.9273, 0.5936, 0.6099,\n                      0.6584, 0.5396, 0.6721, 0.9188, 0.5512, 0.9061, 0.4455, 0.6003, 0.6007,\n                      0.5200], dtype=torch.float64)),\n             ('6.19.convs.1.1.num_batches_tracked', tensor(11419)),\n             ('6.19.convs.2.0.weight',\n              tensor([[[ 0.0797],\n                       [-0.0102],\n                       [ 0.0596],\n                       ...,\n                       [ 0.2428],\n                       [ 0.1211],\n                       [ 0.0528]],\n              \n                      [[-0.0220],\n                       [ 0.1337],\n                       [-0.1664],\n                       ...,\n                       [ 0.0216],\n                       [ 0.1583],\n                       [ 0.0961]],\n              \n                      [[ 0.1662],\n                       [-0.0966],\n                       [ 0.0320],\n                       ...,\n                       [ 0.1126],\n                       [ 0.1122],\n                       [ 0.1576]],\n              \n                      ...,\n              \n                      [[ 0.0625],\n                       [ 0.2303],\n                       [ 0.0232],\n                       ...,\n                       [ 0.1938],\n                       [-0.0746],\n                       [-0.2493]],\n              \n                      [[ 0.1689],\n                       [-0.0716],\n                       [ 0.0050],\n                       ...,\n                       [ 0.0837],\n                       [-0.1406],\n                       [-0.0357]],\n              \n                      [[ 0.1402],\n                       [ 0.0852],\n                       [-0.0055],\n                       ...,\n                       [-0.1540],\n                       [ 0.2255],\n                       [-0.0104]]], dtype=torch.float64)),\n             ('6.19.convs.2.1.weight',\n              tensor([ 2.5642e-02,  8.4580e-03, -4.8173e-03, -4.9446e-04,  1.3209e-02,\n                      -2.9487e-02,  2.0291e-02,  2.4041e-03,  2.3538e-04, -3.7390e-03,\n                      -1.0076e-02,  1.8152e-02,  9.8603e-03, -1.7469e-02,  1.2249e-02,\n                      -3.9430e-02,  3.6992e-02, -1.0561e-02,  1.3577e-02,  2.3682e-02,\n                      -1.7785e-02,  1.1457e-02,  3.7826e-03, -2.4202e-02,  2.8240e-03,\n                      -3.7078e-02, -3.4709e-03, -1.6482e-04, -2.7158e-02,  8.4474e-03,\n                       4.2631e-03, -3.0330e-02, -2.9785e-03, -1.5166e-02, -4.0212e-02,\n                      -2.7101e-02,  1.9115e-03, -9.6038e-03, -6.8617e-03,  6.7111e-04,\n                      -6.8956e-03, -1.8139e-02, -9.8092e-04,  1.3832e-02, -5.0147e-03,\n                      -2.9889e-03,  1.8575e-02,  5.7270e-03,  1.9845e-02, -1.4142e-02,\n                      -7.2997e-03,  1.5792e-02, -2.7999e-03, -1.1880e-02,  2.8977e-02,\n                      -3.8239e-02, -1.8930e-02, -1.6091e-02, -1.1582e-02,  1.1376e-02,\n                       6.2557e-03, -4.3417e-03, -1.2699e-02, -3.3392e-05,  3.2460e-02,\n                       9.4697e-03,  2.8259e-02,  2.4293e-03,  3.7619e-02,  3.6423e-02,\n                       1.7905e-02,  2.5833e-03,  1.8416e-02, -1.5838e-02,  3.7919e-03,\n                      -6.8733e-03,  7.6757e-03, -2.7425e-02, -6.8777e-03, -1.9252e-02,\n                       2.0784e-02, -1.5466e-02,  1.1911e-02, -1.4919e-02,  1.5543e-02,\n                       3.7667e-03, -3.2947e-02, -1.7854e-02, -3.4302e-03, -1.1307e-03,\n                       3.0725e-02, -1.9104e-02,  3.3421e-03, -2.1570e-03,  7.6046e-03,\n                       2.1950e-02,  5.0224e-03, -2.4202e-02, -1.7812e-02,  1.4054e-02,\n                       1.4697e-02,  1.0055e-02,  3.6937e-02, -1.3041e-02, -1.0499e-02,\n                       2.1797e-02, -2.2166e-02,  2.2993e-02,  3.9294e-02, -1.8800e-02,\n                       1.3852e-02,  3.7469e-02,  2.5107e-02, -4.4953e-03,  4.8752e-03,\n                       5.3893e-02, -1.4162e-02,  1.9378e-02, -9.1012e-03, -4.9546e-03,\n                       5.8681e-03,  1.3361e-02, -4.6484e-03,  9.6366e-03,  1.7023e-02,\n                       1.4821e-02, -1.5190e-02,  1.8107e-02,  9.8599e-03,  1.2751e-02,\n                      -1.3604e-02, -2.4777e-02, -1.2270e-02, -2.8400e-02,  2.3828e-02,\n                      -2.2001e-02, -1.6476e-02, -8.7873e-04, -2.2996e-02, -1.3663e-02,\n                       8.9200e-03,  7.1816e-03,  2.5577e-02,  1.0948e-02, -2.4022e-02,\n                      -5.4403e-03,  3.3081e-02,  1.8847e-02,  1.9761e-02,  3.4166e-02,\n                      -1.1408e-02, -2.9594e-02,  3.5449e-02, -2.4427e-02,  2.2056e-02,\n                       5.0418e-03, -1.4556e-02,  6.1573e-03, -5.4429e-03,  2.3332e-02,\n                      -2.4918e-02,  1.6788e-04,  3.3074e-03,  1.3567e-02,  3.2918e-02,\n                       1.2756e-02, -3.8438e-03,  6.0706e-03,  8.5753e-04,  2.4783e-02,\n                       1.7048e-02,  1.3910e-02, -2.6020e-02,  2.6514e-02,  3.5533e-03,\n                      -1.1540e-02, -6.3640e-03, -1.0191e-03, -6.3798e-04, -1.3322e-02,\n                       2.5359e-02,  1.3001e-02, -1.0785e-03,  1.2665e-02, -1.7876e-02,\n                       4.0294e-02, -8.1248e-03,  1.7187e-02,  3.9423e-03,  9.3750e-03,\n                       8.6104e-04, -3.5274e-03, -7.4409e-03,  4.9900e-03,  1.4811e-02,\n                      -4.0469e-02, -1.0745e-02, -6.5732e-03,  9.6444e-03, -6.4943e-03,\n                      -3.4300e-03, -7.9677e-03, -1.8368e-02,  1.3603e-02,  2.8427e-02,\n                       9.3733e-03,  2.0542e-02,  1.4194e-02, -1.1689e-02,  1.4431e-02,\n                      -7.5627e-03, -2.1449e-03,  4.1732e-03,  4.3689e-02,  1.5029e-02,\n                       4.4983e-03, -3.0290e-02, -6.8898e-03, -1.1102e-03, -1.5572e-03,\n                       1.1373e-02, -7.2241e-04, -3.6555e-03, -1.9394e-02,  2.4366e-02,\n                       3.1652e-03, -8.9972e-03,  2.5415e-02,  7.2177e-03,  1.7781e-02,\n                       4.3796e-04, -1.3753e-02,  2.1411e-02, -6.5026e-03, -3.0598e-02,\n                      -1.3901e-02,  1.9894e-02,  1.6247e-02,  1.4317e-02, -9.8724e-04,\n                      -1.5569e-02,  1.5917e-02, -1.1595e-02,  6.6037e-03,  1.4463e-02,\n                      -5.3876e-04, -1.8056e-03,  4.6114e-03, -1.8690e-02, -1.2095e-03,\n                      -1.7851e-02, -6.0589e-03,  1.1632e-02, -1.1150e-02,  1.4940e-02,\n                      -1.7556e-02], dtype=torch.float64)),\n             ('6.19.convs.2.1.bias',\n              tensor([ 5.5795e-03,  6.8452e-03,  1.3027e-02,  1.3996e-02, -1.5968e-03,\n                       7.1464e-03,  4.0992e-03,  3.7857e-03,  7.6059e-03,  3.2851e-03,\n                       1.4242e-02, -6.4224e-03,  4.2620e-03,  9.4007e-04,  5.9677e-04,\n                       5.3216e-03,  2.5768e-02,  1.3462e-03,  1.0280e-02, -3.3940e-03,\n                      -7.9514e-03,  1.3612e-03,  7.9924e-03,  4.8551e-03,  1.5408e-02,\n                      -1.4372e-02,  5.6363e-03,  7.3427e-03,  1.0387e-02, -6.6261e-03,\n                      -4.4624e-03,  1.8424e-02,  5.1608e-03,  1.4987e-02,  1.2605e-02,\n                       1.4338e-02,  1.1324e-02,  6.6319e-03,  1.5994e-02,  4.6495e-04,\n                       8.7336e-03,  9.9964e-03, -2.4465e-03, -6.0165e-03,  8.5780e-03,\n                      -1.6520e-02,  1.3089e-02,  3.9584e-03, -1.1820e-02,  3.2972e-03,\n                       9.8129e-03,  2.5974e-03,  7.5514e-03,  2.0750e-02,  4.0634e-04,\n                       1.4957e-02,  1.0559e-02,  5.1121e-03,  5.1806e-03, -2.9122e-03,\n                       8.0817e-04,  3.6802e-04,  1.4792e-02,  5.3082e-03, -1.1777e-02,\n                       4.5985e-04, -7.8810e-05,  1.0087e-02,  1.7604e-02, -1.3171e-02,\n                       8.0979e-03, -1.7241e-03, -9.4438e-04, -8.3990e-03,  1.1979e-02,\n                       7.6170e-03,  4.7734e-03,  1.8051e-02,  3.0206e-04,  9.0756e-03,\n                       3.3894e-03, -1.0864e-02,  1.8498e-02,  4.3812e-03, -7.3263e-03,\n                       2.1294e-02,  2.2070e-04,  1.0547e-02,  1.2104e-02, -3.1122e-03,\n                       3.0811e-03,  1.2447e-02,  8.4645e-03, -2.9774e-03,  3.8647e-03,\n                      -7.0275e-03,  1.1523e-02,  2.6896e-03,  1.9267e-02,  6.4599e-03,\n                       2.4632e-02,  1.3974e-02,  5.1281e-03,  1.0933e-02,  4.2280e-03,\n                      -5.4675e-03,  4.7855e-03,  1.1219e-02,  4.1039e-03,  4.6562e-03,\n                      -9.1134e-04, -5.5956e-03,  5.5832e-03,  2.0898e-02,  1.5679e-02,\n                      -1.3077e-03,  4.2575e-03,  7.3684e-04, -1.3083e-03, -4.2507e-03,\n                       5.5670e-05,  1.2555e-02,  6.3002e-03,  6.6684e-04,  1.6028e-02,\n                       4.0528e-03,  9.2572e-03,  3.9450e-03,  5.5439e-03,  1.3665e-02,\n                       6.2590e-03,  3.5932e-03,  9.4597e-03,  3.6877e-04,  4.5255e-03,\n                      -1.4191e-02,  8.4326e-03,  4.0407e-03,  7.4254e-03,  1.1482e-02,\n                       2.6038e-02,  1.5751e-02,  5.9726e-03,  1.9073e-03, -5.9728e-03,\n                       6.4643e-03,  3.7168e-03,  4.2105e-03,  1.1550e-03, -5.6850e-05,\n                       1.0249e-02,  6.8243e-03,  2.3168e-03,  1.0297e-02,  1.3657e-02,\n                       2.2880e-03, -5.2862e-03,  4.4627e-03,  6.7281e-03,  9.7064e-04,\n                       6.5972e-03,  9.0131e-03, -1.4831e-03,  5.8038e-03,  1.0834e-02,\n                      -5.5050e-03, -1.0966e-02,  5.5163e-03,  1.1194e-02,  1.1666e-02,\n                       1.3355e-02,  2.3986e-03,  1.3743e-02,  1.4511e-02, -1.4481e-02,\n                       1.6554e-03, -3.8071e-03,  1.4000e-02, -3.6034e-03,  3.6123e-03,\n                       3.5138e-03,  1.3401e-02, -2.8651e-03, -7.4266e-03,  8.4105e-03,\n                       6.2168e-03,  1.0858e-02,  5.8692e-03,  1.3663e-02,  5.5727e-03,\n                       3.5659e-03,  8.1475e-03,  4.6109e-03,  8.9707e-03,  9.1123e-03,\n                       8.1295e-03,  1.1478e-02, -1.1042e-03,  3.3490e-03,  7.2678e-03,\n                      -3.5186e-03,  2.1046e-02,  1.7184e-02,  1.5737e-02,  1.5109e-02,\n                       7.4730e-03,  1.4879e-02, -8.9731e-03,  3.2758e-03,  6.5919e-03,\n                       2.8882e-03,  1.0140e-02, -4.5578e-03,  1.2943e-02,  8.4944e-03,\n                       3.3985e-03,  3.1783e-03,  1.8979e-02,  1.3290e-03, -1.2039e-03,\n                       1.8321e-02,  7.8887e-03,  1.0324e-03,  1.3165e-02,  1.1563e-02,\n                       5.0112e-03, -6.9181e-03, -5.3101e-03,  2.6231e-02,  1.8432e-02,\n                       9.1612e-04, -1.7465e-03,  1.3066e-02,  1.2667e-02, -5.3628e-03,\n                       3.7116e-03, -4.1852e-03,  8.9871e-03,  2.8716e-03,  1.5833e-02,\n                      -5.2716e-03,  9.9374e-04, -8.9385e-03,  1.2544e-02,  2.3159e-04,\n                       3.1393e-03,  5.2788e-03, -1.2344e-04, -2.6189e-02, -1.1535e-02,\n                       1.8015e-02,  1.7858e-02,  8.8621e-03,  1.8253e-02,  3.3046e-03,\n                       8.0231e-04], dtype=torch.float64)),\n             ('6.19.convs.2.1.running_mean',\n              tensor([ 4.6563e-01, -3.4816e-01,  4.7304e-01,  6.3204e-01,  9.7278e-03,\n                      -2.3532e-01, -9.3138e-02, -1.7648e-01, -2.0710e-01, -3.3035e-01,\n                      -7.0218e-01, -6.9077e-02,  2.9301e-02,  1.1658e-01, -3.3423e-01,\n                      -3.4745e-02,  4.7870e-01, -3.3121e-02,  2.1530e-01, -3.3713e-01,\n                       4.3058e-01,  1.4090e-01, -1.0053e-01,  7.5492e-02,  8.6351e-02,\n                       6.1790e-01,  1.8424e-01,  1.1125e-01, -5.5139e-02,  2.7138e-01,\n                       1.8303e-01, -4.4575e-01, -3.4503e-01, -6.8247e-04,  5.2191e-02,\n                      -1.5672e-01,  6.8534e-02,  4.5404e-01,  4.7735e-01, -2.4491e-01,\n                       2.6441e-01,  8.4410e-02, -2.7534e-01, -7.4926e-02, -5.1675e-01,\n                      -8.8760e-03, -2.3826e-03,  2.6709e-01, -3.5656e-01, -1.3981e-02,\n                       4.9776e-02,  1.7527e-01,  3.6491e-02,  7.1266e-01,  6.4192e-01,\n                       8.7452e-02, -3.3114e-01,  3.7922e-02, -2.8434e-01,  5.2543e-01,\n                      -4.8034e-02,  5.7596e-01,  1.2587e-01, -1.7413e-01, -6.3395e-01,\n                       3.8107e-01,  4.6375e-01, -2.6954e-01,  1.4986e-01, -2.7817e-01,\n                       3.4784e-01,  8.9721e-01, -4.9930e-02, -1.0327e+00, -2.3148e-01,\n                       4.2404e-02, -6.7433e-01,  3.5453e-01, -3.8668e-01, -2.9126e-01,\n                       3.8084e-01, -4.3838e-01, -1.2300e-01,  4.8746e-01,  2.8548e-01,\n                      -5.3066e-02,  4.5110e-01,  3.8671e-01,  4.0836e-01, -2.3824e-01,\n                       6.9267e-02,  2.3549e-03, -3.8494e-01, -8.0819e-02, -1.4605e-01,\n                      -1.5555e-01, -4.2562e-01, -7.5378e-01, -1.5044e-01, -5.7594e-01,\n                      -1.0600e+00,  1.4572e-01,  5.6451e-01,  7.1868e-02, -6.1224e-01,\n                      -1.1158e-01,  1.3358e-01,  6.8077e-01,  4.1712e-01,  2.9568e-01,\n                       5.2029e-01, -1.1982e-01,  2.1936e-01,  3.8868e-02, -6.9053e-02,\n                      -1.8599e-01, -4.0702e-01, -4.7971e-01,  1.4578e-01, -7.2118e-01,\n                       1.3920e-01, -5.8302e-01, -1.5235e-01,  1.0100e-01, -3.3491e-01,\n                      -1.3602e-01, -1.1133e-01,  5.8465e-02,  1.2921e-01,  2.0191e-01,\n                      -5.6975e-04, -2.7403e-01, -4.2124e-01,  5.0644e-01, -2.2896e-01,\n                       6.4109e-01, -1.8716e-01,  4.4038e-02, -7.7396e-02, -8.6320e-02,\n                       2.7824e-01, -2.5178e-01,  4.1393e-01, -6.3122e-02,  2.6609e-02,\n                       5.0872e-01,  4.7795e-01, -4.7177e-02,  1.1216e-01,  4.0698e-01,\n                       2.7063e-01,  1.5148e-01,  2.0920e-02,  5.7333e-01, -7.2754e-01,\n                      -1.0667e-02, -2.8255e-01,  2.6180e-02,  5.8384e-01, -2.6073e-01,\n                      -5.6122e-01,  7.5266e-02, -2.9557e-01, -2.4874e-01, -6.1147e-01,\n                      -1.7894e-01,  1.2616e-02, -1.3509e-01,  2.9992e-03, -5.8052e-01,\n                       4.7149e-02,  4.8902e-01, -1.1700e-01, -2.7034e-01,  3.2961e-01,\n                      -3.5747e-01,  3.7908e-02,  2.7772e-02, -1.2957e-01,  6.6487e-02,\n                      -1.6610e-01, -9.8769e-02,  3.5037e-02,  2.2840e-01,  2.4427e-01,\n                      -1.0658e-01,  6.9748e-01,  7.1381e-02,  8.5652e-02,  5.8543e-01,\n                      -3.3029e-01,  1.7319e-01,  4.5155e-01,  1.8966e-01,  9.9249e-02,\n                       2.5932e-01, -5.4634e-01,  3.6261e-01,  2.4419e-01, -3.6525e-01,\n                      -2.3492e-01, -9.7841e-02,  2.2012e-01, -7.3702e-01, -5.4523e-01,\n                       5.9148e-02,  1.1227e-01, -1.5223e-02,  5.0568e-03,  2.6028e-01,\n                      -1.4641e-01,  4.4206e-01,  4.6827e-02, -4.7252e-01, -2.4931e-01,\n                      -1.7327e-01, -5.3082e-01, -5.1788e-01,  4.8424e-02,  1.1789e-01,\n                       1.2217e-01,  4.4098e-02, -3.1413e-01,  7.2869e-01, -9.1709e-01,\n                      -1.2146e-01, -1.4294e-01, -2.3664e-02, -2.5959e-01, -5.9141e-02,\n                      -1.9730e-01,  4.2915e-03,  4.2853e-01, -6.5367e-01, -6.0749e-01,\n                       2.5845e-01,  3.1770e-01,  1.7928e-01,  8.5676e-02, -4.1451e-01,\n                      -2.5173e-01,  4.2405e-01,  5.2295e-01, -4.0515e-01, -8.7854e-02,\n                       1.2757e-01, -1.4580e-01,  1.4460e-01,  5.1708e-02, -8.3048e-03,\n                      -6.2309e-01, -1.7422e-01, -5.0098e-01,  6.4917e-01, -4.7236e-01,\n                       3.5787e-02], dtype=torch.float64)),\n             ('6.19.convs.2.1.running_var',\n              tensor([0.5134, 0.4325, 0.1983, 0.6342, 0.3373, 0.3455, 0.3954, 0.3193, 0.2742,\n                      0.4187, 0.3627, 0.3761, 0.1793, 0.4352, 0.1900, 0.5649, 0.5326, 0.3870,\n                      0.2241, 0.4234, 0.4342, 0.6256, 0.5527, 0.4402, 0.3814, 0.4537, 0.3875,\n                      0.1738, 0.4370, 0.2759, 0.2520, 0.6207, 0.1247, 0.2877, 0.2704, 0.5901,\n                      0.1621, 0.3926, 0.2081, 0.3508, 0.3355, 0.1718, 0.0503, 0.4076, 0.2696,\n                      0.3421, 0.3347, 0.3705, 0.3099, 0.3521, 0.2363, 0.2508, 0.3277, 0.4268,\n                      0.5970, 0.5193, 0.2602, 0.4151, 0.2855, 0.2324, 0.2513, 0.2916, 0.2816,\n                      0.1003, 0.4265, 0.3067, 0.3697, 0.2170, 0.2707, 0.2727, 0.3060, 0.2662,\n                      0.3292, 0.5290, 0.2870, 0.1694, 0.3984, 0.3518, 0.4821, 0.1801, 0.5990,\n                      0.2890, 0.3063, 0.5041, 0.3122, 0.4221, 0.3611, 0.3865, 0.2048, 0.1861,\n                      0.6148, 0.4104, 0.3192, 0.1180, 0.1598, 0.3434, 0.2847, 0.3921, 0.2627,\n                      0.2892, 0.5259, 0.2490, 0.2245, 0.2558, 0.2766, 0.2692, 0.4599, 0.3815,\n                      0.6175, 0.2056, 0.2523, 0.4830, 0.6354, 0.1646, 0.3105, 0.3987, 0.3158,\n                      0.4761, 0.2604, 0.7351, 0.0376, 0.3755, 0.5876, 0.2159, 0.2582, 0.3784,\n                      0.3223, 0.2443, 0.1142, 0.7720, 0.1374, 0.4067, 0.5944, 0.3025, 0.3142,\n                      0.3831, 0.3412, 0.1294, 0.5424, 0.3390, 0.3865, 0.3155, 0.3182, 0.1661,\n                      0.3778, 0.2916, 0.2514, 0.5505, 0.1573, 0.4250, 0.3575, 0.1896, 0.2617,\n                      0.5433, 0.4804, 0.1807, 0.4113, 0.3352, 0.3466, 0.3594, 0.5993, 0.1370,\n                      0.0650, 0.2164, 0.4894, 0.4464, 0.4413, 0.1607, 0.2144, 0.3155, 0.2865,\n                      0.3933, 0.4302, 0.2372, 0.3917, 0.4778, 0.2297, 0.2884, 0.1655, 0.3402,\n                      0.6513, 0.2633, 0.3002, 0.4044, 0.3371, 0.4165, 0.3335, 0.2477, 0.1975,\n                      0.3340, 0.1174, 0.1793, 0.1944, 0.2828, 0.2714, 0.3109, 0.4287, 0.1807,\n                      0.3260, 0.4032, 0.1769, 0.2604, 0.2938, 0.3250, 0.3376, 0.3443, 0.2208,\n                      0.1547, 0.2426, 0.4781, 0.1359, 0.2274, 0.1359, 0.8513, 0.2469, 0.1483,\n                      0.3002, 0.2571, 0.1664, 0.4263, 0.2461, 0.1977, 0.1077, 0.3126, 0.5675,\n                      0.2108, 0.1386, 0.4669, 0.5812, 0.4779, 0.2133, 0.1663, 0.4578, 0.2748,\n                      0.3831, 0.2817, 0.4702, 0.3001, 0.3737, 0.3382, 0.1635, 0.1979, 0.4303,\n                      0.2696, 0.2337, 0.1974, 0.1061, 0.4901, 0.2056, 0.2740, 0.7442, 0.3983,\n                      0.1774, 0.3929, 0.2224, 0.2557], dtype=torch.float64)),\n             ('6.19.convs.2.1.num_batches_tracked', tensor(11419)),\n             ('6.19.convpath.0.0.0.weight',\n              tensor([[[-0.0309],\n                       [ 0.0352],\n                       [-0.0062],\n                       ...,\n                       [ 0.0164],\n                       [-0.1095],\n                       [ 0.1249]],\n              \n                      [[ 0.0469],\n                       [-0.0528],\n                       [-0.0574],\n                       ...,\n                       [-0.0871],\n                       [ 0.0535],\n                       [-0.0431]],\n              \n                      [[-0.0536],\n                       [ 0.1097],\n                       [ 0.0267],\n                       ...,\n                       [ 0.1238],\n                       [-0.1016],\n                       [-0.0073]],\n              \n                      ...,\n              \n                      [[-0.1524],\n                       [-0.1054],\n                       [ 0.0396],\n                       ...,\n                       [-0.0170],\n                       [-0.0055],\n                       [-0.0294]],\n              \n                      [[-0.0636],\n                       [ 0.0465],\n                       [-0.1090],\n                       ...,\n                       [-0.0072],\n                       [ 0.0397],\n                       [-0.0325]],\n              \n                      [[ 0.1725],\n                       [ 0.1143],\n                       [ 0.0235],\n                       ...,\n                       [-0.0319],\n                       [ 0.0712],\n                       [ 0.0875]]], dtype=torch.float64)),\n             ('6.19.convpath.0.0.1.weight',\n              tensor([0.9465, 0.9673, 0.9610, 0.9982, 0.9627, 0.9206, 0.9613, 0.9774, 0.9680,\n                      0.9548, 0.9687, 0.9728, 0.9534, 0.9651, 0.9637, 0.9550, 0.9873, 0.9821,\n                      0.9950, 0.9775, 0.9508, 0.9539, 0.9569, 0.9602, 0.9906, 0.9584, 0.9734,\n                      0.9563, 0.9670, 0.9598, 0.9677, 0.9615, 0.9995, 0.9924, 0.9926, 0.9774,\n                      0.9630, 0.9691, 0.9840, 0.9736, 0.9810, 0.9847, 0.9664, 0.9729, 0.9663,\n                      0.9759, 0.9888, 0.9898, 0.9786, 0.9691, 0.9576, 0.9848, 0.9614, 0.9877,\n                      0.9785, 1.0056, 0.9587, 0.9637, 0.9717, 0.9649, 0.9715, 0.9830, 0.9343,\n                      0.9689], dtype=torch.float64)),\n             ('6.19.convpath.0.0.1.bias',\n              tensor([ 0.0004,  0.0010,  0.0090,  0.0118, -0.0161, -0.0230,  0.0081,  0.0007,\n                      -0.0011, -0.0010, -0.0007,  0.0052, -0.0120, -0.0151,  0.0100, -0.0061,\n                       0.0027, -0.0112,  0.0109, -0.0109, -0.0046, -0.0194, -0.0048, -0.0098,\n                       0.0251,  0.0005, -0.0126,  0.0074,  0.0064, -0.0065,  0.0087, -0.0048,\n                       0.0267,  0.0263,  0.0099,  0.0038,  0.0168,  0.0078,  0.0081,  0.0054,\n                       0.0019,  0.0193, -0.0142,  0.0120, -0.0155,  0.0095,  0.0080,  0.0065,\n                       0.0028, -0.0186, -0.0022,  0.0122, -0.0067, -0.0053, -0.0004,  0.0218,\n                       0.0016,  0.0023,  0.0117, -0.0185,  0.0077,  0.0066,  0.0057, -0.0242],\n                     dtype=torch.float64)),\n             ('6.19.convpath.0.0.1.running_mean',\n              tensor([-0.0352,  0.1269,  1.0086, -0.5691,  0.4288,  0.1688,  0.6714,  0.3483,\n                       1.6770, -0.5643,  0.3108,  0.5974,  0.1055,  0.6841,  0.4968,  1.0746,\n                       0.4248, -0.1263,  0.0488,  1.3591,  0.1826,  0.4513, -0.2599, -0.1598,\n                      -0.3771,  0.4301,  0.3143, -0.1347,  1.0426,  0.4396, -0.5129,  0.8051,\n                      -0.5000, -0.0382, -0.4156,  0.1962, -0.5401, -0.5085,  0.0811,  0.8767,\n                       0.5280,  0.4389, -0.1381,  0.2047,  0.2205,  0.3668, -0.7498, -0.9375,\n                       0.2150,  0.7657, -0.0034,  0.6661, -0.1777,  0.1903, -1.2948,  0.3198,\n                       0.3274, -0.1673, -0.3854,  0.8866,  0.0911, -0.0436, -1.5243, -0.7568],\n                     dtype=torch.float64)),\n             ('6.19.convpath.0.0.1.running_var',\n              tensor([0.6753, 0.6099, 0.1485, 0.1127, 0.4499, 0.1259, 0.3177, 0.1275, 0.3582,\n                      0.1177, 0.1491, 0.1335, 0.1072, 0.1845, 0.3260, 0.5314, 0.1514, 0.1063,\n                      0.1642, 0.6159, 0.2689, 0.0986, 0.2813, 0.1059, 0.2782, 0.4126, 0.2184,\n                      0.3942, 0.3670, 0.6785, 0.2573, 0.6176, 0.1335, 0.2136, 0.1746, 0.1991,\n                      0.2718, 0.2110, 0.0934, 0.3661, 0.3891, 0.1652, 0.1269, 0.1293, 0.1617,\n                      0.5399, 0.2253, 0.1296, 0.4586, 0.1804, 0.7872, 0.2141, 0.2740, 0.1984,\n                      0.1814, 0.1486, 0.2788, 0.1341, 0.1227, 0.2549, 0.4101, 0.1312, 0.5740,\n                      0.1581], dtype=torch.float64)),\n             ('6.19.convpath.0.0.1.num_batches_tracked', tensor(11419)),\n             ('6.19.convpath.0.1.0.weight',\n              tensor([[[ 0.1165, -0.1736,  0.0306, -0.0704, -0.0433],\n                       [ 0.0334, -0.0367, -0.0195,  0.0504, -0.1455],\n                       [ 0.1327,  0.0585, -0.0744,  0.0926,  0.0495],\n                       ...,\n                       [-0.0434,  0.1077, -0.0595,  0.0033,  0.0543],\n                       [-0.0087,  0.1416, -0.0783,  0.0033, -0.0156],\n                       [ 0.0259,  0.0772, -0.0559,  0.0033, -0.0133]],\n              \n                      [[-0.0969, -0.1059, -0.1564, -0.0751, -0.1244],\n                       [-0.1024, -0.0131, -0.1156,  0.0490, -0.0207],\n                       [ 0.0746,  0.0309, -0.0064,  0.0696, -0.0899],\n                       ...,\n                       [ 0.0702, -0.0677,  0.0464, -0.0528,  0.0621],\n                       [-0.1095,  0.0752,  0.0498, -0.0710, -0.0553],\n                       [ 0.0399,  0.1017, -0.1137,  0.1110, -0.0143]],\n              \n                      [[ 0.0486,  0.1574, -0.0219, -0.0175,  0.0295],\n                       [-0.0751, -0.2239,  0.0829,  0.0138,  0.0032],\n                       [ 0.0452, -0.0014, -0.0441, -0.1438, -0.0019],\n                       ...,\n                       [-0.0967, -0.0573,  0.0150, -0.1774,  0.0102],\n                       [-0.1442,  0.1391,  0.0036,  0.0125, -0.0165],\n                       [ 0.0196, -0.0220,  0.0362,  0.0105,  0.0080]],\n              \n                      ...,\n              \n                      [[ 0.0459, -0.0270,  0.0123, -0.0173, -0.0490],\n                       [-0.0014, -0.0581, -0.0340,  0.0084, -0.1285],\n                       [ 0.0311,  0.0581,  0.0909,  0.0502, -0.0235],\n                       ...,\n                       [-0.0576, -0.0291, -0.1795, -0.0349,  0.1208],\n                       [-0.0633, -0.0917,  0.0608,  0.0222,  0.1170],\n                       [ 0.0178, -0.0665, -0.0138,  0.1873,  0.0839]],\n              \n                      [[-0.0355, -0.0649,  0.0332, -0.0104, -0.0937],\n                       [ 0.0547,  0.0169,  0.0314,  0.0078, -0.0403],\n                       [ 0.0762, -0.0570, -0.0565, -0.0390,  0.0486],\n                       ...,\n                       [-0.0129,  0.0333, -0.0114, -0.0347, -0.0766],\n                       [-0.0408,  0.0754, -0.0126,  0.0182, -0.0775],\n                       [-0.0025,  0.0352,  0.1216,  0.1075, -0.1832]],\n              \n                      [[ 0.0954,  0.0212, -0.0932,  0.0348, -0.1242],\n                       [-0.0298, -0.0097, -0.0489,  0.1128, -0.0180],\n                       [ 0.0729,  0.0294, -0.0500, -0.0591,  0.0400],\n                       ...,\n                       [-0.1481,  0.0661,  0.0523, -0.0160,  0.0190],\n                       [ 0.0876,  0.0092,  0.0145, -0.0134, -0.1215],\n                       [ 0.0388,  0.1000,  0.1322, -0.0559,  0.1115]]], dtype=torch.float64)),\n             ('6.19.convpath.0.1.1.weight',\n              tensor([0.9854, 0.9772, 0.9586, 0.9698, 0.9546, 0.9785, 0.9591, 0.9452, 0.9358,\n                      0.9381, 0.9514, 0.9844, 0.9680, 0.9707, 0.9283, 0.9679, 0.9576, 0.9826,\n                      0.9592, 0.9798, 0.9548, 0.9960, 0.9639, 0.9595, 0.9699, 0.9628, 0.9560,\n                      0.9582, 0.9932, 1.0024, 0.9836, 0.9702, 0.9626, 0.9779, 0.9211, 0.9636,\n                      0.9846, 0.9447, 0.9561, 0.9486, 0.9418, 0.9346, 0.9613, 0.9692, 1.0056,\n                      0.9570, 0.9559, 0.9564, 0.9965, 0.9589, 0.9799, 0.9652, 0.9894, 0.9469,\n                      0.9864, 0.9511, 0.9373, 0.9645, 0.9467, 0.9789, 0.9695, 0.9466, 0.9587,\n                      0.9868], dtype=torch.float64)),\n             ('6.19.convpath.0.1.1.bias',\n              tensor([ 0.0189,  0.0067,  0.0051,  0.0044, -0.0194,  0.0132, -0.0118, -0.0287,\n                       0.0040,  0.0007, -0.0265, -0.0091, -0.0233,  0.0129, -0.0266,  0.0060,\n                      -0.0025,  0.0012, -0.0061, -0.0023, -0.0109, -0.0014,  0.0093,  0.0049,\n                       0.0071, -0.0071, -0.0114,  0.0026,  0.0002,  0.0190, -0.0305, -0.0072,\n                       0.0082, -0.0015, -0.0130,  0.0010,  0.0272, -0.0126, -0.0106, -0.0003,\n                      -0.0254, -0.0387, -0.0120,  0.0103, -0.0037, -0.0085,  0.0028,  0.0035,\n                       0.0182, -0.0046,  0.0323,  0.0015,  0.0018, -0.0021,  0.0128, -0.0015,\n                      -0.0285, -0.0041, -0.0327,  0.0104, -0.0117, -0.0086, -0.0268,  0.0189],\n                     dtype=torch.float64)),\n             ('6.19.convpath.0.1.1.running_mean',\n              tensor([-0.5928,  0.4752, -0.6233,  0.0427,  0.3794,  0.6618,  0.1289, -0.1337,\n                      -0.7683, -0.7071,  0.7596, -0.4342,  0.4187, -0.3059,  0.1674,  0.4107,\n                       0.4373, -0.1382,  0.1947, -0.5036,  0.3961,  0.3380, -0.1310, -0.2714,\n                      -0.4456, -0.8531, -0.3238, -0.4221,  0.5841,  0.6657, -0.3842,  0.5015,\n                      -0.5533,  1.1292, -0.6113,  0.5296, -0.1887,  0.7650, -0.2793, -1.5744,\n                      -0.5374, -0.0544,  0.1547, -0.3493,  0.2678,  0.5066, -0.3600, -0.5852,\n                      -0.1266,  0.0696, -0.8083,  0.3702, -0.2838, -0.8286,  0.3888, -0.6621,\n                      -0.4211, -0.0509, -0.2778, -0.2576,  0.3087,  0.1847, -0.5284, -0.0500],\n                     dtype=torch.float64)),\n             ('6.19.convpath.0.1.1.running_var',\n              tensor([1.0307, 0.5464, 0.4976, 0.5659, 0.7815, 0.3228, 0.8903, 0.7220, 0.6383,\n                      0.6007, 0.5564, 0.4324, 0.6375, 0.4143, 0.6234, 0.5191, 0.7773, 0.5040,\n                      0.7775, 0.7485, 0.6540, 0.6999, 0.7966, 0.7159, 0.8776, 0.5601, 0.6416,\n                      0.6073, 0.5239, 0.7212, 1.3477, 1.1656, 1.2305, 0.6658, 0.8735, 0.6730,\n                      0.3857, 0.5948, 0.8603, 0.9221, 0.7339, 0.5856, 0.4816, 0.4837, 0.6153,\n                      0.7093, 0.8636, 0.9905, 0.5833, 0.6152, 0.6400, 0.9273, 0.5936, 0.6099,\n                      0.6584, 0.5396, 0.6721, 0.9188, 0.5512, 0.9061, 0.4455, 0.6003, 0.6007,\n                      0.5200], dtype=torch.float64)),\n             ('6.19.convpath.0.1.1.num_batches_tracked', tensor(11419)),\n             ('6.19.convpath.0.2.0.weight',\n              tensor([[[ 0.0797],\n                       [-0.0102],\n                       [ 0.0596],\n                       ...,\n                       [ 0.2428],\n                       [ 0.1211],\n                       [ 0.0528]],\n              \n                      [[-0.0220],\n                       [ 0.1337],\n                       [-0.1664],\n                       ...,\n                       [ 0.0216],\n                       [ 0.1583],\n                       [ 0.0961]],\n              \n                      [[ 0.1662],\n                       [-0.0966],\n                       [ 0.0320],\n                       ...,\n                       [ 0.1126],\n                       [ 0.1122],\n                       [ 0.1576]],\n              \n                      ...,\n              \n                      [[ 0.0625],\n                       [ 0.2303],\n                       [ 0.0232],\n                       ...,\n                       [ 0.1938],\n                       [-0.0746],\n                       [-0.2493]],\n              \n                      [[ 0.1689],\n                       [-0.0716],\n                       [ 0.0050],\n                       ...,\n                       [ 0.0837],\n                       [-0.1406],\n                       [-0.0357]],\n              \n                      [[ 0.1402],\n                       [ 0.0852],\n                       [-0.0055],\n                       ...,\n                       [-0.1540],\n                       [ 0.2255],\n                       [-0.0104]]], dtype=torch.float64)),\n             ('6.19.convpath.0.2.1.weight',\n              tensor([ 2.5642e-02,  8.4580e-03, -4.8173e-03, -4.9446e-04,  1.3209e-02,\n                      -2.9487e-02,  2.0291e-02,  2.4041e-03,  2.3538e-04, -3.7390e-03,\n                      -1.0076e-02,  1.8152e-02,  9.8603e-03, -1.7469e-02,  1.2249e-02,\n                      -3.9430e-02,  3.6992e-02, -1.0561e-02,  1.3577e-02,  2.3682e-02,\n                      -1.7785e-02,  1.1457e-02,  3.7826e-03, -2.4202e-02,  2.8240e-03,\n                      -3.7078e-02, -3.4709e-03, -1.6482e-04, -2.7158e-02,  8.4474e-03,\n                       4.2631e-03, -3.0330e-02, -2.9785e-03, -1.5166e-02, -4.0212e-02,\n                      -2.7101e-02,  1.9115e-03, -9.6038e-03, -6.8617e-03,  6.7111e-04,\n                      -6.8956e-03, -1.8139e-02, -9.8092e-04,  1.3832e-02, -5.0147e-03,\n                      -2.9889e-03,  1.8575e-02,  5.7270e-03,  1.9845e-02, -1.4142e-02,\n                      -7.2997e-03,  1.5792e-02, -2.7999e-03, -1.1880e-02,  2.8977e-02,\n                      -3.8239e-02, -1.8930e-02, -1.6091e-02, -1.1582e-02,  1.1376e-02,\n                       6.2557e-03, -4.3417e-03, -1.2699e-02, -3.3392e-05,  3.2460e-02,\n                       9.4697e-03,  2.8259e-02,  2.4293e-03,  3.7619e-02,  3.6423e-02,\n                       1.7905e-02,  2.5833e-03,  1.8416e-02, -1.5838e-02,  3.7919e-03,\n                      -6.8733e-03,  7.6757e-03, -2.7425e-02, -6.8777e-03, -1.9252e-02,\n                       2.0784e-02, -1.5466e-02,  1.1911e-02, -1.4919e-02,  1.5543e-02,\n                       3.7667e-03, -3.2947e-02, -1.7854e-02, -3.4302e-03, -1.1307e-03,\n                       3.0725e-02, -1.9104e-02,  3.3421e-03, -2.1570e-03,  7.6046e-03,\n                       2.1950e-02,  5.0224e-03, -2.4202e-02, -1.7812e-02,  1.4054e-02,\n                       1.4697e-02,  1.0055e-02,  3.6937e-02, -1.3041e-02, -1.0499e-02,\n                       2.1797e-02, -2.2166e-02,  2.2993e-02,  3.9294e-02, -1.8800e-02,\n                       1.3852e-02,  3.7469e-02,  2.5107e-02, -4.4953e-03,  4.8752e-03,\n                       5.3893e-02, -1.4162e-02,  1.9378e-02, -9.1012e-03, -4.9546e-03,\n                       5.8681e-03,  1.3361e-02, -4.6484e-03,  9.6366e-03,  1.7023e-02,\n                       1.4821e-02, -1.5190e-02,  1.8107e-02,  9.8599e-03,  1.2751e-02,\n                      -1.3604e-02, -2.4777e-02, -1.2270e-02, -2.8400e-02,  2.3828e-02,\n                      -2.2001e-02, -1.6476e-02, -8.7873e-04, -2.2996e-02, -1.3663e-02,\n                       8.9200e-03,  7.1816e-03,  2.5577e-02,  1.0948e-02, -2.4022e-02,\n                      -5.4403e-03,  3.3081e-02,  1.8847e-02,  1.9761e-02,  3.4166e-02,\n                      -1.1408e-02, -2.9594e-02,  3.5449e-02, -2.4427e-02,  2.2056e-02,\n                       5.0418e-03, -1.4556e-02,  6.1573e-03, -5.4429e-03,  2.3332e-02,\n                      -2.4918e-02,  1.6788e-04,  3.3074e-03,  1.3567e-02,  3.2918e-02,\n                       1.2756e-02, -3.8438e-03,  6.0706e-03,  8.5753e-04,  2.4783e-02,\n                       1.7048e-02,  1.3910e-02, -2.6020e-02,  2.6514e-02,  3.5533e-03,\n                      -1.1540e-02, -6.3640e-03, -1.0191e-03, -6.3798e-04, -1.3322e-02,\n                       2.5359e-02,  1.3001e-02, -1.0785e-03,  1.2665e-02, -1.7876e-02,\n                       4.0294e-02, -8.1248e-03,  1.7187e-02,  3.9423e-03,  9.3750e-03,\n                       8.6104e-04, -3.5274e-03, -7.4409e-03,  4.9900e-03,  1.4811e-02,\n                      -4.0469e-02, -1.0745e-02, -6.5732e-03,  9.6444e-03, -6.4943e-03,\n                      -3.4300e-03, -7.9677e-03, -1.8368e-02,  1.3603e-02,  2.8427e-02,\n                       9.3733e-03,  2.0542e-02,  1.4194e-02, -1.1689e-02,  1.4431e-02,\n                      -7.5627e-03, -2.1449e-03,  4.1732e-03,  4.3689e-02,  1.5029e-02,\n                       4.4983e-03, -3.0290e-02, -6.8898e-03, -1.1102e-03, -1.5572e-03,\n                       1.1373e-02, -7.2241e-04, -3.6555e-03, -1.9394e-02,  2.4366e-02,\n                       3.1652e-03, -8.9972e-03,  2.5415e-02,  7.2177e-03,  1.7781e-02,\n                       4.3796e-04, -1.3753e-02,  2.1411e-02, -6.5026e-03, -3.0598e-02,\n                      -1.3901e-02,  1.9894e-02,  1.6247e-02,  1.4317e-02, -9.8724e-04,\n                      -1.5569e-02,  1.5917e-02, -1.1595e-02,  6.6037e-03,  1.4463e-02,\n                      -5.3876e-04, -1.8056e-03,  4.6114e-03, -1.8690e-02, -1.2095e-03,\n                      -1.7851e-02, -6.0589e-03,  1.1632e-02, -1.1150e-02,  1.4940e-02,\n                      -1.7556e-02], dtype=torch.float64)),\n             ('6.19.convpath.0.2.1.bias',\n              tensor([ 5.5795e-03,  6.8452e-03,  1.3027e-02,  1.3996e-02, -1.5968e-03,\n                       7.1464e-03,  4.0992e-03,  3.7857e-03,  7.6059e-03,  3.2851e-03,\n                       1.4242e-02, -6.4224e-03,  4.2620e-03,  9.4007e-04,  5.9677e-04,\n                       5.3216e-03,  2.5768e-02,  1.3462e-03,  1.0280e-02, -3.3940e-03,\n                      -7.9514e-03,  1.3612e-03,  7.9924e-03,  4.8551e-03,  1.5408e-02,\n                      -1.4372e-02,  5.6363e-03,  7.3427e-03,  1.0387e-02, -6.6261e-03,\n                      -4.4624e-03,  1.8424e-02,  5.1608e-03,  1.4987e-02,  1.2605e-02,\n                       1.4338e-02,  1.1324e-02,  6.6319e-03,  1.5994e-02,  4.6495e-04,\n                       8.7336e-03,  9.9964e-03, -2.4465e-03, -6.0165e-03,  8.5780e-03,\n                      -1.6520e-02,  1.3089e-02,  3.9584e-03, -1.1820e-02,  3.2972e-03,\n                       9.8129e-03,  2.5974e-03,  7.5514e-03,  2.0750e-02,  4.0634e-04,\n                       1.4957e-02,  1.0559e-02,  5.1121e-03,  5.1806e-03, -2.9122e-03,\n                       8.0817e-04,  3.6802e-04,  1.4792e-02,  5.3082e-03, -1.1777e-02,\n                       4.5985e-04, -7.8810e-05,  1.0087e-02,  1.7604e-02, -1.3171e-02,\n                       8.0979e-03, -1.7241e-03, -9.4438e-04, -8.3990e-03,  1.1979e-02,\n                       7.6170e-03,  4.7734e-03,  1.8051e-02,  3.0206e-04,  9.0756e-03,\n                       3.3894e-03, -1.0864e-02,  1.8498e-02,  4.3812e-03, -7.3263e-03,\n                       2.1294e-02,  2.2070e-04,  1.0547e-02,  1.2104e-02, -3.1122e-03,\n                       3.0811e-03,  1.2447e-02,  8.4645e-03, -2.9774e-03,  3.8647e-03,\n                      -7.0275e-03,  1.1523e-02,  2.6896e-03,  1.9267e-02,  6.4599e-03,\n                       2.4632e-02,  1.3974e-02,  5.1281e-03,  1.0933e-02,  4.2280e-03,\n                      -5.4675e-03,  4.7855e-03,  1.1219e-02,  4.1039e-03,  4.6562e-03,\n                      -9.1134e-04, -5.5956e-03,  5.5832e-03,  2.0898e-02,  1.5679e-02,\n                      -1.3077e-03,  4.2575e-03,  7.3684e-04, -1.3083e-03, -4.2507e-03,\n                       5.5670e-05,  1.2555e-02,  6.3002e-03,  6.6684e-04,  1.6028e-02,\n                       4.0528e-03,  9.2572e-03,  3.9450e-03,  5.5439e-03,  1.3665e-02,\n                       6.2590e-03,  3.5932e-03,  9.4597e-03,  3.6877e-04,  4.5255e-03,\n                      -1.4191e-02,  8.4326e-03,  4.0407e-03,  7.4254e-03,  1.1482e-02,\n                       2.6038e-02,  1.5751e-02,  5.9726e-03,  1.9073e-03, -5.9728e-03,\n                       6.4643e-03,  3.7168e-03,  4.2105e-03,  1.1550e-03, -5.6850e-05,\n                       1.0249e-02,  6.8243e-03,  2.3168e-03,  1.0297e-02,  1.3657e-02,\n                       2.2880e-03, -5.2862e-03,  4.4627e-03,  6.7281e-03,  9.7064e-04,\n                       6.5972e-03,  9.0131e-03, -1.4831e-03,  5.8038e-03,  1.0834e-02,\n                      -5.5050e-03, -1.0966e-02,  5.5163e-03,  1.1194e-02,  1.1666e-02,\n                       1.3355e-02,  2.3986e-03,  1.3743e-02,  1.4511e-02, -1.4481e-02,\n                       1.6554e-03, -3.8071e-03,  1.4000e-02, -3.6034e-03,  3.6123e-03,\n                       3.5138e-03,  1.3401e-02, -2.8651e-03, -7.4266e-03,  8.4105e-03,\n                       6.2168e-03,  1.0858e-02,  5.8692e-03,  1.3663e-02,  5.5727e-03,\n                       3.5659e-03,  8.1475e-03,  4.6109e-03,  8.9707e-03,  9.1123e-03,\n                       8.1295e-03,  1.1478e-02, -1.1042e-03,  3.3490e-03,  7.2678e-03,\n                      -3.5186e-03,  2.1046e-02,  1.7184e-02,  1.5737e-02,  1.5109e-02,\n                       7.4730e-03,  1.4879e-02, -8.9731e-03,  3.2758e-03,  6.5919e-03,\n                       2.8882e-03,  1.0140e-02, -4.5578e-03,  1.2943e-02,  8.4944e-03,\n                       3.3985e-03,  3.1783e-03,  1.8979e-02,  1.3290e-03, -1.2039e-03,\n                       1.8321e-02,  7.8887e-03,  1.0324e-03,  1.3165e-02,  1.1563e-02,\n                       5.0112e-03, -6.9181e-03, -5.3101e-03,  2.6231e-02,  1.8432e-02,\n                       9.1612e-04, -1.7465e-03,  1.3066e-02,  1.2667e-02, -5.3628e-03,\n                       3.7116e-03, -4.1852e-03,  8.9871e-03,  2.8716e-03,  1.5833e-02,\n                      -5.2716e-03,  9.9374e-04, -8.9385e-03,  1.2544e-02,  2.3159e-04,\n                       3.1393e-03,  5.2788e-03, -1.2344e-04, -2.6189e-02, -1.1535e-02,\n                       1.8015e-02,  1.7858e-02,  8.8621e-03,  1.8253e-02,  3.3046e-03,\n                       8.0231e-04], dtype=torch.float64)),\n             ('6.19.convpath.0.2.1.running_mean',\n              tensor([ 4.6563e-01, -3.4816e-01,  4.7304e-01,  6.3204e-01,  9.7278e-03,\n                      -2.3532e-01, -9.3138e-02, -1.7648e-01, -2.0710e-01, -3.3035e-01,\n                      -7.0218e-01, -6.9077e-02,  2.9301e-02,  1.1658e-01, -3.3423e-01,\n                      -3.4745e-02,  4.7870e-01, -3.3121e-02,  2.1530e-01, -3.3713e-01,\n                       4.3058e-01,  1.4090e-01, -1.0053e-01,  7.5492e-02,  8.6351e-02,\n                       6.1790e-01,  1.8424e-01,  1.1125e-01, -5.5139e-02,  2.7138e-01,\n                       1.8303e-01, -4.4575e-01, -3.4503e-01, -6.8247e-04,  5.2191e-02,\n                      -1.5672e-01,  6.8534e-02,  4.5404e-01,  4.7735e-01, -2.4491e-01,\n                       2.6441e-01,  8.4410e-02, -2.7534e-01, -7.4926e-02, -5.1675e-01,\n                      -8.8760e-03, -2.3826e-03,  2.6709e-01, -3.5656e-01, -1.3981e-02,\n                       4.9776e-02,  1.7527e-01,  3.6491e-02,  7.1266e-01,  6.4192e-01,\n                       8.7452e-02, -3.3114e-01,  3.7922e-02, -2.8434e-01,  5.2543e-01,\n                      -4.8034e-02,  5.7596e-01,  1.2587e-01, -1.7413e-01, -6.3395e-01,\n                       3.8107e-01,  4.6375e-01, -2.6954e-01,  1.4986e-01, -2.7817e-01,\n                       3.4784e-01,  8.9721e-01, -4.9930e-02, -1.0327e+00, -2.3148e-01,\n                       4.2404e-02, -6.7433e-01,  3.5453e-01, -3.8668e-01, -2.9126e-01,\n                       3.8084e-01, -4.3838e-01, -1.2300e-01,  4.8746e-01,  2.8548e-01,\n                      -5.3066e-02,  4.5110e-01,  3.8671e-01,  4.0836e-01, -2.3824e-01,\n                       6.9267e-02,  2.3549e-03, -3.8494e-01, -8.0819e-02, -1.4605e-01,\n                      -1.5555e-01, -4.2562e-01, -7.5378e-01, -1.5044e-01, -5.7594e-01,\n                      -1.0600e+00,  1.4572e-01,  5.6451e-01,  7.1868e-02, -6.1224e-01,\n                      -1.1158e-01,  1.3358e-01,  6.8077e-01,  4.1712e-01,  2.9568e-01,\n                       5.2029e-01, -1.1982e-01,  2.1936e-01,  3.8868e-02, -6.9053e-02,\n                      -1.8599e-01, -4.0702e-01, -4.7971e-01,  1.4578e-01, -7.2118e-01,\n                       1.3920e-01, -5.8302e-01, -1.5235e-01,  1.0100e-01, -3.3491e-01,\n                      -1.3602e-01, -1.1133e-01,  5.8465e-02,  1.2921e-01,  2.0191e-01,\n                      -5.6975e-04, -2.7403e-01, -4.2124e-01,  5.0644e-01, -2.2896e-01,\n                       6.4109e-01, -1.8716e-01,  4.4038e-02, -7.7396e-02, -8.6320e-02,\n                       2.7824e-01, -2.5178e-01,  4.1393e-01, -6.3122e-02,  2.6609e-02,\n                       5.0872e-01,  4.7795e-01, -4.7177e-02,  1.1216e-01,  4.0698e-01,\n                       2.7063e-01,  1.5148e-01,  2.0920e-02,  5.7333e-01, -7.2754e-01,\n                      -1.0667e-02, -2.8255e-01,  2.6180e-02,  5.8384e-01, -2.6073e-01,\n                      -5.6122e-01,  7.5266e-02, -2.9557e-01, -2.4874e-01, -6.1147e-01,\n                      -1.7894e-01,  1.2616e-02, -1.3509e-01,  2.9992e-03, -5.8052e-01,\n                       4.7149e-02,  4.8902e-01, -1.1700e-01, -2.7034e-01,  3.2961e-01,\n                      -3.5747e-01,  3.7908e-02,  2.7772e-02, -1.2957e-01,  6.6487e-02,\n                      -1.6610e-01, -9.8769e-02,  3.5037e-02,  2.2840e-01,  2.4427e-01,\n                      -1.0658e-01,  6.9748e-01,  7.1381e-02,  8.5652e-02,  5.8543e-01,\n                      -3.3029e-01,  1.7319e-01,  4.5155e-01,  1.8966e-01,  9.9249e-02,\n                       2.5932e-01, -5.4634e-01,  3.6261e-01,  2.4419e-01, -3.6525e-01,\n                      -2.3492e-01, -9.7841e-02,  2.2012e-01, -7.3702e-01, -5.4523e-01,\n                       5.9148e-02,  1.1227e-01, -1.5223e-02,  5.0568e-03,  2.6028e-01,\n                      -1.4641e-01,  4.4206e-01,  4.6827e-02, -4.7252e-01, -2.4931e-01,\n                      -1.7327e-01, -5.3082e-01, -5.1788e-01,  4.8424e-02,  1.1789e-01,\n                       1.2217e-01,  4.4098e-02, -3.1413e-01,  7.2869e-01, -9.1709e-01,\n                      -1.2146e-01, -1.4294e-01, -2.3664e-02, -2.5959e-01, -5.9141e-02,\n                      -1.9730e-01,  4.2915e-03,  4.2853e-01, -6.5367e-01, -6.0749e-01,\n                       2.5845e-01,  3.1770e-01,  1.7928e-01,  8.5676e-02, -4.1451e-01,\n                      -2.5173e-01,  4.2405e-01,  5.2295e-01, -4.0515e-01, -8.7854e-02,\n                       1.2757e-01, -1.4580e-01,  1.4460e-01,  5.1708e-02, -8.3048e-03,\n                      -6.2309e-01, -1.7422e-01, -5.0098e-01,  6.4917e-01, -4.7236e-01,\n                       3.5787e-02], dtype=torch.float64)),\n             ('6.19.convpath.0.2.1.running_var',\n              tensor([0.5134, 0.4325, 0.1983, 0.6342, 0.3373, 0.3455, 0.3954, 0.3193, 0.2742,\n                      0.4187, 0.3627, 0.3761, 0.1793, 0.4352, 0.1900, 0.5649, 0.5326, 0.3870,\n                      0.2241, 0.4234, 0.4342, 0.6256, 0.5527, 0.4402, 0.3814, 0.4537, 0.3875,\n                      0.1738, 0.4370, 0.2759, 0.2520, 0.6207, 0.1247, 0.2877, 0.2704, 0.5901,\n                      0.1621, 0.3926, 0.2081, 0.3508, 0.3355, 0.1718, 0.0503, 0.4076, 0.2696,\n                      0.3421, 0.3347, 0.3705, 0.3099, 0.3521, 0.2363, 0.2508, 0.3277, 0.4268,\n                      0.5970, 0.5193, 0.2602, 0.4151, 0.2855, 0.2324, 0.2513, 0.2916, 0.2816,\n                      0.1003, 0.4265, 0.3067, 0.3697, 0.2170, 0.2707, 0.2727, 0.3060, 0.2662,\n                      0.3292, 0.5290, 0.2870, 0.1694, 0.3984, 0.3518, 0.4821, 0.1801, 0.5990,\n                      0.2890, 0.3063, 0.5041, 0.3122, 0.4221, 0.3611, 0.3865, 0.2048, 0.1861,\n                      0.6148, 0.4104, 0.3192, 0.1180, 0.1598, 0.3434, 0.2847, 0.3921, 0.2627,\n                      0.2892, 0.5259, 0.2490, 0.2245, 0.2558, 0.2766, 0.2692, 0.4599, 0.3815,\n                      0.6175, 0.2056, 0.2523, 0.4830, 0.6354, 0.1646, 0.3105, 0.3987, 0.3158,\n                      0.4761, 0.2604, 0.7351, 0.0376, 0.3755, 0.5876, 0.2159, 0.2582, 0.3784,\n                      0.3223, 0.2443, 0.1142, 0.7720, 0.1374, 0.4067, 0.5944, 0.3025, 0.3142,\n                      0.3831, 0.3412, 0.1294, 0.5424, 0.3390, 0.3865, 0.3155, 0.3182, 0.1661,\n                      0.3778, 0.2916, 0.2514, 0.5505, 0.1573, 0.4250, 0.3575, 0.1896, 0.2617,\n                      0.5433, 0.4804, 0.1807, 0.4113, 0.3352, 0.3466, 0.3594, 0.5993, 0.1370,\n                      0.0650, 0.2164, 0.4894, 0.4464, 0.4413, 0.1607, 0.2144, 0.3155, 0.2865,\n                      0.3933, 0.4302, 0.2372, 0.3917, 0.4778, 0.2297, 0.2884, 0.1655, 0.3402,\n                      0.6513, 0.2633, 0.3002, 0.4044, 0.3371, 0.4165, 0.3335, 0.2477, 0.1975,\n                      0.3340, 0.1174, 0.1793, 0.1944, 0.2828, 0.2714, 0.3109, 0.4287, 0.1807,\n                      0.3260, 0.4032, 0.1769, 0.2604, 0.2938, 0.3250, 0.3376, 0.3443, 0.2208,\n                      0.1547, 0.2426, 0.4781, 0.1359, 0.2274, 0.1359, 0.8513, 0.2469, 0.1483,\n                      0.3002, 0.2571, 0.1664, 0.4263, 0.2461, 0.1977, 0.1077, 0.3126, 0.5675,\n                      0.2108, 0.1386, 0.4669, 0.5812, 0.4779, 0.2133, 0.1663, 0.4578, 0.2748,\n                      0.3831, 0.2817, 0.4702, 0.3001, 0.3737, 0.3382, 0.1635, 0.1979, 0.4303,\n                      0.2696, 0.2337, 0.1974, 0.1061, 0.4901, 0.2056, 0.2740, 0.7442, 0.3983,\n                      0.1774, 0.3929, 0.2224, 0.2557], dtype=torch.float64)),\n             ('6.19.convpath.0.2.1.num_batches_tracked', tensor(11419)),\n             ('6.20.convs.0.0.weight',\n              tensor([[[ 0.0476],\n                       [-0.1550],\n                       [-0.0317],\n                       ...,\n                       [ 0.0603],\n                       [-0.0032],\n                       [-0.0984]],\n              \n                      [[ 0.0939],\n                       [ 0.1092],\n                       [-0.0196],\n                       ...,\n                       [ 0.0424],\n                       [-0.1157],\n                       [-0.1963]],\n              \n                      [[ 0.0488],\n                       [-0.0706],\n                       [-0.0224],\n                       ...,\n                       [ 0.1880],\n                       [-0.0177],\n                       [-0.0785]],\n              \n                      ...,\n              \n                      [[-0.1139],\n                       [ 0.1142],\n                       [ 0.1631],\n                       ...,\n                       [ 0.0237],\n                       [ 0.2427],\n                       [-0.1150]],\n              \n                      [[-0.0670],\n                       [ 0.0406],\n                       [ 0.0810],\n                       ...,\n                       [-0.1754],\n                       [ 0.1236],\n                       [-0.0116]],\n              \n                      [[ 0.0310],\n                       [ 0.0100],\n                       [-0.0825],\n                       ...,\n                       [ 0.1177],\n                       [-0.1649],\n                       [-0.0401]]], dtype=torch.float64)),\n             ('6.20.convs.0.1.weight',\n              tensor([0.9570, 0.9978, 0.9605, 0.9748, 0.9624, 0.9680, 0.9777, 1.0064, 0.9957,\n                      0.9876, 0.9837, 0.9638, 0.9765, 0.9961, 0.9803, 0.9636, 0.9598, 0.9840,\n                      0.9679, 0.9654, 0.9605, 0.9555, 0.9283, 0.9562, 0.9723, 0.9920, 1.0031,\n                      0.9803, 0.9767, 0.9936, 0.9425, 0.9738, 0.9616, 0.9673, 0.9766, 0.9669,\n                      0.9680, 0.9921, 0.9731, 0.9785, 0.9768, 0.9868, 0.9708, 0.9637, 0.9941,\n                      0.9679, 0.9683, 0.9392, 0.9766, 1.0021, 0.9599, 0.9582, 0.9636, 0.9854,\n                      0.9425, 0.9609, 0.9563, 0.9970, 1.0296, 0.9722, 0.9843, 0.9647, 0.9802,\n                      0.9795], dtype=torch.float64)),\n             ('6.20.convs.0.1.bias',\n              tensor([-7.8793e-03,  1.6539e-02, -5.0831e-03,  1.4974e-02,  9.4530e-03,\n                      -1.2007e-02,  4.7464e-03,  3.7740e-02,  2.1361e-02,  7.6922e-03,\n                      -1.0669e-04, -1.5153e-03, -7.1853e-03,  4.2779e-03,  1.5775e-02,\n                      -1.6825e-02,  7.2471e-03,  2.2324e-02,  4.1969e-05, -6.6903e-03,\n                      -2.0347e-02, -5.1689e-03, -2.5578e-02,  5.5452e-03,  1.0847e-02,\n                       5.3774e-03,  4.6737e-03,  5.9176e-03, -1.0246e-02,  1.7053e-02,\n                      -1.7449e-02,  3.0628e-03,  8.3087e-03,  5.8184e-04,  9.3430e-03,\n                      -5.9269e-04, -1.1075e-02,  1.9195e-02, -1.5395e-03, -2.2225e-02,\n                       1.9571e-02,  3.0154e-03, -5.0114e-03, -1.2864e-02, -1.5554e-03,\n                       4.3612e-03,  6.6128e-03, -1.6994e-02,  4.2922e-03,  3.0310e-02,\n                       3.5876e-04,  7.4116e-03, -2.8969e-03,  1.1802e-02,  5.8864e-03,\n                       1.2041e-02,  4.1173e-03,  2.7668e-03,  2.5435e-02,  9.8150e-04,\n                       6.3370e-03,  1.2606e-02,  1.5518e-02,  4.0411e-03],\n                     dtype=torch.float64)),\n             ('6.20.convs.0.1.running_mean',\n              tensor([ 0.9154,  0.2985, -0.2129, -1.0236, -0.3104,  0.7648,  0.0363,  0.0602,\n                       0.1009, -0.7696, -0.9205, -0.4375,  0.2287, -0.5051, -0.9573, -0.1271,\n                      -0.9918, -0.1454, -0.3502,  0.6269,  0.8969, -1.5624, -0.2593, -0.8964,\n                      -0.3351, -0.0227, -0.9133, -0.7113, -0.3329, -0.0708,  0.4311,  0.9299,\n                       0.5119, -0.3825,  0.9115,  0.0998, -0.6060,  0.0886,  1.2144, -0.2897,\n                      -0.2851, -0.3652,  0.3223, -0.1026, -0.3235, -0.2754, -0.3874, -0.0245,\n                      -0.3118, -0.2191,  0.6866, -0.3534, -0.9942,  0.3365, -1.4729, -1.0423,\n                      -1.5268, -0.7534,  0.2379, -0.7365,  0.6082,  0.6973,  0.0664,  0.4735],\n                     dtype=torch.float64)),\n             ...])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(xresnet1d_model_weights_path, map_location=torch.device('cpu'))['model']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T11:02:28.714419Z",
     "start_time": "2024-05-04T11:02:27.831688Z"
    }
   },
   "id": "4739d1841f20cdb2",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 12, 1000])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg, label = valid_dataset[7]\n",
    "ecg.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:03:16.171119Z",
     "start_time": "2024-05-05T10:03:16.148787Z"
    }
   },
   "id": "613d40852992bbbe",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 0., 1., 0.])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T11:04:18.910536Z",
     "start_time": "2024-05-04T11:04:18.905398Z"
    }
   },
   "id": "b884df856a0194a0",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-5.3253, -4.9247, -5.4436,  5.2726, -5.4596]], dtype=torch.float64,\n       grad_fn=<MmBackward0>)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xresnet1d_model(ecg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T11:04:25.952444Z",
     "start_time": "2024-05-04T11:04:25.896342Z"
    }
   },
   "id": "8c5c50d67ffa1660",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[ 0.0900,  0.0730,  0.0500,  ...,  0.0750,  0.0730,  0.0900],\n          [-0.0350, -0.0520, -0.0780,  ..., -0.1060, -0.1050, -0.1040],\n          [-0.1250, -0.1250, -0.1270,  ..., -0.1810, -0.1790, -0.1940],\n          ...,\n          [-0.1500, -0.1500, -0.1500,  ..., -0.2750, -0.2820, -0.2770],\n          [ 0.1400,  0.1390,  0.1350,  ...,  0.1920,  0.2540,  0.3120],\n          [ 0.0100,  0.0090,  0.0050,  ..., -0.2940, -0.2970, -0.2930]]],\n        dtype=torch.float64),\n tensor([0., 0., 1., 0., 1.]))"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[107]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T10:52:04.837719Z",
     "start_time": "2024-05-04T10:52:04.818736Z"
    }
   },
   "id": "11cd0a4c25e804f",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:39<00:00, 54.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.8897126969416126, 0.9216867469879518, 0.8665430954587581, 0.8873957367933272, 0.9031510658016683]\n",
      "accuracy: 0.8936978683966637\n",
      "roc_score : 0.945232846766223\n",
      "class wise AUC : [0.9417918559062147, 0.9382669823171321, 0.932451379466305, 0.958210265166821, 0.9554437509746423]\n",
      "F1 score (Max): 0.8080090213529213\n",
      "class wise precision, recall, f1 score : (0.8080090213529213, 0.945232846766223, [0.8080090213529213, 0.8041618410750325, 0.8005559699915934, 0.7979259734294084, 0.791585762440762, 0.7877588781528645, 0.7830403633295228, 0.7758309809935896, 0.7668490152751574, 0.7584454037942777], [0.8434701188731478, 0.8495703189555446, 0.8566565809379728, 0.8647435897435898, 0.8716169023921774, 0.8788485495639794, 0.8908849881148291, 0.8964660667416573, 0.9036714975845411, 0.9055489964580874], [0.775409329626197, 0.7633611368551128, 0.7513515600864997, 0.7406935434043868, 0.7250154464009887, 0.7137781896818042, 0.6984862527031201, 0.6838121717639789, 0.6660101946246525, 0.6524559777571826], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0],\n        ...,\n        [0, 0, 0, 1, 0],\n        [1, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0]]),\n array([[-3.9445402 , -5.17392056, -3.26830999,  3.12357277, -5.25319514],\n        [-1.64896047, -4.99737425, -4.78981792,  3.16528685, -3.44972022],\n        [-2.92633657, -3.56020432, -4.75886424,  2.19726658, -3.45016258],\n        ...,\n        [-3.35843216, -2.15863849, -2.3312406 ,  1.33540295, -4.82410338],\n        [ 0.89151499, -4.07900148, -2.52005066, -0.22301925, -2.77432349],\n        [-2.88676383, -5.28226944,  0.1416349 , -2.12537415, -1.57720985]]))"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(xresnet1d_model, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T11:05:18.905446Z",
     "start_time": "2024-05-04T11:04:39.439766Z"
    }
   },
   "id": "42169fd9559e83a2",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c281602e5abcd0ef"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2146/2146 [01:00<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9012115563839702, 0.9221808014911463, 0.8802423112767941, 0.8970177073625349, 0.8918918918918919]\n",
      "accuracy: 0.8985088536812675\n",
      "roc_score : 0.9487086238429022\n",
      "class wise AUC : [0.9476852106773366, 0.9358697725430357, 0.9454268714542687, 0.9638844562842611, 0.9506768082556092]\n",
      "F1 score (Max): 0.8211694718834347\n",
      "class wise precision, recall, f1 score : (0.8211694718834347, 0.9487086238429022, [0.8211694718834347, 0.8180125045103792, 0.8157698383023614, 0.8081038861629387, 0.8047648564685581, 0.7985846057967387, 0.7900616418647007, 0.7844893277050097, 0.7772188207858182, 0.769764825544673], [0.8548122643056238, 0.8620804253904951, 0.870801687763713, 0.874593391542544, 0.8806047966631908, 0.8853283898305084, 0.8916938110749185, 0.8953734363502575, 0.9022435897435898, 0.910077519379845], [0.7900745573159367, 0.7782308170239204, 0.7672802112457284, 0.751009630319975, 0.7409521590556074, 0.7273221497359428, 0.7092264678471575, 0.6980428704566636, 0.6826265921093506, 0.6669384902143523], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[0, 0, 1, 0, 0],\n        [0, 0, 0, 1, 0],\n        [0, 0, 0, 0, 1],\n        ...,\n        [0, 0, 1, 0, 0],\n        [0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0]]),\n array([[-3.1677591 , -3.90180522, -1.81254499,  1.32187091, -4.69090351],\n        [-5.44434877, -6.47968096, -6.28095825,  5.6266861 , -5.46598626],\n        [-1.24765092, -1.26739126, -1.03284439, -4.13920664,  2.75576176],\n        ...,\n        [-4.77860175, -5.69768495, -1.22651957, -3.50874596,  1.9376714 ],\n        [-5.44661797, -6.4738648 , -4.4702851 ,  5.25229792, -6.22884795],\n        [-4.89926612, -5.28330157, -5.26760933,  4.08361618, -4.03348173]]))"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(xresnet1d_model, valid_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T11:16:16.585190Z",
     "start_time": "2024-05-04T11:15:15.688894Z"
    }
   },
   "id": "d70a49075504e06f",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e1e86e13f8ee02db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6aa045cef629e4f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNET1d_wang"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df9d78f530c6af91"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet1d(\n  (0): Conv1d(12, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n  (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): Sequential(\n    (0): BasicBlock1d(\n      (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (4): Sequential(\n    (0): BasicBlock1d(\n      (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv1d(128, 128, kernel_size=(1,), stride=(2,), bias=False)\n        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (5): Sequential(\n    (0): BasicBlock1d(\n      (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv1d(128, 128, kernel_size=(1,), stride=(2,), bias=False)\n        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (6): Sequential(\n    (0): AdaptiveConcatPool1d(\n      (ap): AdaptiveAvgPool1d(output_size=1)\n      (mp): AdaptiveMaxPool1d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=256, out_features=5, bias=False)\n  )\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.nn.resnet1d import resnet1d_wang\n",
    "import torch\n",
    "\n",
    "resnet1d_wang_model = resnet1d_wang(input_channels=12, num_classes=5)\n",
    "resnet1d_wang_weights = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\resnet1d_wang\\resnet1d_wang_fold1_16epoch_best_score.pth'\n",
    "# xresnet1d_model.load_state_dict(torch.load(xresnet1d_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "\n",
    "resnet1d_wang_model.load_state_dict(torch.load(resnet1d_wang_weights, map_location=torch.device('cpu'))['model'])\n",
    "resnet1d_wang_model.double()\n",
    "resnet1d_wang_model.eval()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:05:27.154646Z",
     "start_time": "2024-05-05T10:05:27.096772Z"
    }
   },
   "id": "ec815f0e4f18ea4a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-3.4778, -3.9272, -4.5273,  3.4386, -4.4794]], dtype=torch.float64,\n       grad_fn=<MmBackward0>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet1d_wang_model(ecg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:05:35.313314Z",
     "start_time": "2024-05-05T10:05:35.204815Z"
    }
   },
   "id": "e5652ef693016177",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:40<00:00, 52.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9119555143651529, 0.9272474513438369, 0.8897126969416126, 0.8934198331788693, 0.9040778498609824]\n",
      "accuracy: 0.9052826691380907\n",
      "roc_score : 0.9519354108684759\n",
      "class wise AUC : [0.9458144093785179, 0.9414536831255838, 0.9578312980551786, 0.961587959523282, 0.9529897042598171]\n",
      "F1 score (Max): 0.8293092983071139\n",
      "class wise precision, recall, f1 score : (0.8293092983071139, 0.9519354108684759, [0.8293092983071139, 0.824009395552638, 0.8203824261197298, 0.8157066766948554, 0.8115561542500916, 0.805619734018517, 0.7997239338129407, 0.790707686015716, 0.7808625554212011, 0.7714658458705445], [0.8625895182291666, 0.8708686264740076, 0.8767641129032258, 0.8845097029022841, 0.8942021369767035, 0.9047040834682496, 0.9086996336996337, 0.9137591446257738, 0.9166666666666667, 0.9258268964151316], [0.7985016991041086, 0.7819354340438677, 0.7708140253320975, 0.7568350324374421, 0.7428946555452579, 0.7260966944701884, 0.7140871177015755, 0.6968643805993203, 0.6801050355267222, 0.6612218103181958], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0],\n        ...,\n        [0, 0, 0, 1, 0],\n        [1, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0]]),\n array([[-2.66339326, -5.29602226, -2.89385369,  2.33851818, -4.72413427],\n        [-0.23080978, -4.66203341, -3.30822062,  0.85252593, -3.50124264],\n        [-1.55635372, -3.22963769, -3.15087489,  1.13181596, -3.40798393],\n        ...,\n        [-2.55091923, -1.6129529 , -1.08714386,  0.12585486, -4.37837511],\n        [ 3.88926931, -2.08258841, -2.98448787, -1.36419389, -3.06046174],\n        [-2.05338135, -4.74342537,  1.05190746, -1.97983718, -2.72900002]]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(resnet1d_wang_model, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:06:41.431864Z",
     "start_time": "2024-05-05T10:06:00.546513Z"
    }
   },
   "id": "26d5e2441f0b6d6c",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2146/2146 [00:40<00:00, 53.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9114631873252563, 0.9161230195712954, 0.8946877912395154, 0.8951537744641193, 0.8928238583410997]\n",
      "accuracy: 0.9020503261882572\n",
      "roc_score : 0.955242851223654\n",
      "class wise AUC : [0.9547748839087422, 0.9418562141369827, 0.9603593007702597, 0.9645016506873101, 0.9547222066149755]\n",
      "F1 score (Max): 0.8306149669907514\n",
      "class wise precision, recall, f1 score : (0.8306149669907514, 0.955242851223654, [0.8306149669907514, 0.8262283200747632, 0.8213426707617111, 0.8141857850536365, 0.8078183707730434, 0.8003694205160029, 0.7923585677203713, 0.7871001325562982, 0.7801469606959226, 0.7711295453543118], [0.8579295154185022, 0.8646401985111662, 0.8728313963281118, 0.8782216494845361, 0.8873375482964523, 0.8939475574712643, 0.9013266998341625, 0.9110481586402266, 0.9160393746381007, 0.9231763068972371], [0.8049860205032618, 0.7910841876359118, 0.7755902454178315, 0.7588536812674743, 0.7413793103448276, 0.7245262503883194, 0.7068965517241379, 0.6928393911152532, 0.6793647095371234, 0.6620844982913948], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[0, 0, 1, 0, 0],\n        [0, 0, 0, 1, 0],\n        [0, 0, 0, 0, 1],\n        ...,\n        [0, 0, 1, 0, 0],\n        [0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0]]),\n array([[-3.14832513, -3.26460991,  0.2536856 , -0.02308407, -3.61274702],\n        [-4.19766302, -5.41535718, -4.84862716,  4.5559457 , -4.57813923],\n        [-0.94796921, -2.48907457, -0.80158036, -2.77964796,  0.9146152 ],\n        ...,\n        [-4.12834013, -4.75765843, -0.12445068, -3.615529  ,  1.38919457],\n        [-4.86035748, -6.23637954, -4.32480366,  4.19391938, -4.51776387],\n        [-4.62028469, -5.38658484, -5.11096646,  4.1857975 , -4.0493642 ]]))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(resnet1d_wang_model, valid_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T10:07:21.619464Z",
     "start_time": "2024-05-05T10:06:41.432870Z"
    }
   },
   "id": "cadd95b1fb8fbebb",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d283b60ac339a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b03ef03e7d067cbb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inception1d"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96b0a7466fc1ecba"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Inception1d(\n  (layers): Sequential(\n    (0): InceptionBackbone(\n      (im): ModuleList(\n        (0): InceptionBlock1d(\n          (bottleneck): Conv1d(12, 32, kernel_size=(1,), stride=(1,), bias=False)\n          (convs): ModuleList(\n            (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n            (1): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n            (2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n          )\n          (conv_bottle): Sequential(\n            (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n            (1): Conv1d(12, 32, kernel_size=(1,), stride=(1,), bias=False)\n          )\n          (bn_relu): Sequential(\n            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (1): ReLU()\n          )\n        )\n        (1-5): 5 x InceptionBlock1d(\n          (bottleneck): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n          (convs): ModuleList(\n            (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n            (1): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n            (2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n          )\n          (conv_bottle): Sequential(\n            (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n            (1): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n          )\n          (bn_relu): Sequential(\n            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (1): ReLU()\n          )\n        )\n      )\n      (sk): ModuleList(\n        (0): Shortcut1d(\n          (act_fn): ReLU(inplace=True)\n          (conv): Conv1d(12, 128, kernel_size=(1,), stride=(1,), bias=False)\n          (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (1): Shortcut1d(\n          (act_fn): ReLU(inplace=True)\n          (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n          (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (1): Sequential(\n      (0): AdaptiveConcatPool1d(\n        (ap): AdaptiveAvgPool1d(output_size=1)\n        (mp): AdaptiveMaxPool1d(output_size=1)\n      )\n      (1): fastai.layers.Flatten(full=False)\n      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): Dropout(p=0.5, inplace=False)\n      (4): Linear(in_features=256, out_features=5, bias=False)\n    )\n  )\n)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.nn.inception1d import inception1d\n",
    "\n",
    "inception1d_model = inception1d(input_channels=12, num_classes=5)\n",
    "inception1d_model_weights_path = r'C:\\Users\\redmi\\PycharmProjects\\ecg-tool-api\\models\\pretrained\\inception1d\\inception1d_fold1_15epoch_best_score.pth'\n",
    "inception1d_model.load_state_dict(torch.load(inception1d_model_weights_path, map_location=torch.device('cpu'))['model'])\n",
    "inception1d_model.double()\n",
    "inception1d_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T15:47:39.763439Z",
     "start_time": "2024-05-04T15:47:39.628107Z"
    }
   },
   "id": "1f6a3280c064ddc9",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[ 0.0360,  0.0460,  0.0460,  ...,  0.0040, -0.1340, -0.3340],\n          [-0.1140, -0.1040, -0.1060,  ..., -0.0060, -0.1450, -0.3110],\n          [-0.1500, -0.1490, -0.1520,  ..., -0.0100, -0.0100,  0.0230],\n          ...,\n          [ 0.0210,  0.0230,  0.0170,  ..., -0.0880, -0.1230, -0.1090],\n          [-0.0250, -0.0230, -0.0320,  ..., -0.0420, -0.0890, -0.1210],\n          [ 0.0060,  0.0040, -0.0160,  ..., -0.1120, -0.1480, -0.1480]]],\n        dtype=torch.float64),\n tensor([0., 0., 0., 1., 0.]))"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T15:48:15.479207Z",
     "start_time": "2024-05-04T15:48:15.473927Z"
    }
   },
   "id": "2b3efc5fe7bab13b",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-4.4925, -4.6633, -4.5221,  3.2949, -3.5534]], dtype=torch.float64,\n       grad_fn=<MmBackward0>)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception1d_model(ecg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T15:48:19.575014Z",
     "start_time": "2024-05-04T15:48:19.392933Z"
    }
   },
   "id": "edf4f9246a21d763",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2158/2158 [00:48<00:00, 44.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.9138090824837812, 0.9207599629286376, 0.8887859128822985, 0.8980537534754403, 0.9045412418906394]\n",
      "accuracy: 0.9051899907321594\n",
      "roc_score : 0.9569492358010082\n",
      "class wise AUC : [0.954472118706572, 0.9485739362901409, 0.960292853912257, 0.9650091024822187, 0.9563981676138529]\n",
      "F1 score (Max): 0.8345535231120428\n",
      "class wise precision, recall, f1 score : (0.8345535231120428, 0.9569492358010082, [0.8345535231120428, 0.8306702106588043, 0.8268053498758148, 0.819813458866716, 0.813922657858165, 0.8100104919261963, 0.800939796888839, 0.7931867633953288, 0.7889815056776961, 0.7796063832331508], [0.8703432568732715, 0.8780366881507189, 0.8851963746223565, 0.8921845574387948, 0.8958658346333853, 0.902336860670194, 0.9079089924160346, 0.9142170456646331, 0.925715368580633, 0.9332355816226784], [0.8015909793018227, 0.788152610441767, 0.7756410256410257, 0.7583024405313561, 0.745713623725672, 0.7348239110287303, 0.7165199258572753, 0.7004556688291628, 0.6874420759962928, 0.6694084028421379], [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0],\n        ...,\n        [0, 0, 0, 1, 0],\n        [1, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0]]),\n array([[-2.22023794, -5.01295134, -2.70663503,  1.89465267, -4.14693349],\n        [ 0.3324141 , -4.08592618, -3.67161655,  1.15772968, -4.0388319 ],\n        [-1.54339273, -3.06256439, -4.20844905,  2.203993  , -2.77911508],\n        ...,\n        [-2.36203804, -1.22312216, -0.88608206, -0.72825251, -3.85984596],\n        [ 4.51332536, -3.03034121, -3.00525668, -1.98216501, -3.65007412],\n        [-2.02133119, -5.12259159,  0.94243378, -3.00276813, -2.10483386]]))"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(inception1d_model, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T15:49:49.266640Z",
     "start_time": "2024-05-04T15:49:00.379441Z"
    }
   },
   "id": "12da7cd388b0670c",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 1., 0., 1.])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e, l = test_dataset[107]\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T15:51:55.787331Z",
     "start_time": "2024-05-04T15:51:55.777921Z"
    }
   },
   "id": "d2d0b1d6812dee72",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.62190692e-03, 7.54639804e-04, 9.48442227e-01, 5.63857648e-04,\n        4.86173686e-02]])"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(inception1d_model(e), dim=1).detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T15:59:10.111226Z",
     "start_time": "2024-05-04T15:59:09.983949Z"
    }
   },
   "id": "e8e4c565a31a09ff",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x2712580cb90>]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAGdCAYAAADXIOPgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAACJL0lEQVR4nO2dd3hc1Zn/v3dmpNGoN8u2ZONucJUb2ICBhB56T0ghJCSwG0qym0DW7CaQZfdHaMkmIQmk0AlJqAmEDgmEZkDuNu7dkmX1NtLU+/tj7rlz7p2iGWmk+x7zfp6Hh2maeX3uued8z/u+5z2arus6GIZhGIZhiOFy2gCGYRiGYZhksEhhGIZhGIYkLFIYhmEYhiEJixSGYRiGYUjCIoVhGIZhGJKwSGEYhmEYhiQsUhiGYRiGIQmLFIZhGIZhSMIihWEYhmEYkuRcpAQCAdx8881YsmQJli9fjgceeCDlZ//xj3/g/PPPx8KFC3HuuefijTfeyLU5DMMwDMMoiifXX3jnnXdiw4YNePjhh9HY2Ijvf//7qK2txZlnnmn53ObNm3HdddfhpptuwkknnYR33nkH3/72t/HUU0/hqKOOyvj32tp6kOvC/poGVFWVjMh3M3G4nUcHbufRg9t6dOB2Hh1Gqp3F92ZCTkWK3+/Hk08+id/+9reYM2cO5syZg23btuHxxx9PECkvvPACli1bhiuuuAIAMGnSJLz55pt46aWXshIpuo4R66Qj+d1MHG7n0YHbefTgth4duJ1HByfbOaciZfPmzQiHw1i4cKH52uLFi3HfffchGo3C5YpHly688EKEQqGE7+jp6cmlSQzDMAzDKEpORUpLSwsqKiqQn59vvlZdXY1AIIDOzk5UVlaar0+bNs3yt9u2bcP777+PL3zhC1n9pqYNz+Z03zkS383E4XYeHbidRw9u69GB23l0GKl2zub7cipS+vv7LQIFgPk8GAym/Lv29nZcf/31WLRoEU455ZSsfjPTuNZQGMnvZuJwO48O3M6jB7f16MDtPDo42c45FSlerzdBjIjnBQUFSf+mtbUVX/va16DrOn7+859bQkKZwImz6sLtPDpwO48e3NajA7fz6HDYJc6OHTsWHR0dCIfD8HhiX93S0oKCggKUlpYmfL65udlMnH3kkUcs4aBM4cRZ9eF2Hh24nUcPbuvRgdt5dHCynXNaJ2XWrFnweDxYs2aN+VpDQwPmzZuX4CHx+/34xje+AZfLhcceewxjx47NpSkMwzAMwyhOTkWKz+fDBRdcgFtvvRXr1q3D66+/jgceeMD0lrS0tGBgYAAAcP/992Pv3r244447zPdaWlp4dw/DMAzDMABGoJjbihUrcOutt+KrX/0qiouLcf311+P0008HACxfvhy33347LrroIrzyyisYGBjApZdeavn7Cy+8ED/+8Y9zbRbDMAzDMIqh6braEb3W1pFJnK2uLhmR72bicDuPDtzOowe39ejA7Tw6jFQ7i+/NBD5gkGEYhmEYkrBIYRiGYRiGJCxSGIZhGIYhCYsUhsmQDn8QoUjUaTMYhjnMeWHjQWxs6nbaDBKwSGGYDDjUE8DZv1mJi37/ETr7Ew/GZBiGyQVvbW/Fj17eiiv/sMZpU0jAIoVhMmBXux+hiI6DPQG8ubXFaXMYhjlM+WB3h/l4IBRx0BIasEhhmAzoC4TNxxuauOAgwzAjw8GegPl4f+eAg5bQgEUKw2RAbyC+omGRwjDMSNHUHRcmezv7HbSEBixSGCYDeoNxT8qudj96BsJpPs0wDJM9uq7jYHfck7K33e+gNTRgkcIwGdAbsIqSTQfZm8IwTG7pHgijLxj32u7tYE8KixSGyQA53AMAGw7y9kCGYXJLmz9oec4ihUUKw2REnxHuqSzMAwCsb2RPyuHOu7vacfUf12APu9yZUcJe3mAf56SwSGGYTOg2clCOnVIJANjQ1A3Fz+ZkBuE7z2zA6gPd+N/XtjltCvMpodMfEykzxhQBANr9oU99/huLFIbJgJbemBt2+ZRKeD0udA2EsYddsZ8KdrWxJ4UZHYQnpa6sAFVF+QCAvR2f7v7HIoVhMqDZqF1QV16Ao2qKAQDrGzkv5XAlKnnJwlE+CoEZHTr7Y16TMl8eplQVAgB2tLJIYRgmDaFIFG19MU9KTbEXc8aXAAC2tvQ5aRYzgrT3xRMYewMRdPFRCMwo0GH0s3JfHqZXx0I+21s/3eMMixSGGYTmngB0AHluDRWFeajwxZJn7duSmcOHDpsoWbmnI8UnGSZ3dEoiZXKlDwCw/1OePMsihWEGYaeRkzC5shAuTUNhvhsA0E/0XI3ff7AHJ/38XfyhYb/TpihLV79VgK7nKsPMKCBESoUvDxWF+cZrn+7FEIsUhhmEHYa7dZrhfhUixR+kKVLue3cP/KEIfvXObqdNURb7VtCNTZx/xIw8XZInRXhsuwY+3aFGFikMMwjiLI0jymPu18I82iJFEAhzwudQESJFbAXdfKgXQW5PZoTp8AuR4kG5IVLsgvnTBosUhhkEUW22uMADQPKkEAz39AWtrmGeWIeGmBhmjytBuS8PoYiObS29DlvFHO6YOSmFeSj3xcab7oEwwtHRr8nUFwzjJ3/fgVV7nc3HYpHCMIMgEmSLDXHiy6ObkyLquQgO9QZSfJJJh9jNVeHLw1xjNxfFvJTYgXQDXFjwMMAfjGDAWFRU+PJRUpAHzXiv24GQz2Mf7ccfGg7gsQ/2jPpvy7BIGSJ/3XAQX3qkAa9uPuS0KcwIY3pSvDZPCsFwT6tNpHBZ7aFxoCsW4qsrK8CccTGRspHgoZI/fGkLzv3th3h+Y7PTpiQlEtVZQGXIwZ5YnyvxelCY74bHpaHU8N46EfJ5c1srAOCkmWNG/bdlWKQMkf95ZSu2tvThJ//Y6bQpzAjTa4RQir0xcUJZpLT0WT0n27mWy5AwRUp5ASYauUitxLxSXf0hvPxJbJH0IcEt0k3dAzj53vdw5xvbnTZFCQ52x/rXuFKv+VqZQ3kpUV03tz4vmFg+qr9th0XKEBFrg7a+YNrPMenpC4Rx8QMf4Yxfv0+2HkCfCPcIT4oR7hkIRxFxIFacDrsnZQeXdM+acFRHoyFSJpT7UFIQzw2gRKOR0A3ERRUl3tnZDn8ogqfWNqGFmMCjyEGjqvXYkrhIiSfPjm7fa+kNIhjR4daAWkOkOwWLlCEwYMtFYHfm0NnY2I097f1o94fw7s52p81JihnuyY9NViInBaCXl3LIEClioGskOHlRZ19HP8JRHb48F8aWeE2Xew+x4n0HOuPXdne731LKnwKyOZsOctLxYDQbonNcUpEyup6Ufca5ZONKC5DndlYmsEgZAvbkxD6Cbn9VaJfCE7va6a36w1Hd3MUjwj1ejwtuI6ONmkgRIYl540sBAAe7WaRky3apLo5L01DiJepJkQRobyBiFh2kgpzseaCLppeUEsKTMq60wHxN7PARpyOPFpuM/KuZNUWj+rvJYJEyBOw7Jlo55DNk5HDZboIiRYSgCjwuMz6saRp8Rl4KNYHaaUyk4nyhQz0BR7Yvqozoh1ONA96EJ6UvGCEV3mu0CdBV+7ocsiQ5sqjb38lieTDMnBSLJ0VUnc2NSNnf2W8elpqO9UbxQrHYcRIWKUNgT4d1VcAu9aHTLnmldhFbCQLxarNTjVW1oJDoNuQeY2KYXOmDx6UhotNL+KROfGdPLBYvPCkArZCPsLO2LLbyXr2/00FrEpE9Kdu5xsygiKKR1pyU3O3uae0L4sLff4TLH25Im6Kg6zrWGSe8z69lkaIke2wrfooeAEFU1/HipuaM1LMTyJ6Udn/IkXoA6RC7J2aOsbo9qe7w6THar7QgD5WFMc9Pxyi7ilWn0Tb5e9wu+PJiQ2UPoZCPsPNzs2oAAJ800xICXVJbbTzYwxWQ07DlUC+augNwuzRMNjx4QG5zUsQOsJ5AOK3Ybu4JoN0fgsel4aixxcP+3eHCImUI7GmPeVKEG3hvB91465OrG3HLS1tw7ZPrnDYlKfZVPiVvSlTX8e6uWDLvBfPHW97zES2N32Mk+ZZ6PeYBZW0sUrKiUaqRIjDzUgh5UoTAn23UcaGWMyPbE4zo2NXG2+FT8czaJgDAZ6dXmcIEyK1I2SaVI7DnVcqIfjWmOB8F0iYBp2CRMgREgaxjjigHQHsb8gtGkac9Hf0IReitZPYR9kq19QURMrbhHVljXVEUETwJOarr8eq4BR7Tk9JOuH9SIxSJ4pDhdayVREppQawte4h4+nRdNwXyeKOuRm8gTGqHj90rKhZ3VHhmbSOeW9fktBnoDYRNj+3F9bWW94RI6cqBSOmQvsNeqsBqT6xfFeV7Un5mNGGRkiXhqG7GgqmuYGRkF6vIr6CECJ0tmVgGANjVRmcgEyvqMcVeeFya5T2KnpS+QMSs31PqlUQKe1Iypqk7AB2xRGnRfgDI1UrpD0XNay1yGHTEj3CggGgrUbGX0gJk5Z4O3P76dvzva9tGfeeMnUc+2gd/KIIplYVYbIyDglzWSZFDlemOy+izFa90GhYpWdLUNYBIVIfX48J0I0+BysCVjHZ/XDFTC0u19wXNAWL51CoAwA5CLmGRbT9eqgApoHjIYHcg1pZejwv5HpcZ7unwsyclUxqNrbLjywqgSYnSpV5atVL8xkTi0mKhKK/HyJkhYp+u62ZOyhLD47xqP53dRx/sjlfo3dnu3JgzEIrgqTUxb86/Lp9s6XMAUGEIZX8oMuwFkewFbEpTmqA3yJ4UpdlrhHomlBegzHABU0v2FIQjUUvyGrVzXF7d0gIAOGpsMRZMiK0gNjf3kimO12rGZhNFiqg+SymRUoiqMcUxcSJWQtS2SVPmfWPymiYlLwL0PCliIinMd0PT4me8UOmP/lB8u7ZI7F1zoIvMqdxy/SAn8+A+3teJnkAYY0u8OGl6VcL7xV6P6U3ZN8xFpjwXpFuwCm+cCGk7DYuULBEdZWK5zxwYqAxcduzJVsPt5LlGFJ86YWolZlQXwePS0NkfIrMTSYRJKovyE96jGEoRFUgnGFtnxUqIRUpmDIQiZg7XOXPGWd4jJwKESDHCjsXEPD1iTMx3a5hSVQiXBkR1OonHjd1SEUkHRcqHezoBAMdOrrCUOJCZXBm7n5OFy3Rdx/aWPjTs68Smgz1pc5LkvpFOpIjxothLw5NCwwqFEBP9ERVxkTIQjiIUiTpePtiOfQLd20GrnotIBivz5SHf40J1UT4O9gTQ2he0VF10ChEmkXMTBJVi5wyhpNT9RqiirjzWdoVmwTkaEwN1Xt/agu6BMMaXerFscoXlPbGapVK40W9zyZeYIoWGIBULpJKCPLg0DUX5HvQEwugdCKM6iegfbWRPipOVej/a2wkAOGZSRcrPTKooxJoD3djTkWjnfe/twQMf7DWfn3HUGPzP2bOSfk+3zZOi63pCeAmI5bYB7ElRFhHumVjuQ7HXA3GJKXpT7PUxqIV7RJuJCaCCWF0P05OSRKRUGQNtO6F8jx2tsUFsUmUsVFFMtCquDKXdKE8b20AvnD8ebluitKg+u51I8nmfFO4BYNZxsZ8r5hTi9O0jKkRBvJidFDw9A6GIZQHnlEhp6wua/WmJLWFWZpLhSbHvjgpFovhjwwEA8THqlc0t2JakcF5rb8CyiaIvGEnpBRanvhdx4qyamOGeCh9cmmYOEpS2ogqEa3WWUZCnsz+Uk61suULYIjxSQqx0ELGx3fSkpA735LIGSWd/KOkAkynivI3ZxvUWq2xKO5Bk7npjO8749Qfmll8n+XBPBzY09cDj0nD+vHEJ74sk+V1tfhJb+f2h2L0dFym0xqGNZl+M7ewRoYNeAl49kbvl1mKJx219QUeqMn9seFFmjikyk9yTIRYd9nDP+qZu+EMRVPjy8NK/LMMpM6sBxMW2zCaj0N+06kLUGhsBUoV8+mwHqjoNi5QsCEWiZla0WCFQ3IoqENncNcVe8zwISoeQiUQukYAsPClObwkUiBOFq4sTBxDhSWnrC+Ys0ffzD32MLz6yClsOZS9U9nb0o7UvCLdLw0yjposZ7iGwerUT1XX8eU0jOvtDZh6IkzzesB8AcNH88UlFaW1pAYry3QhHdRL1PkSdCyGWC0yR4ryACkWieN1Iil9yRMxDQCnRXJx5NKWqCFMMD9lGB05pFufjLJ5YnvZzk4y5Zm9Hv+l5DEWiuOXFLQCAYyaVw6VpuLg+VnDypU2HzBDv9tY+3PP3HfjucxsBxLaDH1FRaHxf8rmgjz0p6nKgawBRPeZaFXFV0p4UY0AoKfCYK0Eq7mpAzkmh50kJhKNmvsn4JPkxYiILhKM524Ys3K/vGVVus+Hv21oBAIsmlJnCuYjw7h45iTscdXZi7R4ImQmMly6sTfoZTdMwvTp2D20lcA6NOLCvrlwslmJDOYVxaH/nALoGwijKd+PYyZUA4jkzFOq4NJunDXsxpTJ2Te2HNY4GYjEi+lUq6soK4HZpGAjHCw3++p3d5qnJx02JtfGSieWYVOGDPxTBS5tixeHueXM7/rjqgPldZ80eay6wxYL17R1t+Ncn15l5OlzMTWHEwDqh3GcmHIkJgeJEIJLoSrwes2PuJ5KX0hcMY8CIkQoPihApFLZ0ixvWl+dCWUHizVqY7zYnhva+4dsrn67rTpHln4oXNzXj1+/uBgCcfuQY83V5dw+Vbd0CeUdFU7ez4Z5/7mhHOKpjWnUhJlcWpvzcDCH0W5wX+mIVPsGoiivGIQo5KaJQWE2J18ztKS6gk9jbIeWaiVBz7yh7eN7f3Y41B2LXUOScpMLjdmGikQy/p6Mf21p68ejHcc/f6UfFtnhrmoaLDG/KHW9sx7/8ea35G19cXIf/PutILJ5YjonGXPCHhgPY3tqH7z63ER/v7cTP394FgIu5KY1IPBUTPgAUElrB2OkJiAx7j+n5oZKUKiamMl+eOZn6CLmsxbUeX1qQNAMeiHtTcpE8KwuzbDTKxoM9uOWlLYhEdZQVeHCGUZMCiGfnh6M6ucPd5JXrAYdPEX9jayw0cfKM6rSfm2GE0bY5LFI2NnWbNswycj4KTJHi/HUWq/2xUn2hIjMs7rwnRXhqy3358fo3o+zh+cv6g+bjqVXpPSlALDQFAFuae3HvP2NiIt+t4bufnWaphn3BvPFmaL9hXxfCUR11ZQX4zklT8blZYwHEK6UDwOUPN5iPRcpCH7FibjSsUAQRB5aP0vYRPQ0XiMd/S7we091KZTeKSNqaYBF8dEJnYmvg3PElKT9TWZiPA10DOdmGLIe4erPoS1c+vtp8/MevLjaFHgDLYwpudhnZe3LAQe9ebyCMD4zTYU+eOSbtZ2cQCfdsNsIE88aXmmHcAg+dxZI4vG6MlMtliigCYlmUFqgozDM9mKO566hnIIx3d8ZCuj84Y6YplNKxoK4Uf9/Wil8YAgUA7r5gDvI9Vj9DYb4bv7t8AdYeiFf3nV9balloza8txS1nzsSPXt5q+VsRdudibgoj1Hap1KkoTax2RGJqaYHHDKlQKT528/ObAMRj6gAtwbfSmLiWpqlfUFsWE6u7khRZ2nqoF+/tas84zCJ7uLqHmJNTbauM63ZpZv+kljwr16k41Bt0LEzx2pYWhCI6JlX4EqrM2pk+pggaYveQk/VxRD7K7HHxQy8peSHlcI+ggJDHWdRwqfDlmQJhNBN639/djoFwFFMqC3HunLEZ/c3yqVUWj8myyRVmvo+dsSVenH5UjflfsppT58wZh8/b8q9KC/IQlQ6u5GJuCiIUZol08QoJTax2ROGpqqJ8lBfQqUGyu92PiDF3n7+gznydiuBr7glgR6sfGoBjjkgtUuaOL8Urm1uwvrHH8no4EsW1T61HZ38I//7Zabh8UV2Kb4gjVwfuynDAlL0jN5w4JelnCvPd8Ici6BkIo8hLZ03SZsvj2d85YHoFRpOHP9wHADh/3riUYT2BL8+NiRU+7O3ox/aWPnOH12izX6rVFLfNqJMSdn4cEuGeGsmTQklEiTGwvDDPHLdH05MSP6C2eNA+Jziiwoe/XbMUe9r7seVQL04/Kr3XLxO++9lp6OwP4ZXNsXBncb4b/aH4IaXsSVEQebeMgFp9AplWye0qXHn2UvlOILacHju5AmfPH2++7suPdcdcC76BUMSych+Mvxn21deVojxJITfBvNpSAMCGpm6Lx+QvGw6a7fzoR/sQjg7uTZGvS6Z9SZTBr/Dl4StHT0z6GTHQUAv3dPbH+qYYoj9p7kn94RHijte3mROGSDgcDJE8K3ZmtPuDWLO/C7tHaWu/rutmDZJp0q4QCuPQQCiCd3e2459GKEM+84pSsTmztEBRfvzgyBx4UrYe6sVv3ts96L9RlLFItmswHZWF+Vg4oQxfWFSXdJt8tmiahv86fab5PKrrlpwmr4eGPKBhhSIk86QUEStHLRgIRczVQU2x10yCCkd1R4tR/XX9QcvqVWYkPCn+YAQXP/ARzvvthxmfXbTaiOeKrPlUzBxTBK/Hha6BsFk7Y9PBHvz49e3mZ1p6g3h3Z9ugvyl7uDI9hK2lz0hQLPGm/Izon9TCPeLoebF98pPm0c/zeOmT2DbNonx3xkmCIlH1k+ZerD3QhfN++yG++ae1uPShj/G79/eMmK2CA10DaOkNIs+tWfKlKNRJ+f7zm/CdZzeYz+VwDwURJX5fLAhqSwukXUfDvz+ueGwVfvv+Xjzy0b60n2syT1d3/uiPgjw3vrg45ukNRXRzQeVxaRl7eUYaFilZ0JNEpJSZhww676GQEclrBR4XiqTtsoBzoanugRBuezWWrHVx/XizQqKgUFRIzeFA1rCvE4d6g9ARP9JgMPYaOSbTqtPnKOS5XWam/KoDXegeCOEXb+803z9/bkyEPZWkAqQd2ZOSqYhsk8J5qSgk6EkJR6LmvVRfF/NGNeZwh0+nP4R3drZZtnXb0XXdnDBvPzf5WSfJEHkgr29twU//sdOya+r+9/Zk7LEb6pZwUdtiSmWhKUwA5+ukvLurHe/t6rC8Ns6Sk0Jj95GoNluU70ZJgSennhQRwv5gd0fazzUZfX18WerFxWiSb5w5F4rqZs0ij4uGQAFYpGRFj5mIGg8BUD0JWZRQriuPbaH1uF3Ic8c6nhMDWSSq46on1gCIbZ274cSpCUrd3M6dw7oe8nUJZPDvHghFzJVOupoZgqOPKAcAfLSnAz9/axc+3hfzwvzfhXNx5dKJ0BAbtAarT2PxpEQy+7eLvI6qotQhKXF+D4VKn4JOwxYN8fDJoRyWJb/hmfX4t2c34oWNB1N+pq0viKgeK4t+9CAVP2UW1pWZolCEXR764gJzi/+1T61PK44A4J872nDyL9/Db9/L3vOyx7iv7X1TeCoy6eO55lfv7MJ3nol5UMaWeHH3+XPw43NnocwX75dOiyiBuA9rjfoyYsHpD0UyCsumQl4EpNvur+u6WYSNgicFiAuScCSKkDH2UDosl44lxFnx/CdmQmNNSXzlKgRLrkVKKBIdcv5IVNfx70YZZLmaYaGDLuF9nf3YbYREbj5tprnClxG7eyJ6+hs9G2Q3bibbH3e09kFHrLBchS/15C84xhApr29txV82xCbFs2bX4LgpFZhQ7jNP031mEG9Ke78sUga3M6rrpls5nSeliGBp/E7pzCax86A5h+f3iNDRy0Y4JxkiF6Wm2AtPFgOyx+3CD86Yic9Mr8JJ06pw9XGTMHtcCW48ZTqA2CFwZ//8n7jnzR14cOXepB6st3e0oTcQwW/e34PV+7sS3k/HDqNitL0AmFPhnnZ/EA+ujIc3/uPU6ThpehVOsW3n9nlobEHeYAhLcXREsZRfOJyCbiI/DIiFc1Itstr9IQTCUWhIH6YdTfIsnpR4uIcKLFIyYPX+LrxuFHwqzLPGr0cq3PP1P6zBab96f0iHr8k3zFFjE+PWuQinBMNR/OcLn+Av6wcPZQDxFeBRNcU4O8W2u8I8N/INb0+utkrLHoRMkvbEGR6ZZt7PGVdiSTDzelxYceoM828vro9t83t6bVPSQ8xEaKdJCndkkpPyp9WNZtGl2jQrMhFCoxTu6TKLaeWZIYHugXBOVtl9UrGwwjR5JqKYnFhRZ8PxUypx1/lzcPcFc/DNYydB0zScPKMa5xj9evPBHjyx6gB+9c5u3PbK1oS/l71maw5kLlKiuo73jVBCfZ311NxceyoyDTnK41NlYR6WT61K+jkqOSnrG2MVWOcb+TweaZv+cPJS2qT6Uz2BcErRLcKBY4rzyXgrhIc9HIkiYnhSPG4WKcoQikTx03/sMJ//4IyZlvdHypMiCja9k0HSpZ39XfHQwoXz48mppiclBzkpb+1ow6tbWvA/r27LaFIVsfR0JaA1TTNrfbTkyP0vDzyZrDL/vi0mRucbO3cGw+N2WcrY333+bEuuwAnTKjF7XAn8oUhCbsoHu9tx4s/fxc0vfGKpuprJBPGesYPiuCkVOHNW6gTfIorhHlGnojAPRfluiPEwFzYelIrEpatuKnJghiJSUvGFRXU4sqYYlyyegPPmxgTL2zvaEv5dLVKNlWyO09jZ5ke7PwRfnguLJthFStxTER1mqHRbSy8+e+975lEL6RC5bwBwk+FNSoaok+JkqYZIVMfGppgnZZ50f+ei6qy9tEOqqsTiXJyyDLy0o4XwJIYiOkJGTkoee1LU4a3tbfikuRf5bg1Pfm0JTj3S6saUc1KGOzgI5BW/POFliij2dOK0KovXx5fDwxDluPuGg92Dfv7VzWLyL0v7uTFG6EIe/IaDNdyT/t89EIqgwcgpESWkM+Hbn5kKIJYou8xWYMmlafiSkT3/3PqDCEsC5G3jzJjXjBNjBYPlpOi6bm7Zvea4yWn7CMVwj1mnwpcHTdPiCdM5mMDk79id5rTikRApR9YU4/ErFuHuS+vxwzOPxJSqQoSjOh4zTlgWyAI8m3/zBsMLMGdcScIqvMAT7wPDDZX+9v29CISjeOCDvYN+VgiuyZW+tMcKiHGyLzi83I/hsOlgD/yhCIry3ZZS9CVm8uzQvbf2St5CpIQiUdz/7m6sM65dwLj/qWzvBaSclKiOsOlJoWMfHUuIIsI8X1hUlzSRUtx8OnLnUpddh0PRPSI5bEK5dQDOpUtYnvwHO2AvEI6apy/bd/TYEbUVcpVIaQ33pB+8G7sHoCM2sY8vzTxefOG8cbjvsvn43snTkr7/2RnVqCzMQ1tf0OJN2WE7kVqEDgfzpLT7Q+gaCEODtVZGMiiGezrN069jq0nRL3MRhpTDPa19wZQeOeH5rExTB2e4XHPcJADA02sazYXHQChiqVabzb9Z5FPMGZ/o5SuQdu8N9/7OxtMvQpiLJ5anDY+WSJsNRvswP8HfNsXqH50wrco8+BCIJ54f6hn6wsgenhYi5YmGA/jdB3vNTQNCQOYTEgHCaxKKRE0B6WZPihr4gxG8Y7jVTzsyeYW/PLfLHGRzFfKRq3FmO7lEdR1/aIgdzV1XZg2t+MxDvnIgUqR/62A2ionC63ENOinUGcLKPoEPhYFQxBLzHyxpT9Q6kU+5zgRN07B4YnlKj0ae24WrjQnroQ/3oXsghO2tfVhlS5oUBdkGS5w1kz5LvIOuyMRJplREiq7ruN/Y1SJOvS4aIU8KAGxOUX9lNHYxfGZ6NcaVeNE1EMYbW1sBxIrAyY6ErDwpxsnH85KcJ+XSNLMvDHebr9yn+gY5EFAujJYOj0sz+2KnQ+UaRD7P6bax/IiK2OIz0xIFyRCLsKWTygHEQmZAfAeYQITGKXlS5MRZDvcoxjs72xAIRzGhvABH1hSn/JzIS8m0nPlgyCut3ixPDf3z6kbzsd2TIrw+HTmoOtslDTSDHYgnksjGlngHnfwXGgmB9gl8KLy5rdVyTQZLnH1mXczLIZ9ynSvOnj0W5b6YN+WUX75vOX30lX9dhme+fjQ+Z+SWDBbuSeUpSwa1irN7pYJ6U42zcsROr2zyM1Jh/45dKSrBCm9V3ggmCLpdGi40Kio/tbbRCNNZRVOm+WF9wTB2tsb+Lck8KUDuklPl/jfYrqvWJIcJpqJMjJMOVL1+fsNBNHYNwKUBC235POJ+35thsUc7h3oCWGkIoKuWxRYj+zr7MRCKJHjKAkbImZJIkbcgc7hHMf65I+ZFOXnGmLSTa2mOd/jIN3FvlpVsfymdkimf7QEAdUb8/UAOCmdl40kRlV5rMthyJ6po7u8cGPbKWpS3F2GUdJ4UXdfN7aDnzs08HyVTCvLc+O5npyW4UT8zvQqVhfmYWOEzXcCRqJ621oaogWO/vskwi7nlSEAf6gngsgc/xhOrDgzp78Uk7fW4zITfXOZK2ftMssMfAZhu7TzXyA6B580bB49Lw4amHryzsx2bxBZYoz5MpsJs08Ee6IgVSEvltchVOFdexAzmlRFeUvvhlslwqqaULm3X//KSCQkH5000RcrQjjZ4c1srdAD1taVYOCFWRyeqx7wo9v4YMEQAJZFi7u4hugWZDxhMga7r+NA4Cfe4KakPmQPik2BXf25uPjnfI5sV8Or9XeZEfHH9+ISVtgj/5EKkdGchUv66ISYWZqXxRgnKfHmoLMxDuz+E3e1+s6JrtnT2h9CwrxMAcN7ccXj04/1pPSldA2EzXrxoQvmQfnMwzpxVg1NnVpuVKVfv77R46ORj10ORKNyu5OGjT4xt0keNHbw9RSglV7t7fv72Tuxq9+Mnf9+R0cGJdkT47YJ54+AyhH+RGYYcvo1i5Vri9aAnEE7jSRmdwbi6KB9fWFSHxz7ej8cb9pv5W0uOKMfWlj74Q5n9m1cZCd1zU3hRgNi/uQmBYYuATim/YrAkXHGIaU0mnhSf8DiPridlU3Mvdrf3o8DjwteXHZHw/iRDpOzvHEBU181+mSmvG4nvYlPFkolleGVzCz7c05EgGEWxPUo5KfLuHlO88xZk+mxt7kWbPwSvx4V5aQYGQAr35MiNKYcosnGB/+ytWEn2z86oxn9ItToEQrTsbO0bdkVXObE1XbhH13VsNeKz584dl/JzMlOMMMDuFKvgTHh7RxsieqyiqThdN92qUNR7KPfljegqx+N2weuJ/bdsciUqpIPC8qWBQc5LsV8r0Z5yDZxUCO9Vc89ATgrk7e8cusAdCEXw1vbYlnr5mHnhSfHnoBCZuF/mGOJ2V5s/aV8X5b9Ho1bF5xfWwqUBDfu6TM+OEBuZhnvekbacp0Lk+Az3EFF5p0q68gLt/iDa/SFoAMaVDB56LHPIk/KSkTB70vSqpGc0jSstgMelIRCOZl2XqrkngLWN3dAAc3eTKOD4wMp9ltA9EL+vKXlSPFLirAiDUvKk0GkpYry7PZbotrCuzLLCTYZIBm3z52jbrHQTZ3rY3KGegJmkdcOJU5J+5qixJSjwuNDuD6Xcx58pTVI9inTbWzv64xUW6zLc7il2UaVaBWfC37fFrt/JM6rj54ak2YIs5804hdulmacCi7yAjU3dOO1X75tF8wZCEXMnwYQM2rPKqEWi68j4gMV02LdaZsMz65rQ2hdETXG+eZwAEM+byYknxZj0Z9YUw+3S4A9FkuZVmG7tUVgxjistsBQ587g0TDbqBWUizMKRKLYZiZlLpHazU+4bfm5cVNctIieQJolbhEenjymynAyfCidyUna1+fHUmlie3hkpDgz1uDRzAbcny3vk1c2xqsb1daXmgmDppLiQtO/6MXf3EBIpwmtirThLx76cWxIIBHDzzTdjyZIlWL58OR544IGUn920aRMuvfRS1NfX4+KLL8aGDRtSfna0ESLl6DSDgkB0zqFUh02GnNuSSYl0APitcQLr1KpCTEiRq+D1uMxB7n3bIVid/hD+tOpAgvJPhnySKGDdjWRHVFKtLs7P+MacUpnak7JyTwd+9tZO/Oa93SmT+noDYaw0QnWfnVGNggx2PYhdIJNGIGk2UzRNM9tIrGiufWo9ugbC+J9XtwGI76Yo8LjMGP9g3zk5TXtmSyb9IxkDoQj+aOSxXHXsJEtfMENSOThJXORI1BTnm/1oy6FEQT7aK8aL68ebjysL88wk10wWIf/z2jYzRymdiC7LgSelqz9k2X2UzvsmEk3TbSqQEf01VxsMMuGNrS2I6LEcIHHidjJEfle2ybPPG6Hss2fH89jGFHtx/QmJC8VwJGq2ZwEhkSIESYRoTkrOW+rOO+/Ehg0b8PDDD+OWW27Bvffei5dffjnhc36/H1dffTWWLFmCZ555BgsXLsQ111wDv3/4A+lw0XUdH+6OuVfTrVwEY02Xem5ESscQTsT9wMwuT4y5ygg3+3u72i2vf/vZDbj77ztwy0ubB/2tJttJrzvbUoePhnIs+eSq5J6UA139+O5zG/HYx/vx2/f34ltPrktaQO/dne0IRXRMqvBhalWhWUMinSdF5Eosmpi+2NxII6oC9wbCCEeiCeG+Q1nslBKIQ/y2HEq+HTcbMj380M5rW1rQ1B1ATXG+uYtJUO6LTV7DDVMAsV0VADChwodZRs7OhqbuhETk0T5IbdnkCnO1vmxyhZmTkM5Toes6vvXkOjMBHEDafAnRjsPxVNhX/unDPbHPVhYOno8CSDkpOcrdy4T1xrbtc+eOS1v7w9yGnIVIae0NYFe7HxqQcFbRFcdMTPh8QBIplDwpol0iUd0sNkkpJyWnibN+vx9PPvkkfvvb32LOnDmYM2cOtm3bhscffxxnnnmm5bMvvvgivF4vbrrpJmiahv/8z//E22+/jZdffhkXXXRRLs3KmuaeAHoGwnC7NHOAT4cQKQdzIFKaewJYeyBewTUQHnxSaOkN4GBPAC4NKc/OEIiY9trGbvQGwij2erC/s9/cdbByTydaegNmUbVkNHXF/p1Tqgqxr6MffcHYycHJqncKQZNNcTSxAt7f2Y9QJGpOJA98EKuEme/WEIzo2NvRj2ufXAevx5pguqsttnI+eWY1NE0zq3Gm86QIYZhpSGqkqCrKR0d/CO19Ifx59XbzdbFd92BPvEZKpsweV4Ln1h9MqNkQNZLDKwvzzQPX0pHJ2UfJCEWiZu2eC+aPN70IglzlUkR13cyZOaLch7m1pXh+YzMe+nAfHvpwHz4zvQq3nHkkir2eUdmCLOPSNPzfhXOxan8XPjerxkxwF6vXZCvXzYd68dHeTvP5f50+I+1vlPtiYmGo3i4gMZyXTkR1GJ9Ndwq3TNyTMjrhnqiuY4NRBn+wYy5E+G1nBvWZtrf04bfS4ZAza4qThru+tHgCHpeqDQfCUSknJftK4iOFuAVkT8phW8xt8+bNCIfDWLhwofna4sWLsXbtWkSj1s6+du1aLF682FwNapqGRYsWYc2aNbk0aUhsN/I1JlX4MlppiQlkf+eAeeMOlYZ9nZay0Zl4UsShWdOri5KeLiwzodyHieUFiER1sxbJQ9IppjEb0tcoEcJjYrnPFHHChsTPZu9JGVOcj6J8NyJ6fGW89kCXuUvongvm4OzZsdX4x/u68O6udst/jcZvigJ8cU9KrC0D4Sh2t/kt1Ujjk5azKxwx4O9s9+PFTfEVdI0hGkXBuWxquQh3/A5bHtKrm1tw/dMbcOUfVic9/NBOo82DlukxEP/Y3obtrX3Id2sJXhRAXmEPb/Jq7Q0iEI7CrcVE8fE29/4/treZOzFGawuyzKTKQlw4fzwK8tyWxMlU93irdDTEJfXjcf688Uk/JxAT7fZhFEK0n0GTzpPS5o+fwZQJubrOmbK3vR/dA2F4PS5zy3cqZhj3yLYWq1d4d7vf7Of+YASNXQP4/Qd78ea2VnNh84VFtUm/81vLJ+PJK5eY1zoQjpKsOOsyBElUp1kWP6eelJaWFlRUVCA/P+7+q66uRiAQQGdnJyorKy2fnT7deiBVVVUVtm3bltVvZrlbLCPExDqp0pfR91cW5WPGmCJsa+lDw74unHZU8uq0mSDOZJleXYTtrX0IRqKD2vBPI/N/fm1pRvYuOaIc+zoPYtW+TswbX2KWi55fW4p1jd14Zl0jPjc79aF1wmNUW+bFhPICfNLci1UHunBmkr85KJ02a7dNPE98XcOUqkJsaOrBjtY+TKsuMit2njS9CsdOqcTc8aU4dkplygG+rqzA9A7IRa40DfjRy1vM83L+ds1SjC3xmu7/fI9rRPpUpgivwk/+vsPyejga6wcisW9yZWHGdk6pjk1ebf4QugZC5m+IkF8oouOjfZ04a3b6+jD26q3BcNTcmZOOt3fErt1lC+vMmhQyYpLr6g8Nq+3FwZrjywqQ53FhXKkX3zlpKv7P2PUGxCZwTYNlq2Uur3eqPm1Hdvf3BsJ4cVMzTj1yjHltAOsOumtPmDLodx5phLf2dw6gLxhOqAeSCckSPVP9btyTkp9RG1ZL53INtc27+kN4dXMLTp5Zjerq9O28xdgFd2RNMfIGCa9Mry6EW4t5VFv7gqgp8eL5DQfxo5e34sL54/Cfp8/Evz27wVJk8urjJmHOuBIcN6UiqR3ePBemVBci3+0yvShmxdm83Pa74WCGe3SYFWfzjfsi0/6cLdl8X05FSn9/v0WgADCfB4PBjD5r/9xgVFUNrY5GOvqMeW9idTGqqzP7/hOPrMG2ll1Yd6gXly+fanlP1/WM8gfCkSjeMgrInXDkGGxv7UMUSGtDXyCMlz6JZZhftmxyRvaeOrcWz647iFe2tKK8tADhqI75E8pw35cXY/kdb2L1/m6E8jwYX5Z8td5mJL5NH1+GIyoL8YeGA1jb2J30t7uNnIop48tS2pbsGi6YVIENTT3Y2j6Ai8oK8aohKr583BRUV5egGsCUCenr15gUxPpZIBxFZWWx5UC/1pCOOdUlEFJnTGXm13wkKPTF7wmPS8MVx07GA+/uguZ2obq6BM3G6nrupMqs7Kwr9+FAZz86IsD06hIEw1F8KIUS1jf34YoT03/fJ627LM+LygpROUg59FAkivd2xfKlzl8yManNUwyHbkd/GOUVRUNexXXsjP3OtJoS83e+87lZ+M7nZuHJj/fhxqfWYW9XANXVJaZIqakuQXVV4plcwyWTccnj0hCO6nh0dSOe+HAfXtrcgr9ct9x8v9sI9V5x7KSM+no1YouBxq4BHArqmFyXfT+2bzD3eD0p+1mrkTA/va4io744vzjmTe3oD6GgxDckEfXwq1vwize34/7392DND09P284H+mIhxrkTyzOyb1pNMbY296JpIIJZk4vxs7dj/f3ZdQdxZn2dRaDUlHjx3bNmZRS28eW70RMIw1dcAM34fEVpoaPjjEyblCKUb4yVxYVei30jMc9mSk5FitfrTRAZ4nlBQUFGn7V/bjDa2nqGdAhfOva1xhR4kRtobe0Z5NMx5tXE3Ilvb2mx/M2Gpm5897lNOHlGFW46ZXpasbKhqRtNXQMo8Xpw/BFlePDdWB2FdDZsOdSLSFRHmc+DqSV5Gdm7sKYQlYV5aO0N4JfGiv3CuWORHw7jqJpibGruxStrDuCcOclX1nuMFUqpW8O00nxoiIUStuxpQ5Vt0uo14s+h/kCCbZoW6/zJruFUIzfkofd242/rGtHWF8TYEi/mVfsyviYCuRbFMx/utrzXeKgHrZUFZpGlvp5+tLY65+o8f/YYNOxux4SyAly+uM5MVO0PhNHa2mO2Z3ggmHE7aBowvaYYBzr7sXpHK6YU5+GVzYcsuQvvbmsZ9PvWG8XxBI3NXYgOEsb7aG8HugfCqPDl4YhCT9LfKIhEUebzoKs/jBc+3ovl09LnVaXik/0x+8YWJd4HPkOGtvUMoLW1x/TA9XT70aoPf1eRIF2ftpPvdiEcjeCJD2Ph1rX7u/DA37fh3LljoWkadh+K/RtKPa6Mr/W06kI0dg3gw22HMLUk+8MTD9hCRZ3dA0l/uzcQNsM2BdFwxvaJ67xuR0tGeVB2PjB2XXb6QwhHoujq7EvZzuv3xkTrhOL8jOybVlmIrc29uOrhj7F0UrmlqN01j8aOsRhbko87zpuNIyp86On0I5N/tTgHp7m1F/3G/dvvTxwPnaK7K7ZBIRyJoqc3JlPDwdg1zaY/Z4P43kzI6Wg8duxYdHR0IByOS7OWlhYUFBSgtLQ04bOtra2W11pbW1FTkzrMkAxdz/1/YvCuKszP+G8W1pXB7dJwoGsA+zr6zdd/9/5etPUF8eSaJmw82Jv2O9Y1xpO8ivLiJ+Km+xtRA6C2tCBjW/PcrliJdkMvLZpQhjNnjYWuA8cacfwXNjan/HuR8zGu1IvSgjyzWNqqfV0Jn5VjsMm+K9U1PE1yfbcY3oN/PX4y3JqW9fWUXesP2/JvugdC0PX4bg+3K/vvz+V/c8aV4umvH42fXTwPyyZXmq7YcESHrsPMvvdkaaeIue9s80PXgefXx0J8X1o8AW6XhsbuAPZ39qM/GMH2lj5Eorrl76NRHXtsZcP7g+n7pq4D/9gWK962fGolXCmuncflMgthrT7QnfD+vo5+bGjqwVNrGvH29jbLe5GojoPdAfNzQCxXKtlvxO4nHdGoHr/eQ+hPg/2X6biUbIfHf7+yFX/dELv35No9mf72zDFGbsWhvoT32vqC2HSwBy09gZR/LyrIykdJJPucSJ4vK/CgMM+TsX2TjF00nwwyFqb6Ty4El8o28Z/ILZxWXZjRd8sntK/c0wkAOGlalbkhwJfnwh3nzcGccaUo8eZlbLNcLG2o9+9I/ieWzeFoPCdFvlcz7c/Z/pcpORUps2bNgsfjsSS/NjQ0YN68eXDZEtTq6+uxevVqiCQlXdexatUq1NfX59KkISFiwYO5smUK892Yb5w7I2L9jV0DeHdnfKvvS1IiZDJE8un82lJz18FgVUKfXXcQQDwpLVNOP6oGb9+wHG9dfzzuu2y+eSOdPy9WFbZhb6eZTyIjHzU/3qgyucg4sGtdkuTZeF2A7LLZC/LceOKri83nJV4PTh9iro98Qux6I9u/1thtJGpziJU1pYQ2QDr8ywhPhIaY8DnDyFfY3tqHYDiK1caW6/PmjTWrszbs7cK3nlyHLzzcgG8/s8GSGNvWF0RvIAIN8QlssL7pD0bM0NqJg3hHZhiT63Zbcu/bO9pw4e8/wpWPr8aPX9+O7z630dyJFo5E8a0n1+Gc36zEP3e0mUnWyc40MieKaNSyHdnJrZb5KX77mbWxwn1iu3lNSebjkEji32nbvv/Ozjacff9KXPHYapz9m5V42QgR22k06hpNMnbYpUqcFbvMxmWREA/Eq7G+vaMtq78TyBsTAml2m/UGwmbu3PTqwXdoAsBJ06tx48nTzOenzqzG3RfMwbNXHY23rj8eb157nHmvZIMoGBiJ6ub9S6kOiVtKnI0Y9zylYTCnpvh8PlxwwQW49dZbsW7dOrz++ut44IEHcMUVVwCIeVUGBmKd+8wzz0R3dzf+93//F9u3b8f//u//or+/H5/73OdyaVLW9Ici2GGcNjoty1j1CcZALEp/P7uuCbJgfGptEzY39+ClT5rx4ibrf3/b2Iw3t8YG9Hm1JQlFvZIhD7bnpgjNpCPf40JhvtsSghpfWoCFdaXQAdzz9x0YCMUmGmHnox/FttSNKc5HmVGXQbhttyXZVSC2/Q6lDHR1UT7OMITJFUdPGNbOG3vxpIUTywHEV2ajvSU1U+IiJWafeeZMlnbOqY0JyU8O9uD/vbYVgXAUFb48TKksNGsBPdaw3xRxH+zuMGvHAHEBOrW60NxKmq7uDAA8vbYR7f4Qir1uLJ2cPqdihjGRiJL/QGzh8ou3d1o+pwN47ONYH3x7R5u5E+2BlXvNKsrJknNFnktYOp8EcHY3V6p7oqIwD7qum4X7sqmCPLUq1o672q27VB5vOGD+u6N6bDu/HV3XzXO9plXHxr5AimvcZ4j7TCrNygix+sGeDsuW9nAkin9sa8WLm5rx+w/24M43tqPPVoFYXiDFbBu8Gm6t4e3NlPPmjjN3LIpjPFyahsJ895BzpdyadICfeWYUHRUgau9EdZiF/LI9v2gkyfkBgytWrMCtt96Kr371qyguLsb111+P008/HQCwfPly3H777bjoootQXFyM+++/H7fccgv+/Oc/48gjj8RvfvMbFBbmPoktG3a3+xGJ6qgtK0ha9yMdJ02vxs/f3oWG/V3o8Afx1w0xL8cd583G4x/vx7rGbnzlsdVpv6Mo343Z40rMyT0Y0ZEq8Va+iT87ozrh/aFyxqwarD7QjX9sb8Opv3o/6WCwaEKZadM0Y4LZ0NiNPe1+cxUGxAc5sQ04W/77rKPwr8snozbLFZud0gKPWelyxpgi1Bnf1xsIx04dNm7O0dySmgkJnpQhbpU+clwJvB4X+oIR/G1TbBV92pGx072XTCzDAx8kFs97fUuredjiWkOkLJpQboqXwU7IFcXjLltYl1AbJcG+scVwa7HQ3sHuAYwrLUDDvi7sbu9HYZ4bf7tmKQ50DeDLj67C37e1orUviKcMjwMAsx7GlKpCTCxP7Ct5piclHuqRX3eCVAW9qgrz0ReMmPddVYbF0oDY1nSXFjs9vbUviDHFXkSiOjYZ7fObz9fjX59ch13tfqzZ34UFhhcUiHkZxRZuUaW4P8U1FrtAsm2/mWOKML7Ui6buAD7c22mKlj+vacRP/2EVpFVFebhq2STz+YamHsi1BAdCEeSn+HlRcfr4QepG2SnIc+OhLy5EY9eAWVRyuHik080pVnSVi7lFDftchOzLuUjx+Xy44447cMcddyS8t2XLFsvz+fPn49lnn821CcNiSmUhLltYi9Pn1UIz4nKZckSFD5Mrfdjd3o+b/roJ7f4QqovyceLUSgyEIpZwyLIkK8sCjwufX1iHonwPotG4AAlH9aQr/F5jNeP1uHK6Ijx79lj8eXUjdrb5zYFy9rgScwVd4HHhyqXxyrbTq4tQ7stDZ38Ilzz4MX5x8Vwsm1yJqK6biZ9DPVDLpWnm6c3DodyXh31Goa+zZo81B4nugbBlZT0aZ7lkg3xCKRAXK6lCBanIc7tw4ynT8PqWWB5Ycb4HX1saq4ppP0Dzi4vr8IeGA3hja0ssd8mlmeGDmWOKzG3yA4OEe0RNl0xOv/bluTF9TDG2HOrF+qYejCstwNNrY/lWn5tdg2KvB0fWFGPe+FKsb+rGrS9tNgudLZ9aaRZE+/KSCUkFfZ7pSYmaEyzgbNEqObQ4Z1yJWWyvzOcxV9xAdtVJ8z0uTCj3YW9HP3a2+TGm2IsdrX3whyIoyndjfm0pzpk9Fn/ZcBC//2AvfnHJPPNv/7w6thumvq4MJcbOG/spvoKhVuzVNA0nTqvCn1Y34p872nDitCpsbu4xPTtH1hSb4vafO9ptIsUaTg6Eo0Be8usnvFBThiA08j2unAkUQPKkRHTTI0ppnBGmWMI9dMzLvUhRnYI8N246ZTqqq0uGlH39menVeOjDfVhjVI29YN44eNwunDJzDG55aYv52n+ePjPt9+TZTsRNNhj0Ggf7FWVQqyIbCvLc+OUl8/C5+1cCiAmqX1w8L+XnvR4XLqofbw401z+9Ac9/8xhLzQenKyzKbumjJ5ZjozHRBqWTPwHni7nZSeVJGYrr+YJ543H+3MSCYAV5btSVFeBA1wC+sewIfH3ZEXhhYzPa/SGsOdCFxRPLsdc492dSZaEZOksVCgBiq1xx4u/kyswG/HnjS2IipbEbC+tK8XcjbCqfe/Mvx0/CtU+tNxMbl0+txE8vnDvod8eTF2WXu5bx0QIjgSzcrz1hMr715HoAsaRCIaRcWvau96lVhaZIWTqpwiwNP3tcCdwuDV9bNhF/3XAQH+zpwKGegFm9WIikK46ZaIZi5JDMox/tw56OfvznaTMkkZJ9+y2ZWI4/rW40f+8HL25Gl1Hh+/8unIOWviCueGx1wjEju20l6wdCESAv+RQmdh6VZRmOGgnMnBSdpiclXswtnkJAKdxDa0Q+DPjK0RPwjWVH4IuL63D1sZPMMxy8Hhd+cPpMzBxThK9JXohUyKunUIrS+L1GuGco9QYGo7rYi0sX1GLe+FJ8/5Tpg37+HFshsNe2tFjCAU4fTd4nHV43fUyRJddDXrWSzUmJRBGO6mbMONdhil9cPA/f/ew0XLXsCOS5Xfjs9Fj48PkNB9EfilgKHJqnSqcJ9zTs70IgHEVNcT4mVWbmCZtfF/PoPLHqAL7xx7WIRHXMry01k2qB2IGfY4rj4Q9ZwKRDXNdwNO5Jcbr0t+xJmVjuMz1b8mm0QxHNInl2h5EjJjwTIumzrsyHuUaSvyjbvqW51zxSYN74EvMa94ei+Pu2Vvz49W34+du78Jf1B7HpYE/cIzCENpxt2LGtpQ83PL0euw2P2y8vmYfqYq+Zg9PWF7QsIPbaDshMl5MiSu9nu6FgJJB36MkCmQqyIDnsy+IzQGlBHq45fjL+7TPT8M3jJlli8efNG4fHr1icUa6LS9PMjtIXCqOlN2AktvWbCXE9A7GJdyRECgDcdMp0PPDFBSlPVZaZWOGz5MUU5bvNxMo8t+Z4p2+REu7cLk2a/HXLpEVpBQFYPSnhEfT4TKzw4QuL6kwPjdjl9cbWVqxr7IaOWLJ0ZWG+KTjThXvEduB5taUZeytOmlaNGkOAHOgagAbgSttBbSJcIBAHZg6GHDYTzej0RFEk3bfVRflmPlRsq+rQJzORIyZEihABcujjIkPc/WnVAXT1h/D0ulho7ZSZ1SgtyIPPyCHb3tqHm/66CU9L+T86hndA45jifCw0cmHEaezza0ux2EhmL/flIc+tQQfwsFFDJhzVzQ0Nok3SnSUlDjEszyJpdqQQ9lo9KXSmXrmPCVFIaRx03hfGpMSX50JvIIK73tiBd3e145SZ1Xhjayu+vnQi/nX5FNOlWZzjcM9QOaqmGH/fFst5kBP/nPaiAMBnp1fj8Yb95jk28uRvDriEVg8CjzvRTmDkPT5zx5dgbIkXzT0BXPdULAwxe2xsBZxJuKfHSFIuzcLdXpjvxv2fr0fDvk7oOnDU2GIcNTZxy+e/HD8ZfcEIzp5dk7H4FddWB8xD3pwWKSXe+H3rcbvMax2S8maGYqPo458c7MHudj/2SKE6wTlzxuGRj/ZjV5sfV/5htblr5tw5MXEqFldyvpYgqg9vy76mafjZRXPxzx1t8AcjcGmaZfeXyzgUNBQJ4/739uD0o2rQMxCCPxRBaYEHR1T4sMFI8k2GruvmYZViB6KTyAsi01NByGObzJNCaSh0fvZgUlJoDBTvGnVXxPk1DxgFyd7YFtuynGzLpRNcuiB+0FbXQFgSKc6LqKuPm4QVp83Azy6K5S/IGffBIe6YGQ3Eiisc1S0JnyM9wWqahq8vjXsxPC4NFy+Irb4zCff0GPlSJd7sVrITyn04f954XDB/fFKBAsRW2reddRSWZehFAayJiqK+htPevS8sqgMQy6sB4hO+JW9mCH1yUmUhjp1cgYgO3PD0erT7Q3Bp8QMIBVcZYef9nQPoD0XhcWlYNDHm4Ui3GysQjsTr9QxxsvXluXH6UTW4YP54nDdvXMI267Olkgqbm3uw2QhZzZVCUak8Kf5QxJxsKYR7TJGi68MKk40UsimiLo7T94aM8zKTSUnBINs2hRtXrpToJCUFHvzL8ZNw37t70NkfIuVJKcx346L58fwFaxhleAPuSGK6iqO6OYDEDsUbeVsvqq/F0skVaO0Noq6sANXGScyZhHu6A9l7UkYSeWv5AJGBeMaYYjz/zWNQaWwxzjM9KcNPsDxr9li8v7vDzCU6sqYYRfnWa3HGrBo07O80C0LW15Wa4iS9SJErp47Mvf2t5ZPxx1Wx3UZbDvWZC4kplUXYbXiGZE/KYx/vx5iifJwxq8YM9eS7tYT6SE5APSdFvg9CnDjLZENhioFCJA4Kl2vJCOWkDIWygviJtkOtpTAaWMI9BFc3AtkmMbmOZi2XujIf6uvKTIECJA/3rNrfib+uP2g+7x0QnhTnvWiA1ZNiihQCA/G40gIzST6eNxMdtkixL1xmp6iU+sVFE1CY50a5Lw//ctxk83Wfra7RQ19aaD4OhKPD2t2TCb48N1acGkvYf33LIbOK96RKn9legVAEa/Z34Zf/3IWfvbUT//XiZgDWpFknd28JkuekOG+XwBLu4ZwUJhvkgcLrcWFsiRd7O/rNmHN8ZU1Ha4pVdlBO/iPsoQhH4wNuNvUoRgvL5BqKJyI7SbJwzzV/WgcgVpTtiAof3jLKnpcQSFwE4onokahOJtxjJ15wLjrsCsh5bheuPnYSfvP+HgDJjwoAgMlVhXj92mOhwRpakhdIpx85BnPGlWDJEeX4eG+nIVJGvkKzGOfEWWFArKaPqCbb6Q/hB3/ZaPkbXdel7cc0+l7ckyKJT0JjtiXcY55h5pAxSSBkCmPHJyXETq8uwldtOx3MyZVQjzITPSM0M9kFsp0hIomUyZDbTlT/dHqAi4d7YpO9fFqsPxjBB8aODSD3NXyGg7krhEi4x44lJyUH947sPRlfmrq0fp7bldCnPG4XLpo/HkdU+MxcMyFcBsJRKSdl5PritOois85JdVE+vr50IqaPKUKh0ade+yTxLLRwVDfDPRSSZoF4vwtGRi+nLBs0TTOLt/HuHiYr5EP5/uv0mea5JsJDESR43oxwocuuTWqTAWA9TyNCWUxJbecXnhSH27PGCP3sNbYZ75LqV+S7NcuOEHs1WyfJc2sIhOmKlDxpd08uwgJLJ5XDrQERHZg1hIPxVpw2w/Lca4b5oqMi7Avy3PjDFYvh0mAJN4qSC+sMj4pMMBKNh3uIeVLkHBpKIgWIFXSLRKyng1OBRQph5BM/J1f6sLMtVvcgrOuISiKAUphCTvSkGH8VmAfOReWTP+nZ6XZp0BDbOtsfpBHumTXO2OLa3Iv9nf249eX4cRdhKcF32eSKrA+gG0liuTwRM2xGrV96LLt7hr8A8bhd+Ms3l6LTH8L4YZ59BUgiJRQZVp2UbKhJcrhiupILwXCUoCfF8DyGCIsULTbKmJ4UOlMKixTKiLNmgNiAIx8EJdfMoBTucUtbZiOURYor0ZNCUaQAMbvCUd1ciTmdg1RbWmAeEnfh7z+yvBfRdQSMgc5LqF8C8RBfgFDirEx+jj0pQOwE5WxOUU5HMk+KE4I5nfANRnTTUzbYoZajRVJPCrV7w6UhAN7dw2TJdOPI8MrCmNtSPqiK6nkzVk8K5VyPeDKbKVII3Zgy5iAXoRGm0DQNN6U4KkHeKk3JwwfEw2QDVBNnk9RJcRO6t2WRYpbtd2DJXSxtpZ5ZU2TWPgJinhRq4048Fyq+G45QhB5AXJQIDx6lsZDOHcAkcPNpM3BJ/Xj87gsLAFgPqgpaRAqdDiXGVLn+CO3dPbLHx0mLUiMGjFCYzuC7fGqV5XmtkZgZ8/LRFCli9Uo1J8U8BFE6X8jp/COZgmSeFM/o2ycfA7JoQhmOm1JpHmYalBYdFO4TINGT4vTBlskQTSU89C4ibQewSCHN+NICfP/UGWZFWXkrW1Dq8JRcc3KFVCV290RpJ/gC8fgwlXLugmVGKfOL68eblT3lsBS1cI99sqB2vc08KaJFv/Kl8gLxoyQc8KRItXfEoYlyqCwUoTXuxM8aonX/yoh7IWh6Upy0xgqNq8hkhLxzhuL2YwCWvBnKk38yMUXRTiB+3YNEwj2C2z53FG4+bQb+/TPTrJVxiXpSTI8UsXYUiIlBToqnlLsgFkNRafxxYsKdWOGD1+NCXXn8UNN8SyhKbNWncX3j4phmmBGQwj0Ec1I4cVYhzHCP5bwZOp0JsJWbJ+Z2lUm2C4ni4AHEB4x4oSUadpYX5uFC46gBWZwKTwU1AS2aTbSjh9BADMSvc0SHlPNBx8ak+WYOjD+Vhfn4yzePwcRxZejv6Yeu2/J5iI07ZhiP2P0r43ZZBTyHe5ghIdf2oBr3t3hSiIUnZGSbgkR3ewjEgBEibKdbEqdm4iwxAW0fiKlNFtbde7S8AYBknx47CRlwbsVdXZSPIik3RYQWA5ZK1zTGRnsxNzpXNE7ciyee07GSxlVkMsJ6cu/o1CnIFnmgpZbAJiMP/tTCKHaEqZTtlEORVMM9Lo32itYthVOoeQMAydMTjdVpir3mpEVxTE+KVA2XStvJAh6gFUoR2D0nlKYVQqYwg+FJ5kkhtNICUoR7iNkIWFcKAUK7ZpLhVshdLId7KJx+LeOy5fZQa0aXJZxCK/kTsF7juEih0YheT/zaUvPgmp4U474g0mQW7NeRynUFWKQohTxIxHNSaF3CZImzlAZagewKprolVWCfXKkMvjLWvkkzqTu+zZJmOwpzqHpSxDWO6jqMlBQy94wYB4NSITwq+XoJ+R6EBIDAfh2pXFeARYpSyIlrVHf3yKcLU05IlcevQIi2SHHbVmIU7bTs7iFazM1F3CMVFwFAlOC9I+4Z+SgJKhOuefp6OEpucSQnRMeeO2hMCuw5KFSuK8AiRSnk2CbFlRZg2wFAsNaDQNM00y5zayChG1MmviuFbuJsXJzG7aQmoO0nvVISAIA154PiUQ3Jwz1OWhTHLfU/auEeYYW4ptQKuQGJ15FI0wFgkaIUlgJkRLcgW8M9tAYLO3GRQnPSElBP+ATkSSKeE0AtX8oeNqMm9uQ6KRQPvZTrpFDz9FBOOpbbLfbcSWuSw+EeJie4NVkA0HJpCuRtitQGCzvm5E9swLWTUA2SoJ1WcWp9jQrUwz3CvqiO+Nk9hEyUvaTx0AUNA5MmHRNpPNFEtD0pHO5hcoAl3EP0XBxZkJi7ZojZKBD6jmoipSDuSSEsUiwCmqad1CvOyhMDxXyuZOEeKt6oZNV6nSjZn4zEaq5OWpMc+2Wkcl0BFilKYREARCdWdxKRQqnDy7gVCKMAsieFrmcq7kGjmU8BJKk4S8w++T6h6DWTE0DFNSaiAyz5PNQK4dk9KZS8FAK7RVSuK8AiRSnkAUscN095oI17Umh2M414joIgIeGToJ3WUABREaBIxVmAZhVkqycl9hqVCVcWydTCzHFxZ4R7nDQmJRzuYXKAfNNRre1hqT9CVEgJ7HUzqLWlwEz4JHrNgeSVhqnZqdnbkdBADFjDABQ9KfI11oltQTa3b0dBblehfXcPlTaT4XAPkxOS53vQuoSW+iOEJ1VArj9Cc1IViKTAoALFoMJRKZ+CmJ3UtyDL9lAMQYr2i+hynRQHDZKQvRXUTpAWt4HpfaJhloWELchULixYpChFsnwPKqsFgaZpcbd6lN4OBZl4QhvNSUsQP7uH3sQl8CTxpFDrmwlFtYjaB9AMQVrCPcR2cCU9nJGIbZR3zggSclIImcgiRSHkrWviRqR0lLsgfjS5OKuCno1AYpE0KoOaHVNMmXY6aU1y5DopcZFCy1C7KKFlnXViCBP09lhCesTCPaKZaNZJsT6nYZUN23Wk1O+o3afMIIi+QzXcAyRu9STU3y0kFEkjMuDaUaJOSpIaPtTstHv0qF1uTdMSdiBRakO5YBq1wmTx/geCdVJU9KTQsZHeDMekxV4zg8pqQcZ+ai9VTwr13R4C+xZkinaqsQXZao9GcE1LuSquNdxD6xrLhx9S8+TZW4jQJTWx20TJRBpXkcmYBE8KkUFCRna9ys+pIcyiPPkD1hoQAK2JS2A5s4nYBCZIyEGhZR4A2sJZLiZJueIsNZGsoieFkoksUhRDs4UoKIoUzTapUrwpAWnXDPFdSHazKNqZbAsytb6pgEYhHe6xV04F6AhmeeeRbnvNaRJ2zhCxy0KCl5EOLFIUQwwKAWJVFWXETSgGMyLjWALUy6QLKB/+JbBUIyV4OB6QJNxDyzwAtI9AsIdxATrbae21hAA6bZfY72jYJZNgESEbiXQxJlNE3wmZ4R56lzDBk0JKl8exiymCeg9A4iBHzUMBxL1SOuGcFPuqn6KHz2P37hEy0S7qATptaE8ul19zGnsTETHLQkK4xxErkkNvhmPSYk+sy6M0ihmIm9AsA03PRACJ7muKKxxAEU+K8f+wVDLdQ6w9qdVFSUbCjjNCNtvrHwGERIqt3eTXnCYhzEjELpmExFlCJrJIUQwVansIi1TJSRHQtDJxNU1l8JWx5/cA9EKRSuSkEN5uLqodRCwixSFjbNjbDaDTdvZdZETMskBxp5uARYpi2GOvFEWKfTcKQRMB0K+bIbCLPCqDr4xZcl5OqiRmp13cUVzRinakuEMqmTimYp99V5T8mtMkeilo2GWBsIBnkaIYon/Hj5undwnNo8l18ZxSl49jt4vqasLu8aEy+MpoSfIVqHl8VPCcJQhSQm2YrN9R8ZLaj47QQMe2hLL4DtmRjsScFBptB9BsLyYNbptbnZpLHUi2BdlJa1Kjiicl0QPgkCFpcJsePsqeFOtziu1IWZAmFykOGJIE+64oSvlHiYmzdGwTJJhEyEQWKYoh+g7lnBQVEsWAJCtrmmYmyaWgZ6i568yy88MhY1JAtR/KUM4/Sjwoj06b2nOiKI2LKmx9t48plExkkaIY9h0pFFV5ssGMIqqEe+wrWIpW2reAelwamQlMoEJOCuX8I/vET2ns8ZieFHpVmROLudGxTcC7e5icYW7vJRxKSfAcUurxEgnuf2fMGJQEkULQUMpFyAT29C16FtIO91AWUOLaBs1wj4PGDALF+5dzUpicIZ9RAYBkj1fFk6KCGxagufKyI64x5eMaVLjedg8AbY+AM3YkI0Ekk2o3uh4oQYJXmZCJLFIUQ3RwkZ5I8QImJIoRUuUyiR4KmnaqUFY74fReSjOYAaWJKxUqFO4TUJpszUq9BIvgURZ3AoImmVCc45g0qBBKSRi86JkIgHYpaBkVmtNeTIukJ4VwToWA8mGSlE/ztXtSKPW/RC8FHdsEnJPC5AwVdqSocFYFoEauB0D7GHWBGEgolnMXqFBxlrInxW4JIdMSRDItAZX+OUU4J4UZMip0eBVisECSMIpDdgyGSp6UsDFJULRRhXozlPO57O1FSUDZz+6hZJsKuwg5J4XJGYkTK6HeZJBYJ8UZOwZDlXouCVYRtFNMEqLKMEVhmnh96dlI+d5J9KTQMc7tsj+nYxtlD5SAoEkmLFIUQ4UdCgmxa6K3gCqeFPtFpminCiE++0RG8t5JeE7ISMJeHsrHCagxZtueO2NGUlikKAbllZZABRsBNfJ7gMSblNLkIEiYFAg2phKilPCEZjeFkrciYes2IduUKIvvtAFpYJGiGCp4KSi7hWUSxzGadiY2Hz07lfCkEBYAAsrJvZQnW8oJx5TzjOLQ3YHEIkUxVPBSJG5VdMiQQVBj8EhyrgZBO1Uo3U/5OHoBRZsElHMr7BVmKYmURCcjHdsEHO5hcoYK8U1VElJVWFkDUGJyVaHgnAoJyInhHjo2Uq73kVip1yFDkqDCYighF4qQjSxSFEONw6ro35RAsrNcaBpKeQARUA5TCCivFgWUvRWA1T5KplE+Vyjx/qVjm4DyvcEiRTEodnA7qnhSlKmMm2AmPUNVqI1D+Th6QeLuHlrIl5XSJaZcw0WFfK2EMZrQxWWRohh2NybJyUAVT4oidiaIEoJ22ndKUbSRcuKnILGUCy0brZ4UOrZRTtZXQ8Cnf+4kLFIUI7F6IT3snYquJ8X6nKaVtF2xAhUqISdA0Eby3h6i97LdLkqeFBXGGcKOFBYpqqHC7h5VPBQqVO9NhgrXnGJbqiD2EpxmxIzUUj5xFvsYQ/mAQfakZEdORYqu67j77ruxbNkyHHPMMbjzzjsRjUZTfn7NmjX4whe+gIULF+KMM87Ak08+mUtzDkuUcB3aV9WkunwcZXJSBnlOARXEswpbualfa0tOinNmJGC3hVbFWetzQqbFIbxzy5PLL3vwwQfxwgsv4N5770U4HMaNN96IqqoqXHXVVQmfbWlpwTe/+U1cfvnl+PGPf4yNGzdixYoVGDNmDD7zmc/k0qzDCjW2INO3EUgsk05o8WVBhQPKVKjmmigA6FlJPUnakpNCyDR7OyXkSDkI5XwZAT2L4uTUk/LII4/ghhtuwJIlS7Bs2TJ873vfw+OPP570s6+//jqqq6vx7//+75g8eTLOPvtsXHDBBXj++edzadJhh4qFgSjelIAakz+QrL6HE1akx75ypXjNKcfdBdSTpOV7htT9QjgnivIJwwKCJpnkzJPS3NyMpqYmHH300eZrixcvxoEDB3Do0CHU1NRYPn/CCSdg1qxZCd/T29ubK5MOS1RYsSrjSVFg0gLUyKVQQQCogArXWkDpGicmp9IxTo3aVtJj58xISs5ESktLCwBYxEh1dTUA4ODBgwkiZcKECZgwYYL5vK2tDX/7299w/fXXZ/W7I3G9xXcS7EtJjiSnZ6f9pnS7tKQ2Ot3OycQUtbYEkuQhZXnNR6OdPW57Wya/5k6SrF5Frm0cblsnhAaI3d+a7bFTttnbmfK9bA89jUS/Gy4WD5mW2L4jdZ9kQlYiZWBgAM3NzUnf8/v9AID8/HzzNfE4GAwO+r3XX389qqur8fnPfz4bk1BVVZLV56l891Ap8OZZnpeXF6G6mpaddhurqopRXe5L+Xmn2rmwyGt5Xl5WSK4tAaC42Gpn2RDtHMl27ne5Lc/z8tzk2rK0tMf23DdiNg61rb1e65BcVVWCMl9eik+PPvKE6/E4f41FO7eFra8XFOQ5bpsgzx+yPC8q8pKxTeAriPcxTdMS7HNyLsxKpKxduxZXXHFF0vduvPFGADFB4vV6zccA4POlnqD6+vrwrW99C7t378Yf/vCHtJ9NRltbD3Q9qz8ZFE2LXZSR+O7hEgpa78buLj9avbR2kgdtNna098IbDid8zul27vcHLM97uvvR2tqT4tPO0ddntbO7Kzs7R6Odu7oHLM+j4Qi5tuztsdrY0zOQcxuH29ahUMTyvKO9FyFvTvc3DA/p3xSJRB27xvZ27uzss7wfDITI9L/egHXsG+gPkrFNEAhYhZSwb6TGDvG9mZBV71+6dCm2bNmS9L3m5mbcddddaGlpMcM4IgQ0ZsyYpH/T29uLb3zjG9i7dy8efvhhTJ48ORtzAAC6jhEbeEfyu4dKsnoU9Gy0Ph/MRqfaOVncmlpbpmIodo5kOye2Jb1+aUcDvbHD3orUxiC7m95p20T7UL6X7XZoGu17I9l94WQ/zNkSfOzYsaitrUVDQ4P5WkNDA2praxPyUQAgGo3iuuuuw/79+/Hoo49ixowZuTLlsCaxbLYjZqRFlbL4FNsuGSoUg0oWd6dGwq1DsB3tUDaRkmmUr21CTplDdqRDFnmEmg5AjuukXH755bj77rsxbtw4AMA999yDr3/96+b77e3t8Hq9KCoqwlNPPYWVK1fi17/+NUpLS02vS15eHsrLy3Np1mGFCtVcVTlgkPLAJqOALlWzYJVDZqSD+rZ4l0Z0MiO8K4p39wyPnIqUq666Cm1tbbjuuuvgdrtxySWX4MorrzTfv+SSS3DhhRfi+uuvxyuvvIJoNIprrrnG8h3HHHMMHn300VyadVhhX7FSG8QAhTwpNqjamSimHDEjLYm7K+gZqUI7UreRmj0Cyu2mWp0UavduTkWK2+3GihUrsGLFiqTvv/nmm+bj3//+97n86U8NiYf3OWJGWpTxpBBefckQbT4LShyiNshzClDvk1QnM8oiWQUvI6X2skMxPMakQYVibqp4UhKrexI1NOHMGXp2qhCGTMznomekKiFIgNbYQ1ncUQ/hAYn1byjBIkUxXAnnzVDrUomdiqKNAO2BTUYFO90qLBftYs8hK9JD20Z70S+qUDJNAW1M0iYBixTFUKHkvAo2JoPi6h9QxF1se05xYFFB7FE/XoDqiptyu1EdV1JBqe0AmmMJkwYVVTlZT0rCc1XspIfdk0Lxkitx7wzy3GmsbUbHumT1o6iQGO6hB9mDI8EiRTkSY/+0OhSgRt4MkCTeT9fQ9M8JQDlxUZBokgI2EmxHilC/tLKGJ3lvyI+JmcciRTEStyDTQxVPih2qVlJfXQOKhFISEpAdMiQLqJnIOSlDw+qpoAfla8kiRTFUyP5XYacHoIb7H1DDzoScFAWMpNgvqdfUoJuTQrvdKPa1VJBrO6cNYLJDjRWr7Tm1Xm+QGEVRxE5nzEgL9UkCUCMHibrXzFKZlJBxyc4LowTlcApgbS9qbcciRXEoKvTEcI8zdmQLVTMTwhRELaW6yhaoce6V/TktI6leY+reRmrX0Q5V8QmwSFGOxLg6sR4FNZIoATVW/wDoL68NrAMdPSNVaEaK7ZYSSrYST9a3elKoWUdXfAIsUpRDgY0eFpsoe1FUcP8DakyugNUuytddQPLeSfGYClQTQKmHmCkf4AfQvBcELFIUIyFBkWCXt56USs8+gQqCD1DHTrqGxUgMm9GDfu6C9JiQfdTPjrLkfFAzDgBAd8xmkaIYKsTV5QFDhRW1gKqpSuakEBvoACRcYIrtqNKKm5J91LeXU7PHDtXrCrBIURBrF6IoAuQJiuRW1BSQnFihjieFepgvwSSSNhLOYATde4TitUwFxTakeL8KWKQoRuJ2VHq9i3KHl1GhXDWgkEhJ8ZgKKmzlhkpCj1BHVCknhSJUw3gAixTloL7VDqCbXGdHhbYEFAr3EM9Foh4SANQSepTso34Uh7UOCUEo3gwGLFIUQ4WS83KnImieiToiJf1zilC0UQUvpErbuClZR93bSFXcCSjnk7FIUQwVJlbL7h6St2QMFSYtQI1kaYC2yzgZFG2k2gcFqpzdQw3q9wZV8QmwSFEP4m5NwL4adM6OwaHv/k8GVTPJewGIr7YB+ituGUqCSgUPcxx6tlEes1mkKAb1BDGAXidPhRKJlEiS4Eu0geVJi2bSpxq5PQKKl1lL+cRZVKiBI6B5XenmzLBIUQx7B6I+GVC8IVNBd/JP/5wK1L0AKrSj1e1Oz0Kq1zihmBsl46DAZgKSRsVgkaIYKqz+rQMZRQtjqDBpAWqEKexQFHwqtCP1nA91FiC0jFMqJ4WYgSxSFEOFAwZlKJunwqQFUBtuU0N1la0S5NuNqIHUDwulfm9Qto9FimokJIg5Y0Y6KGeKy6jiSUlIliZqqDUnhZ6RKuT2UE5gBOiGo5S5l4lC2UPGIkUx1EicpWdTUhSYtIBkAzBRO4mrUxUmMmvuAj0LqYoolXJSyBkH9qQwOYRyZxJQtctOouBzxIxBoT4AC2SzSHr4FGhH+rkLBI0CEhccDpmRCuL6nTQsUhSDslsuGVS9E4AaK+sYtAfgZFCczFS43tQXIVTtS7CF2LhDtd0EFpuItR2LFMWgXjALoH9DpoLixAqQGzNSQn1nihKuFIWgNP4kFHNzxoyUUPeQWauE04LatWSygFpnSgbFG1KgypylQh4SQN+lbbeJZEjK4imlZyDVyUyV0C1AczFEOWWGRYpiUI/7AzQH12SocCoukERMOWPGoMh20tzdY3vujBlpoe6FpOoRSNi5RbL1DAibBtAzj0WKYlhd6tS6UwzrQEbTRgAJdyPVgU0VMSWjhI0ErzdVESCgaJNAS/nEeahXnKU8r7BIUQzqLnWA/mpQoIyLOCEsRdNQygMdkCy50gkr0qNCzhlVKI871OyxQ9k+FimKQd2lrhLK5qQ4YsXgUBfQahxCxyvuoUI5cZtyzgdAW+CxSFEYip0doD1YyKhyKq4yYor4QJzokXLGjHRQb0PKQtRqGy3rKNtmh1q/Y5GiGCoIAMoDWTpUaM9kz6lAfSBObEfaNtKzjraIomwbiI/blCsds0hRDOoTAUBzcE2GCrs9AHU8PjIUd54lTA4q2EgMyiKKmj0ylG0DaCcds0hRDGtOinN2ZAq1uHU6yNqqwOQK0PfyqZCTQn9nHF2ZIrcXtXw90l4eULuSVlikKAzNQYx2EpaMKp6UhLN7nDFjUMhPsArkpFjCAg6akQrKky1d+UTfA055zGaRohjU99vHoL2iFqhSf0QZOwkPdIAaOSnygEzxOpMWAoQFlAxN0+iO2SxSFMO6WnXMjLRQn6wEikRRknh8aFpqdbc7aEgKVNglRf3eoSwEqN4XAFHPooS139GylUWKYpB3qYPm4JqMxERKNSynaqY1+Y6ekWrkpBBWAaDZZgJVCuFRNI3y4pdFimKokDirUe7xaVCiPQlj6ZvOmZGSRE1KsGGJe1Iod0bKXihq9tihOvYBNMcSJi30c1Iox63TQdVWZXJS5McUbVQgAZl6G1L25FpPkHbQkCSQ9/IQznVkkcLkHuJbUQUJJ6cSNVaFhE/AltRNsC1ViO5R9gYAtO2jeD0FGvHFJWXxySJFMVQ4u0cVTwpl22RUSPi0Q9FEaoNvMqzeAHr2Uq6FQ3miJZ5qRHrMZpGiGNTdwQDxwUJChfyeZFA1VbaLooBmT8rwoTyZWXaXOWhHMii3G0B71xa1a8kMAvVBTCWoDxwCykJPhvJAB6izlVtAsg0tT2gZSHkBR30zAeV7gUWKYlAeJATKCCnqs6qBErtSQD/ubodiM1qFMz0DKd/b1utJyzry9wbhxF4WKapBOAtbQDnLPhWUzbSHosiGpggPdEAyTwo9NMoqALQnW8r5MtSh3FwsUhSDcmcyUcJIew6FY2YMjn0XkkNmDAb19qTombBDPgRJ0qgYlNuOuPYkbR+LFMUgHtoEQN9lLVAmwTfhBZq2EjUrJSSTe4lHICmPP9TbTkDRNsrebxYpikFZ8Qo0yksaCWo3YypUCFMA1oGOugBI9pwaFAU+5TNeKA871H2hlOcVFimKQb2OAkA7bm1FDTsTE2cdMWNQqK9kE9rRESvSQz2vwnq2kHN2JEMj3AGpX1crtAxkkaIatPpPUgiPFRaUsZP8OkxRCF50irk8MpRX3Kp4UqjZBtAeC1mkKAb1zm6HmktYxproSddOexPS9aDFodieCccgOGRHppC3j5iBpAUUYREA0PZ+s0hRDOqdHVDDRoC2bTKKmGl1aTtoRypUCJupdP4RtQUIdZEsoNZuAO2EaBYpimFVvMR6kwFVu9JB7caUobxClKE80AFqJCBT95RSzq2gXGOGouCUIdx0LFJUQ5WdMyqgguADaG8PlKFc8RNIljhL20aK15qgSSaUJ1ritwbppGMWKQpDqyvFUUZH0b0vrRAefFNBsj0VcKWQbDcJyvZRF3gCiqZRHrNZpCgGYcFrYrWRqJGgfWPKWFdhdC1VLifFESsGg3ZOigw166z9j5Z11MdtyvaxSFEMVUIUAsoWUrsZU+EiPvkLqK9kVSjmRjlkAdj6IrEGpNz/qC+IKNokyKlI0XUdd999N5YtW4ZjjjkGd955J6LR6KB/19PTgxNOOAHPPPNMLs05LKF8IwooJ9fJWNuSrqEqXHOA/gRrt4niDhDrDhXHzEgJ5WtM8HJKEF9cEl4IeXL5ZQ8++CBeeOEF3HvvvQiHw7jxxhtRVVWFq666Ku3f3XXXXTh06FAuTTlsoX0jxlDARAB2rxRhCE8MMtTDUiQnBxsqJR9Tu8SUE8ypb3igfO/m1JPyyCOP4IYbbsCSJUuwbNkyfO9738Pjjz+e9m8+/vhjfPDBBxgzZkwuTWEcRJWcFBnKZqri8QF10adCuEd+TNA+olc2hkXM07KTuEYhbV/OREpzczOamppw9NFHm68tXrwYBw4cSOklCQaD+MEPfoAf/vCHyM/Pz5UphzXUkxMB2h3eAmnj4tAWJnEohwKAZImzBK0kfn9TXoDI4TFqoTJiTZUA5Xs3Z+GelpYWAEBNTY35WnV1NQDg4MGDltcF9913H2bPno3ly5cP+XdH4uKL76TYsVy2QYKijQnlx1PY6HQ7u2w3JsW2BIZv52i1s2Wgc9FrT5dtSebScm/jcNvaen/Ta0P7LhCn7EvWzvZwD6W2k21xEbw37HmE9vYdqfskE7ISKQMDA2hubk76nt/vBwCLR0Q8DgaDCZ/fvn07/vjHP+Kvf/1rNiYkUFVVMqy/d+q7h0ppU6/5OC/PhepqgjYe7DMf5+W5B7XRqXYu7wyYj11umm0JAH1afHZ1u7Qh2znS7Zyf5zYflxb7yLVnXn/I8ry6ugS+fHeKTw+PobZ1SXGH+Tg/z0OuDQu8eebjQl++4/bJ7ezxxO+T0lJa/S8vLz7VlpUVkrINAMoO+c3H+fmJ/c7JuTArkbJ27VpcccUVSd+78cYbAcQEidfrNR8DgM/ns3xW13X813/9F2644QbT2zJU2tp6oOvD+ooENC12UUbiu4dLT0+/+TgSjqK1tcdBa5JjtTGS0kan27m7O26nHtVJtiUAdHT2W55na+dotXM4HDEf9/YOkGvP3kDY8rytrQcFebkVKcNt696+AfNxOM294xTBYFzo9fcHHbMvWTtHI/GdpL09tPpfOBS/N7q7+knZBljH7HAo3u9GauwQ35sJWYmUpUuXYsuWLUnfa25uxl133YWWlhZMmDABQDwEZE+KbWxsxOrVq7FlyxbccccdAID+/n7ccsstePHFF/G73/0uY5t0HSM28I7kdw8dq5+Mnn0ALDZpg9pIoZ01zXkbMmWodo58O9Pum4n2DN43h/NbQ/lue54MtTakdo3ldraHmZ22LR2UbQMS7XNyjM5ZTsrYsWNRW1uLhoYGU6Q0NDSgtrY2IR9l7NixePXVVy2vfeUrX8FXvvIVnHfeebky6bBEhZ0elKsXpoKymZS3VsrQ35lihaKJ1NvQmhRPy0DKCfvUx0TKY0xO66RcfvnluPvuuzFu3DgAwD333IOvf/3r5vvt7e3wer0oKirCpEmTrIZ4PKiqqsLYsWNzadJhB+UbMQ7tHQqqkSo5kBou4nZyxdnhQ3my1QgrPMriDqA9xuRUpFx11VVoa2vDddddB7fbjUsuuQRXXnml+f4ll1yCCy+8ENdff30uf/ZTBeVBQqCCjQDt7ZQyhMdeK8QrDdsHX4ImWm0k2IhqLJII2qbU1nLn7EhGTkWK2+3GihUrsGLFiqTvv/nmmyn/Nt17jAztzg6oNJDRb0vAtj3QQTsGg7JtQDJPCj2LqXtSKAtRymdcUV9oEDTJhA8YVAzqZbMB2m5XGbqWWVHRToqX3W4SRRtlKJpH2RdF2TNKy5pEqIV4ZFikKAb1iQCg3eFlKLs4ZSgPvjKU49rJoGgh9T5JefwhbRsxexIg7MFjkaIY5Ds7QLrDp4KynRw+yw2JlZDpWWltQ3r2UQ6pUA6FW3fPULPOLvBo2cciRTGoTwQA7RWNjEZ92SognAdggXhzEjQpAfL3DkWbDOxHCpCC+MKNci4UixTVoHwjJkEBEwHQtpOybTLU7VTifiF+f1MWUZTDjZTbDbB7ehw0JAksUhRDBde/iomzhM1UMyeFoJ30LEoPtYkWoL3iVmBPAQCaphG8XU1YpCiGCgJABSEF0B5wZZRpT+qhSKL3i4z9NFpqkK7jQjhfRoVxW0BtgcEiRTFUmLDIT1YGlJPFZCiuqJOhUqiCKtRtpCzsKesA6mMi5evKIkUxKMcOTYhPViakjZNQxEwZiiarcLkpTxZ2qNnnItx21Pse5XmFRYpqEL4RBVTtssN25hZrTgA9q+lZlIg13EPPYsreChBvOwFF0yh76FmkKAb1iQCgnWUvo8qq1UX0OtuhXr6f8sQloDxZAPZrTMtCym1H2TbAPpXQspBFimKoMLFqKrh7bFCevyjbJkN9IFYB0p4K0N5BQ7ntKIs7gLaAZ5GiGNQTsAA1hBRgn1QpW6oG1BNnVYB6u1G+t12EhQBlcQfQFngsUhRDtYmAso2qeHwot2FqlDSaAGrkVZCE8NhIWdwBVvtcxAxkkaIw1FYLySBtI/GBQ0C6DSWo1/hQAfqTGd1rTMyclFBrN4B2OQYWKUzOUcXbQ9nFKUPZNhnOSRk+1Psk5RCpOuMOQeMIJ72zSFEMTYGZgORNmARldiE5bUCGqDJJUIa+JyX5YwqQzkmh1lg2KItjFimKoUTirNMGZAjlAkYqQnmVrQoa+6NyArWWI584axGftAxkkaIYlBWvgPpqUDWoDRqp4Qs/bAh7KgC7t4IWlMdG6mMiZWnMIkUxVAlRCEhPsIRNk1HETPIDsQrI7UZtlwVAO8GScrVeygIKsM4l1PodixSFodjZAXvhIrpQXj3IUL3OdqgPxCpAvd0oC1HKZ/dYtpYTtA6EF78sUhSD2gohGapMVpTjsDJ0LbNCeQJTBcqeihhq5HFRs436vUF5zGaRohgqrP6pdfJUqJCEDFgnK91BO7KB2mpMFaj3Scr3tirhHooXlvSuLacNYLJDhdU//dVgDMqrBxnKtslo1JeLKkB4sgBoX1bKCzjqt4ZVHNOykEWKYlC+EU0UyUmhbVwcRcxUo28Sh3ZeBe1Fktx21JI/yUNYHLNIUQ3CZamTQdlGZTw+hG2ToewyVgWN8mwB6kKUrjdAhuL9TPm6skhRDGodKBkq2GhHRZupYR3ouEWHAvWwAOVFEmWRTH3Ho1z/xkWs8VikKAZld6uA/EBrQLX9lIXwBKYiFJuQok0CyjlmlG0DaNvHIkUxiPWfpGhpnlGC8o2pIjyYDB/K3gCAdoiU8gKOmDmJEG47HlcUg/oWRcBmI1UjoY7HR4ayndQnWBWgvMsCoH3PUA6pUF8QcU4KkztUmAgID2SpUcdSqlCfYFWAfD0Nwosk2R5qeRXWHY/EbINN4BEzj0WKYlBWvALqqwYBr/xzjJLilBaUPRUAiBoVg/L9TH1MpJz0ziJFMTTqSy3QvAmTQXlVqCLUB2LVoNiGlK+xMuEex6xIDWWBxyJFMVTI97DaSNRIG4qYSbosviptSBmNeFjAGkahZR/lcA8xc9JCrRAeixTVoO4OBggbZoW8a10xVBSn1KDsqQBor7gptx1FwSlD2UPPIkUxKN+IyaBsovW+pGypGrDoGz4qtSE1+ygLKBmKAl4WUexJYYYFwf6dgGpCisk9fN2HBuU6JADte5t0qIy4+KQs8FikKIYKLnVVVoOUE+1UhG62gkIQ75OU7xlrTopjZiSFsrgDaN+7LFIUg3JnElA/JE1AfeBQDY3yckwRqPdJyiFSYuZYUGXhBtBb/LJIUQ0F5gEVhBSg1sChAqpcd8pQ8wDYoXzPWPMqaFlHfeFG2UPGIkUxlJgICA9kKSE4cKgGO1KGjwrhXAE1QSU3F2XbiJkGwNpe1AQeixTFoD5wAfRd1gIlBJ+icHsOEeKTGeXkVMqhKOoQ3oHMIkU1VLgRVRBSAMgnKaoG5QlMFagLfMr2yf2PnCdFfkzMNgAWo6i1HYsUxaDuNgTsHgqqViowcCgG5dWYKlDvh5RDeqp4RinaRnnMZpGiMLS6UhzClbMtWAUfYUMVQQUBTR2VTpKmlrsgQ82bKx9nQfG6UhafLFIUg3JnSgZlEynbpiLypKVC3yQJ8fub2uSfCtJWEjSOoEkmLFIUQ6WVFkBzoBWo0H4q4WLP1LCh7oSUbaLmSZG9FdRsk6FoGeUT4VmkKIYKoRQlwyiKmEkZjeM9w4a6p1SB4QcAzbYTkLSNok0GLFIUQ4VBwlrrwUFDBoOybQriZo0ybDTidzh1ESUgbRvF6yo/JtZ4LFIUhlhfMqFqlx1FzFQGjXNShg31HWfWa0zLQF2PB3yohXtoWZMIseaywCJFMVSoRUF7LRiH8o2pIpyTkgOkZqNWrwKw56Q4ZsagEDaN5LjDOSlMzqC+0lIJnkhzC+XzP1SBusCnnHZk2ebLg2NWUG4uFimKQXn1IqDsEpYhbJqSuCnPYIpA/SRpyrkLMnQtI3lZScMiRTFcLvqrVeqrQWZkYI0yfMjfO4p4yygv5ih6cClrYxYpiuGSOrie5nNOQrnDy1hso9qYCuFSxINGGepCTxVPCrWBxxqKcsyMlFBLNJZhkaIYLumK6TyxDgv5xtRZpQwbF/EJVgWoC3xVcuJoe1LoQdEmAYsUxZAn1ihRlaLKasviSKHZlAnohA3lsvjDh3pFafm6shBgRgMWKYphXf0TRZm4tQJtqRAsTIYP9YrS1EWUgNriKBiOmo/z3PSmXWrtJUOvtZi0yKsXqqtqFV3CNFtSLdiTMnyIaxSLUdSuMdHhEADgD0XMx26CLih6FsVhkaIYcgePEr0pqQ1eqbCsHiiPcIpgESmkhz01oHgfqbIAoUZfMDL4hxyE8rVkkaIYmgIhCsL93QJ7UnKLi/AqWxWoV5S25KQQtI8qfQHiIkV+TOzmZZGiGG4lwj20OnkqLIKPZlMqBe/uGT7UPRWWe5ugfVTxh8JOm5Aeip3NIKciRdd13H333Vi2bBmOOeYY3HnnnYhGoyk/39jYiG9+85uor6/HaaedhhdffDGX5hyWaBr9cI+KgxfVplQJaiswFaHehJR391AuI+CnHu5J8ZgCnlx+2YMPPogXXngB9957L8LhMG688UZUVVXhqquuSvhsOBzGNddcgwkTJuDZZ5/Fhx9+iJtuugnTp0/HzJkzc2nWYQtdT4qCEG1LlXBbEmeV7AWOQ3mysKOKx5QC5EUK4UuZU5HyyCOP4IYbbsCSJUsAAN/73vfws5/9LKlIeeutt9DU1IQnnngCxcXFmDp1Kt5++22sXr2aRUqGUJ1XKXf4VBBtygQoT/7Uq6UqAXGhR3kHF9XxEAD6Q8RFivyY2HXNmUhpbm5GU1MTjj76aPO1xYsX48CBAzh06BBqamosn//www9x7LHHori42HztV7/6Vda/OxINKr6T2sWyo4OmjdZdHqltpNTOVNsyGdnaOVrtLJ8r5XLRb0+KY4ccQnFp9NrQHu5xyr5k7Uy5Wu/dF8zBTX/ZhBWnzSBnG5AoiO3tm2ubs/m+nImUlpYWALCIkerqagDAwYMHE0TKvn37UFdXh7vvvht/+ctfUFFRgRtuuAGnnnpqVr9bVVUyTMud+e5ckJfvRnU1PRvz+kPmY58vf1AbKbSzx0OzLe24XNqQ7Rzpdi4r7Yr/VmUxqksLRvT3hstIXu8ht3VBwHxYXOwl1ydLS3vMxxUVRY7bJ7dzQUGe+dhpu+ycV12CsxZNhIdgITc7RUWJ/c7JMTorkTIwMIDm5uak7/n9fgBAfn6++Zp4HAwGk37+2WefxVlnnYX77rsPK1euxA033IA//elPmDdvXsY2tbX15NzNp2mxizIS351L+gfCaG3tGfyDo0xvIJ7J3t8fTGkjpXYOhSIk29JONKpnbedotXNfb3yCbe/ogysYSvNp5xmJ6z3ctu7wx8fKvr4AuT7Z29NvPu7q8qO1NS/Np0eOZO3cLy2OqLWbSvj98X43UmOH+N5MyEqkrF27FldccUXS92688UYAMUHi9XrNxwDg8/kSPu92u1FeXo5bb70VLpcLc+bMwccff4w///nPWYkUXR+5WORIfncu0HWdpH2yTToGb0MK7Uy1Le0Mx86RbmeLB5fANR2MkbRv6G1t3RZPrw2tdVyctk9uI932OjM0kvU7J/tiViJl6dKl2LJlS9L3mpubcdddd6GlpQUTJkwAEA8BjRkzJuHzNTU10DQNLulY3ylTpqT8fiYRqluQKcZcB4NoUyoF5aRKVaDebCrtPmIOD3IWIBs7dixqa2vR0NBgvtbQ0IDa2tqEfBQAqK+vx7Zt2xCJxLOed+zYgbq6ulyZdNhDdwuyesMX0aZUCi7mNnyoizvKdVKYw5OcZvFcfvnluPvuu7Fy5UqsXLkS99xzjyU81N7ejr6+PgDAOeecg2g0ih/96EfYs2cPHn/8cfzzn//EZZddlkuTDmuozqvUB9pkUG1LpSBe0l0FqLebxTpqNzrfxDmB2tb3nNZJueqqq9DW1obrrrsObrcbl1xyCa688krz/UsuuQQXXnghrr/+ehQXF+PBBx/ErbfeinPOOQe1tbX46U9/ijlz5uTSpMOaKNHlP60unhlUvVIqoaV8wmQKsfkhEclA9qQwo0FORYrb7caKFSuwYsWKpO+/+eablufTp0/HY489lksTPlXwvMpQgsM9hz+ck8KMNvQ3bTMpoSpSZHfhzDHFaT5JB6ptqRacODtcqLebVaTQMpby2T0qQeuq5tiTwowuVMM9+W4Np86sRm8wgjOOStzZRRGaLakW1rL41IY6NaDebpSrujKHJyxSFIbqxKppGm4/d7bTZmQF56QMH8rnf6gC/Xaj6y3jWzg3ELusHO5RGZ5Ycwe35PBxUZu1FIR6C1o9KdStZQ4HWKQoDNVibsynFA4FHPZw4uzhD7V7l0WKwrBGyR3slBo+lJMqVYG6d8JazI22rczhAYsUhYmyKyVn8M6A4eNiT8qwod5smqVgHy34Dj48YZGiMKxRcgd7UoaP7D2hNoEJqNoloC7uODn60wCtC8siRWl4Zs0V3JI5gNbYlhTqEytx8zhxlhl1WKQoDHtScgi35bCxrrJ5AhsK1NtNto5aWXy+hQ9PWKQoDNVibirCOSnDx0U4X0FA1S4BcY3CCdHMqMMihWHAOSm5QIlqpGQNi0HbOlgM5N09hyfULiuLFIXhcE/u4KbMLcTGOWVQKdxD3FTmMIFFisJwuIehhMYz2GGP9XwmYvB4eFjCIoVhwEcM5AIXb0E+7LFsM2chelhC7aqySFEY9qTkDm7J4aNCTgpVu1TBWnHWOTuYTw8sUhSGc1JyB+u93EJ1/qJql4pwWx6eUBPyLFJUhifWnMFNOXwsW5CpjXRMTqBczI3v4cMTFikKw+GeHMJtOWyIzVlJoTaxqoY1J8VBQ5LAt3BuIHZZWaSoDN+TuYPbcvhQG9yY3CMXPXTxFT8smV9b5rQJFjxOG8AMHfak5A5uyhxAbWnNjCx8uQ8rXvqXZWjtDWD6mCKnTbHAnhQFuWxBLQDguhOmOGzJ4QNrlOFTVZjntAmDctMp0wEAX1s60WFL1Ifa7p7Z40qcNkFpqovycdRYem3InhQF+d7J0/CNY49ARWG+06YcNnCdlOEzrrQA/++cWSj2up02JSXnzR2HE6ZW8r2TA6id43NJ/XgAwNFHlDtrCJNTWKQoiKZpPMgyJDntyDFOmzAofO8MHVnLU4vuedwufGFRndNmMDmGwz0MAw73MEy2UBMpzOEJixSGASfOMky28CnIzGjAIoVhwJ4UhskWlijMaMAihWHAibMMkwnWnBSWKczIwyKFYRiGyRqWKMxowCKFYcA5KQyTCZaKs6xSmFGARQrDgHNSGCZrONzDjAIsUhgGnJPCMJkg3ybsSWFGAxYpDMMwTNawRmFGAxYpDAMO9zBMJsj3Ce/uYUYDFikMA06cZRiGoQiLFIaBddcCwzAp4NuEGWVYpDAM2JPCMAxDERYpDMMwDMOQhEUKw4A9KQzDMBRhkcIwoJ+TcsXREwAA//aZaQ5bwnyaoX6fMIcfHqcNYBgKUD92/voTp+IrR09EuS/PaVMYhmFGDfakMJ9q/t85s1BZmIf/u3Cu06YMCgsUxmmKvbyuZUYX7nHMp5rTjhyDU2dWc2EqhsmAOeNK8KXFEzChvMBpU5hPCSxSmE89LFAYJjM0TcN3PjPVaTOYTxEc7mEYhmEYhiQsUhiGYRiGIQmLFIZhGIJMrS5y2gSGcRzOSWEYhiHEY19ehG2tvThucoXTpjCM47BIYRiGIcSRY4tx5Nhip81gGBJwuIdhGIZhGJKwSGEYhmEYhiQsUhiGYRiGIQmLFIZhGIZhSMIihWEYhmEYkrBIYRiGYRiGJCxSGIZhGIYhCYsUhmEYhmFIwiKFYRiGYRiSsEhhGIZhGIYkLFIYhmEYhiEJixSGYRiGYUjCIoVhGIZhGJIofwqypo3cd47EdzNxuJ1HB27n0YPbenTgdh4dRqqds/k+Tdd1Pbc/zzAMwzAMM3w43MMwDMMwDElYpDAMwzAMQxIWKQzDMAzDkIRFCsMwDMMwJGGRwjAMwzAMSVikMAzDMAxDEhYpDMMwDMOQhEUKwzAMwzAkYZHCMAzDMAxJWKQwDMMwDEMSFik2AoEAbr75ZixZsgTLly/HAw884LRJStLc3IwbbrgBxxxzDE444QTcfvvtCAQCAIB9+/bhyiuvxIIFC3DWWWfhnXfesfzte++9h3POOQf19fW44oorsG/fPif+Ccpx9dVX4z/+4z/M55s2bcKll16K+vp6XHzxxdiwYYPl8y+88AJOPfVU1NfX49prr0V7e/tom6wUwWAQP/rRj3D00UfjuOOOw09+8hOIU0W4rXNHU1MTrrnmGixatAgnn3wyHnroIfM9bufhEwwGcc4552DlypXma8Mdkx966CGccMIJWLhwIW6++Wb09/fnzmCdsfDf//3f+rnnnqtv2LBBf/XVV/WFCxfqL730ktNmKUU0GtUvu+wy/Rvf+Ia+detW/aOPPtJPO+00/cc//rEejUb1c889V//ud7+rb9++Xb/vvvv0+vp6/cCBA7qu6/qBAwf0BQsW6L///e/1rVu36t/+9rf1c845R49Gow7/q2jzwgsv6DNnztS///3v67qu6319ffrxxx+v//jHP9a3b9+u33bbbfpxxx2n9/X16bqu62vXrtXnz5+vP/vss/onn3yif/nLX9avvvpqJ/8J5PnBD36gn3766fratWv19957T1+6dKn+xBNPcFvnmMsuu0z/zne+o+/atUt/7bXX9Pr6ev3VV1/lds4BAwMD+rXXXqvPnDlT/+CDD3Rd14c9Jr/88sv64sWL9TfffFNfu3atftZZZ+k/+tGPcmYzixSJvr4+fd68eebF03Vd/+Uvf6l/+ctfdtAq9di+fbs+c+ZMvaWlxXzt+eef15cvX66/9957+oIFC8yBRdd1/atf/ar+85//XNd1Xf+///s/S3v7/X594cKFlmvCWOno6NBPPPFE/eKLLzZFypNPPqmffPLJ5kASjUb10047TX/66ad1Xdf1G2+80fysrut6Y2OjfuSRR+p79+4d/X+AAnR0dOizZ8/WV65cab52//336//xH//BbZ1DOjs79ZkzZ+pbtmwxX7vuuuv0H/3oR9zOw2Tbtm36eeedp5977rkWkTLcMfmLX/yi+Vld1/WPPvpInz9/vu73+3NiN4d7JDZv3oxwOIyFCxeary1evBhr165FNBp10DK1GDNmDH73u9+hurra8npvby/Wrl2L2bNno7Cw0Hx98eLFWLNmDQBg7dq1WLJkifmez+fDnDlzzPeZRO644w6cf/75mD59uvna2rVrsXjxYmjGmeiapmHRokUp23n8+PGora3F2rVrR9V2VWhoaEBxcTGOOeYY87Wrr74at99+O7d1DikoKIDP58MzzzyDUCiEnTt3YtWqVZg1axa38zD58MMPsXTpUvzpT3+yvD6cMTkSiWD9+vWW9xcsWIBQKITNmzfnxG4WKRItLS2oqKhAfn6++Vp1dTUCgQA6OzudM0wxSktLccIJJ5jPo9EoHnvsMSxbtgwtLS2oqamxfL6qqgoHDx4EgEHfZ6y8//77+Pjjj/Gtb33L8vpg7Xjo0CFu5yzYt28f6urq8Nxzz+HMM8/EKaecgl/+8peIRqPc1jnE6/Xihz/8If70pz+hvr4en/vc53DiiSfi0ksv5XYeJl/84hdx8803w+fzWV4fzpjc3d2NQCBged/j8aC8vDxn7e7JybccJvT391sECgDzeTAYdMKkw4K77roLmzZtwlNPPYWHHnooaRuL9k11Dbj9EwkEArjlllvwwx/+EAUFBZb3BmvHgYEBbucs8Pv92LNnD/74xz/i9ttvR0tLC374wx/C5/NxW+eYHTt24LOf/Sy+9rWvYdu2bbjttttw7LHHcjuPEIO1a7r3BwYGzOep/n64sEiR8Hq9CQ0rntsnASYz7rrrLjz88MP46U9/ipkzZ8Lr9SZ4pYLBoNm+qa5BaWnpaJmsDPfeey/mzp1r8VoJUrXjYO1sX2UxMTweD3p7e3HPPfegrq4OANDY2IgnnngCkyZN4rbOEe+//z6eeuopvPXWWygoKMC8efPQ3NyMX//615g4cSK38wgwnDHZ6/Waz+3v56rdOdwjMXbsWHR0dCAcDpuvtbS0oKCggCfJIXDbbbfhwQcfxF133YUzzjgDQKyNW1tbLZ9rbW013YWp3h8zZszoGK0Qf/vb3/D6669j4cKFWLhwIZ5//nk8//zzWLhwIbdzjhkzZgy8Xq8pUABgypQpaGpq4rbOIRs2bMCkSZMsi8LZs2ejsbGR23mEGE67lpeXw+v1Wt4Ph8Po7OzMWbuzSJGYNWsWPB6PJUmzoaEB8+bNg8vFTZUN9957L/74xz/iJz/5Cc4++2zz9fr6emzcuNF0EwKxNq6vrzffb2hoMN/r7+/Hpk2bzPeZOI8++iief/55PPfcc3juuedw8skn4+STT8Zzzz2H+vp6rF692qzjoes6Vq1albKdm5qa0NTUxO2cgvr6egQCAezatct8befOnairq+O2ziE1NTXYs2ePZWW+c+dOTJgwgdt5hBjOmOxyuTBv3jzL+2vWrIHH48FRRx2VGwNzskfoMOIHP/iBfvbZZ+tr167VX3vtNX3RokX6K6+84rRZSrF9+3Z91qxZ+k9/+lP90KFDlv/C4bB+1lln6d/5znf0rVu36vfff7++YMECc0/+vn379Hnz5un333+/uSf/3HPP5TopGfD973/f3ILZ09OjL1u2TL/tttv0bdu26bfddpt+/PHHm9sMV61apc+ZM0f/85//bNaUuOaaa5w0nzxXX321/vnPf17/5JNP9LfffltftmyZ/vDDD3Nb55Du7m79+OOP12+88UZ9586d+htvvKEfc8wx+hNPPMHtnEPkLcjDHZNfeOEFfdGiRfprr72mr127Vj/77LP12267LWe2skix4ff79ZtuuklfsGCBvnz5cv3BBx902iTluP/++/WZM2cm/U/XdX337t36l770JX3u3Ln62Wefrb/77ruWv//HP/6hn3766fr8+fP1r371q1znIENkkaLrseJWF1xwgT5v3jz9kksu0Tdu3Gj5/NNPP62fdNJJ+oIFC/Rrr71Wb29vH22TlaK7u1u/8cYb9QULFujHHnus/otf/MIcqLmtc8e2bdv0K6+8Ul+0aJF+6qmn6g8++CC3c46RRYquD39Mvv/++/Vjjz1WX7x4sb5ixQp9YGAgZ7Zqum74zhiGYRiGYQjBiRYMwzAMw5CERQrDMAzDMCRhkcIwDMMwDElYpDAMwzAMQxIWKQzDMAzDkIRFCsMwDMMwJGGRwjAMwzAMSVikMAzDMAxDEhYpDMMwDMOQhEUKwzAMwzAkYZHCMAzDMAxJ/j+ZisGfF87g3gAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(e[0,6].detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T16:01:15.432635Z",
     "start_time": "2024-05-04T16:01:15.308680Z"
    }
   },
   "id": "c6568a79ef0070ef",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.0350, -0.0520, -0.0780, -0.0730, -0.0770, -0.0800, -0.0800, -0.0780,\n        -0.0710, -0.0670, -0.0610, -0.0550, -0.0500, -0.0430, -0.0320, -0.0230,\n        -0.0120,  0.0070,  0.0260,  0.0500,  0.0810,  0.1050,  0.1340,  0.1570,\n         0.1550,  0.1460,  0.1250,  0.0860,  0.0450,  0.0080, -0.0170, -0.0330,\n        -0.0450, -0.0530, -0.0590, -0.0600, -0.0600, -0.0600, -0.0600, -0.0580,\n        -0.0550, -0.0520, -0.0500, -0.0470, -0.0450, -0.0490, -0.0500, -0.0500,\n        -0.0500, -0.0500, -0.0510, -0.0550, -0.0550, -0.0550, -0.0550, -0.0550,\n        -0.0590, -0.0600, -0.0600, -0.0600, -0.0600, -0.0590, -0.0550, -0.0550,\n        -0.0530, -0.0490, -0.0510, -0.0460, -0.0400, -0.0350, -0.0300, -0.0240,\n        -0.0180,  0.0010,  0.0430,  0.0570,  0.0450,  0.0430,  0.0260, -0.0150,\n        -0.0390, -0.0610, -0.0580, -0.0670, -0.0810, -0.0870, -0.0480,  0.0730,\n         0.2420,  0.6750,  0.7510,  0.3080,  0.0960,  0.0180, -0.0190, -0.0290,\n        -0.0460, -0.0480, -0.0590, -0.0510, -0.0510, -0.0460, -0.0440, -0.0430,\n        -0.0380, -0.0370, -0.0330, -0.0300, -0.0280, -0.0050,  0.0150,  0.0260,\n         0.0480,  0.0740,  0.1060,  0.1370,  0.1680,  0.1740,  0.1610,  0.1490,\n         0.1170,  0.0750,  0.0310, -0.0030, -0.0280, -0.0440, -0.0460, -0.0490,\n        -0.0520, -0.0550, -0.0550, -0.0550, -0.0550, -0.0550, -0.0520, -0.0490,\n        -0.0460, -0.0430, -0.0400, -0.0400, -0.0400, -0.0400, -0.0400, -0.0400,\n        -0.0400, -0.0440, -0.0450, -0.0450, -0.0500, -0.0500, -0.0510, -0.0550,\n        -0.0550, -0.0550, -0.0550, -0.0550, -0.0520, -0.0490, -0.0460, -0.0430,\n        -0.0400, -0.0390, -0.0270, -0.0160,  0.0040,  0.0380,  0.0450,  0.0350,\n         0.0240, -0.0030, -0.0400, -0.0680, -0.0790, -0.0800, -0.0970, -0.0840,\n        -0.1060, -0.0550,  0.0740,  0.2870,  0.7140,  0.6430,  0.2110,  0.0430,\n        -0.0350, -0.0550, -0.0730, -0.0840, -0.0790, -0.0820, -0.0770, -0.0760,\n        -0.0740, -0.0730, -0.0650, -0.0590, -0.0520, -0.0460, -0.0400, -0.0310,\n        -0.0190, -0.0060,  0.0060,  0.0330,  0.0640,  0.0970,  0.1300,  0.1600,\n         0.1730,  0.1620,  0.1470,  0.1030,  0.0500,  0.0110, -0.0190, -0.0340,\n        -0.0450, -0.0540, -0.0550, -0.0550, -0.0600, -0.0600, -0.0610, -0.0650,\n        -0.0650, -0.0650, -0.0650, -0.0650, -0.0650, -0.0650, -0.0650, -0.0650,\n        -0.0650, -0.0660, -0.0700, -0.0700, -0.0700, -0.0700, -0.0700, -0.0740,\n        -0.0750, -0.0750, -0.0750, -0.0750, -0.0740, -0.0700, -0.0700, -0.0700,\n        -0.0700, -0.0700, -0.0670, -0.0640, -0.0620, -0.0580, -0.0560, -0.0520,\n        -0.0350, -0.0040,  0.0310,  0.0410,  0.0330,  0.0320,  0.0130, -0.0330,\n        -0.0660, -0.0830, -0.0710, -0.0740, -0.0640, -0.0610, -0.0610,  0.0440,\n         0.1860,  0.5770,  0.6820,  0.2750,  0.0710, -0.0080, -0.0480, -0.0590,\n        -0.0790, -0.0780, -0.0880, -0.0760, -0.0760, -0.0700, -0.0650, -0.0620,\n        -0.0540, -0.0510, -0.0440, -0.0390, -0.0340, -0.0200, -0.0070,  0.0070,\n         0.0260,  0.0510,  0.0840,  0.1150,  0.1440,  0.1560,  0.1480,  0.1380,\n         0.1050,  0.0590,  0.0200, -0.0070, -0.0200, -0.0330, -0.0430, -0.0450,\n        -0.0450, -0.0480, -0.0510, -0.0490, -0.0460, -0.0430, -0.0410, -0.0370,\n        -0.0350, -0.0330, -0.0290, -0.0300, -0.0300, -0.0300, -0.0300, -0.0250,\n        -0.0250, -0.0250, -0.0250, -0.0250, -0.0270, -0.0310, -0.0300, -0.0340,\n        -0.0350, -0.0350, -0.0400, -0.0400, -0.0400, -0.0400, -0.0400, -0.0380,\n        -0.0310, -0.0270, -0.0210, -0.0140, -0.0120,  0.0040,  0.0190,  0.0570,\n         0.0930,  0.0840,  0.0750,  0.0550,  0.0190,  0.0070, -0.0090, -0.0100,\n        -0.0190, -0.0290, -0.0180, -0.0020,  0.0990,  0.2080,  0.5810,  0.7740,\n         0.3760,  0.1420,  0.0720,  0.0200,  0.0180, -0.0010,  0.0050, -0.0090,\n        -0.0100, -0.0140, -0.0100, -0.0050, -0.0040,  0.0030,  0.0040,  0.0100,\n         0.0200,  0.0290,  0.0410,  0.0530,  0.0750,  0.1010,  0.1240,  0.1520,\n         0.1810,  0.2050,  0.2250,  0.2350,  0.2120,  0.1700,  0.1270,  0.0840,\n         0.0470,  0.0210,  0.0090,  0.0040, -0.0010, -0.0070, -0.0130, -0.0150,\n        -0.0150, -0.0150, -0.0150, -0.0150, -0.0150, -0.0150, -0.0150, -0.0150,\n        -0.0150, -0.0150, -0.0170, -0.0210, -0.0200, -0.0200, -0.0200, -0.0200,\n        -0.0250, -0.0250, -0.0260, -0.0300, -0.0300, -0.0300, -0.0300, -0.0300,\n        -0.0300, -0.0300, -0.0300, -0.0250, -0.0250, -0.0240, -0.0200, -0.0210,\n        -0.0180, -0.0070,  0.0130,  0.0510,  0.0770,  0.0730,  0.0670,  0.0380,\n        -0.0080, -0.0320, -0.0530, -0.0480, -0.0610, -0.0550, -0.0650, -0.0600,\n         0.0730,  0.2290,  0.6570,  0.7750,  0.3230,  0.0970,  0.0190, -0.0190,\n        -0.0190, -0.0380, -0.0350, -0.0530, -0.0540, -0.0490, -0.0450, -0.0400,\n        -0.0360, -0.0310, -0.0240, -0.0180, -0.0100, -0.0050,  0.0020,  0.0220,\n         0.0410,  0.0660,  0.0920,  0.1190,  0.1510,  0.1790,  0.1970,  0.1860,\n         0.1690,  0.1320,  0.0770,  0.0310, -0.0040, -0.0280, -0.0400, -0.0510,\n        -0.0560, -0.0550, -0.0590, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,\n        -0.0600, -0.0600, -0.0630, -0.0650, -0.0650, -0.0690, -0.0700, -0.0700,\n        -0.0700, -0.0700, -0.0700, -0.0700, -0.0700, -0.0720, -0.0750, -0.0750,\n        -0.0750, -0.0750, -0.0750, -0.0750, -0.0750, -0.0750, -0.0750, -0.0750,\n        -0.0730, -0.0630, -0.0520, -0.0430, -0.0210,  0.0090,  0.0210,  0.0140,\n         0.0010, -0.0180, -0.0630, -0.0950, -0.1120, -0.1050, -0.1090, -0.1040,\n        -0.1030, -0.1090,  0.0160,  0.1630,  0.5560,  0.7190,  0.2910,  0.0500,\n        -0.0260, -0.0770, -0.0870, -0.1060, -0.0960, -0.1030, -0.0980, -0.1010,\n        -0.0970, -0.0920, -0.0900, -0.0850, -0.0820, -0.0780, -0.0710, -0.0620,\n        -0.0540, -0.0420, -0.0250, -0.0080,  0.0190,  0.0530,  0.0820,  0.1110,\n         0.1150,  0.1080,  0.0980,  0.0660,  0.0250, -0.0140, -0.0500, -0.0710,\n        -0.0800, -0.0850, -0.0850, -0.0860, -0.0900, -0.0900, -0.0870, -0.0850,\n        -0.0850, -0.0810, -0.0800, -0.0800, -0.0800, -0.0800, -0.0800, -0.0800,\n        -0.0800, -0.0820, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850,\n        -0.0850, -0.0850, -0.0850, -0.0850, -0.0820, -0.0790, -0.0800, -0.0800,\n        -0.0800, -0.0800, -0.0740, -0.0650, -0.0600, -0.0490, -0.0230,  0.0030,\n         0.0300,  0.0330,  0.0170,  0.0050, -0.0360, -0.0670, -0.0820, -0.0840,\n        -0.0960, -0.1010, -0.0850, -0.0890,  0.0200,  0.1380,  0.4790,  0.7300,\n         0.3590,  0.0830,  0.0180, -0.0410, -0.0510, -0.0710, -0.0610, -0.0700,\n        -0.0700, -0.0700, -0.0680, -0.0610, -0.0600, -0.0550, -0.0520, -0.0490,\n        -0.0400, -0.0300, -0.0200, -0.0080,  0.0120,  0.0340,  0.0580,  0.0880,\n         0.1070,  0.1380,  0.1650,  0.1600,  0.1510,  0.1170,  0.0700,  0.0260,\n        -0.0090, -0.0300, -0.0440, -0.0450, -0.0450, -0.0490, -0.0500, -0.0490,\n        -0.0450, -0.0450, -0.0450, -0.0450, -0.0450, -0.0410, -0.0400, -0.0400,\n        -0.0360, -0.0350, -0.0360, -0.0400, -0.0400, -0.0420, -0.0460, -0.0450,\n        -0.0490, -0.0500, -0.0500, -0.0500, -0.0500, -0.0500, -0.0500, -0.0500,\n        -0.0500, -0.0500, -0.0510, -0.0440, -0.0320, -0.0170,  0.0000,  0.0330,\n         0.0570,  0.0650,  0.0610,  0.0300, -0.0120, -0.0460, -0.0630, -0.0640,\n        -0.0680, -0.0650, -0.0450, -0.0640,  0.0330,  0.1460,  0.4510,  0.7680,\n         0.4510,  0.1360,  0.0550, -0.0120, -0.0170, -0.0390, -0.0400, -0.0560,\n        -0.0520, -0.0450, -0.0440, -0.0360, -0.0350, -0.0270, -0.0210, -0.0140,\n        -0.0070, -0.0020,  0.0070,  0.0220,  0.0340,  0.0540,  0.0840,  0.1130,\n         0.1390,  0.1730,  0.1990,  0.1990,  0.1830,  0.1510,  0.1090,  0.0650,\n         0.0240,  0.0020, -0.0040, -0.0110, -0.0190, -0.0260, -0.0300, -0.0300,\n        -0.0290, -0.0360, -0.0410, -0.0350, -0.0330, -0.0280, -0.0250, -0.0210,\n        -0.0200, -0.0200, -0.0160, -0.0140, -0.0170, -0.0200, -0.0200, -0.0220,\n        -0.0260, -0.0250, -0.0210, -0.0200, -0.0200, -0.0200, -0.0200, -0.0190,\n        -0.0110, -0.0030,  0.0040,  0.0140,  0.0190,  0.0600,  0.0970,  0.0940,\n         0.0850,  0.0530,  0.0070, -0.0180, -0.0380, -0.0420, -0.0390, -0.0410,\n        -0.0250, -0.0450,  0.0380,  0.1620,  0.4990,  0.8260,  0.4910,  0.1340,\n         0.0470, -0.0050, -0.0080, -0.0260, -0.0250, -0.0360, -0.0390, -0.0340,\n        -0.0320, -0.0270, -0.0240, -0.0200, -0.0150, -0.0060,  0.0020,  0.0110,\n         0.0240,  0.0390,  0.0490,  0.0660,  0.0940,  0.1220,  0.1500,  0.1820,\n         0.1970,  0.1910,  0.1850,  0.1560,  0.1060,  0.0620,  0.0210, -0.0060,\n        -0.0140, -0.0210, -0.0270, -0.0340, -0.0390, -0.0350, -0.0350, -0.0340,\n        -0.0290, -0.0310, -0.0270, -0.0250, -0.0250, -0.0210, -0.0200, -0.0210,\n        -0.0250, -0.0250, -0.0260, -0.0310, -0.0290, -0.0330, -0.0350, -0.0350,\n        -0.0390, -0.0410, -0.0390, -0.0360, -0.0330, -0.0310, -0.0270, -0.0260,\n        -0.0220, -0.0140, -0.0050,  0.0110,  0.0470,  0.0690,  0.0530,  0.0380,\n        -0.0010, -0.0430, -0.0540, -0.0800, -0.0850, -0.0920, -0.0720, -0.0880,\n        -0.0400,  0.0900,  0.3080,  0.7380,  0.6290,  0.1800,  0.0440, -0.0270,\n        -0.0570, -0.0710, -0.0710, -0.0700, -0.0780, -0.0720, -0.0740, -0.0680,\n        -0.0670, -0.0630, -0.0600, -0.0590, -0.0510, -0.0430, -0.0350, -0.0280,\n        -0.0180,  0.0040,  0.0290,  0.0550,  0.0850,  0.1140,  0.1420,  0.1550,\n         0.1480,  0.1160,  0.0630,  0.0150, -0.0230, -0.0490, -0.0640, -0.0800,\n        -0.0860, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850, -0.0850,\n        -0.0850, -0.0850, -0.0850, -0.0900, -0.0900, -0.0900, -0.0900, -0.0890,\n        -0.0930, -0.0950, -0.0950, -0.0950, -0.0950, -0.0940, -0.0900, -0.0900,\n        -0.0900, -0.0900, -0.0910, -0.0870, -0.0840, -0.0850, -0.0840, -0.0860,\n        -0.0840, -0.0810, -0.0740, -0.0730, -0.0630, -0.0310, -0.0190, -0.0190,\n        -0.0240, -0.0280, -0.0610, -0.1030, -0.1260, -0.1240, -0.1150, -0.1180,\n        -0.0960, -0.1180, -0.0280,  0.0860,  0.3980,  0.7050,  0.3690,  0.0550,\n        -0.0280, -0.0910, -0.0910, -0.1110, -0.1020, -0.1060, -0.1050, -0.1040],\n       dtype=torch.float64)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0,1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T16:00:49.768552Z",
     "start_time": "2024-05-04T16:00:49.734224Z"
    }
   },
   "id": "fdeb480032d4c81e",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cfb71edeb3acefa7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "504f15415a04d342"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN1d"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "222339ccd77bf4ea"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bn_drop_lin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrnn1d\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RNN1d\n\u001B[1;32m----> 3\u001B[0m rnn1d_model \u001B[38;5;241m=\u001B[39m \u001B[43mRNN1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_channels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m rnn1d_model\u001B[38;5;241m.\u001B[39mdouble()\n\u001B[0;32m      5\u001B[0m rnn1d_model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ecg-tool-api\\models\\nn\\rnn1d.py:61\u001B[0m, in \u001B[0;36mRNN1d.__init__\u001B[1;34m(self, input_channels, num_classes, lstm, hidden_dim, num_layers, bidirectional, ps_head, act_head, lin_ftrs_head, bn)\u001B[0m\n\u001B[0;32m     57\u001B[0m actns \u001B[38;5;241m=\u001B[39m [nn\u001B[38;5;241m.\u001B[39mReLU(inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mif\u001B[39;00m act_head \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m nn\u001B[38;5;241m.\u001B[39mELU(inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)] \u001B[38;5;241m*\u001B[39m (\u001B[38;5;28mlen\u001B[39m(lin_ftrs_head) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m+\u001B[39m [\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ni, no, p, actn \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(lin_ftrs_head[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], lin_ftrs_head[\u001B[38;5;241m1\u001B[39m:], ps_head, actns):\n\u001B[1;32m---> 61\u001B[0m     layers_head \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mbn_drop_lin\u001B[49m(ni, no, bn, p, actn)\n\u001B[0;32m     62\u001B[0m layers_head \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\u001B[38;5;241m*\u001B[39mlayers_head)\n\u001B[0;32m     63\u001B[0m layers_tmp\u001B[38;5;241m.\u001B[39mappend(layers_head)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'bn_drop_lin' is not defined"
     ]
    }
   ],
   "source": [
    "from models.nn.rnn1d import RNN1d\n",
    "\n",
    "rnn1d_model = RNN1d(input_channels=12, num_classes=5)\n",
    "rnn1d_model.double()\n",
    "rnn1d_model.eval()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T10:33:49.365070Z",
     "start_time": "2024-05-03T10:33:49.330372Z"
    }
   },
   "id": "4baa946bde015adf",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "de191766aeffc829"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2a6673d6d613922a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "85f5fb2071e0d9d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e1153629844478b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ad6a36b899ecefac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
